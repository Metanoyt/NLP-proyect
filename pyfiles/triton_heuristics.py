mypy allow-untyped-defs __future__ annotations builtins copy dataclasses functools hashlib inspect itertools logging math operator os os path re sys threading time collections namedtuple typing Any Callable Generic Literal TYPE_CHECKING TypeVar Union torch torch _dynamo utils counters set_feature_use torch _environment is_fbcode torch _inductor metrics torch _prims_common compute_required_storage_length torch utils _ordered_set OrderedSet triton_bundler TritonBundler utils prefix_is_reduction triton_version_uses_attrs_dict triton_helpers autotune_cache AutotuneCache benchmarking benchmarker coordinate_descent_tuner CoordescTuner hints _NUM_THREADS_PER_WARP AutotuneHint DeviceProperties HeuristicType ReductionHint TileHint TRITON_MAX_BLOCK TRITON_MAX_RSPLIT runtime_utils ceildiv conditional_product create_bandwidth_info_str dynamo_timed get_first_attr get_max_y_grid get_num_bytes next_power_of_ triton_cache_dir triton_config_to_hashable triton_hash_to_path_key validate_triton_config static_cuda_launcher StaticallyLaunchedCudaKernel triton_compat ASTSource autograd_profiler cc_warp_size CompiledKernel Config GPUTarget HAS_WARP_SPEC KernelInterface knobs OutOfResources PTXASError triton triton_helpers get_constexprs InductorConfig Config Inductor-specific Triton config additional control flags __init__ args dynamic_scale_rblock=True kwargs super __init__ args kwargs dynamic_scale_rblock = dynamic_scale_rblock NoTritonConfigsError RuntimeError pass TYPE_CHECKING collections abc Container Hashable torch _guards CompileId LauncherType = Any _KernelType = Union CompiledKernel StaticallyLaunchedCudaKernel _T = TypeVar _T bound=_KernelType log = logging getLogger __name__ triton_name_sub = re compile r ^def ^ +\ generate_lookup_hash_from_source_code size_hints_str str source_code str - str Name agnostic + strip white space fn_strip_name = re sub triton_name_sub source_code strip count= hash_str = size_hints_str + fn_strip_name fn_hash = hashlib sha hash_str encode utf- hexdigest fn_hash lookup_autotune_config size_hints fn - Config &#124; None lookup_table = torch _inductor config autotune_lookup_table cached_config = None len lookup_table _fused_ fn src fn_hash = generate_lookup_hash_from_source_code str size_hints fn src fn_hash lookup_table config_dict = lookup_table fn_hash block_configs = k v k v config_dict items BLOCK k cached_config = Config block_configs num_warps=config_dict num_warps num_stages=config_dict num_stages cached_config get_total_reduction_numel numels dict str int - int conditional_product numel prefix numel numels items prefix_is_reduction prefix autotune_hints_to_configs hints OrderedSet AutotuneHint size_hints block_size int device_props DeviceProperties - list Config AutotuneHints can attached metadata triton kernels providing suggestions about what try autotuning One reason do there some configs only useful specific scenarios which case we can avoid wasting compile time autotuning unless we know we one those scenarios Based those hints function will generate list additional autotuning configs try xyz_options tuple tuple int int &#124; None int &#124; None configs list Config = hint hints hint == AutotuneHint ONE_ELEMENT_PER_THREAD len size_hints == xyz_options = block_size None None len size_hints == xyz_options = block_size None block_size None len size_hints == xyz_options = block_size block_size block_size configs extend triton_config size_hints xyz num_elements_per_warp= device_props warp_size device_props warp_size xyz xyz_options configs _dump_launch_params args kwargs launcher kernel_name grid call_args = call_kwargs = arg args isinstance arg int bool call_args append str arg call_args append T k v kwargs items isinstance arg int bool call_kwargs k = v call_kwargs k = v call_kwargs update launcher config kwargs call_kwargs num_warps = launcher config num_warps call_kwargs num_stages = launcher config num_stages HAS_WARP_SPEC call_kwargs num_consumer_groups = getattr launcher config num_consumer_groups call_kwargs num_buffers_warp_spec = getattr launcher config num_buffers_warp_spec args_str = call_args args_str extend f k = v k v call_kwargs items args_str = join args_str abs_path = os path abspath sys argv open f abs_path launch_params f f write f kernel_name &#124; args_str &#124; grid r \n check_autotune_cache configs list Config filename str &#124; None inductor_meta dict str Any - tuple list Config AutotuneCache &#124; None dict str Any Given list configs checks autotune cache metadata autotune_cache = None autotune_cache_info = disabled = inductor_meta get force_disable_caches False disabled filename None len configs inductor_meta get coordinate_descent_tuning os environ get TRITON_INTERPRET = configs_hash = hash_configs configs autotune_cache = AutotuneCache create inductor_meta filename configs_hash autotune_cache best_config = autotune_cache read_best inductor_meta configs configs = best_config autotune_cache_info best_config = triton_config_to_hashable best_config autotune_cache_info autotune_cache_state = hit autotune_cache_info autotune_cache_state = miss autotune_cache_info num_configs = len configs inductor_meta get coordinate_descent_tuning autotune_cache_info coordesc_tuning = True len configs == This config coordinate descent tuning started which same final config chosen i e only_config best_config autotune_cache_info coordesc_tuning_start_config = triton_config_to_hashable configs len configs == autotune_cache_info autotune_cache_state = only config autotune_cache_info only_config = triton_config_to_hashable configs disabled autotune_cache_info autotune_cache_state = force_disabled log debug autotune caching disabled config force_disable_caches configs autotune_cache autotune_cache_info CachingAutotuner KernelInterface Simplified version Triton autotuner has no invalidation key caches best config disk improve cold start times Unlike main triton Autotuner version can precompile all configs does rely Triton JIT __init__ fn triton_meta passed directly triton configs save_cache_hook mutated_arg_names list str see Note clone mutated buffers optimize_mem heuristic_type size_hints=None inductor_meta=None metadata relevant triton custom_kernel=False whether kernel inductor-generated custom filename str &#124; None = None reset_to_zero_arg_names list str &#124; None = None autotune_cache_info dict str Any &#124; None = None super __init__ assert len configs Non-empty TritonConfig list required compiling makes sure there no pre-hooks any triton configs cfg configs validate_triton_config cfg fn = fn device_props DeviceProperties = triton_meta device triton_meta = triton_meta device device_props index device_type device_props type inductor_meta = inductor_meta None inductor_meta deterministic_mode = inductor_meta get deterministic False save_cache_hook = save_cache_hook mutated_arg_names = mutated_arg_names reset_to_zero_arg_names = reset_to_zero_arg_names None reset_to_zero_arg_names optimize_mem = optimize_mem cached_config = lookup_autotune_config size_hints fn configs = cached_config cached_config configs heuristic_type = heuristic_type custom_kernel = custom_kernel cuda_kernel_saved = False autotune_cache_info = autotune_cache_info log isEnabledFor logging DEBUG log debug CachingAutotuner gets d configs s len configs fn __name__ c configs log debug c compile_results list CompileResult _KernelType = launchers list LauncherType = lock = threading Lock os getenv TRITON_CACHE_DIR None os environ TRITON_CACHE_DIR = triton_cache_dir triton_meta get device log debug Triton cache dir s os environ TRITON_CACHE_DIR size_hints = size_hints coordesc_tuner = CoordescTuner is_mm=False is_native_matmul=triton_meta get native_matmul False name=self fn __name__ size_hints=size_hints inductor_meta=self inductor_meta filename = filename used profiling kernel_hash str = Kernels stored codecache filename hash code We rely obtain kernel hash filename None base_name = os path basename filename py base_name kernel_hash = os path splitext base_name precompile_time_taken_ns = autotune_time_taken_ns = Dumps launch configs after autotuning dump_launch_params = os environ get TORCHINDUCTOR_DUMP_LAUNCH_PARAMS == triton_interpret = os environ get TRITON_INTERPRET == Compile-time info included runtime logginging compile_id CompileId &#124; None = None is_backward = False Mode launch grid calculation grid_mode Literal python cpp = python is_statically_launchable Checks every compiled kernel statically launchable which allows us efficiently cache FXGraphCache compile_results False all isinstance x StaticTritonCompileResult x compile_results recheck_autotune_cache reload_kernel_from_src Callable CachingAutotuner - None On cache load static autotuner we need recheck autotune cache since best config could have been found previous run assert is_statically_launchable configs = result config result compile_results cached_configs _ autotune_cache_info = check_autotune_cache configs filename inductor_meta autotune_cache_info = autotune_cache_info I e there autotune cache hit len cached_configs == len configs best_config = cached_configs Grab best compiled config s list available ones best_config_hash = triton_config_to_hashable best_config compile_result compile_results triton_config_to_hashable compile_result config == best_config_hash compile_results = compile_result If best config isn t our list compile results s likely because found coordesc after cache already saved best_config found_by_coordesc dynamo_timed CachingAutotuner slow_precompile_config fn fn None fn = reload_kernel_from_src fn compile_results = _precompile_config best_config set_compile_info compile_id CompileId &#124; None is_backward bool - None compile_id = compile_id is_backward = is_backward precompile warm_cache_only=False reload_kernel Callable CachingAutotuner &#124; None = None static_triton_bundle_key str &#124; None = None warm_cache_only _precompile_worker lock Helper function reloading kernel generated worker parent Normally we don t need reload kernel parent process certain cases coordesc tuning dynamic_scale_rblock we need actually run compilation parent process reload_kernel None _reload_kernel = reload_kernel _precompile_worker static_triton_bundle_key None is_statically_launchable TritonBundler put_static_autotuner static_triton_bundle_key _make_launchers _dynamic_scale_rblock _precompile_worker compile_results result compile_results TritonBundler put triton_hash_to_path_key result kernel hash type ignore attr-defined triton_meta get device assert launchers configs raise NoTritonConfigsError No triton configs available compile_results = exc = None c configs try compile_results append _precompile_config c except OutOfResources PTXASError e exc = e len compile_results == raise NoTritonConfigsError f No valid triton configs type exc __name__ exc compile_results = compile_results configs = None _dynamic_scale_rblock TODO jansel we should find way move extra compile into worker process Currently relies _make_launchers which requires cuda context populate nreg device_prop = device_props deterministic_mode inductor_meta get dynamic_scale_rblock True inductor_meta get persistent_reduction heuristic_type == HeuristicType REDUCTION size_hints None Disable Intel Triton ready n_regs compiled_binary device_prop type cuda hip device_prop major device_prop major = torch version hip device_prop regs_per_multiprocessor None assert device_prop regs_per_multiprocessor assert device_prop max_threads_per_multi_processor assert device_prop multi_processor_count seen_config_hashes OrderedSet Hashable &#124; None = None warp_size = device_prop warp_size result compile_results triton_config = result config compiled_binary = result kernel assert len size_hints = xblock = triton_config kwargs get XBLOCK reduction_kwargs = kwarg kwarg triton_config kwargs kwarg startswith R rblocks = triton_config kwargs kwarg kwarg reduction_kwargs total_block = size_hints x + xblock - xblock nreg = getattr compiled_binary n_regs None nreg None continue make sure rblocks too small conditional_product rblocks = continue each SM A has -bit registers To maximize theoretical occupancy we need run threads each SM So each thread should use no more than = registers In cases where occupancy matters each thread uses too many registers reduce R _BLOCK reduce register usage For kernel https gist github com shunting e cccc fe d b b c c cbd PLBartForCausalLM latency improve ms ms nreg = device_prop regs_per_multiprocessor device_prop max_threads_per_multi_processor continue nreg_per_warp = nreg warp_size nreg_per_block = nreg_per_warp triton_config num_warps Previously we set max_blocks_per_sm max_threads_per_multi_processo num_warps The formula below tighter upper bound since we have assumption nreg device_prop regs_per_multiprocessor device_prop max_threads_per_multi_processor due condition above regs_per_multiprocessor nreg_per_block = regs_per_multiprocessor nreg num_warps regs_per_multiprocessor regs_per_multiprocessor max_threads_per_multi_processor num_warps = max_threads_per_multi_processor num_warps Using tighter upper bound can reveal more optimization opportunities max_blocks_per_sm = max device_prop regs_per_multiprocessor nreg_per_block total_block = max_blocks_per_sm device_prop multi_processor_count no need improve occupancy continue new_config = copy deepcopy triton_config Reduce largest Rn_BLOCK factor largest_rkwarg str = max reduction_kwargs key=triton_config kwargs __getitem__ new_config kwargs largest_rkwarg = seen_config_hashes None seen_config_hashes = OrderedSet triton_config_to_hashable x config x compile_results new_config_hash = triton_config_to_hashable new_config new_config_hash seen_config_hashes continue seen_config_hashes add new_config_hash log debug Dynamically scale down s TritonConfig s get new TritonConfig s largest_rkwarg triton_config new_config fn fn None We parent process while program compiled worker fn dropped prepare_for_pickle We haven t loaded module containing real fn yet assert hasattr _reload_kernel assert callable _reload_kernel fn = _reload_kernel fn compile_results append _precompile_config new_config noqa B _make_launchers _make_launchers len launchers == len compile_results torch _dynamo device_interface DeviceGuard device_interface = get_device_interface load binary correct device DeviceGuard device_interface triton_meta device need initialize context dynamo_timed CachingAutotuner synchronize Deliberately avoid overloading pt _compile_events log_pt _compile_event=False device_interface synchronize device_interface current_device launchers = exc = None result compile_results try launchers append result make_launcher except OutOfResources PTXASError torch cuda OutOfMemoryError e exc = e len launchers == raise RuntimeError f No valid triton configs type exc __name__ exc launchers = launchers prepare_for_pickle - tuple Any Any Any Any Any Any Drop stuff triton JITFunction does pickle This must called after precompile so these things no longer needed Returns tuple old values old_values = fn fn fn __globals__ fn used_global_vals fn repr launchers getattr fn _hash_lock None fn fn = None fn __globals__ = None fn used_global_vals = None fn repr = _ConstRepr fn repr fn launchers = fn _hash_lock = None old_values restore_after_unpickle old_values tuple Any Any Any Any Any Any &#124; None - None old_values fn fn fn __globals__ fn used_global_vals fn repr launchers fn _hash_lock = old_values even we don t need have specific values we do need _hash_lock valid RLock fn _hash_lock = threading RLock prepare_for_caching - None Statically Launched CUDA Kernels have raw cubin them we don t need store cache since TritonBundler handles collection us result compile_results isinstance result StaticTritonCompileResult Don t save inductor cache very large result kernel cubin_raw = None __getstate__ - dict str Any assert launchers pickle should called after make_launchers __dict__ lock None __setstate__ state dict str Any - None __dict__ update state lock = threading Lock get_device_interface code cannot run compile workers because imports torch torch _dynamo device_interface get_interface_for_device get_interface_for_device device_props type replace hip cuda _create_compile_meta cfg Config - dict str Any Create compilation metadata given autotuner config This involves processing Config kwargs so kwargs part triton signature passed options triton compile instead compile_meta = copy deepcopy triton_meta compile_meta num_warps = cfg num_warps compile_meta num_stages = cfg num_stages cfg_kwargs = cfg kwargs device_props type == hip cfg_kwargs = cfg_kwargs k matrix_instr_nonkdim waves_per_eu kpack k cfg_kwargs compile_meta k = cfg_kwargs pop k compile_meta constants update cfg_kwargs i get_constexprs fn arg_name = fn arg_names i arg_name compile_meta constants arg_name == num_warps arg_name == num_stages compile_meta constants arg_name = getattr cfg arg_name HAS_WARP_SPEC compile_meta num_consumer_groups = getattr cfg num_consumer_groups compile_meta num_buffers_warp_spec = getattr cfg num_buffers_warp_spec compile_meta debug = inductor_meta get assert_indirect_indexing True inductor_meta get is_hip False device type will hip rather than cuda here compile_meta device_type = device_props type compile_meta cc = device_props cc compile_meta _create_compile_options cfg Config compile_meta dict str Any - dict str Any Create options pass triton compile based compile metadata given config options = num_warps compile_meta num_warps num_stages compile_meta num_stages debug compile_meta debug sanitize_overflow False turn off additional asserts added overflow checks enable_fp_fusion compile_meta options enable_fp_fusion = compile_meta enable_fp_fusion HAS_WARP_SPEC options update num_consumer_groups compile_meta get num_consumer_groups num_buffers_warp_spec compile_meta get num_buffers_warp_spec device_props type == cuda options update launch_cooperative_grid compile_meta get launch_cooperative_grid False launch_pdl compile_meta get launch_pdl False True device_props type == hip waves_per_eu compile_meta options waves_per_eu = compile_meta waves_per_eu matrix_instr_nonkdim compile_meta options matrix_instr_nonkdim = compile_meta matrix_instr_nonkdim options _precompile_config cfg Config - CompileResult _KernelType Ahead time compile given autotuner config compile_meta = _create_compile_meta cfg device_props type == cpu triton_helpers set_driver_to_cpu triton_helpers set_driver_to_gpu ASTSource raise RuntimeError Installed triton version too old please upgrade compile_args = ASTSource fn compile_meta signature compile_meta constants compile_meta configs device_props type == mtia mtia host_runtime torch_mtia acc_flags type ignore import-not-found build_codename arch = build_codename arch = compile_meta cc target = GPUTarget compile_meta device_type arch cc_warp_size compile_meta cc options = _create_compile_options cfg compile_meta compile_kwargs = target target options options try binary = triton compile compile_args compile_kwargs except Exception log exception Triton compilation failed s\n s\nmetadata s inductor_meta get kernel_name triton_ fn src compile_meta raise Simulate JIT Hook call torch _inductor config run_jit_post_compile_hook knobs getattr knobs runtime jit_post_compile_hook None try hook = knobs runtime jit_post_compile_hook base args everyone should get call_kwargs = dict key=getattr fn cache_key kernel_hash str fn repr=getattr fn src None fn=self fn compile=binary is_manual_warmup=False already_compiled=True only add inductor_args hook takes sig = inspect signature hook params = sig parameters inductor_args params call_kwargs inductor_args = inductor_meta config_args hook call_kwargs except Exception log exception jit_post_compile_hook failed TritonBundler put triton_hash_to_path_key binary hash triton_meta get device If binary has cubin file directly launch save binary static_launcher = StaticTritonCompileResult can_statically_launch binary inductor_meta triton_meta heuristic_type static_launcher None result = StaticTritonCompileResult static_launcher cfg compile_meta inductor_meta result TritonCompileResult binary cfg compile_meta inductor_meta bench launcher args with_profiler=False kwargs Measure performance given launcher we don t skip configs spilled registers when auto-tuning custom user-written Triton kernels i we don t have any knowledge control over kernel code ii there empirical evidence some complicated custom Triton kernels register-spilling config may yield best latency custom_kernel launcher n_spills inductor_meta get spill_threshold torch version hip log debug Skip config s because register spilling d launcher config launcher n_spills float inf device_interface = get_device_interface stream = device_interface get_raw_stream device_interface current_device cpu_copies = copy_args_to_cpu_if_needed args kwargs kernel_call cloned_args cloned_kwargs = maybe_clone_args cpu_copies args kwargs reset zero before evaluating any config reset_to_zero_args args kwargs kernel_name = inductor_meta get kernel_name triton kernel autograd_profiler _is_profiler_enabled profiler_kwargs = get_profiler_kwargs stream launcher torch _C _profiler _RecordFunctionFast kernel_name cloned_args profiler_kwargs try launcher cloned_args cloned_kwargs stream=stream except Exception log error Failed during launch s kernel_name raise try launcher cloned_args cloned_kwargs stream=stream except Exception log error Failed during launch s kernel_name raise restore_args_from_cpu cpu_copies only use profiler when already profiler instance with_profiler autograd_profiler _is_profiler_enabled torch _inductor utils do_bench_using_profiling do_bench_using_profiling kernel_call warmup= rep= device_props type == cpu benchmarker benchmark_cpu kernel_call benchmarker benchmark_gpu kernel_call rep= is_vetted_benchmarking=True copy_args_to_cpu_if_needed args kwargs To support benchmarking presence mutated args we need avoid autotuning contanminating them We try pass cloned args kernel If those clones would increase peak memory usage however we instead copy cpu restore them after each iteration Figure out args copied do copying optimize_mem copies = try budget = torch cuda max_memory_allocated - torch cuda memory_allocated except RuntimeError Possibly custom CUDA allocator see https github com pytorch pytorch issues maybe_copy name arg name mutated_arg_names arg is_cuda nonlocal budget assert isinstance arg torch Tensor required_storage_length = compute_required_storage_length arg size arg stride size = required_storage_length arg element_size size budget cpu_arg = torch empty_strided required_storage_length dtype=arg dtype device= cpu pin_memory=True cpu_arg copy_ arg as_strided required_storage_length non_blocking=True copies name = arg cpu_arg budget -= size name arg zip fn arg_names args maybe_copy name arg name arg kwargs items maybe_copy name arg copies restore_args_from_cpu cpu_copies pair cpu_copies values arg cpu_arg = pair required_storage_length = compute_required_storage_length arg size arg stride arg as_strided required_storage_length copy_ cpu_arg non_blocking=True reset_to_zero_args args kwargs reset_to_zero_arg_names i arg enumerate args fn arg_names i reset_to_zero_arg_names assert isinstance arg torch Tensor reset_to_zero_arg_names should only contain valid argument names arg zero_ name arg kwargs items name reset_to_zero_arg_names assert isinstance arg torch Tensor reset_to_zero_arg_names should only contain valid argument names arg zero_ maybe_clone_args exclude Container str args kwargs - tuple list Any dict str Any Prepare new args kwargs cloning any in-place buffers provided exclusion list avoid autotune contaminating them Avoid cloning other buffers because leads increased memory usage compile_fx clone_preserve_strides prepare_arg name arg name mutated_arg_names name exclude assert isinstance arg torch Tensor clone_preserve_strides arg arg cloned_args = prepare_arg name arg name arg itertools zip_longest fn arg_names len args args cloned_kwargs = name prepare_arg name arg name arg kwargs items cloned_args cloned_kwargs clone_args args kwargs - tuple list Any dict str Any maybe_clone_args OrderedSet args kwargs benchmark_all_configs args kwargs dynamo_timed CachingAutotuner benchmark_all_configs log_pt _compile_event=True metadata= kernel_name inductor_meta get kernel_name dynamo_compile_column_us= runtime_triton_autotune_time_us compile_id=self compile_id is_backward=self is_backward log_waitcounter=True waitcounter_name_override= triton_autotuner Temporarily disable due spam compilation_callback callback_handler install_callbacks compilation_callback CallbackTrigger TRITON_AUTOTUNING str compile_id timings = launcher bench launcher args kwargs launcher launchers k v timings items coordesc_tuner cache_benchmark_result k config v log isEnabledFor logging DEBUG log debug Benchmark all input configs s get fn __name__ k v timings items log debug s f nreg d nspill d #shared-mem s k config v k n_regs k n_spills k shared metrics is_metric_table_enabled kernel_autotune fn fn None fn = _reload_kernel fn kernel_path = fn fn __code__ co_filename kernel_name = fn __name__ k v timings items metrics log_kernel_autotune_result kernel_path kernel_name k config v reset_to_zero_args args kwargs timings autotune_to_one_config args kwargs Do actual autotuning start_time = time time_ns timings = benchmark_all_configs args kwargs benchmark_time_taken_ns = time time_ns - start_time launchers = builtins min timings key=timings get autotune_time_taken_ns = precompile_time_taken_ns + benchmark_time_taken_ns log best config launcher = launchers log debug Best config s s f nreg d nspill d #shared-mem s fn __name__ launcher config timings launcher launcher n_regs launcher n_spills launcher shared save_cache_hook save_cache_hook launcher config autotune_time_taken_ns triton_cache_hash=launcher cache_hash save_gpu_kernel stream launcher key = inductor_meta get kernel_name None unique kernel name assert key None kernel_name can None params = mangled_name launcher bin metadata name hasattr launcher bin metadata name launcher bin metadata name num_warps launcher bin num_warps hasattr launcher bin num_warps launcher bin metadata num_warps shared_mem launcher bin shared hasattr launcher bin shared launcher bin metadata shared stream stream User defined triton kernels will have arbitrary kwarg names config config_to_dict launcher config inductor_meta inductor_meta triton_meta triton_meta def_args launcher def_args call_args launcher call_args global_scratch launcher global_scratch profile_scratch launcher profile_scratch device_props type == xpu On XPU backend threads_per_warp always For Intel GEMM Triton kernels can This information must preserved so Cpp wrapper can launch kernel correct configuration params threads_per_warp = getattr launcher bin metadata threads_per_warp torch _inductor codecache CudaKernelParamCache bin_type = hip hsaco xpu spv get device_props type cubin binary = launcher bin asm bin_type Also store asm code which can used debugging generating cpp package asm_type = hip amdgcn cuda ptx xpu spv get device_props type None asm = launcher bin asm get asm_type None CudaKernelParamCache set key params binary bin_type asm asm_type cuda_kernel_saved = True coordinate_descent_tuning launcher args kwargs Coordinate descent tuning can run without max-autotune The only difference between these two starting config coordinate_descent tuning E g assuming regular autotune only get one config C while max-autotune get configs C C C C max-autotune figure out C best Then coordinate desecnt tuning run max-autotune disabled will start C while coordinate descent tuning run max-autotune enabled will start C heuristic_type HeuristicType TEMPLATE HeuristicType USER_AUTOTUNE HeuristicType FIXED skip triton template launcher deterministic_mode heuristic_type HeuristicType REDUCTION HeuristicType PERSISTENT_REDUCTION HeuristicType SPLIT_SCAN Not only RBLOCK size matters numericals reduction num_warps also matters since affect how much data handled each thread how many warp-reduction we do parallel how much data there block reduction launcher dynamo_timed CachingAutotuner coordinate_descent_tuning These generate too many pt _compile_event logs log_pt _compile_event=False metadata= kernel_name inductor_meta get kernel_name dynamo_compile_column_us= runtime_triton_autotune_time_us compile_id=self compile_id is_backward=self is_backward log_waitcounter=True waitcounter_name_override= triton_autotuner _coordinate_descent_tuning launcher args kwargs _coordinate_descent_tuning launcher args kwargs config launcher = launcher config launcher TODO should we just load kernels ahead time we know we re going call fn fn None We parent process while program compiled worker fn dropped prepare_for_pickle We haven t loaded module containing real fn yet assert hasattr _reload_kernel assert callable _reload_kernel fn = _reload_kernel fn benchmark_one_config config lock launcher = _precompile_config config make_launcher config launcher config = launcher out = bench launcher args kwargs counters inductor coordesc_tuning_bench += log debug COORDESC s f nreg d nspill d #shared-mem d launcher config out launcher n_regs launcher n_spills launcher shared out assert heuristic_type == HeuristicType PERSISTENT_REDUCTION R _BLOCK launcher config kwargs Coordinate descent tuner relies assumption persistent reduction s triton config does have R _BLOCK start_time = time time_ns best_config = coordesc_tuner autotune benchmark_one_config launcher config None coordesc_time_taken_ns = time time_ns - start_time best_config found_by_coordesc = True save_cache_hook save_cache_hook best_config autotune_time_taken_ns + coordesc_time_taken_ns found_by_coordesc=True best_config config launcher On Coordesc cache hit we might have loaded launcher This can happen because PyCodeCache saves CachingAutotuners memory even separate compile IDs which can have different inputs without changing output code config launcher best_config = _precompile_config best_config make_launcher fn_hash = generate_lookup_hash_from_source_code str size_hints fn src log debug Function hash s has best config s fn_hash best_config config launcher best_config get_profiler_kwargs stream launcher kernel_kwargs_str = join f k = v k v launcher config kwargs items ret = kernel_file filename kernel_hash kernel_hash kernel_backend triton stream stream num_warps launcher config num_warps num_stages launcher config num_stages kernel_kwargs kernel_kwargs_str kernel_name inductor_meta ret kernel_name = inductor_meta kernel_name kernel_flop inductor_meta ret kernel_flop = inductor_meta kernel_flop kernel_num_gb inductor_meta ret kernel_num_gb = inductor_meta kernel_num_gb ret run args stream benchmark_run=False kwargs type ignore override hasattr triton set_allocator alloc_fn size int align int stream int &#124; None torch empty size dtype=torch int device=self device_props type triton set_allocator alloc_fn triton_interpret args grid = _interpret_args_grid args configs fn grid args kwargs configs kwargs len launchers = len launchers == start_time = time time_ns precompile precompile_time_taken_ns = time time_ns - start_time len launchers autotune_to_one_config args kwargs getattr launchers config found_by_coordesc False inductor_meta get coordinate_descent_tuning False launchers = coordinate_descent_tuning launchers args kwargs launcher = launchers launcher store_cubin benchmark_run cuda_kernel_saved save_gpu_kernel stream launcher PyTorch execution trace replay calls CachingAutotuner run instead calls launcher so _RecordFunctionFast need capture args into CachingAutotuner run make copy here avoid mutating original args args_without_constexprs = tuple args dump_launch_params new_args grid = _interpret_args_grid args launcher config _dump_launch_params new_args kwargs launcher fn __name__ grid faster than entering exiting context manager even context manager nullcontext autograd_profiler _is_profiler_enabled profiler_kwargs = get_profiler_kwargs stream launcher torch _C _profiler _RecordFunctionFast inductor_meta get kernel_name triton kernel args_without_constexprs profiler_kwargs launcher args kwargs stream=stream launcher args kwargs stream=stream _interpret_args_grid args tuple Any cfg Config - tuple tuple Any tuple int int int triton_version_uses_attrs_dict filtered_signature - list str constexprs passed args new_signature list str = triton runtime interpreter InterpretedFunction i x enumerate triton_meta signature keys isinstance fn InterpretedFunction These torch compiled triton kernels definitely have block size configs Dynamo does currently trace user defined triton kernels when TRITON_INTERPRET= x cfg kwargs keys new_signature append x i get_constexprs fn use constexprs rather than just configs since user defined triton kernels may have any configs new_signature append x new_signature filtered_signature - list str list triton_meta signature keys grid = GridExpr from_meta inductor_meta cfg mode=self grid_mode eval_slow dict zip filtered_signature inductor_meta get extra_launcher_args args inductor_meta get extra_launcher_args args = args -len inductor_meta extra_launcher_args args grid _ConstRepr __init__ value str value = value __call__ _=None - str value CompileResult Generic _T Base representing compiled result __init__ kernel _T config Config compile_meta dict str Any inductor_meta dict str Any kernel = kernel config = config compile_meta = compile_meta inductor_meta = inductor_meta make_launcher - LauncherType _gen_launcher_code scope def_args runner_args - LauncherType grid = GridExpr from_meta inductor_meta config grid prefix usually empty grid x_grid something like ` - xnumel - ` lines = f launcher join def_args stream f line line grid prefix f grid_ = grid x_grid f grid_ = grid y_grid f grid_ = grid z_grid f runner join runner_args launcher_code = \n join lines exec launcher_code scope scope launcher _get_arg_lists arg_names constexprs - tuple list str list str OrderedSet str Return bunch intermediate lists args needed generating launcher code compile_meta = compile_meta cfg = config known_constants = OrderedSet arg i arg enumerate arg_names i constexprs https github com pytorch pytorch issues fn constexprs doesn t properly deal None args so when we filter out arg UserDefinedTritonKernel codegen we need filter here well We also don t want modify fn We know we removed something signature It s compile_meta constants It isn t constant we already know about Note The value interest has already been added compile_meta constants so we use fn constexprs instead It isn t compile_meta signature none_args = OrderedSet k k v compile_meta constants items v None k known_constants none_args = none_args difference OrderedSet compile_meta signature keys _convert_constant constant isinstance constant str r + constant + repr constant triton_version_uses_attrs_dict call_args = arg_names def_args = arg_names implicit_constants = OrderedSet num_warps num_stages union OrderedSet k k known_constants implicit_constants = implicit_constants OrderedSet compile_meta constants keys num_warps num_stages special implicit args signature see test_triton_kernel_special_params def_args = arg arg def_args arg implicit_constants repl = k _convert_constant compile_meta constants get k k implicit_constants call_args = repl get arg arg arg call_args call_args = arg i arg enumerate arg_names i constexprs arg none_args cfg_dict = config_to_dict cfg def_args = name name arg_names name cfg_dict name none_args extra_launcher_args inductor_meta def_args = def_args inductor_meta extra_launcher_args call_args def_args none_args CannotStaticallyLaunchKernel Exception pass StaticTritonCompileResult CompileResult StaticallyLaunchedCudaKernel TritonCompileResult uses StaticCudaLauncher which vastly simplifies setup metadata needed kept staticmethod can_statically_launch kernel CompiledKernel inductor_meta dict str Any triton_meta dict str Any heuristic_type HeuristicType - StaticallyLaunchedCudaKernel &#124; None torch _inductor config use_static_cuda_launcher None check_can_launch - StaticallyLaunchedCudaKernel triton_meta get device_type = cuda Only cuda kernels raise CannotStaticallyLaunchKernel Non-cuda device torch _inductor config cpp_wrapper If we re running cpp wrapper doesn t make sense statically compile since everything codegenned anyway raise CannotStaticallyLaunchKernel Cpp wrapper enabled heuristic_type == HeuristicType USER_AUTOTUNE torch _inductor config static_launch_user_defined_triton_kernels Don t support user defined triton kernels yet raise CannotStaticallyLaunchKernel User defined triton kernel inductor_meta get store_cubin Requires storing entire binary raise CannotStaticallyLaunchKernel store_cubin enabled getattr kernel metadata launch_pdl False getattr kernel metadata launch_cooperative_grid False raise CannotStaticallyLaunchKernel static launch does support launch attributes cubin_location = os path join triton_cache_dir triton_meta get device triton_hash_to_path_key kernel hash f kernel src fn __name__ cubin os path exists cubin_location raise CannotStaticallyLaunchKernel f Cubin path found cubin_location kernel _cubin_path = cubin_location try static_kernel = StaticallyLaunchedCudaKernel kernel except NotImplementedError e raise CannotStaticallyLaunchKernel f NotImplemented str e e static_kernel try result = check_can_launch result except CannotStaticallyLaunchKernel e log info Bypassing StaticallyLaunchedCudaKernel due s str e noqa G torch _inductor config strict_static_cuda_launcher raise e None reload_cubin_path When loading cache disk we want reload cubin files their appropriate location disc cubin_location = os path join triton_cache_dir compile_meta get device triton_hash_to_path_key kernel hash f kernel name cubin os path exists cubin_location kernel cubin_raw None We saved raw cubin so write he appropriate location kernel reload_cubin_from_raw cubin_location raise RuntimeError Cubin file saved TritonBundler found s cubin_location kernel cubin_path = cubin_location make_launcher - LauncherType If least one static make_launcher call occurs we re sure static cuda launcher used compile set_feature_use static_cuda_launcher True Load binary parent kernel cubin_path reload_cubin_path device = compile_meta get device device None device = kernel load_kernel device scope = runner kernel run NOTE Constexpr handling triton static cuda launcher Triton kernels have two types constexprs declared ones which ones user has explicitly declared tl constexpr implied ones which expressions triton deems constant while compiling analyzing code i e unused parameters example Triton kernels handle constexprs slightly differently depending which version triton we care about we support In triton kernels do require passing any declared constexprs into kernel In triton kernels require all declared constexprs passed into kernel where they subsequently ignored When statically launching since we re launching triton generated cubin we actually want always get rid all const exprs declared implied since underlying cubin file has all constants stripped away anyway But CachingAutotuner run will pass us different number arguments depending whether we re triton later so we grab def_args same logic non static TritonCompileResult We then generate call_args ourselves since we want only subset arguments passed triton Here arg_names exactly fn src arg_names declared_constexprs exactly fn src constexprs which matches behavior regular TritonCompileResult _ def_args none_args = _get_arg_lists kernel arg_names kernel declared_constexprs call_args = arg i arg enumerate kernel arg_names i kernel full_constexprs arg none_args StaticallyLaunchedCudaKernel run takes order grid_ grid_ grid_ stream call_args runner_args = grid_ grid_ grid_ stream call_args launcher = _gen_launcher_code scope def_args runner_args launcher config = config type ignore attr-defined launcher n_regs = kernel n_regs type ignore attr-defined launcher n_spills = kernel n_spills type ignore attr-defined launcher shared = kernel shared type ignore attr-defined launcher cache_hash = triton_hash_to_path_key kernel hash type ignore attr-defined launcher store_cubin = False type ignore attr-defined launcher _is_static = True type ignore attr-defined launcher TritonCompileResult CompileResult CompiledKernel Upstream Triton CompileKernel can pickled This wrapper support serialization generate launcher function staticmethod functools lru_cache _kernel_metadata_cls fields tuple str - Any namedtuple KernelMetadata sorted fields staticmethod _serialize_metadata metadata Triton uses nested called KernelMetadata store metadata information Pickle does work well nested namedtuples namedtuple doesn t appear toplevel namespace module So these serialization deser functions used convert namedtuples dict back As packed_metadata depending triton backend KernelMetadata can namedtuple regular tuple So serialization function branches whether metadata serialized namedtuple regular serializable one is_namedtuple obj - bool isinstance obj tuple hasattr obj _asdict hasattr obj _fields is_namedtuple metadata metadata _asdict metadata staticmethod _deserialize_metadata metadata isinstance metadata dict TritonCompileResult _kernel_metadata_cls tuple metadata keys metadata metadata __getstate__ - dict str Any kernel = kernel replace fields don t pickle nicely kernel_state = kernel __dict__ See doc about serializing metadata above metadata _serialize_metadata kernel metadata packed_metadata _serialize_metadata getattr kernel packed_metadata None module None regenerated kernel _init_handles function None regenerated kernel _init_handles run None regenerated kernel _init_handles __dict__ kernel kernel_state type ignore dict-item __setstate__ state dict str Any - None src = ASTSource __new__ ASTSource src __setstate__ state kernel src TODO jansel need fixup src fn which now None kernel = CompiledKernel __new__ CompiledKernel metadata = state kernel metadata packed_metadata = state kernel packed_metadata kernel __dict__ update state kernel src src metadata _deserialize_metadata metadata packed_metadata _deserialize_metadata packed_metadata __dict__ update state kernel = kernel make_launcher - LauncherType Launching triton kernels performance sensitive we compile custom Python function get grid reorder args underlying wrapper cfg = config compile_meta = compile_meta binary = kernel fn = binary src fn binary _init_handles call_args def_args none_args = _get_arg_lists fn arg_names get_constexprs fn binary_shared = binary shared hasattr binary shared binary metadata shared knobs None launch_enter = binary __class__ launch_enter_hook launch_exit = binary __class__ launch_exit_hook launch_enter = knobs runtime launch_enter_hook launch_exit = knobs runtime launch_exit_hook math math_lib triton triton_lib torch torch_lib scope = grid_meta cfg kwargs bin binary launch_enter_hook launch_enter launch_exit_hook launch_exit metadata binary packed_metadata hasattr binary packed_metadata binary metadata shared binary_shared num_warps binary num_warps hasattr binary num_warps binary metadata num_warps cta_args binary num_ctas get_first_attr binary cluster_dims clusterDims hasattr binary num_ctas binary metadata num_ctas binary metadata cluster_dims hasattr binary metadata function get_first_attr binary function cu_function runner get_first_attr binary run c_wrapper math math_lib torch torch_lib triton triton_lib hasattr binary launch_metadata launch args before CompiledKernel launch_metadata added TODO jansel delete branch mid- runner_args = grid_ grid_ grid_ num_warps cta_args shared stream function launch_enter_hook launch_exit_hook metadata call_args args after CompiledKernel launch_metadata https github com triton-lang triton pull Getting kernel launch args extremely perf-sensitive Evaluating ` bin launch_metadata ` relatively expensive returns None unless ` launch_enter_hook ` installed So we don t have hook installed we want burn None launch args zero overhead See https github com pytorch pytorch issues launch_enter launch_metadata = f bin launch_metadata grid_ grid_ grid_ stream join call_args launch_metadata = None runner_args = grid_ grid_ grid_ stream function metadata launch_metadata launch_enter_hook launch_exit_hook call_args launcher = _gen_launcher_code scope def_args runner_args launcher = scope launcher launcher config = cfg launcher n_regs = getattr binary n_regs None launcher n_spills = getattr binary n_spills None launcher shared = binary_shared launcher cache_hash = triton_hash_to_path_key binary hash launcher store_cubin = inductor_meta get store_cubin False store global variable avoid high overhead reading when calling run launcher store_cubin launcher fn = fn launcher bin = binary triton_version_uses_attrs_dict arg filtering wasn t done above cfg_dict = config_to_dict cfg def_args = x x def_args x cfg_dict call_args = x x call_args compile_meta signature get x constexpr = constexpr x none_args launcher def_args = def_args launcher call_args = call_args kernel_metadata = getattr kernel metadata None scratch arguments None indicates kernel doesn t take any scratch argument otherwise number indicates number bytes scratch need provided AMD s Triton backend global scratch size never provided AMD s safe pass extra null arg so always include global_scratch int &#124; None = getattr kernel_metadata global_scratch_size torch version hip None profile_scratch int &#124; None = getattr kernel_metadata profile_scratch_size None launcher global_scratch = global_scratch launcher profile_scratch = profile_scratch launcher _find_names obj gc inspect frame = inspect currentframe while frame None frame f_locals frame = frame f_back obj_names = referrer gc get_referrers obj isinstance referrer dict k v referrer items v obj obj_names append k obj_names collected_calls list Any = start_graph collected_calls clear end_graph output_file len collected_calls == overall_time = sum call call collected_calls overall_gb = sum call call collected_calls cur_file = inspect stack filename summary_str = f SUMMARY cur_file \n f overall_time f ms \t overall_gb f GB\t overall_gb overall_time e f GB s log info s summary_str output_file None sort perf numbers descending order i e placing most runtime-heavy kernels top list sorted_calls = sorted collected_calls key=lambda c float c reverse=True try open output_file file log info Save profile bandwidth results s output_file file write ====================\n file write f TRITON KERNELS BANDWIDTH INFO cur_file \n ms num_gb gb_per_s kernel_name sorted_calls also display runtime percentage each kernel percentage = f ms overall_time f suffix = f \t percentage \t kernel_name bw_info_str = create_bandwidth_info_str ms num_gb gb_per_s suffix=suffix color=False file write bw_info_str + \n file write f summary_str \n\n except Exception log warning failed write profile bandwidth result into s output_file exc_info=True DebugAutotuner CachingAutotuner __init__ args regex_filter= with_profiler=False with_bandwidth_info=True kwargs regex_filter = regex_filter with_profiler = with_profiler with_bandwidth_info = with_bandwidth_info super __init__ args kwargs cached = None run args stream kwargs with_bandwidth_info super run args stream=stream kwargs benchmark_run=True possible_names = _find_names kernel_name = f max possible_names key=len re match regex_filter kernel_name len launchers = len launchers == start_time = time time_ns precompile precompile_time_taken_ns = time time_ns - start_time len launchers autotune_to_one_config args kwargs launcher = launchers launcher store_cubin save_gpu_kernel stream launcher cached None ms = bench launcher args with_profiler=self with_profiler num_in_out_ptrs = len arg_name arg_name fn arg_names arg_name startswith in_out_ptr num_gb = inductor_meta get kernel_num_gb None num_gb None num_gb = get_num_bytes args num_in_out_args=num_in_out_ptrs e gb_per_s = num_gb ms e cached = ms num_gb gb_per_s kernel_name collected_calls append ms num_gb gb_per_s kernel_name log info s create_bandwidth_info_str ms num_gb gb_per_s suffix=f \t kernel_name AOTI we will call kernel its timing info has been cached already collected_calls append cached hash_configs configs list Config Hash used check changes configurations hasher = hashlib sha cfg configs hasher update f sorted cfg kwargs items cfg num_warps cfg num_stages \n encode hasher hexdigest cached_autotune size_hints list int &#124; None configs list Config triton_meta heuristic_type filename=None inductor_meta=None custom_kernel=False A copy triton autotune calls our subclass Our subclass has additional debugging error handling on-disk caching configs = unique_configs configs assert len configs == filename inductor_meta = inductor_meta None inductor_meta configs autotune_cache autotune_cache_info = check_autotune_cache configs filename inductor_meta mutated_arg_names = inductor_meta pop mutated_arg_names optimize_mem = inductor_meta pop optimize_mem True restore_value triton_meta mutated_arg_names += triton_meta pop restore_value reset_to_zero_arg_names list str = reset_to_zero triton_meta reset_to_zero_arg_names extend triton_meta pop reset_to_zero decorator fn Remove XBLOCK config s function argument This way coordinate descent tuning will try tune Context When TritonKernel no_x_dim True we hardcode XBLOCK inspect XBLOCK inspect signature fn fn parameters tconfig configs XBLOCK tconfig kwargs assert tconfig kwargs XBLOCK == tconfig kwargs pop XBLOCK inductor_meta get profile_bandwidth DebugAutotuner fn triton_meta=triton_meta inductor_meta=inductor_meta regex_filter=inductor_meta profile_bandwidth_regex with_profiler=inductor_meta profile_bandwidth_with_do_bench_using_profiling configs=configs save_cache_hook=autotune_cache autotune_cache save mutated_arg_names=mutated_arg_names reset_to_zero_arg_names=reset_to_zero_arg_names optimize_mem=optimize_mem heuristic_type=heuristic_type size_hints=size_hints custom_kernel=custom_kernel filename=filename with_bandwidth_info=True CachingAutotuner fn triton_meta=triton_meta inductor_meta=inductor_meta configs=configs save_cache_hook=autotune_cache autotune_cache save mutated_arg_names=mutated_arg_names reset_to_zero_arg_names=reset_to_zero_arg_names optimize_mem=optimize_mem heuristic_type=heuristic_type size_hints=size_hints custom_kernel=custom_kernel filename=filename autotune_cache_info=autotune_cache_info decorator unique_configs configs list Config Remove duplicate configurations seen OrderedSet Hashable = OrderedSet pruned_configs = cfg configs key = triton_config_to_hashable cfg key seen seen add key pruned_configs append cfg pruned_configs check_config cfg xnumel=None ynumel=None znumel=None numel label zip xnumel ynumel znumel XYZ numel None continue block = cfg f label BLOCK numel == assert block == f TritonKernel indexing assumes numel == = BLOCK == f label lower numel== numel label BLOCK= block cfg= cfg max_block = TRITON_MAX_BLOCK label max_block_str = f config triton max_block label assert max_block block == f TritonKernel indexing assumes label BLOCK divides max_block_str f label BLOCK= block max_block_str = max_block cfg= cfg check_max_block cfg dict str int Check block sizes within maximum allowed var val cfg items block_suffix = BLOCK block_suffix var prefix = var removesuffix block_suffix max_block = TRITON_MAX_BLOCK prefix assert val = max_block f var too large Maximum max_block Actual val _num_warps num_warps max_num_warps= min_num_warps= register_intensive=False On AMD GPU each warp has lanes which double size NV GPU therefore using half number warps here correspondingly torch version hip max_num_warps = max_num_warps + min_num_warps = min_num_warps + persistent reduction register intensive register_intensive max_num_warps = max_num_warps next_power_of_ min max num_warps min_num_warps max_num_warps _check_max_grid_x size_hints x num_warps Check maxGridSize exceeded - so then must scale XBLOCK further max_grid_x = warp_size = torch version hip TODO query warp size once merged num_blocks = size_hints x + x - x while num_blocks num_warps warp_size max_grid_x x size_hints x x = Scale up XBLOCK grid exceeds limits num_blocks = num_blocks num_blocks num_warps warp_size max_grid_x raise AssertionError Reduction config exceeds cudaDeviceProp maxGridSize Please raise pytorch issue x num_blocks triton_config size_hints x y=None z=None num_stages= num_elements_per_warp= min_elem_per_thread= num_warps=None matrix_instr=None waves_per_eu=None - Config Construct pointwise triton config some adjustment heuristics based size_hints Size_hints tuple numels each tile dimension will rounded up nearest power num_elements_per_warp suggestion controlling how many warps triton config should contain e g x= y= z= then num_elements = = Then we set num_elements_per_warp= we ll launch elem elem warp = warps Note s just suggestion sometimes other adjustment heuristics will override num_elements_per_warp min_elem_per_thread controls minimum number elements processed each thread It s always enforced Ideally we want read some device config maxGridSize = target = conditional_product x y z conditional_product size_hints values target target = shrink sizes size hints x = min x size_hints x y y = min y size_hints y z z = min z size_hints z we below original block size scale up where we can calculated grid size larger than limit we bump up corresponding dimension while x min size_hints x TRITON_MAX_BLOCK X x maxGridSize size_hints x conditional_product x y z target x = while y y min size_hints y TRITON_MAX_BLOCK Y y maxGridSize size_hints y conditional_product x y z target y = while z z min size_hints z TRITON_MAX_BLOCK Z z maxGridSize size_hints z conditional_product x y z target z = Calculate num_warps they hard passed config num_warps None num_warps = _num_warps conditional_product x y z num_elements_per_warp min_num_warps= we going arrive warps only bs too small due numel being too small However workaround some ptx bugs we still want least warps there s enough elements per thread given rare situation don t expect affect perf general see https github com pytorch pytorch pull conditional_product x y z = torch version hip num_warps = max num_warps xnumel = size_hints x ynumel = size_hints get y znumel = size_hints get z Increase x satisfy min_elem_per_thread requirements block_size = max conditional_product x y z min_elem_per_thread _NUM_THREADS_PER_WARP num_warps x = math ceil block_size conditional_product x y z x _num_blocks = _check_max_grid_x size_hints x num_warps x = min x size_hints x cfg = XBLOCK x y cfg YBLOCK = y z cfg ZBLOCK = z check_max_block cfg check_config cfg xnumel=xnumel ynumel=ynumel znumel=znumel config = Config cfg num_warps=num_warps num_stages=num_stages torch version hip matrix_instr None config kwargs matrix_instr_nonkdim = matrix_instr waves_per_eu None config kwargs waves_per_eu = waves_per_eu config _get_nd_reduction_numels r int size_hints dict str int - dict str int Converts linear reduction numel ND row major order This order often desirable presents opportunities coalesce memory accesses For example r = size_hints = function returns This unraveling works because both r size_hints powers Shrink r size_hints r = min r get_total_reduction_numel size_hints num_reduction_dims = len prefix prefix size_hints prefix_is_reduction prefix remaining = r rnumels = idx range num_reduction_dims - - - prefix = f r idx _ max_size = min size_hints prefix TRITON_MAX_BLOCK prefix upper dim = min max_size remaining assert remaining dim == f Expected dimension dim divide remaining size remaining rnumels prefix = dim remaining = dim Sanity check results final_numel = conditional_product rnumels values assert r == final_numel f Expected ND reduction size rnumels have r elements assert all rnumels prefix = size_hints prefix prefix rnumels f rnumels exceed size_hints rnumels size_hints rnumels triton_config_reduction size_hints x int r int num_stages= num_warps=None register_intensive=False waves_per_eu=None dynamic_scale_rblock=True reduction_hint=None - Config Construct reduction triton config some adjustment heuristics based size_hints Size_hints tuple numels each tile dimension will rounded up nearest power Convert linear reduction numel into multi-dimensional block rnumels = _get_nd_reduction_numels r size_hints shrink sizes size hints x = min x size_hints x total_numel - int conditional_product x rnumels values target = total_numel conditional_product size_hints values target target = we below original block size scale up where we can while x size_hints x total_numel target x = prefix sorted rnumels while rnumels prefix size_hints prefix total_numel target rnumels prefix = num_warps None reduction_hint == ReductionHint INNER is_fbcode r contiguous so ensure each thread has elements vectorized loads assuming bf fp xblock usually - default giving each thread more work num_warps = r num_warps = total_numel max_num_warps = r = num_warps = _num_warps num_warps max_num_warps=max_num_warps register_intensive=register_intensive x _num_blocks = _check_max_grid_x size_hints x num_warps prefix sorted rnumels while total_numel target rnumels prefix == break rnumels prefix = cfg = _get_config x x rnumels check_max_block cfg check_config cfg xnumel=size_hints x config = InductorConfig cfg num_warps=num_warps num_stages=num_stages dynamic_scale_rblock=dynamic_scale_rblock torch version hip waves_per_eu None config kwargs waves_per_eu = waves_per_eu config _get_config numels dict str int - dict str int Convert numels x r _ etc block sizes XBLOCK R _BLOCK etc prefix upper + BLOCK numel prefix numel numels items triton_config_tiled_reduction size_hints x y r num_stages= register_intensive=False waves_per_eu=None Construct tile reduction triton config some adjustment heuristics based size_hints Size_hints tuple numels each tile dimension will rounded up nearest power Convert linear reduction numel into multi-dimensional block rnumels = _get_nd_reduction_numels r size_hints shrink sizes size hints x = min x size_hints x y = min y size_hints y total_numel - int conditional_product x y rnumels values target = total_numel conditional_product size_hints values target target = we below original block size scale up where we can while x size_hints x total_numel target x = prefix sorted rnumels while rnumels prefix size_hints prefix total_numel target rnumels prefix = while y size_hints y total_numel target y = cfg = _get_config x x y y rnumels num_warps = _num_warps total_numel min_num_warps= num_warps = _num_warps num_warps max_num_warps= register_intensive=register_intensive check_config cfg xnumel=size_hints x ynumel=size_hints y check_max_block cfg config = Config cfg num_warps=num_warps num_stages=num_stages torch version hip waves_per_eu None config kwargs waves_per_eu = waves_per_eu config _maybe_filter_configs_for_tma_restrictions inductor_meta configs list Config tma_min_block_sizes dict str int tma_min_block_sizes = inductor_meta get tma_min_block_sizes configs Rn blocks provided kernel persistent reductions inductor_meta get persistent_reduction tma_min_block_sizes = block_type block_size block_type block_size tma_min_block_sizes prefix_is_reduction block_type lower assert all block_type configs kwargs block_type tma_min_block_sizes keys Add config guaranteed compile example_config = configs config_block_sizes = example_config kwargs config_block_sizes update tma_min_block_sizes new_configs = Config config_block_sizes num_warps=example_config num_warps num_stages=example_config num_stages maxnreg=example_config maxnreg pre_hook=example_config pre_hook Remove configs will compile c configs all c kwargs get block_type = min_block_value block_type min_block_value tma_min_block_sizes items new_configs append c log debug Filtering configs TMA API restrictions Input configs size d Output configs size d len configs len new_configs new_configs configs pointwise size_hints triton_meta tile_hint=None filename=None min_elem_per_thread= inductor_meta=None Construct triton heuristics based size_hints inductor_meta = inductor_meta None inductor_meta assert inductor_meta get no_x_dim numel = functools reduce operator mul size_hints values bs = max min numel hinted_configs = autotune_hints_to_configs inductor_meta get autotune_hints OrderedSet size_hints bs triton_meta device triton_config_with_settings = functools partial triton_config min_elem_per_thread=min_elem_per_thread configs = None len size_hints == inductor_meta get autotune_pointwise True inductor_meta get max_autotune inductor_meta get max_autotune_pointwise configs = triton_config_with_settings size_hints bs configs = triton_config_with_settings size_hints bs num_elements_per_warp= triton_config_with_settings size_hints bs num_elements_per_warp= hinted_configs Additional configs appended ROCm builds torch version hip configs extend triton_config_with_settings size_hints TRITON_MAX_BLOCK X waves_per_eu= triton_config_with_settings size_hints wrt better than max_block some kernel triton_config_with_settings size_hints num_warps= num_stages= waves_per_eu= improvement inductor_meta get atomic_add_found configs extend triton_config_with_settings size_hints num_warps= num_stages= improvement len size_hints == Only avoiding tuning TileHint SQUARE ROCm builds ROCm has observed improvement diverging here inductor_meta get autotune_pointwise True torch version hip None tile_hint == TileHint SQUARE inductor_meta get max_autotune inductor_meta get max_autotune_pointwise configs = triton_config_with_settings size_hints configs = triton_config_with_settings size_hints triton_config_with_settings size_hints ~ better fp triton_config_with_settings size_hints triton_config_with_settings size_hints triton_config_with_settings size_hints bs triton_config_with_settings size_hints bs hinted_configs Additional configs appended ROCm builds torch version hip configs extend triton_config_with_settings size_hints better some kernels triton_config_with_settings size_hints + some kernels triton_config_with_settings size_hints additional more triton_config_with_settings size_hints + some kernels len size_hints == inductor_meta get autotune_pointwise True configs = triton_config_with_settings size_hints configs = triton_config_with_settings size_hints triton_config_with_settings size_hints triton_config_with_settings size_hints triton_config_with_settings size_hints triton_config_with_settings size_hints bs triton_config_with_settings size_hints bs triton_config_with_settings size_hints bs hinted_configs configs raise NotImplementedError f size_hints size_hints configs = _maybe_filter_configs_for_tma_restrictions inductor_meta configs cached_autotune size_hints configs triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType POINTWISE filename=filename make_matmul_triton_config sizes dict str int num_warps int num_stages int config = XBLOCK sizes get x YBLOCK sizes get y ZBLOCK sizes get z R _BLOCK sizes get r Remove keys None values i e missing sizes config = k v k v config items v None Config config num_warps=num_warps num_stages=num_stages _config_helper bmm=False persistent=False Each entry sizes_dict num_warps num_stages _base_mm_configs = x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r x y r out = sizes w s _base_mm_configs d = dict sizes persistent d pop r None bmm d z = out append d w s Deduplicate converting dicts immutable frozensets deduped = frozenset d items w s d w s d w s out list deduped values triton_native_mm_configs = _config_helper bmm=False persistent=False triton_native_persistent_mm_configs = _config_helper bmm=False persistent=True triton_native_bmm_configs = _config_helper bmm=True persistent=False triton_native_persistent_bmm_configs = _config_helper bmm=True persistent=True _reduction_configs size_hints dict str int inductor_meta dict str Any triton_meta dict str Any num_dynamic= - list Config reduction_hint = inductor_meta get reduction_hint Convert reductions D simplify heuristics rnumel = get_total_reduction_numel size_hints Is max autotune enabled max_autotune_enabled = inductor_meta get max_autotune inductor_meta get max_autotune_pointwise register_intensive = False MAX_R _BLOCK = loads_and_red = inductor_meta get num_load + inductor_meta get num_reduction size_hints x = loads_and_red = A heuristics reduce R _BLOCK kernel potentially need many registers Consider load reduction since load need move data into registers reduction needs accumulator The magic numbers bit arbitrary We cannot rely dynamically scaling down R _BLOCK later since sometimes triton makes use less registers worse perf Check https github com pytorch pytorch issues The heuristic very simple one since registers can reused But hopefully can good enough indicator MAX_R _BLOCK = register_intensive = True triton_meta get native_matmul len size_hints == make_matmul_triton_config sizes num_warps num_stages sizes num_warps num_stages triton_native_mm_configs len size_hints == make_matmul_triton_config sizes num_warps num_stages sizes num_warps num_stages triton_native_bmm_configs raise NotImplementedError native matmul only supports mm bmm pattern make_config x r num_warps=None num_stages= register_intensive=False dynamic_scale_rblock=True waves_per_eu=None For D case tiling scores create adapted version y size_hints assert tiling_scores inductor_meta adapt_config_for_tiling size_hints inductor_meta tiling_scores x r num_warps=num_warps num_stages=num_stages register_intensive=register_intensive waves_per_eu=waves_per_eu For other cases use original function triton_config_reduction size_hints x r num_warps=num_warps num_stages=num_stages register_intensive=register_intensive waves_per_eu=waves_per_eu dynamic_scale_rblock=dynamic_scale_rblock reduction_hint=reduction_hint outer_config_opt Default vectorized loads max_x_block x_block = load_factor = inductor_meta get num_load x = size_hints x num_warps = None Try use all SMs small x x = x_block = max min x outer_r_block = min rnumel Lower bound x = = around SMs x = x_block = outer_r_block = x_block num_dynamic Lots compute multiple dynamic shape per loop iteration Larger RBLOCK minimizes loop iteration outer_r_block = max min rnumel num_dynamic == Dynamic shapes introduce lot register pressure indexing outer_r_block = load_factor = min next_power_of_ max rnumel x_block = max min max_x_block next_power_of_ x x_block load_factor rnumel = outer_r_block = x_block Heavier reductions contain lot more overhead per loop iteration We minimize overhead enlarging r block rnumel = outer_r_block = outer_r_block = x_block = min x_block num_warps = Set register intensive true default we try maximize tiles heuristic make_config x_block outer_r_block num_warps=num_warps register_intensive=register_intensive contiguous_config = make_config rnumel = is_fbcode less persistent min rnumel MAX_R _BLOCK register_intensive=register_intensive tiny_config = make_config rnumel rnumel = min rnumel MAX_R _BLOCK register_intensive=register_intensive outer_config = make_config register_intensive=register_intensive TODO paulzhan Test heuristic AMD internal testing correctness torch version hip is_fbcode outer_config = outer_config_opt configs = inductor_meta get add_persistent_rblock loads_and_red = xnumel = max rnumel c = make_config xnumel min rnumel register_intensive=register_intensive dynamic_scale_rblock=False configs append c result_configs = For d tiling default more autotuning initially y size_hints pass max_autotune_enabled pass skip all these cases reduction_hint == ReductionHint INNER configs + contiguous_config reduction_hint == ReductionHint OUTER configs + outer_config reduction_hint == ReductionHint OUTER_TINY configs + tiny_config We continue here under following conditions - max_autotune_enabled True - max_autotune_enabled False reduction_hint NOT one above cases result_configs = configs + contiguous_config outer_config tiny_config make_config make_config halve XBLOCK Rn_BLOCK compared outer_config TODO may only beneficial when each iteration reduction quite heavy E g https gist github com shunting ef f db d make_config num_warps= torch version hip result_configs extend make_config num_warps= num_stages= waves_per_eu= make_config num_warps= num_stages= waves_per_eu= result_configs match_target_block_product size_hints tiling_scores target_block_product min_block_size= Distribute block sizes across dimensions according tiling scores aiming match target product block sizes total_score = sum tiling_scores values total_score == just assume even score no minimum block size min_block_size = tiling_scores = dict fromkeys tiling_scores keys target_block_product First give each coalescing dimension least min_block_size block_sizes = relative_scores = curr_block_product = dim score tiling_scores items score == block_sizes dim = continue block_sizes dim = min_block_size curr_block_product = min_block_size relative_scores dim = score total_score Scale up dimensions their relative scores until we reach target while curr_block_product target_block_product relative_scores dim score = max relative_scores items key=lambda item item Check we ve hit max dimension block_sizes dim = TRITON_MAX_BLOCK dim capitalize block_sizes dim = size_hints dim del relative_scores dim continue block_sizes dim = relative_scores dim = curr_block_product = block_sizes adapt_config_for_tiling size_hints tiling_scores original_x original_r num_warps=None num_stages= register_intensive=False persistent_reduction=False waves_per_eu=None - Config Create adapted configuration based tiling scores redistributing same total block size x r according tiling scores assert all s tiling_scores s size_hints target_block_product = original_x original_r block_sizes = match_target_block_product size_hints tiling_scores target_block_product triton_config_tiled_reduction size_hints block_sizes x block_sizes y block_sizes r _ num_stages=num_stages register_intensive=register_intensive waves_per_eu=waves_per_eu filter_reduction_configs_for_determinism inductor_meta dict str Any configs list Config - list Config Filter configs reduction so numerics can deterministic Heuristics - skip reduction configs too small RBLOCK - skip reduction configs XBLOCK== we confident will perform well - there tie pick config second largest RBLOCK - there still tie pick config second largest num_warps - there still tie pick config second largest XBLOCK configs = unique_configs configs assert len configs _do_filter_due_to_inductor_config inductor_meta get deterministic False inductor_meta get force_filter_reduction_configs False inductor_meta get are_deterministic_algorithms_enabled _do_filter_due_to_inductor_config len configs == no filtering happening NOT deterministic mode configs log isEnabledFor logging DEBUG log debug reduction configs before filtering c configs log debug s c log debug _has_too_small_rblock config rblock = config kwargs get R _BLOCK too small RBLOCK likely bad rblock None rblock = _nonpromising_xblock_ config kernel like https gist github com shunting b c e bc fe ff d d without load store having contiguous rdim unlikely perform well XBLOCK== config kwargs XBLOCK == inductor_meta get has_loadstore_with_contiguous_rdim True newconfigs = filter lambda x _has_too_small_rblock x configs accept filtering only there configs left len newconfigs configs = newconfigs newconfigs = filter lambda x _nonpromising_xblock_ x configs len newconfigs configs = newconfigs assert len configs _r _block c c kwargs get R _BLOCK - _xblock c c kwargs get XBLOCK - _num_warps c c num_warps _pick_second_largest accessor nonlocal configs configs = sorted configs key=lambda x accessor x accessor configs = accessor configs - max_val = accessor configs - configs = filter lambda x accessor x = max_val configs second_max_val = accessor configs - configs = filter lambda x accessor x == second_max_val configs configs _pick_config nonlocal configs assert len configs len configs == configs break tie R _BLOCK configs = _pick_second_largest _r _block len configs == configs break tie num_warps configs = _pick_second_largest _num_warps len configs == configs break tie XBLOCK configs = _pick_second_largest _xblock there still tie pick first one configs configs = _pick_config log isEnabledFor logging DEBUG log debug reduction configs after filtering c configs log debug s c log debug configs reduction size_hints reduction_hint=False triton_meta=None filename=None inductor_meta=None args triton heuristics inductor_meta = inductor_meta None inductor_meta inductor_meta reduction_hint = reduction_hint inductor_meta get no_x_dim size_hints x = assert triton_meta None num_dynamic = k triton_meta signature keys ks k num_dynamic += configs = _reduction_configs size_hints=size_hints inductor_meta=inductor_meta triton_meta=triton_meta num_dynamic=num_dynamic configs = _maybe_filter_configs_for_tma_restrictions inductor_meta configs configs = filter_reduction_configs_for_determinism inductor_meta configs cached_autotune size_hints configs=configs triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType REDUCTION filename=filename cooperative_reduction size_hints reduction_hint triton_meta filename inductor_meta inductor_meta = inductor_meta None inductor_meta inductor_meta reduction_hint = reduction_hint inductor_meta get no_x_dim size_hints x = Cooperative reductions currently only support single reduction dimension assert len size_hints == Cooperative reductions don t support tiling reduction dims xnumel rnumel = size_hints x size_hints r _ TODO jansel we should base target SM count local GPU target = split = max min target xnumel TRITON_MAX_RSPLIT assert rnumel = split assert split = TRITON_MAX_RSPLIT inductor_meta persistent_reduction configs = _persistent_reduction_configs x xnumel r _ rnumel split reduction_hint inductor_meta triton_meta configs = _reduction_configs size_hints= x xnumel r _ rnumel split inductor_meta=inductor_meta triton_meta=triton_meta config configs config kwargs RSPLIT = split TODO jansel add more configs max_autotune configs = _maybe_filter_configs_for_tma_restrictions inductor_meta configs configs = filter_reduction_configs_for_determinism inductor_meta configs cached_autotune size_hints configs=configs triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType REDUCTION filename=filename _persistent_reduction_configs size_hints reduction_hint=False inductor_meta=None triton_meta=None xnumel = size_hints x rnumel = get_total_reduction_numel size_hints loads_and_stores = inductor_meta get num_load + inductor_meta get num_store MAX_PERSISTENT_BLOCK_NUMEL = triton_meta get native_matmul len size_hints == make_matmul_triton_config sizes num_warps num_stages sizes num_warps num_stages triton_native_persistent_mm_configs len size_hints == make_matmul_triton_config sizes num_warps num_stages sizes num_warps num_stages triton_native_persistent_bmm_configs raise NotImplementedError native matmul only supports mm bmm pattern max_autotune_enabled = inductor_meta get max_autotune inductor_meta get max_autotune_pointwise torch version hip xblock_vals = xblock_vals = y size_hints configs = triton_config_reduction size_hints xblock rnumel register_intensive=True reduction_hint=reduction_hint xblock xblock_vals xblock == rnumel xblock = MAX_PERSISTENT_BLOCK_NUMEL xblock = xnumel configs = assert tiling_scores inductor_meta x_y_scores = dim inductor_meta tiling_scores dim dim x y target_block_size xblock_vals target_block_size rnumel MAX_PERSISTENT_BLOCK_NUMEL continue block_sizes = match_target_block_product size_hints x_y_scores target_block_size configs append triton_config_tiled_reduction size_hints block_sizes x block_sizes y rnumel tiny_configs = triton_config_reduction size_hints rnumel rnumel = rnumel defer more autotuning initially y size_hints pass TODO jansel we should able improve these heuristics max_autotune_enabled Do filter configs when tuning reduction_hint == ReductionHint INNER rnumel = rnumel configs = configs x_block = xnumel x_block loads_and_stores = x_block = configs = triton_config_reduction size_hints x_block rnumel register_intensive=True reduction_hint == ReductionHint OUTER configs = configs - reduction_hint == ReductionHint OUTER_TINY configs = tiny_configs torch version hip If autotune enabled append tiny configs conf tiny_configs conf configs configs append conf c configs we don t need Rn_BLOCK persistent reduction prefix size_hints prefix_is_reduction prefix c kwargs pop f prefix upper BLOCK configs persistent_reduction size_hints reduction_hint=False triton_meta=None filename=None inductor_meta=None inductor_meta = inductor_meta None inductor_meta inductor_meta reduction_hint = reduction_hint inductor_meta get no_x_dim size_hints x = configs = _persistent_reduction_configs size_hints reduction_hint inductor_meta triton_meta This key added inductor meta its clear heuristic choice persistent Add remove below so persistent configs can filtered appropriately _maybe_filter_configs_for_tma_restrictions persistent_reduction_key = persistent_reduction inductor_meta persistent_reduction_key = True configs = _maybe_filter_configs_for_tma_restrictions inductor_meta configs inductor_meta pop persistent_reduction_key inductor_meta get RSPLIT_SIZE new_configs = c configs c kwargs RSPLIT_SIZE = inductor_meta get RSPLIT_SIZE small XBLOCK use less registers smem c kwargs XBLOCK = rnumel_hint = size_hints r _ rnumel_hint = c num_warps = c num_warps = max c num_warps new_configs append c less warps so potentially each sm can run more thread blocks Inside each thread block we handle split sequentially more thread blocks beneficial here newc = copy deepcopy c newc num_warps = new_configs append newc more warps larger rows new_configs append c c num_warps newc = copy deepcopy c newc num_warps = new_configs append newc configs = unique_configs new_configs configs = filter_reduction_configs_for_determinism inductor_meta configs cached_autotune size_hints configs triton_meta=triton_meta inductor_meta=inductor_meta filename=filename heuristic_type=HeuristicType PERSISTENT_REDUCTION split_scan size_hints reduction_hint=False triton_meta=None filename=None inductor_meta=None Heuristic TritonSplitScanKernel inductor_meta = inductor_meta None inductor_meta inductor_meta reduction_hint = reduction_hint inductor_meta get no_x_dim size_hints x = assert triton_meta None len size_hints = raise NotImplementedError f size_hints size_hints configs = _reduction_configs size_hints=size_hints inductor_meta=inductor_meta triton_meta=triton_meta Fixup configs enforce minimum Rn_BLOCK size min_rblock = inductor_meta get min_split_scan_rblock cfg configs var list cfg kwargs keys var startswith R cfg kwargs var min_rblock cfg kwargs var = min_rblock configs = _maybe_filter_configs_for_tma_restrictions inductor_meta configs configs = filter_reduction_configs_for_determinism inductor_meta configs cached_autotune size_hints configs=configs triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType SPLIT_SCAN filename=filename template num_stages num_warps triton_meta num_consumer_groups= num_buffers_warp_spec= filename=None inductor_meta=None Compile triton template Prepare base configuration config_args = num_stages num_stages num_warps num_warps Conditionally add arguments based HAS_WARP_SPEC HAS_WARP_SPEC config_args update num_consumer_groups num_consumer_groups num_buffers_warp_spec num_buffers_warp_spec cached_autotune None triton Config config_args triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType TEMPLATE filename=filename _pop_config_kwargs config dict str Any - dict str Any Extract triton Config options should become kwargs popped = key num_warps num_stages num_ctas maxnreg num_consumer_groups num_buffers_warp_spec val = config pop key None val None popped key = val popped config_to_dict config Config - dict str Any config_dict = config kwargs num_warps config num_warps num_stages config num_stages HAS_WARP_SPEC config_dict update num_consumer_groups getattr config num_consumer_groups num_buffers_warp_spec getattr config num_buffers_warp_spec config_dict config_from_dict config dict str Any - Config config = config Config config _pop_config_kwargs config fixed_config config filename triton_meta inductor_meta Used when configuration already decided compile time config = config cached_autotune None triton Config config _pop_config_kwargs config triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType FIXED filename=filename user_autotune configs triton_meta filename=None inductor_meta=None custom_kernel=False Compile user defined triton kernel len configs == configs = triton Config configs = map config_from_dict configs cached_autotune None configs triton_meta=triton_meta heuristic_type=HeuristicType USER_AUTOTUNE filename=filename inductor_meta=inductor_meta custom_kernel=custom_kernel foreach triton_meta num_warps filename=None inductor_meta=None Compile triton foreach kernel cached_autotune None triton Config num_stages= num_warps=num_warps triton_meta=triton_meta inductor_meta=inductor_meta heuristic_type=HeuristicType TEMPLATE filename=filename dataclasses dataclass GridExpr Generate code grid size expressions launcher inductor_meta dict str Any mode Literal python cpp = python prefix list str = dataclasses field default_factory=list x_grid str &#124; int = y_grid str &#124; int = z_grid str &#124; int = __post_init__ - None assert mode python cpp generate meta dict str int - None raise NotImplementedError ceildiv numel str &#124; int block None &#124; int &#124; str - str &#124; int block None block == numel isinstance numel int isinstance block int ceildiv numel block constant fold This trick only works python where negative integer division floored mode == python f - numel - block For cpp code gen f numel + block - block maximum seq list int &#124; str - int &#124; str Codegen max function constant folding constants represented int items = _constant_fold max seq len items = items mode == python f max join map str items functools reduce lambda x y f std max x y items summation seq list int &#124; str - int &#124; str Codegen sum function constant folding constants represented int items = _constant_fold sum seq len items = items + join map str items _constant_fold fn Callable list int int seq list int &#124; str - list int &#124; str Constant fold through commutative fn where ints constants items list int &#124; str = x x seq isinstance x int const_items = x x seq isinstance x int const_items items append fn const_items items assign_tmp name str expr str &#124; int - str Grid functions one per kernel so name collisions fine mode == python f name = expr mode == cpp f uint _t name = expr raise AssertionError f invalid mode mode staticmethod from_meta inductor_meta dict str Any cfg Config &#124; dict str int mode Literal python cpp = python - GridExpr grid_cls = globals inductor_meta grid_type assert issubclass grid_cls GridExpr grid = grid_cls inductor_meta=inductor_meta mode=mode isinstance cfg Config cfg = config_to_dict cfg grid generate cfg grid eval_slow meta dict str int - tuple int int int scope = meta line prefix exec line scope exec f grid_ = x_grid scope exec f grid_ = y_grid scope exec f grid_ = z_grid scope scope grid_ scope grid_ scope grid_ Grid D GridExpr generate meta dict str int - None x_grid = ceildiv xnumel meta get XBLOCK Grid D GridExpr generate meta dict str int - None x_grid = ceildiv xnumel meta get XBLOCK y_grid = ceildiv ynumel meta get YBLOCK Grid D GridExpr generate meta dict str int - None x_grid = ceildiv xnumel meta get XBLOCK y_grid = ceildiv ynumel meta get YBLOCK z_grid = ceildiv znumel meta get ZBLOCK Grid DWithYZOverflow GridExpr generate meta dict str int - None x_grid = ceildiv xnumel meta get XBLOCK prefix extend assign_tmp y_grid_raw_ ceildiv ynumel meta get YBLOCK assign_tmp y_grid_div_ ceildiv y_grid_raw_ get_max_y_grid y_grid = ceildiv y_grid_raw_ y_grid_div_ z_grid = y_grid_div_ MixOrderReductionGrid GridExpr generate meta dict str int - None split_size = meta get RSPLIT_SIZE xblock = meta get XBLOCK assert split_size assert xblock == Mix order reduction force XBLOCK= right now x_grid = ceildiv xnumel split_size CooperativeReductionGrid GridExpr generate meta dict str int - None x_grid = str meta RSPLIT y_grid = ceildiv xnumel meta get XBLOCK SplitScanGrid GridExpr generate meta dict str int - None assert meta get XBLOCK == x_grid = ceildiv r _numel meta get R _BLOCK y_grid = xnumel FixedGrid GridExpr staticmethod setup_grid_as_args - dict str Any Inductor meta so launcher takes three extra grid arguments grid_type FixedGrid __name__ fixed_grid _grid_ _grid_ _grid_ extra_launcher_args _grid_ _grid_ _grid_ generate meta dict str int - None x_grid y_grid z_grid = inductor_meta fixed_grid PrecomputedGrid GridExpr generate meta dict str int - None candidate inductor_meta precomputed_grids all meta get k == v k v candidate config items x_grid y_grid z_grid = candidate mode raise AssertionError f Precomputed grid found meta inductor_meta precomputed_grids ComboKernelGrid GridExpr generate meta dict str int combo_meta = inductor_meta combo_grid_meta combo_meta default_config meta = combo_meta default_config meta no_x_dims = xnumels = ynumels = znumels = num range combo_meta num_kernels assert combo_meta f xnumel_ num None combo_meta f xnumel_ num no_x_dims append combo_meta f no_x_dim_ num xnumels append combo_meta f xnumel_ num f xnumel_ num f ynumel_ num combo_meta ynumels append combo_meta f ynumel_ num f ynumel_ num f znumel_ num combo_meta znumels append combo_meta f znumel_ num f znumel_ num x_grid = combo_x_grid xnumels no_x_dims meta combo_meta min_blocks x_grid = maximum x_grid combo_meta min_blocks ynumels y_grid = ceildiv maximum ynumels meta get YBLOCK znumels z_grid = ceildiv maximum znumels meta get ZBLOCK combo_x_grid xnumels list int &#124; str no_x_dims list bool meta dict str int - str &#124; int raise NotImplementedError SequentialComboKernelGrid ComboKernelGrid combo_x_grid xnumels list int &#124; str no_x_dims list bool meta dict str int - str &#124; int assert len xnumels == len no_x_dims summation ceildiv x no_x_dim meta get XBLOCK x no_x_dim zip xnumels no_x_dims RoundRobinComboKernelGrid ComboKernelGrid combo_x_grid xnumels list int &#124; str no_x_dims list bool meta dict str int - str assert len xnumels == len no_x_dims num_kernels = inductor_meta combo_grid_meta num_kernels exprs = x x no_x_dim zip xnumels no_x_dims no_x_dim xnumels_x_dim = x x no_x_dim zip xnumels no_x_dims no_x_dim xnumels_x_dim exprs append ceildiv maximum xnumels_x_dim meta get XBLOCK f maximum exprs num_kernels