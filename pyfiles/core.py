mypy ignore-errors collections collections abc contextlib logging math operator unittest abc ABC abstractmethod collections abc Callable Iterable dataclasses asdict dataclass field enum Enum functools partial itertools product typing Any Optional TypeVar Union torch torch testing make_tensor torch testing _internal common_device_type skipCPUIfNoFFT tol toleranceOverride torch testing _internal common_dtype _dispatch_dtypes floating_and_complex_types floating_and_complex_types_and floating_types get_all_dtypes torch testing _internal common_utils extract_test_fn IS_FBCODE is_iterable_of_tensors noncontiguous_like OPINFO_SAMPLE_INPUT_INDEX TEST_WITH_ROCM torch_to_numpy_dtype_dict TrackedInputIter USE_PYTEST torch testing _internal opinfo utils torchgen utils dataclass_repr setup logging log = logging getLogger __name__ Reasonable testing sizes dimensions L = M = S = XS = Unique value distinguish default anything _NOTHING = object Extension getattr support qualified names e g _getattr_qual torch linalg norm - torch linalg norm _getattr_qual obj name default=_NOTHING try path name split obj = getattr obj path obj except AttributeError default _NOTHING default raise DecorateInfo Describes which test type tests should wrapped given decorators when testing operator Any test matches all provided arguments will decorated The decorators will only applied active_if argument True __slots__ = decorators cls_name test_name device_type dtypes active_if __init__ decorators cls_name=None test_name=None device_type=None dtypes=None active_if=True decorators = list decorators isinstance decorators collections abc Sequence decorators cls_name = cls_name test_name = test_name device_type = device_type dtypes = dtypes active_if = active_if Validate dtypes dtypes None dtype dtypes assert isinstance dtype torch dtype is_active cls_name test_name device_type dtype param_kwargs active_if cls_name None cls_name == cls_name test_name None test_name == test_name device_type None device_type == device_type dtypes None dtype dtypes Support callables over kwargs determine decorator active active_if param_kwargs isinstance active_if Callable active_if FIXME Note historically input kwarg had Tensor TensorList we trying support scalar inputs too Some tests still depend input being Tensor TensorList however SampleInput Represents sample inputs function __slots__ = input args kwargs output_process_fn_grad broadcasts_input name __init__ input var_args args=None kwargs=None output_process_fn_grad=None broadcasts_input=None name=None var_kwargs input first input op typically either Tensor TensorList Sequence Tensor This follows typical pattern where Tensor inputs op t = t op input = input Allow calling either SampleInput input args=args kwargs=kwargs SampleInput input args kwargs mix two forms args None kwargs None assert var_args var_kwargs A SampleInput can constructed naturally args kwargs explicitly setting args kwargs parameters two methods construction cannot mixed var_args var_kwargs assert output_process_fn_grad None broadcasts_input None name None A SampleInput constructed naturally args kwargs cannot specify additional metadata keyword arguments args = args args None var_args assert isinstance args tuple kwargs = kwargs kwargs None var_kwargs assert isinstance kwargs dict output_process_fn_grad = output_process_fn_grad output_process_fn_grad None lambda x x name = name name None Specifies ` input ` broadcasted given operator supports broadcasting This field used verify behavior inplace variant If SampleInput marked ` broadcasts_input=True ` verified we get ` RuntimeError ` sample inplace variant Also inplace grad grad tests skipped such inputs they will error out otherwise broadcasts_input = broadcasts_input broadcasts_input None False with_metadata output_process_fn_grad=None broadcasts_input=None name=None output_process_fn_grad None output_process_fn_grad = output_process_fn_grad broadcasts_input None broadcasts_input = broadcasts_input name None name = name _repr_helper formatter Helper function details SampleInput ` str ` It consolidates all fields SampleInput allows formatting fields like ` input ` ` args ` etc ` formatter ` callable customize representation Look ` summary ` method example arguments = f input= formatter input f args= formatter args f kwargs= formatter kwargs f broadcasts_input= broadcasts_input f name= repr name f SampleInput join arguments None __repr__ _repr_helper lambda x x summary Returns SampleInput details more friendly format It formats ` Tensor ` ` TensorList ` more condensed representation formatter arg Format any instance ` Tensor ` standalone list dict Tensor TensorShape Eg Tensor shape formatted Tensor isinstance arg torch Tensor shape = str tuple arg shape dtype = str arg dtype device = str arg device contiguity_suffix = NB sparse CSR tensors annoyingly is_sparse=False is_sparse = arg is_sparse arg layout == torch sparse_csr is_sparse arg is_contiguous contiguity_suffix = contiguous=False f Tensor size= shape device= device dtype= dtype contiguity_suffix isinstance arg dict k formatter v k v arg items is_iterable_of_tensors arg TensorList + join map formatter arg + isinstance arg list tuple Handle list tuple + join map formatter arg + repr arg _repr_helper formatter Applies transform f t - t each tensor dtype SampleInput transform f tt t _tt t torch no_grad f t isinstance t torch Tensor _tt t isinstance t torch dtype _tt t isinstance t list list map tt t isinstance t tuple tuple map tt t isinstance t dict k tt v k v t items t sample_tt_input tt_args tt_kwargs = tt input tt args tt kwargs Note transformed SampleInput assumes metadata like output_process_fn_grad still valid SampleInput sample_tt_input args=tt_args kwargs=tt_kwargs output_process_fn_grad=self output_process_fn_grad broadcasts_input=self broadcasts_input name=self name + _transformed Returns NumPy version sample input object form tuple input args kwargs Converts tensors ndarrays calling detach cpu numpy them Converts dtypes remapping them using torch_to_numpy_dtype_dict numpy to_numpy t isinstance t torch Tensor t dtype torch bfloat t detach cpu torch float numpy t dtype torch chalf t detach cpu torch cfloat numpy t detach cpu numpy isinstance t torch dtype torch_to_numpy_dtype_dict t t transform to_numpy noncontiguous to_noncontiguous t isinstance t torch Tensor noncontiguous_like t isinstance t torch dtype t t transform to_noncontiguous NumericsFilter = collections namedtuple NumericsFilter condition safe_val ErrorInput A SampleInput will cause operation throw error plus information about resulting error __slots__ = sample_input error_type error_regex __init__ sample_input error_type=RuntimeError error_regex sample_input = sample_input error_type = error_type error_regex = error_regex AliasInfo Class holds alias information For example torch abs - torch absolute torch Tensor absolute torch Tensor absolute_ __init__ alias_name name = alias_name op = _getattr_qual torch alias_name method_variant = getattr torch Tensor alias_name None inplace_variant = getattr torch Tensor alias_name + _ None __call__ args kwargs op args kwargs Note OpInfos ~~~~~~~~~~~~~~ The majority note written shortly after PyTorch release If you notice s out-of-date think could improved then please file issue See also OpInfo tracker https github com pytorch pytorch issues See also Writing Test Templates common_device_type py learn how parametrize test template using OpInfos See also PyTorch s GitHub wiki running writing tests https github com pytorch pytorch wiki Running-and-writing-tests See also ModuleInfos OpInfo s sister defined common_modules py An OpInfo collection metadata related PyTorch operator This metadata used generate tests validate properties operator like implements correct gradient formula WHY OPINFOS ~~~~~~~~~~~~ OpInfos principally intended do three things allow systematic testing over all PyTorch s operators simplify operating testing autogenerating many tests allow systems like autograd torchscript fx nnc test against every PyTorch operator All these goals still work progress Not every operator has OpInfo some operator tests could automatically generated still have written manually It s helpful understand OpInfos both about test simplification modularity PyTorch complicated framework many interrelated systems too many any one person keep track An OpInfo can thought interface between operator implementer those other systems Instead requiring implementer torch foo understand how test its forward mode AD NNC support s typically handled automatically just defining OpInfo It s often surprising OpInfo writers just implementing OpInfo typically can t verify operator actually implemented correctly If OpInfo doesn t validate my op works expected what s point But point above OpInfos intended let you focus testing operator logic you re familiar instead having write tests how operator interacts each PyTorch s many systems And OK turns out SOMETIMES just writing OpInfo DOES validate your op works expected s only special cases See below details WHAT S AN OPINFO ~~~~~~~~~~~~~~~~~ So what OpInfo It s Python describes operator s properties like which dtypes supports CPU whether has any aliases These properties can divided into three categories Metadata describing operator like operator s name supports out kwarg Test directives like skips tell test suite skip some tests A sample inputs function generates valid inputs operator OpInfo attributes described more detail below THE SAMPLE INPUTS FUNCTION ~~~~~~~~~~~~~~~~~~~~~~~~~~ The sample inputs function merits special elaboration This function crucial testing OpInfos A typical OpInfo test has treat operator black box There s no structure test understand exploit Without sample inputs wouldn t even know how call OpInfo s operator The sample input function saves day providing different SampleInputs can used call operator A sample input function should have following signature sample_inputs_foo op_info device dtype requires_grad kwargs And should iterable SampleInputs see description above Each SampleInput defines input args kwargs output_process_fn_grad function broadcasts_input bool name All sample_inputs functions invoked within ` torch no_grad ` environment efficiency correctness As such remember set requires_grad flag inputs after performing any transformations them The input first argument operator tensor method inplace variants operator should called should requested device requested dtype its requires_grad attribute should set requires_grad argument args should contain positional arguments kwargs keyword arguments output_process_fn_grad has interesting name It s function maps operator s output when given input args kwargs portion output gradcheck For example consider operator like torch linalg slogdet https pytorch org docs main generated torch linalg slogdet html This operator returns tuple two tensors first tensor cannot backwarded through Its output_process_fn_grad filters output tuple just second argument which we can call backward Functions produce single tensor can ignore argument broadcasts_input bool indicated SampleInput causes operator broadcast input argument This important tests understand because inplace variants operations throw runtime error they would broadcast their input arguments so tests work inplace variants filter SampleInputs broadcast their input name string s just used debugging It appears when printing SampleInput Sample inputs designed used many tests some very time consuming so they should small set small tensors An elaborated set sample inputs can specified using reference_inputs_func attribute The reference inputs operation extended set sample inputs can more exhaustively test operator They used only few tests careful take too long run Adding reference inputs highly encouraged THE OPTIONAL ERROR INPUTS FUNCTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpInfos may optionally specify error inputs through error function If specified test_errors test_ops py will call op these inputs validate desired error thrown Error inputs automate common testing pattern where multiple inputs passed operation errors they thrown reviewed Tests written style should ported new OpInfo pattern Error inputs specified using ErrorInputs which contains SampleInput see above data about expected error OPINFO FILE ORGANIZATION ~~~~~~~~~~~~~~~~~~~~~~~~ All OpInfos currently defined file Most OpInfo tests defined test_ops py some system-specific tests defined those systems test files subclass-specific tests defined test file corresponds subclass see below Expect reorganization future WHAT S TESTED ~~~~~~~~~~~~~~ Every OpInfo op_db sequence has following properties validated test_ops py - its supported dtypes specified correctly - operation produces same results when called noncontiguous inputs - supports out= argument properly allows out= see https github com pytorch pytorch wiki Developer-FAQ#how-does-out-work-in-pytorch - works conjugate view bit properly - its function method inplace variants perform same operation torch add torch Tensor add torch Tensor add_ all do same thing - its inplace variant preserves input s storage - its gradient formula implemented correctly supports gradgrad complex grad gradgrad forward mode AD properly op s function inplace variants method variants skipped reduce test time - operation performs same operation when traced scripted using jit - operation autodifferentiated jit expected - operator s aliases any perform same operation jit understands alias - operator throws correct errors error_inputs defined - operator produces same results NumPy reference ref defined - operator produces same results NumPy reference extended set reference inputs both ref reference_inputs_func defined NOTE elementwise unary elementwise binary OpInfos do even only ref defined because they effectively autogenerate reference inputs - operator works different CUDA devices Additional OpInfo tests test_jit_fuser_te py test_fx_experimental py test_fx py These tests validate operators work NNC FX expected For performance some above tests may only run first SampleInput returned OpInfo s sample input function In addition these tests some subclasses discussed next section define additional tests Critically mentioned above what s necessarily tested operator works expected When implementing OpInfo engineer must still typically write one more tests validating operator s behavior The exception reference testing sufficient operation belongs OpInfo subclass has more exhaustive operator testing Elementwise unary elementwise binary operators particular usually don t require additional testing beyond writing Opinfo OPINFO SUB CLASSES ~~~~~~~~~~~~~~~~~~~ In addition OpInfo base there several specialized OpInfo subclasses For example UnaryUfuncInfo subclass used unary elementwise operations These operations have common structure test_unary_ufuncs py exploits additional automated testing The automated testing test_unary_ufuncs py so thorough comparing operator NumPy reference function plethora values just implementing OpInfo unary elementwise operation often sufficient testing The ForeachFuncInfo another OpInfo subclass hyper-specialized very unique operations These OpInfos aren t included op_db sequence have their own tests Other OpInfo subclasses like SpectralFuncInfo just convenience when writing OpInfos TESTING A NEW OPERATOR ~~~~~~~~~~~~~~~~~~~~~~ If you re adding new operator any following namespaces - torch - torch fft - torch linalg - torch special - torch nn functional then you should typically add OpInfo As mentioned couple times above implementing OpInfo usually sufficient testing unless operator unary binary elementwise operator The OpInfo will only test properties described WHAT S TESTED section It DOES NOT necessarily verify operator implemented correctly TIPS FOR WRITING AN OPINFO AND OPINFO TESTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Writing OpInfo can little daunting Since point OpInfo consumed variety systems can hard understand how deal test failures how set OpInfo metadata properly Before adding OpInfo helps look other OpInfos A sample inputs function must defined operator s dtypes must specified Once s done you should run operator s tests test_ops py these can filtered using -k argument pytest Tests fail should provide error message describes what change about your OpInfo You don t need worry about changing OpInfo s default values unless test yells you Similarly you re writing test consumes OpInfos then s critical your test provides clear error message describing what do when fails You should assume OpInfo implementer familiar your system If you see confusing error message while developing OpInfo then please file issue describing what happened This trial-and-error approach writing OpInfo can frustrating s probably necessary long OpInfos don t require learning about all systems consume them One thing can help get_supported_dtypes function defined utils py This function can used programmatically specify dtypes operator supports especially useful writing OpInfo machine without CUDA device See its documentation more details THE FUTURE OF OPINFOS AND OPINFO TESTING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In future we expect OpInfo coverage improve cover great majority PyTorch s public operators Classes methods operator database dataclass OpInfo Operator information helper functions acquiring string name function name str An optional reference function accepts ndarrays AKA NumPy arrays If given op will compared its reference each its sample inputs ref Optional Callable = None following metadata describes operator its variants its aliases any iterable aliases e g absolute torch abs aliases Iterable = None additional string include test name useful when op needs multiple OpInfos like divide does often because s really several different ops behind scenes variant_test_name str = function variant operation populated torch name None op Callable = None allows method variant operation specified follows - _NOTHING default then OpInfo attempts discover variant using its name - None then OpInfo explicitly specifies has no associated method - Callable then callable should method associated operation method_variant Callable = _NOTHING allows inplace variant operation specified follows - _NOTHING default then OpInfo attempts discover variant using its name - None then OpInfo explicitly specifies has no associated inplace variant - Callable then callable should inplace variant associated operation inplace_variant Callable = _NOTHING allows operator variant operation specified follows - _NOTHING default then OpInfo attempts discover variant using its name - None then OpInfo explicitly specifies has no associated operator - Callable then callable should operator associated operation operator_variant Callable = _NOTHING allows inplace operator variant operation specified follows - _NOTHING default then OpInfo attempts discover variant using its name - None then OpInfo explicitly specifies has no associated inplace operator - Callable then callable should inplace operator associated operation inplace_operator_variant Callable = _NOTHING following metadata test directives skipping modifying tests information about which tests skip skips tuple = decorators apply generated tests decorators tuple = following pointers functions generate certain classes inputs function generate sample inputs strided layouts sample_inputs_func Callable = None function generate more thorough set samples inputs strided layouts reference_inputs_func Callable = None function generate inputs will throw errors error_inputs_func Callable = None function generate sparse coo csr csc bsr bsc inputs will throw errors error_inputs_sparse_func Callable = None function generate sample inputs sparse coo layouts sample_inputs_sparse_coo_func Callable = None function generate sample inputs sparse csr layouts sample_inputs_sparse_csr_func Callable = None function generate sample inputs sparse csc layouts sample_inputs_sparse_csc_func Callable = None function generate sample inputs sparse bsr layouts sample_inputs_sparse_bsr_func Callable = None function generate sample inputs sparse bsc layouts sample_inputs_sparse_bsc_func Callable = None following metadata relates dtype support tested correctness test_ops py dtypes function works CPU inherited other device types don t specify their own dtypes dtypes _dispatch_dtypes = None following dtypesIf options override dtypes value their respective device types I e instead writing multiple ` dtypesIfCUDA ` ` dtypesIfROCM ` etc one can simply define dict dtypesIf = cuda torch float torch double rocm torch half torch bfloat dtypesIf dict str _dispatch_dtypes = field default_factory=dict __getattribute__ name str - Any name startswith dtypesIf name = dtypesIf TODO Warn used dev_name = name removeprefix dtypesIf lower dtypesIf get dev_name super __getattribute__ name __setattr__ name str value Any - None TODO After migration start adding warnings here name startswith dtypesIf name = dtypesIf assert isinstance value _dispatch_dtypes type None dev_name = name removeprefix dtypesIf lower dtypesIf dev_name = value super __setattr__ name value dtypes function expected work CUDA dtypesIfCUDA _dispatch_dtypes = None dtypes function expected work ROCM dtypesIfROCM _dispatch_dtypes = None dtypesIfHpu _dispatch_dtypes = None dtypes function expected work XPU dtypesIfXPU _dispatch_dtypes = None backward dtypes function expected work backward_dtypes _dispatch_dtypes = None backward dtypes function expected work CUDA backward_dtypesIfCUDA _dispatch_dtypes = None backward dtypes function expected work ROCM backward_dtypesIfROCM _dispatch_dtypes = None backward_dtypesIfHpu _dispatch_dtypes = None following metadata describes operators out= support whether op supports out kwarg defaults True op does allow out kwarg supports incorrectly then test_out test_ops py should fail supports_out bool = True following metadata relates autograd support whether operation supports backward mode AD true gradient correctness tested test_ops py using op s sample inputs supports_autograd bool = True whether op supports second order gradients true gradgrad correctness tested test_ops py defaults support_autograd s value TODO rename supports_bwgrad_bwgrad consistent below supports_gradgrad bool = None whether ops supports second order gradients via forward-over-reverse If True forward-over-reverse gradgrad correctness tested If False test forward grad implemented Defaults False supports_fwgrad_bwgrad bool = False whether operation supports inplace autograd true tested test_ops py defaults supports_autograd s value supports_inplace_autograd bool = None Whether operation support forward mode AD If value True we check gradients correct If value False we test forward grad implemented supports_forward_ad bool = False Whether operation has varargs variant e g functions like ones zeros methods like view permute supports_varargs bool = False Whether forward operation avoids materializing COW tensor inputs supports_cow_input_no_materialize_forward bool = True Whether backward operation avoids materializing COW tensor inputs supports_cow_input_no_materialize_backward bool = True Whether skip backward part COW tensor input test skip_cow_input_backward bool = False If ` supports_cow_input_no_materialize_forward == True ` list contains arg indices kwarg names inputs expected materialize allow_cow_input_materialize_forward list Union int str = None If ` supports_cow_input_no_materialize_backward == True ` list contains arg indices kwarg names inputs expected materialize allow_cow_input_materialize_backward list Union int str = None wrapper function gradcheck gradcheck_wrapper Callable = lambda op args kwargs op args kwargs whether check batched grad when doing gradcheck defaults support_autograd s value check_batched_grad bool = None whether check batched grad grad when doing gradgradcheck default s support_gradgrad s value check_batched_gradgrad bool = None whether check batched forward grad when doing gradcheck defaults value ` supports_forward_ad ` check_batched_forward_grad bool = None whether check batched forward grad when doing gradcheck defaults value ` check_batched_forward_grad ` check_inplace_batched_forward_grad bool = None tolerance nondeterminism while performing gradcheck gradcheck_nondet_tol float = Whether use fast implementation gradcheck gradgradcheck When set None defers default value provided wrapper function around gradcheck testing _internal common_utils gradcheck gradcheck_fast_mode bool = None following metadata relates JIT support tested correctness test_ops py name corresponding aten operator aten_name str = None composite implicit autograd op decomposed op decomp_aten_name Optional str = None name corresponding aten operator backwards aten_backward_name Optional str = None op s aten node expected symbolically autodiffed assert_autodiffed bool = False list strings node names expected DifferentiableGraph when autodiffed Ex aten add aten mm default populated aten name Python operator autodiff_nonfusible_nodes list str = None list strings node names expected FusionGroups inside DifferentiableGraphs when operation autodiffed Ex aten add aten mm defaults empty list Note currently no ops use fusible nodes autodiff_fusible_nodes list str = None following metadata relates sparse support used test_sparse py whether op supports sparse coo inputs defaults False TODO rename supports_sparse supports_sparse_coo supports_sparse bool = None only run tracing tests supports_scripting bool = True operator can traced supports_tracing bool = True following metadata relates sparse compressed support used test_sparse_csr py test_sparse py whether op supports sparse csr inputs defaults False supports_sparse_csr bool = None whether op supports sparse csc inputs defaults False supports_sparse_csc bool = None whether op supports sparse bsr inputs defaults False supports_sparse_bsr bool = None whether op supports sparse bsc inputs defaults False supports_sparse_bsc bool = None whether op supports nested jagged inputs defaults False supports_njt bool = None whether op promotes integer inputs float promotes_int_to_float bool = False following metadata relates complex support checked test_ops py test_conjugated_samples bool = True test_neg_view bool = True assert jit shape analysis fully propagates shape assert_jit_shape_analysis bool = False following metadata relates ExpandedWeights support checked test_expanded_weights py supports_expanded_weight bool = False is_factory_function bool = False skip_correctness_check_compile_vs_eager bool = False __post_init__ _original_opinfo_args = asdict copy assert dtypes None f OpInfo name has no dtypes Validates dtypes generated dispatch-related functions name val dtypesIf items val None assert isinstance val _dispatch_dtypes dtypesIf name = set val aten_name None aten_name = name Attribute verify dynamic_dtypes used dynamic_dtypes = any isinstance dtypes utils _dynamic_dispatch_dtypes dtypes dtypesIf values dynamic_dtypes Make sure ` dtyesIfCUDA ` dynamic dynamic dispatch used CPU This because below we set dtypesIfCUDA dtypes they None assert isinstance dtypesIfCUDA utils _dynamic_dispatch_dtypes f To use dynamic dtypes operator name acquire dtypes dynamically argument ` dtypesIfCUDA ` This ensure CUDA dtypes acquired correctly they differ CPU dtypes occasionally dtypes = set dtypes NOTE backward dtypes must acquired before forward dtypes since they fallback explicit implicit specifications forward dtypes backward_dtypesIfROCM = set backward_dtypesIfROCM backward_dtypesIfROCM None backward_dtypesIfCUDA backward_dtypesIfCUDA None backward_dtypes backward_dtypes None dtypesIfROCM dtypesIfROCM None dtypesIfCUDA dtypesIfCUDA None dtypes backward_dtypesIfCUDA = set backward_dtypesIfCUDA backward_dtypesIfCUDA None backward_dtypes backward_dtypes None dtypesIfCUDA dtypesIfCUDA None dtypes backward_dtypesIfHpu = set backward_dtypesIfHpu backward_dtypesIfHpu None backward_dtypes backward_dtypes None dtypes backward_dtypes = set backward_dtypes backward_dtypes None dtypes Inherit cpu dev_type cuda hpu dtypesIf get dev_type None dtypesIf dev_type = dtypes Inherit CUDA dev_type rocm xpu dtypesIf get dev_type None dtypesIf dev_type = dtypesIf cuda NOTE op unspecified assumed under torch namespace op op = _getattr_qual torch name method_variant _NOTHING method_variant = getattr torch Tensor name None attributes like real imag callable callable method_variant method_variant = None inplace_variant _NOTHING inplace_name = name + _ inplace_variant = getattr torch Tensor inplace_name None operator_variant _NOTHING operator_variant = getattr operator name None inplace_operator_variant _NOTHING Note operator i op will use operator op assign result lhs when no __i op __ method found This results appearance inplace operator variant which does have correct inplace behavior To avoid we guard automatic detection inplace operator check inplace variant exists inplace_variant None inplace_operator_name = i + name inplace_operator_variant = getattr operator inplace_operator_name None inplace_operator_variant = None decorators = decorators skips Specifying sample inputs function without specifying corresponding layout support implies layout support supports_sparse None supports_sparse = sample_inputs_sparse_coo_func None sample_inputs_sparse_coo_func None sample_inputs_sparse_coo_func = _sample_inputs_unspecified supports_sparse_csr None supports_sparse_csr = sample_inputs_sparse_csr_func None sample_inputs_sparse_csr_func None sample_inputs_sparse_csr_func = _sample_inputs_unspecified supports_sparse_csc None supports_sparse_csc = sample_inputs_sparse_csc_func None sample_inputs_sparse_csc_func None sample_inputs_sparse_csc_func = _sample_inputs_unspecified supports_sparse_bsr None supports_sparse_bsr = sample_inputs_sparse_bsr_func None sample_inputs_sparse_bsr_func None sample_inputs_sparse_bsr_func = _sample_inputs_unspecified supports_sparse_bsc None supports_sparse_bsc = sample_inputs_sparse_bsc_func None sample_inputs_sparse_bsc_func None sample_inputs_sparse_bsc_func = _sample_inputs_unspecified supports_njt None supports_njt = False We run sampling functions without tracking gradiends creation inputs sample_inputs_func = torch no_grad sample_inputs_func sample_inputs_sparse_coo_func = torch no_grad sample_inputs_sparse_coo_func sample_inputs_sparse_csr_func = torch no_grad sample_inputs_sparse_csr_func sample_inputs_sparse_csc_func = torch no_grad sample_inputs_sparse_csc_func sample_inputs_sparse_bsr_func = torch no_grad sample_inputs_sparse_bsr_func sample_inputs_sparse_bsc_func = torch no_grad sample_inputs_sparse_bsc_func reference_inputs_func None reference_inputs_func = torch no_grad reference_inputs_func autodiff_fusible_nodes autodiff_fusible_nodes = autodiff_nonfusible_nodes None autodiff_nonfusible_nodes = aten + name Autograd support Autograd flags depend backward AD only - If setting has been explicitly set raise error inconsistent supports_gradgrad None supports_gradgrad = supports_autograd assert supports_gradgrad supports_autograd supports_gradgrad refines part autograd supported so should set supports_autograd False check_batched_grad None check_batched_grad = supports_autograd supports_forward_ad assert check_batched_grad supports_autograd supports_forward_ad check_batched_grad refines part autograd will checked gradcheck so should set supports_autograd False check_batched_gradgrad None check_batched_gradgrad = supports_gradgrad assert check_batched_gradgrad supports_gradgrad check_batched_gradgrad refines part autograd will checked gradgradcheck so should set either supports_gradgrad supports_autograd False check_batched_forward_grad None check_batched_forward_grad = supports_forward_ad assert check_batched_forward_grad supports_forward_ad check_batched_forward_grad should only used when supports_forward_ad True It used disable test specific cases where op supports forward ad fails compute batched forward grad check_inplace_batched_forward_grad None check_inplace_batched_forward_grad = check_batched_forward_grad assert check_inplace_batched_forward_grad check_batched_forward_grad check_batched_forward_grad should only used when check_batched_forward_grad True It used disable test specific cases where op supports batched forward grad fails compute batched forward grad inplace variant op assert supports_fwgrad_bwgrad supports_autograd supports_fwgrad_bwgrad enables forward-over-backward gradgrad checks should only True backward ad also checked i e supports_forward_ad should True name Autograd flags depend both forward AD backward AD supports_inplace_autograd None supports_inplace_autograd = supports_autograd supports_forward_ad assert supports_inplace_autograd supports_autograd supports_forward_ad supports_inplace_autograd refines part autograd supported so should set both supports_autograd supports_forward_ad False aliases None aliases = tuple AliasInfo aliases type ignore assignment aliases = __call__ args kwargs Calls function variant operator op args kwargs __str__ dataclass_repr get_op Returns function variant operator torch op_name op get_method Returns method variant operator torch Tensor op_name Returns None operator has no method variant method_variant get_inplace Returns inplace variant operator torch Tensor op_name _ Returns None operator has no inplace variant inplace_variant get_operator Returns operator variant operator e g operator neg Returns None operator has no operator variant operator_variant get_inplace_operator Returns inplace operator variant operator e g operator iadd Returns None operator has no inplace operator variant inplace_operator_variant Returns tuple callables TestCase - subtest context TestCase - skip xfail context I d love combine these into one I haven t figured out how do way works like should I tried LOT things _maybe_skip_or_xfail rules device sample idx _subtest_fn test_case sample=sample name idx=idx test_case subTest sample=sample idx=idx rules None len rules == _subtest_fn lambda _ contextlib nullcontext NB match first rule only order matters rule rules rule sample_match_fn device sample log debug matched s rule s s s s rule type rule name full_name device sample Provide context test case run sample input through subtest AND handle skip xfail needed _subtest_fn lambda test_case rule=rule rule get_context test_case log debug matched no rules s s s full_name device sample _subtest_fn lambda _ contextlib nullcontext _sample_callback_fn use_subtests device Get sample-specific skips xfails sample_skips_and_xfails = getattr extract_test_fn sample_skips_and_xfails None sample_skips_and_xfails None use_subtests raise RuntimeError Sample-specific skips xfails require use_subtests=True Please pass sample generation function run test logic within returned contexts NB order matters For example test_foo device dtype op sample subtest_ctx skip_xfail_ctx op sample_inputs use_subtests=True these contexts handle running within subtests skips xfails subtest_ctx skip_xfail_ctx test logic here use_subtests use default callback returns sample without subtest context None USE_PYTEST try pytest_subtests noqa F except ModuleNotFoundError raise RuntimeError Encountered OpInfo test use_subtests=True pytest-subtests installed The feature will work correctly within pytest without package please install None _f sample idx self=self device=device sample_skips_and_xfails=sample_skips_and_xfails use_subtests=use_subtests When subtests enabled also subtest context This required xfails skips work properly sample _maybe_skip_or_xfail sample_skips_and_xfails device sample idx _f conjugate_sample_inputs device dtype requires_grad=False kwargs Returns iterable SampleInputs tensor input first tensor sequence input conjugated set_seed = kwargs pop set_seed True use_subtests = kwargs pop use_subtests False samples = sample_inputs_func device dtype requires_grad kwargs conj_samples = list samples conjugate tensor _requires_grad = tensor requires_grad tensor = tensor conj tensor requires_grad_ _requires_grad i sample enumerate samples sample = conj_samples i Note assumed input here either tensor tensorlist isinstance sample input torch Tensor sample input = conjugate sample input sample input = conjugate sample input TrackedInputIter iter conj_samples conjugate sample input item_callback=self _sample_callback_fn use_subtests device set_seed=set_seed restrict_to_index=OPINFO_SAMPLE_INPUT_INDEX sample_inputs device dtype requires_grad=False kwargs Returns iterable SampleInputs These samples should sufficient test function works correctly autograd TorchScript etc set_seed = kwargs pop set_seed True use_subtests = kwargs pop use_subtests False samples = sample_inputs_func device dtype requires_grad kwargs kwargs get include_conjugated_inputs False conj_samples = conjugate_sample_inputs device dtype requires_grad kwargs samples_list = list samples samples_list extend conj_samples samples = tuple samples_list TrackedInputIter iter samples sample input item_callback=self _sample_callback_fn use_subtests device set_seed=set_seed restrict_to_index=OPINFO_SAMPLE_INPUT_INDEX reference_inputs device dtype requires_grad=False kwargs Returns iterable SampleInputs Distinct sample_inputs above because returns expanded set inputs when reference_inputs_func defined If undefined returns sample inputs set_seed = kwargs pop set_seed True use_subtests = kwargs pop use_subtests False reference_inputs_func None samples = sample_inputs_func device dtype requires_grad kwargs TrackedInputIter iter samples reference input item_callback=self _sample_callback_fn use_subtests device set_seed=set_seed restrict_to_index=OPINFO_SAMPLE_INPUT_INDEX kwargs get include_conjugated_inputs False raise NotImplementedError references = reference_inputs_func device dtype requires_grad kwargs TrackedInputIter iter references reference input item_callback=self _sample_callback_fn use_subtests device set_seed=set_seed restrict_to_index=OPINFO_SAMPLE_INPUT_INDEX error_inputs device kwargs Returns iterable ErrorInputs set_seed = kwargs pop set_seed True use_subtests = kwargs pop use_subtests False errs = error_inputs_func device kwargs _error_item_callback e i use_subtests=use_subtests device=device cb = _sample_callback_fn use_subtests device no rules apply just sample cb None e adapt callback call since ErrorInputs contain SampleInputs _ subtest_ctx = cb e sample_input i e subtest_ctx TrackedInputIter iter errs error input track_callback=lambda e e sample_input item_callback=_error_item_callback set_seed=set_seed restrict_to_index=OPINFO_SAMPLE_INPUT_INDEX error_inputs_sparse device layout kwargs Returns iterable ErrorInputs contain sparse sample inputs specified layout supports_sparse_layout layout raise unittest SkipTest unsupported sparse layout error_inputs_sparse_func device layout kwargs supports_sparse_layout layout Return True OpInfo supports specified sparse layout layout_name = str layout split - map torch sparse_coo OpInfo supports_sparse layout_name = layout_name replace _coo getattr f supports_ layout_name sample_inputs_sparse layout device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs specified sparse layout layout_name = str layout split - sample_inputs_mth = getattr sample_inputs_ + layout_name non_empty_sampler op generator found_sample = False sample generator found_sample = True yield sample found_sample raise unittest SkipTest NO SAMPLES non_empty_sampler sample_inputs_mth device dtype requires_grad=requires_grad kwargs _sample_inputs_unspecified args kwargs Raises NotImplemented exception OpInfo instance creation specifies supports_sparse &#124; _csr &#124; _csc &#124; _bsr &#124; _bsc =True without specifying corresponding sample function sample_inputs_sparse_ coo &#124; csr &#124; csc &#124; bsr &#124; bsc _func To avoid either define corresponding sample function re-map unsupported samples error inputs appropriate opinfo definitions sparse py _validate_sample_input_sparse_ op function raise NotImplementedError no sample function specified sample_inputs_sparse_coo device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs sparse coo layout sample_inputs_sparse_coo_func device dtype requires_grad kwargs sample_inputs_sparse_csr device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs sparse csr layout sample_inputs_sparse_csr_func device dtype requires_grad kwargs sample_inputs_sparse_csc device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs sparse csc layout sample_inputs_sparse_csc_func device dtype requires_grad kwargs sample_inputs_sparse_bsr device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs sparse bsr layout sample_inputs_sparse_bsr_func device dtype requires_grad kwargs sample_inputs_sparse_bsc device dtype requires_grad=False kwargs Returns iterable SampleInputs contain inputs sparse bsc layout sample_inputs_sparse_bsc_func device dtype requires_grad kwargs get_decorators test_class test_name device dtype param_kwargs Returns decorators targeting given test result = decorator decorators isinstance decorator DecorateInfo decorator is_active test_class test_name device dtype param_kwargs result extend decorator decorators result append decorator result supported_dtypes device_type device_type == privateuse device_type = torch _C _get_privateuse _backend_name device_type = torch device device_type type device_type == cuda TEST_WITH_ROCM device_type = rocm result = dtypesIf get device_type dtypes device_type == mps result - torch float torch cdouble result supported_backward_dtypes device_type supports_autograd set device_type == privateuse device_type = torch _C _get_privateuse _backend_name device_type = torch device device_type type backward_dtypes = None device_type == cuda backward_dtypes = backward_dtypesIfROCM TEST_WITH_ROCM backward_dtypesIfCUDA device_type == hpu backward_dtypes = backward_dtypesIfHpu device_type == mps backward_dtypes = backward_dtypes - torch double torch cdouble backward_dtypes = backward_dtypes allowed_backward_dtypes = floating_and_complex_types_and torch bfloat torch float torch complex set allowed_backward_dtypes intersection backward_dtypes supports_dtype dtype device_type - bool dtype supported_dtypes device_type property full_name Returns full name helps uniquely identify OpInfo variant = + variant_test_name variant_test_name example normal in_place where normal name in_place variant f name variant property formatted_name Returns formatted full name OpInfo can used test names full_name replace _ Represents skip xfail rule matching particular set tests It allows granularity device dtype op individual sample levels This flexibility allows entire bugs represented single rule even corresponds multiple conceptual test cases across multiple ops dataclass SampleRule ABC function indicate whether rule applies op True so NB str arg callable device_type op_match_fn Callable str OpInfo bool = None function indicate whether rule applies sample True so sample_match_fn Callable torch device SampleInput bool = None optional name identifying rule name str = __post_init__ op_match_fn None raise ValueError must have op_match_fn set useful sample_match_fn None default match all samples sample_match_fn = lambda device sample True returns string identifier rule type abstractmethod type - str returns appropriate context handles xfail skips etc abstractmethod get_context test_case useful specifying xfails dataclass XFailRule SampleRule expected error type error_type TypeVar = Exception expected error message error_msg str = property type - str xfail get_context test_case test_case assertRaisesRegex failing within torch compile wraps within BackendCompilerFailed error_type torch _dynamo exc BackendCompilerFailed error_msg useful specifying skips dataclass SkipRule SampleRule property type skip get_context test_case contextlib contextmanager skipcontext test_case=test_case test_case skipTest Skipped yield skipcontext Decorator defines skip xfail rules given test function If these present ops decorator will apply these each op place them onto parametrized test functions use e g OpInfo sample_inputs sample_skips_and_xfails __init__ rules rules = rules __call__ fn rules = getattr fn sample_skips_and_xfails None rules None raise RuntimeError Multiple sets sample_skips_and_xfails defined fn sample_skips_and_xfails = rules fn _generate_reduction_inputs device dtype requires_grad kwargs Generates input tensors testing reduction operators yield make_tensor dtype=dtype device=device requires_grad=requires_grad yield make_tensor dtype=dtype device=device requires_grad=requires_grad yield make_tensor dtype=dtype device=device requires_grad=requires_grad yield make_tensor dtype=dtype device=device requires_grad=requires_grad _generate_reduction_kwargs ndim supports_multiple_dims=True Generates subset all valid dim keepdim kwargs given ndim appropriate testing reduction operators Test default dim keepdim yield Test reducing inner outer most dimensions yield dim keepdim True yield dim - keepdim False Test reducing middle dimension ndim yield dim ndim keepdim True supports_multiple_dims Test reducing all dimensions yield dim tuple range ndim keepdim False Test reducing both first last dimensions ndim yield dim - keepdim True Test reducing every other dimension starting second ndim yield dim tuple range ndim keepdim False sample_inputs_reduction op_info device dtype requires_grad kwargs Sample inputs reduction operators TODO heitorschueroff Once all reduction operators using ReductionOpInfo use op_info supports_multiple_dims directly supports_multiple_dims bool = kwargs get supports_multiple_dims True TODO heitorschueroff Once all reduction operators using ReductionOpInfo use op_info generate_args_kwargs directly generate_args_kwargs = kwargs get generate_args_kwargs lambda args kwargs yield t _generate_reduction_inputs device dtype requires_grad reduction_kwargs _generate_reduction_kwargs t ndim supports_multiple_dims args kwargs generate_args_kwargs t reduction_kwargs kwargs update reduction_kwargs yield SampleInput t detach requires_grad_ requires_grad args=args kwargs=kwargs NOTE Reductions For testing purposes we relax definition reduction operator defined docstring below We do capture operators similar API so they can tested automatically However Strictly speaking reduction operator operator can reduce array single scalar value can computed partial result reducing subarrays This usually means reduction operation should commutative associative This definition important when comes implementation determines how reduction can parallelized For example many summary statistics such median mode quantile cannot computed partial results because these sorting counting based algorithms need information would lost reduced value ReductionOpInfo OpInfo Reduction operator information An operator reduction operator reduces one more dimensions input tensor single value Reduction operators must implement following signature - ` op input args dim=None keepdim=False kwargs - Tensor ` ReductionOpInfo tests reduction operators implement consistent API Optional features such reducing over multiple dimensions captured optional keyword parameters ReductionOpInfo constructor If reduction operator does yet implement full required API reduction operators should documented xfailing failing tests rather than adding optional parameters ReductionOpInfo NOTE The API reduction operators has yet been finalized some requirements may change See tests test test_reductions py __init__ name The identity value operator has one identity Optional Any = None The nan policy operator implements one - propagate NaN values propagated output - omit NaN values discarded during reduction nan_policy Optional str = None Whether operator supports reducing multiple dimensions supports_multiple_dims bool = True Whether operator promotes integral floating point dtypes promotes_int_to_float bool = False Whether operator promotes all integral dtypes int promotes_int_to_int bool = False If specific dtype given then operator always returns dtype irrespective input dtype If None operator returns dtype according type promotion rules above result_dtype Optional torch dtype = None Casts complex results real e g linalg norm torch var complex_to_real bool = False ReductionOpInfo tests generate their own input dim keepdim arguments call function generate tuples extra args kwargs use when calling op This required operators have other required parameters besides input tensor generate_args_kwargs Callable = lambda t dim=None keepdim=False yield Options OpInfo base kwargs _original_reduction_args = locals copy assert nan_policy None propagate omit These mutually exclusive options assert result_dtype promotes_int_to_float assert result_dtype promotes_int_to_int assert result_dtype complex_to_real assert promotes_int_to_float promotes_int_to_int Default sample_inputs_func ReductionOpInfo which augments sample inputs sample_inputs_reduction args kwargs generate_args_kwargs This only used sample_inputs_func None sample_inputs_func args kwargs kwargs supports_multiple_dims = supports_multiple_dims kwargs generate_args_kwargs = generate_args_kwargs yield sample_inputs_reduction args kwargs Override OpInfo defaults call base __init__ kwargs setdefault inplace_variant None kwargs setdefault sample_inputs_func sample_inputs_func super __init__ name promotes_int_to_float=promotes_int_to_float kwargs identity = identity nan_policy = nan_policy supports_multiple_dims = supports_multiple_dims promotes_int_to_int = promotes_int_to_int complex_to_real = complex_to_real result_dtype = result_dtype generate_args_kwargs = generate_args_kwargs The base reference input generation elementwise binary operations _reference_inputs_elementwise_binary op device dtype requires_grad exclude_zero kwargs yield op sample_inputs_func op device dtype requires_grad kwargs yield generate_elementwise_binary_tensors op device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero dtype torch bool yield generate_elementwise_binary_small_value_tensors op device=device dtype=dtype requires_grad=requires_grad dtype torch bool torch uint torch int yield generate_elementwise_binary_large_value_tensors op device=device dtype=dtype requires_grad=requires_grad yield generate_elementwise_binary_broadcasting_tensors op device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero yield generate_elementwise_binary_with_scalar_samples op device=device dtype=dtype requires_grad=requires_grad yield generate_elementwise_binary_with_scalar_and_type_promotion_samples op device=device dtype=dtype requires_grad=requires_grad dtype is_floating_point dtype is_complex yield generate_elementwise_binary_extremal_value_tensors op device=device dtype=dtype requires_grad=requires_grad Note these references inputs use scalars SampleInput input value many tests require SampleInput input tensor list tensors reference_inputs_elementwise_binary op device dtype requires_grad kwargs hasattr op rhs_make_tensor_kwargs exclude_zero = op rhs_make_tensor_kwargs get exclude_zero False gen = partial _reference_inputs_elementwise_binary op device dtype requires_grad exclude_zero kwargs yields normal samples yield gen yields noncontiguous samples sample gen yield sample noncontiguous yield generate_elementwise_binary_noncontiguous_tensors op device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero yield generate_elementwise_binary_arbitrarily_strided_tensors op device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero A functional extends elementwise binary operator s bespoke error inputs generic error inputs elementwise binary operations make_error_inputs_elementwise_binary error_inputs_func error_inputs_func_wrapper op device kwargs error_inputs_func None yield error_inputs_func op device kwargs op supports_rhs_python_scalar si = SampleInput torch tensor device=device args= yield ErrorInput si error_type=Exception error_regex= op supports_one_python_scalar si = SampleInput args= torch tensor device=device yield ErrorInput si error_type=Exception error_regex= kwargs get skip_two_python_scalars False op supports_two_python_scalars si = SampleInput args= yield ErrorInput si error_type=Exception error_regex= error_inputs_func_wrapper The following functions classes testing elementwise binary operators Returns generator pairs contiguous tensors requested device requested dtype This function intended test non-vectorized vectorized code paths elementwise binary functions well their handling odd tensor sizes like zero-dim tensors tensors zero elements Each iterable will include tensor no elements zero dim scalar tensors small D tensors medium D tensor large D tensor generate_elementwise_binary_tensors op device dtype requires_grad=False exclude_zero=False shapes = tensors no elements zero dim scalar tensor small D tensor medium D tensor large D tensor make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero shape shapes lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs generate_elementwise_binary_arbitrarily_strided_tensors op device dtype requires_grad=False exclude_zero=False shape strides offset strided_cases = make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero shape strides offset strided_cases = make_arg as_strided shape strides offset b = make_arg shape yield SampleInput args= b kwargs=op sample_kwargs device dtype Returns generator pairs contiguous tensors requested device requested dtype Unlike previous function values these tensors specified manually generate_elementwise_binary_small_value_tensors op device dtype requires_grad=False exclude_zero=None exclude_zero None hasattr op rhs_make_tensor_kwargs exclude_zero = op rhs_make_tensor_kwargs get exclude_zero False defines interesting values _unsigned_int_vals = _int_vals = - - - - _float_vals = - - - - -math pi math pi -math pi + math pi - -math pi math pi -math pi - math pi + l_vals = r_vals = dtype is_floating_point prod = product _float_vals _float_vals dtype is_complex complex_vals = product _float_vals _float_vals Note use list required here map generator will emptied following product won t produce desired cross-product complex_vals = complex x x complex_vals prod = product complex_vals complex_vals dtype torch int torch int torch int torch int prod = product _int_vals _int_vals dtype torch uint prod = product _unsigned_int_vals _unsigned_int_vals raise ValueError Unsupported dtype l r prod l_vals append l r == exclude_zero r_vals append r_vals append r lhs = torch tensor l_vals device=device dtype=dtype requires_grad=requires_grad rhs = torch tensor r_vals device=device dtype=dtype requires_grad=requires_grad yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs generate_elementwise_binary_large_value_tensors op device dtype requires_grad=False _large_int_vals = - - _large_float _vals = - - - _large_float_vals = _large_float _vals + - - e e l_vals = r_vals = dtype == torch float prod = product _large_float _vals _large_float _vals dtype is_floating_point prod = product _large_float_vals _large_float_vals dtype is_complex complex_vals = product _large_float_vals _large_float_vals Note use list required here map generator will emptied following product won t produce desired cross-product complex_vals = complex x x complex_vals prod = product complex_vals complex_vals dtype torch int torch int torch int prod = product _large_int_vals _large_int_vals raise ValueError Unsupported dtype l r prod l_vals append l r_vals append r lhs = torch tensor l_vals device=device dtype=dtype requires_grad=requires_grad rhs = torch tensor r_vals device=device dtype=dtype requires_grad=requires_grad yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs generate_elementwise_binary_extremal_value_tensors op device dtype requires_grad=False _float_extremals = float inf float -inf float nan l_vals = r_vals = dtype is_floating_point prod = product _float_extremals _float_extremals dtype is_complex complex_vals = product _float_extremals _float_extremals Note use list required here map generator will emptied following product won t produce desired cross-product complex_vals = complex x x complex_vals prod = product complex_vals complex_vals raise ValueError Unsupported dtype l r prod l_vals append l r_vals append r lhs = torch tensor l_vals device=device dtype=dtype requires_grad=requires_grad rhs = torch tensor r_vals device=device dtype=dtype requires_grad=requires_grad yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs Test case NaN propagation nan = float nan dtype is_floating_point complex float nan float nan lhs = make_tensor device=device dtype=dtype requires_grad=requires_grad lhs view - = nan rhs = make_tensor device=device dtype=dtype requires_grad=requires_grad rhs view - = nan yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs Returns generator pairs contiguous noncontiguous tensors require broadcasting generate_elementwise_binary_broadcasting_tensors op device dtype requires_grad=False exclude_zero=False shapes = make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero shape noncontiguous product shapes True False shape_lhs shape_rhs = shape lhs = make_arg shape_lhs noncontiguous=noncontiguous op lhs_make_tensor_kwargs rhs = make_arg shape_rhs noncontiguous=noncontiguous op rhs_make_tensor_kwargs yield SampleInput lhs args= rhs broadcasts_input=True kwargs=op sample_kwargs device dtype lhs Returns generator pairs contiguous tensors scalars generate_elementwise_binary_with_scalar_samples op device dtype requires_grad=False make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad shapes = op supports_rhs_python_scalar shape shapes lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs lhs_scalar = make_arg op lhs_make_tensor_kwargs item rhs_scalar = make_arg op rhs_make_tensor_kwargs item yield SampleInput lhs args= rhs_scalar kwargs=op sample_kwargs device dtype lhs Extends scalar lhs op supports_one_python_scalar yield SampleInput lhs_scalar args= rhs kwargs=op sample_kwargs device dtype lhs_scalar op supports_two_python_scalars lhs_scalar = make_arg op lhs_make_tensor_kwargs item rhs_scalar = make_arg op rhs_make_tensor_kwargs item yield SampleInput lhs_scalar args= rhs_scalar kwargs=op sample_kwargs device dtype lhs_scalar Returns generator pairs contiguous tensors d tensors scalars type promotion generate_elementwise_binary_with_scalar_and_type_promotion_samples op device dtype requires_grad=False add these samples only logical comparison ops arithmetic ops happy about extremal scalars op name eq ne gt ge lt le logical_and logical_or logical_xor make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad shape = shape big enough trigger vectorization has non-vectorized tail values = float nan float inf -float inf scalar_tensors = tuple torch tensor val val values op supports_rhs_python_scalar lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs scalar values + scalar_tensors yield SampleInput lhs args= scalar kwargs=op sample_kwargs device dtype lhs Extends scalar lhs op supports_one_python_scalar yield SampleInput scalar args= rhs kwargs=op sample_kwargs device dtype scalar Returns generator pairs noncontiguous tensors generate_elementwise_binary_noncontiguous_tensors op device dtype requires_grad=False exclude_zero=False make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero Generic noncontiguity lhs = make_arg noncontiguous=True op lhs_make_tensor_kwargs rhs = make_arg noncontiguous=True op rhs_make_tensor_kwargs yield SampleInput lhs clone args= rhs clone kwargs=op sample_kwargs device dtype lhs yield SampleInput lhs contiguous args= rhs kwargs=op sample_kwargs device dtype lhs Transposed lhs = make_arg op lhs_make_tensor_kwargs rhs = make_arg op rhs_make_tensor_kwargs yield SampleInput lhs T args= rhs T kwargs=op sample_kwargs device dtype lhs More noncontiguity shapes = shape shapes lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs lhs_non_contig = torch empty shape + device=device dtype=dtype lhs_non_contig copy_ lhs rhs_non_contig = torch empty shape + device=device dtype=dtype rhs_non_contig copy_ rhs yield SampleInput lhs_non_contig clone args= rhs_non_contig clone kwargs=op sample_kwargs device dtype lhs yield SampleInput lhs_non_contig contiguous args= rhs_non_contig kwargs=op sample_kwargs device dtype lhs Noncontiguous indices shape = lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs lhs_non_contig = lhs rhs_non_contig = rhs yield SampleInput lhs_non_contig clone args= rhs_non_contig clone kwargs=op sample_kwargs device dtype lhs yield SampleInput lhs_non_contig contiguous args= rhs_non_contig kwargs=op sample_kwargs device dtype lhs Expanded tensors shapes = shape shapes lhs = make_arg shape op lhs_make_tensor_kwargs rhs = make_arg shape op rhs_make_tensor_kwargs lhs_non_contig = lhs expand - - rhs_non_contig = rhs expand - - yield SampleInput lhs_non_contig args= rhs_non_contig kwargs=op sample_kwargs device dtype lhs Sample inputs elementwise binary operators like add sample_inputs_elementwise_binary op device dtype requires_grad kwargs _M = S kwargs get small_inputs_only False M _S = XS kwargs get small_inputs_only False S hasattr op rhs_make_tensor_kwargs exclude_zero = op rhs_make_tensor_kwargs get exclude_zero False make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad exclude_zero=exclude_zero shapes = _S _S _S _M _S _S _M _S _M _S _S _M _S _S _M _S _M _S _M _S _M _S _M _S XS _M XS shape_lhs shape_rhs shapes lhs = make_arg shape_lhs op lhs_make_tensor_kwargs rhs = make_arg shape_rhs op rhs_make_tensor_kwargs broadcasts_input = shape_lhs = torch broadcast_shapes shape_lhs shape_rhs yield SampleInput lhs args= rhs kwargs=op sample_kwargs device dtype lhs broadcasts_input=broadcasts_input Metadata binary universal functions ufuncs accept two tensor have common properties BinaryUfuncInfo OpInfo Operator information universal binary functions binary ufuncs These functions two tensors common properties like - they elementwise functions - output shape determined input shape - they typically have method inplace variants - they typically support out kwarg - they typically have NumPy SciPy references See NumPy s universal function documentation https numpy org doc stable reference ufuncs html more details about concept ufuncs __init__ name sample_inputs_func=sample_inputs_elementwise_binary reference_inputs_func=reference_inputs_elementwise_binary sample_kwargs=lambda device dtype input error_inputs_func=None lhs_make_tensor_kwargs=None rhs_make_tensor_kwargs=None always_returns_bool=False Set true op always returns bool tensors supports_rhs_python_scalar=True Whether operator allows Tensor x scalar inputs supports_one_python_scalar=False Whether operator allows scalar x tensor tensor x scalar inputs supports_two_python_scalars=False Whether operator allows scalar x scalar inputs kwargs _original_binary_ufunc_args = locals copy Elementwise binary operations perform equivalent test_numpy_refs test_binary_ufuncs additional test granularity So generic test_ops py test skipped because s redundant common_skips = DecorateInfo unittest skip Skipping redundant test TestCommon test_numpy_refs kwargs skips = kwargs get skips + common_skips super __init__ name sample_inputs_func=sample_inputs_func reference_inputs_func=reference_inputs_func error_inputs_func=make_error_inputs_elementwise_binary error_inputs_func kwargs sample_kwargs = sample_kwargs lr hs_make_tensor_kwargs part OpInfo able dynamically generate valid samples later lhs_make_tensor_kwargs None lhs_make_tensor_kwargs = lhs_make_tensor_kwargs = lhs_make_tensor_kwargs rhs_make_tensor_kwargs None rhs_make_tensor_kwargs = rhs_make_tensor_kwargs = rhs_make_tensor_kwargs always_returns_bool = always_returns_bool supports_rhs_python_scalar = supports_rhs_python_scalar supports_one_python_scalar = supports_one_python_scalar supports_two_python_scalars = supports_two_python_scalars supports_two_python_scalars supports_one_python_scalar = True supports_one_python_scalar assert supports_rhs_python_scalar Can t support lhs rhs Python scalars rhs scalars The following functions classes testing elementwise unary operators sample_inputs_elementwise_unary op_info device dtype requires_grad op_kwargs=None kwargs op_kwargs op_kwargs = _L = S kwargs get small_inputs_only False L low high = op_info domain is_floating = dtype is_floating_point dtype is_complex low = low low None is_floating low + op_info _domain_eps high = high high None is_floating high - op_info _domain_eps op_info supports_sparse_csr op_info supports_sparse_csc op_info supports_sparse_bsr op_info supports_sparse_bsc Tensors dim= sparse compressed testing yield SampleInput make_tensor _L _L device=device dtype=dtype low=low high=high requires_grad=requires_grad kwargs=op_kwargs Creates D empty scalar tensor shape _L yield SampleInput make_tensor shape device=device dtype=dtype low=low high=high requires_grad=requires_grad kwargs=op_kwargs Replace values satisfying condition safe value This used block out values could cause singularity like tan pi _replace_values_in_tensor tensor condition safe_value mask = condition tensor tensor masked_fill_ mask safe_value Helper create unary elementwise tensor valid inputs _make_unary_elementwise_tensor shape op dtype kwargs low high = op domain is_floating = dtype is_floating_point dtype is_complex low = low low None is_floating low + op _domain_eps high = high high None is_floating high - op _domain_eps = make_tensor shape low=low high=high dtype=dtype kwargs op reference_numerics_filter None dtype torch bool condition safe_value = op reference_numerics_filter _replace_values_in_tensor condition safe_value Restricts values tensor domain given elementwise unary operator _filter_unary_elementwise_tensor op short-circuits boolean tensors dtype torch bool low high = op domain is_floating = dtype is_floating_point dtype is_complex low = low low None is_floating low + op _domain_eps high = high high None is_floating high - op _domain_eps dtype torch uint low None low = max low dtype is_floating_point dtype is_complex low = math ceil low low None None high = math floor high high None None op reference_numerics_filter None condition safe_value = op reference_numerics_filter _replace_values_in_tensor condition safe_value low None high None dtype is_complex real clamp_ low high imag clamp_ low high clamp_ min=low max=high generate_elementwise_unary_tensors op device dtype requires_grad kwargs Special-cases bool dtype torch bool tensors = torch empty device=device dtype=torch bool torch tensor True device=device torch tensor False device=device torch tensor True False device=device make_tensor device=device dtype=dtype make_tensor device=device dtype=dtype tensors yield SampleInput kwargs=op sample_kwargs device dtype shapes = Empty sizes make_arg = partial _make_unary_elementwise_tensor op=op device=device dtype=dtype requires_grad=requires_grad shape shapes = make_arg shape yield SampleInput kwargs=op sample_kwargs device dtype generate_elementwise_unary_small_value_tensors op device dtype requires_grad=False sample generate_elementwise_binary_small_value_tensors op device=device dtype=dtype requires_grad=requires_grad = _filter_unary_elementwise_tensor sample input op=op yield SampleInput kwargs=op sample_kwargs device dtype generate_elementwise_unary_large_value_tensors op device dtype requires_grad=False sample generate_elementwise_binary_large_value_tensors op device=device dtype=dtype requires_grad=requires_grad = _filter_unary_elementwise_tensor sample input op=op yield SampleInput sample input kwargs=op sample_kwargs device dtype generate_elementwise_unary_extremal_value_tensors op device dtype requires_grad=False sample generate_elementwise_binary_extremal_value_tensors op device=device dtype=dtype requires_grad=requires_grad yield SampleInput sample input kwargs=op sample_kwargs device dtype sample input generate_elementwise_unary_noncontiguous_tensors op device dtype requires_grad=False make_arg = partial _make_unary_elementwise_tensor op=op device=device dtype=dtype requires_grad=requires_grad Generic noncontiguity t = make_arg noncontiguous=True yield SampleInput t kwargs=op sample_kwargs device dtype t Transposed t = make_arg T yield SampleInput t kwargs=op sample_kwargs device dtype t Expanded tensors shapes = shape shapes t = make_arg shape t_non_contig = t expand - - yield SampleInput t_non_contig kwargs=op sample_kwargs device dtype t_non_contig generate_elementwise_unary_arbitrarily_strided_tensors op device dtype requires_grad=False shape strides offset strided_cases = make_arg = partial make_tensor device=device dtype=dtype requires_grad=requires_grad shape strides offset strided_cases = make_arg as_strided shape strides offset yield SampleInput kwargs=op sample_kwargs device dtype Reuses elementwise binary generators consistency TODO future generalize reference generators handle n-ary elementwise operations _reference_inputs_elementwise_unary op device dtype requires_grad kwargs yield op sample_inputs_func op device dtype requires_grad kwargs yield generate_elementwise_unary_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs dtype torch bool yield generate_elementwise_unary_small_value_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs dtype torch bool torch uint torch int op handles_large_floats dtype is_floating_point dtype is_complex yield generate_elementwise_unary_large_value_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs dtype is_floating_point op handles_complex_extremal_values dtype is_complex yield generate_elementwise_unary_extremal_value_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs reference_inputs_elementwise_unary op device dtype requires_grad kwargs gen = partial _reference_inputs_elementwise_unary op device dtype requires_grad kwargs yields normal samples yield gen yields noncontiguous samples sample gen yield sample noncontiguous yield generate_elementwise_unary_noncontiguous_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs yield generate_elementwise_unary_arbitrarily_strided_tensors op device=device dtype=dtype requires_grad=requires_grad kwargs Metadata unary universal functions ufuncs accept single tensor have common properties like UnaryUfuncInfo OpInfo Operator information universal unary functions unary ufuncs These functions single tensor common properties like - they elementwise functions - input shape output shape - they typically have method inplace variants - they typically support out kwarg - they typically have NumPy SciPy references See NumPy s universal function documentation https numpy org doc reference ufuncs html more details about concept ufuncs __init__ name string name function dtypes=floating_types domain= None None low high domain function handles_complex_extremal_values=True whether op correctly handles extremal values like nan inf handles_large_floats=True whether op correctly handles large float values like e supports_complex_to_float=False op supports casting complex input real output safely eg angle sample_inputs_func=sample_inputs_elementwise_unary reference_inputs_func=reference_inputs_elementwise_unary sample_kwargs=lambda device dtype input reference_numerics_filter=None Filters values range domain specified above should tested kwargs _original_unary_ufunc_args = locals copy super __init__ name dtypes=dtypes sample_inputs_func=sample_inputs_func reference_inputs_func=reference_inputs_func kwargs domain = domain handles_complex_extremal_values = handles_complex_extremal_values handles_large_floats = handles_large_floats supports_complex_to_float = supports_complex_to_float reference_numerics_filter = reference_numerics_filter test_unary_ufuncs py generates its own inputs test consistency operator sliced tensors non-contig tensors etc ` sample_kwargs ` utility function provide kwargs along those inputs required eg clamp It should two dictionaries first holding kwarg torch operator second one reference NumPy operator sample_kwargs = sample_kwargs Epsilon ensure grad gradgrad checks don t test values outside function s domain _domain_eps = e- sample_inputs_spectral_ops device dtype requires_grad=False kwargs is_fp _or_chalf = dtype == torch complex dtype == torch half is_fp _or_chalf nd_tensor = partial make_tensor S S + S + device=device dtype=dtype requires_grad=requires_grad oned_tensor = partial make_tensor device=device dtype=dtype requires_grad=requires_grad cuFFT supports powers half complex half precision NOTE For hfft hfft hfftn irfft irfft irfftn default args where output_size n= input_size - we make sure logical fft size power two low = None high = None name fft hfft fft irfft _refs fft hfft _refs fft irfft shapes = name fft hfft fft irfft _refs fft hfft _refs fft irfft shapes = name fft hfftn fft irfftn _refs fft hfftn _refs fft irfftn shapes = Adjusting limits because test would flaky due over-saturation float See https github com pytorch pytorch pull low = - high = shapes = nd_tensor = partial make_tensor shapes device=device low=low high=high dtype=dtype requires_grad=requires_grad oned_tensor = partial make_tensor shapes device=device low=low high=high dtype=dtype requires_grad=requires_grad ndimensional == SpectralFuncType ND yield SampleInput nd_tensor s= is_fp _or_chalf dim= norm= ortho yield SampleInput nd_tensor norm= ortho yield SampleInput nd_tensor s= yield SampleInput oned_tensor yield SampleInput nd_tensor dim=dim dim - - - - ndimensional == SpectralFuncType TwoD yield SampleInput nd_tensor s= is_fp _or_chalf dim= norm= ortho yield SampleInput nd_tensor norm= ortho yield SampleInput nd_tensor s= is_fp _or_chalf yield SampleInput nd_tensor dim= yield SampleInput nd_tensor dim= - yield SampleInput nd_tensor dim= - - - yield SampleInput nd_tensor n= is_fp _or_chalf dim= norm= ortho yield SampleInput nd_tensor norm= ortho yield SampleInput nd_tensor n= is_fp _or_chalf yield SampleInput oned_tensor yield SampleInput nd_tensor dim=dim dim - - - SpectralFuncType = Enum SpectralFuncType OneD TwoD ND Metadata Fast Fourier Transforms torch fft SpectralFuncInfo OpInfo Operator information torch fft transforms __init__ name string name function ref=None Reference implementation probably np fft namespace dtypes=floating_and_complex_types ndimensional SpectralFuncType sample_inputs_func=sample_inputs_spectral_ops decorators=None kwargs _original_spectral_func_args = dict locals copy _original_spectral_func_args update kwargs decorators = list decorators decorators None decorators += skipCPUIfNoFFT DecorateInfo toleranceOverride torch chalf tol e- e- TestCommon test_complex_half_reference_testing super __init__ name=name dtypes=dtypes decorators=decorators sample_inputs_func=sample_inputs_func kwargs ref = ref ndimensional = ndimensional ShapeFuncInfo OpInfo Early version specialized OpInfo Shape manipulating operations like tile roll __init__ name string name function ref reference function dtypes=floating_types dtypesIfCUDA=None dtypesIfROCM=None dtypesIfXPU=None sample_inputs_func=None kwargs super __init__ name dtypes=dtypes dtypesIfCUDA=dtypesIfCUDA dtypesIfROCM=dtypesIfROCM dtypesIfXPU=dtypesIfXPU sample_inputs_func=sample_inputs_func kwargs ref = ref sample_inputs_foreach device dtype N noncontiguous=False same_size=False low=None high=None zero_size means EVERY input empty zero_size bool requires_grad bool mutually exclusive same_size zero_size which all nothing intersperse_empty_tensors bool = False zero_size torch empty dtype=dtype device=device _ range N same_size make_tensor N N dtype=dtype device=device noncontiguous=noncontiguous low=low high=high requires_grad=requires_grad _ range N interweave some empty tensors + have last tensors empty see torch empty dtype=dtype device=device requires_grad=requires_grad i == i = N - intersperse_empty_tensors make_tensor N - i N - i dtype=dtype device=device noncontiguous=noncontiguous low=low high=high requires_grad=requires_grad i range N get_foreach_method_names name get torch inplace reference function op_name = _foreach_ + name inplace_op_name = op_name + _ op = getattr torch op_name None inplace_op = getattr torch inplace_op_name None ref = getattr torch name None ref_inplace = getattr torch Tensor name + _ None op inplace_op ref ref_inplace dataclass ForeachFuncInfo OpInfo Early version specialized OpInfo foreach functions The main differences parent ` dtypes ` ` dtypesIfCUDA ` ` dtypesIfROCM ` set ` get_all_dtypes include_qint=False ` b following arguments ` ` supports_alpha_param=True ` ` means function supports python scalar ` ` numbers Number ` ` last keyword argument such ` _foreach_add ` ` ` supports_scalar_self_arg=True ` ` means function can take python scalar its first argument Currently only ` _foreach_pow ` supports ` ` backward_requires_result=True ` ` which could sound self-explanatory means function uses forward result its backward computation supports_alpha_param bool = False supports_scalar_self_arg bool = False backward_requires_result bool = False __post_init__ foreach_method foreach_method_inplace torch_ref_method torch_ref_inplace = get_foreach_method_names name supports_out note crcrpar ` foreach_method ` ` zero ` ` None ` ` None ` would call ` _getattr_qual ` ` OpInfo __post_init__ ` which should fail since ` _foreach_zero ` defined moment Thus skip qualification set similar torch function assert foreach_method None assert torch_ref_method None foreach_method = foreach_method_inplace torch_ref_method = torch_ref_inplace We disable all complex tests internally foreach due reported flakiness tracked supported_dtypes = get_all_dtypes include_qint=False IS_FBCODE supported_dtypes = x x supported_dtypes x torch complex dtypes = _dispatch_dtypes supported_dtypes op = foreach_method method_variant = foreach_method ref = torch_ref_method inplace_variant = foreach_method_inplace ref_inplace = torch_ref_inplace has_no_in_place = inplace_variant None name = name name = f _foreach_ name name == norm ref = torch linalg vector_norm name == minimum because minimum ref does support inplace scalar ref = torch clamp_max ref_inplace = torch Tensor clamp_max_ name == maximum because maximum ref does support inplace scalar ref = torch clamp_min ref_inplace = torch Tensor clamp_min_ The following sets ` dtypesIfCUDA ` ` dtypesIfROCM ` accordingly super __post_init__ sample_zero_size_inputs device dtype requires_grad=False kwargs hasattr sample_inputs_func sample_zero_size_tensor_inputs sample_inputs_func sample_zero_size_tensor_inputs device dtype requires_grad kwargs gradcheck_wrapper_hermitian_input op input args kwargs Gradcheck wrapper functions take Hermitian matrices input They require modified function because finite-difference algorithm calculating derivatives does preserve Hermitian property input op input + input mH args kwargs gradcheck_wrapper_ctc_loss op input args kwargs Gradcheck wrapper ctc loss project onto log-simplex space See https github com pytorch pytorch issues op input log_softmax dim= args kwargs gradcheck_wrapper_triangular_input op args upper=False idx= kwargs Gradcheck wrapper functions take lower upper triangular matrices input They require modified function because finite-difference algorithm calculating derivatives does preserve triangular property input ` idx ` used specific which ` args idx ` triangularized triangular_arg = args idx triu upper args idx tril op args idx triangular_arg args idx + upper kwargs gradcheck_wrapper_triangular_input_real_positive_diagonal op args upper=False idx= kwargs Gradcheck wrapper functions take lower upper triangular matrices real positive diagonals example cholesky-like operations arg = args idx arg_diag = arg diagonal - - arg_diag_embed = torch diag_embed arg_diag id_diag_tensor = torch ones_like arg_diag id_tensor = torch diag_embed id_diag_tensor new_arg = arg - diag arg + I new_arg = arg - arg_diag_embed + id_tensor gradcheck_wrapper_triangular_input op args idx new_arg args idx + upper=upper idx=idx kwargs gradcheck_wrapper_masked_operation op input args kwargs Gradcheck wrapper masked operations When mask specified replaces masked-out elements zeros Use operations produce non-finite masked-out elements instance minimum maximum reductions output = op input args kwargs mask = kwargs get mask mask None output_mask = torch masked _output_mask op input args kwargs output = torch where output_mask output output new_zeros output gradcheck_wrapper_masked_pointwise_operation op input args kwargs Gradcheck wrapper masked pointwise operations Assumes result will masked iff both tensors masked specific index When mask specified replaces masked-out elements zeros Use operations produce non-finite masked-out elements instance minimum maximum reductions output = op input args kwargs input_mask = kwargs get input_mask other_mask = kwargs get other_mask input_mask None other_mask None combined_mask = torch logical_and input_mask other_mask new_kwargs = dict mask=combined_mask kwargs output_mask = torch masked _input_mask input args new_kwargs output = torch where output_mask output output new_zeros output clone_sample sample kwargs Given SampleInput function analyzes its input args kwargs produces copy each non-Tensor entry being copied reference each Tensor entry cloned ` t clone requires_grad_ t requires_grad ` clone_tensor t isinstance t torch Tensor t detach clone requires_grad_ t requires_grad t sample_kwargs = kwargs kwargs sample kwargs SampleInput clone_tensor sample input args=tuple map clone_tensor sample args kwargs= k clone_tensor v k v sample_kwargs items