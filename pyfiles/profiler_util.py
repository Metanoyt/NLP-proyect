mypy allow-untyped-defs bisect itertools math collections defaultdict namedtuple operator attrgetter typing Any Optional typing_extensions deprecated torch torch autograd DeviceType __all__ = EventList FormattedTimesMixin Interval Kernel FunctionEvent FunctionEventAvg StringTable MemRecordsAcc EventList list A list Events pretty printing __init__ args kwargs use_device = kwargs pop use_device None profile_memory = kwargs pop profile_memory False with_flops = kwargs pop with_flops False pyrefly ignore not-iterable super __init__ args kwargs _use_device = use_device _profile_memory = profile_memory _tree_built = False _with_flops = with_flops _build_tree _populate_cpu_children _remove_dup_nodes _set_backward_stacktraces _tree_built = True __str__ table _remove_dup_nodes while True to_delete = set idx range len idx cpu_parent None idx cpu_parent name == idx name len idx cpu_parent cpu_children == idx cpu_parent cpu_children = idx cpu_children idx cpu_parent kernels = idx kernels lift kernels up ch idx cpu_children ch cpu_parent = idx cpu_parent to_delete add idx len to_delete == break new_evts = ev ind ev enumerate ind to_delete clear extend new_evts _populate_cpu_children Populate child events into each underlying FunctionEvent object One event child another s e inside s e Where s e would start end child event s interval And s e start end parent event s interval Example In event list would have make parent two other intervals If any reason two intervals intersect only partially function will record parent child relationship between then Some events can async i e start end different threads since s generally undefined how attribute children ranges async ranges we do use them when calculating nested ranges stats sync_events = evt evt evt is_async evt device_type == DeviceType CPU events = sorted sync_events key=attrgetter thread Group both thread node_id so events happen have same thread_id different nodes aren t incorrectly grouped together threads = itertools groupby events key=lambda event event thread event node_id For each thread we keep stack current nested parents We maintain invariant each interval subset all other intervals lower stack First we sort intervals their start time Then we iterate over them Every time we see new interval we remove several parents top until we restore invariant Then parent child relationship recorded stack empty Finally we add new interval list Algorithm has O N log N complexity where N number intervals _thread_id thread_events threads thread_events_ = sorted thread_events key=lambda event event time_range start -event time_range end current_events list FunctionEvent = event thread_events_ while len current_events parent = current_events - event time_range start = parent time_range end event time_range end parent time_range end can t parent current_events pop parent append_cpu_child event event cpu_parent None raise AssertionError f There already CPU parent event event key event set_cpu_parent parent break current_events append event _set_backward_stacktraces bw_parent evt evt None None evt scope == BACKWARD_FUNCTION evt bw_parent evt cpu_parent fwd_stacks = evt bw_parent evt None evt stack None t = evt sequence_nr evt thread t fwd_stacks fwd_stacks t = evt stack evt p = bw_parent evt p None p fwd_thread None raise AssertionError Expected fwd_thread set backward parent t = p sequence_nr p fwd_thread evt stack = fwd_stacks get t property self_cpu_time_total sum event self_cpu_time_total event table sort_by=None row_limit= max_src_column_width= max_name_column_width= max_shapes_column_width= header=None top_level_events_only=False time_unit=None Print EventList nicely formatted table Args sort_by str optional Attribute used sort entries By default they printed same order they registered Valid keys include ` ` cpu_time ` ` ` ` cuda_time ` ` ` ` xpu_time ` ` ` ` cpu_time_total ` ` ` ` cuda_time_total ` ` ` ` xpu_time_total ` ` ` ` cpu_memory_usage ` ` ` ` cuda_memory_usage ` ` ` ` xpu_memory_usage ` ` ` ` self_cpu_memory_usage ` ` ` ` self_cuda_memory_usage ` ` ` ` self_xpu_memory_usage ` ` ` ` count ` ` top_level_events_only bool optional Boolean flag determine selection events display If true profiler will only display events top level like top-level invocation python ` lstm ` python ` add ` other functions nested events like low-level cpu cuda xpu ops events omitted profiler result readability time_unit str optional A time unit used all values table Valid options ` ` s ` ` ` ` ms ` ` ` ` us ` ` Returns A string containing table _build_table sort_by=sort_by row_limit=row_limit max_src_column_width=max_src_column_width max_name_column_width=max_name_column_width max_shapes_column_width=max_shapes_column_width header=header profile_memory=self _profile_memory with_flops=self _with_flops top_level_events_only=top_level_events_only time_unit=time_unit export_chrome_trace path Export EventList Chrome tracing tools file The checkpoint can later loaded inspected under ` ` chrome tracing ` ` URL Args path str Path where trace will written os device_name = cuda _use_device _use_device open path w f next_id = Use file IO over using json dump since JSON dumping very slow technique proven give x speedup f write evt evt trace_name None continue f write name ph X ts dur tid pid CPU functions args format evt trace_name evt time_range start evt time_range elapsed_us evt thread evt is_remote f node_id evt node_id thread_id evt thread _ evt kernels s f draw Flow arrows CPU launch GPU kernel f write f name evt trace_name ph s f ts evt time_range start f tid evt thread pid CPU functions f id next_id f cat cpu_to_ device_name args Note use torch profiler get device kernel trace next_id += len remove trailing whitespace comma f seek f tell - os SEEK_SET f truncate f write supported_export_stacks_metrics self_cpu_time_total self_cuda_time_total self_xpu_time_total self_privateuse _time_total export_stacks path str metric str metric supported_export_stacks_metrics raise ValueError metric should one + str supported_export_stacks_metrics translate_table = str maketrans \t\n ____ open path w f evt evt stack len evt stack metric_value = getattr evt metric replace cuda device replace xpu device replace privateuse device int metric_value stack_str = entry reversed evt stack stack_str += entry translate translate_table stack_str += stack_str = stack_str - + + str int metric_value f write stack_str + \n key_averages group_by_input_shapes=False group_by_stack_n= group_by_overload_name=False Averages all function events over their keys Args group_by_input_shapes group entries event name input shapes rather than just event name This useful see which input shapes contribute runtime most may help size-specific optimizations choosing best candidates quantization aka fitting roof line group_by_stack_n group top n stack trace entries group_by_overload_name Differentiate operators their overload name e g aten add Tensor aten add out will aggregated separately Returns An EventList containing FunctionEventAvg objects _tree_built raise AssertionError Expected tree built before calling key_averages stats dict tuple str FunctionEventAvg = defaultdict FunctionEventAvg get_key event group_by_input_shapes group_by_stack_n group_by_overload_name - tuple str key = str event key str event node_id str event device_type str event is_legacy str event is_user_annotation group_by_overload_name key append evt overload_name group_by_input_shapes key append str event input_shapes group_by_stack_n key += event stack group_by_stack_n tuple key evt stats get_key evt group_by_input_shapes group_by_stack_n group_by_overload_name add evt avg_list = EventList stats values use_device=self _use_device profile_memory=self _profile_memory with_flops=self _with_flops evt avg_list evt stack = evt stack group_by_stack_n group_by_input_shapes evt input_shapes = group_by_overload_name evt overload_name = avg_list total_average Averages all events Returns A FunctionEventAvg object total_stat = FunctionEventAvg evt total_stat += evt total_stat key = None total_stat key = Total total_stat _format_time time_us Define how format time FunctionEvent US_IN_SECOND = US_IN_MS = time_us = US_IN_SECOND f time_us US_IN_SECOND f s time_us = US_IN_MS f time_us US_IN_MS f ms f time_us f us _format_time_share time_us total_time_us Define how format time FunctionEvent total_time_us == time_us = raise AssertionError f Expected time_us == got time_us NaN f time_us total_time_us f _format_memory nbytes Return formatted memory size string KB = MB = KB GB = MB abs nbytes = GB f nbytes GB f GB abs nbytes = MB f nbytes MB f MB abs nbytes = KB f nbytes KB f KB str nbytes + B _attr_formatter name property lambda _format_time getattr name FormattedTimesMixin Helpers FunctionEvent FunctionEventAvg The subclass should define ` _time_total ` ` count ` attributes cpu_time_str = _attr_formatter cpu_time device_time_str = _attr_formatter device_time cpu_time_total_str = _attr_formatter cpu_time_total device_time_total_str = _attr_formatter device_time_total self_cpu_time_total_str = _attr_formatter self_cpu_time_total self_device_time_total_str = _attr_formatter self_device_time_total property cpu_time count == cpu_time_total count type ignore attr-defined property device_time count == device_time_total count type ignore attr-defined property deprecated ` cuda_time ` deprecated please use ` device_time ` instead category=FutureWarning cuda_time To deprecated device_time Interval __init__ start end start = start end = end elapsed_us r Returns length interval end - start Kernel = namedtuple Kernel name device duration FunctionEvent FormattedTimesMixin Profiling information about single function __init__ id name thread start_us end_us overload_name=None fwd_thread=None input_shapes=None stack=None scope= use_device=None cpu_memory_usage= device_memory_usage= is_async=False is_remote=False sequence_nr=- node_id=- device_type=DeviceType CPU device_index= device_resource_id=None is_legacy=False flops=None trace_name=None concrete_inputs=None kwinputs=None is_user_annotation=False metadata_json=None id int = id node_id int = node_id name str = name pyrefly ignore bad-assignment overload_name str = overload_name pyrefly ignore bad-assignment trace_name str = trace_name time_range Interval = Interval start_us end_us thread int = thread fwd_thread Optional int = fwd_thread kernels list Kernel = count int = cpu_children list FunctionEvent = cpu_parent Optional FunctionEvent = None pyrefly ignore bad-assignment input_shapes tuple int = input_shapes pyrefly ignore bad-assignment concrete_inputs list Any = concrete_inputs pyrefly ignore bad-assignment kwinputs dict str Any = kwinputs pyrefly ignore bad-assignment stack list = stack scope int = scope use_device Optional str = use_device cpu_memory_usage int = cpu_memory_usage device_memory_usage int = device_memory_usage is_async bool = is_async is_remote bool = is_remote sequence_nr int = sequence_nr device_type DeviceType = device_type device_index int = device_index device_resource_id int = thread device_resource_id None device_resource_id is_legacy bool = is_legacy flops Optional int = flops is_user_annotation Optional bool = is_user_annotation self_cpu_percent = - total_cpu_percent = - total_device_percent = - metadata_json = metadata_json append_kernel name device duration device_type = DeviceType CPU raise AssertionError Expected device_type CPU kernels append Kernel name device duration append_cpu_child child Append CPU child type FunctionEvent One supposed append only direct children event have correct cpu time being reported device_type = DeviceType CPU raise AssertionError Expected device_type CPU isinstance child FunctionEvent raise AssertionError Expected child FunctionEvent child device_type = DeviceType CPU raise AssertionError Expected child device_type CPU cpu_children append child set_cpu_parent parent Set immediate CPU parent type FunctionEvent One profiling FunctionEvent should have only one CPU parent such child s range interval completely inside parent s We use connection determine event top-level op device_type = DeviceType CPU raise AssertionError Expected device_type CPU isinstance parent FunctionEvent raise AssertionError Expected parent FunctionEvent parent device_type = DeviceType CPU raise AssertionError Expected parent device_type CPU cpu_parent = parent Note async events don t have children used when computing metrics other events have only total cpu time property self_cpu_memory_usage is_async device_type = DeviceType CPU cpu_memory_usage - sum child cpu_memory_usage child cpu_children property self_device_memory_usage is_async device_type = DeviceType CPU device_memory_usage - sum child device_memory_usage child cpu_children property deprecated ` self_cuda_memory_usage ` deprecated Use ` self_device_memory_usage ` instead category=FutureWarning self_cuda_memory_usage To deprecated self_device_memory_usage property cpu_time_total device_type == DeviceType CPU time_range elapsed_us property self_cpu_time_total is_async device_type = DeviceType CPU cpu_time_total - sum child cpu_time_total child cpu_children property device_time_total is_async use_device device_type == DeviceType CPU is_legacy account kernels children ops sum kinfo duration kinfo kernels + sum ch device_time_total ch cpu_children each legacy cpu events has single fake kernel sum kinfo duration kinfo kernels device_type DeviceType CUDA DeviceType PrivateUse DeviceType MTIA DeviceType HPU raise AssertionError f Expected device_type CUDA PrivateUse MTIA HPU got device_type time_range elapsed_us property deprecated ` cuda_time_total ` deprecated Use ` device_time_total ` instead category=FutureWarning cuda_time_total To deprecated device_time_total property self_device_time_total is_async use_device device_type == DeviceType CPU device_time_total - sum child device_time_total child cpu_children device_type DeviceType CUDA DeviceType PrivateUse DeviceType MTIA DeviceType HPU raise AssertionError f Expected device_type CUDA PrivateUse MTIA HPU got device_type device_time_total property deprecated ` self_cuda_time_total ` deprecated Use ` self_device_time_total ` instead category=FutureWarning self_cuda_time_total To deprecated self_device_time_total property key name __repr__ device_name = use_device device_time = device_time_str device_memory_usage = device_memory_usage f FunctionEvent id= id name= name overload_name= overload_name f device_type= device_type node_id= node_id cpu_time= cpu_time_str f start_us= time_range start end_us= time_range end f cpu_children= str child id child cpu_children device_name _time= device_time f name= name thread= thread input_shapes= str input_shapes f cpu_memory_usage= cpu_memory_usage device_name _memory_usage= device_memory_usage f is_async= is_async is_remote= is_remote seq_nr= sequence_nr is_legacy= is_legacy FunctionEventAvg FormattedTimesMixin Used average stats over multiple FunctionEvent objects __init__ - None key Optional str = None count int = node_id int = is_async bool = False is_remote bool = False use_device Optional str = None cpu_time_total int = device_time_total int = self_cpu_time_total int = self_device_time_total int = input_shapes Optional list list int = None overload_name Optional str = None stack Optional list = None scope Optional int = None cpu_memory_usage int = device_memory_usage int = self_cpu_memory_usage int = self_device_memory_usage int = cpu_children Optional list FunctionEvent = None cpu_parent Optional FunctionEvent = None device_type DeviceType = DeviceType CPU is_legacy bool = False flops int = add other key None First function being recorded part FunctionEventAvg propagate fields key = other key node_id = other node_id is_async = other is_async is_remote = other is_remote cpu_parent = other cpu_parent cpu_children = other cpu_children overload_name = other overload_name input_shapes = other input_shapes stack = other stack scope = other scope device_type = other device_type is_legacy = other is_legacy use_device = other use_device is_user_annotation = other is_user_annotation isinstance other FunctionEvent FunctionEventAvg raise AssertionError Expected other FunctionEvent FunctionEventAvg other key = key raise AssertionError f Expected keys match got other key vs key cpu_time_total += other cpu_time_total device_time_total += other device_time_total self_cpu_time_total += other self_cpu_time_total self_device_time_total += other self_device_time_total cpu_memory_usage += other cpu_memory_usage device_memory_usage += other device_memory_usage self_cpu_memory_usage += other self_cpu_memory_usage self_device_memory_usage += other self_device_memory_usage count += other count flops None pyrefly ignore bad-assignment flops = other flops other flops None flops += other flops __iadd__ other add other __repr__ device_name = cuda use_device use_device self_device_time = self_device_time_total_str device_time = device_time_str device_memory = device_memory_usage f FunctionEventAvg key= key self_cpu_time= self_cpu_time_total_str cpu_time= cpu_time_str f self_ device_name _time= self_device_time device_name _time= device_time input_shapes= str input_shapes f cpu_memory_usage= cpu_memory_usage device_name _memory_usage= device_memory StringTable defaultdict __missing__ key manage cases like t demangled unsigned short separately now simply check length avoid unexpected results short sequences key = torch _C _demangle key len key key key MemRecordsAcc Acceleration structure accessing mem_records interval __init__ mem_records _mem_records = mem_records _start_nses list int = _indices list int = len mem_records tmp = sorted r start_ns i i r enumerate mem_records _start_nses _indices = zip tmp type ignore assignment in_interval start_us end_us r Return all records given interval To maintain backward compatibility convert us ns function start_idx = bisect bisect_left _start_nses start_us end_idx = bisect bisect_right _start_nses end_us i range start_idx end_idx yield _mem_records _indices i _filter_stack_entry entry filtered_entries = autograd __init__ _make_grads autograd __init__ backward torch tensor backward _internal common_utils prof_callable _internal common_utils prof_func_call _internal common_utils prof_meth_call all f entry f entry f filtered_entries MEMORY_EVENT_NAME = memory OUT_OF_MEMORY_EVENT_NAME = OutOfMemory _filter_name name ignoring following utility ops filtered_out_names = MEMORY_EVENT_NAME used only top-level memory events OUT_OF_MEMORY_EVENT_NAME profiler _record_function_enter profiler _record_function_enter_new profiler _record_function_exit aten is_leaf aten output_nr aten _version name filtered_out_names Demangles optionally rewrites provided event name with_wildcard - whether replace certain numbered event names wildcard name aggregate them together profiler table output _rewrite_name name with_wildcard=False string_table = StringTable name = string_table name with_wildcard name startswith ProfilerStep# name = ProfilerStep name _build_table events sort_by=None header=None row_limit= max_src_column_width= max_name_column_width= max_shapes_column_width= with_flops=False profile_memory=False top_level_events_only=False time_unit=None Print summary events which can list FunctionEvent FunctionEventAvg len events == has_device_time = any event self_device_time_total event events has_device_mem = any event self_device_memory_usage event events use_device = events use_device Running PrivateUse device profiler enable ProfilerActivity PrivateUse can also catch privateuse memory usage Here only need check has_privateuse _time use_device use_device has_device_time raise RuntimeError use_device None there device performance data has_input_shapes = any event input_shapes None len event input_shapes event events has_overload_names = any event overload_name None len event overload_name event events sort_by None events = EventList sorted events key=lambda evt getattr evt sort_by replace cuda device replace xpu device replace privateuse device reverse=True use_device=use_device profile_memory=profile_memory with_flops=with_flops name_column_width = max len evt key evt events + max_name_column_width None name_column_width = min name_column_width max_name_column_width shapes_column_width = max len str evt input_shapes evt events + max_shapes_column_width None shapes_column_width = min shapes_column_width max_shapes_column_width DEFAULT_COLUMN_WIDTH = flops_column_width = DEFAULT_COLUMN_WIDTH src_column_width = None stacks = evt stack evt events evt stack None len evt stack has_stack = len stacks has_stack src_column_width = max max len entry entry stack stack stacks + max_src_column_width None src_column_width = min src_column_width max_src_column_width headers = Name has_overload_names headers append Overload Name headers += Self CPU Self CPU CPU total CPU total CPU time avg device_name = use_device upper use_device None None has_device_time headers extend f Self device_name f Self device_name f device_name total f device_name time avg profile_memory headers extend CPU Mem Self CPU Mem use_device has_device_mem headers extend f device_name Mem f Self device_name Mem headers append Calls Only append Node ID any event has valid = Node ID append_node_id = any evt node_id = - evt events append_node_id headers append Node ID Have use list because nonlocal Py only SPACING_SIZE = row_format_lst = header_sep_lst = line_length_lst = -SPACING_SIZE add_column padding text_dir= row_format_lst += + text_dir + str padding + + SPACING_SIZE header_sep_lst += - padding + SPACING_SIZE line_length_lst += padding + SPACING_SIZE auto_scale_flops flops flop_headers = FLOPs KFLOPs MFLOPs GFLOPs TFLOPs PFLOPs flops = raise AssertionError f Expected flops positive got flops pyrefly ignore no-matching-overload log_flops = max min math log flops float len flop_headers - log_flops = log_flops len flop_headers raise AssertionError f Expected log_flops range len flop_headers got log_flops pow math floor log_flops - flop_headers int log_flops add_column name_column_width has_overload_names add_column name_column_width _ headers + has_overload_names add_column DEFAULT_COLUMN_WIDTH has_input_shapes headers append Input Shapes add_column shapes_column_width has_stack headers append Source Location add_column src_column_width text_dir= with_flops Auto-scaling flops header raw_flops = evt flops evt events evt flops len raw_flops = flops_scale flops_header = auto_scale_flops min raw_flops headers append f Total flops_header add_column flops_column_width with_flops = False can t find any valid flops row_format = row_format_lst header_sep = header_sep_lst line_length = line_length_lst add_column = None type ignore assignment Have use list because nonlocal Py only result = append s result append s result append \n Yes newline after end well sum_self_cpu_time_total = sum_self_device_time_total = evt events sum_self_cpu_time_total += evt self_cpu_time_total evt device_type == DeviceType CPU evt is_legacy legacy profiler kernel info stored cpu events sum_self_device_time_total += evt self_device_time_total evt device_type DeviceType CUDA DeviceType PrivateUse DeviceType MTIA evt is_user_annotation kineto profiler there re events correct device type e g CUDA sum_self_device_time_total += evt self_device_time_total Actual printing header None append = line_length append header top_level_events_only append = line_length append This report only display top-level ops statistics append header_sep append row_format format headers append header_sep trim_path path src_column_width len path src_column_width offset = len path - src_column_width path = path offset len path path = + path path override_time_unit time_us default_str time_unit US_IN_SECOND = US_IN_MS = time_unit == s f time_us US_IN_SECOND f s time_unit == ms f time_us US_IN_MS f ms time_unit == us f time_us f us default_str event_limit = evt events event_limit == row_limit break top_level_events_only evt cpu_parent None continue event_limit += name = evt key max_name_column_width None len name = max_name_column_width - name = name max_name_column_width - + evt self_cpu_percent = _format_time_share evt self_cpu_time_total sum_self_cpu_time_total evt total_cpu_percent = _format_time_share evt cpu_time_total sum_self_cpu_time_total evt is_async row_values = name has_overload_names overload_name = evt overload_name max_name_column_width None len overload_name = max_name_column_width - overload_name = overload_name max_name_column_width - + row_values += overload_name row_values += Self CPU total async events evt self_cpu_percent override_time_unit evt self_cpu_time_total evt self_cpu_time_total_str time_unit Self CPU total CPU total async events evt total_cpu_percent override_time_unit evt cpu_time_total evt cpu_time_total_str time_unit CPU total override_time_unit evt cpu_time evt cpu_time_str time_unit CPU time avg has_device_time evt total_device_percent = _format_time_share evt self_device_time_total sum_self_device_time_total row_values extend override_time_unit evt self_device_time_total evt self_device_time_total_str time_unit device time total evt total_device_percent override_time_unit evt device_time_total evt device_time_total_str time_unit override_time_unit evt device_time evt device_time_str time_unit device time avg profile_memory row_values extend CPU Mem Total _format_memory evt cpu_memory_usage Self CPU Mem Total _format_memory evt self_cpu_memory_usage use_device has_device_mem row_values extend Device Mem Total _format_memory evt device_memory_usage Self Device Mem Total _format_memory evt self_device_memory_usage row_values append evt count Number calls append_node_id row_values append evt node_id has_input_shapes row_values append str evt input_shapes shapes_column_width with_flops evt flops = row_values append -- row_values append f evt flops flops_scale f type ignore possibly-undefined has_stack src_field = len evt stack src_field = trim_path evt stack src_column_width row_values append src_field append row_format format row_values has_stack empty_headers = len headers - entry evt stack append row_format format empty_headers + trim_path entry src_column_width empty_headers append append row_format format empty_headers append header_sep append f Self CPU time total override_time_unit sum_self_cpu_time_total _format_time sum_self_cpu_time_total time_unit has_device_time append f Self use_device upper use_device None None f time total override_time_unit sum_self_device_time_total _format_time sum_self_device_time_total time_unit join result