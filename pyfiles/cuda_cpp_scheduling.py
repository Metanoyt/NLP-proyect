mypy allow-untyped-defs hashlib logging collections abc Sequence typing cast torch _inductor codegen cuda cutlass_python_evt CutlassEVTCodegen MockCutlassHandler torch _inductor utils Placeholder torch utils _ordered_set OrderedSet _dynamo utils counters config codecache code_hash get_path ir Buffer ComputedBuffer CUDATemplateBuffer Pointwise scheduler BaseSchedulerNode BaseScheduling FusedSchedulerNode SchedulerNode WhyNoFuse utils get_fused_kernel_name get_kernel_metadata sympy_product virtualized V common BackendFeature IndentedBuffer log = logging getLogger __name__ WhyNoFuseNames WhyNoFuse __init__ name str name str - None name = name name = name CUDACPPScheduling BaseScheduling Partial Scheduling implementation CUDA C++ Kernels This intended used combination TritonScheduling delegated CUDACombinedScheduling It handles fusion decisions CUDA C++ specific template code generation classmethod get_backend_features cls device - OrderedSet BackendFeature OrderedSet group_fn sizes tuple V graph sizevars simplify sympy_product s s sizes staticmethod is_cuda_cpp_template node BaseSchedulerNode - bool isinstance node SchedulerNode isinstance node node CUDATemplateBuffer is_cuda_cpp_fused_template node BaseSchedulerNode - bool isinstance node FusedSchedulerNode is_cuda_cpp_template node can_fuse_vertical node BaseSchedulerNode node BaseSchedulerNode - bool is_cuda_cpp_template node isinstance node BaseSchedulerNode assert node node node node should None _can_fuse_epilogue_impl cast CUDATemplateBuffer node node node type ignore arg-type is_cuda_cpp_fused_template node isinstance node BaseSchedulerNode assert node node node node should None assert node node node node should None fnode = cast FusedSchedulerNode node _can_fuse_epilogue_impl fnode get_template_node type ignore arg-type _unwrap_epilogue_nodes fnode node type ignore arg-type False define_kernel src_code str node_schedule - str wrapper = V graph wrapper_code src_code wrapper src_to_kernel kernel_name = wrapper src_to_kernel src_code fused_name = get_fused_kernel_name node_schedule config triton descriptive_names config triton descriptive_names use original src_code key kernel_hash = hashlib sha src_code encode utf- hexdigest fused_name == fused no EVT kernel use original kernel name kernel_name = f cutlass_ kernel_hash kernel_name = f cutlass_ fused_name _ kernel_hash wrapper src_to_kernel src_code = kernel_name src_code = src_code replace str Placeholder KERNEL_NAME kernel_name _ _ kernel_path = get_path code_hash src_code py compile_wrapper = IndentedBuffer compile_wrapper writeline async_compile cuda r compile_wrapper splice src_code strip=True compile_wrapper writeline f so aot_compile= str V graph aot_mode metadata_comment = f kernel path kernel_path origins detailed_origins = get_kernel_metadata node_schedule wrapper metadata_comment += \n + origins + \n + detailed_origins wrapper define_kernel kernel_name compile_wrapper getvalue metadata_comment kernel_name codegen_template template_node BaseSchedulerNode epilogue_nodes Sequence BaseSchedulerNode prologue_nodes Sequence BaseSchedulerNode Codegen CUDA template possibly fused epilogues counters inductor cuda_epilogue_fusion_counter += len epilogue_nodes assert is_cuda_cpp_template template_node Template node passed CUDAScheduler codegen_template must SchedulerNode wraps CUDATemplateBuffer template_node = cast SchedulerNode template_node _ _numel rnumel = template_node group assert rnumel == ctb CUDATemplateBuffer = cast CUDATemplateBuffer template_node node epilogue_ir_nodes list Buffer = n node n epilogue_nodes type ignore misc assert all isinstance n ComputedBuffer n epilogue_ir_nodes Epilogue nodes must all instances ir ComputedBuffer kernel render = ctb make_kernel_render type ignore misc ctb epilogue_nodes=epilogue_nodes kernel node template_node epilogue_nodes node mark_run typically there codegen pass which runs after mark_run kernel we ve already generated C++ code we still need let kernel know about loads stores occur fused kernel memory planning properly optimize allocations ctb emulate_store_fn node epilogue_ir_nodes V set_ops_handler MockCutlassHandler V get_ops_handler assert isinstance node ComputedBuffer Not sure why we need do again node get_store_function CutlassEVTCodegen get_index_vars node V set_kernel_handler kernel src_code = render node_schedule = template_node epilogue_nodes kernel_name = define_kernel src_code node_schedule debug printing values intermediate tensors _ call_args arg_signatures _ = kernel args python_argdefs debug_printer_manager = V graph wrapper_code debug_printer debug_printer_manager set_printer_args call_args kernel_name arg_signatures kernel debug_printer_manager codegen_comment node_schedule kernel_name kernel call_kernel kernel_name ctb V graph removed_buffers &#124; = kernel removed_buffers free_buffers_in_scheduler staticmethod _unwrap_epilogue_nodes fused_node FusedSchedulerNode - list BaseSchedulerNode nodes = fused_node get_nodes template_node = fused_node get_template_node assert all n node None n nodes All epilogue nodes should have IRNode pyrefly ignore redundant-cast cast list BaseSchedulerNode n n nodes n node template_node _can_fuse_epilogue_impl cuda_template_buffer CUDATemplateBuffer existing_epilogue_nodes list BaseSchedulerNode node_to_fuse BaseSchedulerNode - bool Check given node can fused epilogue At moment Kernels support fusion Pointwise operations wrapped named ComputedBuffer nodes Args cuda_template_buffer A CUDATemplateBuffer object representing CUDA template s result buffer existing_epilogue_nodes List SchedulerNode The list already fused epilogue nodes node_to_fuse The SchedulerNode node checked can fused epilogue Returns - bool True given node can fused epilogue False otherwise why = WhyNoFuseNames cuda_template_buffer get_name node_to_fuse get_name scheduler_nodes_to_fuse = node_to_fuse get_nodes assert isinstance cuda_template_buffer CUDATemplateBuffer Checks constituent nodes s_node scheduler_nodes_to_fuse node = s_node node isinstance node ComputedBuffer why f node ComputedBuffer False isinstance node data Pointwise why f node Pointwise op False node get_computed_buffer_name type ignore attr-defined why f node does have computed buffer name False name = node get_computed_buffer_name type ignore attr-defined dtype can differ strides can differ long they broadcastable node get_size = cuda_template_buffer get_size why f name s size node get_size differs cuda_template_buffer get_name s \ size cuda_template_buffer get_size False assert len existing_epilogue_nodes cuda_template_buffer get_name OrderedSet rd name rd node_to_fuse read_writes reads First epilogue node must read cuda template buffer node_to_fuse has_aliasing_or_mutation why f node_to_fuse get_name has aliasing mutation False node_to_fuse is_reduction why f node_to_fuse get_name reduction which yet supported EVT False config cuda cutlass_epilogue_fusion_enabled config epilogue_fusion why cutlass epilogue fusion enabled False cuda_template_buffer supports_epilogue_fusion why epilogue fusion only supported TMA-enabled gemm ops False try torch _inductor codegen cuda cutlass_python_evt CutlassEVTCodegen CutlassEVTCodegen ir_to_evt_python_code cuda_template_buffer get_name existing_epilogue_nodes + list node_to_fuse get_nodes OrderedSet except NotImplementedError e not_implemented_op = str e not_implemented_op startswith _op_ not_implemented_op = not_implemented_op why f Cannot fuse epilogue node node_to_fuse into cuda_template_buffer name \ likely due unsupported operation not_implemented_op noqa G B False Likely due unsupported dtype why f Cannot fuse epilogue node node_to_fuse into cuda_template_buffer name \ Reason not_implemented_op noqa G B False True