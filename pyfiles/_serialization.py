mypy allow-untyped-defs Serialization This module contains functionality serializing TorchScript modules notably torch jit save torch jit load This intended imported directly please use exposed functionalities ` torch jit ` os torch torch _jit_internal _get_model_id torch _utils_internal log_torchscript_usage torch jit _recursive wrap_cpp_module torch serialization validate_cuda_device save m f _extra_files=None r Save offline version module use separate process The saved module serializes all methods submodules parameters attributes module It can loaded into C++ API using ` ` torch jit load filename ` ` into Python API func ` torch jit load torch jit load ` To able save module must make any calls native Python functions This means all submodules must subclasses ` ScriptModule ` well DANGER All modules no matter their device always loaded onto CPU during loading This different func ` torch load ` s semantics may change future Args m A ` ScriptModule ` save f A file-like object has implement write flush string containing file name _extra_files Map filename contents which will stored part ` f ` note torch jit save attempts preserve behavior some operators across versions For example dividing two integer tensors PyTorch performed floor division module containing code saved PyTorch loaded PyTorch its division behavior will preserved The same module saved PyTorch will fail load PyTorch however since behavior division changed does know how replicate behavior Example testcode torch io MyModule torch nn Module forward x x + m = torch jit script MyModule Save file torch jit save m scriptmodule pt This line equivalent previous m save scriptmodule pt Save io BytesIO buffer buffer = io BytesIO torch jit save m buffer Save extra files extra_files = foo txt b bar torch jit save m scriptmodule pt _extra_files=extra_files log_torchscript_usage save model_id=_get_model_id m _extra_files None _extra_files = isinstance f str os PathLike m save f _extra_files=_extra_files ret = m save_to_buffer _extra_files=_extra_files f write ret load f map_location=None _extra_files=None _restore_shapes=False r Load ` ScriptModule ` ` ScriptFunction ` previously saved func ` torch jit save torch jit save ` All previously saved modules no matter their device first loaded onto CPU then moved devices they saved If fails e g because run time system doesn t have certain devices exception raised Args f file-like object has implement read readline tell seek string containing file name map_location string torch device A simplified version ` ` map_location ` ` ` torch jit save ` used dynamically remap storages alternative set devices _extra_files dictionary filename content The extra filenames given map would loaded their content would stored provided map _restore_shapes bool Whether retrace module load using stored inputs Returns A ` ScriptModule ` object warning It possible construct malicious pickle data which will execute arbitrary code during func ` torch jit load ` Never load data could have come untrusted source could have been tampered Only load data you trust Example testcode torch io torch jit load scriptmodule pt Load ScriptModule io BytesIO object open scriptmodule pt rb f buffer = io BytesIO f read Load all tensors original device torch jit load buffer Load all tensors onto CPU using device buffer seek torch jit load buffer map_location=torch device cpu Load all tensors onto CPU using string buffer seek torch jit load buffer map_location= cpu Load extra files extra_files = foo txt values will replaced data torch jit load scriptmodule pt _extra_files=extra_files print extra_files foo txt testoutput hide testcleanup os os remove scriptmodule pt isinstance f str os PathLike os path exists f raise ValueError f The provided filename f does exist os path isdir f raise ValueError f The provided filename f directory map_location = validate_map_location map_location _extra_files None _extra_files = cu = torch _C CompilationUnit isinstance f str os PathLike cpp_module = torch _C import_ir_module cu os fspath f map_location _extra_files pyrefly ignore bad-argument-count _restore_shapes type ignore call-arg cpp_module = torch _C import_ir_module_from_buffer cu pyrefly ignore missing-attribute f read map_location _extra_files pyrefly ignore bad-argument-count _restore_shapes type ignore call-arg TODO Pretty sure approach loses ConstSequential status such ret = wrap_cpp_module cpp_module log_torchscript_usage load model_id=_get_model_id ret ret validate_map_location map_location=None isinstance map_location str map_location = torch device map_location map_location None isinstance map_location torch device raise ValueError map_location should either None string torch device got type + str type map_location str map_location startswith cuda validate_cuda_device map_location map_location jit_module_from_flatbuffer f isinstance f str os PathLike f = os fspath f wrap_cpp_module torch _C _load_jit_module_from_file f wrap_cpp_module torch _C _load_jit_module_from_bytes f read save_jit_module_to_flatbuffer m f _extra_files=None r Save offline version module use separate process The saved module serializes all methods submodules parameters attributes module It can loaded into C++ API using ` ` torch jit load_jit_module_from_file filename ` ` into Python API func ` torch jit jit_module_from_flatbuffer torch jit jit_module_from_flatbuffer ` To able save module must make any calls native Python functions This means all submodules must subclasses ` ScriptModule ` well DANGER All modules no matter their device always loaded onto CPU during loading This different func ` torch load ` s semantics may change future Args m A ` ScriptModule ` save f A string file path Example testcode torch io MyModule torch nn Module forward x x + m = torch jit script MyModule Save file torch jit save_jit_module_to_flatbuffer m scriptmodule ff extra_files = _extra_files extra_files None extra_files = isinstance f str os PathLike f = os fspath f torch _C _save_jit_module m _c f extra_files s = torch _C _save_jit_module_to_bytes m _c extra_files f write s get_flatbuffer_module_info path_or_file r Get some information regarding model file flatbuffer format Args path_or_file Either str Path file like object BytesIO OK If s str Path we will read file referenced path Bytes Returns A dict metadata what file contains currently looks like bytecode_version int operator_version int function_names __torch__ ___torch_mangle_ Foo forward set type_names set set opname_to_num_args aten linear Dict str int isinstance path_or_file str os PathLike open path_or_file rb f all_bytes = f read all_bytes = path_or_file read torch _C _get_module_info_from_flatbuffer all_bytes