mypy ignore-errors random dataclasses dataclass typing Optional torch torchfuzz operators get_operator list_operators torchfuzz tensor_fuzzer fuzz_tensor_size fuzz_torch_tensor_type fuzz_valid_stride ScalarSpec Spec specs_compatible TensorSpec Cache operators module level avoid repeated calls list_operators _CACHED_OPERATORS = None _get_cached_operators Get cached operators initializing necessary global _CACHED_OPERATORS _CACHED_OPERATORS None _CACHED_OPERATORS = list_operators _CACHED_OPERATORS _get_template_filtered_operators template str = default supported_ops Optional list str = None Get operators filtered template s supported_ops user override If supported_ops provided takes precedence used filter registry Otherwise template s supported_ops used If neither specified all operators returned Instantiate template template == dtensor torchfuzz codegen DTensorFuzzTemplate fuzz_template = DTensorFuzzTemplate template == unbacked torchfuzz codegen UnbackedFuzzTemplate fuzz_template = UnbackedFuzzTemplate torchfuzz codegen DefaultFuzzTemplate fuzz_template = DefaultFuzzTemplate all_operators = _get_cached_operators Determine allowed ops list allowed_ops = supported_ops supported_ops fuzz_template supported_ops If no supported_ops specified all operators allowed_ops all_operators Filter operators based allowed_ops filtered_ops = op_name operator all_operators items Always include operations don t have specific torch operation utility operations like arg constant item scalar ops torch_op = operator torch_op_name torch_op None Set template operators support hasattr operator set_template operator set_template template type ignore attr-defined filtered_ops op_name = operator continue Check operator supports any allowed operations should_include = False supported_op allowed_ops Direct torch operation matching torch_op == supported_op should_include = True break Direct name matching fallback supported_op op_name op_name supported_op should_include = True break should_include Set template operators support hasattr operator set_template operator set_template template type ignore attr-defined filtered_ops op_name = operator filtered_ops dataclass OperationNode Represents node operation graph Attributes node_id Unique identifier node op_name Name operation e g torch ops aten add scalar_add arg input_specs List input specifications required operation output_spec Output specification produced operation input_nodes List node IDs provide inputs operation depth Depth level node generation tree node_id str op_name str input_specs list Spec output_spec Spec input_nodes list str depth int __str__ - str String representation debugging f node_id op_name - output_spec depth depth __repr__ - str Detailed representation debugging f OperationNode node_id= node_id op_name= op_name f input_specs= input_specs output_spec= output_spec f input_nodes= input_nodes depth= depth dataclass OperationGraph Represents graph operations Attributes nodes Dictionary mapping node_id OperationNode root_node_id ID root node produces final output output node target_spec The specification root node should produce nodes dict str OperationNode root_node_id str The output node - produces final result graph target_spec Spec __post_init__ Validate graph structure after initialization root_node_id nodes raise ValueError f Root node root_node_id found nodes get_topological_order - list str Get nodes topological order dependencies before dependents Returns List node IDs topological order visited = set temp_visited = set result = visit node_id str node_id temp_visited raise ValueError f Cycle detected involving node node_id node_id visited temp_visited add node_id node = nodes node_id Visit all input nodes first input_node_id node input_nodes input_node_id nodes Skip external inputs visit input_node_id temp_visited remove node_id visited add node_id result append node_id Start all nodes handle disconnected components node_id nodes node_id visited visit node_id result get_leaf_nodes - list str Get all leaf nodes nodes no inputs node_id node_id node nodes items node input_nodes get_node_dependencies node_id str - list str Get all nodes node depends transitive closure visited = set dependencies = collect_deps current_id str current_id visited current_id nodes visited add current_id node = nodes current_id input_node_id node input_nodes dependencies append input_node_id collect_deps input_node_id collect_deps node_id dependencies __str__ - str String representation debugging lines = f OperationGraph root root_node_id target target_spec node_id get_topological_order node = nodes node_id inputs_str = f - node input_nodes node input_nodes lines append f node inputs_str \n join lines fuzz_spec template str = default - Spec Generate random Spec either TensorSpec ScalarSpec using template s distribution preferences Args template Template name determine configuration distribution Returns Spec Either TensorSpec ScalarSpec according template s distribution Try use template s custom distribution available try Instantiate template template == dtensor torchfuzz codegen DTensorFuzzTemplate fuzz_template = DTensorFuzzTemplate template == unbacked torchfuzz codegen UnbackedFuzzTemplate fuzz_template = UnbackedFuzzTemplate torchfuzz codegen DefaultFuzzTemplate fuzz_template = DefaultFuzzTemplate Use template s custom spec generation fuzz_template fuzz_spec_custom except Exception Fallback original hardcoded behavior template fails Get random dtype based template dtype = fuzz_torch_tensor_type template probability returning ScalarSpec random random ScalarSpec dtype=dtype probability returning TensorSpec Get random size corresponding stride size = fuzz_tensor_size stride = fuzz_valid_stride size TensorSpec size=size stride=stride dtype=dtype fuzz_op target_spec Spec depth stack_size template str = default supported_ops Optional list str = None - tuple str list Spec Given output specification returns operation can produce tensor layout using operator system Args target_spec Desired output specification TensorSpec ScalarSpec depth Maximum depth operation generation At depth only leaf operations constant arg allowed Higher depths allow more complex operations stack_size Current stack size When reduces probability leaf operations Returns Tuple operation_name list_of_argument_specs where each argument spec describes layout requirements operation s inputs Get template-filtered operators available_operators = _get_template_filtered_operators template supported_ops Filter operators can produce target spec IMPORTANT iterate deterministic order avoid dict-order nondeterminism compatible_ops = op_name sorted available_operators keys operator = available_operators op_name operator can_produce target_spec compatible_ops append op_name operator Shuffle seeded RNG caller seeds random deterministic base order random shuffle compatible_ops compatible_ops raise ValueError f No operators available can produce target_spec Categorize operators into leaf non-leaf leaf_ops = non_leaf_ops = op_name operator compatible_ops op_name constant arg op_name startswith arg_ leaf_ops append op_name operator non_leaf_ops append op_name operator Choose operation based depth stack size constraints depth == At depth only allow leaf operations leaf_ops If no leaf ops can produce spec fallback arg _get_arg_args_specs target_spec Weighted choice among leaf ops leaf_weights = op get_weight target_spec=target_spec depth=depth stack_size=stack_size template=template _ op leaf_ops idx = random choices range len leaf_ops weights=leaf_weights k= chosen_op_name chosen_operator = leaf_ops idx At higher depths choose between leaf non-leaf operations Reduce probability leaf operations when stack_size stack_size depth non_leaf_ops chance non-leaf chance leaf random random Weighted choice among non-leaf ops nonleaf_weights = op get_weight target_spec=target_spec depth=depth stack_size=stack_size template=template _ op non_leaf_ops idx = random choices range len non_leaf_ops weights=nonleaf_weights k= chosen_op_name chosen_operator = non_leaf_ops idx leaf_ops leaf_weights = op get_weight target_spec=target_spec depth=depth stack_size=stack_size template=template _ op leaf_ops idx = random choices range len leaf_ops weights=leaf_weights k= chosen_op_name chosen_operator = leaf_ops idx nonleaf_weights = op get_weight target_spec=target_spec depth=depth stack_size=stack_size template=template _ op non_leaf_ops idx = random choices range len non_leaf_ops weights=nonleaf_weights k= chosen_op_name chosen_operator = non_leaf_ops idx Normal probability distribution over all ops all_ops = non_leaf_ops + leaf_ops all_ops all_weights = op get_weight target_spec=target_spec depth=depth stack_size=stack_size template=template _ op all_ops idx = random choices range len all_ops weights=all_weights k= chosen_op_name chosen_operator = all_ops idx chosen_op_name chosen_operator = arg get_operator arg chosen_operator None If no operator found fallback arg _get_arg_args_specs target_spec input_specs = chosen_operator fuzz_inputs_specs target_spec chosen_op_name input_specs Global counter generating unique argument IDs _next_arg_id = _get_arg_args_specs target_spec Spec - tuple str list Spec Get argument specifications arg operation global _next_arg_id Generate unique argument ID arg_id = _next_arg_id _next_arg_id += Return operation name arg_id embedded no input specs f arg_ arg_id fuzz_operation_graph target_spec Spec max_depth int = seed Optional int = None template str = default supported_ops Optional list str = None - OperationGraph Generate graph operations produces target specification The graph-based approach allows better visualization debugging potential optimizations like common subexpression elimination Args target_spec The desired output specification TensorSpec ScalarSpec max_depth Maximum depth operations At depth only leaf operations constant arg used seed Random seed reproducible generation If None uses current random state template Template name determine configuration Returns OperationGraph nodes organized DAG structure Set seed reproducible generation seed None random random seed seed torch manual_seed seed Reset global arg counter deterministic behavior global _next_arg_id _next_arg_id = Global counter unique node IDs - start deterministic behavior node_counter = Dictionary store all nodes node_id - OperationNode nodes dict str OperationNode = _generate_node spec Spec depth int stack_size int = - str Generate node given spec its node_id nonlocal node_counter Generate new operation op_name input_specs = fuzz_op spec depth stack_size template supported_ops Create unique node ID node_id = f node_ node_counter node_counter += Generate input nodes input_node_ids = input_specs Non-leaf operations input_spec input_specs input_node_id = _generate_node input_spec max depth - stack_size + len input_node_ids + input_node_ids append input_node_id Create operation node node = OperationNode node_id=node_id op_name=op_name input_specs=input_specs output_spec=spec input_nodes=input_node_ids depth=depth Store node nodes node_id = node node_id Generate root node root_node_id = _generate_node target_spec max_depth Create operation graph graph = OperationGraph nodes=nodes root_node_id=root_node_id target_spec=target_spec Verify root node produces target spec root_node = nodes root_node_id specs_compatible root_node output_spec target_spec raise ValueError f Generated graph root node produces root_node output_spec f target spec target_spec graph