mypy allow-untyped-defs typing Optional Union sympy torch ir Pointwise ShapeAsConstantBuffer TensorBox virtualized ops pyre-ignore dense_idx_to_jagged_idx batch_idx seq_idx offsets_loader jagged_len jagged_len + used upper bound because last sequence length may zero begin_idx = ops indirect_indexing offsets_loader batch_idx jagged_len + end_idx = offsets_loader batch_idx + jagged_idx = begin_idx + seq_idx jagged_idx end_idx get_inverse_offsets offsets TensorBox jagged_len Union int sympy Expr realize bool = True - Union TensorBox ShapeAsConstantBuffer Returns inverse_offsets - inverse offsets array offsets maps batch index dense jagged index i e offset into jagged tensor inverse_offsets maps jagged index batch index e g offsets will inverse_offsets = For given offsets computed inverse_offsets cached first call reused further calls hasattr offsets inverse_offsets inverse_offsets already computed these offsets can reuse offsets inverse_offsets ops bucketize takes offsets get_name which doesn t exist Pointwise kernels i e we need realize before using In other words we need offsets global memory so we can binary search over entire tensor offsets realize device torch device = offsets get_device_or_error dtype torch dtype = offsets get_dtype pyre-ignore inner_fn index idx = index bucket = ops bucketize values=ops index_expr idx dtype boundaries= offsets get_name offsets get_size - offsets get_size offsets get_stride offsets get_stride - boundary_indices= indexing_dtype=dtype right=True ops bucketize above returns -based bucket indices we need -based hence we subtract batch bucket - inverse_offsets = Pointwise create device=device dtype=dtype inner_fn=inner_fn ranges= jagged_len realize freeze node so doesn t get inlined downstream inverse_offsets realize cache inverse_offsets further reuse offsets inverse_offsets = inverse_offsets type ignore attr-defined inverse_offsets jagged_idx_to_dense_idx jagged_idx pyre-ignore inverse_offsets_loader pyre-ignore offsets_loader pyre-ignore batch_size Union int sympy Expr max_seq_len Union int sympy Expr offsets_dtype torch dtype - tuple sympy Expr sympy Expr batch_idx = ops indirect_indexing inverse_offsets_loader jagged_idx batch_size + batch_start = offsets_loader batch_idx seq = ops index_expr jagged_idx offsets_dtype - batch_start check=False because there may sequences longer than max_seq_len seq_idx = ops indirect_indexing seq max_seq_len check=False batch_idx seq_idx register_jagged_ops Avoid circular importing here lowering fallback_handler is_integer_type register_lowering pyre-ignore register_lowering torch ops aten _jagged_to_padded_dense_forward default _jagged_to_padded_dense_forward jagged_values TensorBox jagged_offsets list TensorBox max_lengths list int list ints SymInts padding_value float = - Union TensorBox ShapeAsConstantBuffer device = jagged_values get_device_or_error dtype = jagged_values get_dtype jagged_values_size = jagged_values get_size only handle common case single jagged dimension len jagged_offsets = device type = cuda device = jagged_offsets get_device len jagged_values_size = len jagged_offsets get_size = len max_lengths = len jagged_offsets is_integer_type jagged_offsets fallback_handler torch ops aten _jagged_to_padded_dense_forward default add_to_fallback_set=False jagged_values jagged_offsets max_lengths padding_value offsets TensorBox = jagged_offsets offsets_len = offsets get_size offsets_dtype = offsets get_dtype batch_size = offsets_len - max_seq_len = max_lengths embedding_len = jagged_values_size jagged_len = jagged_values_size output_size = batch_size max_seq_len embedding_len values_loader = jagged_values make_loader offsets_loader = offsets make_loader pyre-ignore inner_fn index dense tensor size B N D batch_idx seq_idx emb_idx = index jagged_idx end_idx = dense_idx_to_jagged_idx batch_idx=batch_idx seq_idx=seq_idx offsets_loader=offsets_loader jagged_len=jagged_len ops masked ops lt ops index_expr jagged_idx offsets_dtype end_idx lambda values_loader jagged_idx emb_idx padding_value Pointwise create device=device dtype=dtype inner_fn=inner_fn ranges=output_size _dense_to_jagged_forward_impl fallback_op pyre-ignore dense TensorBox jagged_offsets list TensorBox jagged_len Optional int = None - Union TensorBox ShapeAsConstantBuffer device = dense get_device_or_error dtype = dense get_dtype dense_size = dense get_size only handle common case single jagged dimension len jagged_offsets = device type = cuda device = jagged_offsets get_device len jagged_offsets get_size = len dense_size = jagged_len None is_integer_type jagged_offsets fallback_handler fallback_op add_to_fallback_set=False dense jagged_offsets jagged_len offsets TensorBox = jagged_offsets offsets_dtype = offsets get_dtype batch_size = dense_size max_seq_len = dense_size embedding_len = dense_size - output_size = jagged_len embedding_len dense_loader = dense make_loader offsets_loader = offsets make_loader inverse_offsets = get_inverse_offsets offsets=offsets jagged_len=jagged_len inverse_offsets_loader = inverse_offsets make_loader pyre-ignore inner_fn index jagged tensor size sum_B N_B D jagged_idx emb_idx = index batch_idx seq_idx = jagged_idx_to_dense_idx jagged_idx=jagged_idx offsets_loader=offsets_loader inverse_offsets_loader=inverse_offsets_loader batch_size=batch_size max_seq_len=max_seq_len offsets_dtype=offsets_dtype ops masked ops lt ops index_expr seq_idx offsets_dtype ops index_expr max_seq_len offsets_dtype lambda dense_loader batch_idx seq_idx emb_idx jagged sequence longer than max_seq_len Pointwise create device=device dtype=dtype inner_fn=inner_fn ranges=output_size pyre-ignore register_lowering torch ops aten _padded_dense_to_jagged_forward _dense_to_jagged_forward dense TensorBox jagged_offsets list TensorBox jagged_len Optional int = None - Union TensorBox ShapeAsConstantBuffer _dense_to_jagged_forward_impl fallback_op=torch ops aten _padded_dense_to_jagged_forward default dense=dense jagged_offsets=jagged_offsets jagged_len=jagged_len