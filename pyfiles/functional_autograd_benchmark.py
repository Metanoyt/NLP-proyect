time argparse ArgumentParser collections defaultdict collections abc Callable typing Any NamedTuple torch torch autograd functional try functorch ft has_functorch = True print f Found functorch ft __version__ except ImportError has_functorch = False audio_text_models ppl_models vision_models utils GetterType InputsType TimingResultType to_markdown_table VType get_task_func task str - Callable hessian_fwdrev model inp strict=None functional hessian model inp strict=False vectorize=True outer_jacobian_strategy= forward-mode hessian_revrev model inp strict=None functional hessian model inp strict=False vectorize=True jacfwd model inp strict=None functional jacobian model inp strict=False vectorize=True strategy= forward-mode jacrev model inp strict=None functional jacobian model inp strict=False vectorize=True task == hessian_fwdrev hessian_fwdrev task == hessian_revrev hessian_revrev task == jacfwd jacfwd task == jacrev jacrev getattr functional task get_task_functorch task str - Callable torch no_grad vjp model inp v=None strict=None assert v None out vjpfunc = ft vjp model inp out vjpfunc v torch no_grad jvp model inp v=None strict=None assert v None ft jvp model inp v torch no_grad vhp model inp v=None strict=None assert v None argnums = tuple range len inp _ vjpfunc aux = ft vjp ft grad_and_value model argnums inp has_aux=True aux vjpfunc v torch no_grad hvp model inp v=None strict=None assert v None argnums = tuple range len inp _ hvp_out aux = ft jvp ft grad_and_value model argnums inp v has_aux=True aux hvp_out torch no_grad jacfwd model inp v=None strict=None argnums = tuple range len inp ft jacfwd model argnums inp torch no_grad jacrev model inp v=None strict=None argnums = tuple range len inp ft jacrev model argnums inp torch no_grad hessian model inp v=None strict=None argnums = tuple range len inp ft hessian model argnums=argnums inp torch no_grad hessian_fwdrev model inp v=None strict=None argnums = tuple range len inp ft jacfwd ft jacrev model argnums=argnums argnums=argnums inp torch no_grad hessian_revrev model inp v=None strict=None argnums = tuple range len inp ft jacrev ft jacrev model argnums=argnums argnums=argnums inp task locals locals task task == jacobian raise RuntimeError functorch has no equivalent autograd functional jacobian vectorize=False yet raise RuntimeError f Unsupported task task Listing different tasks FAST_TASKS_NO_DOUBLE_BACK = vjp FAST_TASKS = FAST_TASKS_NO_DOUBLE_BACK + vhp jvp ALL_TASKS_NON_VECTORIZED = FAST_TASKS + hvp jacobian hessian DOUBLE_BACKWARD_TASKS = jvp hvp vhp hessian VECTORIZED_TASKS = hessian_fwdrev hessian_revrev jacfwd jacrev ALL_TASKS = ALL_TASKS_NON_VECTORIZED + VECTORIZED_TASKS Model definition which contains - name string model name - getter function get model It takes input device which model will run It should forward function parameters Tensors used input forward function Note forward must have any side effect - tasks list recommended tasks can run reasonable amount time model - unsupported list tasks model cannot run ModelDef NamedTuple name str getter GetterType tasks list str unsupported list str MODELS = ModelDef resnet vision_models get_resnet FAST_TASKS ModelDef fcn_resnet vision_models get_fcn_resnet FAST_TASKS ModelDef detr vision_models get_detr FAST_TASKS ModelDef ppl_simple_reg ppl_models get_simple_regression ALL_TASKS ModelDef ppl_robust_reg ppl_models get_robust_regression ALL_TASKS ModelDef wav letter audio_text_models get_wav letter FAST_TASKS ModelDef deepspeech audio_text_models get_deepspeech FAST_TASKS_NO_DOUBLE_BACK DOUBLE_BACKWARD_TASKS ModelDef transformer audio_text_models get_transformer FAST_TASKS ModelDef multiheadattn audio_text_models get_multiheadattn FAST_TASKS get_v_for model Callable inp InputsType task str - VType v VType task vjp out = model inp v = torch rand_like out task jvp hvp vhp isinstance inp tuple v = tuple torch rand_like i i inp v = torch rand_like inp v = None v run_once model Callable inp InputsType task str v VType kwargs - None func = get_task_func task v None func model inp v=v strict=True func model inp strict=True run_once_functorch model Callable inp InputsType task str v VType maybe_check_consistency=False - None func = get_task_functorch task v None res = func model inp v=v strict=True res = func model inp strict=True maybe_check_consistency af_func = get_task_func task v None expected = af_func model inp v=v strict=True expected = af_func model inp strict=True atol = e- task == vhp e- torch testing assert_close res expected rtol= e- atol=atol msg=f Consistency fail task task run_model model_getter GetterType args Any task str run_once_fn Callable = run_once - list float args gpu == - device = torch device cpu noop pass do_sync = noop device = torch device f cuda args gpu do_sync = torch cuda synchronize model inp = model_getter device v = get_v_for model inp task Warmup maybe_check_consistency=True checks consistency between functorch vs autograd functional done run_once_functorch only run_once_fn model inp task v maybe_check_consistency=True elapsed = range args num_iters do_sync start = time time run_once_fn model inp task v do_sync elapsed append time time - start elapsed main parser = ArgumentParser Main script benchmark functional API autograd parser add_argument -- output type=str default= help= Text file where write output parser add_argument -- num-iters type=int default= parser add_argument -- gpu type=int default=- help= GPU use - CPU - auto-detect parser add_argument -- run-slow-tasks action= store_true help= Run even slow tasks parser add_argument -- model-filter type=str default= help= Only run models filter parser add_argument -- task-filter type=str default= help= Only run tasks filter parser add_argument -- num-threads type=int default= help= Number concurrent threads use when running cpu parser add_argument -- seed type=int default= help= The random seed use args = parser parse_args results TimingResultType = defaultdict defaultdict torch set_num_threads args num_threads torch set_num_interop_threads args num_threads This automatically seed cuda available torch manual_seed args seed args gpu == - args gpu = torch cuda is_available - name model_getter recommended_tasks unsupported_tasks MODELS args model_filter name args model_filter continue tasks = ALL_TASKS args run_slow_tasks recommended_tasks task tasks task unsupported_tasks continue args task_filter task args task_filter continue runtimes = run_model model_getter args task runtimes = torch tensor runtimes mean var = runtimes mean runtimes var results name task = mean item var item print f Results model name task task mean s var var has_functorch try runtimes = run_model model_getter args task run_once_fn=run_once_functorch except RuntimeError e print f Failed model using Functorch name task task Error message \n\t e continue runtimes = torch tensor runtimes mean var = runtimes mean runtimes var results name f functorch task = mean item var item print f Results model name task task using Functorch mean s var var args output open args output w f f write to_markdown_table results __name__ == __main__ main