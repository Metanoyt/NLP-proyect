mypy allow-untyped-defs mypy disable-error-code=arg-type __future__ annotations functools sys warnings typing TYPE_CHECKING torch torch _C _onnx _C_onnx torch _C torch onnx _constants errors torch onnx _internal torchscript_exporter _type_utils jit_utils registration symbolic_helper symbolic_opset opset torch onnx _internal torchscript_exporter _globals GLOBALS TYPE_CHECKING collections abc Sequence EDITING THIS FILE READ THIS FIRST see Note Edit Symbolic Files README md This file exports ONNX ops opset Opset supported ONNX release release __all__ = dequantize div embedding_bag fake_quantize_per_tensor_affine flip fmod isfinite isinf nan_to_num quantize_per_tensor quantized_add_relu quantized_add quantized_cat quantized_conv d_relu quantized_conv d_relu quantized_conv d_relu quantized_conv d quantized_conv d quantized_conv d quantized_conv_transpose d quantized_conv_transpose d quantized_conv_transpose d quantized_group_norm quantized_hardswish quantized_instance_norm quantized_layer_norm quantized_leaky_relu quantized_linear quantized_linear_relu quantized_mul quantized_sigmoid slice sort topk _onnx_symbolic = functools partial registration onnx_symbolic opset= _onnx_symbolic aten div div g jit_utils GraphContext other args len args == opset true_divide g other _div_rounding_mode g other args symbolic_helper parse_args v v s _div_rounding_mode g jit_utils GraphContext other rounding_mode rounding_mode == floor _floor_divide g other opset _div_rounding_mode g other rounding_mode _onnx_symbolic aten _floor_divide _floor_divide g jit_utils GraphContext other symbolic_helper _is_fp symbolic_helper _is_fp other out = opset true_divide g other g op Floor out Integer division does truncation rounding div = g op Div other Division negative = other zero = g op Constant value_t=torch tensor dtype=torch int negative = g op Xor g op Less zero g op Less other zero For negative numbers other = subtract round down instead up mod = g op Mod other fmod_i= fixup_mask = g op And negative g op Not g op Equal mod zero one = g op Constant value_t=torch tensor dtype=torch int fixup = g op Sub div one g op Where fixup_mask fixup div _onnx_symbolic aten sort symbolic_helper parse_args v i i none sort g jit_utils GraphContext dim descending out=None symbolic_helper _sort_helper g dim descending=descending out=out _onnx_symbolic aten topk symbolic_helper parse_args v v i i i none topk g jit_utils GraphContext k dim largest sorted out=None symbolic_helper _topk_helper g k dim largest=largest sorted=sorted out=out _aten_max_pool_onnx g jit_utils GraphContext _C Value kernel_shape Sequence int strides Sequence int pads Sequence int dilations Sequence int ceil_mode bool unbatched_rank int - _C Value self_rank = g op Size g op Shape self_rank == unbatched_rank C H W - N C H W N= = g op Unsqueeze g op Constant value_t=torch tensor dtype=torch int pool_result _ = g op MaxPool outputs= ceil_mode_i=ceil_mode dilations_i=dilations kernel_shape_i=kernel_shape pads_i=pads strides_i=strides self_rank == unbatched_rank pool_result = g op Squeeze pool_result g op Constant value_t=torch tensor dtype=torch int pool_result For MaxPool _adjust_attributes_of_max_pool expand_size int kernel_size Sequence int &#124; int stride Sequence int &#124; int padding Sequence int &#124; int dilation Sequence int &#124; int - tuple Sequence int Sequence int Sequence int Sequence int Adjust attributes avg_pool match ONNX specification isinstance dilation int dilation = dilation expand_size isinstance kernel_size int kernel_shape = kernel_size expand_size kernel_shape = kernel_size type ignore assignment isinstance padding int pads = padding expand_size type ignore operator assignment len padding == pads = padding expand_size type ignore operator assignment len padding == D padding pads = padding type ignore operator assignment len padding == D padding pads = padding type ignore operator assignment When padding already done all dimensions we don t need double eg pads = padding type ignore assignment isinstance stride int strides = stride expand_size stride strides = kernel_shape strides = stride type ignore assignment pyrefly ignore bad-return kernel_shape strides pads dilation _aten_max_pool_with_indices_onnx g jit_utils GraphContext _C Value kernel_shape Sequence int strides Sequence int pads Sequence int dilations Sequence int ceil_mode bool unbatched_rank int n_dims_one Sequence int n_dims_zero Sequence int n_dims_axes Sequence int - tuple _C Value Sequence int self_rank = g op Size g op Shape self_rank == unbatched_rank C H W - N C H W N= = g op Unsqueeze g op Constant value_t=torch tensor dtype=torch int pool_result indices = g op MaxPool outputs= ceil_mode_i=ceil_mode dilations_i=dilations kernel_shape_i=kernel_shape pads_i=pads strides_i=strides _ flatten_indices = g op MaxPool outputs= dilations_i=dilations kernel_shape_i=n_dims_one strides_i=n_dims_one ends = g op Constant value_t=torch tensor n_dims_one starts = g op Constant value_t=torch tensor n_dims_zero axes = g op Constant value_t=torch tensor n_dims_axes delta = g op Slice flatten_indices starts ends axes indices = g op Sub indices delta self_rank == unbatched_rank pool_result = g op Squeeze pool_result value_t=torch tensor dtype=torch int indices = g op Squeeze indices value_t=torch tensor dtype=torch int pool_result indices _onnx_symbolic aten max_pool d decorate= symbolic_helper _apply_params max_pool d return_indices=False _onnx_symbolic aten max_pool d decorate= symbolic_helper _apply_params max_pool d return_indices=False _onnx_symbolic aten max_pool d decorate= symbolic_helper _apply_params max_pool d return_indices=False _onnx_symbolic aten max_pool d_with_indices decorate= symbolic_helper _apply_params max_pool d_with_indices return_indices=True _onnx_symbolic aten max_pool d_with_indices decorate= symbolic_helper _apply_params max_pool d_with_indices return_indices=True _onnx_symbolic aten max_pool d_with_indices decorate= symbolic_helper _apply_params max_pool d_with_indices return_indices=True _max_pool name str expand_size int return_indices bool symbolic_helper quantized_args True False False False False False symbolic_helper parse_args v i symbolic_fn g jit_utils GraphContext input _C Value kernel_size Sequence int stride Sequence int padding int &#124; Sequence int dilation Sequence int ceil_mode bool kernel_shape strides pads dilations = _adjust_attributes_of_max_pool expand_size kernel_size stride padding dilation return_indices _aten_max_pool_with_indices_onnx g input kernel_shape strides pads dilations ceil_mode expand_size + expand_size expand_size + i i range expand_size _aten_max_pool_onnx g input kernel_shape strides pads dilations ceil_mode expand_size + symbolic_fn For AvgPool _adjust_attributes_of_avg_pool expand_size int kernel_size Sequence int &#124; int stride Sequence int &#124; int padding Sequence int &#124; int - tuple Sequence int Sequence int Sequence int Adjust attributes avg_pool match ONNX specification isinstance kernel_size int kernel_shape = kernel_size expand_size kernel_shape = kernel_size type ignore assignment isinstance padding int pads = padding expand_size len padding == pads = padding expand_size type ignore operator assignment len padding == pads = padding expand_size type ignore operator assignment pads = padding type ignore operator assignment isinstance stride int strides = stride expand_size stride strides = kernel_shape strides = stride type ignore assignment pyrefly ignore bad-return kernel_shape strides pads _onnx_symbolic aten avg_pool d decorate= symbolic_helper _apply_params avg_pool d _onnx_symbolic aten avg_pool d decorate= symbolic_helper _apply_params avg_pool d _onnx_symbolic aten avg_pool d decorate= symbolic_helper _apply_params avg_pool d _avg_pool name expand_size symbolic_helper quantized_args True False False False False False False symbolic_helper parse_args v i i none symbolic_fn g input _C Value kernel_size Sequence int stride Sequence int padding int &#124; Sequence int ceil_mode int count_include_pad int divisor_override=None kernel_shape strides pads = _adjust_attributes_of_avg_pool expand_size kernel_size stride padding result = g op AveragePool input ceil_mode_i=ceil_mode count_include_pad_i=count_include_pad kernel_shape_i=kernel_shape pads_i=pads strides_i=strides result symbolic_fn _onnx_symbolic aten upsample_nearest d decorate= symbolic_helper _apply_params upsample_nearest d nearest _onnx_symbolic aten upsample_nearest d decorate= symbolic_helper _apply_params upsample_nearest d nearest _onnx_symbolic aten upsample_nearest d decorate= symbolic_helper _apply_params upsample_nearest d nearest _onnx_symbolic aten upsample_linear d decorate= symbolic_helper _apply_params upsample_linear d linear _onnx_symbolic aten upsample_bilinear d decorate= symbolic_helper _apply_params upsample_bilinear d linear _onnx_symbolic aten upsample_trilinear d decorate= symbolic_helper _apply_params upsample_trilinear d linear _interpolate name dim interpolate_mode symbolic_helper quantized_args True False False symbolic_fn g input output_size args scales align_corners = symbolic_helper _get_interpolate_attributes g interpolate_mode args symbolic_helper _interpolate_warning interpolate_mode align_corners = symbolic_helper _maybe_get_scalar align_corners align_corners symbolic_helper _unimplemented name align_corners == True input scales None scales = symbolic_helper _interpolate_size_to_scales g input output_size dim g op Resize input scales mode_s=interpolate_mode symbolic_fn _onnx_symbolic aten __interpolate __interpolate g jit_utils GraphContext input size scale_factor mode align_corners recompute_scale_factor antialias scales mode = symbolic_helper _interpolate_get_scales_and_mode g input size scale_factor mode align_corners g op Resize input scales mode_s=mode _slice g jit_utils GraphContext input torch _C Value axes list &#124; torch Tensor &#124; torch _C Value starts list &#124; torch Tensor &#124; torch _C Value ends list &#124; torch Tensor &#124; torch _C Value steps list &#124; torch Tensor &#124; torch _C Value &#124; None = None is_none_value value value None True isinstance value torch _C Value value node kind == prim Constant isinstance value type _C NoneType to_slice_input list_or_value default_value=None Convert input param into D torch Value is_none_value list_or_value default_value None list_or_value = default_value isinstance list_or_value torch Tensor g op Constant value_t=list_or_value clone detach isinstance list_or_value list g op Constant value_t=torch tensor list_or_value rank = symbolic_helper _get_tensor_rank list_or_value rank == symbolic_helper _unsqueeze_helper g list_or_value rank == list_or_value raise errors SymbolicValueError f Rank must rank list_or_value get_const_value list_or_value isinstance list_or_value list torch Tensor len list_or_value == list_or_value None symbolic_helper _maybe_get_const list_or_value i Check slice no-op get_const_value starts == get_const_value ends == _constants INT _MAX steps None get_const_value steps == input axes = to_slice_input axes starts = to_slice_input starts default_value= ends = to_slice_input ends default_value=_constants INT _MAX steps None g op Slice input starts ends axes steps = to_slice_input steps default_value= g op Slice input starts ends axes steps _onnx_symbolic aten slice slice g jit_utils GraphContext args len args == aten slice Tensor int dim int start=None int end=None int step= - Tensor dims start end step = args len args == aten slice t l int start=None int end=None int step= - t start end step = args dims = raise errors SymbolicValueError Unknown aten slice signature symbolic_helper _slice_helper g axes=dims starts=start ends=end steps=step _onnx_symbolic aten flip symbolic_helper parse_args v flip g jit_utils GraphContext input dims symbolic_helper _slice_helper g input axes=dims starts= - len dims ends= -_constants INT _MAX len dims steps= - len dims _onnx_symbolic aten fmod fmod g jit_utils GraphContext input other g op Mod input other fmod_i= _onnx_symbolic aten embedding_bag symbolic_helper parse_args v v v i i i v i i embedding_bag g jit_utils GraphContext embedding_matrix indices offsets scale_grad_by_freq mode sparse per_sample_weights include_last_offset padding_idx scale_grad_by_freq GLOBALS export_training symbolic_helper _onnx_unsupported embedding_bag scale_grad_by_freq training mode padding_idx None padding_idx = raise RuntimeError embedding_bag padding_idx warnings warn Export embedding_bag dynamic input offsets shape supported opset Please use opset higher export model dynamic input shape stacklevel= offsets_dim_ = symbolic_helper _get_tensor_dim_size offsets offsets_dim_ None include_last_offset offset_len = offsets_dim_ - offsets_extended = offsets offset_len = offsets_dim_ offsets_extended = offsets g op Constant value_t=torch tensor sys maxsize offsets_extended = g op Concat offsets_extended axis_i= list_ = i range offset_len start_ = symbolic_helper _unsqueeze_helper g opset select g offsets_extended torch tensor torch tensor i end_ = symbolic_helper _unsqueeze_helper g opset select g offsets_extended torch tensor torch tensor i + axes_ = g op Constant value_t=torch tensor indices_row = g op Slice indices start_ end_ axes_ embeddings = g op Gather embedding_matrix indices_row symbolic_helper _is_none per_sample_weights per_sample_weights_row = g op Slice per_sample_weights start_ end_ axes_ per_sample_weights_row = symbolic_helper _unsqueeze_helper g per_sample_weights_row embeddings = g op Mul embeddings per_sample_weights_row mode == embeddings = symbolic_helper _reducesum_helper g embeddings axes_i= keepdims_i= mode == embeddings = g op ReduceMean embeddings axes_i= keepdims_i= embeddings = g op ReduceMax embeddings axes_i= keepdims_i= embeddings = symbolic_helper _unsqueeze_helper g embeddings list_ append embeddings output = g op Concat list_ axis_i= aten embedding_bag returns tuple elements output offset bag bag_size max_indices But last three outputs used torch nn EmbeddingBag torch nn functional embedding_bag output None None None symbolic_helper _onnx_unsupported embedding_bag unknown shape offsets opset supported please use opset higher _onnx_symbolic aten fake_quantize_per_tensor_affine symbolic_helper parse_args v v v i i fake_quantize_per_tensor_affine g jit_utils GraphContext inputs scale zero_point quant_min=- quant_max= NOTE special case PyTorch restricts activations range https github com pytorch pytorch blob b b d b c f e c c ede bd torch ao quantization observer py#L quant_min quant_max == symbolic_helper _onnx_opset_unsupported_detailed fake_quantize_per_tensor_affine Quantize range supported requires opset Clip inputs quant_min quant_max - raise errors SymbolicValueError f For quant_min quant_max ONNX allows only - f Got quant_min quant_max inputs scale = symbolic_helper _maybe_get_scalar scale scale None symbolic_helper _onnx_opset_unsupported_detailed fake_quantize_per_tensor_affine Non-constant scale supported inputs pyrefly ignore missing-attribute scale = scale float data Avoid exporter generating double type quant_min == zero_point = g op Cast zero_point to_i=_C_onnx TensorProtoDataType UINT zero_point = g op Cast zero_point to_i=_C_onnx TensorProtoDataType INT g op DequantizeLinear g op QuantizeLinear inputs scale zero_point scale zero_point _onnx_symbolic aten isinf isinf g jit_utils GraphContext input g op IsInf g op Cast input to_i=_C_onnx TensorProtoDataType DOUBLE _onnx_symbolic aten isfinite isfinite g jit_utils GraphContext input inf_node = isinf g input nan_node = opset isnan g input opset __not_ g opset __or_ g inf_node nan_node _onnx_symbolic aten quantize_per_tensor quantize_per_tensor g jit_utils GraphContext input scale zero_point dtype dtype = symbolic_helper _get_const dtype i dtype TODO justinchuby Extract all cast ops into helper function zero_point = g op Cast zero_point to_i=_type_utils JitScalarType dtype onnx_type scale = g op Cast scale to_i=_C_onnx TensorProtoDataType FLOAT symbolic_helper quantize_helper g input scale zero_point _onnx_symbolic aten dequantize dequantize g jit_utils GraphContext input symbolic_helper dequantize_helper g input _onnx_symbolic aten nan_to_num symbolic_helper parse_args v f f f nan_to_num g jit_utils GraphContext input nan posinf neginf Cannot create int type tensor inf nan values so we simply original tensor symbolic_helper _is_fp input input input_dtype = _type_utils JitScalarType from_value input dtype nan None nan = nan_cond = opset isnan g input nan_result = g op Where nan_cond g op Constant value_t=torch tensor nan dtype=input_dtype input For None values posinf neginf we use greatest lowest finite value representable input s dtype finfo = torch finfo input_dtype posinf None posinf = finfo max posinf_cond = opset logical_and g isinf g nan_result opset gt g nan_result g op Constant value_t=torch LongTensor nan_posinf_result = g op Where posinf_cond g op Constant value_t=torch tensor posinf dtype=input_dtype nan_result neginf None neginf = finfo min neginf_cond = opset logical_and g isinf g nan_posinf_result opset lt g nan_posinf_result g op Constant value_t=torch LongTensor g op Where neginf_cond g op Constant value_t=torch tensor neginf dtype=input_dtype nan_posinf_result Quantized symbolics --------------------------------------------------------- https github com pytorch pytorch wiki PyTorch-ONNX-exporter#quantized-model-export Support starts opset because ` DequantizeLinear ` ` QuantizeLinear ` introduced opset version _onnx_symbolic quantized linear quantized_linear g jit_utils GraphContext q_input q_weight bias op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset linear g input weight bias symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized linear_relu quantized_linear_relu g jit_utils GraphContext q_input q_weight bias op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset linear g input weight bias output = opset relu g output symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized add quantized_add g jit_utils GraphContext x y op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x y _ _ _ = symbolic_helper dequantize_helper g y output = opset add g x y symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized add_relu quantized_add_relu g jit_utils GraphContext x y op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x y _ _ _ = symbolic_helper dequantize_helper g y output = opset add g x y output = opset relu g output symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized mul quantized_mul g jit_utils GraphContext x y op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x y _ _ _ = symbolic_helper dequantize_helper g y output = opset mul g x y symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized hardswish quantized_hardswish g jit_utils GraphContext x op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = opset hardswish g x symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized sigmoid quantized_sigmoid g jit_utils GraphContext x op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = opset sigmoid g x symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized leaky_relu quantized_leaky_relu g jit_utils GraphContext x negative_slope inplace op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = opset leaky_relu g x negative_slope inplace symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized layer_norm quantized_layer_norm g jit_utils GraphContext x normalized_shape weight bias eps op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = opset layer_norm g x normalized_shape weight bias eps False symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized group_norm quantized_group_norm g jit_utils GraphContext x num_groups weight bias eps op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = opset group_norm g x num_groups weight bias eps False symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized instance_norm symbolic_helper parse_args v v v f v v quantized_instance_norm g jit_utils GraphContext q_input weight bias eps op_scale op_zero_point input _ _ _ = symbolic_helper dequantize_helper g q_input output = opset instance_norm g input weight bias None None False eps False symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d_relu quantized_conv d_relu g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups output = opset relu g output symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d_relu quantized_conv d_relu g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups output = opset relu g output symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d_relu quantized_conv d_relu g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups output = opset relu g output symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d quantized_conv d g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d quantized_conv d g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv d quantized_conv d g jit_utils GraphContext q_input q_weight bias stride padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv d g input weight bias stride padding dilation groups symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv_transpose d quantized_conv_transpose d g jit_utils GraphContext q_input q_weight bias stride padding output_padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv_transpose d g input weight bias stride padding output_padding groups dilation symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv_transpose d quantized_conv_transpose d g jit_utils GraphContext q_input q_weight bias stride padding output_padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv_transpose d g input weight bias stride padding output_padding groups dilation symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized conv_transpose d quantized_conv_transpose d g jit_utils GraphContext q_input q_weight bias stride padding output_padding dilation groups op_scale op_zero_point input input_scale _ _ = symbolic_helper dequantize_helper g q_input weight weight_scale _ _ = symbolic_helper dequantize_helper g q_weight q_bias = symbolic_helper requantize_bias_helper g bias input_scale weight_scale bias _ _ _ = symbolic_helper dequantize_helper g q_bias output = opset conv_transpose d g input weight bias stride padding output_padding groups dilation symbolic_helper quantize_helper g output op_scale op_zero_point _onnx_symbolic quantized cat symbolic_helper parse_args v i v v quantized_cat g jit_utils GraphContext q_inputs _C Value dim int op_scale _C Value op_zero_point _C Value - _C Value unpacked_inputs = symbolic_helper _unpack_list q_inputs dequantized = symbolic_helper dequantize_helper g input input unpacked_inputs concatenated = g op Concat dequantized axis_i=dim symbolic_helper quantize_helper g concatenated op_scale op_zero_point