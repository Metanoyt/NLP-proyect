mypy allow-untyped-defs itertools logging operator os collections defaultdict collections abc Sequence typing Any Callable typing_extensions TypeAlias torch torch _dynamo utils counters torch fx experimental symbolic_shapes free_symbols guard_or_false torch utils _ordered_set OrderedSet pattern_matcher Arg CallFunction CallFunctionVarArgs CallMethodVarArgs FailedMatch get_arg_value Ignored KeywordArg ListOf Match MatchContext MULTIPLE PatternExpr PatternMatcherPass register_graph_pattern RepeatedExpr group_batch_fusion is_node_meta_valid POST_GRAD_FUSIONS PRE_GRAD_FUSIONS log = logging getLogger __name__ _Arguments TypeAlias = tuple torch fx node Argument _TransformParam TypeAlias = tuple _Arguments &#124; None _Arguments &#124; None _Arguments &#124; None _Arguments &#124; None _Range TypeAlias = tuple int int PRE_GRAD_PATTERNS dict str PatternMatcherPass = POST_GRAD_PATTERNS dict str PatternMatcherPass = pre_grad_pass_names = normalization_pass remove_split_with_size_one_pass merge_getitem_cat_pass merge_stack_tahn_unbind_pass merge_splits_pass mutate_cat_pass split_cat_pass unbind_stack_pass split_cat_to_slices_pass unbind_cat_to_view_pass split_stack_to_cats_pass unbind_stack_to_slices_pass move_reshape_out_of_split_stack_pass einsum_to_pointwise_pass post_grad_pass_names = normalization_aten_pass decompose_mm_pass unbind_stack_aten_pass shape_padding_multiplier pad_aten_mm_pass split_cat_aten_pass select_cat_aten_pass move_view_after_cat_aten_pass backend = os environ get TORCHINDUCTOR_PATTERN_MATCH_BACKEND inductor pass_name pre_grad_pass_names exclude all passes group batch fusion they do use pattern matcher pass_name PRE_GRAD_FUSIONS continue PRE_GRAD_PATTERNS pass_name = PatternMatcherPass pass_name=pass_name pass_name post_grad_pass_names exclude all passes group batch fusion they do use pattern matcher pass_name POST_GRAD_FUSIONS continue POST_GRAD_PATTERNS pass_name = PatternMatcherPass pass_name=pass_name construct_pattern_matcher_pass pass_name str Return specific pattern_matcher_pass given pass name pass_name PRE_GRAD_PATTERNS PRE_GRAD_PATTERNS pass_name POST_GRAD_PATTERNS pass_name _get_split_args_default split_node input_kwarg = tensor split_size_kwarg = split_size_or_sections dim_kwarg = dim default_dim_value = split_node op == call_method split_size_kwarg = split_size get_arg_value split_node input_kwarg get_arg_value split_node split_size_kwarg get_arg_value split_node dim_kwarg default_dim_value _get_dim node Any assert isinstance node torch fx Node dim node kwargs assert isinstance node kwargs dim int node kwargs dim node target torch unbind len node args == assert isinstance node args - int node args - defaults dim= node target torch split len node args == assert isinstance node args - int node args - defaults dim= raise AssertionError f Can t extract ` dim ` node target node args node kwargs noqa W ############The pattern optimized is######### unbind dim= \ getitem getitem - user= &#124; &#124; split split - dim= user= split_section_size= &#124; &#124; getitem getitem - user= \ cat dim= - user= &#124; ################After transformation############# unbind dim= \ getitem getitem - user= \ cat dim= - user= &#124; normalize_split_base match Match _get_split_args Callable torch fx Node tuple torch fx Node &#124; None Any &#124; None int &#124; None Normalize split split_size into split_with_sizes so we only deal one type split subsequent optimizations split_node = match nodes graph = match graph split_input split_size split_dim = _get_split_args split_node split_input None split_dim None split_size None log debug couldn t find split args is_node_meta_valid split_node log debug example value absent node s split_node assert isinstance split_node meta example_value list tuple split_sections = t size split_dim t split_node meta example_value any isinstance section torch SymInt section split_sections TODO dynamic_shapes assume_static_by_default=False fails while AOT Autograd tracing split_dim Normalize split dim split_dim += split_input meta example_value dim new_args = split_input split_sections new_kwargs = dim split_dim split_node args == new_args split_node kwargs == new_kwargs split_node op == call_function graph inserting_after split_node new_split_node = graph call_function torch split args=new_args kwargs=new_kwargs type ignore arg-type split_node replace_all_uses_with new_split_node new_split_node meta update split_node meta graph erase_node split_node counters backend normalization_pass += register_graph_pattern CallFunctionVarArgs torch split users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass register_graph_pattern CallMethodVarArgs split users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_split_default match Match args kwargs normalize_split_base match _get_split_args_default register_graph_pattern CallFunctionVarArgs torch split users=MULTIPLE pass_dict=construct_pattern_matcher_pass remove_split_with_size_one_pass register_graph_pattern CallMethodVarArgs split users=MULTIPLE pass_dict=construct_pattern_matcher_pass remove_split_with_size_one_pass remove_split_with_size_one match Match args kwargs graph = match graph split_node = match nodes split_input split_size split_dim = _get_split_args_default split_node split_input None split_dim None split_size None log debug couldn t find split args is_node_meta_valid split_node log debug example value absent node s split_node assert isinstance split_node meta example_value list tuple split_sections = t size split_dim t split_node meta example_value any isinstance section torch SymInt section split_sections TODO dynamic_shapes assume_static_by_default=False fails while AOT Autograd tracing remove dummy split whose split sections size one theoretically nodes no users should removed we have seen corner case thus we add its users check walk around StopIteration error len split_sections == len split_node users keys find grand children split_node next_users = find_next_users split_node user = next iter split_node users keys replace users grand child node input node next_user next_users next_user replace_input_with user split_input erase split node its child graph erase_node user graph erase_node split_node counters backend remove_split_with_size_one_pass += register_graph_pattern CallFunctionVarArgs torch unbind users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass register_graph_pattern CallMethodVarArgs unbind users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_unbind_default match Match args kwargs node = match nodes graph = match graph input = get_arg_value node input dim = get_arg_value node dim dim None axis = node kwargs get axis axis None dim = axis dim = input None log debug couldn t find unbind args is_node_meta_valid input log debug example value absent node s input ndim = input meta example_value ndim pyrefly ignore unsupported-operation dim Normalize unbind dim dim += ndim graph inserting_after node new_node = graph call_function torch unbind args= input kwargs= dim dim node replace_all_uses_with new_node new_node meta update node meta graph erase_node node counters backend normalization_pass += register_graph_pattern CallFunctionVarArgs torch cat torch concat users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_cat_default match Match args kwargs cat_node = match nodes graph = match graph tensors = get_arg_value cat_node tensors cat_dim = get_arg_value cat_node dim cat_dim None cat_axis = cat_node kwargs get axis cat_axis None cat_dim = cat_axis cat_dim = tensors None cat_dim None log debug couldn t find cat args assert isinstance tensors list tuple tensor itertools chain cat_node tensors is_node_meta_valid tensor log debug example value absent node s tensor ndim = cat_node meta example_value dim is_empty_tensor x special case where torch cat supports cat ing empty tensor x_shape = x meta example_value shape len x_shape == guard_or_false x_shape == assert all ndim == x meta example_value dim is_empty_tensor x x tensors pyrefly ignore unsupported-operation cat_dim Normalize cat dim cat_dim += ndim new_args = tensors new_kwargs = dim cat_dim cat_node args == new_args cat_node kwargs == new_kwargs cat_node op == call_function cat_node target torch cat graph inserting_after cat_node new_cat_node = graph call_function torch cat args=new_args kwargs=new_kwargs cat_node replace_all_uses_with new_cat_node new_cat_node meta update cat_node meta graph erase_node cat_node counters backend normalization_pass += register_graph_pattern CallFunctionVarArgs torch stack users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_stack_default match Match args kwargs node = match nodes graph = match graph tensors = get_arg_value node tensors dim = get_arg_value node dim tensors None dim None log debug couldn t find stack args assert isinstance tensors list tuple A bug pytorch some nodes miss example_value metadata tensor itertools chain node tensors is_node_meta_valid tensor log debug example value absent node s tensor ndim = node meta example_value dim dim Normalize dim dim += ndim graph inserting_after node new_node = graph call_function node target type ignore arg-type args= tensors kwargs= dim dim node replace_all_uses_with new_node new_node meta update node meta graph erase_node node counters backend normalization_pass += find_next_users split_node torch fx Node - list torch fx Node next_users = getitem_node split_node users keys getitem_user getitem_node users keys getitem_user next_users next_users append getitem_user next_users register_graph_pattern CallMethodVarArgs squeeze users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_squeeze_default match Match args kwargs squeeze_node = match nodes squeeze_input = get_arg_value squeeze_node dim squeeze_node kwargs assert len squeeze_node args == dim = squeeze_node kwargs dim len squeeze_node args == squeeze Tensor dim = None len squeeze_node args == squeeze Tensor int dim squeeze Tensor int dim dim = squeeze_node args squeeze Tensor int dim called varargs dim = squeeze_node args isinstance dim Sequence len dim == dim = dim match graph inserting_after squeeze_node dim None new_squeeze_node = match graph call_function torch squeeze args= squeeze_input new_squeeze_node = match graph call_function torch squeeze args= squeeze_input kwargs= dim dim squeeze_node replace_all_uses_with new_squeeze_node new_squeeze_node meta update squeeze_node meta match graph erase_node squeeze_node register_graph_pattern CallMethodVarArgs reshape users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_reshape_default match Match args kwargs reshape_node = match nodes is_node_meta_valid reshape_node log debug example value absent node s reshape_node reshape_input = get_arg_value reshape_node free_symbols reshape_node meta example_value shape log debug dynamic shape supported s reshape_node match graph inserting_after reshape_node new_reshape_node = match graph call_function torch reshape args= reshape_input tuple reshape_node meta example_value shape reshape_node replace_all_uses_with new_reshape_node new_reshape_node meta update reshape_node meta match graph erase_node reshape_node register_graph_pattern CallMethodVarArgs clamp users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass register_graph_pattern CallFunctionVarArgs torch clamp users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_clamp_default match Match args kwargs clamp_node = match nodes is_node_meta_valid clamp_node log debug example value absent node s clamp_node free_symbols clamp_node meta example_value shape log debug dynamic shape supported s clamp_node len clamp_node args args = get_arg_value clamp_node kwargs = min get_arg_value clamp_node kwarg_name= min max get_arg_value clamp_node kwarg_name= max args = clamp_node args kwargs = clamp_node kwargs match graph inserting_after clamp_node new_clamp_node = match graph call_function torch clamp args=args kwargs=kwargs clamp_node replace_all_uses_with new_clamp_node new_clamp_node meta update clamp_node meta match graph erase_node clamp_node register_graph_pattern CallMethodVarArgs detach users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_pass normalize_detach_default match Match args kwargs detach_node = match nodes is_node_meta_valid detach_node log debug example value absent node s detach_node free_symbols detach_node meta example_value shape log debug dynamic shape supported s detach_node match graph inserting_after detach_node new_detach_node = match graph call_function torch detach args=detach_node args detach_node replace_all_uses_with new_detach_node new_detach_node meta update detach_node meta match graph erase_node detach_node TorchSplit CallFunction Matches call torch split normalized form Ensures all users splits unique getitems __init__ arg sizes func=torch split - None using KeywordArg dim ` dim ` checks they all match super __init__ func arg sizes _users=MULTIPLE dim=KeywordArg dim _match node torch fx Node ctx MatchContext m = super _match node ctx m m split_sections = node args isinstance split_sections list tuple FailedMatch split normalized check users all unique getitems seen_idxs = OrderedSet int user node users CallFunction operator getitem Arg Arg match user This should ideally never happen Split user should always getitem FailedMatch f user split getitem user isinstance user args int FailedMatch only integer getitems handled user args seen_idxs FailedMatch f duplicate getitem user args user args - type ignore operator This shouldn t ideally happen dynamo normalizes indexes positive FailedMatch negative index seen_idxs add user args m register_graph_pattern TorchSplit CallFunction operator getitem TorchSplit KeywordArg first_split_input KeywordArg first_split_sections Ignored KeywordArg next_split_sections pass_dict=construct_pattern_matcher_pass merge_splits_pass merge_splits match Match first_split_input torch fx Node first_split_sections list int next_split_sections list int Note dim implicitly passed TorchSplit internally uses pattern dim dim int node = match output_node possible split has no users we check corner case skip pattern len node users keys == graph = match graph first_split = node args args type ignore union-attr next_split_index = node args args type ignore union-attr new_split_sections = list first_split_sections new_split_sections next_split_index next_split_index + = next_split_sections type ignore operator misc first_split_dim = _get_dim first_split to_remove = graph inserting_before first_split type ignore arg-type Add new split node new_split = graph call_function torch split args= first_split_input new_split_sections kwargs= dim first_split_dim is_node_meta_valid first_split_input new_split meta example_value = torch split first_split_input meta example_value new_split_sections dim=first_split_dim first_split_num_to_user = user args user user first_split users keys type ignore union-attr new_split_num = split_num range len first_split_sections split_num first_split_num_to_user new_split_num += continue old_getitem = first_split_num_to_user split_num split_num = next_split_index old_getitem update_arg new_split old_getitem update_arg new_split_num new_split_num += next_split_num_to_user = user args user user node users keys It necessary all getitems split node used next_split_num range len next_split_sections graph inserting_after new_split new_getitem = graph call_function operator getitem args= new_split new_split_num new_split_num += next_split_num next_split_num_to_user continue next_getitem = next_split_num_to_user next_split_num new_getitem meta update next_getitem meta next_getitem replace_all_uses_with new_getitem to_remove append next_getitem to_remove append node to_remove append old_getitem to_remove append first_split type ignore arg-type node to_remove graph erase_node node counters backend merge_splits_pass += SplitCatSimplifier Helper simplify split-cat pattern In simple cases both split cat node can removed split- cat pattern However there various cases where they can t we need simplify split add transforms before cat Some such cases Final node has additional args coming initial split Shuffling args between split cat Some final nodes non- cat stack Split-dim = cat-dim equal split Note any combination above cases can happen To deal - we iterate over all users split And figure out common ranges can merged Then we simplify split accordingly In best case split can entirely removed To deal we add some transformations unflatten + movedim See ` get_transform_params ` Finally depending final node being cat stack unsqueeze flatten needs added simplify graph torch fx Graph split_node torch fx Node split_sections list int Find next users i e users after getitem next_users = find_next_users split_node Gather inputs next users When inputs come ` split_node ` they instead represented tuple indicating split ranges See ` get_user_input_list ` more details user_inputs_list = get_user_input_list split_node next_users Simplify split_sections based user_inputs_list In simpler cases len simplified_split_ranges == we can simply replace split node Otherwise we simplify simplified_split_ranges = get_simplified_split_ranges split_sections next_users user_inputs_list simplified_split_ranges Simplification possible transform_params_list = get_transform_params split_node next_users user_inputs_list transform_params_list Start actual replacement user_inputs_list_new = replace_split graph split_node split_sections user_inputs_list simplified_split_ranges replace_cat graph split_node next_users user_inputs_list_new transform_params_list type ignore arg-type erase_old_nodes graph split_node next_users type ignore arg-type counters backend unbind_stack_pass += get_user_input_list split_node torch fx Node next_users list torch fx Node - list list torch fx Node &#124; _Range Returns list inputs following user nodes order The outer list represents user node The inner list represents inputs particular node This list can either contain - tuple representing ranges get_items should go into cat closed interval - torch fx Node representing other inputs which coming our split user_inputs_list list list torch fx Node &#124; _Range = user next_users user target torch cat torch stack user_inputs_list append get_merged_user_inputs split_node user user_inputs_list append get_non_cat_node_input split_node user type ignore arg-type user_inputs_list get_merged_user_inputs split_node torch fx Node cat_node torch fx Node - list torch fx Node &#124; _Range user_inputs = get_arg_value cat_node tensors simplified_user_inputs = split_users = OrderedSet split_node users keys user_input user_inputs user_input split_users simplified_user_inputs append user_input Add which getitem cat depends simplified_user_inputs append user_input args merge_consecutive_inputs simplified_user_inputs get_non_cat_node_input split_node torch fx Node node torch fx Node - list _Range Get input non cat node same format ` get_merged_user_inputs ` node_input = split_users = OrderedSet split_node users keys node_arg node all_input_nodes node_arg split_users getitem_num = get_arg_value node_arg node_input append getitem_num getitem_num node_input merge_consecutive_inputs inputs list torch fx Node &#124; int - list torch fx Node &#124; _Range Merge consecutive inputs going into user node For e g arg arg - arg arg merged_ranges = cur_range = None input_ inputs isinstance input_ int cur_range cur_range = input_ input_ input_ == cur_range + cur_range += merged_ranges append tuple cur_range cur_range = input_ input_ cur_range merged_ranges append tuple cur_range cur_range = None merged_ranges append input_ type ignore arg-type cur_range merged_ranges append tuple cur_range merged_ranges type ignore return-value get_simplified_split_ranges split_sections next_users user_inputs_list list list torch fx Node &#124; _Range - list _Range &#124; None ranges = OrderedSet Any user_inputs user_inputs_list ranges update u u user_inputs isinstance u tuple cumulative_sizes = + torch cumsum torch tensor split_sections tolist split_ranges = sorted cumulative_sizes r cumulative_sizes r + r ranges has_non_overlapping_ranges split_ranges This need strict condition However we keep now simplicity None split_ranges = fill_gaps split_ranges cumulative_sizes - len split_sections == len split_ranges Simplification possible None counters backend scmerge_split_sections_removed = len split_sections - len split_ranges split_ranges has_non_overlapping_ranges ranges list _Range - bool range_ next_range itertools pairwise ranges range_ next_range False True fill_gaps ranges list _Range min_ int max_ int - list _Range cur = min_ filled_ranges = b ranges cur filled_ranges append cur filled_ranges append b cur = b filled_ranges - max_ filled_ranges append filled_ranges - max_ filled_ranges get_transform_params split_node torch fx Node next_users list torch fx Node user_inputs_list list list torch fx Node &#124; _Range - list list _TransformParam &#124; None Figure out what transforms needed each input each cat node We replace split node unflatten followed movedim split_dim = _get_dim split_node split_sections = split_node args transform_params_list list list _TransformParam = user_node user_inputs zip next_users user_inputs_list user_node target torch cat torch stack transform_params_list append continue cat_dim = get_arg_value user_node dim transform_params list _TransformParam = user_input user_inputs split_dim == cat_dim user_node target torch cat No transform needed transform_params append None None None None isinstance user_input tuple Split being simplified Verify equal split subset_split_sections = split_sections type ignore index user_input user_input + type ignore index All sections should equal len OrderedSet subset_split_sections = type ignore arg-type None num_splits = len subset_split_sections type ignore arg-type unflatten_params = split_dim num_splits - movedim_params = split_dim cat_dim split_dim = cat_dim None transform_params append unflatten_params movedim_params None None user_node target torch stack split_dim = cat_dim We need unsqueeze inputs coming through split transform_params append None None cat_dim None Non-split inputs transform_params append None None None None transform_params_list append transform_params transform_params_list replace_split graph torch fx Graph split_node torch fx Node split_sections list int user_inputs_list list list torch fx Node &#124; _Range split_ranges list _Range - list list torch fx Node Replace split node It can either remove split node len split_ranges == simplify into split lesser sections len split_ranges Returns new ` user_inputs_list ` tuples replaced new getitems newer split node split_input = split_node args split_dim = _get_dim split_node len split_ranges == We can completely eliminate split node split_items = split_input graph inserting_after split_node new_split = graph call_function torch split args= split_input r - r r split_ranges kwargs= dim split_dim is_node_meta_valid split_input type ignore arg-type union-attr new_split meta example_value = torch split split_input meta example_value type ignore union-attr r - r r split_ranges dim=split_dim counters backend scmerge_split_added += split_items = graph inserting_after new_split i range len split_ranges getitem = graph call_function operator getitem args= new_split i is_node_meta_valid new_split getitem meta example_value = new_split meta example_value i split_items append getitem Now assign right getitem right input cumulative_sizes = + torch cumsum torch tensor split_sections tolist new_user_inputs_list = user_inputs user_inputs_list new_user_inputs = user_input user_inputs isinstance user_input tuple Find correct new getitem present split_items new_user_inputs append pyrefly ignore bad-argument-type split_items split_ranges index cumulative_sizes user_input cumulative_sizes user_input + new_user_inputs append user_input new_user_inputs_list append new_user_inputs new_user_inputs_list type ignore return-value replace_cat graph torch fx Graph split_node torch fx Node next_users list torch fx Node user_inputs_list_new transform_params_list list list _TransformParam split_dim = _get_dim split_node split_users = split_node users keys new_cats = user_node user_inputs_new transform_params zip next_users user_inputs_list_new transform_params_list user_node target torch cat torch stack Change args kwargs non-cat stack nodes Replace old getitems belonging original split node newer getitems next_cat_input = input_node user_node all_input_nodes input_node split_users user_node replace_input_with input_node user_inputs_new next_cat_input next_cat_input += continue Handle cat stack user nodes cat_dim = get_arg_value user_node dim user_inputs_new_transformed user_inputs_new_transformed_meta = For ` unsqueeze ` transform we will combine consecutive inputs same unsqueeze params stack them to_stack to_stack_meta = stack_dim = None graph inserting_before user_node user_input_new transform_param zip user_inputs_new transform_params pyrefly ignore bad-argument-type is_node_meta_valid user_input_new log debug example value absent node s user_input_new Apply transforms unflatten_params movedim_params unsqueeze_params flatten_params = transform_param unsqueeze_params stack_dim None stack_dim == unsqueeze_params to_stack append user_input_new pyrefly ignore missing-attribute to_stack_meta append user_input_new meta example_value stack_dim = unsqueeze_params continue to_stack stacked_input = graph call_function torch stack args= to_stack kwargs= dim stack_dim stacked_input meta example_value = torch stack type ignore arg-type to_stack_meta dim=stack_dim type ignore arg-type to_stack to_stack_meta = stack_dim = None user_inputs_new_transformed append stacked_input user_inputs_new_transformed_meta append stacked_input meta example_value unsqueeze_params to_stack append user_input_new stack_dim = unsqueeze_params pyrefly ignore missing-attribute to_stack_meta append user_input_new meta example_value continue unflatten_params pyrefly ignore missing-attribute user_input_new_meta = user_input_new meta example_value user_input_new = graph call_function torch unflatten args= user_input_new unflatten_params user_input_new meta example_value = torch unflatten type ignore arg-type user_input_new_meta type ignore arg-type unflatten_params type ignore arg-type movedim_params pyrefly ignore missing-attribute user_input_new_meta = user_input_new meta example_value user_input_new = graph call_function torch movedim args= user_input_new movedim_params user_input_new meta example_value = torch movedim type ignore arg-type user_input_new_meta type ignore arg-type movedim_params type ignore arg-type flatten_params pyrefly ignore missing-attribute user_input_new_meta = user_input_new meta example_value user_input_new = graph call_function torch flatten args= user_input_new flatten_params user_input_new meta example_value = torch flatten type ignore arg-type user_input_new_meta flatten_params type ignore arg-type user_inputs_new_transformed append user_input_new user_inputs_new_transformed_meta append pyrefly ignore missing-attribute user_input_new meta example_value to_stack stacked_input = graph call_function torch stack args= to_stack kwargs= dim stack_dim stacked_input meta example_value = torch stack type ignore arg-type to_stack_meta dim=stack_dim type ignore arg-type user_inputs_new_transformed append stacked_input user_inputs_new_transformed_meta append stacked_input meta example_value graph inserting_after user_node len user_inputs_new_transformed new_cat_node = graph call_function torch cat args= user_inputs_new_transformed kwargs= dim cat_dim new_cat_node meta example_value = torch cat user_inputs_new_transformed_meta dim=cat_dim counters backend scmerge_cat_added += new_cat_node = user_inputs_new_transformed - new_cat_node meta example_value = user_inputs_new_transformed_meta - user_node target torch cat split_dim = cat_dim split_node target torch split graph inserting_after new_cat_node new_cat_node_meta = new_cat_node meta example_value new_cat_node = graph call_function torch flatten args= new_cat_node cat_dim cat_dim + new_cat_node meta example_value = torch flatten new_cat_node_meta cat_dim cat_dim + user_node replace_all_uses_with new_cat_node new_cats append new_cat_node erase_old_nodes graph torch fx Graph split_node torch fx Node next_users list torch fx Node to_remove = split_node counters backend scmerge_split_removed += to_remove extend split_node users keys next_user next_users next_user target torch cat torch stack continue counters backend scmerge_cat_removed += to_remove append next_user node reversed to_remove len node users keys == graph erase_node node UnbindCatRemover SplitCatSimplifier Helper merge Unbind- Cat Stack Many cases similar SplitCatSimplifier Unbind can t simplified like splits So we can only remove unbind node Other than other cases like multiple users additional args dim mismatch similar ` SplitCatSimplifier ` hence we extend remove_unbind graph torch fx Graph unbind_node torch fx Node is_node_meta_valid unbind_node we need check getitem indices unbind consecutive all go same cat node before we do unbind remove otherwise will hit error when we unbind part them getitem_indices = getitem_node args getitem_node unbind_node users keys is_sorted_and_consecutive getitem_indices len type ignore arg-type getitem_indices = len unbind_node meta example_value num_unbind = len getitem_indices split_sections = _ range num_unbind type ignore operator arg-type super simplify graph unbind_node split_sections get_simplified_split_ranges split_sections list int next_users list torch fx Node user_inputs_list list list torch fx Node &#124; _Range - list _Range &#124; None simplified_split_ranges = super get_simplified_split_ranges split_sections next_users user_inputs_list simplified_split_ranges len simplified_split_ranges = None simplified_split_ranges get_transform_params split_node torch fx Node next_users list torch fx Node user_inputs_list list list torch fx Node &#124; _Range - list list _TransformParam &#124; None Figure out what transforms needed each input each cat node Here rough transforms we apply x - unbind - stack = x - movedim x - unbind - cat = x - movedim - flatten When cat stack nodes have additional args addn --- &#124; addn - unsqueeze --- &#124; x - unbind - stack = x - movedim - cat addn --- &#124; addn --- &#124; x - unbind - cat = x - movedim - flatten - cat Note application these depends dims well split_dim = _get_dim split_node transform_params_list list list _TransformParam = user_node user_inputs zip next_users user_inputs_list cat_dim = get_arg_value user_node dim transform_params list _TransformParam = user_input user_inputs isinstance user_input tuple User input coming unbind movedim_params = split_dim cat_dim split_dim = cat_dim None flatten_params = None user_node target torch cat flatten_params = cat_dim cat_dim + transform_params append None movedim_params None flatten_params user_node target torch stack We need unsqueeze inputs coming through unbind into cat transform_params append None None cat_dim None Non-unbind inputs transform_params append None None None None transform_params_list append transform_params transform_params_list GetItem CallFunction __init__ arg index _users= - None super __init__ operator getitem arg index _users=_users find_anchor_nodes ctx MatchContext searched OrderedSet torch fx Node We generally match GetItem arg being Arg So we never anchor nodes stored node ctx pattern_to_node returned Here we override find_anchor_nodes use ctx pattern_to_node pattern flat_args_kwargs isinstance pattern PatternExpr other_node pattern find_anchor_nodes ctx searched isinstance other_node torch fx Node continue node other_node users node searched _match_fns node yield node searched add node register_graph_pattern RepeatedExpr CallFunction torch squeeze GetItem TorchSplit KeywordArg split_input KeywordArg split_sizes Ignored KeywordArg dim _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_pass register_graph_pattern RepeatedExpr CallFunction torch squeeze GetItem TorchSplit KeywordArg split_input KeywordArg split_sizes Ignored dim=KeywordArg dim _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_pass merge_split_squeeze match Match split_input torch fx Node split_sizes list int dim int graph = match graph split = next node node match nodes node target torch split all s == s split_sizes isinstance dim Sequence next_users = find_next_users split all node target torch squeeze node next_users graph inserting_before match output_node unbind = graph call_function torch unbind args= split_input kwargs= dim dim is_node_meta_valid split_input unbind meta example_value = torch unbind split_input meta example_value dim=dim item_index getitem_node sorted getitem_node args getitem_node getitem_node split users keys squeeze = next iter getitem_node users keys new_get_item = graph call_function operator getitem args= unbind item_index squeeze replace_all_uses_with new_get_item new_get_item meta update squeeze meta graph erase_node squeeze graph erase_node getitem_node graph erase_node split counters backend split_cat_pass += getitem_unbind = ListOf GetItem CallFunction torch unbind KeywordArg unbind_input dim=KeywordArg dim _users=MULTIPLE Ignored _users=MULTIPLE partial=True register_graph_pattern CallFunction torch stack torch cat getitem_unbind Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_stack_pass register_graph_pattern CallFunction torch stack torch cat getitem_unbind dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_stack_pass register_graph_pattern CallFunction torch stack torch cat tensors=getitem_unbind dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_stack_pass merge_unbind_stack match Match unbind_input torch fx Node dim int unbind_node = next node node match nodes node target torch unbind UnbindCatRemover remove_unbind match graph unbind_node getitem_split = ListOf CallFunction operator getitem TorchSplit Ignored KeywordArg split_sections Ignored _users=MULTIPLE partial=True reshape_getitem_split = ListOf CallFunction torch reshape CallFunction operator getitem TorchSplit Ignored KeywordArg split_sections Ignored _users=MULTIPLE Arg _users=MULTIPLE partial=True register_graph_pattern CallFunction torch stack torch cat tensors=getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_pass register_graph_pattern CallFunction torch stack torch cat getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_pass register_graph_pattern CallFunction torch stack torch cat getitem_split Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_pass simplify_split_cat match Match split_sections list int dim int isinstance split_sections list tuple Unnormalized split split_node = next node node match nodes node target torch split pyrefly ignore bad-argument-type SplitCatSimplifier simplify match graph split_node split_sections noqa W ############pattern optimized is######### split_node dim= \ \ getitem getitem getitem getitem - user= \ \ cat user=mul dim= cat user=mul dim= &#124; \ &#124; \ ################after transformation############# split_node dim= \ getitem getitem &#124; \ &#124; \ has_same_parent_node node torch fx Node input nodes node should come same parent prev_node = None getitem node args type ignore union-attr getitem target = operator getitem type ignore union-attr False prev_node None prev_node = getitem args type ignore union-attr getitem args = prev_node type ignore union-attr False True remove_zeros split_sections list int Remove zeros list get index mapping dict getitem split node getitem new split node new_split_sections index_mapping = idx = i range len split_sections split_sections i new_split_sections append split_sections i index_mapping i = idx idx += new_split_sections index_mapping is_sorted_and_consecutive arr list int - bool check array sorted arr == sorted arr check differences between adjacent elements all all x - x == x itertools pairwise arr False calculate_fused_tensor_size split_node torch fx Node indices list int - int Calculate fused tensor size indices fused_tensor_size = i range len split_node args type ignore arg-type i indices fused_tensor_size += split_node args i type ignore operator assignment index pyrefly ignore bad-return fused_tensor_size register_graph_pattern CallFunction torch cat getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass merge_getitem_cat_pass merge_getitem_cat match Match split_sections list int dim int isinstance split_sections list tuple Unnormalized split graph = match graph split_node = next node node match nodes node target torch split split_input _split_size split_dim = _get_split_args_default split_node cat split have different dims Find next users i e users after getitem next_users = find_next_users split_node immutable_list object does support mutation Create new copy split_sections = list split_sections cat_user next_users cat_user target torch cat cat_dim = get_arg_value cat_user dim check all getitems cat_user same node check input cat has all getitem split check all getitem only has one single user split_dim = cat_dim has_same_parent_node cat_user all len arg users == arg cat_user args type ignore union-attr continue find index getitems cated stacked type ignore union-attr indices = arg args arg cat_user args type ignore union-attr getitems merged must consecutive otherwise returned sliced tensor could wrong is_sorted_and_consecutive indices type ignore arg-type continue update arg cat user only keep first getitem cat_user update_arg cat_user args type ignore index calculate fused tensor sizes indices fused_tensor_size = i range len split_node args type ignore arg-type i indices fused_tensor_size += split_node args i type ignore operator assignment index update split sections split_sections indices = calculate_fused_tensor_size type ignore index split_node indices type ignore arg-type padding others zeros keep same dict size i indices split_sections i = type ignore index remove all unused indexes split_node new_split_sections index_mapping = remove_zeros split_sections graph inserting_after split_node new_split_node = graph call_function torch split args= split_input split_sections kwargs= dim split_dim split_node replace_all_uses_with new_split_node new_split_node meta update split_node meta remove all unused getitem nodes to_remove = cat_user dictionary keys changed during iteration new_split_getitem_nodes = list new_split_node users keys getitem_node new_split_getitem_nodes getitem_node args indices to_remove append getitem_node update meta data getitem getitem_node args == indices cat_user replace_all_uses_with getitem_node getitem_node meta update cat_user meta update getitem index new split node getitem_node update_arg index_mapping getitem_node args graph erase_node split_node getitem_node to_remove graph erase_node getitem_node update split sections new split node new_split_node update_arg new_split_sections split_node = new_split_node split_sections = new_split_sections counters backend merge_getitem_cat_pass += ############pattern optimized is######### split_node dim= - user=multiple \ \ getitem getitem getitem getitem - user=multiple \ \ \ other_op cat user=mul dim= other_op &#124; ################after transformation############# split_node dim= - - user=multiple \ \ getitem getitem getitem getitem - user=multiple \ \ \ other_op register_graph_pattern CallFunction torch cat getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass mutate_cat_pass mutate_cat_node match Match split_sections list int dim int isinstance split_sections list tuple Unnormalized split graph = match graph split_node = next node node match nodes node target torch split _split_input _split_size split_dim = _get_split_args_default split_node cat split have different dims Find next users i e users after getitem next_users = find_next_users split_node cat_user next_users cat_user target torch cat cat_dim = get_arg_value cat_user dim check all getitems cat_user same node check input cat has all getitem split split_dim = cat_dim has_same_parent_node cat_user continue find index getitems cat indices idx_to_getitem = getitem cat_user args type ignore union-attr indices append getitem args type ignore union-attr idx_to_getitem getitem args = getitem type ignore union-attr getitems merged must consecutive otherwise returned sliced tensor could wrong is_sorted_and_consecutive indices type ignore arg-type continue case cat uses all getitems split len split_sections == len cat_user args type ignore arg-type replace users cat node input split node cat_user replace_all_uses_with split_node args type ignore arg-type remove cat node graph erase_node cat_user counters backend mutate_cat_pass += case cat uses some getitems split is_node_meta_valid split_node args type ignore arg-type check split dim construct slice tuple start_fused_size = calculate_fused_tensor_size split_node list range indices type ignore arg-type end_fused_size = start_fused_size + calculate_fused_tensor_size split_node indices type ignore arg-type slice_list = i range len split_node args meta example_value shape type ignore union-attr i = split_dim slice_list append slice None None None slice_list append slice start_fused_size end_fused_size None graph inserting_after split_node slice_node = graph call_function operator getitem args= split_node args tuple slice_list cat_user replace_all_uses_with slice_node slice_node meta update cat_user meta remove cat node graph erase_node cat_user counters backend mutate_cat_pass += getitem_split_aten = ListOf CallFunction operator getitem CallFunctionVarArgs torch ops aten split_with_sizes default users=MULTIPLE Ignored _users=MULTIPLE partial=True register_graph_pattern CallFunctionVarArgs torch ops aten split Tensor users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_aten_pass normalize_split_default_aten match Match args kwargs split_node = match nodes graph = match graph split_input split_size split_dim = _get_split_args_default split_node split_input None split_dim None split_size None log debug couldn t find split args is_node_meta_valid split_node log debug val absent node s split_node assert isinstance split_node meta val list tuple split_sections = t size split_dim t split_node meta val any isinstance section torch SymInt section split_sections TODO dynamic_shapes assume_static_by_default=False fails while AOT Autograd tracing split_dim Normalize split dim split_dim += split_input meta val dim we also need check input split_node primals =torch randn split = torch ops aten split Tensor primals - truncate automatically split_ = torch ops aten split_with_sizes default primals dim = - runtime error split_input_size = split_input meta val shape split_dim split_size = min split_size split_input_size split_section_list = split_size len split_node meta val new_args = split_input split_section_list new_kwargs = dim split_dim split_node args == new_args split_node kwargs == new_kwargs split_node op == call_function graph inserting_after split_node new_split_node = graph call_function torch ops aten split_with_sizes default args=new_args kwargs=new_kwargs type ignore arg-type split_node replace_all_uses_with new_split_node new_split_node meta update split_node meta graph erase_node split_node counters backend normalization_aten_pass += register_graph_pattern CallFunctionVarArgs torch ops aten split_with_sizes default users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_aten_pass normalize_split_with_size_default_aten match Match args kwargs split_node = match nodes graph = match graph split_input split_sections split_dim = _get_split_args_default split_node split_input None split_dim None split_sections None log debug couldn t find split args is_node_meta_valid split_node log debug val absent node s split_node any isinstance section torch SymInt section split_sections TODO dynamic_shapes assume_static_by_default=False fails while AOT Autograd tracing split_dim Normalize split dim split_dim += split_input meta val dim new_args = split_input split_sections new_kwargs = dim split_dim split_node args == new_args split_node kwargs == new_kwargs split_node op == call_function graph inserting_after split_node new_split_node = graph call_function torch ops aten split_with_sizes default args=new_args kwargs=new_kwargs type ignore arg-type split_node replace_all_uses_with new_split_node new_split_node meta update split_node meta graph erase_node split_node counters backend normalization_aten_pass += register_graph_pattern CallFunction torch ops aten cat default getitem_split_aten dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_aten_pass merge_split_cat_aten match Match args kwargs graph = match graph split_node = match nodes threshold_to_cat = torch _inductor config post_grad_fusion_options split_cat_aten_pass get threshold_to_cat get getitem nodes split node getitem_nodes = list split_node users keys cat_node list getitem_nodes users keys cat_dim = get_arg_value cat_node dim cat_inputs = get_arg_value cat_node tensors try cat_input_len = len cat_inputs except TypeError continue cat_input_len threshold_to_cat continue check split node cat node has same dim all getitem nodes have same parent node parent_to_indices = defaultdict list type ignore var-annotated parent_to_getitems = defaultdict list type ignore var-annotated cat_input cat_inputs skip all non-getitem cat input cat_input target = operator getitem continue current_getitem_parent = cat_input args split_dim = get_arg_value current_getitem_parent dim split_dim = cat_dim break getitem_idx = cat_input args current_getitem_parent parent_to_indices getitem_idx = parent_to_indices current_getitem_parent - - + parent_to_indices current_getitem_parent append getitem_idx parent_to_getitems current_getitem_parent append cat_input parent_to_getitems current_getitem_parent - append cat_input parent_to_indices current_getitem_parent - append getitem_idx cat_inputs_list = list cat_inputs update_cat_arg = iterate through indices construct slice nodes parent indices parent_to_indices items idx indice enumerate indices start end = indice indice - split_sections = list parent args input_of_current_getitem_parent = parent args len indice = threshold_to_cat len indice == len split_sections len indice = len split_sections get start end slicing indices slice_node = graph call_function torch ops aten slice Tensor args= input_of_current_getitem_parent split_dim type ignore possibly-undefined sum split_sections start sum split_sections end + slice_node = input_of_current_getitem_parent find index cat_inputs_list given getitem node update_cat_arg append slice_node cat_inputs_list index parent_to_getitems parent idx cat_inputs_list index parent_to_getitems parent idx - result = i = slice_tensor start end update_cat_arg while i start result append cat_inputs_list i i += result append slice_tensor i = end + while i len cat_inputs_list result append cat_inputs_list i i += cat_node update_arg result getitem_node getitem_nodes len getitem_node users == graph erase_node getitem_node len split_node users == graph erase_node split_node counters backend split_cat_aten_pass += register_graph_pattern CallFunction torch ops aten cat default ListOf CallFunctionVarArgs torch ops aten select int users=MULTIPLE partial=True dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass select_cat_aten_pass merge_select_cat_aten match Match args kwargs graph = match graph node = match nodes node_input = get_arg_value node tensors get select nodes node select_nodes = list node_input users keys cat_node list node users keys cat_node target torch ops aten cat default cat_dim = get_arg_value cat_node dim cat_inputs = get_arg_value cat_node tensors check all select nodes has same slice dim all select_node args == select_nodes args select_node select_nodes continue We only consider case where selece slice dim cat node has same dim select_nodes args = cat_dim continue is_node_meta_valid cat_node continue check cat node has consecutive indices indices = select args select cat_node args type ignore union-attr is_sorted_and_consecutive indices type ignore arg-type len select_nodes = len cat_inputs continue check all select nodes can merged cat node input len indices = select_nodes args meta val shape cat_dim type ignore union-attr continue reshape node input same shape cat node graph inserting_before node view_node = graph call_function torch ops aten view default args= node_input cat_node meta val shape replace node input new node cat_node replace_all_uses_with view_node view_node meta update cat_node meta remove cat node graph erase_node cat_node select_node select_nodes len select_node users == graph erase_node select_node counters backend select_cat_aten_pass += register_graph_pattern CallFunctionVarArgs torch ops aten cat default users=MULTIPLE pass_dict=construct_pattern_matcher_pass normalization_aten_pass normalize_cat_default_aten match Match args kwargs cat_node = match nodes graph = match graph tensors = get_arg_value cat_node tensors cat_dim = get_arg_value cat_node dim cat_dim None cat_axis = cat_node kwargs get axis cat_axis None cat_dim = cat_axis cat_dim = tensors None cat_dim None log debug couldn t find cat args assert isinstance tensors list tuple tensor itertools chain cat_node tensors val tensor meta log debug val absent node s tensor ndim = cat_node meta val dim is_empty_tensor x torch fx Node - bool special case where torch ops aten cat default supports cat ing empty tensor x_shape = x meta val shape len x_shape == x_shape == assert all ndim == x meta val dim is_empty_tensor x x tensors pyrefly ignore unsupported-operation cat_dim Normalize cat dim cat_dim += ndim graph inserting_after cat_node new_cat_node = graph call_function torch ops aten cat default args= tensors kwargs= dim cat_dim cat_node replace_all_uses_with new_cat_node new_cat_node meta update cat_node meta graph erase_node cat_node counters backend normalization_aten_pass += register_graph_pattern CallFunction torch ops aten cat ListOf CallFunctionVarArgs torch ops aten unsqueeze _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_stack_aten_pass merge_unbind_stack_aten match Match args kwargs node = match nodes - graph = match graph pyre-fixme unsqueeze_nodes = list node args type ignore arg-type cat_dim = get_arg_value node dim check unsqueeze nodes come select nodes all get_arg_value unsqueeze_node input target torch ops aten select unsqueeze_node unsqueeze_nodes select_nodes = get_arg_value unsqueeze_node input unsqueeze_node unsqueeze_nodes parent_of_select_node = get_arg_value select_nodes input check target select_nodes same all select_node target torch ops aten select select_node select_nodes check select nodes come same parent node all get_arg_value select_node input == parent_of_select_node select_node select_nodes len unsqueeze_nodes = len select_nodes check select nodes have same dim all get_arg_value select_node dim == cat_dim select_node select_nodes check select nodes have consecutive indices starting get_arg_value select_nodes index = is_sorted_and_consecutive get_arg_value select_node index select_node select_nodes check users parent select node only unsqueeze nodes go cat node we simply check number users parent select node len parent_of_select_node users keys = len node args type ignore arg-type node replace_all_uses_with parent_of_select_node graph erase_node node unsqueeze_node unsqueeze_nodes graph erase_node unsqueeze_node select_node select_nodes len select_node users == graph erase_node select_node counters backend unbind_stack_aten_pass += divide_into_consecutive_sublists indices list int - list list int n = len indices n = indices Initialize list sublists sublists = Iterate over indices i = while i n Initialize current sublist sublist = indices i Iterate over remaining indices j = i + while j n indices j == indices j - + Add next index current sublist sublist append indices j j += Add current sublist list sublists sublists append sublist Move next index i = j sublists update_args_from_split_getitem graph torch fx Graph node torch fx Node getitem_indices list int parents_seen list torch fx Node new_cat_args list torch fx Node new_cat_args_meta list torch fx Node idx_to_getitems dict int torch fx Node threshold_to_cat int = split_input split_size split_dim = _get_split_args_default parents_seen - case number getitems same split size eliminate split len split_size == len getitem_indices is_sorted_and_consecutive getitem_indices we can merge getitems previous parent new_cat_args append split_input new_cat_args_meta append split_input meta example_value len getitem_indices case number getitems smaller than split size larger than threshold indices getitems all consecutive we need divide indices into multiple groups geitem_indices_sublist = divide_into_consecutive_sublists getitem_indices sublist geitem_indices_sublist len sublist = threshold_to_cat case number getitems smaller than split size larger than threshold we need slice input parent start_fused_size = sum split_size sublist end_fused_size = sum split_size sublist - + slice_list = i range len split_input meta example_value shape type ignore union-attr i = split_dim slice_list append slice None None None slice_list append slice start_fused_size end_fused_size None graph inserting_after node slice_node = graph call_function operator getitem args= split_input tuple slice_list slice_node meta example_value = split_input meta example_value tuple slice_list new_cat_args append slice_node new_cat_args_meta append slice_node meta example_value case number getitems smaller than threshold no merge done get getitems based indexes i sublist new_cat_args append idx_to_getitems i new_cat_args_meta append idx_to_getitems i meta example_value reshape_cat_node graph torch fx Graph cat_node torch fx Node unbind_input torch fx Node cat_dim int unbind_dim int cat_shape torch Size - torch fx Node cat_dim = unbind_dim construct permute node args which has same shape slice node then has same dim unbind_input i e shape cat + graph inserting_after cat_node permute_list = list range len cat_shape + permute_list unbind_dim permute_list cat_dim = permute_list cat_dim permute_list unbind_dim permute_node = graph call_function torch permute args= unbind_input permute_list permute_node meta example_value = torch permute unbind_input meta example_value permute_list type ignore arg-type permute_node = unbind_input graph inserting_after permute_node reshape_node = graph call_function torch reshape args= permute_node tuple cat_shape reshape_node meta example_value = torch reshape permute_node meta example_value tuple cat_shape type ignore arg-type reshape_node update_args_from_unbind_getitem graph torch fx Graph node torch fx Node cat stack node getitem_indices list int parents_seen list torch fx Node new_cat_args list torch fx Node new_cat_args_meta list torch fx Node idx_to_getitems dict int torch fx Node threshold_to_cat int = unbind_input = get_arg_value parents_seen - input split unbind input unbind_dim = get_arg_value parents_seen - dim split unbind dim cat_dim = get_arg_value node dim cat stack dim case number getitems same split size eliminate split size = list unbind_input meta example_value shape unbind_dim size == len getitem_indices cat_shape = torch cat idx_to_getitems i meta example_value i getitem_indices dim=cat_dim shape we can merge getitems previous parent reshape_node = reshape_cat_node graph node unbind_input cat_dim unbind_dim cat_shape new_cat_args append reshape_node new_cat_args_meta append reshape_node meta example_value len getitem_indices = threshold_to_cat is_sorted_and_consecutive getitem_indices case number getitems smaller than split size larger than threshold we need slice input parent cat_shape = torch cat idx_to_getitems i meta example_value i getitem_indices dim=cat_dim shape slice_list = i range len cat_shape + i = unbind_dim slice_list append slice None None None start end step slice_list append slice getitem_indices getitem_indices - + None graph inserting_after node slice_node = graph call_function operator getitem args= unbind_input tuple slice_list slice_node meta example_value = torch narrow unbind_input meta example_value unbind_dim getitem_indices getitem_indices - - getitem_indices + reshape_node = reshape_cat_node graph node slice_node cat_dim unbind_dim cat_shape new_cat_args append reshape_node new_cat_args_meta append reshape_node meta example_value case number getitems smaller than threshold no merge done get getitems based indexes i getitem_indices new_cat_args append idx_to_getitems i new_cat_args_meta append idx_to_getitems i meta example_value construct_cat_args graph torch fx Graph cat_or_stack_node torch fx Node inputs list torch fx Node split_or_unbind_node torch fx Node threshold_to_cat int = run_update_func Callable = update_args_from_split_getitem type ignore type-arg - tuple list torch fx Node list torch Tensor new_cat_args parents_seen getitem_indices idx_to_getitems = type ignore var-annotated new_cat_args_meta = type ignore var-annotated input inputs input target = operator getitem update last arg based getitem_indices parents_seens len parents_seen run_update_func type ignore arg-type union-attr graph cat_or_stack_node getitem_indices parents_seen new_cat_args new_cat_args_meta idx_to_getitems type ignore arg-type union-attr threshold_to_cat new_cat_args append input new_cat_args_meta append input meta example_value reset indices array getitem_indices idx_to_getitems = get parent node getitem input parent idx = input args input args type ignore union-attr parent target = split_or_unbind_node target type ignore union-attr new_cat_args append input new_cat_args_meta append input meta example_value continue cannot use parents_seen check since first item could non getitem node len parents_seen == parents_seen append parent idx_to_getitems idx = input getitem_indices append idx case we only have one getitem input last position input == inputs - new_cat_args append input new_cat_args_meta append input meta example_value continue last input tensors we also check can optimized parent = parents_seen - input == inputs - input == inputs - getitem_indices append idx idx_to_getitems idx = input run_update_func type ignore arg-type union-attr graph cat_or_stack_node getitem_indices parents_seen new_cat_args new_cat_args_meta idx_to_getitems type ignore arg-type union-attr threshold_to_cat reset indices array next parent remember add last element since first item round parent add parent list seen parents parents_seen append parent getitem_indices idx_to_getitems = idx idx input getitem_indices append idx idx_to_getitems idx = input new_cat_args new_cat_args_meta remove_split_unbind_children graph torch fx Graph inputs list torch fx Node nodes = OrderedSet Any input inputs input target operator getitem nodes add input args type ignore union-attr len input users keys == graph erase_node input check split node remove has no users node nodes len node users keys == type ignore union-attr graph erase_node node type ignore arg-type ############pattern optimized is######### split_node dim= - user=multiple \ \ other inputs getitem getitem getitem - user=multiple \ \ cat user=mul dim= other_op &#124; ################after transformation############# split_node dim= other inputs - - user=multiple \ cat user=mul dim= split_node register_graph_pattern CallFunction torch cat getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_cat_to_slices_pass split_cat_to_slices match Match split_sections list int dim int isinstance split_sections list tuple Unnormalized split split_nodes = node node match nodes node target torch split split_nodes split_node = next node node split_nodes Handle case where there no nodes target torch split split_dim = get_arg_value split_node dim graph = match graph threshold_to_cat = torch _inductor config pre_grad_fusion_options split_cat_to_slices_pass get threshold_to_cat get cat_node check its inputs meta data next_users = find_next_users split_node cat_node next_users cat_node target = torch cat is_node_meta_valid cat_node continue cat_inputs = get_arg_value cat_node tensors type ignore union-attr new_cat_args _ = construct_cat_args graph cat_node cat_inputs split_node threshold_to_cat update_args_from_split_getitem At least one node would returned new_cat_args case new cat args has length we can remove cat node len new_cat_args == cat_node replace_all_uses_with new_cat_args remove inputs cat_node they have no users cat_inputs = cat_node args type ignore union-attr graph erase_node cat_node remove_split_unbind_children graph cat_inputs type ignore arg-type counters backend split_cat_to_slices_pass += continue len new_cat_args len new_cat_args len cat_inputs new_args = new_cat_args graph inserting_after cat_node new_cat_node = graph call_function torch cat args=new_args split cat have same dim kwargs= dim split_dim cat_node replace_all_uses_with new_cat_node new_cat_node meta update cat_node meta remove cat node graph erase_node cat_node remove_split_unbind_children graph cat_inputs counters backend split_cat_to_slices_pass += ############pattern optimized is######### unbind dim= - user=multiple \ \ getitem getitem getitem getitem - user=multiple \ \ cat user=mul dim= other_op &#124; ################after transformation############# input_of_unbind &#124; \ slice &#124; view &#124; register_graph_pattern CallFunction torch cat getitem_unbind dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_cat_to_view_pass unbind_cat_to_view match Match unbind_input torch fx Node dim int unbind_node = next node node match nodes node target torch unbind graph = match graph get cat_node check its inputs meta data next_users = find_next_users unbind_node threshold_to_cat = torch _inductor config pre_grad_fusion_options unbind_cat_to_view_pass get threshold_to_cat get cat_node check its inputs meta data cat_node next_users cat_node target = torch cat is_node_meta_valid cat_node continue inputs = get_arg_value cat_node tensors type ignore union-attr new_cat_args new_cat_args_meta = construct_cat_args graph cat_node inputs unbind_node threshold_to_cat update_args_from_unbind_getitem get view shape At least one node would returned new_cat_args case only one node new cat args don t need cat len new_cat_args == cat_node replace_all_uses_with new_cat_args remove inputs cat_node they have no users cat_inputs = cat_node args type ignore union-attr graph erase_node cat_node remove_split_unbind_children graph cat_inputs type ignore arg-type counters backend unbind_cat_to_view_pass += continue len new_cat_args len new_cat_args len inputs get view shape cat_dim = get_arg_value cat_node dim graph inserting_after cat_node new_cat_node = graph call_function torch cat args= new_cat_args kwargs= dim cat_dim new_cat_node meta example_value = torch cat new_cat_args_meta dim=cat_dim type ignore arg-type cat_node replace_all_uses_with new_cat_node new_cat_node meta update cat_node meta remove inputs cat_node they have no users cat_inputs = cat_node args type ignore union-attr graph erase_node cat_node remove_split_unbind_children graph cat_inputs type ignore arg-type counters backend unbind_cat_to_view_pass += reshape_cat_node_to_stack graph torch fx Graph cat_node torch fx Node stack_node torch fx Node split_or_unbind_dim int - None reshape cat node stack node shape stack_shape = stack_node meta example_value shape stack_dim = _get_dim stack_node stack_dim = split_or_unbind_dim case stack dim same split dim we need reshape split input before we do reshape reshape_list = list stack_shape reshape_list stack_dim reshape_list split_or_unbind_dim = reshape_list split_or_unbind_dim reshape_list stack_dim reshape_node = graph call_function torch reshape args= cat_node tuple reshape_list reshape_node meta example_value = torch reshape cat_node meta example_value tuple reshape_list pyrefly ignore bad-argument-type permute_list = list range len stack_shape permute_list stack_dim permute_list split_or_unbind_dim = permute_list split_or_unbind_dim permute_list stack_dim permute_node = graph call_function torch permute args= reshape_node permute_list permute_node meta example_value = torch permute reshape_node meta example_value permute_list case stack dim same split dim we can directly reshape split input permute_node = cat_node reshape_node = graph call_function torch Tensor view args= permute_node stack_shape type ignore arg-type stack_node replace_all_uses_with reshape_node reshape_node meta update stack_node meta stack_inputs = stack_node args type ignore union-attr remove stack node graph erase_node stack_node check input stack node remove nodes have no users remove_split_unbind_children graph stack_inputs type ignore arg-type convert_reshape_cat_arg_to_stack graph torch fx Graph cat_node torch fx Node stack_node torch fx Node stack_node_shape torch Size stack_dim int split_dim int - torch fx Node reshape cat node stack node shape cat_shape = cat_node meta example_value shape stack_dim = split_dim permute_list = list range len cat_shape permute_list stack_dim permute_list split_dim = permute_list split_dim permute_list stack_dim permute_node = graph call_function torch permute args= cat_node permute_list permute_node meta example_value = torch permute cat_node meta example_value permute_list permute_node = cat_node reshape_node = graph call_function torch Tensor view args= permute_node tuple stack_node_shape type ignore arg-type reshape_node meta example_value = torch Tensor view permute_node meta example_value tuple stack_node_shape type ignore arg-type reshape_node ############pattern optimized is######### &#124; &#124; split split dim= \ \ getitem getitem other ops \ &#124; stack user=mul dim= - can different dim &#124; ################after transformation############# \ \ getitem getitem getitem getitem - user=multiple \ cat user=mul dim= cat_other_opts \ cat &#124; view &#124; register_graph_pattern CallFunction torch stack getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass split_stack_to_cats_pass split_stack_to_cats match Match split_sections list int dim int isinstance split_sections list tuple Unnormalized split split_node = next node node match nodes node target torch split split_dim = get_arg_value split_node dim graph = match graph threshold_to_cat = torch _inductor config pre_grad_fusion_options split_stack_to_cats_pass get threshold_to_cat get stack_node check its inputs meta data next_users = find_next_users split_node stack_node next_users stack_node target = torch stack is_node_meta_valid stack_node continue inputs = get_arg_value stack_node tensors type ignore union-attr new_cat_args new_cat_args_meta = construct_cat_args graph stack_node inputs split_node threshold_to_cat update_args_from_split_getitem At least one node would returned new_cat_args case only one node new cat args don t need cat len new_cat_args == reshape_cat_node_to_stack graph new_cat_args stack_node split_dim counters backend split_stack_to_cats_pass += continue len new_cat_args len new_cat_args len inputs graph inserting_after stack_node cat_node = graph call_function torch cat args= new_cat_args kwargs= dim split_dim cat_node meta example_value = torch cat type ignore arg-type new_cat_args_meta dim=split_dim reshape_cat_node_to_stack graph cat_node stack_node split_dim counters backend split_stack_to_cats_pass += ############pattern optimized is######### unbind dim= - user=multiple \ \ others getitem getitem getitem - user=multiple \ \ \ stack user=mul dim= other_op &#124; ################after transformation############# input_of_unbind &#124; \ slice &#124; view others &#124; stack &#124; register_graph_pattern CallFunction torch stack getitem_unbind dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass unbind_stack_to_slices_pass unbind_stack_to_slices match Match unbind_input torch fx Node dim int unbind_node = next node node match nodes node target torch unbind graph = match graph get cat_node check its inputs meta data next_users = find_next_users unbind_node threshold_to_cat = torch _inductor config pre_grad_fusion_options unbind_stack_to_slices_pass get threshold_to_cat get cat_node check its inputs meta data stack_node next_users stack_node target = torch stack is_node_meta_valid stack_node continue inputs = get_arg_value stack_node tensors type ignore union-attr new_cat_args new_cat_args_meta = construct_cat_args graph stack_node inputs unbind_node threshold_to_cat update_args_from_unbind_getitem unbind_dim = get_arg_value unbind_node dim At least one node would returned new_cat_args case only one node new cat args don t need cat len new_cat_args == reshape_cat_node_to_stack graph new_cat_args stack_node unbind_dim counters backend unbind_stack_to_slices_pass += continue len new_cat_args len new_cat_args len inputs get view shape cat_dim = get_arg_value stack_node dim graph inserting_after stack_node new_cat_node = graph call_function torch cat args= new_cat_args kwargs= dim cat_dim new_cat_node meta example_value = torch cat new_cat_args_meta dim=cat_dim reshape_cat_node_to_stack graph new_cat_node stack_node unbind_dim counters backend unbind_stack_to_slices_pass += ############pattern optimized is######### input &#124; split dim= - user=multiple \ \ others getitem getitem \ \ reshape reshape reshape other_op \ \ stack user=mul dim= &#124; ################after transformation############# input &#124; permute &#124; reshape others &#124; cat dim= &#124; get_view_shape_list cat_arg torch fx Node stack_dim int - list int cat_arg must split input view_shape_list = user cat_arg users keys user target torch split getitem user users keys getitem target operator getitem reshape_user = user user getitem users keys user target torch reshape len reshape_user view_shape_list = list reshape_user meta example_value unsqueeze stack_dim shape view_shape_list stack_dim = - view_shape_list view_shape_list register_graph_pattern CallFunction torch stack reshape_getitem_split dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass move_reshape_out_of_split_stack_pass move_reshape_out_of_split_stack match Match args kwargs split_node = next node node match nodes node target torch split split_dim = _get_dim split_node split_users = list split_node users keys stack_nodes = node node match nodes node target torch stack graph = match graph threshold_to_cat = torch _inductor config pre_grad_fusion_options move_reshape_out_of_split_stack_pass get threshold_to_cat stack_node stack_nodes is_node_meta_valid stack_node log debug example value absent node s stack_node continue stack_dim = _get_dim stack_node stack_inputs = get_arg_value stack_node tensors type ignore union-attr inputs = stack_input stack_inputs stack_input target = torch reshape inputs append stack_input inputs append stack_input args type ignore union-attr new_cat_args _new_cat_args_meta = construct_cat_args graph stack_node inputs split_node threshold_to_cat update_args_from_split_getitem At least one node would returned new_cat_args case only one node new cat args don t need cat len new_cat_args == reshape_node = convert_reshape_cat_arg_to_stack graph new_cat_args stack_node stack_node meta example_value shape stack_dim split_dim stack_node replace_all_uses_with reshape_node remove stack node graph erase_node stack_node check input stack node remove nodes have no users remove_split_unbind_children graph stack_inputs type ignore arg-type remove_split_unbind_children graph split_users type ignore arg-type counters backend move_reshape_out_of_split_stack_pass += continue len new_cat_args len new_cat_args len inputs decompose cat args into multiple stack nodes i e we stack all nodes exist stack inputs reshape rest followed cat stack_node_input stack_node_input_meta cat_inputs = type ignore var-annotated cat_arg new_cat_args cat_arg stack_inputs len stack_node_input graph inserting_after stack_node decomposed_stack_node = graph call_function torch stack args= stack_node_input kwargs= dim stack_dim decomposed_stack_node meta example_value = torch stack stack_node_input_meta dim=stack_dim cat_inputs append decomposed_stack_node cat_arg must split input view_shape_list = get_view_shape_list cat_arg stack_dim stack_node_shape = torch reshape cat_arg meta example_value tuple view_shape_list shape type ignore union-attr cat_inputs append convert_reshape_cat_arg_to_stack graph cat_arg stack_node stack_node_shape stack_dim split_dim stack_node_input stack_node_input_meta = stack_node_input append cat_arg stack_node_input_meta append cat_arg meta example_value len stack_node_input graph inserting_after stack_node decomposed_stack_node = graph call_function torch stack args= stack_node_input kwargs= dim stack_dim decomposed_stack_node meta example_value = torch stack stack_node_input_meta dim=stack_dim cat_inputs append decomposed_stack_node graph inserting_after stack_node cat_node = graph call_function torch cat args= cat_inputs kwargs= dim stack_dim stack_node replace_all_uses_with cat_node cat_node meta update stack_node meta graph erase_node stack_node remove_split_unbind_children graph stack_inputs type ignore arg-type remove_split_unbind_children graph split_users type ignore arg-type counters backend move_reshape_out_of_split_stack_pass += view_getitem_split_aten = ListOf CallFunction torch ops aten reshape default CallFunction operator getitem CallFunctionVarArgs torch ops aten split_with_sizes default users=MULTIPLE Ignored _users=MULTIPLE Arg _users=MULTIPLE partial=True register_graph_pattern CallFunction torch ops aten cat default view_getitem_split_aten dim=Ignored _users=MULTIPLE pass_dict=construct_pattern_matcher_pass move_view_after_cat_aten_pass move_view_after_cat match Match args kwargs split_node = next node node match nodes node target torch ops aten split_with_sizes default split_input split_section split_dim = _get_split_args_default split_node split_users = list split_node users keys getitem_indices = getitem args getitem split_users getitem target operator getitem is_sorted_and_consecutive getitem_indices type ignore arg-type cat_nodes = node node match nodes node target torch ops aten cat default graph = match graph cat_node cat_nodes is_node_meta_valid cat_node log debug example value absent node s cat_node continue cat_dim = _get_dim cat_node cat_inputs = get_arg_value cat_node tensors type ignore union-attr we only consider following special case len cat_inputs = len split_section continue check cat inputs all view nodes all view_node target torch ops aten reshape default view_node cat_inputs continue check view nodes all getitem nodes all view_node args target operator getitem view_node cat_inputs continue view_indices = view args args view cat_inputs is_sorted_and_consecutive view_indices type ignore arg-type continue cat_dim = split_dim construct permute node permute_list = list range len cat_node meta val shape + permute_list split_dim permute_list cat_dim = permute_list cat_dim permute_list split_dim permute_node = graph call_function torch ops aten permute default args= split_input permute_list permute_node = split_input graph inserting_before cat_node view_node = graph call_function torch ops aten reshape default args= permute_node list cat_node meta val shape cat_node replace_all_uses_with view_node view_node meta update cat_node meta graph erase_node cat_node counters backend move_view_after_cat_aten_pass += match_einsum_strings s str - bool This function takes string s input where s format letter string letter string - letter string It checks strings match rule returns True they do False otherwise The rule - The three strings have same first two characters - The first two strings have same third character - The second third strings have same last character Split input string into parts parts = s replace - split Strip leading trailing whitespaces each part parts = part strip part parts Check we have exactly three parts len parts = False Extract strings s s s = parts Check strings have correct lengths len s = len s = len s = False Check rule s == s == s s == s s == s register_graph_pattern CallFunctionVarArgs torch functional einsum users=MULTIPLE pass_dict=construct_pattern_matcher_pass einsum_to_pointwise_pass replace_einsum_to_pointwise match Match args kwargs repl input weights input unsqueeze - weights sum - should_replace_einsum einsum_node - bool equation = get_arg_value einsum_node users = einsum_node users keys now we only consider case two operands len einsum_node args == is_node_meta_valid input is_node_meta_valid weights any user target == add user target operator add user users match_einsum_strings equation einsum_node = match nodes input weights = get_arg_value einsum_node get_arg_value einsum_node should_replace_einsum einsum_node pyrefly ignore bad-argument-type match replace_by_example repl input weights counters backend einsum_to_pointwise_pass +=