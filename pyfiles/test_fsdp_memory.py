Owner s oncall distributed sys unittest torch torch nn nn torch optim optim torch distributed dist torch distributed fsdp FullyShardedDataParallel FSDP torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp FSDPTest torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests TEST_CUDA TEST_HPU TEST_WITH_DEV_DBG_ASAN torch utils checkpoint checkpoint dist is_available print Distributed available skipping tests file=sys stderr sys exit TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit device_type = acc type acc = torch accelerator current_accelerator cpu get_cur_mem rank result prefix Collect memory allocated values result dict MB TEST_CUDA torch _C _cuda_clearCublasWorkspaces result prefix = round torch accelerator memory_allocated Model nn Module __init__ hidden_dim with_fsdp=False with_checkpoint=False super __init__ with_fsdp stem = nn Sequential nn Conv d kernel_size= FSDP nn BatchNorm d nn ReLU inplace=True stem = nn Sequential nn Conv d kernel_size= nn BatchNorm d nn ReLU inplace=True with_fsdp blocks = nn Sequential nn Conv d hidden_dim kernel_size= padding= FSDP nn BatchNorm d hidden_dim nn ReLU inplace=True nn Conv d hidden_dim hidden_dim kernel_size= padding= FSDP nn BatchNorm d hidden_dim nn ReLU inplace=True nn Conv d hidden_dim hidden_dim kernel_size= padding= FSDP nn BatchNorm d hidden_dim nn ReLU inplace=True nn AdaptiveAvgPool d output_size= nn Flatten blocks = nn Sequential nn Conv d hidden_dim kernel_size= padding= nn BatchNorm d hidden_dim nn ReLU inplace=True nn Conv d hidden_dim hidden_dim kernel_size= padding= nn BatchNorm d hidden_dim nn ReLU inplace=True nn Conv d hidden_dim hidden_dim kernel_size= padding= nn BatchNorm d hidden_dim nn ReLU inplace=True nn AdaptiveAvgPool d output_size= nn Flatten head = nn Linear hidden_dim with_checkpoint = with_checkpoint forward x with_checkpoint head checkpoint blocks stem x use_reentrant=True head blocks stem x create_model with_fsdp with_checkpoint model_hidden_dim torch manual_seed model = Model model_hidden_dim with_fsdp with_checkpoint with_fsdp model stem = FSDP model stem model blocks = FSDP model blocks model head = FSDP model head model TestFSDPMemory FSDPTest property world_size _dist_train with_checkpoint expected model_hidden_dim iterations gpu_id = rank batch = torch randn size= device_type model = create_model with_fsdp=True with_checkpoint=with_checkpoint model_hidden_dim=model_hidden_dim model = model device_type model = FSDP model We enable momentum so after first iteration optimizer state added total memory used criterion = nn MSELoss optimizer = optim SGD model parameters lr= e- momentum= results = results memory stats iteration range iterations get_cur_mem gpu_id results f iter iteration start out = model batch get_cur_mem gpu_id results f iter iteration after fwd out = sum o sum o out fake_loss = criterion out torch tensor device_type get_cur_mem gpu_id results f iter iteration after loss fake_loss backward get_cur_mem gpu_id results f iter iteration after bwd optimizer step get_cur_mem gpu_id results f iter iteration after step It important use ` set_to_none ` below optimizer zero_grad reclaim memory model zero_grad set_to_none=True get_cur_mem gpu_id results f iter iteration done cmp results expected ret = assertEqual results keys expected keys k v results items exp = expected k abs exp - v allow MB rounding differences ret += f k got v expected exp \n ret output = cmp results expected assertEqual output unittest skipIf TEST_HPU Memory will different CUDA HPU skipping skip_if_lt_x_gpu parametrize ckpt no_ckpt ckpt test_fsdp_memory ckpt hidden_dim model size ~ MB model_hidden_dim = model = create_model with_fsdp=False with_checkpoint=False model_hidden_dim=model_hidden_dim device_type model_size_mb = round torch accelerator memory_allocated del model sharded_model_size_mb = int model_size_mb world_size We have observed sometimes after rd iteration th one can fail test much bigger scale tests We run iterations here just case happens iterations = expected = iteration range iterations iteration == sharded model size + MB temp memory expected f iter iteration start = sharded_model_size_mb + hard calculate memory size get printed memory usage ckpt == ckpt expected f iter iteration after fwd = expected f iter iteration after loss = expected f iter iteration after fwd = expected f iter iteration after loss = sharded model size + sharded grad size + M temp memory expected f iter iteration after bwd = sharded_model_size_mb + after optimizer step first iteration memory usage increased sharded_model_size_mb because increased optimizer states memory usage expected f iter iteration start = sharded_model_size_mb + ckpt == ckpt expected f iter iteration after fwd = + sharded_model_size_mb expected f iter iteration after loss = + sharded_model_size_mb expected f iter iteration after fwd = + sharded_model_size_mb expected f iter iteration after loss = + sharded_model_size_mb expected f iter iteration after bwd = sharded_model_size_mb + sharded model size + sharded grad size + optimizer states + M temp memory expected f iter iteration after step = sharded_model_size_mb + grad memory claimed after setting grad = None sharded model size + optimizer states + M temp memory expected f iter iteration done = sharded_model_size_mb + Get fsdp checkpoint flags with_ckpt = ckpt == ckpt _dist_train with_ckpt expected model_hidden_dim iterations instantiate_parametrized_tests TestFSDPMemory __name__ == __main__ run_tests