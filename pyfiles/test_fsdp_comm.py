Owner s oncall distributed sys contextlib nullcontext enum auto Enum typing Optional unittest mock patch torch torch nn nn torch nn functional F torch distributed dist torch _utils _get_device_module torch distributed fsdp FullyShardedDataParallel FSDP torch distributed fsdp fully_sharded_data_parallel ShardingStrategy torch distributed fsdp wrap ModuleWrapPolicy torch nn parallel distributed DistributedDataParallel DDP torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp DEVICEInitMode FSDPInitMode FSDPTest get_devtype MLP NestedWrappedModule TransformerWithSharedParams torch testing _internal common_utils parametrize run_tests TEST_WITH_DEV_DBG_ASAN device_type = torch device get_devtype dist is_available print Distributed available skipping tests file=sys stderr sys exit TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit PassType Enum __order__ = FWD BWD FWD = auto BWD = auto TestCommunication FSDPTest Tests ` ` FullyShardedDataParallel ` ` s collective communication usage _init_model device nested_model bool sharding_strategy ShardingStrategy fsdp_kwargs = sharding_strategy sharding_strategy device_id device_type type nested_model model = NestedWrappedModule init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_AFTER fsdp_kwargs fsdp_model FSDP = FSDP model process_group fsdp_kwargs fsdp_model FSDP = TransformerWithSharedParams init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_BEFORE fsdp_kwargs fsdp_model _run_iter fsdp_model batch use_no_sync bool Runs iteration inside outside ` ` no_sync ` ` context context = fsdp_model no_sync use_no_sync nullcontext context output = fsdp_model batch loss = fsdp_model module get_loss batch output loss backward _get_ref_num_reduce_scatters num_fsdp int in_no_sync bool - int Returns reference number reduce-scatters iteration ` ` no_sync ` ` context num_fsdp in_no_sync _get_ref_num_all_gathers num_fsdp int sharding_strategy Optional ShardingStrategy is_first_iter bool is_last_iter_no_sync bool - int Returns reference number all-gathers iteration summing over forward backward passes sum _get_ref_num_all_gathers_in_pass num_fsdp sharding_strategy pass_type is_first_iter is_last_iter_no_sync pass_type PassType _get_ref_num_all_gathers_in_pass num_fsdp int sharding_strategy Optional ShardingStrategy pass_type PassType is_first_iter bool is_last_iter_no_sync bool Returns reference number all-gathers given setting sharding_strategy None sharding_strategy = ShardingStrategy FULL_SHARD default Forward pass pass_type == PassType FWD sharding_strategy == ShardingStrategy SHARD_GRAD_OP is_last_iter_no_sync Modules do free full parameters last iteration s backward pass ` no_sync ` num_all_gathers = pass_type == PassType FWD Otherwise all modules all-gather full parameters forward pass num_all_gathers = num_fsdp Backward pass pass_type == PassType BWD sharding_strategy == ShardingStrategy FULL_SHARD Root does free full parameters end forward pass num_all_gathers = num_fsdp - pass_type == PassType BWD sharding_strategy == ShardingStrategy SHARD_GRAD_OP Modules do free full parameters end forward pass num_all_gathers = assert f Unsupported add branch pass_type= pass_type f is_first_iter= is_first_iter f is_last_iter_no_sync= is_last_iter_no_sync f sharding_strategy= sharding_strategy is_first_iter pass_type == PassType FWD With execution order validation first iteration we have additional two all-gathers before every actual all-gather forward pass num_all_gathers = num_all_gathers _print_ref_num_all_gathers_in_pass num_fsdp int sharding_strategy ShardingStrategy pass_type PassType is_first_iter bool is_last_iter_no_sync bool Helper method printing number all-gathers specific setting This may helpful since branching complex rank = only print one rank num_all_gathers = _get_ref_num_all_gathers_in_pass num_fsdp sharding_strategy pass_type is_first_iter is_last_iter_no_sync print f Pass pass_type \n f Is First Iteration is_first_iter \n f Sharding Strategy sharding_strategy \n f Last iteration ` no_sync ` is_last_iter_no_sync \n f Number all-gathers num_all_gathers skip_if_lt_x_gpu parametrize nested_model False True parametrize use_no_sync False True parametrize sharding_strategy ShardingStrategy SHARD_GRAD_OP None test_communication device nested_model bool use_no_sync bool sharding_strategy Optional ShardingStrategy Tests FSDP s communication cost terms calls collective communication primitives i e all-gather reduce-scatter Arguments nested_model bool If ` ` True ` ` uses ` ` NestedWrappedModule ` ` which has nested FSDP instances ` ` False ` ` uses default model which does have nested FSDP instances use_no_sync bool If ` ` True ` ` runs some iterations inside ` ` no_sync ` ` context manager accumulate gradients followed some iterations outside context manager ` ` False ` ` only runs some iterations outside context manager sharding_strategy Optional ShardingStrategy Configures FSDP algorithm Enable execution order checking dist set_debug_level dist DebugLevel DETAIL Initialize model inputs fsdp_model = _init_model device_type nested_model sharding_strategy batch = fsdp_model module get_input device_type Count number FSDP instances manage parameters since number collectives function number num_fsdp = sum isinstance m FSDP len m params m fsdp_model modules If ` use_no_sync=True ` we run ` num_iters ` iterations inside ` no_sync ` followed ` num_iters ` iterations outside ` no_sync ` ` use_no_sync=False ` we only run ` num_iters ` iterations outside ` no_sync ` num_iters = patch torch distributed all_gather_into_tensor mock_all_gather patch torch distributed reduce_scatter_tensor mock_reduce_scatter reset_mocks mock_all_gather reset_mock mock_reduce_scatter reset_mock Check communication cost when using ` no_sync ` use_no_sync i range num_iters reset_mocks _run_iter fsdp_model batch use_no_sync=True num_all_gathers = mock_all_gather call_count num_reduce_scatters = mock_reduce_scatter call_count ref_num_all_gathers = _get_ref_num_all_gathers num_fsdp sharding_strategy is_first_iter=i == is_last_iter_no_sync=i ref_num_reduce_scatters = _get_ref_num_reduce_scatters num_fsdp in_no_sync=True assertEqual num_all_gathers ref_num_all_gathers assertEqual num_reduce_scatters ref_num_reduce_scatters Check normal communication cost when using ` no_sync ` i range num_iters reset_mocks _run_iter fsdp_model batch use_no_sync=False num_all_gathers = mock_all_gather call_count num_reduce_scatters = mock_reduce_scatter call_count ref_num_all_gathers = _get_ref_num_all_gathers num_fsdp sharding_strategy is_first_iter=not use_no_sync i == is_last_iter_no_sync=use_no_sync i == ref_num_reduce_scatters = _get_ref_num_reduce_scatters num_fsdp in_no_sync=False assertEqual num_all_gathers ref_num_all_gathers assertEqual num_reduce_scatters ref_num_reduce_scatters TestExplicitUnshard FSDPTest property world_size - int min _get_device_module device_type device_count skip_if_lt_x_gpu parametrize use_orig_params False True test_unshard_async device use_orig_params bool ReduceModule nn Module __init__ dim int group dist ProcessGroup super __init__ group = group weight = nn Parameter torch randn dim dim forward x torch Tensor y = F relu x weight NOTE This all-reduce differentiable included exercise overlap work = dist all_reduce y group=self group async_op=True y work MLPs nn Module __init__ dim int super __init__ mlp = MLP dim mlp = MLP dim mlp = MLP dim forward ys list torch Tensor works list dist Work y y y work work work = ys works work wait z = mlp y work wait z = mlp y work wait z = mlp y z + z + z ReduceModel nn Module __init__ dim int group dist ProcessGroup super __init__ reduce_module = ReduceModule dim group reduce_module = ReduceModule dim group reduce_module = ReduceModule dim group mlps = MLPs dim forward x torch Tensor y work = reduce_module x isinstance mlps mlp FSDP mlps mlp _unshard async_op=True y work = reduce_module x isinstance mlps mlp FSDP mlps mlp _unshard async_op=True y work = reduce_module x isinstance mlps mlp FSDP mlps mlp _unshard async_op=True mlps y y y work work work group = process_group batch_size dim = torch manual_seed ref_model = DDP ReduceModel dim group device_type device_ids= rank ref_optim = torch optim Adam ref_model parameters lr= e- torch manual_seed model = ReduceModel dim group model mlps = FSDP model mlps sharding_strategy=ShardingStrategy SHARD_GRAD_OP auto_wrap_policy=ModuleWrapPolicy MLP device_id=device_type type use_orig_params=use_orig_params model mlps check_is_root mlp_params = set model mlps parameters mlp_param_names = n n p model named_parameters p mlp_params DDP _set_params_and_buffers_to_ignore_for_model model mlp_param_names model = DDP model device_type device_ids= rank optim = torch optim Adam model parameters lr= e- torch manual_seed + rank + inp = torch randn batch_size dim device=device_type _ range losses list torch Tensor = _model _optim ref_model ref_optim model optim losses append _model inp sum losses - backward _optim step _optim zero_grad assertEqual losses losses model module mlps _wait_unshard_streams_on_current_stream devices = cuda hpu xpu instantiate_device_type_tests TestCommunication globals only_for=devices allow_xpu=True instantiate_device_type_tests TestExplicitUnshard globals only_for=devices allow_xpu=True __name__ == __main__ run_tests