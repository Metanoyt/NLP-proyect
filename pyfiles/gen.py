__future__ annotations argparse functools json keyword os collections defaultdict namedtuple OrderedDict dataclasses dataclass field pathlib Path typing Any Literal TYPE_CHECKING TypeVar typing_extensions assert_never yaml torchgen api dispatcher dispatcher torchgen api meta meta torchgen api native native torchgen api structured structured torchgen dest dest torchgen api cpp torchgen api translate translate torchgen api types Binding CppSignature CppSignatureGroup DispatcherSignature NamedCType NativeSignature SpecialArgName torchgen context method_with_native_function native_function_manager with_native_function with_native_function_and_indices torchgen gen_aoti_c_shim gen_aoti_c_shim_files gen_static_dispatch_backend_call_signature torchgen gen_functionalization_type gen_functionalization_definition gen_functionalization_registration gen_functionalization_view_inverse_declaration gen_functionalization_view_meta_classes_decl gen_functionalization_view_meta_classes_impl GenCompositeViewCopyKernel torchgen gen_vmap_plumbing gen_all_vmap_plumbing torchgen model Argument BackendIndex BackendMetadata BaseOperatorName DEFAULT_KERNEL_NAMESPACE dispatch_device_map DispatchKey FRAGMENT_NAMESPACES FunctionSchema is_cuda_dispatch_key is_generic_dispatch_key is_ufunc_dispatch_key is_xpu_dispatch_key Location NativeFunction NativeFunctionsGroup NativeFunctionsViewGroup OperatorName OptionalType SchemaKind SelfArgument STRUCTURED_DISPATCH_KEYS TensorOptionsArguments Type Variant ViewSchemaKind torchgen native_function_generation add_generated_native_functions gen_composite_functional_kernel gen_composite_out_kernel pre_group_native_functions torchgen selective_build selector SelectiveBuilder torchgen utils concatMap context FileManager make_file_manager mapMaybe NamespaceHelper Target torchgen yaml_utils YamlDumper YamlLoader TYPE_CHECKING collections abc Callable Sequence typing Optional T = TypeVar T Welcome ATen code generator v The ATen code generator responsible parsing native_functions yaml then generating various generated files e g TypeDefault cpp based operators defined file This means code generator knows how parse function schema then translate into various C++ types boilerplate code Some things know about file when you modify - This file has STRICT mypy typechecking Typecheck ` mypy -- config mypy-strict ini ` root source directory - Most heavy lifting lives external modules - model has data model native_functions yaml The classes those file represent what you see when you look native_functions yaml - api has conversions how translate JIT schema into various C++ APIs codegen interacts There fact THREE different C++ APIs public C++ API dispatcher API legacy dispatcher API See each these respective files more information ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ HELPER FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ A custom loader YAML let us also keep track line numbers each entry YAML file LineLoader YamlLoader construct_mapping node deep=False type ignore no-untyped-def mapping = super construct_mapping node deep=deep type ignore no-untyped-call Add so line numbering starts mapping __line__ = node start_mark line + mapping Parse native_functions yaml into sequence NativeFunctions Backend Indices ParsedYaml = namedtuple ParsedYaml native_functions backend_indices _GLOBAL_PARSE_NATIVE_YAML_CACHE dict str ParsedYaml = _GLOBAL_PARSE_TAGS_YAML_CACHE dict str set str = file_manager_from_dispatch_key dispatch_key DispatchKey device_fms dict str FileManager default_fm FileManager - FileManager fm = device_fms get next device check device dispatch_device_map items check dispatch_key default_fm fm parse_native_yaml_struct es object valid_tags set str ignore_keys set DispatchKey &#124; None = None path str = stdin skip_native_fns_gen bool = False - ParsedYaml assert isinstance es list rs list NativeFunction = bs dict DispatchKey dict OperatorName BackendMetadata = defaultdict dict e es assert isinstance e dict f expected dict e assert isinstance e get __line__ int e loc = Location path e __line__ funcs = e get func assert funcs None f missed func e context lambda f loc \n funcs func m = NativeFunction from_yaml e loc valid_tags ignore_keys rs append func BackendIndex grow_index bs m error_check_native_functions rs Default dict prevent codegen barfing when we have dispatch key has no kernels yet indices dict DispatchKey BackendIndex = defaultdict lambda BackendIndex dispatch_key=DispatchKey Undefined use_out_as_primary=True external=False device_guard=False I m actually sure about undefined could hit empty TensorList hypothetically could have sizes index= skip_native_fns_gen add_generated_native_functions rs bs k v bs items All structured in-tree operators implemented terms their out operator indices k = BackendIndex dispatch_key=k use_out_as_primary=True external=False Only cuda-like devices tree require device guards device_guard=is_cuda_dispatch_key k is_xpu_dispatch_key k index=v ParsedYaml rs indices parse_tags_yaml_struct es object path str = stdin - set str assert isinstance es list rs set str = set e es assert isinstance e get __line__ int e loc = Location path e __line__ tags = e get tag context lambda f loc \n tags e_i = e copy name = e_i pop tag desc = e_i pop desc ensure each tag has non-empty description assert desc = rs add name rs functools cache parse_tags_yaml path str - set str global _GLOBAL_PARSE_TAGS_YAML_CACHE path _GLOBAL_PARSE_TAGS_YAML_CACHE open path f es = yaml load f Loader=LineLoader _GLOBAL_PARSE_TAGS_YAML_CACHE path = parse_tags_yaml_struct es path=path _GLOBAL_PARSE_TAGS_YAML_CACHE path parse_native_yaml path str tags_yaml_path str ignore_keys set DispatchKey &#124; None = None skip_native_fns_gen bool = False loaded_yaml object &#124; None = None - ParsedYaml global _GLOBAL_PARSE_NATIVE_YAML_CACHE path _GLOBAL_PARSE_NATIVE_YAML_CACHE valid_tags = parse_tags_yaml tags_yaml_path loaded yaml provided use instead reading path loaded_yaml None open path f es = yaml load f Loader=LineLoader es = loaded_yaml _GLOBAL_PARSE_NATIVE_YAML_CACHE path = parse_native_yaml_struct es valid_tags ignore_keys path=path skip_native_fns_gen=skip_native_fns_gen _GLOBAL_PARSE_NATIVE_YAML_CACHE path Some assertions already performed during parsing those only within single NativeFunction Assertions here meant performed across NativeFunctions error_check_native_functions funcs Sequence NativeFunction - None func_map dict OperatorName NativeFunction = base_func_map dict BaseOperatorName list NativeFunction = defaultdict list f funcs func_map f func name = f base_func_map f func name name append f f funcs f structured_delegate None delegate_func = func_map get f structured_delegate assert delegate_func None f f func name marked structured_delegate pointing f f structured_delegate f structured_delegate missing assert delegate_func structured f f func name marked structured_delegate pointing f f structured_delegate f structured_delegate marked structured f Consider adding structured=True delegated operator Check reserved Python keywords PYTHON_RESERVED_KEYWORDS = set keyword kwlist List pre-existing operators known have reserved keywords Exclusion list used suppress assertion these operators EXCLUSION_LIST = _has_compatible_shallow_copy_type random_ uniform_ arg f func arguments flat_all arg name PYTHON_RESERVED_KEYWORDS str f func name arg name EXCLUSION_LIST raise AssertionError f Argument name arg name function f func name reserved Python keyword See Note resize_ Functionalization resize_ technically inplace view op therefore needs tag would overkill add true view variant resize Instead resize_ gets special treatment functionalization we have resize op non-aliasing + functional inplace_view f tags str f func name = resize_ str f func name = resize_as_ str f func name name = set_ base_name = f func name name assert base_name inplace f f func name marked tag inplace_view doesn t follow naming convention inplace ops - codegen expects base name have trailing underscore out_of_place_base_name = BaseOperatorName base_name base False base_name dunder_method assert len base_func_map out_of_place_base_name f f func name marked tag inplace_view The codegen expects there corresponding f out-of-place view op name base_name matching schema didn t find one cpp_string s str - str Convert python string into c++ string literal s = s replace \\ \\\\ s = s replace \\ s = s replace \a \\a s = s replace \b \\b s = s replace \f \\f s = s replace \n \\n s = s replace \v \\v s = s replace \t \\t f s ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C++ CODE GENERATION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Most functions section curried they consist function takes some parameters e g what generated which itself returns function actually maps NativeFunction code generated This pattern makes convenient use map concatMap similar functional combinators static_dispatch_keys backends list BackendIndex - list DispatchKey len backends == backend dispatch_key backend backends + DispatchKey CompositeImplicitAutograd DispatchKey CompositeImplicitAutogradNestedTensor DispatchKey CompositeExplicitAutograd DispatchKey CompositeExplicitAutogradNonFunctional get_static_dispatch_backend f NativeFunction backend_index BackendIndex - DispatchKey &#124; None f structured_delegate None backend_index has_kernel f TODO ops structured_delegate should check dispatch table out variant instead For now these structured ops all have CPU CUDA kernels so we always dispatch ` backend ` could wrong when we migrate math default_backend ops use structured delegate backend_index dispatch_key f has_composite_explicit_autograd_kernel DispatchKey CompositeExplicitAutograd f has_composite_explicit_autograd_non_functional_kernel DispatchKey CompositeExplicitAutogradNonFunctional f has_composite_implicit_autograd_kernel DispatchKey CompositeImplicitAutograd f has_composite_implicit_autograd_nested_tensor_kernel DispatchKey CompositeImplicitAutogradNestedTensor None static_dispatch_ops_header f NativeFunction backend_index list BackendIndex - str &#124; None backend_index None f manual_kernel_registration None output = index backend_index dispatch_key = get_static_dispatch_backend f index dispatch_key None output append f #include ATen ops f root_name _ dispatch_key lower _dispatch h \n join output static_dispatch_extra_headers backends list BackendIndex - list str f #include ATen dispatch_key Functions h dispatch_key static_dispatch_keys backends Translates arguments ` sig ` CppSignature bindings Note we have special case ` memory_format ` argument case covered tools codegen api translate yet its application limited static dispatch translate_args sig CppSignature &#124; DispatcherSignature cpp_sig CppSignature - str Adds SpecialArgName possibly_redundant_memory_format NamedCType memory_format bindings add_spl_memory_format_binding input_bindings list Binding - list Binding output_bindings list Binding = binding input_bindings binding name == memory_format spl_mem_format_binding = Binding nctype=NamedCType SpecialArgName possibly_redundant_memory_format binding nctype type name=binding name default=binding default argument=binding argument output_bindings append spl_mem_format_binding output_bindings append binding output_bindings src_bindings = list sig arguments goal_bindings = list cpp_sig arguments When last argument CPP signature has SpecialArgName possibly_redundant_memory_format NCType get memory_format bindings dispatcher signature have same NCType well arg goal_bindings arg nctype name == SpecialArgName possibly_redundant_memory_format src_bindings = add_spl_memory_format_binding src_bindings break exprs = translate src_bindings goal_bindings join expr exprs generate_static_dispatch_backend_call sig CppSignature &#124; DispatcherSignature f NativeFunction backend_index BackendIndex - str cpp_sig = gen_static_dispatch_backend_call_signature sig f name = cpp_sig name exprs = translate_args sig cpp_sig backend_metadata = backend_index get_kernel f kernel_ns = backend_metadata cpp_namespace backend_metadata backend_metadata cpp_namespace DEFAULT_KERNEL_NAMESPACE ns = kernel_ns replace native f ns backend_index dispatch_key lower name exprs generate_static_dispatch_fallback_call sig CppSignature &#124; DispatcherSignature f NativeFunction backend_indices list BackendIndex - str cpp_sigs = CppSignatureGroup from_native_function f method=False fallback_binding=False sig symint f func has_symint cpp_sig = cpp_sigs symint_signature cpp_sig = cpp_sigs signature assert cpp_sig None name = cpp_sig name exprs = translate_args sig cpp_sig ns = DEFAULT_KERNEL_NAMESPACE replace native f has_composite_explicit_autograd_kernel f ns DispatchKey CompositeExplicitAutograd lower name exprs f has_composite_explicit_autograd_non_functional_kernel f ns DispatchKey CompositeExplicitAutogradNonFunctional lower name exprs f has_composite_implicit_autograd_kernel f ns DispatchKey CompositeImplicitAutograd lower name exprs f has_composite_implicit_autograd_nested_tensor_kernel f ns DispatchKey CompositeImplicitAutogradNestedTensor lower name exprs f TORCH_CHECK false Static dispatch does support name for\ join str index dispatch_key index backend_indices static_dispatch sig CppSignature &#124; DispatcherSignature f NativeFunction backend_indices list BackendIndex - str For given ` NativeFunction ` find out corresponding backend dispatch If more than one backends exist fallback static dispatch determining dispatch key inputs Arguments sig A CppSignature DispatcherSignature native function we want use f NativeFunction generate static dispatch backend_indices All available backends Return C++ code call backend-specific functions e g cpu add other scale len backend_indices == f manual_kernel_registration keys = b b backend_indices b has_kernel f f structured_delegate None b dispatch_key STRUCTURED_DISPATCH_KEYS len keys == generate_static_dispatch_backend_call sig f keys len keys == generate_static_dispatch_fallback_call sig f backend_indices native_tensor_args = name sig arguments isinstance argument SelfArgument isinstance argument Argument argument type is_tensor_like tensor_args = join native_tensor_args tensor_opts = f func arguments tensor_options stmts = subexprs list str = tensor_opts None subexprs append DispatchKeySet c computeDispatchKey dtype layout device tensor_args = subexprs append f c detail multi_dispatch_key_set tensor_args stmts append f DispatchKeySet _dk_set = &#124; join subexprs stmts append DispatchKey _dk = c highestPriorityBackendTypeId _dk_set dispatch_code = index keys dispatch_code append f case DispatchKey index dispatch_key dispatch_code append f \t generate_static_dispatch_backend_call sig f index fallback = generate_static_dispatch_fallback_call sig f backend_indices connector = \n\t\t f connector join stmts switch _dk connector join dispatch_code default fallback Generates RegisterSchema cpp Depending selector either all schemas registered only some case selective build dataclass frozen=True RegisterSchema selector SelectiveBuilder known_tags dict str int = field default_factory=dict method_with_native_function __call__ f NativeFunction - str &#124; None selector is_native_function_selected f None tags = + join f Tag tag tag sorted f tags + tags == f m cpp_string str f func \n maybe_tags = tags known_tags idx = len known_tags known_tags tags = idx maybe_tags = f const std vector Tag tags_ idx = tags \n f maybe_tags m cpp_string str f func tags_ known_tags tags \n Generates Operators h Operators cpp These provide macros given operator overload name allow users access un-overloaded function version operator This useful extension writers who want want decltype operator don t want worry about method-only operators dataclass frozen=True ComputeOperators target Literal Target DECLARATION Target DEFINITION static_dispatch_backend_indices list BackendIndex method_with_native_function __call__ f NativeFunction - str sig = DispatcherSignature from_schema f func name = f func name unambiguous_name target Target DECLARATION Note The ATen Operators API The ATen Operators API lives _ops namespace contains compile-time metadata about each operator + entry points into Dispatcher The C++ function method redispatch API s all implemented wrappers into various bits structs defined here Important characteristics about Operators API It follows Dispatcher API This kind necessary avoid overhead For example followed C++ API then all faithful C++ factory functions would need wrap their arguments into TensorOptions only unwrap them again Overload names disambiguated This helpful pytorch extenders who would like decltype aten operator has overloads e g decltype _ops mul_Tensor call No argument defaulting allowed This more implementation detail avoid #include cycles since TensorBody h which defines Tensor needs include file manual_cpp_bindings faithful names included API This applies stuff like __dispatch__is_complex add_outf These aren t real aten ops they re just additional functions provided C++ API They re implemented wrappers Functions h call into actual operators defined here i e _ops is_complex call _ops add_out call This means ATEN_OP is_complex will fastpath will go through dispatcher f struct TORCH_API name using schema = sig type using ptr_schema = schema See Note static constexpr char members windows NVCC static constexpr const char name = aten f func name name static constexpr const char overload_name = f func name overload_name static constexpr const char schema_str = cpp_string str f func static sig defn name= call is_redispatching_fn=False static sig defn name= redispatch is_redispatching_fn=True target Target DEFINITION defns = f aten f func static C _NOINLINE c TypedOperatorHandle name schema create_ name _typed_handle c Dispatcher singleton findSchemaOrThrow name name name overload_name typed name schema is_redispatching_fn False True is_redispatching_fn dispatcher_exprs_str = join dispatchKeySet + name sig arguments method_base = redispatch dispatcher_exprs_str = join name sig arguments method_base = call dispatcher_call = method_base method_name = f name method_base fn_body = f static auto op = create_ name _typed_handle op dispatcher_call dispatcher_exprs_str is_redispatching_fn len static_dispatch_backend_indices call should go through static dispatch fn_body = static_dispatch sig f backend_indices=self static_dispatch_backend_indices defns += f aten f func sig defn name=method_name is_redispatching_fn=is_redispatching_fn fn_body defns assert_never target Generates Functions h which provides functional public C++ API scaffolding call into dispatcher these functions dataclass frozen=True ComputeFunction method_with_native_function __call__ f NativeFunction - str &#124; None sig_group = CppSignatureGroup from_native_function f method=False fallback_binding=f manual_cpp_binding has_symint = f func has_symint result = sig sig_group signatures See Note The ATen Operators API target_sig = DispatcherSignature from_schema f func exprs = translate sig arguments target_sig arguments exprs_str = join e expr e exprs sig symint intlike_t = c SymInt intlike_t = int _t Variant function f variants result += f aten f func inline sig decl _ops f func name unambiguous_name call exprs_str The template function can used template situations where you want switch between symint version depending template argument NB we ALWAYS generate even methods But we put header so can take advantage per-op headers has_symint result += f namespace symint template typename T typename = std enable_if_t std is_same_v T intlike_t sig decl suppress_symint_suffix=True _ops f func name unambiguous_name call exprs_str result Generates TensorBody h This file provides object-oriented method-based public C++ API scaffolding call into dispatcher these functions dataclass frozen=True ComputeTensorMethod target Literal Target DECLARATION Target DEFINITION static_dispatch_backend_indices list BackendIndex method_with_native_function __call__ f NativeFunction - str &#124; None Variant method f variants None assert f func is_out_fn assert f func arguments self_arg None sig_group = CppSignatureGroup from_native_function f method=True fallback_binding=f manual_cpp_binding target Target DECLARATION result = sig sig_group signatures result += f sig decl const \n result target Target DEFINITION assert_never target result = sig sig_group signatures target_sig = DispatcherSignature from_schema f func exprs = translate sig arguments target_sig arguments method=True exprs_str = join e expr e exprs result += f aten f func inline sig defn prefix= Tensor const _ops f func name unambiguous_name call exprs_str result Generates RedispatchFunctions h This similar C++ API defined Functions h provides access dispatcher s redispatch API dataclass frozen=True ComputeRedispatchFunction method_with_native_function __call__ f NativeFunction - str &#124; None We unconditionally generate function variants redispatch API This mainly because we can namespace functions separately methods sig_group = CppSignatureGroup from_native_function f method=False fallback_binding=f manual_cpp_binding result = sig sig_group signatures target_sig = DispatcherSignature from_schema f func exprs = translate sig arguments target_sig arguments exprs_str = join dispatchKeySet + expr exprs result += f aten f func inline sig decl is_redispatching_fn=True _ops f func name unambiguous_name redispatch exprs_str result Generates ATenOpList cpp runtime accessible list all aten operators TODO This historically used help some JIT interop code figure out whether treat aten namespace d operators one way another we should reevaluate actually needed with_native_function compute_aten_op f NativeFunction - str f aten f func name name f func name overload_name Generates MetaFunctions h compute_meta_function_declaration g NativeFunctionsGroup - str &#124; None g structured None native_function_manager g out name = meta name g args = structured meta_arguments g args_str = join decl args parent_class = g out structured_inherits parent_class None parent_class = impl MetaBase meta_return = void precomputed = g out precomputed g structured None precomputed Generate template declaration one bool parameter each precomputed element Each parameter true corresponding terms position precomputed element has been set precomputed_values = precomputed replace values precomputed add precomputed_elements = elem replace_list precomputed_values elem replace_list precomputed_template_parameters = elem name upper elem precomputed_elements precomputed_template_params_str = join f bool param = false param precomputed_template_parameters precompute_template_decl = f template precomputed_template_params_str Generate string containing declarations all precomputed elements precomputed_elements_with_cpp_types = structured argument_type elem binds=elem name elem precomputed_elements precomputed_elements_decl = \n join f elem cpp_type strip_ref=True elem name elem precomputed_elements_with_cpp_types Generate setter methods each precomputed element Each method will new instance precompute_out template parameter corresponds member set method true indicate has been set setter_methods = i elem enumerate precomputed_elements Generate signature The type will same type ` ` template parameter corresponding element set method set true The assert generated below will ensure template parameter false type ` ` return_ty_templates = join precomputed_template_parameters i + true + precomputed_template_parameters i + return_ty = f precompute_out return_ty_templates elem_cpp_ty = precomputed_elements_with_cpp_types i cpp_type strip_ref=True signature = f return_ty set_ elem name elem_cpp_ty value Generate assert which checks template parameter corresponding precomputed element set method false corresponding object ` ` points This ensures each element can set only once assert_msg = f elem name already set assert_stmt = f static_assert precomputed_template_parameters i == false assert_msg Generate new object construction block All state except element method sets copied object ` ` points The value element method sets taken method parameter construction_stmts = construction_stmts append f return_ty ret j elem enumerate precomputed_elements i == j construction_stmts append f ret elem name = value construction_stmts append f ret elem name = this- elem name construction_stmts append ret construction_block = \n join construction_stmts setter_methods append f signature assert_stmt construction_block setter_methods_decl = \n join setter_methods Meta should instance struct containing precomputed elements meta_return_template_params = join true len precomputed_template_parameters This typedef actually using statement needed so TORCH_META_FUNC can reuse type which has variable number template parameters meta_return_typedef = f using meta_return_ty = precompute_out meta_return_template_params meta_return = meta_return_ty precomputed_decl = f precompute_template_decl struct TORCH_API precompute_out setter_methods_decl precomputed_elements_decl meta_return_typedef = precomputed_decl = f \ struct TORCH_API structured_ name public parent_class precomputed_decl meta_return_typedef meta_return meta args_str needs_backend_select f NativeFunction selector SelectiveBuilder - bool name = str f func name name name endswith _like name startswith new_ False f func arguments tensor_options None False selector is_native_function_selected f Generates RegisterBackendSelect cpp series kernels which provide specialized computation dispatch key operator signatures which cannot easily done automatically using templating dataclass frozen=True ComputeBackendSelect target Literal Target DEFINITION Target REGISTRATION Selector object determine which operators generate registration code selector SelectiveBuilder method_with_native_function __call__ f NativeFunction - str &#124; None needs_backend_select f selector None name = native name f func BackendSelect can go Meta so must preserve symints native_sig = NativeSignature f func symint=True native_tensor_args = native_sig arguments isinstance argument Argument argument type is_tensor_like dispatcher_sig = DispatcherSignature from_schema f func sig NativeSignature &#124; DispatcherSignature sig = dispatcher_sig dispatcher_exprs = dispatcher_sig exprs dispatch_key = c computeDispatchKey dtype layout device target Target DEFINITION I don t think there s actually good reason generate these two cases differently The first case could probably improved though- calls computeDispatchKeySet which looks TLS dispatch keys- there should any time we reach backend select native_tensor_args assert f func arguments has_tensor_arg tensor_args = join name native_tensor_args compute_dk = f \ DispatchKeySet _dk_set = c DispatchKeySet dispatch_key &#124; c detail multi_dispatch_key_set tensor_args DispatchKeySet _dk_mask = c DispatchKeySet DispatchKeySet FULL_AFTER DispatchKey BackendSelect DispatchKeySet _dk = c impl computeDispatchKeySet _dk_set _dk_mask assert f func arguments has_tensor_arg compute_dk = f DispatchKeySet _dk = c DispatchKeySet dispatch_key f \ aten f func C _ALWAYS_INLINE sig defn name compute_dk _ops f func name unambiguous_name redispatch _dk join expr dispatcher_exprs target Target REGISTRATION f m impl aten f func name TORCH_FN name assert_never target ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ YAML CODE GENERATION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ format_yaml data object - str Ignore alias Dumper YamlDumper ignore_aliases = lambda data True type ignore assignment Support serializing OrderedDict dict_representer dumper Any data Any - Any dumper represent_dict data items YamlDumper add_representer OrderedDict dict_representer type ignore no-untyped-call Some yaml parsers e g Haskell s don t understand line breaks width= e turns off optional line breaks improves portability outputted yaml yaml dump data default_flow_style=False Dumper=YamlDumper width= e type ignore no-any-return call-overload For some reason some defaults we write YAML written native YAML objects rather than doing them uniformly strings This function detects those cases converts them into native Python objects pythonify_default s str - object s == true True s == false False try int s except ValueError try float s except ValueError s What dynamic type Over time semantic meaning dynamic type has degraded meaninglessness old days captured dtype-ness types has gone away removal TH These days s mostly same thing C++ API argument type except Tensor Tensor arguments simply present Tensor TODO Get rid dynamic_type after getting tools autograd use new codegen framework dynamic_type t Type - str isinstance t OptionalType dynamic_type t elem Note we don t use t is_tensor_like here because would also include Tensor str t == Tensor Tensor This legacy concept so never report SymInt cpp argumenttype_type t mutable=False binds= __placeholder__ symint=False cpp_type compute_method_of_yaml variants set Variant - list str This written out explicitly ensure Tensor namespace put into list right order method_of = Type Variant method variants method_of append Tensor Variant function variants method_of append namespace method_of compute_returns_yaml f NativeFunction - tuple list dict str str dict str str Note name field_name ~~~~~~~~~~~~~~~~~~~~~~~~~~ To understand name_to_field_name we must first talk about schema lstsq X Tensor Tensor A Tensor X Tensor b qr - Tensor solution Tensor b QR There something very odd about schema out variant function say will convert into lstsq_out C++ API names output arguments don t match keyword argument names inputs It TURNS OUT situation historical Declarations yaml we want output abbreviated only show relevant fields arguments - field_name solution name X - field_name QR name qr returns - field_name solution name X - field_name QR name qr The name fields stored field_name name arguments stored name So when we process arguments we need way get corresponding At moment most conveniently done constructing mapping name argument concept field_name concept while processing arguments since we don t directly maintain correspondence modeling function schema itself See also https github com pytorch pytorch issues name_to_field_name dict str str = Compute returns field YAML entry names = cpp return_names f returns = i r name enumerate zip f func returns names ret = dynamic_type dynamic_type r type name name legacy report ints type cpp return_type r symint=False cpp_type r name See Note name field_name ret field_name = r name f func is_out_fn name_to_field_name f func arguments out i name = r name returns append ret returns name_to_field_name arguments yaml roughly corresponds public C++ API compute_cpp_argument_yaml cpp_a Binding schema_order bool kwarg_only_set set str out_arg_set set str name_to_field_name dict str str - object isinstance cpp_a argument TensorOptionsArguments arg dict str object = annotation None dynamic_type TensorOptions is_nullable False name cpp_a name type cpp_a type kwarg_only True cpp_a default None arg default = cpp_a default arg isinstance cpp_a argument SelfArgument raise AssertionError isinstance cpp_a argument Argument compute_argument_yaml cpp_a argument schema_order=schema_order kwarg_only_set=kwarg_only_set out_arg_set=out_arg_set name_to_field_name=name_to_field_name compute_argument_yaml Argument schema_order bool kwarg_only_set set str out_arg_set set str name_to_field_name dict str str - object arg dict str object = annotation str annotation annotation None dynamic_type dynamic_type type is_nullable type is_nullable name name legacy report ints type cpp argument_type binds= __placeholder__ symint=False cpp_type default None arg default = pythonify_default cpp default_expr default type symint=False name kwarg_only_set arg kwarg_only = True name out_arg_set arg output = True arg allocate = True See Note name field_name name name_to_field_name arg field_name = name_to_field_name name Historically booleans don t get their size recorded because already built into cpp type e g std array bool l = type is_list_like l None l size None str l elem = bool arg size = l size arg with_native_function compute_declaration_yaml f NativeFunction - object returns name_to_field_name = compute_returns_yaml f These sets used conveniently test argument kwarg-only out argument kwarg_only_set = name f func arguments flat_kwarg_only out_arg_set = name f func arguments out sig_group = CppSignatureGroup from_native_function f method=False fallback_binding=False cpp_args = sig_group signature arguments arguments = compute_cpp_argument_yaml cpp_a schema_order=False kwarg_only_set=kwarg_only_set out_arg_set=out_arg_set name_to_field_name=name_to_field_name cpp_a cpp_args schema_order_jit_arguments = list f func schema_order_arguments schema_order_arguments = compute_argument_yaml schema_order=True kwarg_only_set=kwarg_only_set out_arg_set=out_arg_set name_to_field_name=name_to_field_name schema_order_jit_arguments cpp_schema_order_types = NB method here doesn t matter r type schema_order_jit_arguments r cpp argument method=False cpp_no_default_args=set faithful=False symint=False has_tensor_options=False legacy report ints cpp_returns = cpp returns_type f func returns symint=False cpp_type schema_order_cpp_signature = f cpp_returns join cpp_schema_order_types is_factory_method = any isinstance argument TensorOptionsArguments cpp_args Variant method f variants OrderedDict name cpp name f func operator_name str f func name name overload_name str f func name overload_name manual_kernel_registration f manual_kernel_registration category_override f category_override f category_override None schema_string f aten f func arguments arguments schema_order_cpp_signature schema_order_cpp_signature schema_order_arguments schema_order_arguments method_of compute_method_of_yaml f variants mode native python_module f python_module None f python_module returns returns inplace f func name name inplace is_factory_method is_factory_method abstract f is_abstract device_guard f device_guard with_gil False deprecated False has_math_kernel f has_composite_implicit_autograd_kernel See Note Auto generated composite kernels has_autogenerated_composite_kernel f NativeFunction - bool f structured f structured_delegate None f func kind == SchemaKind functional f func kind == SchemaKind inplace with_native_function_and_indices compute_registration_declarations f NativeFunction backend_indices dict DispatchKey BackendIndex - str name = dispatcher name f func returns_type = dispatcher returns_type f func returns cpp_type args = dispatcher arguments f func args_str = join no_default decl args comment_data dict str str = schema f aten f func TODO What exactly semantics dispatch field dispatch str k k v backend_indices items v has_kernel f = DispatchKey CompositeImplicitAutograd k k v backend_indices items v has_kernel f = DispatchKey CompositeImplicitAutograd DispatchKey CompositeImplicitAutogradNestedTensor default str f has_composite_kernel has_autogenerated_composite_kernel f f returns_type name args_str json dumps comment_data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN IT ALL ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ get_custom_build_selector provided_op_registration_allowlist list str &#124; None op_selection_yaml_path str &#124; None - SelectiveBuilder assert provided_op_registration_allowlist None op_selection_yaml_path None Both provided_op_registration_allowlist + op_selection_yaml_path can NOT provided + same time op_registration_allowlist set str &#124; None = None provided_op_registration_allowlist None op_registration_allowlist = set provided_op_registration_allowlist op_registration_allowlist None selector = SelectiveBuilder from_legacy_op_registration_allow_list op_registration_allowlist True False op_selection_yaml_path None selector = SelectiveBuilder from_yaml_path op_selection_yaml_path selector = SelectiveBuilder get_nop_selector selector get_grouped_by_view_native_functions native_functions Sequence NativeFunction - Sequence NativeFunction &#124; NativeFunctionsViewGroup maybe_create_view_group d dict ViewSchemaKind &#124; SchemaKind NativeFunction - list NativeFunction &#124; NativeFunctionsViewGroup funcs list NativeFunction &#124; NativeFunctionsViewGroup = ViewSchemaKind aliasing d view = d pop ViewSchemaKind aliasing view_inplace = d pop ViewSchemaKind aliasing_inplace None view_copy = d pop SchemaKind functional None funcs append NativeFunctionsViewGroup view=view view_copy=view_copy view_inplace=view_inplace Take remaining functions weren t part view group emit them separately funcs extend d values funcs grouped_by_views dict FunctionSchema dict SchemaKind &#124; ViewSchemaKind NativeFunction = defaultdict dict f native_functions schema = f func view_signature view_kind ViewSchemaKind = f view_schema_kind We need group up ops relevant same view consisting view op ViewSchemaKind aliasing view_inplace op ViewSchemaKind aliasing_inplace view_copy op SchemaKind functional view_kind == ViewSchemaKind non_aliasing kind = f func kind assert kind grouped_by_views schema grouped_by_views schema kind = f assert view_kind grouped_by_views schema f view_kind already grouped_by_views schema keys grouped_by_views schema view_kind = f list concatMap maybe_create_view_group grouped_by_views values get_grouped_native_functions native_functions Sequence NativeFunction - Sequence NativeFunction &#124; NativeFunctionsGroup flatten_pre_group d dict SchemaKind NativeFunction - Sequence NativeFunction &#124; NativeFunctionsGroup r = NativeFunctionsGroup from_dict d r None Invariant any NativeFunctions code-generated should have been grouped into NativeFunctionsGroup objects assert any generated f tags f d values list d values r TODO how come ValuesView isn t Sequence lol pre_grouped_native_functions = pre_group_native_functions native_functions list concatMap flatten_pre_group list pre_grouped_native_functions values get_ns_grouped_kernels grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup backend_indices dict DispatchKey BackendIndex native_function_decl_gen Callable NativeFunctionsGroup &#124; NativeFunction BackendIndex list str = dest compute_native_function_declaration - dict str list str ns_grouped_kernels dict str list str = defaultdict list f grouped_native_functions native_function_namespaces = set dispatch_keys = set dispatch_key backend_idx backend_indices items backend_metadata = backend_idx get_kernel f backend_metadata namespace = backend_metadata cpp_namespace dispatch_keys add dispatch_key native_function_namespaces add namespace namespace = DEFAULT_KERNEL_NAMESPACE assert len native_function_namespaces = f Codegen only supports one namespace per operator got native_function_namespaces dispatch_keys ns_grouped_kernels namespace extend native_function_decl_gen f backend_idx ns_grouped_kernels get_native_function_declarations_from_ns_grouped_kernels ns_grouped_kernels dict str list str - list str declarations list str = newline = \n namespace kernels ns_grouped_kernels items ns_helper = NamespaceHelper namespace_str=namespace entity_name= max_level= Convert set first remove duplicate kernel names Backends allowed repeat kernel names only generate declaration once ordered_kernels = list OrderedDict fromkeys kernels declarations extend f ns_helper prologue newline join ordered_kernels ns_helper epilogue split newline declarations Return native function declarations grouped their namespaces get_native_function_declarations grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup backend_indices dict DispatchKey BackendIndex native_function_decl_gen Callable NativeFunctionsGroup &#124; NativeFunction BackendIndex list str = dest compute_native_function_declaration - list str Generate kernel declarations ` NativeFunction s h ` param grouped_native_functions sequence ` NativeFunction ` ` NativeFunctionGroup ` param backend_indices kernel collections grouped dispatch key param native_function_decl_gen callable generate kernel declaration each ` NativeFunction ` list string string all declarations grouped namespaces split newline ns_grouped_kernels = get_ns_grouped_kernels grouped_native_functions=grouped_native_functions backend_indices=backend_indices native_function_decl_gen=native_function_decl_gen get_native_function_declarations_from_ns_grouped_kernels ns_grouped_kernels=ns_grouped_kernels get_kernel_namespace f NativeFunction &#124; NativeFunctionsGroup backend_idx BackendIndex - str backend_metadata = backend_idx get_kernel f assert backend_metadata native backend_metadata cpp_namespace f The kernel function f func name isinstance f NativeFunction f functional func name f dispatch key backend_idx dispatch_key f has namespace backend_metadata cpp_namespace s ending native backend_metadata cpp_namespace backend_metadata DEFAULT_KERNEL_NAMESPACE Return native function definitions grouped dispatch key custom namespace Used RegisterDispatchKey cpp etc get_native_function_definitions fm FileManager grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup dispatch_key DispatchKey backend_idx BackendIndex selector SelectiveBuilder rocm bool symint bool skip_dispatcher_op_registration bool gen_dispatch_helpers bool - list str definitions list str = ns_definitions dict str list str = defaultdict list anonymous_definitions dict str list str = defaultdict list registrations dict str dict str list str = defaultdict dict newline = \n ns_gen = dest RegisterDispatchKey backend_idx Target NAMESPACED_DEFINITION selector rocm=rocm symint=symint class_method_name=None skip_dispatcher_op_registration=skip_dispatcher_op_registration anonymous_gen = dest RegisterDispatchKey backend_idx Target ANONYMOUS_DEFINITION selector rocm=rocm symint=symint class_method_name=None skip_dispatcher_op_registration=skip_dispatcher_op_registration reg_gen = dest RegisterDispatchKey backend_idx Target REGISTRATION selector rocm=rocm symint=symint class_method_name=None skip_dispatcher_op_registration=skip_dispatcher_op_registration f grouped_native_functions kernel_namespace = get_kernel_namespace f=f backend_idx=backend_idx replace native ns_definitions kernel_namespace extend ns_gen f anonymous_definitions kernel_namespace extend anonymous_gen f namespace = f namespace isinstance f NativeFunction f functional namespace namespace registrations kernel_namespace registrations kernel_namespace = defaultdict list registrations kernel_namespace namespace extend reg_gen f kernel_namespace ns_definitions len ns_definitions kernel_namespace == continue ns_helper = NamespaceHelper namespace_str=kernel_namespace registration_body = namespace registrations kernel_namespace registrations kernel_namespace namespace continue registration_body += f TORCH_LIBRARY_IMPL namespace dispatch_key m newline join registrations kernel_namespace namespace definitions extend fm substitute_with_template RegisterDispatchDefinitions ini lambda ns_prologue ns_helper prologue ns_epilogue ns_helper epilogue dispatch_anonymous_definitions anonymous_definitions kernel_namespace static_init_dispatch_registrations skip_dispatcher_op_registration registration_body deferred_dispatch_registrations dispatch_namespace dispatch_key lower dispatch_namespaced_definitions ns_definitions kernel_namespace split newline definitions Return native function declarations grouped dispatch key custom namespace Used CPUFunctions_inl h etc get_namespaced_declaration grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup dispatch_key DispatchKey backend_idx BackendIndex selector SelectiveBuilder rocm bool symint bool - list str declarations list str = ns_grouped_kernels dict str list str = defaultdict list newline = \n func = dest RegisterDispatchKey backend_idx Target NAMESPACED_DECLARATION selector rocm=rocm class_method_name=None skip_dispatcher_op_registration=False symint=symint f grouped_native_functions namespace = get_kernel_namespace f=f backend_idx=backend_idx replace native dispatch_key lower ns_grouped_kernels namespace extend func f namespace kernels ns_grouped_kernels items len kernels == continue ns_helper = NamespaceHelper namespace_str=namespace entity_name= max_level= ordered_kernels = list OrderedDict fromkeys kernels declarations extend f ns_helper prologue newline join ordered_kernels ns_helper epilogue split newline declarations Return native function schema registration code aten other namespaces get_native_function_schema_registrations native_functions Sequence NativeFunction schema_selector SelectiveBuilder - tuple list str str ns_native_functions dict str list NativeFunction = defaultdict list native_function native_functions ns_native_functions native_function namespace append native_function schema_registrations = aten_schema_registrations = custom_namespace = None namespace funcs ns_native_functions items schema_registrations_body = list mapMaybe RegisterSchema schema_selector funcs NB we have separate aten namespace registration other namespaces because template we hardcoded operator ATen already namespace == aten aten_schema_registrations = schema_registrations_body custom_namespace = namespace tab = \t namespace predefined we should use define library fragment instead new library torch_library_macro = TORCH_LIBRARY_FRAGMENT namespace FRAGMENT_NAMESPACES TORCH_LIBRARY schema_registrations += f torch_library_macro custom_namespace m tab join schema_registrations_body aten_schema_registrations schema_registrations gen_aggregated_headers native_functions Sequence NativeFunction grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup structured_native_functions Sequence NativeFunctionsGroup static_dispatch_idx list BackendIndex selector SelectiveBuilder backend_indices dict DispatchKey BackendIndex cpu_fm FileManager device_fms dict str FileManager functions_keys set DispatchKey dispatch_keys Sequence DispatchKey rocm bool - None Buck doesn t support dynamic output files so we aggregate all operator headers into single file cpu_fm write NativeMetaFunctions h lambda NativeMetaFunctions_includes NativeMetaFunctions_declarations list mapMaybe compute_meta_function_declaration structured_native_functions method_native_functions = fn fn native_functions Variant method fn variants non_method_native_functions = fn fn native_functions fn method_native_functions cpu_fm write MethodOperators h lambda MethodOperators_includes MethodOperators_declarations list mapMaybe ComputeOperators Target DECLARATION static_dispatch_backend_indices=static_dispatch_idx method_native_functions cpu_fm write Operators h lambda Operators_includes #include ATen MethodOperators h Operators_declarations list mapMaybe ComputeOperators Target DECLARATION static_dispatch_backend_indices=static_dispatch_idx non_method_native_functions cpu_fm write Functions h lambda static_dispatch_extra_headers static_dispatch_extra_headers static_dispatch_idx Functions_includes #include ATen Operators h Functions_declarations list mapMaybe ComputeFunction native_functions declarations = get_native_function_declarations grouped_native_functions=grouped_native_functions backend_indices=backend_indices cpu_fm write NativeFunctions h lambda NativeFunctions_includes #include ATen NativeMetaFunctions h NativeFunctions_declarations declarations dispatch_key dispatch_keys fm = file_manager_from_dispatch_key dispatch_key device_fms cpu_fm dispatch_key functions_keys inl_headers = f #include ATen dispatch_key Functions_inl h fm write_with_template f dispatch_key Functions h DispatchKeyFunctions h lambda dispatch_key str dispatch_key inline_headers inl_headers fm write_with_template f dispatch_key Functions_inl h DispatchKeyFunctions_inl h lambda DispatchKeyFunctions_inl_includes dispatch_namespace dispatch_key lower dispatch_namespaced_declarations get_namespaced_declaration grouped_native_functions=grouped_native_functions dispatch_key=dispatch_key backend_idx=backend_indices dispatch_key selector=selector rocm=rocm symint=True del fm gen_per_operator_headers native_functions Sequence NativeFunction grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup static_dispatch_idx list BackendIndex selector SelectiveBuilder backend_indices dict DispatchKey BackendIndex cpu_fm FileManager device_fms dict str FileManager ops_fm FileManager functions_keys set DispatchKey dispatch_keys Sequence DispatchKey rocm bool - None For CMake builds split operator declarations into separate headers ATen ops folder split up header dependencies functions_by_root_name dict str list NativeFunction = defaultdict list fn native_functions functions_by_root_name fn root_name append fn grouped_functions_by_root_name dict str list NativeFunction &#124; NativeFunctionsGroup = defaultdict list group grouped_native_functions name = group root_name grouped_functions_by_root_name name append group name functions functions_by_root_name items ops_fm write_with_template f name _ops h Operator h lambda declarations list mapMaybe ComputeOperators Target DECLARATION static_dispatch_backend_indices=static_dispatch_idx functions ops_fm write_with_template f name h Function h lambda static_dispatch_ops_headers list mapMaybe lambda fn static_dispatch_ops_header fn backend_index=static_dispatch_idx functions operator_includes f #include ATen ops name _ops h function_definitions list mapMaybe ComputeFunction functions grouped_functions = grouped_functions_by_root_name get name structured_functions = fn fn grouped_functions isinstance fn NativeFunctionsGroup fn structured is_structured = len structured_functions is_structured ops_fm write_with_template f name _meta h NativeMetaFunction h lambda meta_function_declarations list mapMaybe compute_meta_function_declaration structured_functions declarations = get_native_function_declarations grouped_native_functions=grouped_functions backend_indices=backend_indices native_function_decl_gen=dest compute_native_function_declaration ops_fm write_with_template f name _native h NativeFunction h lambda extra_includes f #include ATen ops name _meta h is_structured native_function_declarations declarations category suffix Functions Operators _ops NativeMetaFunctions _meta NativeFunctions _native cpu_fm write f category h lambda f category _includes f #include ATen ops name suffix h name sorted functions_by_root_name keys f category _declarations dispatch_key dispatch_keys dispatch_key functions_keys continue dispatch_namespace = dispatch_key lower dispatch_names = name functions functions_by_root_name items grouped_functions = grouped_functions_by_root_name get name declarations = list concatMap dest RegisterDispatchKey backend_indices dispatch_key Target NAMESPACED_DECLARATION selector rocm=rocm symint=True class_method_name=None skip_dispatcher_op_registration=False grouped_functions len declarations == continue dispatch_names append name ops_fm write_with_template f name _ dispatch_namespace _dispatch h DispatchKeyFunction h lambda dispatch_namespace dispatch_namespace dispatch_namespaced_declarations declarations fm = file_manager_from_dispatch_key dispatch_key device_fms cpu_fm inl_headers = f #include ATen dispatch_key Functions_inl h fm write_with_template f dispatch_key Functions h DispatchKeyFunctions h lambda dispatch_key str dispatch_key inline_headers inl_headers fm write_with_template f dispatch_key Functions_inl h DispatchKeyFunctions_inl h lambda dispatch_namespace dispatch_namespace DispatchKeyFunctions_inl_includes f #include ATen ops name _ dispatch_namespace _dispatch h name sorted dispatch_names dispatch_namespaced_declarations del fm cpu_fm write MethodOperators h lambda MethodOperators_includes sorted f #include ATen ops name _ops h name functions functions_by_root_name items any Variant method fn variants fn functions MethodOperators_declarations gen_headers native_functions Sequence NativeFunction valid_tags set str grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup structured_native_functions Sequence NativeFunctionsGroup static_dispatch_idx list BackendIndex selector SelectiveBuilder backend_indices dict DispatchKey BackendIndex core_fm FileManager cpu_fm FileManager device_fms dict str FileManager ops_fm FileManager dispatch_keys Sequence DispatchKey functions_keys set DispatchKey rocm bool per_operator_headers bool - None per_operator_headers gen_per_operator_headers native_functions=native_functions grouped_native_functions=grouped_native_functions static_dispatch_idx=static_dispatch_idx selector=selector backend_indices=backend_indices cpu_fm=cpu_fm device_fms=device_fms ops_fm=ops_fm dispatch_keys=dispatch_keys functions_keys=functions_keys rocm=rocm gen_aggregated_headers native_functions=native_functions grouped_native_functions=grouped_native_functions structured_native_functions=structured_native_functions static_dispatch_idx=static_dispatch_idx selector=selector backend_indices=backend_indices cpu_fm=cpu_fm device_fms=device_fms dispatch_keys=dispatch_keys functions_keys=functions_keys rocm=rocm core_fm write TensorBody h lambda tensor_method_declarations list mapMaybe ComputeTensorMethod target=Target DECLARATION static_dispatch_backend_indices=static_dispatch_idx native_functions tensor_method_definitions list mapMaybe ComputeTensorMethod target=Target DEFINITION static_dispatch_backend_indices=static_dispatch_idx native_functions cpu_fm write RedispatchFunctions h lambda function_redispatch_definitions list mapMaybe ComputeRedispatchFunction native_functions cpu_fm write RegistrationDeclarations h lambda registration_declarations compute_registration_declarations f backend_indices f native_functions cpu_fm write VmapGeneratedPlumbing h lambda gen_all_vmap_plumbing native_functions gen_aten_interned_strings - dict str str attrs set str = set All function argument names names = set All ATen function names func native_functions names add str func func name name Some operators don t have functional variant we still create symbol without underscore names add func func name name base attrs update arg name arg func func schema_order_arguments These keywords C++ so aren t valid symbol names https en cppreference com w cpp language operator_alternative names -= and_eq bitand bitor compl not_eq or_eq xor xor_eq aten_symbols \\\n join f _ aten name name sorted names attr_symbols \\\n join f _ attr name name sorted attrs core_fm write aten_interned_strings h gen_aten_interned_strings gen_tags_enum - dict str str enum_of_valid_tags \n join sorted valid_tags core_fm write enum_tag h gen_tags_enum gen_source_files native_functions Sequence NativeFunction grouped_native_functions Sequence NativeFunction &#124; NativeFunctionsGroup structured_native_functions Sequence NativeFunctionsGroup view_groups Sequence NativeFunctionsViewGroup selector SelectiveBuilder static_dispatch_idx list BackendIndex backend_indices dict DispatchKey BackendIndex aoti_fm FileManager core_fm FileManager cpu_vec_fm FileManager cpu_fm FileManager device_fms dict str FileManager dispatch_keys Sequence DispatchKey functions_keys set DispatchKey rocm bool force_schema_registration bool per_operator_headers bool skip_dispatcher_op_registration bool update_aoti_c_shim bool aoti_backends set Optional DispatchKey extend_aoti_c_shim bool - None extra_cuda_headers = \ #include c cuda CUDAGuard h #include ATen cuda ATenCUDAGeneral h #include ATen cuda CUDADevice h #include ATen cuda CUDAContext h rocm extra_cuda_headers = \ #include ATen hip impl HIPGuardImplMasqueradingAsCUDA h #include ATen hip ATenHIPGeneral h #include ATen hip HIPDevice h #include ATen hip HIPContext h dispatch_key dispatch_keys fm = file_manager_from_dispatch_key dispatch_key device_fms cpu_fm per_operator_headers operator_headers - list str headers = g grouped_native_functions is_registered = False backend_index has_kernel g is_registered = True The above has_kernel test group will only test existence out dispatch because s how structured kernels work But sometimes functions can grouped structured then you need check each individual piece they may have manual dispatch entries isinstance g NativeFunctionsGroup any backend_index has_kernel fn fn g functions is_registered = True TODO condition bit questionable It has do fact structured kernels get generated kernels Meta + CompositeExplicitAutogradNonFunctional keys g structured dispatch_key DispatchKey Meta DispatchKey CompositeExplicitAutogradNonFunctional is_registered = True is_registered continue headers append f #include ATen ops g root_name _native h dispatch_key == DispatchKey CompositeExplicitAutogradNonFunctional headers append f #include ATen ops g root_name h dispatch_key functions_keys headers append f #include ATen ops g root_name _ dispatch_namespace _dispatch h sorted set headers operator_headers - list str headers = #include ATen NativeFunctions h dispatch_key == DispatchKey CompositeExplicitAutogradNonFunctional headers append #include ATen Functions h dispatch_key functions_keys headers append f #include ATen dispatch_key s Functions h headers backend_index = backend_indices dispatch_key ns_grouped_native_functions = defaultdict list grouped_native_function grouped_native_functions namespace = grouped_native_function namespace isinstance grouped_native_function NativeFunction grouped_native_function functional namespace ns_grouped_native_functions namespace append grouped_native_function dispatch_namespace = str dispatch_key lower CompositeImplicitAutogradNestdTensor does currently user helpers generated compilation will fail when ` -Werror=unused-function ` flag set gen_dispatch_helpers bool = dispatch_key = DispatchKey CompositeImplicitAutogradNestedTensor register_dispatch_key_base_env = extra_cuda_headers extra_cuda_headers is_cuda_dispatch_key dispatch_key external_backend_headers dispatch_headers dest gen_registration_headers backend_index per_operator_headers rocm ops_headers could sharded doesn t seem necessary ops_headers operator_headers dispatch_helpers dest gen_registration_helpers backend_index gen_dispatch_helpers register_dispatch_key_env_callable gnf NativeFunction &#124; NativeFunctionsGroup - dict str list str dispatch_definitions get_native_function_definitions fm=fm noqa F grouped_native_functions= gnf dispatch_key=dispatch_key backend_idx=backend_index selector=selector rocm=rocm symint=True skip_dispatcher_op_registration=skip_dispatcher_op_registration gen_dispatch_helpers=gen_dispatch_helpers fm write_sharded_with_template f Register dispatch_key cpp RegisterDispatchKey cpp grouped_native_functions key_fn=lambda x x root_name env_callable=register_dispatch_key_env_callable num_shards= dispatch_key == DispatchKey CPU base_env=register_dispatch_key_base_env sharded_keys= dispatch_definitions g structured_native_functions g out ufunc_inner_loop is_ufunc_dispatch_key dispatch_key continue name = g functional func name name dispatch_key DispatchKey CPU assert fm cpu_fm fm write_with_template f UfuncCPU_ name cpp UfuncCPU cpp lambda meta_declaration compute_meta_function_declaration g native_declaration dest compute_native_function_declaration g backend_indices dispatch_key native_definitions dest compute_ufunc_cpu g cpu_vec_fm write_with_template f UfuncCPUKernel_ name cpp UfuncCPUKernel cpp lambda name name native_definitions dest compute_ufunc_cpu_kernel g dispatch_key DispatchKey CUDA cuda_headers = #include ATen native cuda Loops cuh rocm cuda_headers = #include ATen native hip Loops cuh fm write_with_template f UfuncCUDA_ name cu UfuncCUDA cu lambda name name cuda_headers cuda_headers meta_declaration compute_meta_function_declaration g native_declaration dest compute_native_function_declaration g backend_indices dispatch_key native_definitions dest compute_ufunc_cuda g raise AssertionError f unrecognized dispatch_key ufunc del fm gen_aoti_c_shim_files aoti_fm=aoti_fm aoti_backends=aoti_backends native_functions=native_functions backend_indices=backend_indices structured_native_functions=structured_native_functions extra_cuda_headers=extra_cuda_headers update_aoti_c_shim=update_aoti_c_shim extend_aoti_c_shim=extend_aoti_c_shim BackendSelect generated specially gen_backend_select - dict str list str relevant_fns = fn fn native_functions needs_backend_select fn selector ops_headers f #include ATen ops fn root_name _ops h fn relevant_fns backend_select_method_definitions list mapMaybe ComputeBackendSelect Target DEFINITION selector relevant_fns backend_select_function_registrations list mapMaybe ComputeBackendSelect Target REGISTRATION selector relevant_fns cpu_fm write RegisterBackendSelect cpp gen_backend_select schema_selector = selector force_schema_registration schema_selector = SelectiveBuilder get_nop_selector aten_schema_registrations schema_registrations = get_native_function_schema_registrations native_functions=native_functions schema_selector=schema_selector cpu_fm write RegisterSchema cpp lambda aten_schema_registrations skip_dispatcher_op_registration aten_schema_registrations schema_registrations skip_dispatcher_op_registration schema_registrations key_func fn NativeFunction &#124; NativeFunctionsGroup &#124; NativeFunctionsViewGroup - str fn root_name cpu_fm write_sharded Operators cpp native_functions key_fn=key_func env_callable=lambda fn operator_headers f #include ATen ops fn root_name h definitions ComputeOperators Target DEFINITION static_dispatch_backend_indices=static_dispatch_idx fn base_env= static_dispatch_extra_headers static_dispatch_extra_headers static_dispatch_idx num_shards= sharded_keys= operator_headers definitions static_dispatch_extra_headers cpu_fm write Functions cpp dict core_fm write TensorMethods cpp dict core_fm write ATenOpList cpp lambda aten_ops list mapMaybe compute_aten_op native_functions gen_op_headers g NativeFunction &#124; NativeFunctionsGroup &#124; NativeFunctionsViewGroup - list str isinstance g NativeFunctionsViewGroup view ops always get functionalization kernel headers = f #include ATen ops g view root_name _native h f #include ATen ops g view root_name _ops h g view_copy None headers += f #include ATen ops g view_copy root_name _native h f #include ATen ops g view_copy root_name _ops h headers isinstance g NativeFunctionsGroup headers = f #include ATen ops g functional root_name _native h f #include ATen ops g functional root_name _ops h f #include ATen ops g out root_name _native h f #include ATen ops g out root_name _ops h g inplace None headers += f #include ATen ops g inplace root_name _native h f #include ATen ops g inplace root_name _ops h g mutable None headers += f #include ATen ops g mutable root_name _native h f #include ATen ops g mutable root_name _ops h headers f #include ATen ops g root_name _native h f #include ATen ops g root_name _ops h functionalization_env_callable g NativeFunction &#124; NativeFunctionsGroup &#124; NativeFunctionsViewGroup - dict str list str ops_headers gen_op_headers g func_definitions gen_functionalization_definition selector g func_registrations gen_functionalization_registration selector g backend_indices DispatchKey CompositeImplicitAutograd all_groups list NativeFunction &#124; NativeFunctionsGroup &#124; NativeFunctionsViewGroup = list structured_native_functions + list view_groups type ignore assignment arg-type operator Note all operators functionalization needs handle mutable aliasing ops should grouped properly The only reason we really need deal direct NativeFunctions here instead groups because We can provide better error checking error out someone introduces mutable op doesn t obey grouping logic functionalization needs manually register CompositeImplicitAutograd kernels which might grouped Although could go away long-term we add dedicated dispatch key decompositions structured_map dict OperatorName NativeFunction = f func name f f concatMap lambda g list g functions structured_native_functions view_map dict OperatorName NativeFunction = f func name f f concatMap lambda g list g functions view_groups all_groups extend f f native_functions f func name structured_map f func name view_map cpu_fm write_sharded RegisterFunctionalization cpp all_groups key_fn=key_func env_callable=functionalization_env_callable num_shards= sharded_keys= ops_headers func_definitions func_registrations func_add_back_views_definitions func_add_back_views_registrations cpu_fm write FunctionalInverses h lambda view_inverse_declarations list mapMaybe lambda g gen_functionalization_view_inverse_declaration selector g view_groups cpu_fm write ViewMetaClasses h lambda view_meta_declarations list concatMap lambda g gen_functionalization_view_meta_classes_decl selector g view_groups cpu_fm write ViewMetaClasses cpp lambda view_meta_implementations list concatMap lambda g gen_functionalization_view_meta_classes_impl selector g view_groups op_headers list concatMap gen_op_headers view_groups Note view_copy NativeFunctions Every view operator native_functions yaml CompositeImplicitAutograd needs have corresponding non-aliasing view _copy variant Backends use functionalization don t know how handle aliasing ops expected implement kernels these view _copy kernels instead The code view _copy operators core pretty boilerplate-heavy however so we codegen following A CompositeExplicitAutogradNonFunctional kernel every view _copy operator These never explicitly invoked functionalization pass they could theoretically called user code I added these kernels completeness since ops part public API A derivative formula every view _copy operator view _copy operators can reuse same derivative formulas their view op counterparts so rather than stamping all entries out derivatives yaml we codegen them This similar how autograd codegen doesn t require inplace ops have derivatives yaml entry cpu_fm write CompositeViewCopyKernels cpp lambda ops_headers \n join f #include ATen ops f root_name _ops h \n NB include important ensures we set visibility generated view_copy kernels correctly f #include ATen ops f root_name _native h f g view g view_copy None g view g view_copy g view_groups + \n join f #include ATen ops f root_name _ops h \n NB include also important correct visibility f #include ATen ops f root_name _native h f g inplace g mutable g functional f None generated f tags g structured_native_functions CompositeViewCopyKernel_Definitions list mapMaybe GenCompositeViewCopyKernel backend_indices DispatchKey CompositeExplicitAutogradNonFunctional view_groups GeneratedCompositeFunctional_Definitions list mapMaybe gen_composite_functional_kernel structured_native_functions GeneratedCompositeOut_Definitions list mapMaybe gen_composite_out_kernel structured_native_functions gen_declarations_yaml cpu_fm FileManager native_functions Sequence NativeFunction - None cpu_fm write Declarations yaml lambda format_yaml compute_declaration_yaml f f native_functions get_torchgen_root - Path If you re depending torchgen out-of-tree you can use root figure out path native_functions yaml Path __file__ parent resolve main - None parser = argparse ArgumentParser description= Generate ATen source files parser add_argument -s -- source-path help= path source directory ATen default= aten src ATen parser add_argument -o -- output-dependencies help= output list dependencies into given file exit parser add_argument -- dry-run action= store_true help= run without writing any files still updates outputs parser add_argument -- per-operator-headers action= store_true help= generate separate headers per operator ATen ops parser add_argument -d -- install-dir -- install_dir help= output directory default= build aten src ATen parser add_argument -- aoti-install-dir -- aoti_install_dir help= output directory AOTInductor shim default= torch csrc inductor aoti_torch generated parser add_argument -- rocm action= store_true help= reinterpret CUDA ROCm HIP adjust filepaths accordingly parser add_argument -- mps action= store_true help= Generate MPS registration code when set parser add_argument -- xpu action= store_true help= Generate XPU registration code when set parser add_argument -- mtia action= store_true help= Generate MTIA registration code when set TODO -- op-registration-whitelist will removed when all call-sites gen py moved over using operator YAML file mobile custom build parser add_argument -- op-registration-whitelist -- op_registration_whitelist nargs= help= filter op registrations whitelist set each item ` namespace ` ` operator name ` without overload name e g aten empty aten conv d parser add_argument -- op-selection-yaml-path -- op_selection_yaml_path help= Provide path operator selection custom build YAML contains information about set selected operators their categories training Each operator either full operator name overload just bare operator name The operator names also contain namespace prefix e g aten parser add_argument -- backend-whitelist -- backend_whitelist nargs= help= filter dispatch backend whitelist set e g CPU CUDA QuantizedCPU parser add_argument -- static-dispatch-backend -- static_dispatch_backend nargs= help= generate static dispatch code specific backend set parser add_argument -- skip-dispatcher-op-registration -- skip_dispatcher_op_registration action= store_true help= Avoid registering operators into dispatcher parser add_argument -- force-schema-registration -- force_schema_registration action= store_true help= force generate schema-only registrations all ops including those listed -- op-registration-whitelist parser add_argument -- generate type=str nargs= choices= headers sources declarations_yaml default= headers sources declarations_yaml help= Generate only subset files parser add_argument -- update-aoti-c-shim action= store_true help= Update AOTInductor C shim after adding entry inductor_fallback_ops torchgen aoti fallback_ops py WARNING Do use unless you sure what you doing parser add_argument -- extend-aoti-c-shim action= store_true help= This Flag indicates generation c shims out-of-tree ATen ops which extension In-tree ATen op c shims This flag needs combined --- source-path= out-of-tree native_functions yaml -- aoti-install-dir= in-tree aoti_install_dir extend default torch csrc inductor aoti_torch generated extend WARNING Do use unless you sure what you doing options = parser parse_args selector = get_custom_build_selector options op_registration_whitelist options op_selection_yaml_path native_yaml_path = os path join options source_path native native_functions yaml tags_yaml_path = os path join options source_path native tags yaml torchgen model dispatch_keys Only limited set dispatch keys get CPUFunctions h headers generated them set functions_keys = DispatchKey CPU DispatchKey CUDA DispatchKey CompositeImplicitAutograd DispatchKey CompositeImplicitAutogradNestedTensor DispatchKey CompositeExplicitAutograd DispatchKey CompositeExplicitAutogradNonFunctional DispatchKey Meta DispatchKey MTIA aoti_backends = DispatchKey CPU DispatchKey CUDA None will generate aten shim based aten_shimified_ops which does bypass dispatcher None TODO stop generating CUDA kernels non-CUDA builds ignore_keys = set MPS_KEYS = DispatchKey MPS DispatchKey SparseMPS DispatchKey SparseCsrMPS options mps options update_aoti_c_shim functions_keys update MPS_KEYS aoti_backends add DispatchKey MPS ignore_keys update MPS_KEYS dispatch_keys = k k dispatch_keys k MPS_KEYS options xpu options update_aoti_c_shim functions_keys add DispatchKey XPU aoti_backends add DispatchKey XPU ignore_keys add DispatchKey XPU DispatchKey XPU dispatch_keys del dispatch_keys dispatch_keys index DispatchKey XPU options mtia ignore_keys add DispatchKey MTIA DispatchKey MTIA dispatch_keys del dispatch_keys dispatch_keys index DispatchKey MTIA options backend_whitelist dispatch_keys = k k dispatch_keys is_generic_dispatch_key k str k options backend_whitelist parsed_yaml = parse_native_yaml native_yaml_path tags_yaml_path ignore_keys valid_tags = _GLOBAL_PARSE_TAGS_YAML_CACHE tags_yaml_path native_functions backend_indices = parsed_yaml native_functions parsed_yaml backend_indices grouped_native_functions = get_grouped_native_functions native_functions structured_native_functions = g g grouped_native_functions isinstance g NativeFunctionsGroup native_functions_with_view_groups = get_grouped_by_view_native_functions native_functions view_groups = g g native_functions_with_view_groups isinstance g NativeFunctionsViewGroup NB It mandatory NOT use os path join here install directory will eventually ingested cmake which does respect Windows style path slashes If you switch use os path join you ll get error like Syntax error cmake code when parsing string C Jenkins workspace pytorch-builds pytorch-win-ws -cuda -cudnn -py -build build aten src ATen\core TensorMethods h Invalid character escape \c core_install_dir = f options install_dir core Path core_install_dir mkdir parents=True exist_ok=True ops_install_dir = f options install_dir ops Path ops_install_dir mkdir parents=True exist_ok=True aoti_install_dir = f options aoti_install_dir Path aoti_install_dir mkdir parents=True exist_ok=True core_fm = make_file_manager options=options install_dir=core_install_dir cpu_fm = make_file_manager options=options cpu_vec_fm = make_file_manager options=options cuda_fm = make_file_manager options=options ops_fm = make_file_manager options=options install_dir=ops_install_dir aoti_fm = make_file_manager options=options install_dir=aoti_install_dir device_fms = cuda cuda_fm options xpu device_fms xpu = make_file_manager options=options static_dispatch_idx list BackendIndex = options static_dispatch_backend static_dispatch_idx = backend_indices DispatchKey parse key key options static_dispatch_backend key options static_dispatch_backend dp_key = DispatchKey parse key dp_key functions_keys functions_keys add dp_key sources options generate gen_source_files native_functions=native_functions grouped_native_functions=grouped_native_functions structured_native_functions=structured_native_functions view_groups=view_groups selector=selector static_dispatch_idx=static_dispatch_idx backend_indices=backend_indices aoti_fm=aoti_fm core_fm=core_fm cpu_vec_fm=cpu_vec_fm cpu_fm=cpu_fm device_fms=device_fms dispatch_keys=dispatch_keys functions_keys=functions_keys rocm=options rocm force_schema_registration=options force_schema_registration per_operator_headers=options per_operator_headers skip_dispatcher_op_registration=options skip_dispatcher_op_registration update_aoti_c_shim=options update_aoti_c_shim aoti_backends=aoti_backends extend_aoti_c_shim=options extend_aoti_c_shim headers options generate gen_headers native_functions=native_functions valid_tags=valid_tags grouped_native_functions=grouped_native_functions structured_native_functions=structured_native_functions static_dispatch_idx=static_dispatch_idx selector=selector backend_indices=backend_indices core_fm=core_fm cpu_fm=cpu_fm device_fms=device_fms ops_fm=ops_fm dispatch_keys=dispatch_keys functions_keys=functions_keys rocm=options rocm per_operator_headers=options per_operator_headers declarations_yaml options generate gen_declarations_yaml native_functions=native_functions cpu_fm=cpu_fm options output_dependencies depfile_path = Path options output_dependencies resolve depfile_name = depfile_path name depfile_stem = depfile_path stem fm prefix cpu_fm cpu_vec_fm cpu_vec_ core_fm core_ ops_fm ops_ + device_fm f device _ device device_fm device_fms items varname = prefix + depfile_stem path = depfile_path parent prefix + depfile_name fm write_outputs varname str path __name__ == __main__ main