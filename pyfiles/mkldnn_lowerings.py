mypy allow-untyped-defs functools typing Optional Union torch torch utils _pytree pytree torch _inductor kernel mm_common mm_args config ir codegen cpp_gemm_template CppGemmTemplate codegen cpp_grouped_gemm_template CppGroupedGemmTemplate codegen cpp_utils create_epilogue_with_attr ir TensorBox lowering add add_needs_realized_inputs aten permute register_lowering to_dtype view select_algorithm autotune_select_algorithm ChoiceCaller ExternKernelChoice utils use_aten_gemm_kernels use_cpp_gemm_template virtualized ops OpsValue V create_int _compensation W_tensor torch Tensor packed_weight ir TensorBox x_scale ir TensorBox x_zp ir TensorBox w_scale ir TensorBox - tuple bool Union ir TensorBox ir ShapeAsConstantBuffer Optional Union ir TensorBox ir ShapeAsConstantBuffer x_w_scale Optional Union ir TensorBox ir ShapeAsConstantBuffer = None use_int _fast_compensation_path = all isinstance item ir TensorBox item get_name V graph constants hasattr item data data isinstance item data data ir ConstantBuffer item x_scale x_zp w_scale use_int _fast_compensation_path x_w_scale_tensor = V graph constants x_scale get_name V graph constants w_scale get_name x_w_scale = V graph add_tensor_constant x_w_scale_tensor name=packed_weight get_name + _x_w_compens weight_compens_tensor = torch sum W_tensor torch float dim= x_zp_tensor = V graph constants x_zp get_name weight_compens_tensor = weight_compens_tensor x_w_scale_tensor x_zp_tensor weight_compens = V graph add_tensor_constant weight_compens_tensor name=packed_weight get_name + _BMatrixCompens weight_compens_tensor = torch sum W_tensor torch float dim= weight_compens = V graph add_tensor_constant weight_compens_tensor name=packed_weight get_name + _BMatrixCompens type ignore return-type use_int _fast_compensation_path weight_compens x_w_scale codegen_int _gemm_template_compensation use_int _fast_compensation_path bool input OpsValue _weight_compo OpsValue _x_scale Optional OpsValue _x_zp Optional OpsValue _w_scale Optional OpsValue _x_w_scale Optional OpsValue - OpsValue use_int _fast_compensation_path temp = ops sub ops mul input _x_w_scale _weight_compo temp = ops mul ops mul input _x_scale _w_scale NOTE We will apply compensation even x_zp int quantization That s because when torch compile invoked dynamic quantization x might coincidentally have such values x_zp might zero despite asymmetric quantization Besides x_zp dummy int x x statically quantized we d still perform redundant compute avoid making code messy because we discovered redundant computation compensation did lead performance degradation input shapes tested temp = ops sub temp ops mul ops mul ops mul _x_scale _w_scale _x_zp _weight_compo temp grouped_gemm_lowering x TensorBox w list TensorBox b list TensorBox attr=None scalars=None algorithm=None layout=None x_size = x get_size len x_size GEMM template needs D input normalize input shape here x = view x - x_size - num_gemm = len w assert config max_autotune config max_autotune_gemm pyrefly ignore bad-assignment b = bias bias None ir ExternKernel realize_input bias bias b choices list ChoiceCaller = _ layout x _ = mm_args x permute w layout=layout kwargs = has_bias bias None bias b trans_w True epilogue_creator None act_mapping dict fromkeys range num_gemm x input_nodes = x w input_nodes extend bias bias b bias None CppGroupedGemmTemplate add_choices choices layout input_nodes kwargs type ignore arg-type assert len choices = result = autotune_select_algorithm grouped_gemm choices input_nodes layout template_buf = result data data return_bufs = ir MultiOutput layout template_buf list gemm_idx gemm_idx range num_gemm pyrefly ignore bad-argument-type template_buf layout = ir MultiOutputLayout device=input_nodes get_device template_buf outputs = return_bufs return_tensors = ir TensorBox create return_bufs gemm_idx gemm_idx range num_gemm len x_size gemm_idx range num_gemm return_tensors gemm_idx = view return_tensors gemm_idx type ignore arg-type x_size - return_tensors gemm_idx get_size - return_tensors grouped_gemm_lowering _inductor_lowering_function = True type ignore attr-defined register_onednn_fusion_ops torch _C _has_mkldnn mkldnn_ir aten_mkldnn_linear_unary = ExternKernelChoice torch ops mkldnn _linear_pointwise mkldnn _linear_pointwise has_out_variant=False kernel_creator=mkldnn_ir LinearUnary create aten_mkldnn_linear_binary = ExternKernelChoice torch ops mkldnn _linear_pointwise binary mkldnn _linear_pointwise has_out_variant=False kernel_creator=mkldnn_ir LinearBinary create aten_mkldnn_qlinear_unary = ExternKernelChoice torch ops onednn qlinear_pointwise onednn qlinear_pointwise has_out_variant=False kernel_creator=mkldnn_ir QLinearPointwisePT E create aten_mkldnn_qlinear_binary = ExternKernelChoice torch ops onednn qlinear_pointwise binary onednn qlinear_pointwise has_out_variant=False kernel_creator=mkldnn_ir QLinearPointwiseBinaryPT E create cpu_needs_realized_inputs = torch ops mkldnn _convolution_pointwise torch ops mkldnn _convolution_pointwise_ torch ops mkldnn _convolution_transpose_pointwise torch ops mkldnn _linear_pointwise aten mkldnn_rnn_layer default torch ops onednn qconv_pointwise register_lowering torch ops mkldnn _convolution_pointwise convolution_unary x TensorBox weight TensorBox bias TensorBox padding stride dilation groups attr scalars algorithm TensorBox create mkldnn_ir ConvolutionUnary create x weight bias padding stride dilation groups attr scalars algorithm register_lowering torch ops mkldnn _convolution_pointwise binary convolution_binary x TensorBox other TensorBox weight TensorBox bias TensorBox padding stride dilation groups binary_attr binary_alpha unary_attr unary_scalars unary_algorithm TensorBox create mkldnn_ir ConvolutionBinary create x other weight bias padding stride dilation groups binary_attr binary_alpha unary_attr unary_scalars unary_algorithm register_lowering torch ops mkldnn _convolution_pointwise_ binary convolution_binary_inplace x TensorBox other TensorBox weight TensorBox bias TensorBox padding stride dilation groups binary_attr binary_alpha unary_attr unary_scalars unary_algorithm TensorBox create mkldnn_ir ConvolutionBinaryInplace create x other weight bias padding stride dilation groups binary_attr binary_alpha unary_attr unary_scalars unary_algorithm register_lowering torch ops mkldnn _linear_pointwise linear_unary x TensorBox w TensorBox b TensorBox attr scalars algorithm layout=None x_size = x get_size len x_size GEMM template needs D input normalize input shape here x = view x - x_size - b None b = ir ExternKernel realize_input b type ignore assignment choices list ChoiceCaller = config max_autotune config max_autotune_gemm transposed_w = permute w _ layout x transposed_w = mm_args x transposed_w layout=layout use_cpp_gemm_template layout x transposed_w epilogue_creator buf create_epilogue_with_attr buf attr scalars=scalars algorithm=algorithm kwargs = has_bias b None trans_w True epilogue_creator None attr == none epilogue_creator b None kwargs input_indices = type ignore assignment CppGemmTemplate add_choices choices layout x w b None x w b kwargs type ignore arg-type len choices == use_aten_gemm_kernels kwargs = dict attr=attr scalars=scalars algorithm=algorithm b None kwargs B = None choices append aten_mkldnn_linear_unary bind x w b None x w b layout kwargs assert w get_name V graph constants input_gen_fns = lambda x V graph constants x get_name result = autotune_select_algorithm linear_unary choices x w b None x w b layout input_gen_fns=input_gen_fns len x_size result = view result x_size - result get_size - result register_lowering torch ops mkldnn _linear_pointwise binary linear_binary x TensorBox y TensorBox w TensorBox b TensorBox attr layout=None x_size = x get_size len x_size GEMM template needs D input normalize input shape here x = view x - x_size - y_size = y get_size len y_size y = view y - y_size - b None b = ir ExternKernel realize_input b type ignore assignment choices list ChoiceCaller = config max_autotune config max_autotune_gemm transposed_w = permute w _ layout x transposed_w y = mm_args x transposed_w y layout=layout use_cpp_gemm_template layout x transposed_w epilogue_creator buf create_epilogue_with_attr buf attr other=y kwargs = has_bias b None trans_w True epilogue_creator epilogue_creator pyrefly ignore unsupported-operation kwargs input_indices = b None CppGemmTemplate add_choices choices layout x y w b None x y w b kwargs type ignore arg-type len choices == use_aten_gemm_kernels kwargs = dict attr=attr b None kwargs B = None choices append aten_mkldnn_linear_binary bind x y w b None x y w b layout kwargs assert w get_name V graph constants input_gen_fns = lambda x V graph constants x get_name result = autotune_select_algorithm linear_binary choices x y w b None x y w b layout input_gen_fns=input_gen_fns len x_size result = view result x_size - result get_size - result register_lowering torch ops mkldnn _convolution_transpose_pointwise convolution_transpose_unary x TensorBox weight TensorBox bias TensorBox padding output_padding stride dilation groups attr scalars algorithm TensorBox create mkldnn_ir ConvolutionTransposeUnary create x weight bias padding output_padding stride dilation groups attr scalars algorithm register_lowering aten mkldnn_rnn_layer default mkldnn_rnn_layer x TensorBox w TensorBox w TensorBox w TensorBox w TensorBox hx TensorBox cx TensorBox reverse bool batch_sizes list int mode int hidden_size int num_layers int has_biases bool bidirectional bool batch_first bool train bool pytree tree_map TensorBox create mkldnn_ir MkldnnRnnLayer create x w w w w hx cx reverse batch_sizes mode hidden_size num_layers has_biases bidirectional batch_first train register_lowering torch ops onednn qconv_pointwise type_promotion_kind=None qconvolution_unary x TensorBox x_scale x_zp packed_weight TensorBox w_scale TensorBox w_zp TensorBox bias TensorBox stride padding dilation groups o_inv_scale o_zero_point output_dtype attr scalars algorithm To align qlinear where x_scale x_zp converted Tensor assert type x_scale float x_scale = V graph add_tensor_constant torch tensor x_scale dtype=torch float name= x_scale assert type x_zp int x_zp = V graph add_tensor_constant torch tensor x_zp dtype=torch int name= x_zp TensorBox create mkldnn_ir QConvPointWisePT E create x x_scale x_zp packed_weight w_scale w_zp bias stride padding dilation groups o_inv_scale o_zero_point output_dtype attr scalars algorithm register_lowering torch ops onednn qconv d_pointwise binary type_promotion_kind=None register_lowering torch ops onednn qconv d_pointwise binary_tensor type_promotion_kind=None qconvolution_binary x TensorBox x_scale x_zp packed_weight TensorBox w_scale TensorBox w_zp TensorBox accum TensorBox bias TensorBox stride padding dilation groups o_inv_scale o_zero_point output_dtype accum_scale accum_zp binary_attr alpha unary_attr unary_scalars unary_algorithmm To align qlinear where x_scale x_zp converted Tensor assert type x_scale float x_scale = V graph add_tensor_constant torch tensor x_scale dtype=torch float name= x_scale assert type x_zp int x_zp = V graph add_tensor_constant torch tensor x_zp dtype=torch int name= x_zp binary_attr == sum output_dtype torch float torch bfloat accum get_dtype torch float torch bfloat accum get_dtype = output_dtype For int -mixed-bf quantization inplace add there case when accum dtype float output dtype bfloat Since accum will inplaced changed post op sum we will do accum dtype conversion here accum = to_dtype accum output_dtype TensorBox create mkldnn_ir QConvPointWiseBinaryPT E create x x_scale type ignore arg-type x_zp type ignore arg-type packed_weight w_scale w_zp accum bias stride padding dilation groups o_inv_scale o_zero_point output_dtype accum_scale accum_zp binary_attr alpha unary_attr unary_scalars unary_algorithmm register_lowering torch ops onednn qlinear_pointwise type_promotion_kind=None qlinear_unary x TensorBox x_scale x_zp packed_weight TensorBox w_scale TensorBox w_zp TensorBox bias TensorBox o_scale o_zero_point output_dtype attr scalars algorithm layout=None assert packed_weight get_dtype torch int torch float _e m fn Only int e m fn weights supported oneDNN qlinear x_size = x get_size len x_size GEMM template needs D input normalize input shape here x = view x - x_size - isinstance x_scale ir TensorBox assert type x_scale float x_scale = V graph add_tensor_constant torch tensor x_scale dtype=torch float name= x_scale x_scale realize all dim == dim x_scale get_size Corner-case discovered LLaMA series If all outer dims x_scale make D tensor Otherwise epilogue creator will run into indexing issues x_scale = view x_scale assert len x_scale get_size x_scale must D D x_zp None If x_zp None x int quantized per-tensor its scale reshaped then codegened code would segfault we don t create tensor x_zp It s safe do so since x symmetrically quantized int tensor Moreover oneDNN qlinear API doesn t accept None value zp x_zp = V graph add_tensor_constant torch tensor dtype=torch int name= x_zp isinstance x_zp ir TensorBox assert type x_zp int x_zp = V graph add_tensor_constant torch tensor x_zp dtype=torch int name= x_zp x_zp realize assert x_zp get_numel == x_zp incompatible oneDNN qlinear When channels less than w_scale w_zp Pointwise instead ConstantBuffer Refer https github com pytorch pytorch blob f d ed b c ff fe torch _inductor graph py#L -L noqa B w_zp None If w_zp None then s dummy tensor created denote absence zero point thus w int symmetrically quantized Moreover oneDNN qlinear API doesn t accept None value zp pyrefly ignore bad-assignment w_zp = V graph add_tensor_constant torch tensor dtype=torch int name= w_zp w_scale realize w_zp realize w_zp get_dtype = torch int isinstance ir InputsKernel unwrap_storage_for_input w_zp ir ConstantBuffer W_zp might ConstantBuffer int convert int w_zp_tensor = V graph constants w_zp get_name torch int w_zp = V graph add_tensor_constant type ignore assignment torch tensor w_zp_tensor dtype=torch int name=w_zp get_name bias_dtype = None bias None bias get_dtype choices list ChoiceCaller = config max_autotune config max_autotune_gemm _ layout x packed_weight = mm_args x packed_weight layout=layout out_dtype=output_dtype GEMM template currently only supports symmetrically quantized weights isinstance ir InputsKernel unwrap_storage_for_input w_zp ir ConstantBuffer torch equal torch zeros_like V graph constants w_zp get_name V graph constants w_zp get_name use_cpp_gemm_template layout x packed_weight W_tensor = V graph constants packed_weight get_name to_dense use_int _fast_compensation_path weight_compens x_w_scale = create_int _compensation W_tensor packed_weight pyrefly ignore bad-argument-type x_scale pyrefly ignore bad-argument-type x_zp w_scale epilogue_creator input_buffer Epilogue convert s f u s f assert output_dtype torch float torch bfloat torch uint torch int input_loader = input_buffer make_loader weight_compens_loader = weight_compens make_loader x_w_scale_loader = None use_int _fast_compensation_path assert x_w_scale None x_w_scale_loader = x_w_scale make_loader x_scale_loader = x_scale make_loader w_scale_loader = w_scale make_loader x_zp_loader = x_zp make_loader nonlocal bias bias_loader = None bias None bias_loader = bias make_loader inner_fn index nonlocal bias input = input_loader index MicroKernel Output int cvt FP before doing compensation input = ops to_dtype input torch float weight_compens_index = index - _x_scale = None _x_zp = None _w_scale = None use_int _fast_compensation_path _x_scale = x_scale_loader _x_zp = x_zp_loader _w_scale = w_scale_loader weight_compens_index _weight_compo = weight_compens_loader weight_compens_index _x_w_scale = None use_int _fast_compensation_path assert x_w_scale_loader None _x_w_scale = x_w_scale_loader weight_compens_index Step Compute s s - s u s - s GEMM then apply compensation temp = codegen_int _gemm_template_compensation use_int _fast_compensation_path input _weight_compo _x_scale _x_zp _w_scale _x_w_scale Step add Bias applicable bias None pyrefly ignore not-callable _bias = bias_loader weight_compens_index nonlocal bias_dtype assert bias_dtype torch float torch bfloat bias_dtype == torch bfloat _bias = ops to_dtype _bias torch float temp = ops add temp _bias temp output_buf = ir Pointwise device=input_buffer get_device dtype=torch float Hardcode FP u s f s s f inner_fn=inner_fn ranges=input_buffer get_size Step Doing unary post op fusion attr = none output_buf = create_epilogue_with_attr output_buf attr scalars=scalars algorithm=algorithm Step Cast output Target Dtype output_dtype == torch bfloat output_cast_loader = output_buf make_loader inner_fn_cast_output_to_bf index input = output_cast_loader index ops to_dtype input output_dtype output_buf = ir Pointwise device=output_buf get_device_or_error dtype=output_dtype inner_fn=inner_fn_cast_output_to_bf ranges=output_buf get_size output_dtype torch uint torch int lowering _create_constants requant_input_loader = output_buf make_loader inner_fn_requant index scale zero_point input = requant_input_loader index inv_scale zero_point = _create_constants scale zero_point dtype=torch float val = ops round input inv_scale + zero_point output_dtype == torch uint qmin qmax = _create_constants dtype=torch float qmin qmax = _create_constants - dtype=torch float clamped = ops minimum ops maximum val qmin qmax ops to_dtype clamped output_dtype output_buf = ir Pointwise device=output_buf get_device_or_error dtype=output_dtype inner_fn=functools partial inner_fn_requant scale=float o_scale zero_point=int o_zero_point ranges=output_buf get_size output_buf assert x get_dtype torch uint torch int CppGemmTemplate add_choices choices layout x x_scale x_zp packed_weight w_scale w_zp bias None x x_scale x_zp packed_weight w_scale w_zp bias has_bias=bias None epilogue_creator=epilogue_creator input_indices= bias None len choices == use_aten_gemm_kernels kwargs = dict output_scale=o_scale output_zero_point=o_zero_point output_dtype=output_dtype post_op_name=attr post_op_args=scalars post_op_algorithm=algorithm bias None kwargs bias = None choices append aten_mkldnn_qlinear_unary bind x x_scale x_zp packed_weight w_scale w_zp bias None x x_scale x_zp packed_weight w_scale w_zp bias layout kwargs assert packed_weight get_name V graph constants input_gen_fns = lambda x V graph constants x get_name packed weight lambda x V graph constants x get_name weight scale lambda x V graph constants x get_name weight zp lambda x V graph constants x get_name bias isinstance ir InputsKernel unwrap_storage_for_input x_scale ir ConstantBuffer x statically quantized input_gen_fns = lambda x V graph constants x get_name isinstance ir InputsKernel unwrap_storage_for_input x_zp ir ConstantBuffer input_gen_fns = lambda x V graph constants x get_name result = autotune_select_algorithm qlinear_unary choices x x_scale x_zp packed_weight w_scale w_zp bias None x x_scale x_zp packed_weight w_scale w_zp bias layout input_gen_fns=input_gen_fns len x_size result = view result x_size - result get_size - result register_lowering torch ops onednn qlinear_pointwise binary type_promotion_kind=None register_lowering torch ops onednn qlinear_pointwise binary_tensor type_promotion_kind=None qlinear_binary x TensorBox x_scale x_zp packed_weight TensorBox w_scale TensorBox w_zp TensorBox x TensorBox bias TensorBox o_scale o_zero_point output_dtype x _scale x _zp binary_attr alpha unary_attr unary_scalars unary_algorithmm layout=None x_size = x get_size x _size = x get_size assert len x_size == len x _size len x_size binary_attr == add GEMM template needs D input normalize input shape here x = view x - x_size - x = view x - x _size - isinstance x_scale ir TensorBox assert type x_scale float x_scale = V graph add_tensor_constant torch tensor x_scale dtype=torch float name= x_scale x_scale realize all dim == dim x_scale get_size Corner-case discovered LLaMA series If all outer dims x_scale make D tensor Otherwise epilogue creator will run into indexing issues x_scale = view x_scale assert len x_scale get_size x_scale must D D x_zp None x_zp = V graph add_tensor_constant torch tensor dtype=torch int name= x_zp w_zp None pyrefly ignore bad-assignment w_zp = V graph add_tensor_constant torch tensor dtype=torch int name= w_zp isinstance x_zp ir TensorBox assert type x_zp int x_zp = V graph add_tensor_constant torch tensor x_zp dtype=torch int name= x_zp x_zp realize When channels less than w_scale w_zp Pointwise instead ConstantBuffer Refer https github com pytorch pytorch blob f d ed b c ff fe torch _inductor graph py#L -L noqa B w_scale realize w_zp realize w_zp get_dtype = torch int isinstance ir InputsKernel unwrap_storage_for_input w_zp ir ConstantBuffer w_zp_tensor = V graph constants w_zp get_name torch int w_zp = V graph add_tensor_constant type ignore assignment torch tensor w_zp_tensor dtype=torch int name=w_zp get_name binary_attr == sum output_dtype torch float torch bfloat x get_dtype torch float torch bfloat x get_dtype = output_dtype For int -mixed-bf quantization inplace add there case when accum dtype float output dtype bfloat Since accum will inplaced changed post op sum we will do accum dtype conversion here x = to_dtype x output_dtype assert x get_dtype == output_dtype dtype accum qlinear post op sum should same output x _dtype = x get_dtype bias_dtype = bias get_dtype bias None None choices list ChoiceCaller = config max_autotune config max_autotune_gemm binary_attr == add TODO Support inplace sum fusion _ layout x packed_weight x = mm_args x packed_weight x layout=layout out_dtype=output_dtype isinstance ir InputsKernel unwrap_storage_for_input x_zp ir ConstantBuffer len x_zp get_layout size == Per tensor quant act isinstance ir InputsKernel unwrap_storage_for_input w_zp ir ConstantBuffer torch equal torch zeros_like V graph constants w_zp get_name V graph constants w_zp get_name We only compensate MatrixB assume B_zp avoid compensation MatrixA use_cpp_gemm_template layout x packed_weight W_tensor = V graph constants packed_weight get_name W_tensor = W_tensor to_dense use_int _fast_compensation_path weight_compens x_w_scale = create_int _compensation W_tensor packed_weight pyrefly ignore bad-argument-type x_scale pyrefly ignore bad-argument-type x_zp w_scale epilogue_creator input_buffer Epilogue convert s f u s f assert output_dtype torch float torch bfloat torch uint torch int input_loader = input_buffer make_loader x _loader = x make_loader weight_compens_loader = weight_compens make_loader x_w_scale_loader = None use_int _fast_compensation_path assert x_w_scale None x_w_scale_loader = x_w_scale make_loader x_scale_loader = x_scale make_loader w_scale_loader = w_scale make_loader x_zp_loader = x_zp make_loader nonlocal bias bias_loader = None bias None bias_loader = bias make_loader inner_fn index nonlocal bias input = input_loader index _x = x _loader index _x_scale = None _x_zp = None _w_scale = None weight_compens_index = index - use_int _fast_compensation_path _x_scale = x_scale_loader _x_zp = x_zp_loader _w_scale = w_scale_loader weight_compens_index MicroKernel Output int cvt FP before doing compensation input = ops to_dtype input torch float _weight_compo = weight_compens_loader weight_compens_index _x_w_scale = None use_int _fast_compensation_path assert x_w_scale_loader None _x_w_scale = x_w_scale_loader weight_compens_index Step Doing compensation cvt fp temp = codegen_int _gemm_template_compensation use_int _fast_compensation_path input _weight_compo _x_scale _x_zp _w_scale _x_w_scale Step add Bias applicable bias None pyrefly ignore not-callable _bias = bias_loader weight_compens_index nonlocal bias_dtype assert bias_dtype torch float torch bfloat bias_dtype == torch bfloat _bias = ops to_dtype _bias torch float temp = ops add temp _bias Step Binary add nonlocal x _dtype assert x _dtype torch float torch bfloat x _dtype == torch bfloat _x = ops to_dtype _x torch float temp = ops add temp _x temp output_buf = ir Pointwise device=input_buffer get_device dtype=torch float Hardcode FP u s f inner_fn=inner_fn ranges=input_buffer get_size Step Unary post op has unary_attr = none output_buf = create_epilogue_with_attr output_buf unary_attr scalars=unary_scalars algorithm=unary_algorithmm Step Cast output Target Dtype output_dtype == torch bfloat output_cast_loader = output_buf make_loader inner_fn_cast_output_to_bf index input = output_cast_loader index ops to_dtype input output_dtype output_buf = ir Pointwise device=output_buf get_device_or_error dtype=output_dtype inner_fn=inner_fn_cast_output_to_bf ranges=output_buf get_size output_dtype torch uint torch int lowering _create_constants requant_input_loader = output_buf make_loader inner_fn_requant index scale zero_point input = requant_input_loader index inv_scale zero_point = _create_constants scale zero_point dtype=torch float val = ops round input inv_scale + zero_point output_dtype == torch uint qmin qmax = _create_constants dtype=torch float qmin qmax = _create_constants - dtype=torch float clamped = ops minimum ops maximum val qmin qmax ops to_dtype clamped torch uint output_buf = ir Pointwise device=output_buf get_device_or_error dtype=torch uint inner_fn=functools partial inner_fn_requant scale=float o_scale zero_point=int o_zero_point ranges=output_buf get_size output_buf CppGemmTemplate add_choices choices layout x x_scale x_zp packed_weight w_scale w_zp x bias None x x_scale x_zp packed_weight w_scale w_zp x bias has_bias=bias None epilogue_creator=epilogue_creator Reorder bias x input_indices= bias None len choices == use_aten_gemm_kernels kwargs = dict output_scale=o_scale output_zero_point=o_zero_point output_dtype=output_dtype other_scale=x _scale other_zp=x _zp binary_post_op=binary_attr binary_alpha=alpha unary_post_op=unary_attr unary_post_op_args=unary_scalars unary_post_op_algorithm=unary_algorithmm bias None kwargs bias = None choices append aten_mkldnn_qlinear_binary bind x x_scale x_zp packed_weight w_scale w_zp x bias None x x_scale x_zp packed_weight w_scale w_zp x bias layout kwargs assert packed_weight get_name V graph constants input_gen_fns = lambda x V graph constants x get_name lambda x V graph constants x get_name lambda x V graph constants x get_name bias None input_gen_fns = lambda x V graph constants x get_name For bias result = autotune_select_algorithm qlinear_binary choices x x_scale x_zp packed_weight w_scale w_zp x bias None x x_scale x_zp packed_weight w_scale w_zp x bias layout input_gen_fns=input_gen_fns len x_size binary_attr == add result = view result x_size - result get_size - result torch _C has_mkl aten_mkl_linear = ExternKernelChoice torch ops mkl _mkl_linear mkl _mkl_linear has_out_variant=False kernel_creator=mkldnn_ir MKLPackedLinear create cpu_needs_realized_inputs append torch ops mkl _mkl_linear register_lowering torch ops mkl _mkl_linear mkl_packed_linear x TensorBox packed_w TensorBox orig_w TensorBox b Optional TensorBox batch_size layout=None choices list ChoiceCaller = config max_autotune config max_autotune_gemm transposed_w = permute orig_w _ layout x transposed_w = mm_args x transposed_w layout=layout use_cpp_gemm_template layout x transposed_w CppGemmTemplate add_choices choices layout x packed_w orig_w trans_w=True input_indices= len choices == use_aten_gemm_kernels choices append aten_mkl_linear bind x packed_w orig_w layout B=None batch_size=batch_size assert packed_w get_name V graph constants assert orig_w get_name V graph constants packed_w mkldnn tensor which we can t generate directly so we use weights original tensor autotune input_gen_fns = lambda x V graph constants x get_name lambda x V graph constants x get_name result TensorBox = autotune_select_algorithm packed_linear choices x packed_w orig_w layout input_gen_fns=input_gen_fns b None result = add result b result add_needs_realized_inputs cpu_needs_realized_inputs