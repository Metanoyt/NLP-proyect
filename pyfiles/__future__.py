_overwrite_module_params_on_conversion bool = False _swap_module_params_on_conversion bool = False set_overwrite_module_params_on_conversion value bool - None Sets whether assign new tensors parameters instead changing existing parameters in-place when converting ` ` nn Module ` ` When enabled following methods will assign new parameters module ` ` module device ` ` e g meth ` nn Module cuda ` moving module between devices ` ` module dtype ` ` e g meth ` nn Module float ` converting module different dtype meth ` nn Module ` meth ` nn Module to_empty ` Args value bool Whether assign new tensors global _overwrite_module_params_on_conversion _overwrite_module_params_on_conversion = value get_overwrite_module_params_on_conversion - bool Returns whether assign new tensors parameters instead changing existing parameters in-place when converting ` torch nn Module ` Defaults ` ` False ` ` See func ` ~torch __future__ set_overwrite_module_params_on_conversion ` more information _overwrite_module_params_on_conversion set_swap_module_params_on_conversion value bool - None Sets whether use func ` ~torch utils swap_tensors ` instead setting ` ` data ` ` change existing parameters in-place when converting ` ` nn Module ` ` instead ` ` param copy_ state_dict key ` ` when loading state dict into ` ` nn Module ` ` note This function takes precedence over func ` ~torch __future__ get_overwrite_module_params_on_conversion ` When enabled following methods will swap existing parameters in-place ` ` module device ` ` e g meth ` nn Module cuda ` moving module between devices ` ` module dtype ` ` e g meth ` nn Module float ` converting module different dtype meth ` nn Module ` meth ` nn Module to_empty ` meth ` nn Module load_state_dict ` The semantics meth ` ~nn Module load_state_dict ` when set follows For each parameter buffer its corresponding ` ` state_dict key ` ` transformed via meth ` ~torch Tensor module_load ` i e ` ` res = param module_load state_dict key ` ` If necessary ` ` res ` ` will wrapped ` ~nn Parameter ` The parameter buffer module will swapped via func ` ~torch utils swap_tensors ` ` ` res ` ` Args value bool Whether use func ` ~torch utils swap_tensors ` global _swap_module_params_on_conversion _swap_module_params_on_conversion = value get_swap_module_params_on_conversion - bool Returns whether use func ` ~torch utils swap_tensors ` instead setting data change existing parameters in-place when converting ` ` nn Module ` ` Defaults ` ` False ` ` See func ` ~torch __future__ set_swap_module_params_on_conversion ` more information _swap_module_params_on_conversion