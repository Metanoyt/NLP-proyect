usr bin env python mypy allow-untyped-defs typing Any TypeVar Optional NamedTuple Union collections abc Callable Sequence textwrap torch torch _C TupleType ListType torch jit _recursive wrap_cpp_module T = TypeVar T MAX_RAW_TENSOR_SIZE = InflatableArg NamedTuple Helper type bundled inputs value compressed deflated input stored model Value must same type argument function deflated input fmt formatable code string executed inflate compressed data into appropriate input It can use value input format str It must result value same type value fmt_fn formatable function code string executed inflate compressed data into appropriate input It must result value same type value The function name should formatable part string Note Only top level InflatableArgs can inflated i e you cannot place inflatable arg inside some other structure You should instead create inflatable arg such fmt code string returns full structure your input value Any fmt str = fmt_fn str = bundle_inputs model torch jit ScriptModule inputs Union Optional Sequence tuple Any dict Callable Optional Sequence tuple Any info Optional Union list str dict Callable list str = None _receive_inflate_expr Optional list str = None - torch jit ScriptModule Create copy specified model inputs attached The original model mutated changed any way Models bundled inputs can invoked uniform manner benchmarking code coverage tools If inputs passed list then inputs will bundled forward If inputs instead passed map then all methods specified map will have their corresponding inputs bundled Info should match watchever type chosen inputs The returned model will support following methods ` get_all_bundled_inputs_for_ function_name - List Tuple Any ` Returns list tuples suitable passing model like ` inp model get_all_bundled_inputs_for_foo model foo inp ` ` get_bundled_inputs_functions_and_info - Dict str Dict str List str ` Returns dictionary mapping function names metadata dictionary This nested dictionary maps preset strings like get_inputs_function_name - name function attribute model can run get back list inputs corresponding function info - user provided extra information about bundled inputs If forward has bundled inputs then these following functions will also defined returned module ` get_all_bundled_inputs - List Tuple Any ` Returns list tuples suitable passing model like ` inp model get_all_bundled_inputs model inp ` ` get_num_bundled_inputs - int ` Equivalent ` len model get_all_bundled_inputs ` slightly easier call C++ Inputs can specified one two ways - The model can define ` _generate_bundled_inputs_for_ function_name ` If user chooses method inputs function should map None - The ` inputs ` argument function can dictionary mapping functions list inputs same form will returned get_all_bundled_inputs_for_ function_name Alternatively only bundling inputs forward map can omitted singular list inputs can provided instead The type inputs List Tuple Any The outer list corresponds list inputs inner tuple list args together make up one input For inputs functions take one arg will tuple length one The Any actual data makes up args e g tensor Info optional parameter maps functions list strings providing extra information about function s bundled inputs Alternatively only bundling inputs forward map can omitted singular list information can provided instead This could descriptions expected outputs etc - Ex info= model forward man eating icecream airplane dog This function will attempt optimize arguments so e g arguments like ` torch zeros ` will represented compactly Only top-level arguments will optimized Tensors lists tuples will isinstance model torch jit ScriptModule raise Exception Only ScriptModule supported noqa TRY ignored_methods ignored_attrs = _get_bundled_inputs_attributes_and_methods model clone = torch _C _hack_do_not_use_clone_module_with_class type ignore attr-defined model _c ignored_methods ignored_attrs The above cloning function returns torch _C scriptmodule we need torch jit scriptmodule Fortunately there function _recursive does exactly conversion cloned_module = wrap_cpp_module clone isinstance inputs dict isinstance info dict info None raise AssertionError If inputs dict info must dict None augment_many_model_functions_with_bundled_inputs cloned_module inputs _receive_inflate_expr info isinstance info list info None raise AssertionError If inputs list info must list None augment_model_with_bundled_inputs cloned_module inputs _receive_inflate_expr info cloned_module augment_model_with_bundled_inputs model torch jit ScriptModule inputs Optional Sequence tuple Any = None _receive_inflate_expr Optional list str = None For debugging info Optional list str = None Optional argument provide info about forward its inputs skip_size_check=False - None Add bundled sample inputs model forward function Models bundled inputs can invoked uniform manner benchmarking code coverage tools Augmented models will support following methods ` get_all_bundled_inputs - List Tuple Any ` Returns list tuples suitable passing model like ` inp model get_all_bundled_inputs model inp ` ` get_num_bundled_inputs - int ` Equivalent ` len model get_all_bundled_inputs ` slightly easier call C++ ` get_bundled_inputs_functions_and_info - Dict str Dict str List str ` Returns dictionary mapping function names metadata dictionary This nested dictionary maps preset strings like get_inputs_function_name - name function attribute model can run get back list inputs corresponding function info - user provided extra information about bundled inputs Inputs can specified one two ways - The model can define ` _generate_bundled_inputs_for_forward ` If user chooses method inputs should None - ` inputs ` list inputs form List Tuple Any A list tuples where elements each tuple args make up one input isinstance model torch jit ScriptModule raise Exception Only ScriptModule supported noqa TRY forward Callable = model forward Sometimes forward won t have name attached so just case hasattr forward __name__ forward __name__ = forward augment_many_model_functions_with_bundled_inputs model inputs= forward inputs _receive_inflate_expr=_receive_inflate_expr info= forward info info None skip_size_check=skip_size_check augment_many_model_functions_with_bundled_inputs model torch jit ScriptModule inputs dict Callable Optional Sequence tuple Any _receive_inflate_expr Optional list str = None For debugging info Optional dict Callable list str = None Optional argument provide info about function its inputs skip_size_check=False - None Add bundled sample inputs model arbitrary list public functions Models bundled inputs can invoked uniform manner benchmarking code coverage tools Augmented models will support following methods ` get_all_bundled_inputs_for_ function_name - List Tuple Any ` Returns list tuples suitable passing model like ` inp model get_all_bundled_inputs_for_foo model foo inp ` ` get_bundled_inputs_functions_and_info - Dict str Dict str List str ` Returns dictionary mapping function names metadata dictionary This nested dictionary maps preset strings like get_inputs_function_name - name function attribute model can run get back list inputs corresponding function info - user provided extra information about bundled inputs If forward has bundled inputs then these following functions also defined ` get_all_bundled_inputs - List Tuple Any ` Returns list tuples suitable passing model like ` inp model get_all_bundled_inputs model inp ` ` get_num_bundled_inputs - int ` Equivalent ` len model get_all_bundled_inputs ` slightly easier call C++ Inputs can specified one two ways - The model can define ` _generate_bundled_inputs_for_ function_name ` If user chooses method inputs function should map None - The ` inputs ` argument function can dictionary mapping functions list inputs same form will returned get_all_bundled_inputs_for_ function_name The type inputs List Tuple Any The outer list corresponds list inputs inner tuple list args together make up one input For inputs functions take one arg will tuple length one The Any actual data makes up args e g tensor Info optional parameter maps functions list strings providing extra information about function s bundled inputs This could descriptions expected outputs etc - Ex info= model forward man eating icecream airplane dog This function will attempt optimize arguments so e g arguments like ` torch zeros ` will represented compactly Only top-level arguments will optimized Tensors lists tuples will isinstance model torch jit ScriptModule raise Exception Only ScriptModule supported noqa TRY inputs raise Exception Please provide inputs least function noqa TRY hasattr model get_all_bundled_inputs hasattr model get_bundled_inputs_functions_and_info raise Exception noqa TRY Models can only augmented bundled inputs once This Model seems have already been augmented bundled inputs Please start afresh one doesn t have bundled inputs get_bundled_inputs_functions_and_info_template = function input_list inputs items hasattr function __name__ function_name = function __name__ hasattr function name function_name = function name type ignore attr-defined raise Exception noqa TRY At least one your functions has no attribute name please ensure all have one m foo name = foo input_list None isinstance input_list Sequence raise TypeError f Error inputs function function_name Sequence function_arg_types = arg type arg function schema arguments type ignore attr-defined deflated_inputs_type ListType = ListType TupleType function_arg_types model _c _register_attribute f _bundled_inputs_deflated_ function_name deflated_inputs_type hasattr model _generate_bundled_inputs_for_ + function_name input_list None raise Exception noqa TRY f inputs function_name None _generate_bundled_inputs_for_ function_name already defined Model author already defined _generate_bundled_inputs_for_ function_name input_list None len input_list == raise Exception noqa TRY f inputs function_name must specified f _generate_bundled_inputs_for_ function_name already defined Iterate over inputs args each input Accumulate ` deflated_inputs ` possibly compressed values ` parts ` joined into expression unpacks them deflated_inputs = parts = inp_idx args enumerate input_list isinstance args tuple isinstance args list type ignore arg-type raise TypeError f Error bundled input function function_name idx inp_idx Tuple List deflated_args = parts append arg_idx arg enumerate args inflate_helper_fn_name = _get_inflate_helper_fn_name arg_idx inp_idx function_name deflated inflater helper_definition = _inflate_expr arg f deflated inp_idx arg_idx inflate_helper_fn_name skip_size_check=skip_size_check deflated_args append deflated parts append f inflater helper_definition model define textwrap dedent helper_definition deflated_inputs append tuple deflated_args parts append parts append expr = \n join parts Back-channel expr debugging _receive_inflate_expr None _receive_inflate_expr append expr setattr model f _bundled_inputs_deflated_ function_name deflated_inputs definition = textwrap dedent _generate_bundled_inputs_for_ name deflated = _bundled_inputs_deflated_ name expr format expr=expr name=function_name model define definition Define get_all_bundled_inputs_for_ function_name caches generated inputs model define textwrap dedent get_all_bundled_inputs_for_ name all_inputs = _generate_bundled_inputs_for_ name assert all_inputs None all_inputs format name=function_name Add high level helper methods inputs_info = repr info function info function info get_bundled_inputs_functions_and_info_template += f temp_dict Dict str List str = info List str = inputs_info temp_dict info = info temp_dict get_inputs_function_name = get_all_bundled_inputs_for_ function_name all_inputs function_name = temp_dict To ensure backwards compatibility streamlined api forward these wrappers provided function_name == forward model define textwrap dedent get_all_bundled_inputs get_all_bundled_inputs_for_forward model define textwrap dedent get_num_bundled_inputs len get_all_bundled_inputs_for_forward Define some high level helper methods act all bundled inputs model define textwrap dedent f get_bundled_inputs_functions_and_info all_inputs Dict str Dict str List str = get_bundled_inputs_functions_and_info_template all_inputs _inflate_expr arg T ref str inflate_helper_fn_name str skip_size_check bool = False - tuple Union T torch Tensor str Optional str Allow custom inflation expressions any object For example calling custom image-decoding ops Or just use format string ignore size limits isinstance arg InflatableArg arg fmt_fn arg fmt raise Exception noqa TRY f Bundled input argument position ref has f both arg fmt_fn = \n arg fmt_fn f \n arg fmt = arg fmt Please choose ` arg fmt ` deflater straightforward ` arg fmt_fn ` you need function helper_definition = arg fmt_fn format inflate_helper_fn_name expr = f inflate_helper_fn_name ref arg value expr helper_definition arg value arg fmt format ref None isinstance arg torch Tensor Small-storage tensors can just saved directly arg _typed_storage size = MAX_RAW_TENSOR_SIZE skip_size_check arg ref None Small contiguous tensors can cloned have small storage TODO Should we do even non-contiguous tensors arg is_contiguous arg numel = MAX_RAW_TENSOR_SIZE arg clone ref None Example inputs commonly come torch zeros torch ones torch full These can represented compactly fmt torch contiguous_format torch channels_last arg is_contiguous memory_format=fmt arg == arg flatten all item arg flatten clone expand arg size f ref contiguous memory_format= fmt None Prevent big tensors being bundled default TODO Provide more useful diagnostics raise Exception noqa TRY f Bundled input argument position ref f tensor storage size arg _typed_storage size f You probably don t want bundle input arg ref None _get_bundled_inputs_attributes_and_methods script_module torch jit ScriptModule - tuple list str list str methods list str = attributes list str = Has bundled inputs forward hasattr script_module get_all_bundled_inputs methods append get_all_bundled_inputs methods append get_num_bundled_inputs methods append run_on_bundled_input hasattr script_module get_bundled_inputs_functions_and_info methods append get_bundled_inputs_functions_and_info all_info = script_module get_bundled_inputs_functions_and_info function_name all_info methods append get_all_bundled_inputs_for_ + function_name methods append _generate_bundled_inputs_for_ + function_name attributes append _bundled_inputs_deflated_ + function_name bundled_inputs_fn = getattr script_module f get_all_bundled_inputs_for_ function_name num_bundled_inputs int = len bundled_inputs_fn Check inflate helper functions each function argument bundled input func = getattr script_module function_name arg_idx range len func schema arguments - input_idx range num_bundled_inputs helper_fn_name = _get_inflate_helper_fn_name arg_idx=arg_idx input_idx=input_idx function_name=function_name arg has InflatableArg fmt_fn add helper function name hasattr script_module helper_fn_name methods append helper_fn_name methods attributes _get_inflate_helper_fn_name arg_idx int input_idx int function_name str - str f _inflate_helper_for_ function_name _input_ input_idx _arg_ arg_idx bundle_randn size dtype=None Generate tensor will inflated torch randn stub = torch zeros dtype=dtype expand size InflatableArg value=stub fmt= torch randn_like bundle_large_tensor t Wrap tensor allow bundling regardless size InflatableArg value=t fmt=