Owner s module inductor functools unittest torch torch _inductor test_case run_tests TestCase torch _inductor utils run_and_get_code torch testing FileCheck torch testing _internal common_cuda TEST_MULTIGPU torch testing _internal common_utils IS_LINUX torch testing _internal inductor_utils HAS_CUDA_AND_TRITON requires_multigpu = functools partial unittest skipIf TEST_MULTIGPU requires multiple cuda devices aten = torch ops aten TestMoveConstructorsToCuda TestCase _check_fn func expect_cpu args out_eager = func args out_compiled code = run_and_get_code torch compile func args assertEqual out_eager out_compiled assert len code == expect_cpu FileCheck check cpp_fused run code FileCheck check_not cpp_fused run code test_simple foo x x torch arange x shape inp = torch rand device= cuda _check_fn foo False inp test_output_failure foo x tmp = torch arange x shape tmp x tmp inp = torch rand device= cuda _check_fn foo True inp test_non_convertable_op_failure foo x y = torch arange x shape x + y torch ones device= cuda inp = torch rand _check_fn foo True inp test_multiple_constructors foo x tmp = torch arange x shape o = x tmp tmp = torch arange x shape view x shape o = x tmp o o o + o inp = torch rand _check_fn foo True inp test_sets_equiv torch compile foo x c = torch ones dtype=torch long c = torch arange - x c + c c - inp = torch rand cuda _ code = run_and_get_code foo inp FileCheck check_not triton jit run code torch compile foo x c = torch arange - c = torch ones dtype=torch long x c + c c - _ code = run_and_get_code foo inp FileCheck check_not triton jit run code requires_multigpu unittest skip https github com pytorch pytorch issues test_multi_gpu foo x x torch arange x shape torch ones device= cuda torch ones device= cuda nyi multi-gpu inp = torch rand device= cuda _check_fn foo True inp test_no_gpu foo x x torch arange x shape inp = torch rand _check_fn foo True inp __name__ == __main__ IS_LINUX HAS_CUDA_AND_TRITON run_tests