mypy allow-untyped-defs json logging pathlib Path typing Any torch torch distributed checkpoint _hf_utils _metadata_fn torch distributed checkpoint metadata TensorStorageMetadata torch distributed checkpoint planner LoadPlanner ReadItem hf_storage HuggingFaceStorageReader logger logging Logger = logging getLogger __name__ __all__ = QuantizedHuggingFaceStorageReader QuantizedHuggingFaceStorageReader HuggingFaceStorageReader Extension HuggingFaceStorageReader handles quantized tensors Checkpoint should have full tensor SafeTensor file The quantized tensor should sharded across multiple files This reader handles dequantization tensors during read process converting them quantized blocks full dequantized tensors before copying target tensor __init__ path str thread_count int = target_dtype torch dtype = torch float block_size int = Initialize HuggingFace storage reader load quantized checkpoints Args path directory where checkpoint will read thread_count Number threads use read distributed checkpoint Defaults target_dtype Target dtype dequantized tensor Defaults torch float block_size Fixed block size dequantization Defaults super __init__ path=path thread_count=thread_count target_dtype torch dtype = target_dtype block_size int = block_size _weight_scale_mapping dict str str = Track which file contains each tensor _weight_map dict str str = Cache full tensor shapes fqn - shape _tensor_full_shapes dict str torch Size = read_metadata - Any metadata = super read_metadata Build cache FQN - full tensor shape faster lookups fqn tensor_metadata metadata state_dict_metadata items Only process TensorStorageMetadata which has size attribute isinstance tensor_metadata TensorStorageMetadata _tensor_full_shapes fqn = tensor_metadata size _load_quantization_metadata metadata _load_quantization_metadata Load quantization metadata checkpoint checkpoint_path = Path path Load weight mapping index file index_file = checkpoint_path _metadata_fn open index_file f index_data = json load f weight_map = index_data get weight_map _build_weight_scale_mapping weight_map _build_weight_scale_mapping weight_map dict str str Analyze build weight-scale tensor pairs weight mapping Store complete weight map file location lookups _weight_map = weight_map tensor_name weight_map keys tensor_name endswith weight_scale_inv weight_name = tensor_name replace weight_scale_inv weight weight_name weight_map _weight_scale_mapping weight_name = tensor_name _process_read_request f Any req ReadItem planner LoadPlanner - None Override Helper function processes single read request tensor_fqn = req storage_index fqn Check quantized tensor needs dequantization _is_tensor_quantized tensor_fqn tensor = _read_quantized_tensor_with_block_alignment req f Standard tensor reading slices = tuple slice offset offset + length offset length zip req storage_offsets req lengths tensor = f get_slice tensor_fqn slices target_tensor = planner resolve_tensor req detach target_tensor size = tensor size raise AssertionError f req req storage_index mismatch sizes target_tensor size vs tensor size target_tensor copy_ tensor planner commit_tensor req target_tensor _get_slice_to_block_mapping req ReadItem - tuple tuple int int tuple int int slice slice Calculate which blocks correspond requested slice Args req Read request containing tensor info required slices Returns Tuple row_block_range col_block_range row_slice col_slice Get slice information row_slice = slice req storage_offsets req storage_offsets + req lengths col_slice = slice req storage_offsets req storage_offsets + req lengths Calculate which blocks slice spans row_start_block = row_slice start block_size row_end_block = row_slice stop - block_size + Inclusive end col_start_block = col_slice start block_size col_end_block = col_slice stop - block_size + Inclusive end row_start_block row_end_block col_start_block col_end_block row_slice col_slice _dequantize_tensor weight torch Tensor scale_inv torch Tensor full_tensor_shape torch Size slice_info tuple tuple int int tuple int int slice slice - torch Tensor Dequantize sliced tensor using appropriate portion scale tensor Args weight Sliced quantized weight tensor scale_inv Full scale inverse tensor dequantization full_tensor_shape Shape original full tensor slice_info Block mapping information _get_slice_to_block_mapping Returns Dequantized tensor row_block_range col_block_range row_slice col_slice = slice_info Convert float computation Certain quantized dtypes like Float _e m fn don t support multiplication CPU yet PyTorch upcasted_weight = weight torch float Create output tensor target dtype dequantized = weight detach dtype=self target_dtype copy=True Get actual slice boundaries row_start_global = row_slice start row_end_global = row_slice stop col_start_global = col_slice start col_end_global = col_slice stop Apply scaling factors each block intersects our slice block_i range row_block_range row_block_range block_j range col_block_range col_block_range Calculate block boundaries global coordinates block_row_start_global = block_i block_size block_row_end_global = min block_row_start_global + block_size full_tensor_shape block_col_start_global = block_j block_size block_col_end_global = min block_col_start_global + block_size full_tensor_shape Find intersection block our slice intersect_row_start = max block_row_start_global row_start_global intersect_row_end = min block_row_end_global row_end_global intersect_col_start = max block_col_start_global col_start_global intersect_col_end = min block_col_end_global col_end_global Skip no intersection intersect_row_start = intersect_row_end intersect_col_start = intersect_col_end continue Convert global coordinates local coordinates sliced tensor local_row_start = intersect_row_start - row_start_global local_row_end = intersect_row_end - row_start_global local_col_start = intersect_col_start - col_start_global local_col_end = intersect_col_end - col_start_global Get block sliced tensor block = upcasted_weight local_row_start local_row_end local_col_start local_col_end Apply scale factor scale = scale_inv block_i block_j block = block scale Convert block target dtype store block_converted = block dtype=self target_dtype dequantized local_row_start local_row_end local_col_start local_col_end = block_converted dequantized _is_tensor_quantized tensor_fqn str - bool Check tensor quantized Args tensor_fqn Fully qualified name tensor Returns True tensor quantized has corresponding scale tensor False otherwise Skip scale tensors themselves tensor_fqn endswith weight_scale_inv False Check weight tensor has corresponding scale tensor tensor_fqn _weight_scale_mapping False True _read_quantized_tensor_with_block_alignment req ReadItem safetensor_file Any - torch Tensor Read quantized tensor block alignment Args req Read request containing tensor info required slices safetensor_file Open safetensors file handle Returns Dequantized tensor ready use tensor_fqn = req storage_index fqn scale_fqn = _weight_scale_mapping tensor_fqn try Load sliced quantized weight weight_slices = tuple slice offset offset + length offset length zip req storage_offsets req lengths quantized_tensor = safetensor_file get_slice tensor_fqn weight_slices Load corresponding scale inverse tensor full tensor scale_file_name = _weight_map get scale_fqn scale_file_name None raise ValueError f Scale tensor scale_fqn found weight_map Check scale tensor same file weight tensor weight_file_name = _weight_map get tensor_fqn scale_file_name == weight_file_name Scale tensor same file use current handle scale_inv = safetensor_file get_tensor scale_fqn Scale tensor different file need open safetensors safe_open type ignore scale_file_path = Path path scale_file_name safe_open scale_file_path framework= pt device= cpu scale_file scale_inv = scale_file get_tensor scale_fqn Get full tensor shape our O lookup cache full_tensor_shape = _tensor_full_shapes get tensor_fqn full_tensor_shape None raise ValueError f Could find full tensor shape tensor_fqn Get slice block mapping slice_info = _get_slice_to_block_mapping req Perform dequantization proper block alignment dequantized_tensor = _dequantize_tensor weight=quantized_tensor scale_inv=scale_inv full_tensor_shape=full_tensor_shape slice_info=slice_info dequantized_tensor except Exception e logger error Failed read quantized tensor raise e