Owner s module unknown platform functools partial unittest skipIf skipif torch torch testing _internal common_device_type instantiate_device_type_tests OpDTypes ops torch testing _internal common_methods_invocations op_db torch testing _internal common_utils IS_MACOS run_tests skipIfTorchInductor TestCase TestGradients unMarkDynamoStrictTest TODO mitigate flaky issue macOS https github com pytorch pytorch issues AFAIK c ThreadPool looks correct way uses condition_variable wait The issue seems point macOS itself https github com graphia-app graphia issues IS_MACOS torch set_num_threads gradcheck requires double precision _gradcheck_ops = partial ops dtypes=OpDTypes supported allowed_dtypes= torch double torch cdouble unMarkDynamoStrictTest TestFwdGradients TestGradients Test forward-over-reverse gradgrad computed correctly _gradcheck_ops op_db test_fn_fwgrad_bwgrad device dtype op _skip_helper op device dtype op supports_fwgrad_bwgrad _check_helper device dtype op op get_op fwgrad_bwgrad err_msg = r Trying use forward AD does support hint_msg = Running forward-over-backward gradgrad OP has does support did raise any error If your op supports forward AD you should set supports_fwgrad_bwgrad=True assertRaisesRegex NotImplementedError err_msg msg=hint_msg _check_helper device dtype op op get_op fwgrad_bwgrad _forward_grad_helper device dtype op variant is_inplace TODO clean up how attributes passed gradcheck OpInfos call_grad_test_helper check_batched_forward_grad = op check_batched_forward_grad is_inplace op check_inplace_batched_forward_grad is_inplace _grad_test_helper device dtype op variant check_forward_ad=True check_backward_ad=False check_batched_grad=False check_batched_forward_grad=check_batched_forward_grad op supports_forward_ad call_grad_test_helper err_msg = r Trying use forward AD does support hint_msg = Running forward AD OP has does support did raise any error If your op supports forward AD you should set supports_forward_ad=True assertRaisesRegex NotImplementedError err_msg msg=hint_msg call_grad_test_helper _gradcheck_ops op_db skipif platform machine == s x reason= Different precision openblas functions https github com OpenMathLib OpenBLAS issues test_forward_mode_AD device dtype op _skip_helper op device dtype _forward_grad_helper device dtype op op get_op is_inplace=False _gradcheck_ops op_db skipIfTorchInductor fixed test_inplace_forward_mode_AD device dtype op _skip_helper op device dtype op inplace_variant op supports_inplace_autograd skipTest Skipped Operation does support inplace autograd _forward_grad_helper device dtype op _get_safe_inplace op get_inplace is_inplace=True instantiate_device_type_tests TestFwdGradients globals __name__ == __main__ TestCase _default_dtype_check_enabled = True run_tests