mypy allow-untyped-defs types warnings weakref copyreg dispatch_table typing Any torch torch cuda _pin_memory_utils pin_memory_utils torch storage UntypedStorage torch utils weak WeakIdKeyDictionary StateDictStager A optimizing storage objects during staging async checkpointing StateDictStager stages state_dict CPU DRAM while applying optimizations like memory sharing pinning improve performance It caches storage objects avoid redundant copies can configured automatically share memory multi-process usage pin memory faster CPU-GPU transfers Attributes pin_memory bool Whether pin CPU memory faster CPU-GPU transfers share_memory bool Whether share memory across processes pin_memory_min_bytes int Minimum tensor size bytes pin memory default _cached_storage_mapping WeakIdKeyDictionary Maps storage objects optimized CPU storages using weak references __init__ pin_memory bool = False share_memory bool = False pin_memory_min_bytes int = pin_memory torch cuda is_available warnings warn Ignoring pin_memory flag checkpoint staging pinning memory requires CUDA CUDA available stacklevel= pin_memory = False pin_memory = pin_memory share_memory = share_memory Mapping original storage objects CPU storages using weak references _cached_storage_mapping = WeakIdKeyDictionary pin_memory_min_bytes = pin_memory_min_bytes _deepcopy_atomic x _ x _deepcopy_list x memo non_blocking=False y list = memo id x = y append = y append x append deepcopy_with_tensor_offload memo non_blocking=non_blocking y _deepcopy_tuple x memo non_blocking=False y = deepcopy_with_tensor_offload memo non_blocking=non_blocking x We re going put tuple memo s still important we check case tuple contains recursive mutable structures try memo id x except KeyError pass Check any elements changed during deepcopy k j zip x y k j At least one element changed create new tuple tuple y No elements changed original tuple x _deepcopy_dict x memo non_blocking=False y dict = memo id x = y key value x items y deepcopy_with_tensor_offload key memo non_blocking=non_blocking = deepcopy_with_tensor_offload value memo non_blocking=non_blocking y _deepcopy_method x memo non_blocking=False Copy instance methods type x x __func__ deepcopy_with_tensor_offload x __self__ memo non_blocking=non_blocking d dict Any Any = _deepcopy_dispatch = d d type None = _deepcopy_atomic d int = _deepcopy_atomic d float = _deepcopy_atomic d bool = _deepcopy_atomic d complex = _deepcopy_atomic d bytes = _deepcopy_atomic d str = _deepcopy_atomic d types CodeType = _deepcopy_atomic d type = _deepcopy_atomic d range = _deepcopy_atomic d types BuiltinFunctionType = _deepcopy_atomic d types FunctionType = _deepcopy_atomic d weakref ref = _deepcopy_atomic d property = _deepcopy_atomic d types MethodType = _deepcopy_method d dict = _deepcopy_dict d tuple = _deepcopy_tuple d list = _deepcopy_list _stage_untyped_storage storage UntypedStorage non_blocking bool = False Called hooked storage_deepcopy function torch Tensor __deepcopy__ This method handles storage optimization logic StagingStateDict It checks storage has already been cached so reuses Otherwise creates new CPU storage applies memory optimizations Args storage The storage optimize Returns The optimized storage Check we ve already cached storage storage _cached_storage_mapping cached_storage = _cached_storage_mapping storage assert cached_storage size == storage size For async checkpointing We cache storages DRAM reuse them Cached storage size does match original storage size This should never happen we track original storage weakref clean up cache storage Please report PyTorch Distributed Checkpointing Reuse cached storage update new data cached_storage copy_ storage non_blocking=non_blocking cached_storage Create new CPU storage share_memory new_storage = type storage _new_shared storage size device= cpu new_storage = type storage storage size device= cpu Skip pinning tensors below minimum size threshold Small tensors e g optimizer step counters scalars have negligible transfer time improvement pinning pinning overhead significant pin_memory new_storage nbytes = pin_memory_min_bytes pin_memory_utils pin_memory new_storage data_ptr new_storage nbytes Set up weak reference unpin when cpu storage garbage collected f = weakref finalize new_storage pin_memory_utils unpin_memory new_storage data_ptr This makes sure finalizer called after cuda context destroyed f atexit = False new_storage copy_ storage non_blocking=non_blocking Cache storage - WeakIdKeyDictionary will automatically clean up when storage garbage collected _cached_storage_mapping storage = new_storage new_storage torch no_grad stage state_dict Any non_blocking bool = False - Any deepcopy_with_tensor_offload state_dict None non_blocking _offload_tensor x memo non_blocking=False Deep copy PyTorch tensor optimized storage handling This method creates CPU copy tensor while applying memory optimizations like sharing pinning based StateDictStager configuration Args x The tensor copy memo Memo dictionary tracking already copied objects non_blocking Whether perform non-blocking copies where possible Returns A CPU copy tensor optimized storage data_ptr we allocate new storage below so we can skip memory allocation using size y = x new_empty x data_ptr = x size device= cpu Store memo dict early handle recursive references d = id x memo d = y type x torch Tensor x data_ptr = Get untyped storage untyped_storage = x untyped_storage storage_id = id untyped_storage Check storage has already been staged deepcopy operation This handles case where different tensors share same storage e g FSDP state_dict where norm weight norm_weight reference same storage PyTorch caches untyped_storage calls so same storage - same id storage_id memo copied_storage = memo storage_id Storage seen before operation stage copied_storage = _stage_untyped_storage untyped_storage non_blocking=non_blocking Add memo avoid re-staging we see storage again memo storage_id = copied_storage Set tensor data using staged storage y set_ copied_storage x storage_offset x size x stride Copy any attributes tensor might have hasattr x __dict__ attr_name attr_value x __dict__ items setattr y attr_name deepcopy_with_tensor_offload attr_value memo non_blocking=non_blocking hasattr x __slots__ slot x __slots__ hasattr x slot setattr y slot deepcopy_with_tensor_offload getattr x slot memo non_blocking=non_blocking y close Clean up all cached storages release associated resources This method clears internal storage cache allowing garbage collection cached CPU storages Any pinned memory associated cached storages will automatically unpinned through weak reference finalizers _cached_storage_mapping clear torch no_grad deepcopy_with_tensor_offload x memo=None _nil= non_blocking=False noqa B Deep copy operation arbitrary Python objects special handling PyTorch tensors This implementation extends standard deepcopy functionality handle PyTorch tensors their storages way optimizes memory usage performance similar stage method It applies memory sharing pinning optimizations based StateDictStager configuration Args x The object deep copy memo Memo dictionary tracking already copied objects _nil Sentinel value memo dictionary non_blocking Whether perform non-blocking copies where possible Returns A deep copy input object optimized tensor storage handling memo None memo = d = id x y = memo get d _nil y _nil y cls = type x tensors subclasses tensors handled separately isinstance x torch Tensor y = _offload_tensor x memo non_blocking=non_blocking Use dispatch table standard types copier = _deepcopy_dispatch get cls copier None Check atomic copier only accepts x memo copier __name__ == _deepcopy_atomic y = copier x memo y = copier x memo non_blocking=non_blocking issubclass cls type type copier also atomic y = _deepcopy_dispatch type x memo copier = getattr x __deepcopy__ None copier None y = copier memo reductor = dispatch_table get cls reductor rv = reductor x reductor = getattr x __reduce_ex__ None reductor None rv = reductor reductor = getattr x __reduce__ None reductor rv = reductor raise RuntimeError f un deep copyable object type cls isinstance rv str y = x Unpack rv tuple elements up pickle protocol explicitly pass non_blocking keyword arg len rv == func args = rv y = _reconstruct x memo func args non_blocking=non_blocking len rv == func args state = rv y = _reconstruct x memo func args state non_blocking=non_blocking len rv == func args state listiter = rv y = _reconstruct x memo func args state listiter non_blocking=non_blocking len rv == func args state listiter dictiter = rv y = _reconstruct x memo func args state listiter dictiter non_blocking=non_blocking raise RuntimeError f Unexpected pickle protocol value length len rv If its own copy don t memoize y x memo d = y _keep_alive x memo Make sure x lives least long d y _keep_alive x memo Keeps reference object x memo Because we remember objects their id we have assure possibly temporary objects kept alive referencing them We store reference id memo which should normally used unless someone tries deepcopy memo itself try memo id memo append x except KeyError aha first one - memo id memo = x _reconstruct x memo func args state=None listiter=None dictiter=None non_blocking=False deep = memo None deep args args = tuple deepcopy_with_tensor_offload arg memo non_blocking=non_blocking arg args y = func args deep memo id x = y state None deep state = deepcopy_with_tensor_offload state memo non_blocking=non_blocking hasattr y __setstate__ y __setstate__ state isinstance state tuple len state == state slotstate = state slotstate = None state None y __dict__ update state slotstate None key value slotstate items setattr y key value listiter None deep item listiter item = deepcopy_with_tensor_offload item memo non_blocking=non_blocking y append item item listiter y append item dictiter None deep key value dictiter key = deepcopy_with_tensor_offload key memo non_blocking=non_blocking value = deepcopy_with_tensor_offload value memo non_blocking=non_blocking y key = value key value dictiter y key = value y