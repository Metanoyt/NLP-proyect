Owner s module unknown collections json os re textwrap timeit unittest typing Any expecttest numpy np torch torch utils benchmark benchmark_utils torch testing _internal common_utils IS_SANDCASTLE IS_WINDOWS run_tests slowTest TEST_WITH_ASAN TestCase CALLGRIND_ARTIFACTS str = os path join os path split os path abspath __file__ callgrind_artifacts json generate_callgrind_artifacts - None Regenerate ` callgrind_artifacts json ` Unlike expect tests regenerating callgrind counts will produce large diff since build directories conda pip directories included instruction string It also deterministic due jitter Python takes over minute run As result running function manual print Regenerating callgrind artifact stats_no_data = benchmark_utils Timer y = torch ones collect_callgrind number= stats_with_data = benchmark_utils Timer y = torch ones collect_callgrind number= user = os getenv USER to_entry fn_counts f c fn replace f user test_user c fn fn_counts artifacts = baseline_inclusive to_entry stats_no_data baseline_inclusive_stats baseline_exclusive to_entry stats_no_data baseline_exclusive_stats ones_no_data_inclusive to_entry stats_no_data stmt_inclusive_stats ones_no_data_exclusive to_entry stats_no_data stmt_exclusive_stats ones_with_data_inclusive to_entry stats_with_data stmt_inclusive_stats ones_with_data_exclusive to_entry stats_with_data stmt_exclusive_stats open CALLGRIND_ARTIFACTS w f json dump artifacts f indent= load_callgrind_artifacts - tuple benchmark_utils CallgrindStats benchmark_utils CallgrindStats Hermetic artifact unit test Callgrind wrapper In addition collecting counts wrapper provides some facilities manipulating displaying collected counts The results several measurements stored callgrind_artifacts json While FunctionCounts CallgrindStats pickleable artifacts testing stored raw string form easier inspection avoid baking any implementation details into artifact itself open CALLGRIND_ARTIFACTS f artifacts = json load f pattern = re compile r ^\s - + \s + $ to_function_counts count_strings list str inclusive bool - benchmark_utils FunctionCounts data list benchmark_utils FunctionCount = cs count_strings Storing entries f c fn rather than c fn adds some work reviving artifact makes json much easier read match = pattern search cs assert match None c fn = match groups data append benchmark_utils FunctionCount count=int c function=fn benchmark_utils FunctionCounts tuple sorted data reverse=True inclusive=inclusive baseline_inclusive = to_function_counts artifacts baseline_inclusive True baseline_exclusive = to_function_counts artifacts baseline_exclusive False stats_no_data = benchmark_utils CallgrindStats benchmark_utils TaskSpec y = torch ones pass number_per_run= built_with_debug_symbols=True baseline_inclusive_stats=baseline_inclusive baseline_exclusive_stats=baseline_exclusive stmt_inclusive_stats=to_function_counts artifacts ones_no_data_inclusive True stmt_exclusive_stats=to_function_counts artifacts ones_no_data_exclusive False stmt_callgrind_out=None stats_with_data = benchmark_utils CallgrindStats benchmark_utils TaskSpec y = torch ones pass number_per_run= built_with_debug_symbols=True baseline_inclusive_stats=baseline_inclusive baseline_exclusive_stats=baseline_exclusive stmt_inclusive_stats=to_function_counts artifacts ones_with_data_inclusive True stmt_exclusive_stats=to_function_counts artifacts ones_with_data_exclusive False stmt_callgrind_out=None stats_no_data stats_with_data MyModule torch nn Module forward x x + TestBenchmarkUtils TestCase regularizeAndAssertExpectedInline x Any expect str indent int = - None x_str str = re sub object x - a-fA-F + object xXXXXXXXXXXXX x isinstance x str repr x \n x_str Indent makes reference align call site x_str = textwrap indent x_str indent assertExpectedInline x_str expect skip= test_timer timer = benchmark_utils Timer stmt= torch ones sample = timer timeit median assertIsInstance sample float median = timer blocked_autorange min_run_time= median assertIsInstance median float We set very high threshold avoid flakiness CI The internal algorithm tested ` test_adaptive_timer ` median = timer adaptive_autorange threshold= median Test multi-line statements work properly median = benchmark_utils Timer stmt= torch no_grad y = x + setup= x = torch ones requires_grad=True _ range x = x + timeit median assertIsInstance sample float slowTest unittest skipIf IS_SANDCASTLE C++ timing OSS only unittest skipIf True Failing clang see test_timer_tiny_fast_snippet timer = benchmark_utils Timer auto x = void x timer=timeit default_timer language=benchmark_utils Language CPP median = timer blocked_autorange median assertIsInstance median float slowTest unittest skipIf IS_SANDCASTLE C++ timing OSS only unittest skipIf True Failing clang see test_cpp_timer timer = benchmark_utils Timer #ifndef TIMER_GLOBAL_CHECK static_assert false #endif torch Tensor y = x + setup= torch Tensor x = torch empty global_setup= #define TIMER_GLOBAL_CHECK timer=timeit default_timer language=benchmark_utils Language CPP t = timer timeit assertIsInstance t median float _MockTimer _seed = _timer_noise_level = _timer_cost = e- ns _function_noise_level = _function_costs = pass e- cheap_fn e- expensive_fn e- torch no_grad \n y = x + e- __init__ stmt setup timer globals _random_state = np random RandomState seed=self _seed _mean_cost = dict _function_costs stmt sample mean noise_level max _random_state normal mean mean noise_level e- timeit number sum First timer invocation sample _timer_cost _timer_noise_level Stmt body sample _mean_cost number _function_noise_level Second timer invocation sample _timer_cost _timer_noise_level test_adaptive_timer MockTimer benchmark_utils Timer _timer_cls = _MockTimer _MockCudaTimer _MockTimer torch cuda synchronize much more expensive than just timeit default_timer _timer_cost = e- _function_costs = _MockTimer _function_costs _MockTimer _function_costs GPU should faster once there enough work expensive_fn e- MockCudaTimer benchmark_utils Timer _timer_cls = _MockCudaTimer m = MockTimer pass blocked_autorange min_run_time= regularizeAndAssertExpectedInline m \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX pass Median ns IQR ns measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer pass adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX pass Median ns IQR ns measurements runs per measurement thread Check against strings so we can reuse expect infra regularizeAndAssertExpectedInline m mean e- regularizeAndAssertExpectedInline m median e- regularizeAndAssertExpectedInline len m times regularizeAndAssertExpectedInline m number_per_run regularizeAndAssertExpectedInline MockTimer cheap_fn blocked_autorange min_run_time= \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX cheap_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer cheap_fn adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX cheap_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer expensive_fn blocked_autorange min_run_time= \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX expensive_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer expensive_fn adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX expensive_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer pass blocked_autorange min_run_time= \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX pass Median ns IQR ns measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer pass adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX pass Median ns IQR ns measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer cheap_fn blocked_autorange min_run_time= \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX cheap_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer cheap_fn adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX cheap_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer expensive_fn blocked_autorange min_run_time= \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX expensive_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockCudaTimer expensive_fn adaptive_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX expensive_fn Median us IQR us measurements runs per measurement thread Make sure __repr__ reasonable multi-line label sub_label description we don t need check numerics multi_line_stmt = torch no_grad y = x + regularizeAndAssertExpectedInline MockTimer multi_line_stmt blocked_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX stmt torch no_grad y = x + Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer multi_line_stmt sub_label= scalar_add blocked_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX stmt scalar_add torch no_grad y = x + Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer multi_line_stmt label= x + no grad sub_label= scalar_add blocked_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX x + no grad scalar_add Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer multi_line_stmt setup= setup_fn sub_label= scalar_add blocked_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX stmt scalar_add torch no_grad y = x + setup setup_fn Median us IQR us measurements runs per measurement thread regularizeAndAssertExpectedInline MockTimer multi_line_stmt setup= x = torch ones requires_grad=True _ range x = x + sub_label= scalar_add description= Multi-threaded scalar math num_threads= blocked_autorange \ torch utils benchmark utils common Measurement object xXXXXXXXXXXXX stmt scalar_add torch no_grad y = x + Multi-threaded scalar math setup x = torch ones requires_grad=True _ range x = x + Median us IQR us measurements runs per measurement threads slowTest unittest skipIf IS_WINDOWS Valgrind supported Windows unittest skipIf IS_SANDCASTLE Valgrind OSS only unittest skipIf TEST_WITH_ASAN fails asan test_collect_callgrind assertRaisesRegex ValueError r ` collect_callgrind ` requires globals wrapped r ` CopyIfCallgrind ` so serialization explicit benchmark_utils Timer pass globals= x collect_callgrind collect_baseline=False assertRaisesRegex Subprocess raises AttributeError pickle _ValgrindWrapper re-raises generic OSError OSError AttributeError Can t get attribute MyModule benchmark_utils Timer model globals= model benchmark_utils CopyIfCallgrind MyModule collect_callgrind collect_baseline=False torch jit script add_one x x + timer = benchmark_utils Timer y = add_one x + k setup= x = torch ones globals= add_one benchmark_utils CopyIfCallgrind add_one k benchmark_utils CopyIfCallgrind model benchmark_utils CopyIfCallgrind MyModule setup=f \ sys sys path append repr os path split os path abspath __file__ test_benchmark_utils MyModule stats = timer collect_callgrind number= counts = stats counts denoise=False assertIsInstance counts int assertGreater counts There some jitter allocator so we use simpler task test reproducibility timer = benchmark_utils Timer x += setup= x = torch ones stats = timer collect_callgrind number= repeats= assert isinstance stats tuple Check repeats least somewhat repeatable within instructions per iter counts = collections Counter s counts denoise=True _ _ s stats assertGreater max counts values f Every instruction count total unique counts torch utils benchmark utils valgrind_wrapper timer_interface wrapper_singleton assertIsNone wrapper_singleton _bindings_module JIT d bindings only back testing slowTest unittest skipIf IS_WINDOWS Valgrind supported Windows unittest skipIf IS_SANDCASTLE Valgrind OSS only unittest skipIf True Failing clang see test_collect_cpp_callgrind timer = benchmark_utils Timer x += setup= torch Tensor x = torch ones timer=timeit default_timer language= c++ stats = timer collect_callgrind _ range counts = s counts s stats assertGreater min counts No stats collected assertEqual min counts max counts C++ Callgrind should deterministic s stats assertEqual s counts denoise=True s counts denoise=False De-noising should apply C++ stats = timer collect_callgrind number= repeats= assert isinstance stats tuple NB Unlike example above there no expectation all repeats will identical counts = collections Counter s counts denoise=True _ _ s stats assertGreater max counts values repr counts test_manipulate_callgrind_stats stats_no_data stats_with_data = load_callgrind_artifacts Mock ` torch set_printoptions linewidth= ` wide_linewidth = benchmark_utils FunctionCounts stats_no_data stats inclusive=False _data False _linewidth= l repr wide_linewidth splitlines keepends=False assertLessEqual len l assertEqual ` delta ` just convenience method stats_with_data delta stats_no_data _data stats_with_data stats - stats_no_data stats _data deltas = stats_with_data as_standardized delta stats_no_data as_standardized custom_transforms fn str fn = re sub re escape usr include c++ bits fn fn = re sub r build fn fn = re sub + + re escape libsupc++ libsupc++ fn fn regularizeAndAssertExpectedInline stats_no_data \ torch utils benchmark utils valgrind_wrapper timer_interface CallgrindStats object xXXXXXXXXXXXX y = torch ones All Noisy symbols removed Instructions Baseline runs per measurement thread regularizeAndAssertExpectedInline stats_no_data counts regularizeAndAssertExpectedInline stats_no_data counts denoise=True regularizeAndAssertExpectedInline stats_no_data stats \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX __tls_get_addr usr lib ld- so _int_free usr lib libc- so build torch csrc utils python rch torch lib libtorch_python so build aten src ATen record_fu ytorch torch lib libtorch_cpu so build c core Device h c epos pytorch torch lib libc so _int_malloc usr lib libc- so build c core TensorOptions ytorch torch lib libtorch_cpu so tmp build af python_ da envs throwaway bin python malloc usr lib libc- so usr include c++ ext new_allocator h torch PythonArgs intlist int usr include c++ bits stl_vect _object _object _object usr include c++ bits stl_vect rningHandler ~PyWarningHandler usr include c++ bits stl_vect ject _object _object bool usr include c++ bits stl_algobase h torch PythonArgs intlist int usr include c++ bits shared_p ad_accumulator Tensor const usr include c++ bits move h c te c AutogradMetaInterface usr include c++ bits atomic_b DispatchKey caffe TypeMeta usr include c++ array Ten Tensor c Scalar const Total regularizeAndAssertExpectedInline stats_no_data stats inclusive=True \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX x usr lib ld- so below main usr lib libc- so tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python tmp build af python_ envs throwaway bin python build torch csrc tensor pytho ch torch lib libtorch_python so codespell ignore data users test_user repos pyto nsors get_default_scalar_type pthread_mutex_lock usr lib libpthread- so build c core TensorImpl h c ch torch lib libtorch_python so build aten src ATen record_fu torch torch lib libtorch_cpu so data users test_user repos pyto uard std optional c Device data users test_user repos pyto ersionCounter ~VersionCounter data users test_user repos pyto ratorKernel Tensor const replace codespell ignore regularizeAndAssertExpectedInline wide_linewidth \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX __tls_get_addr usr lib ld- so _int_free usr lib libc- so build torch csrc utils python_arg_parser cpp torch FunctionSignature bool data users test_user repos pytorch torch lib libtorch_python so build aten src ATen record_function cpp RecordFunction RecordFun ordScope data users test_user repos pytorch torch lib libtorch_cpu so build c core Device h c Device validate data users test_user repos pytorch torch lib libc so _int_malloc usr lib libc- so build c core TensorOptions h c TensorOptions merge_in c Tens ns const data users test_user repos pytorch torch lib libtorch_cpu so tmp build af python_ work Python ceval c _PyEval_EvalFrameDefault home test_user miniconda envs throwaway bin python malloc usr lib libc- so usr include c++ ext new_allocator h torch PythonArgs intlist int usr include c++ bits stl_vector h torch PythonArgParser raw_parse _object _object _object _object usr include c++ bits stl_vector h torch PyWarningHandler ~PyWarningHandler usr include c++ bits stl_vector h torch FunctionSignature parse _object _object _object _object bool usr include c++ bits stl_algobase h torch PythonArgs intlist int usr include c++ bits shared_ptr_base h torch autograd impl try_get_grad_accumulator Tensor const usr include c++ bits move h c TensorImpl set_autograd_meta std u AutogradMetaInterface std default_delete c AutogradMetaInterface usr include c++ bits atomic_base h Tensor detail make_tensor t_null_type c StorageImpl c DispatchKey caffe TypeMeta usr include c++ array Tensor c Dispatcher callWithDispatchKe c Scalar const c DispatchKey Tensor c Scalar const Total noqa B regularizeAndAssertExpectedInline stats_no_data as_standardized stats \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX __tls_get_addr _int_free build torch csrc utils python ject _object _object bool build aten src ATen record_fu RecordFunction RecordScope build c core Device h c Device validate _int_malloc build c core TensorOptions erge_in c TensorOptions const Python ceval c _PyEval_EvalFrameDefault malloc usr include c++ ext new_allocator h torch PythonArgs intlist int usr include c++ bits stl_vect _object _object _object usr include c++ bits stl_vect rningHandler ~PyWarningHandler usr include c++ bits stl_vect ject _object _object bool usr include c++ bits stl_algobase h torch PythonArgs intlist int usr include c++ bits shared_p ad_accumulator Tensor const usr include c++ bits move h c te c AutogradMetaInterface usr include c++ bits atomic_b DispatchKey caffe TypeMeta usr include c++ array Ten Tensor c Scalar const Total regularizeAndAssertExpectedInline deltas \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX Objects dictobject c lookdict_unicode _int_free malloc build torch csrc utils python torch PythonArgs intlist int __tls_get_addr free Objects dictobject c lookdict_unicode_nodummy build torch csrc utils python torch PythonArgs intlist int Objects longobject c PyLong_AsLongLongAndOverflow home nwani m conda-bld compile del_op cc operator delete void usr include c++ bits stl_vector h torch PythonArgs intlist int _int_malloc _int_memalign - build c util SmallVector h _contiguous c ArrayRef long - build c util SmallVector h nsor_restride c MemoryFormat - usr include c++ bits stl_vect es _object _object _object - Python ceval c _PyEval_EvalFrameDefault - Objects tupleobject c PyTuple_New Total regularizeAndAssertExpectedInline len deltas regularizeAndAssertExpectedInline deltas transform custom_transforms \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX Objects dictobject c lookdict_unicode _int_free malloc torch csrc utils python_numbers h torch PythonArgs intlist int __tls_get_addr free Objects dictobject c lookdict_unicode_nodummy torch csrc utils python_arg_parser h torch PythonArgs intlist int Objects longobject c PyLong_AsLongLongAndOverflow c util SmallVector h c TensorImpl compute_contiguous const stl_vector h torch PythonArgs intlist int _int_malloc _int_memalign - stl_vector h torch autograd TH es _object _object _object - c util SmallVector h c Tens _contiguous c ArrayRef long - c util SmallVector h c Tens nsor_restride c MemoryFormat - Python ceval c _PyEval_EvalFrameDefault - Objects tupleobject c PyTuple_New Total regularizeAndAssertExpectedInline deltas filter lambda fn fn startswith \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX _int_free malloc __tls_get_addr free _int_malloc _int_memalign Total regularizeAndAssertExpectedInline deltas \ torch utils benchmark utils valgrind_wrapper timer_interface FunctionCounts object xXXXXXXXXXXXX Objects dictobject c lookdict_unicode _int_free malloc build torch csrc utils python_ h torch PythonArgs intlist int __tls_get_addr Total test_compare Simulate several approaches costs = overhead_optimized_fn e- e- compute_optimized_fn e- e- special_case_fn square inputs only e- e- sizes = overhead_optimized_fn _MockTimer_ _MockTimer _function_costs = tuple f fn i j costs + costs i j i j sizes MockTimer_ benchmark_utils Timer _timer_cls = _MockTimer_ compute_optimized_fn _MockTimer_ _MockTimer _function_costs = tuple f fn i j costs + costs i j i j sizes MockTimer_ benchmark_utils Timer _timer_cls = _MockTimer_ special_case_fn _MockTimer_ _MockTimer _function_costs = tuple f fn i j costs + costs i j i j sizes i == j MockTimer_ benchmark_utils Timer _timer_cls = _MockTimer_ results = i j sizes results append MockTimer_ f fn i j label= fn description=f i j sub_label= overhead_optimized blocked_autorange min_run_time= results append MockTimer_ f fn i j label= fn description=f i j sub_label= compute_optimized blocked_autorange min_run_time= i == j results append MockTimer_ f fn i j label= fn description=f i j sub_label= special_case square blocked_autorange min_run_time= rstrip_lines s str - str VSCode will rstrip ` expected ` string literal whether you like So we have rstrip compare table well \n join i rstrip i s splitlines keepends=False compare = benchmark_utils Compare results regularizeAndAssertExpectedInline rstrip_lines str compare strip \ ------------------------------------------------- fn ------------------------------------------------ &#124; &#124; &#124; &#124; &#124; threads -------------------------------------------------------------------------------------------- overhead_optimized &#124; &#124; &#124; &#124; &#124; compute_optimized &#124; &#124; &#124; &#124; &#124; special_case square &#124; &#124; &#124; &#124; &#124; Times microseconds us compare trim_significant_figures regularizeAndAssertExpectedInline rstrip_lines str compare strip \ ------------------------------------------------- fn ------------------------------------------------ &#124; &#124; &#124; &#124; &#124; threads -------------------------------------------------------------------------------------------- overhead_optimized &#124; &#124; &#124; &#124; &#124; compute_optimized &#124; &#124; &#124; &#124; &#124; special_case square &#124; &#124; &#124; &#124; &#124; Times microseconds us compare colorize columnwise_colored_actual = rstrip_lines str compare strip columnwise_colored_expected = textwrap dedent \ ------------------------------------------------- fn ------------------------------------------------ &#124; &#124; &#124; &#124; &#124; threads -------------------------------------------------------------------------------------------- overhead_optimized &#124; &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m compute_optimized &#124; \x b m\x b m \x b m\x b m &#124; &#124; &#124; \x b m\x b m \x b m\x b m &#124; special_case square &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m Times microseconds us noqa B compare colorize rowwise=True rowwise_colored_actual = rstrip_lines str compare strip rowwise_colored_expected = textwrap dedent \ ------------------------------------------------- fn ------------------------------------------------ &#124; &#124; &#124; &#124; &#124; threads -------------------------------------------------------------------------------------------- overhead_optimized &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m compute_optimized &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m &#124; \x b m\x b m \x b m\x b m special_case square &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m &#124; &#124; \x b m\x b m \x b m\x b m Times microseconds us noqa B print_new_expected s str - None print f \\ end= l s splitlines keepends=False print \n + textwrap indent repr l - end= print \n expecttest ACCEPT expecttest does currently support non-printable characters so these two entries have updated manually columnwise_colored_actual = columnwise_colored_expected print New columnwise coloring \n print_new_expected columnwise_colored_actual rowwise_colored_actual = rowwise_colored_expected print New rowwise coloring \n print_new_expected rowwise_colored_actual assertEqual columnwise_colored_actual columnwise_colored_expected assertEqual rowwise_colored_actual rowwise_colored_expected unittest skipIf IS_WINDOWS os getenv VC_YEAR == Random seed only accepts int test_fuzzer fuzzer = benchmark_utils Fuzzer parameters= benchmark_utils FuzzedParameter n minval= maxval= distribution= loguniform tensors= benchmark_utils FuzzedTensor x size= n seed= expected_results = i tensors _ _ enumerate fuzzer take x = tensors x assertEqual x torch tensor expected_results i rtol= e- atol= e- __name__ == __main__ run_tests