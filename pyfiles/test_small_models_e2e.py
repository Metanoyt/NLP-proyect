Owner s module onnx Unit tests onnx dynamo exporter __future__ annotations logging pytest transformers onnxscript ir torch torch onnx _internal exporter _testing onnx_testing torch testing _internal common_utils torch utils _pytree torch_pytree _WithExport export model args= kwargs=None options - torch onnx ONNXProgram isinstance model torch nn Module model = model eval onnx_program = torch onnx export model args kwargs=kwargs dynamo=True fallback=False verbose=False options assert onnx_program None onnx_program common_utils instantiate_parametrized_tests DynamoExporterTest common_utils TestCase _WithExport test_insert_contiguous_between_transpose_and_view Model torch nn Module forward query key value res = torch nn functional scaled_dot_product_attention query key value rest = res transpose rest view model = Model query = torch rand dtype=torch float key = torch rand dtype=torch float value = torch rand dtype=torch float ep = torch export export model query key value strict=False assertNotIn call_method str ep graph onnx_program = export model query key value onnx_testing assert_onnx_program onnx_program atol= e- rtol= test_constant_complex MulModule torch nn Module forward x y = + j torch ops aten mul x y Example usage complex inputs x = torch tensor + j + j + j + j dtype=torch complex onnx_program = export MulModule x onnx_testing assert_onnx_program onnx_program test_pow_does_not_trigger_type_promotion Model torch nn Module forward x x x = torch tensor dtype=torch float onnx_program = export Model x onnx_testing assert_onnx_program onnx_program assertNotIn Cast node op_type node onnx_program model graph test_onnx_export_control_flow CondModel torch nn Module forward x true_fn x x + false_fn x x - y = torch cond x sum true_fn false_fn x y onnx_program = export CondModel torch tensor onnx_model = onnx_program model assertIn If node op_type node onnx_model graph onnx_testing assert_onnx_program onnx_program Test different branches onnx_testing assert_onnx_program onnx_program args= torch tensor - - test_onnx_export_nested_control_flow_and_nested_weights Submodule torch nn Module __init__ super __init__ Nested weight weight = torch nn Parameter torch tensor forward x true_fn x x weight false_fn x x weight y = torch cond x sum = true_fn false_fn x y CondModel torch nn Module __init__ super __init__ submodule = Submodule weight = torch nn Parameter torch tensor forward x true_fn x submodule x - weight false_fn x x - weight y = torch cond x sum true_fn false_fn x y onnx_program = export CondModel torch tensor onnx_testing assert_onnx_program onnx_program onnx_testing assert_onnx_program onnx_program args= torch tensor onnx_testing assert_onnx_program onnx_program args= torch tensor test_onnx_export_control_flow_multi_outputs CondModel torch nn Module forward x z = torch ones_like x true_fn x z x = x + z = z x z false_fn x z x = x - z = z x z x = torch cond x sum true_fn false_fn x z x z onnx_program = export CondModel torch tensor onnx_testing assert_onnx_program onnx_program onnx_testing assert_onnx_program onnx_program args= torch tensor - - test_empty EmptyModel torch nn Module forward x torch empty x size dtype=torch int Since ` torch empty ` returns tensor uninitialized data we cannot test under ` test_fx_to_onnx_with_onnxruntime py ` result comparison _ = export EmptyModel torch randn test_multiple_outputs_op_with_evaluator TopKModel torch nn Module forward x values _ = torch topk x torch sum values onnx_program = export TopKModel torch arange requires_grad=True onnx_testing assert_onnx_program onnx_program test_exported_program_torch_distributions_normal_Normal Model torch nn Module __init__ - None normal = torch distributions normal Normal super __init__ forward x normal sample x shape torch no_grad exported_program = torch export export Model args= torch randn strict=False _ = export exported_program common_utils parametrize float _type onnx_type common_utils subtest torch float _e m ir DataType FLOAT E M name= torch_float _e m common_utils subtest torch float _e m fnuz ir DataType FLOAT E M FNUZ name= torch_float _e m fnuz common_utils subtest torch float _e m fn ir DataType FLOAT E M FN name= torch_float _e m fn common_utils subtest torch float _e m fnuz ir DataType FLOAT E M FNUZ name= torch_float _e m fnuz test_float _support float _type torch dtype onnx_type ir DataType Float Module torch nn Module forward input torch Tensor input = input float _type input onnx_program = export Float Module torch randn assertEqual onnx_program model graph outputs dtype onnx_type test_float _support Float Module torch nn Module forward torch empty dtype=torch float _e m fn_x onnx_program = export Float Module optimize=False output = onnx_program model graph outputs assertEqual output dtype ir DataType FLOAT E M The shape shape - shape - because ONNX stores shape unpacked tensor assertEqual output shape numpy test_bfloat _support BfloatModel torch nn Module __init__ super __init__ Test parameters param = torch nn Parameter torch tensor dtype=torch bfloat forward x Test constant tensors stored bfloat const = torch tensor dtype=torch bfloat x const param input = torch tensor dtype=torch bfloat onnx_program = export BfloatModel input optimize=False initializers = onnx_program model graph initializers values assertEqual len initializers initializer initializers assertEqual initializer dtype ir DataType BFLOAT assertEqual onnx_program model graph inputs dtype ir DataType BFLOAT assertEqual onnx_program model graph outputs dtype ir DataType BFLOAT test_export_with_logging_logger logger = logging getLogger __name__ LoggingLoggerModule torch nn Module forward x logger info abc x + onnx_program = export LoggingLoggerModule torch tensor onnx_testing assert_onnx_program onnx_program test_export_with_hf_logging_logger logger = transformers utils logging get_logger __name__ HFLoggingLoggerModule torch nn Module forward x logger warning_once abc x + onnx_program = export HFLoggingLoggerModule torch tensor onnx_testing assert_onnx_program onnx_program test_export_with_print PrintModule torch nn Module forward x print abc x + onnx_program = export PrintModule torch tensor onnx_testing assert_onnx_program onnx_program test_export_with_dynamic_input Model torch nn Module forward x x + dim = torch export Dim dim onnx_program = export Model torch randn dtype=torch float dynamic_shapes= dim onnx_testing assert_onnx_program onnx_program args= torch randn dtype=torch float test_export_with_specialized_input_during_tracing Model torch nn Module forward x y x + y dim _x = torch export Dim dim _x min= dynamic_shapes = x dim _x y torch export Dim STATIC specialized input y during tracing onnx_program = export Model torch ones dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program args= torch ones test_export_with_none_arg_name_in_dynamic Model torch nn Module forward b sum + b sum dim = torch export Dim dim onnx_program = export Model torch randn torch randn dynamic_shapes= None dim test_inputs = torch randn torch randn onnx_testing assert_onnx_program onnx_program args=test_inputs test_export_with_non_arg_name_with_kwarg Model torch nn Module forward b kw kw sum + b sum + kw sum - kw sum dim = torch export Dim dim dim_for_kw = torch export Dim dim_for_kw onnx_program = export Model torch randn torch randn kw torch ones kw torch zeros We specifying dynamism first kwarg even though user passed different order dynamic_shapes= None dim dim_for_kw None This should work even kwarg order flipped onnx_testing assert_onnx_program onnx_program args= torch randn torch randn kwargs= kw torch ones kw torch zeros test_export_with_input_lifting_buffers_mutation persistent True False CustomModule torch nn Module __init__ - None super __init__ register_buffer my_buffer torch tensor persistent=persistent forward x b output = x + b my_buffer add_ + Mutate buffer through in-place addition output dim = torch export Dim dim onnx_program = export CustomModule torch rand dtype=torch float torch randn dynamic_shapes= dim dim onnx_testing assert_onnx_program onnx_program args= torch rand dtype=torch float torch randn test_export_with_non_arg_name_with_container_type Model torch nn Module forward b sum + sum + b sum count = dynamify_inp x Mark second input dynamic nonlocal count count == dim = torch export Dim dim min= count += dim count += None dynamic_shapes = torch_pytree tree_map dynamify_inp torch randn torch randn torch randn onnx_program = export Model torch randn torch randn torch randn dynamic_shapes=dynamic_shapes NOTE Careful input format The input format should consistent how model exported onnx_testing assert_onnx_program onnx_program args= torch randn torch randn torch randn test_export_with_lazy_module_kwargs LazyModule torch nn modules lazy LazyModuleMixin torch nn Module initialize_parameters args kwargs pass forward x y x + y m = LazyModule dim = torch export Dim dim dynamic_shapes = dim dim onnx_program = export m x torch randn y torch randn dynamic_shapes=dynamic_shapes inputs = x torch randn y torch randn onnx_testing assert_onnx_program onnx_program kwargs=inputs test_export_of_rename_dynamic_axes_required_model_with_mixed_type_of_dynamic_shapes NestedModel torch nn Module forward x torch Tensor ys list torch Tensor zs dict str torch Tensor c torch Tensor y = ys + ys + zs + zs b w = x shape c shape = x + w x + y c x - w x - y c input = torch ones torch zeros torch ones torch zeros b torch ones torch ones dynamic_shapes = torch export Dim dim_x min= Dim custom_name_axis_ys_ torch export Dim AUTO custom name torch export Dim AUTO b custom_name_axis_zs_b_ _DimHint custom_name_axis_c_ custom name Export model Assert warning message assertWarnsRegex UserWarning The axis name will used since shares same shape constraints another axis onnx_program = export NestedModel input dynamic_shapes=dynamic_shapes optimize=False Assert exported model input = torch ones torch zeros torch ones torch zeros b torch ones torch ones onnx_testing assert_onnx_program onnx_program args=input Assert dynamic axes names Some names respected because they share same shape constraints so they same ExportedProgram expected_axis_names = dim_x dim_x dim_x dim_x dim_x custom_name_axis_c_ expected_axis_name input zip expected_axis_names onnx_program model graph inputs assertEqual input shape value expected_axis_name test_export_of_static_dim_constraints NOTE This test ensure static dim constraints respected Model torch nn Module __init__ - None super __init__ l = torch nn Linear forward x y z x = l x + y x z inputs = torch randn torch randn torch randn dx = torch export Dim dx min= max= dy = dx + dz = torch export Dim dz min= max= all these should fine dynamic_shapes = dx torch export Dim AUTO dy torch export Dim STATIC dz onnx_program = export Model inputs dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program make sre naming working assertEqual onnx_program model graph inputs shape dx test_export_sym_max Model torch nn Module forward x torch sym_max x shape inputs = torch zeros dynamic_shapes = torch export Dim DYNAMIC torch export Dim DYNAMIC onnx_program = export Model inputs dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program assertIn Max node op_type node onnx_program model graph test_export_sym_min Model torch nn Module forward x torch sym_min x shape inputs = torch zeros dynamic_shapes = torch export Dim DYNAMIC torch export Dim DYNAMIC onnx_program = export Model inputs dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program assertIn Min node op_type node onnx_program model graph test_export_sym_not SymNotModel torch nn Module forward x comparison = x shape == x shape torch sym_not comparison inputs = torch zeros dynamic_shapes = torch export Dim DYNAMIC torch export Dim DYNAMIC onnx_program = export SymNotModel inputs dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program assertIn Not node op_type node onnx_program model graph test_export_sym_float SymFloatModel torch nn Module forward x = x shape torch sym_float inputs = torch zeros dynamic_shapes = torch export Dim DYNAMIC torch export Dim DYNAMIC onnx_program = export SymFloatModel inputs dynamic_shapes=dynamic_shapes onnx_testing assert_onnx_program onnx_program assertIn Cast node op_type node onnx_program model graph test_scan_cdist_add dist unused torch Tensor x torch Tensor samex torch Tensor sub = samex - x reshape - sq = sub sub rd = torch sqrt sq sum axis= unused clone rd ScanModel torch nn Module forward x z = torch tensor dtype=torch float y = x clone out = torch ops higher_order scan dist z x additional_inputs= y out inputs = torch tensor - - - dtype=torch float onnx_program = export ScanModel inputs onnx_testing assert_onnx_program onnx_program test_scan_cdist_dynamic_shapes dist y torch Tensor scanned_x torch Tensor sub = y - scanned_x reshape - sq = sub sub rd = torch sqrt sq sum axis= y clone rd ScanModel torch nn Module forward x y carry out = torch ops higher_order scan dist y x additional_inputs= out x_rows = torch export Dim x_rows y_rows = torch export Dim y_rows dim = torch export Dim dim inputs = torch randn torch randn onnx_program = export ScanModel inputs dynamic_shapes= x_rows dim y_rows dim onnx_testing assert_onnx_program onnx_program pytest mark xfail reason= Data dependent error test_scan_loop_inplace dummy_loop padded torch Tensor pos torch Tensor copy = torch zeros padded shape i range pos shape p = pos i copy i p = padded i p copy dummy_loop_with_scan padded torch Tensor pos torch Tensor pad_row padded p row = torch zeros padded shape torch _check p item torch _check p item padded shape check always true we add anyway make dimension = avoid raising exception about dynamic dimension torch compiler is_exporting torch _check p item row p item = padded p item row torch ops higher_order scan pad_row padded pos select_when_exporting f f_scan f_scan torch compiler is_exporting f ScanModel torch nn Module forward images position select_when_exporting dummy_loop dummy_loop_with_scan images position DYN = torch export Dim DYNAMIC x = torch randn y = torch arange dtype=torch int + ep = torch export export ScanModel x y dynamic_shapes= images DYN DYN position DYN strict=False onnx_program = export ep onnx_testing assert_onnx_program onnx_program common_utils instantiate_parametrized_tests DynamoExporterNewOpsetsTest common_utils TestCase _WithExport test_group_norm_opset_ Model torch nn Module forward x torch nn functional group_norm x x = torch randn dtype=torch float onnx_program = export Model x opset_version= TODO after ort support As ONNX Runtime operator implemented yet call assert_onnx_program after ort support assertIn GroupNormalization node op_type node onnx_program model graph test_attention_opset_ Model torch nn Module forward query key value torch nn functional scaled_dot_product_attention query key value query = torch rand dtype=torch float key = torch rand dtype=torch float value = torch rand dtype=torch float onnx_program = export Model query key value opset_version= assertEqual Attention n op_type n onnx_program model graph onnx_testing assert_onnx_program onnx_program atol= e- rtol= test_rms_norm Test RMS normalization various configurations RMSNormModel torch nn Module forward x torch nn functional rms_norm x x = torch randn onnx_program = export RMSNormModel x opset_version= onnx_testing assert_onnx_program onnx_program Test multi-dimensional normalized_shape RMSNormModel D torch nn Module forward x torch nn functional rms_norm x x = torch randn onnx_program = export RMSNormModel D x opset_version= onnx_testing assert_onnx_program onnx_program test_rms_norm_with_weight Test RMS normalization weight parameter RMSNormWithWeight torch nn Module __init__ super __init__ weight = torch nn Parameter torch ones forward x torch nn functional rms_norm x weight=self weight x = torch randn onnx_program = export RMSNormWithWeight x opset_version= onnx_testing assert_onnx_program onnx_program test_rms_norm_with_eps Test RMS normalization custom epsilon RMSNormWithEps torch nn Module forward x torch nn functional rms_norm x eps= e- x = torch randn onnx_program = export RMSNormWithEps x opset_version= onnx_testing assert_onnx_program onnx_program test_enable_gqa_in_attention_ _with_dropout Model torch nn Module forward q k v torch nn functional scaled_dot_product_attention pylint disable=not-callable q k v enable_gqa=True dropout_p= model = Model query = torch randn key = torch randn value = torch randn onnx_program = export model query key value opset_version= opset only uses manually gqa path when dropout enabled dropout makes output non-deterministic so we check presence ops used path all_ops = node op_type node onnx_program model graph assertIn Unsqueeze all_ops assertIn Expand all_ops assertIn Reshape all_ops __name__ == __main__ common_utils run_tests