time numpy np torch Microbenchmarks Tensor repeat operator Supports PyTorch input_shapes = repeats = NUM_WARMUP_ITERS = NUM_BENCHMARK_ITERS = DTYPE_TO_BYTES = float generate_data_for_repeat input_tensors = torch randn input_shape input_shape input_shapes total_num_elements = input_tensor repeat zip input_tensors repeats total_num_elements += input_tensor numel total_num_elements += input_tensor numel np prod repeat input_tensors total_num_elements DTYPE_TO_BYTES float input_tensors total_bytes = generate_data_for_repeat BYTES_TO_MB = pt_repeat input_tensor repeat input_tensor repeat repeat pt_repeat_n_times niters _ range niters input_tensor repeat zip input_tensors repeats pt_repeat input_tensor repeat __name__ == __main__ Warm up runs pt_repeat_n_times NUM_WARMUP_ITERS s = time time pt_repeat_n_times NUM_BENCHMARK_ITERS total_time_s = time time - s total_time_per_iter_s = total_time_s NUM_BENCHMARK_ITERS achieved_bandwidth = total_bytes BYTES_TO_MB total_time_per_iter_s print f Time total_time_per_iter_s Achieved Bandwidth achieved_bandwidth MB s