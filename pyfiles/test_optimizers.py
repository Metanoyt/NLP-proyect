Owner s module dynamo PYTEST_DONT_REWRITE prevents pytest rewriting assertions which interferes test_adam OptimizerTests functools torch torch _dynamo torch _dynamo test_case torch _dynamo testing torch nn Parameter MyOptimizer torch optim Optimizer __init__ params super __init__ params _init_group params group any_complex = False p group params params append p any_complex &#124; = p is_complex any_complex step group param_groups params = any_complex = _init_group params group any_complex params -= params += End EndTests torch _dynamo test_case TestCase https github com pytorch torchdynamo issues test_optimizing_over_tensor_with_requires_grad Net torch nn Module forward x y z = torch bmm x y z = torch flatten z z training_iter_fn batch model optimizer optimizer zero_grad out = model batch target = torch tensor loss = torch nn CrossEntropyLoss out target loss backward optimizer step loss net = Net input = torch randn input = torch randn requires_grad=True optimizer = torch optim Adam input lr= cnts = torch _dynamo testing CompileCounter opt_training_iter_fn = torch compile training_iter_fn backend=cnts batch = x input y input _ range opt_training_iter_fn batch net optimizer assertEqual cnts frame_count test_state_dict torch compile backend= eager _test_state_dict weight bias input fn_base optimizer weight bias optimizer zero_grad i = input loss = weight mv i + bias pow sum loss backward loss optimizer = torch optim Adagrad weight bias fn = functools partial fn_base optimizer weight bias optimizer fn optimizer fn = _test_state_dict Parameter torch randn Parameter torch randn torch randn requires_grad=True optimizer step fn test_init_group dtype torch float torch cfloat tensor = torch randn dtype=dtype params = Parameter tensor detach clone requires_grad=False opt_params = Parameter tensor detach clone requires_grad=False optim = MyOptimizer params optim step opt_optim = MyOptimizer opt_params opt_step = torch compile backend= eager fullgraph=True opt_optim step opt_step assertEqual params opt_params __name__ == __main__ torch _dynamo test_case run_tests run_tests