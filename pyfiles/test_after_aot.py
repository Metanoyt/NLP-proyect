Owner s module dynamo io os shutil sys tempfile unittest torch _dynamo test_case torch _dynamo repro after_aot InputReader InputWriter save_graph_repro torch fx experimental proxy_tensor make_fx torch testing _internal common_utils IS_FBCODE torch utils _traceback report_compile_source_on_error strip_trailing_whitespace r \n join l rstrip l r split \n TestAfterAot torch _dynamo test_case TestCase unittest skipIf IS_FBCODE NotImplementedError test_save_graph_repro TODO This triggers CUDA context initialization even though CPU only buf = io StringIO args = torch randn f x x x gm = make_fx f args tempfile TemporaryDirectory d save_graph_repro buf gm args inductor_accuracy save_dir=d r = buf getvalue report_compile_source_on_error exec r __compile_source__ r shutil rmtree os path join d storages Should still work even without save dir report_compile_source_on_error exec r __compile_source__ r unittest skipIf sys byteorder = little checksum depends endianness test_dump_tensor test tensor expected tempfile TemporaryDirectory d writer = InputWriter d stable_hash=True writer tensor x tensor assertExpectedInline \n join writer _lines expected skip= reader = InputReader d env = reader reader torch torch TODO assert no logs exec \n join writer _lines env assertEqual reader args tensor test torch zeros \ buf = reader storage c fd ca b ac b dda e eb d reader tensor buf is_leaf=True x test torch ones dtype=torch int \ buf = reader storage c e da c c cc dd d bd e dtype_hint=torch int reader tensor buf dtype=torch int is_leaf=True x test torch empty memory_format=torch channels_last fill_ \ buf = reader storage ebab d e c c b aefd bdd afc reader tensor buf is_leaf=True x __name__ == __main__ torch _dynamo test_case run_tests run_tests