itertools collections abc Callable dataclasses asdict dataclass functools partial typing Union numpy np tabulate tabulate tqdm tqdm torch torch nn nn torch nn functional F torch utils benchmark benchmark torch nn attention bias CausalBias CausalVariant torch nn parameter Parameter benchmark_torch_function_in_microseconds func Callable args kwargs - float warmup _ range func args kwargs t = benchmark Timer stmt= func args kwargs globals= args args kwargs kwargs func func t adaptive_autorange min_run_time= median e dataclass frozen=True ExperimentConfig batch_size int num_heads int q_seq_len int k_seq_len int embed_dim int dtype torch dtype property head_dim - int embed_dim num_heads asdict dict_obj = asdict dict_obj head_dim = head_dim dict_obj dataclass frozen=True ExperimentResults materialized_mask_time float attn_mask_subclass_time float get_entries - list f materialized_mask_time f f attn_mask_subclass_time f dataclass frozen=True Experiment config ExperimentConfig results ExperimentResults get_entries - list config get_entries + results get_entries generate_inputs batch_size q_sequence_length kv_sequence_length embed_dim dtype device q_shape = batch_size q_sequence_length embed_dim kv_shape = batch_size kv_sequence_length embed_dim make_q = partial torch rand q_shape device=device dtype=dtype make_kv = partial torch rand kv_shape device=device dtype=dtype make_q make_kv make_kv CompositeMHA torch nn Module __init__ num_heads embed_dim device=None dtype=None factory_kwargs = device device dtype dtype super __init__ head_dim = embed_dim num_heads embed_dim = embed_dim assert head_dim num_heads == embed_dim embed_dim must divisible num_heads q_proj_weight = Parameter torch empty embed_dim embed_dim factory_kwargs k_proj_weight = Parameter torch empty embed_dim embed_dim factory_kwargs v_proj_weight = Parameter torch empty embed_dim embed_dim factory_kwargs out_proj = Parameter torch empty embed_dim embed_dim factory_kwargs num_heads = num_heads forward query torch Tensor key torch Tensor value torch Tensor mask Union torch Tensor CausalBias query_projected = F linear query q_proj_weight key_projected = F linear key k_proj_weight value_projected = F linear value v_proj_weight query = query view query_projected size - num_heads head_dim transpose key = key view key_projected size - num_heads head_dim transpose value = value view value_projected size - num_heads head_dim transpose attn = torch nn functional scaled_dot_product_attention query key value attn_mask=mask dropout_p= attn = attn transpose reshape query size - embed_dim Match signature nn MHA F linear attn out_proj reset_parameters nn init xavier_uniform_ q_proj_weight nn init xavier_uniform_ k_proj_weight nn init xavier_uniform_ v_proj_weight nn init constant_ out_proj run_single_experiment config ExperimentConfig - ExperimentResults device = torch device cuda composite_mha = CompositeMHA config num_heads config embed_dim device config dtype composite_mha reset_parameters query key value = generate_inputs config batch_size config q_seq_len config k_seq_len config embed_dim config dtype device attn_mask = CausalBias CausalVariant LOWER_RIGHT config q_seq_len config k_seq_len attn_mask_tensor = attn_mask _materialize device materialized_mask_time = benchmark_torch_function_in_microseconds composite_mha query key value attn_mask_tensor attn_mask_subclass_time = benchmark_torch_function_in_microseconds composite_mha query key value attn_mask torch testing assert_close composite_mha query key value attn_mask_tensor composite_mha query key value attn_mask ExperimentResults materialized_mask_time=materialized_mask_time attn_mask_subclass_time=attn_mask_subclass_time generate_experiment_configs - list ExperimentConfig batch_sizes = num_heads = q_kv_seq_lens = embed_dims = dtypes = torch bfloat all_configs = bsz heads q_seq_len kv_seq_len embed_dim dtype itertools product batch_sizes num_heads q_kv_seq_lens embed_dims dtypes all_configs append ExperimentConfig batch_size=bsz num_heads=heads q_seq_len=q_seq_len k_seq_len=kv_seq_len embed_dim=embed_dim dtype=dtype all_configs calculate_speedup results ExperimentResults - float results materialized_mask_time results attn_mask_subclass_time print_results results list Experiment Calculate speedups speedups = calculate_speedup r results r results Find indices max min speedups max_speedup_index = np argmax speedups min_speedup_index = np argmin speedups Get config dictionaries max_config_dict = results max_speedup_index config asdict min_config_dict = results min_speedup_index config asdict Create table data table_data = Type Average Speedup np mean speedups dict fromkeys max_config_dict Type Max Speedup speedups max_speedup_index max_config_dict Type Min Speedup speedups min_speedup_index min_config_dict Print table print tabulate table_data headers= keys tablefmt= pretty main seed = np random seed seed torch manual_seed seed results = Run one timing experiment comparing nn_mha vs composite_mha config tqdm generate_experiment_configs results append Experiment config run_single_experiment config print_results results __name__ == __main__ main