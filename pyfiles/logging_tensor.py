mypy ignore-errors torch torch utils _pytree tree_map typing Optional collections abc Iterator logging contextlib itertools torch utils _dtype_abbrs dtype_abbrs _dtype_abbrs torch utils _python_dispatch TorchDispatchMode torch utils weak WeakTensorKeyDictionary functools torch _C _profiler gather_traceback symbolize_tracebacks logger = logging getLogger LoggingTensor How chain calls works LoggingTensor Call torch sin Attempt __torch_function__ In LoggingTensor torch function disabled so we bypass entirely Enter dispatcher wind your way through Autograd Hit Python dispatch key call __torch_dispatch__ This Tensor can work autograd two ways - The wrapped Tensor does require gradients In case LoggingTensor can require gradients user asks constructor kwarg - The wrapped Tensor can require gradients In case autograd will tracked wrapped Tensor LoggingTensor itself cannot require gradients WARNING We allow these two possibilities testing purposes You should NEVER use both single test you might get surprising behavior TODO TensorBase should work LoggingTensor torch Tensor elem torch Tensor __slots__ = elem context = contextlib nullcontext staticmethod __new__ cls elem args kwargs The wrapping tensor LoggingTensor shouldn t hold any memory question should still advertise same device before r = torch Tensor _make_wrapper_subclass cls elem size strides=elem stride storage_offset=elem storage_offset TODO clone storage aliasing dtype=elem dtype layout=elem layout device=elem device requires_grad=kwargs get requires_grad False real tensor held element tensor r elem = elem detach r requires_grad elem r __repr__ super __repr__ tensor_contents=f elem classmethod __torch_dispatch__ cls func types args= kwargs=None unwrap e e elem isinstance e cls e wrap e cls e isinstance e torch Tensor e cls context rs = tree_map wrap func tree_map unwrap args tree_map unwrap kwargs logging getLogger LoggingTensor info f func __module__ func __name__ args kwargs rs noqa G rs LoggingTensorMode TorchDispatchMode __torch_dispatch__ func types args= kwargs=None kwargs None kwargs = rs = func args kwargs logging getLogger LoggingTensor info f func __module__ func __name__ args kwargs rs noqa G rs LoggingTensorReentrant LoggingTensor context = torch overrides enable_reentrant_dispatch https stackoverflow com questions python-logging-handler-to-append-to-list LoggingTensorHandler logging Handler __init__ log_list list str use_shortid_for_all_tensors bool with_type bool tracebacks_list Optional list - None logging Handler __init__ log_list = log_list use_shortid_for_all_tensors = use_shortid_for_all_tensors tracebacks_list = tracebacks_list memo = WeakTensorKeyDictionary next_id = with_type = with_type _shortid t torch Tensor - int t memo memo t = next_id next_id += memo t _fmt object with_type bool = False - str cond_cls = torch Tensor use_shortid_for_all_tensors LoggingTensor isinstance cond_cls maybe_type = with_type with_type maybe_type = f _dtype_abbrs dtype join map str shape x = f $ _shortid maybe_type x repr emit record fmt_args = join itertools chain str tree_map _fmt record args f k = str tree_map _fmt v k v record args items fmt_rets = tree_map functools partial _fmt with_type=True record args log_list append f fmt_rets = record msg fmt_args tracebacks_list None tracebacks_list append record traceback log_input name str var object - None logger info input name var noqa PLE GatherTraceback logging Filter __init__ python=True script=True cpp=False python = python script = script cpp = cpp filter record record traceback = gather_traceback python=self python script=self script cpp=self cpp True contextlib contextmanager capture_logs is_mode=False python_tb=False script_tb=False cpp_tb=False - Iterator list str collect_traceback = python_tb script_tb cpp_tb log_list list str = tracebacks_list list str = handler = LoggingTensorHandler log_list with_type=True use_shortid_for_all_tensors=is_mode tracebacks_list=tracebacks_list collect_traceback None logger addHandler handler logger setLevel logging INFO logger propagate = False collect_traceback logger addFilter GatherTraceback python=python_tb script=script_tb cpp=cpp_tb try collect_traceback yield log_list tracebacks_list yield log_list finally symbolized_tracebacks = symbolize_tracebacks tracebacks_list tracebacks_list clear tracebacks_list extend symbolized_tracebacks logger removeHandler handler contextlib contextmanager capture_logs_with_logging_tensor_mode python_tb=False script_tb=False cpp_tb=False LoggingTensorMode capture_logs True python_tb script_tb cpp_tb logs yield logs