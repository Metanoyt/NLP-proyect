__future__ annotations torchgen api dispatcher torchgen api types BaseCppType BaseCType Binding boolT ConstRefCType CType longT NamedCType tensorT torchgen model Argument BaseTy BaseType FunctionSchema NativeFunction NativeFunctionsViewGroup This file describes translation JIT schema API s used when creating ` ViewMeta ` specializations used functionalization pass These API s mostly follow dispatcher API one difference - While forward function just directly calls into _ops API following dispatcher convention logic here reverse function responsible generating both call-site declarations which implemented manually functionalization impl namespace Define some specific lambda input arguments base_binding = Binding name= base nctype=NamedCType name= base type=ConstRefCType BaseCType tensorT argument=Argument name= base type=BaseType BaseTy Tensor default=None annotation=None default=None has_symbolic_inputs_binding = Binding name= has_symbolic_inputs nctype=NamedCType name= has_symbolic_inputs type=BaseCType boolT argument=Argument name= has_symbolic_inputs type=BaseType BaseTy bool default=None annotation=None default=None mutated_view_binding = Binding name= mutated_view nctype=NamedCType name= mutated_view type=ConstRefCType BaseCType tensorT argument=Argument name= base type=BaseType BaseTy Tensor default=None annotation=None default=None out_index_binding = Binding name= out_index nctype=NamedCType name= out_index type=BaseCType longT argument=Argument name= out_index type=BaseType BaseTy int default=None annotation=None default=None reapply_views_binding = Binding name= reapply_views nctype=NamedCType name= reapply_views type=BaseCType boolT argument=Argument name= reapply_views type=BaseType BaseTy bool default=None annotation=None default=None InverseReturnModeT = BaseCppType functionalization InverseReturnMode inverse_return_mode_binding = Binding name= inverse_return_mode nctype=NamedCType name= inverse_return_mode type=BaseCType InverseReturnModeT argument=Argument name= inverse_return_mode NB actually bool doesn t matter because isn t used type=BaseType BaseTy bool default=None annotation=None default=None Name ` ViewMeta ` specialization created classname func FunctionSchema with_namespace bool = False - str namespace = functionalization with_namespace f namespace func name unambiguous_name _ViewMeta Name operation called inside ` forward ` ` reverse ` implementations name g NativeFunctionsViewGroup is_reverse bool include_namespace bool reapply_views bool &#124; None = None - str reapply_views None reapply_views only important fwd lambda since we always plumb runtime reapply_views argument into reverse function assert is_reverse is_reverse reverse_name g view include_namespace forward case we just directly call into _ops API so we always need namespace assert include_namespace assert g view_copy None api_name = g view func name unambiguous_name reapply_views g view_copy func name unambiguous_name f _ops api_name call reverse_name f NativeFunction include_namespace bool - str reverse we plumb reapply_views flag into function support both copy non-copy variants We could avoid doing would require writing out twice many view inverse functions api_name = f func name unambiguous_name reverse case we codegen both call-sites which need full namespace declarations which don t include_namespace f functionalization FunctionalInverses api_name _inverse f api_name _inverse returns_type func FunctionSchema - CType Assertion all view ops tensor-like outputs assert len func returns = ret func returns assert ret type is_tensor_like However type lambda always individual tensor For multi-tensor outputs each tensor needs tracked individually BaseCType tensorT Checks whether ` func ` might more than one value is_multi_output func FunctionSchema - bool len func returns len func returns == func returns type is_list_like None ` ViewMeta ` specialization constructor parameters base_ctor_arguments func FunctionSchema - list Binding All specializations parematerized ` has_symbolic_inputs ` flag arguments = has_symbolic_inputs_binding If ` func ` might more than value we also parameterize specialization output index is_multi_output func arguments append out_index_binding arguments ` ViewMeta ` specialized constructor arguments Values needed specifically specialization base does need Same attributes non-owning extra_ctor_arguments func FunctionSchema - list Binding attributes func owning=False ` ViewMeta ` specialized non-static member data Essential data calling instance s ` forward ` ` reverse functions You can think them values should captured functionalization kernel attributes func FunctionSchema owning bool = True - list Binding args = func arguments flat_all assert args type == BaseType BaseTy Tensor reapply_views_binding inverse_return_mode_binding dispatcher argument remove_non_owning_ref_types=owning args op_arguments func FunctionSchema is_reverse bool - list Binding args = func arguments flat_all assert args type == BaseType BaseTy Tensor non_self_args = args The forward lambda calls _ops API while reverse lambda calls view inverse API Both these follow dispatcher API non_self_bindings = dispatcher argument non_self_args is_reverse forward lambda swaps out original tensor argument lambd arg base base_binding + non_self_bindings reverse lambda does same additional mutated_view arg additionally we have calling convention view ops multiple tensor outputs their corresponding view_inverse function takes additional index argument is_multi_output func base_binding mutated_view_binding inverse_return_mode_binding out_index_binding + non_self_bindings base_binding mutated_view_binding inverse_return_mode_binding + non_self_bindings