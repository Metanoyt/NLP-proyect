Owner s module inductor copy os unittest torch torch nn torch _dynamo utils counters same torch _inductor metrics torch _inductor runtime benchmarking benchmarker torch _inductor test_case TestCase torch testing _internal inductor_utils GPU_TYPE HAS_GPU set so metrics appear torch _logging set_logs inductor_metrics=True DO_PERF_TEST = os environ get DO_PERF_TEST == TestScatterOpt TestCase setUp super setUp metrics reset counters clear check_metric val= assertEqual val metrics num_matches_for_scatter_upon_const_tensor do_acc_test f args expect = f args actual = torch compile f args assertTrue same expect actual tol= e- f expect= \n actual= \n test_ d_tensor L M N = f x y = torch full L M N dtype=torch float y scatter_ x unsqueeze y x = torch randint N L M dtype=torch int do_acc_test f x expected_num_bytes = L M N torch float itemsize + L M torch int itemsize assertEqual metrics num_bytes_accessed expected_num_bytes test_non_last_dim Test case scatter dimension last one M N = f x y = torch full M N dtype=torch float y scatter_ x unsqueeze y x = torch randint M N dtype=torch int do_acc_test f x expected_num_bytes = M N torch float itemsize + N torch int itemsize assertEqual metrics num_bytes_accessed expected_num_bytes test_neg_scatter_dim M N = f x y = torch full M N dtype=torch float y scatter_ - x unsqueeze y x = torch randint N M dtype=torch int do_acc_test f x expected_num_bytes = M N torch float itemsize + M torch int itemsize assertEqual metrics num_bytes_accessed expected_num_bytes test_shorter_index_tensor M N = f x y = torch full M N dtype=torch float y scatter_ x unsqueeze y x = torch randint N M dtype=torch int do_acc_test f x no match since index tensor shorter May support future assertEqual counters inductor pattern_matcher_count test_nonzero_const_tensor M N = f x y = torch full M N dtype=torch float y scatter_ x unsqueeze y x = torch randint N M dtype=torch int do_acc_test f x expected_num_bytes = M N torch float itemsize + M torch int itemsize assertEqual metrics num_bytes_accessed expected_num_bytes test_can_not_optimize_due_to_dense M N = f x y = torch full M N dtype=torch float y scatter_ x y x = torch randint N M N dtype=torch int do_acc_test f x expected_num_bytes = M N torch float itemsize + M N torch int itemsize + torch float itemsize Use assertGreaterEqual rather than assertEqual due issue related StarDep mentioned here https github com pytorch pytorch pull #discussion_r assertGreaterEqual metrics num_bytes_accessed expected_num_bytes test_can_not_optimize_due_to_non_const M N = f x y y scatter_ x y x = torch randint N M dtype=torch int y = torch randn M N do_acc_test f x y The generated code quite in-efficient There kernels copy arg buf scatter upon buf copy buf back arg Link wrapper https gist github com shunting d b e b e b f c c f expected_num_bytes = M N torch float itemsize + M torch int itemsize + torch float itemsize assertGreaterEqual metrics num_bytes_accessed expected_num_bytes second kernel third kernel both mutation kernel So we overestimated memory accessed Update test once overestimiation fixed over_estimate = M torch float itemsize + M N torch float itemsize assertEqual metrics num_bytes_accessed expected_num_bytes + over_estimate test_cross_entropy_loss Match full+scatter CEL replaces pointwise Perf data A GPU Without scatter optimization ms= peak_mem= GB With scatter optimization ms= peak_mem= GB B T D V = DO_PERF_TEST use smaller V doing perf test avoid OOM CI V = V ref_model = nn Linear D V torch bfloat opt_model = copy deepcopy ref_model ce = nn CrossEntropyLoss f m x label ce m x view - V label view - backward opt_f = torch compile f x = torch randn B T D torch bfloat label = torch randint V B T torch int f ref_model x label ref_grad = ref_model weight grad opt_f opt_model x label act_grad = opt_model weight grad assert torch allclose ref_grad act_grad atol= e- rtol= e- f ref_grad= \n act_grad= check_metric DO_PERF_TEST GPU_TYPE == xpu raise unittest SkipTest torch xpu reset_peak_memory_stats implemented torch cuda reset_peak_memory_stats _ range opt_f opt_model x label ms = benchmarker benchmark_gpu lambda opt_f opt_model x label peak_mem = torch cuda max_memory_allocated print f ms= f peak_mem= f GB HAS_GPU torch set_default_device GPU_TYPE __name__ == __main__ torch _inductor test_case run_tests HAS_GPU run_tests