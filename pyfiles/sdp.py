argparse itertools random warnings dataclasses dataclass pathlib Path pprint pprint typing Optional numpy np prettytable PrettyTable tqdm tqdm torch torch utils benchmark benchmark torch backends cuda sdp_kernel warnings filterwarnings ignore dataclass frozen=True ExperimentConfig batch_size int num_heads int max_sequence_len int embed_dimension int dtype torch dtype pad_percentage Optional float enable_math bool enable_flash bool enable_mem_efficient bool enable_cudnn bool get_entries - list batch_size num_heads max_sequence_len embed_dimension dtype pad_percentage enable_math enable_flash enable_mem_efficient enable_cudnn classmethod get_entry_names cls - list str batch_size num_heads max_sequence_len embed_dimension dtype pad_percentage enable_math enable_flash enable_mem_efficient enable_cudnn dataclass frozen=True ExperimentResults nn_mha_time float compiled_nn_mha_time Optional float composite_mha_time float compiled_composite_mha_time Optional float get_entries - list f nn_mha_time f f compiled_nn_mha_time f compiled_nn_mha_time None f composite_mha_time f f compiled_composite_mha_time f compiled_composite_mha_time None classmethod get_entry_names cls - list str nn_mha_time \u b s compiled_nn_mha_time \u b s composite_mha_time \u b s compiled_composite_mha_time \u b s dataclass frozen=True Experiment config ExperimentConfig results ExperimentResults get_entries - list config get_entries + results get_entries CompositeMHA torch nn Module __init__ num_heads in_proj_weight in_proj_bias out_proj super __init__ in_proj_weight = in_proj_weight in_proj_bias = in_proj_bias out_proj = out_proj num_heads = num_heads forward query key value mask query key key value raise NotImplementedError query key value must same Tensor now mask None raise NotImplementedError mask currently supported query_projected = torch nn functional linear query in_proj_weight in_proj_bias batch_size = query_projected size embed_dim = query_projected size head_dim = embed_dim num_heads query key value = query_projected chunk - query = query view batch_size - num_heads head_dim transpose key = key view batch_size - num_heads head_dim transpose value = value view batch_size - num_heads head_dim transpose output sdp = batch num_heads seq_len head_dim attn = torch nn functional scaled_dot_product_attention query key value attn_mask=None dropout_p= is_causal=False attn = attn transpose reshape batch_size - num_heads head_dim Match signature nn MHA out_proj attn None build_composite_mha_from_nn_mha pt assert pt _qkv_same_embed_dim in_proj_weight = pt in_proj_weight assert in_proj_weight None assert pt batch_first CompositeMHA pt num_heads pt in_proj_weight pt in_proj_bias pt out_proj generate_rand_batch batch_size max_sequence_len embed_dimension pad_percentage=None dtype=torch float device= cuda pad_percentage torch randn batch_size max_sequence_len embed_dimension dtype=dtype device=device None Really slow should work seq_len_list = int max_sequence_len - random gauss pad_percentage _ range batch_size Make random ele max length seq_len_list random randint batch_size - = max_sequence_len print f Theoretical padding pad_percentage actual - sum seq_len_list batch_size max_sequence_len torch nested nested_tensor torch randn seq_len embed_dimension dtype=dtype device=device seq_len seq_len_list seq_len_list benchmark_torch_function_in_microseconds f args kwargs t = benchmark Timer stmt= f args kwargs globals= args args kwargs kwargs f f t blocked_autorange mean e assert_close_tensors tensor_a tensor_b First order sanity check Not replacement rigorous tests tensor_a is_nested tensor_b is_nested b zip tensor_a unbind tensor_b unbind assert torch allclose b atol= e- rtol= e- assert torch allclose tensor_a tensor_b atol= e- rtol= e- run_single_experiment config ExperimentConfig - ExperimentResults sdp_kernel enable_math=config enable_math enable_flash=config enable_flash enable_mem_efficient=config enable_mem_efficient enable_cudnn=config enable_cudnn dropout_p = mask = None nn_mha = torch nn MultiheadAttention embed_dim=config embed_dimension num_heads=config num_heads batch_first=True dropout=dropout_p nn_mha = nn_mha eval cuda config dtype composite_mha = build_composite_mha_from_nn_mha nn_mha qkv lengths = generate_rand_batch config batch_size config max_sequence_len config embed_dimension config pad_percentage config dtype nn_mha_output _ = nn_mha qkv qkv qkv mask composite_mha_output _ = composite_mha qkv qkv qkv mask First order sanity check assert_close_tensors nn_mha_output composite_mha_output nn_mha_time = benchmark_torch_function_in_microseconds nn_mha qkv qkv qkv mask composite_mha_time = benchmark_torch_function_in_microseconds composite_mha qkv qkv qkv mask TorchDynamo will error NestedTensors config pad_percentage None compiled_nn_mha = torch compile nn_mha compiled_composite_mha = torch compile composite_mha compiled_nn_mha_time = benchmark_torch_function_in_microseconds compiled_nn_mha qkv qkv qkv mask compiled_composite_mha_time = benchmark_torch_function_in_microseconds compiled_composite_mha qkv qkv qkv mask compiled_nn_mha_time = None compiled_composite_mha_time = None results = ExperimentResults nn_mha_time compiled_nn_mha_time composite_mha_time compiled_composite_mha_time Experiment config results Could generator generate_experiments batch_sizes num_heads max_seq_lens embed_dims dtypes pad_percentages - list ExperimentConfig configs = bsz n_heads seq_len embed_dim dtype padding itertools product batch_sizes num_heads max_seq_lens embed_dims dtypes pad_percentages configs append ExperimentConfig batch_size=bsz num_heads=n_heads max_sequence_len=seq_len embed_dimension=embed_dim dtype=dtype pad_percentage=padding enable_math=False enable_flash=True enable_mem_efficient=True enable_cudnn=True configs main save_path Optional Path seed = np random seed seed torch manual_seed seed Run one timing experiment comparing nn_mha vs composite_mha config = ExperimentConfig batch_size= num_heads= max_sequence_len= embed_dimension= dtype=torch float pad_percentage=None enable_math=False enable_flash=True enable_mem_efficient=True enable_cudnn=True experiment = run_single_experiment config pprint experiment table = PrettyTable table float_format = table field_names = ExperimentConfig get_entry_names + ExperimentResults get_entry_names Run bunch experiments batch_sizes = num_heads = max_seq_lens = embed_dims = dtypes = torch bfloat torch float torch float pad_percentages = None experiment_configs = generate_experiments batch_sizes num_heads max_seq_lens embed_dims dtypes pad_percentages experiments list Experiment = experiment_config tqdm experiment_configs experiment = run_single_experiment experiment_config experiments append experiment table add_row experiment get_entries print table csv_string = table get_csv_string save_path None open save_path w csvfile csvfile write csv_string __name__ == __main__ parser = argparse ArgumentParser parser add_argument -- save-path -- save_path type=str help= Path save results args = parser parse_args save_path = Path args save_path args save_path None main save_path