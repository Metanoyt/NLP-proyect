Owner s oncall distributed torch torch distributed _functional_collectives funcol torch distributed tensor _random random torch distributed device_mesh init_device_mesh torch distributed tensor Replicate torch distributed tensor parallel api parallelize_module torch distributed tensor parallel style ColwiseParallel torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_utils run_tests torch testing _internal distributed _tensor common_dtensor DTensorTestBase MLPModule with_comms TensorParallelRandomStateTests DTensorTestBase get_tensor_slice idx n large_tensor shape = large_tensor shape assert shape n == local_shape = shape n shape slice_idx = slice idx local_shape idx + local_shape slice local_shape large_tensor slice_idx check_gathered_tensors self_rank size gathered_tensors assertFunc other_rank range size self_rank = other_rank assertFunc get_tensor_slice self_rank size gathered_tensors get_tensor_slice other_rank size gathered_tensors with_comms skip_if_lt_x_gpu test_model_init dp_size = tp_size = world_size dp_size mesh_ d = init_device_mesh device_type dp_size tp_size mesh_dim_names= dp tp dp_mesh = mesh_ d dp tp_mesh = mesh_ d tp dp_rank = dp_mesh get_coordinate tp_rank = tp_mesh get_coordinate assertEqual dp_rank rank tp_size assertEqual tp_rank rank tp_size enable_distribute_flag True False local model meta device model = MLPModule device= meta col-wise parallel style shards weight over tensor dim model_tp = parallelize_module model tp_mesh net ColwiseParallel output_layouts=Replicate net ColwiseParallel output_layouts=Replicate most cases random number generator states set data loader following way - within tensor parallel group RNG set same seed - across data parallel groups RNG set different seeds torch get_device_module device_type manual_seed disable enable parallel RNG feature random _rng_tracker random _rng_tracker distribute_region_enabled = enable_distribute_flag assertTrue model_tp net weight is_meta initialize model s local shard model_tp to_empty device=self device_type model_tp reset_parameters examine weights initialized adhere DP TP dtensor model_tp net weight model_tp net weight check within TP group d mesh represents TP group _ d_mesh = dtensor device_mesh assert _ d_mesh ndim == assertEqual _ d_mesh tp_mesh tensor_local = dtensor to_local all-gather local shards tensor_gather = funcol all_gather_tensor tensor_local gather_dim= group=_ d_mesh assertEqual _ d_mesh get_coordinate tp_rank compare local shards within TP group tp_weights_assert tensor tensor enable_distribute_flag each rank within TP group shall initialize local weights differently assertNotEqual tensor tensor without parallel RNG weight initialization violates TP setup each rank within TP group has same initial weights assertEqual tensor tensor check_gathered_tensors tp_rank tp_size tensor_gather tp_weights_assert check across TP groups all-gather local shards tensor_gather = funcol all_gather_tensor tensor_local gather_dim= group=dp_mesh compare local shards across TP groups dp_weights_assert tensor tensor local weights shall initialized same across TP groups doesn t matter whether DTensor s RNG infra activated since all spmd ranks started same seed assertEqual tensor tensor check_gathered_tensors dp_rank dp_size tensor_gather dp_weights_assert __name__ == __main__ run_tests