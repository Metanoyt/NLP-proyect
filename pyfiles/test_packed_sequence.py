Owner s module nn itertools random torch torch nn utils rnn rnn_utils torch testing _internal common_utils run_tests TestCase PackedSequenceTest TestCase _type_by_name = torch DoubleTensor torch DoubleTensor double torch FloatTensor torch FloatTensor float We leave out ` torch HalfTensor torch HalfTensor half ` because error ` pad_packed_sequence ` AttributeError torch HalfTensor object has no attribute fill_ torch LongTensor torch LongTensor long torch IntTensor torch IntTensor int torch ShortTensor torch ShortTensor short torch CharTensor torch CharTensor char torch ByteTensor torch ByteTensor byte __init__ args kwargs super __init__ args kwargs batch_size = max_length = _ordered_sequence tensor_type Create ordered list random sequences seqs = tensor_type random randint max_length _ range batch_size tensor_type == torch ByteTensor seqs = s random_ s seqs seqs = s random_ - s seqs ordered = sorted seqs key=len reverse=True ordered _padded_sequence tensor_type Create Tensor random padded sequences ordered = _ordered_sequence tensor_type lengths = len i i ordered padded_tensor = rnn_utils pad_sequence ordered padded_tensor lengths test_type_casts Test type casting ` PackedSequence ` against type casting tensor input_type _ _type_by_name values expected_type_str _ cast_str _type_by_name items enforce_sorted True False padded lengths = _padded_sequence input_type packed = rnn_utils pack_padded_sequence padded lengths enforce_sorted=enforce_sorted Apply cast ` PackedSequence ` instance unpack masked = getattr packed cast_str unpacked _ = rnn_utils pad_packed_sequence masked assertEqual unpacked type expected_type_str test_wrong_order = torch ones b = torch ones b_a = rnn_utils pad_sequence b assertRaises RuntimeError lambda rnn_utils pack_padded_sequence b_a enforce_sorted=True test_pad_sequence_with_tensor_sequences seq_tuple_input = torch nn utils rnn pad_sequence torch tensor torch tensor - - seq_tensor_input = torch nn utils rnn pad_sequence torch tensor - - assertEqual seq_tuple_input seq_tensor_input assertEqual seq_tuple_input shape torch Size test_pad_sequence_with_non_iterable_sequences msg = r Expected iterable input sequences got arg type assertRaisesRegex RuntimeError msg torch nn utils rnn pad_sequence test_total_length padded lengths = _padded_sequence torch FloatTensor max_length = max lengths packed = rnn_utils pack_padded_sequence padded lengths test ValueError total_length max_length total_length - max_length - batch_first True False err_fn rnn_utils pad_packed_sequence packed batch_first=batch_first total_length=total_length assertRaisesRegex ValueError r Expected total_length least r length longest sequence input err_fn test pad_packed_sequence returns results correct length batch_first True False no_extra_pad _ = rnn_utils pad_packed_sequence packed batch_first=batch_first total_length_delta total_length = max_length + total_length_delta unpacked lengths_out = rnn_utils pad_packed_sequence packed batch_first=batch_first total_length=total_length assertEqual lengths lengths_out assertEqual unpacked size batch_first total_length total_length_delta == ref_output = no_extra_pad batch_first extra_pad = no_extra_pad new_zeros batch_size total_length_delta ref_output = torch cat no_extra_pad extra_pad extra_pad = no_extra_pad new_zeros total_length_delta batch_size ref_output = torch cat no_extra_pad extra_pad assertEqual unpacked ref_output test_to enforce_sorted True False padded lengths = _padded_sequence torch IntTensor = rnn_utils pack_padded_sequence padded lengths enforce_sorted=enforce_sorted cpu assertIs cpu assertIs cpu assertIs cpu dtype=torch int assertEqual long torch int torch cuda is_available cuda cuda cuda torch cuda device_count == cuda b = cuda device=cuda assertIs b b cuda assertIs b b cuda assertEqual b cpu assertEqual b cuda assertEqual b cpu dtype=torch int assertIs b b dtype=torch int assertEqual b long b dtype=torch int test_to_memory_format m = torch nn Conv d in_channels= out_channels= kernel_size= bias=True m = m memory_format=torch channels_last param m parameters param dim == assertTrue param is_contiguous memory_format=torch channels_last test_pad_sequence pad tensor length torch cat tensor data tensor data new length - tensor size tensor size zero_ single dimensional = torch tensor b = torch tensor c = torch tensor batch_first = true expected = torch tensor padded = rnn_utils pad_sequence b c True assertEqual padded expected batch_first = false padded = rnn_utils pad_sequence b c assertEqual padded expected transpose padding_side = left batch_first=True expected = torch tensor padded = rnn_utils pad_sequence b c batch_first=True padding_side= left assertEqual padded expected padding_side = left batch_first=False padded = rnn_utils pad_sequence b c batch_first=False padding_side= left assertEqual padded expected transpose pad non-zero value expected = torch tensor padded = rnn_utils pad_sequence b c True assertEqual padded expected Test pad sorted sequence expected = torch tensor padded = rnn_utils pad_sequence b c True assertEqual padded expected more dimensions maxlen = num_dim sequences list torch Tensor = trailing_dims = num_dim i range maxlen + seq_len = i i sequences append torch rand seq_len trailing_dims random shuffle sequences batch first = true expected = torch stack pad seq maxlen maxlen seq sequences padded = rnn_utils pad_sequence sequences True assertEqual padded expected batch first = false padded = rnn_utils pad_sequence sequences assertEqual padded expected transpose padding_side = left batch_first=True expected = torch stack pad seq flip maxlen maxlen flip seq sequences padded = rnn_utils pad_sequence sequences batch_first=True padding_side= left assertEqual padded expected padding_side = left batch_first=False padded = rnn_utils pad_sequence sequences batch_first=False padding_side= left assertEqual padded expected transpose test_unpad_sequence single dimensional = torch tensor b = torch tensor c = torch tensor sequences = b c lengths = torch as_tensor v size v sequences batch_first True False padded_sequences = rnn_utils pad_sequence sequences batch_first=batch_first unpadded_sequences = rnn_utils unpad_sequence padded_sequences lengths batch_first=batch_first assertEqual sequences unpadded_sequences more dimensions maxlen = num_dim sequences = trailing_dims = num_dim i range maxlen + seq_len = i i sequences append torch rand seq_len trailing_dims random shuffle sequences lengths = torch as_tensor v size v sequences padded_sequences = rnn_utils pad_sequence sequences batch_first=batch_first unpadded_sequences = rnn_utils unpad_sequence padded_sequences lengths batch_first=batch_first assertEqual sequences unpadded_sequences test_pack_sequence _compatibility_test sequences lengths batch_first enforce_sorted=False padded = rnn_utils pad_sequence sequences batch_first packed = rnn_utils pack_sequence sequences enforce_sorted unpacked = rnn_utils pad_packed_sequence packed batch_first assertEqual padded unpacked pack_padded = rnn_utils pack_padded_sequence padded lengths batch_first enforce_sorted assertEqual packed pack_padded single dimensional = torch tensor b = torch tensor c = torch tensor packed = rnn_utils pack_sequence b c enforce_sorted=False expected = torch tensor assertEqual packed batch_sizes assertEqual packed data data expected assertEqual packed sorted_indices assertEqual packed unsorted_indices packed_unsorted = rnn_utils pack_sequence b c enforce_sorted=False assertEqual packed_unsorted batch_sizes assertEqual packed_unsorted data data expected assertEqual packed_unsorted sorted_indices assertEqual packed_unsorted unsorted_indices single dimensional enforce_sorted = True packed_enforce_sorted = rnn_utils pack_sequence b c enforce_sorted=True assertEqual packed_enforce_sorted batch_sizes assertEqual packed_enforce_sorted data data expected assertTrue packed_enforce_sorted sorted_indices None assertTrue packed_enforce_sorted unsorted_indices None assertRaisesRegex RuntimeError must sorted decreasing order rnn_utils pack_sequence b c enforce_sorted=True assertRaisesRegex RuntimeError You can pass ` enforce_sorted=False ` rnn_utils pack_sequence b c enforce_sorted=True more dimensions maxlen = num_dim sequences = lengths = trailing_dims = num_dim i range maxlen - seq_len = i i lengths append seq_len sequences append torch rand seq_len trailing_dims unsorted_sequences = s clone s sequences random shuffle unsorted_sequences unsorted_sequences_lengths = t size t unsorted_sequences compatibility other utilities batch_first True False enforce_sorted True False _compatibility_test sequences lengths batch_first enforce_sorted _compatibility_test unsorted_sequences unsorted_sequences_lengths batch_first test_unpack_sequence single dimensional = torch tensor b = torch tensor c = torch tensor sequences = b c packed_sequences = rnn_utils pack_sequence sequences enforce_sorted=False unpacked_sequences = rnn_utils unpack_sequence packed_sequences assertEqual sequences unpacked_sequences more dimensions maxlen = num_dim sequences = trailing_dims = num_dim i range maxlen + seq_len = i i sequences append torch rand seq_len trailing_dims random shuffle sequences packed_sequences = rnn_utils pack_sequence sequences enforce_sorted=False unpacked_sequences = rnn_utils unpack_sequence packed_sequences assertEqual sequences unpacked_sequences test_pack_padded_sequence generate_test_case sorted_lengths should_shuffle pad tensor length torch cat tensor tensor new length - tensor size tensor size zero_ max_length = sorted_lengths batch_sizes = sum map bool filter lambda x x = i sorted_lengths i range max_length + padded = torch cat pad i + torch arange l + view l max_length i l enumerate sorted_lengths expected_data = torch arange + i + + n i range batch_size n batch_size enumerate batch_sizes expected_data = list itertools chain from_iterable expected_data expected_data = torch stack expected_data dim= should_shuffle Shuffle padded sequence create unsorted sequence permutation = list range len sorted_lengths random shuffle permutation unsorted_indices = torch tensor permutation padded = padded index_select unsorted_indices lengths = torch tensor sorted_lengths index_select unsorted_indices unsorted_indices = None lengths = sorted_lengths padded requires_grad_ lengths expected_data batch_sizes unsorted_indices test_cases = sorted_lengths should_shuffle False False True test_case batch_first itertools product test_cases True False sorted_lengths should_shuffle = test_case padded lengths expected_data batch_sizes unsorted_indices = generate_test_case sorted_lengths should_shuffle src = padded batch_first src = src transpose check output packed = rnn_utils pack_padded_sequence src lengths batch_first=batch_first enforce_sorted=not should_shuffle assertEqual packed data data expected_data assertEqual packed batch_sizes batch_sizes assertEqual packed unsorted_indices unsorted_indices test inverse unpacked unpacked_len = rnn_utils pad_packed_sequence packed batch_first=batch_first assertEqual unpacked src assertEqual unpacked_len lengths check grad padded grad None padded grad data zero_ grad_output = unpacked data clone normal_ unpacked backward grad_output batch_first grad_output transpose_ i l enumerate lengths assertEqual padded grad data l i grad_output l i l assertEqual padded grad data l i abs sum test error messages assertRaisesRegex RuntimeError You can pass ` enforce_sorted=False ` packed = rnn_utils pack_padded_sequence torch randn assertRaisesRegex RuntimeError empty tensor packed = rnn_utils pack_padded_sequence torch randn assertRaisesRegex RuntimeError empty tensor packed = rnn_utils pack_padded_sequence torch randn torch randn True __name__ == __main__ run_tests