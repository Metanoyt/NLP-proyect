torch torch _inductor runtime benchmarking benchmarker create_blocked_tensor B M N blocksize sparsity dtype device assert sparsity = sparsity = sparsity should value between assert M blocksize == assert N blocksize == shape = B M blocksize N blocksize int B == A = torch bernoulli torch full shape - sparsity dtype=dtype device=device expected_nnz = int - sparsity M N blocksize blocksize nonzero_indices = A flatten nonzero actual_nnz = nonzero_indices shape actual_nnz expected_nnz selected_nonzeros = torch randperm actual_nnz actual_nnz - expected_nnz A flatten nonzero_indices selected_nonzeros = actual_nnz expected_nnz zero_indices = A == flatten nonzero selected_zeros = torch randperm zero_indices shape expected_nnz - actual_nnz A flatten zero_indices selected_zeros = A = torch repeat_interleave A blocksize dim=- A = torch repeat_interleave A blocksize dim=- A _test_worker test_func ms ms_min ms_max = benchmarker benchmark_gpu test_func warmup= rep= tflops = m k n e- ms e- ms tflops test_dense_dense_mm x y meta test_func x=x to_dense y=y torch matmul x y _test_worker test_func test_torch_matmul x y meta test_func x=x y=y torch matmul x y _test_worker test_func test_bsr_dense_mm x y meta torch sparse _triton_ops bsr_dense_mm test_func x=x y=y bsr_dense_mm x y meta=dict GROUP_SIZE_ROW= num_stages= num_warps= _test_worker test_func test_bsr_dense_mm_with_meta x y meta torch sparse _triton_ops bsr_dense_mm test_func x=x y=y meta=meta bsr_dense_mm x y meta=meta _test_worker test_func test_bsr_scatter_mm x y meta torch sparse _triton_ops bsr_scatter_mm bsr_scatter_mm_indices_data indices_data = bsr_scatter_mm_indices_data x y indices_format= scatter_mm meta test_func x=x y=y bsr_scatter_mm x y indices_data=indices_data _test_worker test_func test_bsr_scatter_mm x y meta torch sparse _triton_ops bsr_scatter_mm bsr_scatter_mm_indices_data indices_data = bsr_scatter_mm_indices_data x y indices_format= bsr_strided_mm_compressed meta test_func x=x y=y bsr_scatter_mm x y indices_data=indices_data _test_worker test_func test_bsr_scatter_mm x y meta torch sparse _triton_ops bsr_scatter_mm bsr_scatter_mm_indices_data test_func x=x y=y indices_data = bsr_scatter_mm_indices_data x y indices_format= bsr_strided_mm_compressed meta bsr_scatter_mm x y indices_data=indices_data _test_worker test_func test_linear x y meta torch nn functional F test_func x=x y=y transpose - - F linear y x _test_worker test_func __name__ == __main__ argparse atexit itertools sys triton torch testing make_tensor torch manual_seed integer_list list map int split float_list list map float split integer_or_float_list lst = n split n count == start end = map int n split lst extend range start end n count == start end step = map int n split lst extend range start end step n lst append float n lst append int n lst parser = argparse ArgumentParser description= SpTritonOps parser add_argument -- ops default= dense_dense_mm bsr_dense_mm bsr_scatter_mm type=str parser add_argument -- b default= type=int parser add_argument -- m default= type=integer_list parser add_argument -- k default=None type=integer_list parser add_argument -- n default=None type=integer_list parser add_argument -- bm default= type=integer_list parser add_argument -- bk default=None type=integer_list parser add_argument -- tile_m default=None type=integer_list parser add_argument -- tile_n default=None type=integer_list parser add_argument -- split_n default=None type=integer_list parser add_argument -- group_size default=None type=integer_list parser add_argument -- num_warps default=None type=integer_list parser add_argument -- num_stages default=None type=integer_list parser add_argument -- sparsity default= type=integer_or_float_list parser add_argument -- dtype default= float type=str parser add_argument -- device default= cuda type=str parser add_argument -- repeat default= type=int parser add_argument -- outfile default= stdout type=str parser add_argument -- star default=False action= store_true args = parser parse_args args outfile == stdout outfile = sys stdout args outfile == stderr outfile = sys stderr outfile = open args outfile ops = args ops split b = args b m_list = args m n_list = args n None k_list = args k None bm_list = args bm bk_list = args bk None split_n_list = args split_n None tile_m_list = args tile_m None tile_n_list = args tile_n None group_size_list = args group_size None num_warps_list = args num_warps None num_stages_list = args num_stages None sparsity_list = args sparsity dtype = getattr torch args dtype args star torch sparse _triton_ops assert len m_list len n_list len k_list len bm_list len bk_list == m = m_list n = n_list m k = k_list m bm = bm_list bk = bk_list bm bsr_scatter_mm ops meta = torch sparse _triton_ops scatter_mm_meta m k n bm bk bsr_dense_mm_with_meta ops meta = torch sparse _triton_ops bsr_dense_mm_meta m k n bm bk raise NotImplementedError f -- star implemented operations ops bsr_scatter_mm ops split_n_list None split_n_list = meta SPLIT_N meta SPLIT_N meta SPLIT_N int meta SPLIT_N == split_n_list == split_n_list = meta SPLIT_N tile_m_list None tile_m_list = meta TILE_M meta TILE_M meta TILE_M int meta TILE_M == tile_m_list == tile_m_list = meta TILE_M tile_n_list None tile_n_list = meta TILE_N meta TILE_N meta TILE_N int meta TILE_N == tile_n_list == tile_n_list = meta TILE_N group_size_list None group_size_list = meta GROUP_SIZE - meta GROUP_SIZE meta GROUP_SIZE + int meta GROUP_SIZE == group_size_list == group_size_list = meta GROUP_SIZE bsr_dense_mm_with_meta ops group_size_list None group_size_list = meta GROUP_SIZE_ROW - meta GROUP_SIZE_ROW meta GROUP_SIZE_ROW + int meta GROUP_SIZE_ROW == group_size_list == group_size_list = meta GROUP_SIZE_ROW num_warps_list None num_warps_list = meta num_warps meta num_warps meta num_warps int meta num_warps == num_warps_list == num_warps_list = meta num_warps num_stages_list None num_stages_list = meta num_stages - meta num_stages meta num_stages + int meta num_stages == num_stages_list == num_stages_list = meta num_stages device = args device dense_dense_mm_sizes = set target_performance = None performance_rtol = e- best_messages = atexit register show_best_messages best_messages=best_messages print TOP m best_messages - print m sys stdout flush m k n bm bk sparsity itertools product m_list k_list n_list bm_list bk_list sparsity_list k = k m n = n m bk = bk bm bm m bk k Skip invalid parameter combinations continue blocksize = bm bk isinstance sparsity int integer sparsity value corresponds desired nnz value sparsity = - bk bm sparsity m k sparsity sparsity continue x = create_blocked_tensor b m k blocksize sparsity dtype device to_sparse_bsr blocksize recompute sparsity sparsity = - bk bm x _nnz m k y = make_tensor k n dtype=dtype device=device bsr_size = f b x m x k b f k x n op ops op == dense_dense_mm m k n dense_dense_mm_sizes Skip already benchmarked cases continue dense_dense_mm_sizes add m k n best_tflops = split_n num_warps num_stages tile_m tile_n group_size itertools product split_n_list num_warps_list num_stages_list tile_m_list tile_n_list group_size_list tile_m bm tile_n n split_n n split_n = split_n n Skip invalid parameter combinations continue test_func = globals test_ + op meta = dict bsr_scatter_mm =dict SPLIT_N=split_n TILE_M=tile_m TILE_N=tile_n GROUP_SIZE=group_size num_stages=num_stages num_warps=num_warps bsr_dense_mm_with_meta=dict GROUP_SIZE_ROW=group_size num_stages=num_stages num_warps=num_warps get op meta_str = join f k = v k v meta items v None time_ms_lst = performance_tflops_lst = r range args repeat try time_ms performance_tflops = test_func x y meta except triton compiler OutOfResources print f op= op meta_str bsr_size k x n dtype= args dtype sparsity= nnz= x _nnz f blocksize= bm x bk OutOfResources file=outfile continue except AssertionError raise except Exception msg msg = str msg split \n print f op= op meta_str bsr_size k x n dtype= args dtype sparsity= nnz= x _nnz f blocksize= bm x bk msg file=outfile continue time_ms_lst append time_ms performance_tflops_lst append performance_tflops mark = op == dense_dense_mm target_performance None target_performance = performance_tflops target_performance None abs - performance_tflops target_performance performance_rtol mark += best_tflops performance_tflops best_tflops = performance_tflops best_message = f op= op meta_str bsr_size x n dtype= args dtype sparsity= f nnz= x _nnz f blocksize= bm x bk time= time_ms f ms performance= performance_tflops f TFLOPS best_message best_messages best_messages append best_message mark += print f op= op meta_str bsr_size x n dtype= args dtype sparsity= f nnz= x _nnz f blocksize= bm x bk f time= time_ms f ms performance= performance_tflops f TFLOPS mark file=outfile outfile flush args repeat avg_time_ms = sum time_ms_lst len time_ms_lst avg_performance_tflops = sum performance_tflops_lst len performance_tflops_lst print f op= op meta_str bsr_size k x n dtype= args dtype sparsity= nnz= x _nnz f blocksize= bm x bk f time= time_ms f ms performance= performance_tflops f TFLOPS AVERAGE file=outfile outfile flush op bsr_scatter_mm bsr_dense_mm_with_meta Break operations do consume parameters break