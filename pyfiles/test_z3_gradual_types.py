Owner s module fx operator unittest torch torch fx GraphModule symbolic_trace torch fx experimental meta_tracer symbolic_trace meta_symbolic_trace torch fx experimental migrate_gradual_types constraint BinConstraintT DVar T TVar torch fx experimental migrate_gradual_types constraint_generator ConstraintGenerator torch fx experimental migrate_gradual_types constraint_transformation transform_constraint torch fx experimental migrate_gradual_types operation op_consistency op_matching op_precision torch fx experimental migrate_gradual_types transform_to_z evaluate_conditional_with_constraints transform_all_constraints torch fx experimental migrate_gradual_types z _types D tensor_type z _dyn torch fx experimental rewriter RewritingTracer torch fx tensor_type Dyn TensorType try z type ignore HAS_Z = True except ImportError HAS_Z = False try torchvision models HAS_TORCHVISION = True except ImportError HAS_TORCHVISION = False skipIfNoTorchVision = unittest skipIf HAS_TORCHVISION no torchvision TorchDynamoUseCases unittest TestCase test_dim BasicBlock torch nn Module forward x TensorType y = x dim y symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat y_res = z z Int assertEqual s model y_res test_reshape In example we prove some nodes must always have fixed shape regardless input BasicBlock torch nn Module forward x Dyn y = x view tmp = y size tmp symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat dim = z Int assertEqual s model dim print s model dim HFOperations unittest TestCase test_eq_dim test dimensions equalities BasicBlock torch nn Module forward x TensorType eq = x dim == eq ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock The node we considering gt node n graph nodes n target == operator eq node = n positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z sat assertEqual negative z unsat test_conditional_ne_ This test case HFmodels interface A function takes node graph considers conditional node represents its negation solves each formula remaining sets constraints Returns BasicBlock torch nn Module forward x TensorType y TensorType size_ = x size getitem_ = size_ getitem_ = size_ getitem_ = size_ ne_ = y = getitem_ getitem_ getitem_ ne_ ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock The node we considering gt node n graph nodes n target == operator ne node = n since x y equal requirement x = y cannot true so we should get unsat positive condition sat negative condition positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z unsat assertEqual negative z sat test_bmm BasicBlock torch nn Module forward x TensorType Dyn y TensorType bmm = torch bmm x y bmm symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock b = BasicBlock forward torch rand torch rand transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed output = z Const tensor_type assertEqual s check z sat assertEqual s model output arg arg b shape assertEqual s model output arg arg b shape assertEqual s model output arg arg b shape test_bmm BasicBlock torch nn Module forward x Dyn y TensorType bmm = torch bmm x y bmm symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock b = BasicBlock forward torch rand torch rand transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed output = z Const tensor_type assertEqual s check z sat assertEqual s model output arg arg b shape assertEqual s model output arg arg assertEqual s model output arg arg b shape test_bmm BasicBlock torch nn Module forward x TensorType y TensorType bmm = torch bmm x y bmm symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z unsat test_transpose BasicBlock torch nn Module forward x TensorType transpose = x transpose transpose symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock b = BasicBlock forward torch rand transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed output = z Const tensor_type assertEqual s check z sat assertEqual s model output arg arg b shape assertEqual s model output arg arg b shape assertEqual s model output arg arg b shape assertEqual s model output arg arg b shape change annotation Dyn n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat test_index_select BasicBlock torch nn Module forward x TensorType y Dyn index_select = x index_select y index_select symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock print symbolic_traced b = BasicBlock forward torch rand torch ones int transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat index_select = z Const tensor_type second dimension result should affected since index assertEqual s model index_select arg arg b shape replacement_vector = z Const tensor_type we set vector Dyn s = z Solver s add transformed assertEqual s check z sat index_select = z Const tensor_type s add replacement_vector == z _dyn assertEqual s check z sat implies index should dyn assertEqual s model index_select arg arg test_get_attr BasicBlock torch nn Module forward x TensorType getattr = x device = x getattr symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock b = BasicBlock forward torch rand transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat attr_res = z Const tensor_type assert s model attr_res arg arg == b shape assert s model attr_res arg arg == b shape assert s model attr_res arg arg == b shape test_expand BasicBlock torch nn Module forward x TensorType size = x size getitem = size - expand = x expand getitem expand b = BasicBlock forward torch rand symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat expand_res = z Const tensor_type assert s model expand_res arg arg == b shape assert s model expand_res arg arg == b shape change annotation input Dyn last dimension should still n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat assert s model expand_res arg arg == b shape test_getitem_tensor BasicBlock torch nn Module forward x TensorType getitem = x None None slice None None None slice None None None getitem B = BasicBlock b = B forward torch rand symbolic_traced torch fx GraphModule = symbolic_trace B transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat get_item_res = z Const tensor_type assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape change annotation input make sure propagates output n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat dyn check assert s model get_item_res arg arg == test_getitem_tensor BasicBlock torch nn Module forward x TensorType getitem = x None None getitem B = BasicBlock b = B forward torch rand symbolic_traced torch fx GraphModule = symbolic_trace B transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat get_item_res = z Const tensor_type assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape test_getitem_tensor_ BasicBlock torch nn Module forward x TensorType getitem = x None slice None None None None slice None None None getitem B = BasicBlock b = B forward torch rand symbolic_traced torch fx GraphModule = symbolic_trace B transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat get_item_res = z Const tensor_type assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape assert s model get_item_res arg arg == b shape test_layer_norm BasicBlock torch nn Module __init__ - None super __init__ l = torch nn LayerNorm forward x Dyn l x ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat make output size tensor which should result migration input b = BasicBlock forward torch rand input = z Const tensor_type output = z Const tensor_type s add output == tensor_type tensor D s check assertEqual s model input s model output input shape = output shape assertEqual b shape s model input arg arg change annotation wrong shape n graph nodes n op == placeholder n type = TensorType traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z unsat fix annotation n graph nodes n op == placeholder n type = TensorType traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed s check b = BasicBlock forward torch rand shape assertEqual s model output arg arg b assertEqual s model output arg arg b test_layer_norm_functional BasicBlock torch nn Module forward x Dyn torch nn functional layer_norm x ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat make output size tensor which should result migration input b = BasicBlock forward torch rand input = z Const tensor_type output = z Const tensor_type s add output == tensor_type tensor D s check assertEqual s model input s model output input shape = output shape assertEqual b shape s model input arg arg test_ne_int_long_type_as BasicBlock torch nn Module forward x TensorType Dyn Dyn y TensorType Dyn Dyn ne_int = torch ne x y int type_as = ne_int type_as y long = type_as long long symbolic_traced torch fx GraphModule = symbolic_trace BasicBlock transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat migrate one parameters fully static shape so we can compare input = z Const tensor_type input_ = z Const tensor_type s s = z Ints s s output_long = z Const tensor_type s add input == tensor_type tensor D D s add input_ == tensor_type tensor D s D s assertEqual s check z sat actual_shape = BasicBlock forward torch rand torch rand shape assertEqual s model output_long arg arg actual_shape assertEqual s model output_long arg arg actual_shape test_ne s s = z Ints s s s s = z Ints s s d d = D s s D s BasicBlock torch nn Module forward x Dyn y Dyn torch ne x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat change annotations n graph nodes n name == x n type = TensorType n name == y n type = TensorType Dyn resulting type should TensorType transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat force second dimension Dyn output should still TensorType input = z Const tensor_type s add input == tensor_type tensor d d assertEqual s check z sat B = BasicBlock forward torch rand torch rand output = z Const tensor_type assertEqual s model output arg arg B shape assertEqual s model output arg arg B shape test_cumsum BasicBlock torch nn Module forward x TensorType Dyn t = torch cumsum x t symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed should unsat since index valid annotation assertEqual s check z unsat modify annotation Dyn which should give sat n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat modify annotation right tensor size n symbolic_traced graph nodes n op == placeholder n type = TensorType verify input equal output B = BasicBlock forward torch rand res_shape = B shape transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat confirm output matches expected tensor result = z Const tensor_type assertEqual s model result arg arg res_shape assertEqual s model result arg arg res_shape assertEqual s model result arg arg res_shape assertEqual s model result arg arg res_shape confirm output dyn assertNotEqual s model result arg arg as_long assertNotEqual s model result arg arg as_long assertNotEqual s model result arg arg as_long assertNotEqual s model result arg arg as_long test_cumsum_kwargs BasicBlock torch nn Module forward x TensorType Dyn t = torch cumsum x dim= t symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed should unsat since index valid annotation assertEqual s check z unsat modify annotation Dyn which should give sat n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat test_arange BasicBlock torch nn Module forward x TensorType size = x size getitem = size - arange = torch arange getitem arange B = BasicBlock forward torch rand symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat arange_result = z Const tensor_type assertNotEqual s model arange_result arg arg as_long assertEqual s model arange_result arg arg as_long B size change annotation Dyn This will migrate arbitrary type n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn Dyn Dyn Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat test_scalar_add BasicBlock torch nn Module forward x TensorType size = x size getitem = size - arange = torch arange getitem add = arange + add symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat arange_result = z Const tensor_type add_result = z Const tensor_type assertEqual s model arange_result s model add_result test_regular_add_ BasicBlock torch nn Module forward x TensorType = x size = size getitem = size - add = getitem + add b = BasicBlock forward torch rand symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat res = z Int assertEqual s model res b test_regular_add_ BasicBlock torch nn Module forward x TensorType = x size = size getitem = size - add = + getitem add b = BasicBlock forward torch rand symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat res = z Int assertEqual s model res b test_embedding BasicBlock torch nn Module __init__ - None super __init__ embedding = torch nn Embedding padding_idx= forward x TensorType embedding x B = BasicBlock forward torch ones dtype=torch long size ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat embedding_result = z Const tensor_type assert s model embedding_result arg arg == B assert s model embedding_result arg arg == B assert s model embedding_result arg arg == B change type This should still satisfiable n traced graph nodes n op == placeholder n type = TensorType Dyn Dyn transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat assert s model embedding_result arg arg == assert s model embedding_result arg arg == assert s model embedding_result arg arg == B change type Dyn Here we will get arbitrary migration n traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat test_embedding_ BasicBlock torch nn Module forward x TensorType y TensorType Dyn torch nn functional embedding x y B = BasicBlock forward torch ones dtype=torch long torch rand size ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat embedding_result = z Const tensor_type assert s model embedding_result arg arg == B assert s model embedding_result arg arg == B assert s model embedding_result arg arg == B test_size_two_args BasicBlock torch nn Module forward x TensorType Dyn Dyn size = x size - size ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat d d = z Int z Int d d = z Int input_d z Int input_d migrate third dimension s add d = assertEqual s check z sat input = z Const tensor_type s add input == tensor_type tensor D D D d d check item we got right one assertEqual s check z sat assertEqual s model d s model d assertEqual s model d s model d test_size_getitem BasicBlock torch nn Module forward x Dyn size = x size getitem = size - getitem ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat force input size s s s s = z Ints x x x x s s s s = z Ints x x x x d d d d = D s s D s s D s s D s s input = z Const tensor_type s add input == tensor_type tensor d d d d check model still SAT assertEqual s check z sat s s = z Int z Int check item correct assertEqual s model s s model s invalid index should still SAT because input will Dyn BasicBlock torch nn Module forward x Dyn size = x size getitem = size - getitem ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat s add input = z _dyn assertEqual s check z unsat test_view_mul BasicBlock torch nn Module __init__ - None super __init__ embed_tokens = torch nn Embedding padding_idx= forward x TensorType size = x size getitem = size - view = x view - getitem embed_tokens = embed_tokens view mul = embed_tokens mul print B ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm print traced transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat print s model embedding_result = z Const tensor_type note view output will tensor dim dim dim due reshape constraints This can lifted would require revising type rules accordingly so we leave now assert s model embedding_result arg arg == assert s model embedding_result arg arg == mul_result = z Const tensor_type assert s model mul_result == s model embedding_result test_gt BasicBlock torch nn Module forward x TensorType Dyn size = x size getitem_ = size - gt = getitem_ gt ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat res = z Bool assertEqual s model res True test_view BasicBlock torch nn Module forward x TensorType view = x view - view ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat test_lt_tensor BasicBlock torch nn Module forward x TensorType y Dyn lt = x y lt ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat test_conditional_wrong_assumption Test condition after making wrong assumption about input BasicBlock torch nn Module forward x Dyn gt = x gt ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock The node we considering gt node n graph nodes n target == operator gt node = n positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z sat assertEqual negative z sat test_conditional This test case HFmodels interface A function takes node graph considers conditional node represents its negation solves each formula remaining sets constraints Returns BasicBlock torch nn Module __init__ - None super __init__ embed_tokens = torch nn Embedding padding_idx= forward x TensorType Dyn size = x size getitem = size - view = x view - getitem _embed_tokens = embed_tokens view getitem_ = size - gt = getitem_ gt ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock The node we considering gt node n graph nodes n target == operator gt node = n positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z sat assertEqual negative z unsat change annotation Dyn n graph nodes n op == placeholder n type = Dyn here both should SAT since input Dyn positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z sat assertEqual negative z sat change annotation TensorType Dyn Dyn n graph nodes n op == placeholder n type = TensorType Dyn Dyn here both should SAT well positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z sat assertEqual negative z sat test_conditional_ This test case HFmodels interface A function takes node graph considers conditional node represents its negation solves each formula remaining sets constraints Returns opposite result above testcase BasicBlock torch nn Module __init__ - None super __init__ embed_tokens = torch nn Embedding padding_idx= forward x TensorType Dyn size = x size getitem = size - view = x view - getitem _embed_tokens = embed_tokens view getitem_ = size - lt = getitem_ lt ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock The node we considering gt node n graph nodes n target == operator lt node = n positive negative = evaluate_conditional_with_constraints ast_rewriter root graph node assertEqual positive z unsat assertEqual negative z sat ComposeOperationsGradualTypes unittest TestCase test_masked_fill BasicBlock torch nn Module forward x TensorType size = x size getitem = size - arange = torch arange getitem view = x view - getitem lt = arange view masked_fill = x masked_fill_ lt masked_fill B = BasicBlock forward torch rand print B shape symbolic_traced torch fx GraphModule = meta_symbolic_trace BasicBlock meta_args= print symbolic_traced transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat masked_fill_res = z Const tensor_type assertEqual s model masked_fill_res arg arg as_long B size assertEqual s model masked_fill_res arg arg as_long B size change annotation Dyn This will migrate arbitrary type n symbolic_traced graph nodes n op == placeholder n type = Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn Dyn Dyn Dyn transformed = transform_all_constraints symbolic_traced counter= s = z Solver s add transformed assertEqual s check z sat test_add_reshape_ BasicBlock torch nn Module forward x Dyn y Dyn torch add torch reshape x torch reshape y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat test_add_reshape_ BasicBlock torch nn Module forward x Dyn y Dyn torch add torch reshape x - torch reshape y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat test_conv_reshape_add_ BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn y Dyn torch add conv torch reshape x y B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z sat test_conv_reshape_add_ _ BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn y TensorType torch add conv torch reshape x y B = BasicBlock res = B forward torch rand torch rand size ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z sat conv_result = z Const tensor_type add_result = z Const tensor_type input_ = z Const tensor_type s s s s = z Ints x x x x s s s s = z Ints x x x x d d d d = D s s D s s D s s D s s solver add conv_result == tensor_type tensor d d d d solver check assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res solver add input_ == tensor_type tensor D D assertEqual solver check z sat solver add add_result == tensor_type tensor d d d d assertEqual solver check z sat first dimension could anything because we have broadcasting assert solver model s == res assert solver model s == res assert solver model s == res assert solver model s == res test_conv_reshape_add_ _ BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn y TensorType torch add conv torch reshape x y B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z unsat test_conv_reshape_add_ BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn y TensorType torch add conv torch reshape x y B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z unsat GradualTypes unittest TestCase test_conv_reshape_unsat BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn conv torch reshape x B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z unsat test_conv_reshape BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn conv torch reshape x B = BasicBlock res = B forward torch rand size ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z sat conv_result = z Const tensor_type s s s s = z Ints x x x x s s s s = z Ints x x x x d d d d = D s s D s s D s s D s s solver add conv_result == tensor_type tensor d d d d solver check print solver model print type solver model s assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res s s s s = z Ints y y y y s s s s = z Ints y y y y d d d d = D s s D s s D s s D s s input = z Const tensor_type solver add input == tensor_type tensor d d d d assert solver check == sat solver add s == solver add s == solver add s == solver add s == print solver check print solver model test_conv_reshape BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x TensorType conv torch reshape x - B = BasicBlock res = B forward torch rand size ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z sat conv_result = z Const tensor_type s s s s = z Ints x x x x s s s s = z Ints x x x x d d d d = D s s D s s D s s D s s solver add conv_result == tensor_type tensor d d d d solver check print solver model assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res assert solver model s as_long == res TestSingleOperation unittest TestCase test_conv_wrong_example BasicBlock torch nn Module __init__ - None super __init__ conv = torch nn Conv d in_channels= out_channels= kernel_size= stride= padding= groups= bias=False dilation= conv = torch nn Conv d in_channels= out_channels= kernel_size= stride= padding= groups= bias=False dilation= relu = torch nn ReLU inplace=True forward x Dyn y = relu conv x noqa F z = relu conv x z ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced solver = z Solver solver add transformed print solver check assert solver check == z sat s s s s = z Ints s s s s s s s s = z Ints s s s s d d d d = D s s D s s D s s D s s x = z Const tensor_type solver add x == tensor_type tensor d d d d assert solver check == z sat solver add s = assert solver check == z unsat test_conv_dyn s s s s = z Ints s s s s e e e e = z Ints e e e e s s s s = z Ints s s s s e e e e = z Ints e e e e d d d d = D s s D s s D s s D s s b b b b = D e e D e e D e e D e e BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn conv x BasicBlock forward torch rand ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced solver = z Solver solver add transformed assert solver check == z sat x = z Const tensor_type y = z Const tensor_type solver add x == tensor_type tensor d d d d y == tensor_type tensor b b b b assert solver check == z sat assert solver model s as_long == solver model e as_long assert solver model s as_long == solver model e as_long solver add s = assert solver check == z sat assert solver model s as_long == solver add s = assertEqual solver check z unsat solver = z Solver solver add transformed assert solver check == z sat solver add x == tensor_type tensor d d d assertEqual solver check z unsat test_add s s s s = z Ints s s s s s s s s = z Ints s s s s d d = D s s D s s BasicBlock torch nn Module forward x Dyn y Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat make tensor size x = z Const tensor_type s add x == tensor_type tensor D s assertEqual s check z sat y = z Const tensor_type s add y == tensor_type tensor D s assertEqual s check z sat s add s == tensor s add s == tensor assertEqual s check z sat BasicBlock torch nn Module forward x TensorType Dyn y Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced s = z Solver s add transformed assertEqual s check z sat make tensor size x = z Const tensor_type s add x == tensor_type tensor D s assertEqual s check z sat y = z Const tensor_type s add y == tensor_type tensor D s assertEqual s check z sat s add s == tensor s add s == tensor assertEqual s check z unsat BasicBlock torch nn Module forward x TensorType Dyn y Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced s = z Solver s add transformed x = z Const tensor_type s add x == tensor_type tensor d d assertEqual s check z unsat test_add_padding s s s s = z Ints s s s s BasicBlock torch nn Module forward x TensorType Dyn y TensorType Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s add x == tensor_type tensor D s assertEqual s check z sat print s model test_add_padding_ s s s s = z Ints s s s s BasicBlock torch nn Module forward x TensorType Dyn Dyn y TensorType Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat print s model x = z Const tensor_type s add x == tensor_type tensor D s D s assertEqual s check z sat y = z Const tensor_type s add y == tensor_type tensor D s assertEqual s check z sat add_result = z Const tensor_type broadcast_res broadcast_res = z Const tensor_type z Const tensor_type print s model assert s model broadcast_res decl == tensor_type tensor assert s model broadcast_res decl == tensor_type tensor assert s model add_result decl == tensor_type tensor assert s model y decl == tensor_type tensor print s model prevent broadcasting dimension s add s assert s check second dimension result number Dyn however first input dimension had been we would have had dyn result seen next test case assert s model add_result arg arg as_long = test_add_padding_ s s s s = z Ints s s s s BasicBlock torch nn Module forward x TensorType Dyn y TensorType Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed print transformed assertEqual s check z sat x = z Const tensor_type y = z Const tensor_type s add s = s add x == tensor_type tensor D s D s s add y == tensor_type tensor D s assertEqual s check z sat print s model add_result = z Const tensor_type assert s model add_result arg arg as_long == assert s model add_result arg arg as_long == test_add_padding_ BasicBlock torch nn Module forward x TensorType y TensorType torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat add_result = z Const tensor_type assert s model add_result == tensor_type tensor D D test_add_padding_ BasicBlock torch nn Module forward x TensorType y TensorType torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z unsat test_add_size_ BasicBlock torch nn Module forward x TensorType Dyn Dyn Dyn y TensorType Dyn Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type y = z Const tensor_type s s s s s = z Ints s s s s s s add x == tensor_type tensor D s D D s s add y == tensor_type tensor D s D s D s assertEqual s check z sat s add s == assertEqual s check z sat s add s == assertEqual s check z unsat test_add_padding_ BasicBlock torch nn Module forward x TensorType Dyn y TensorType Dyn Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type y = z Const tensor_type s s s s s = z Ints s s s s s s add x == tensor_type tensor D s s add y == tensor_type tensor D s D s D s assertEqual s check z sat s add s == s add s == assertEqual s check z unsat test_add_padding_ BasicBlock torch nn Module forward x TensorType Dyn y TensorType Dyn Dyn Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s s s s s = z Ints s s s s s s add x == tensor_type tensor D s s D s s assertEqual s check z unsat test_add_padding_ BasicBlock torch nn Module forward x TensorType Dyn y TensorType Dyn Dyn Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type y = z Const tensor_type s s s s s = z Ints s s s s s s add x == tensor_type tensor D s s add s = assertEqual s check z sat s add y == tensor_type tensor D s D s D s D s assertEqual s check z sat test_add_padding_ BasicBlock torch nn Module forward x Dyn y TensorType Dyn Dyn Dyn Dyn torch add x y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced counter= s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type y = z Const tensor_type s s s s s s s = z Ints s s s s s s s s add x == tensor_type tensor D s s s add s == assertEqual s check z sat s add y == tensor_type tensor D s D s D s D s s assertEqual s check z sat s add s == assertEqual s check z sat s add s = s = assert s check assert s model s as_long == s model s as_long test_conv_static s s s s = z Ints s s s s e e e e = z Ints e e e e s s s s = z Ints s s s s e e e e = z Ints e e e e d d d d = D s s D s s D s s D s s b b b b = D e e D e e D e e D e e BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding dilation=dilation forward x TensorType conv x ast_rewriter = RewritingTracer B = BasicBlock res = B forward torch rand size graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c assertEqual solver check z sat x = z Const tensor_type y = z Const tensor_type solver add x == tensor_type tensor d d d d solver add y == tensor_type tensor b b b b assertEqual solver check z sat print solver model assert solver model e as_long == res assert solver model e as_long == res B = BasicBlock res = B forward torch rand size graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm new_transformed_c = transform_all_constraints traced solver = z Solver solver add new_transformed_c solver add x == tensor_type tensor d d d d solver add y == tensor_type tensor b b b b assertEqual solver check z sat assert solver model e as_long == res assert solver model e as_long == res test_reshape_dyn s s s s = z Ints s s s s BasicBlock torch nn Module forward x Dyn torch reshape x - ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s add x == tensor_type tensor D s assertEqual s check z sat s add z Or s == s == s == assertEqual s check z sat s add s == assertEqual s check z unsat test_reshape_annotated s s s s = z Ints s s s s s s s s = z Ints s s s s d d = D s s D s s BasicBlock torch nn Module forward x TensorType Dyn torch reshape x - ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s add x == tensor_type tensor d d assertEqual s check z unsat test_reshape_static_target s s s s = z Ints s s s s BasicBlock torch nn Module forward x TensorType Dyn torch reshape x ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced print transformed s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s add x == tensor_type tensor D s s check assert s model s as_long == s add s = assertEqual s check z unsat test_reshape_static_target s s s s = z Ints s s s s BasicBlock torch nn Module forward x Dyn torch reshape x ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm transformed = transform_all_constraints traced s = z Solver s add transformed assertEqual s check z sat x = z Const tensor_type s add x == tensor_type tensor D s s check assert s model s as_long == s add s = assertEqual s check z unsat test_conv D_maxpool d_flatten BasicBlock torch nn Module __init__ - None super __init__ conv = torch nn Conv d pool = torch nn MaxPool d conv = torch nn Conv d fc = torch nn Linear pool = torch nn AdaptiveAvgPool d forward x TensorType out = conv x out = pool out out = conv out out = pool out out = fc out out = pool out out = torch flatten out out B = BasicBlock res = B forward torch rand shape ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints solver check input = z Const tensor_type solver add input == tensor_type tensor D D D D solver check output = z Const tensor_type assert solver model output arg arg == res assert solver model output arg arg == res test_conv D_maxpool d_flatten_unsat BasicBlock torch nn Module __init__ - None super __init__ conv = torch nn Conv d pool = torch nn MaxPool d conv = torch nn Conv d fc = torch nn Linear pool = torch nn AdaptiveAvgPool d forward x TensorType out = conv x out = pool out out = conv out out = pool out out = fc out out = pool out out = torch flatten out out B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints solver check input = z Const tensor_type solver add input == tensor_type tensor D D D D assertEqual solver check z unsat test_conv D_maxpool d_flatten_dyn BasicBlock torch nn Module __init__ - None super __init__ conv = torch nn Conv d pool = torch nn MaxPool d conv = torch nn Conv d fc = torch nn Linear pool = torch nn AdaptiveAvgPool d forward x TensorType Dyn out = conv x out = pool out out = conv out out = pool out out = fc out out = pool out out = torch flatten out out B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints assertEqual solver check z sat test_type_check_flatten s s s s = z Ints s s s s M torch nn Module forward x TensorType torch flatten x start_dim= end_dim= module = M symbolic_traced torch fx GraphModule = symbolic_trace module constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z sat flatten = z Const tensor_type res = M forward torch rand size assert solver model flatten arg arg == res assert solver model flatten arg arg == res M torch nn Module forward x TensorType Dyn torch flatten x start_dim= end_dim= module = M symbolic_traced torch fx GraphModule = symbolic_trace module constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z sat x = z Const tensor_type y = z Const tensor_type solver add x == tensor_type tensor D D D s D assertEqual solver check z sat assert solver model y arg arg == M torch nn Module forward x TensorType Dyn torch flatten x module = M print module forward torch rand shape symbolic_traced torch fx GraphModule = symbolic_trace module constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z unsat ConstraintGeneration unittest TestCase test_add_reshape BasicBlock torch nn Module forward x Dyn y Dyn torch add torch reshape x torch reshape y ast_rewriter = RewritingTracer graph = ast_rewriter trace BasicBlock traced = GraphModule ast_rewriter root graph gm generator = ConstraintGenerator traced new_constraints counter = generator generate_constraints assert len new_constraints conjucts == test_conv_reshape_add BasicBlock torch nn Module __init__ in_planes out_planes kernel_size stride padding groups dilation super __init__ conv = torch nn Conv d in_channels=in_planes out_channels=out_planes kernel_size=kernel_size stride=stride padding=padding groups=groups bias=False dilation=dilation forward x Dyn y Dyn torch add conv torch reshape x y B = BasicBlock ast_rewriter = RewritingTracer graph = ast_rewriter trace B traced = GraphModule ast_rewriter root graph gm generator = ConstraintGenerator traced new_constraints counter = generator generate_constraints assert len new_constraints conjucts == TestInternalConstraints unittest TestCase test_precision c = BinConstraintT Dyn TVar x op_precision transformed _ = transform_constraint c assert transformed == T c = BinConstraintT TensorType Dyn TVar x op_precision transformed counter = transform_constraint c assert len transformed conjucts == test_matching c = BinConstraintT TVar x TensorType DVar DVar b DVar c DVar d op_matching transformed _ = transform_constraint c assert len transformed disjuncts == test_consistency c = BinConstraintT TVar x TensorType DVar DVar b op_consistency transformed count = transform_constraint c assert len transformed disjuncts == transformed count = transform_constraint transformed count assert len transformed disjuncts == test_apply_broadcasting c = ApplyBroadcasting TVar TVar TVar TVar transformed count = transform_apply_broadcasting c assert len transformed conjucts == skipIfNoTorchVision TestResNet unittest TestCase test_resnet _unsat traced = symbolic_trace models resnet n traced graph nodes n type = Dyn constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints input = z Const tensor_type input dimensions solver add input == tensor_type tensor D D D assertEqual solver check z unsat test_resnet traced = symbolic_trace models resnet n traced graph nodes n type = Dyn sample_input = torch randn res = models resnet forward sample_input size constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints assertEqual solver check z sat linear = z Const tensor_type input = z Const tensor_type solver add input == tensor_type tensor D D D D assertEqual solver check z sat assert solver model linear == tensor_type tensor D res D res test_resnet traced = symbolic_trace models resnet n traced graph nodes n type = Dyn constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints linear = z Const tensor_type input = z Const tensor_type batch = z Int b solver add input == tensor_type tensor D batch D D D solver add batch solver check assert solver model batch == solver model linear arg arg test_resnet traced = symbolic_trace models resnet n traced graph nodes n type = Dyn constraints = transform_all_constraints traced counter= solver = z Solver solver add constraints linear = z Const tensor_type input = z Const tensor_type batch d d = z Ints b d d solver add input == tensor_type tensor D batch D D D solver add linear == tensor_type tensor D d D d assertEqual solver check z sat solver add batch = d assertEqual solver check z unsat skipIfNoTorchVision TestAlexNet unittest TestCase test_alexnet alexnet = models alexnet symbolic_traced torch fx GraphModule = symbolic_trace alexnet n symbolic_traced graph nodes n type = Dyn print symbolic_traced res = alexnet forward torch rand size constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z sat input = z Const tensor_type conv = z Const tensor_type solver add input == tensor_type tensor D D D D assertEqual solver check z sat assert solver model conv == tensor_type tensor D D D D relu = z Const tensor_type assert solver model relu == tensor_type tensor D D D D maxpool = z Const tensor_type assert solver model maxpool == tensor_type tensor D D D D maxpool = z Const tensor_type assert solver model maxpool == tensor_type tensor D D D D flatten = z Const tensor_type assert solver model flatten == tensor_type tensor D D linear = z Const tensor_type assert solver model linear == tensor_type tensor D D linear = z Const tensor_type assert solver model linear == tensor_type tensor D res D res test_alexnet alexnet = models alexnet symbolic_traced torch fx GraphModule = symbolic_trace alexnet n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z unsat test_alexnet alexnet = models alexnet symbolic_traced torch fx GraphModule = symbolic_trace alexnet n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn Dyn constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z sat test_alexnet alexnet = models alexnet symbolic_traced torch fx GraphModule = symbolic_trace alexnet n symbolic_traced graph nodes n op == placeholder n type = TensorType Dyn Dyn constraints = transform_all_constraints symbolic_traced counter= solver = z Solver solver add constraints assertEqual solver check z unsat __name__ == __main__ unittest main