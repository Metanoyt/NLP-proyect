mypy allow-untyped-defs Functions synthesizing magic methods JIT-compiled dataclasses ast dataclasses inspect os collections abc Callable functools partial torch _jit_internal FAKE_FILENAME_PREFIX is_optional torch _sources ParsedDef SourceContext _get_fake_filename cls method_name os path join FAKE_FILENAME_PREFIX cls __name__ method_name compose_fn cls name str body_lines list str signature str - ParsedDef body = \n join f b b body_lines decl = f name signature \n body Parse function declaration try py_ast = ast parse decl except SyntaxError e This should only happen there s some unforeseeable change dataclasses module makes our synthesized code fail raise RuntimeError f TorchScript failed synthesize dataclass method name cls __name__ Please file bug report https github com pytorch pytorch issues e fake_filename = _get_fake_filename cls name Parse function ParsedDef py_ast ctx=SourceContext source=decl filename=fake_filename file_lineno= leading_whitespace_len= source=decl filename=fake_filename file_lineno= synthesize__init__ cls - ParsedDef Supporting default factories way people expect would sort require us allow compiling lambda functions which currently supported any field default_factory dataclasses MISSING field dataclasses fields cls raise NotImplementedError Default factory initializers supported TorchScript dataclasses Simply read off generated __init__ signature CPython s implementation It ll almost correct except InitVar annotations which we need handle specially signature = inspect signature cls __init__ Handle InitVars needed only works Python + when ` type ` attribute added InitVar see CPython commit here https github com python cpython commit ee ba e c c e c init_vars list str = params = name param signature parameters items ann = param annotation isinstance ann dataclasses InitVar The TorchScript interpreter can t handle InitVar annotations so we unwrap underlying type here init_vars append name params append param replace annotation=ann type type ignore attr-defined params append param signature = signature replace parameters=params body = Assign all attributes f field name = field name field dataclasses fields cls field init field name init_vars Call user s impl __post_init__ exists hasattr cls __post_init__ body append __post_init__ + join init_vars + compose_fn cls __init__ body pass signature=str signature This placeholder moment since TorchScript interpreter doesn t call __repr__ synthesize__repr__ cls - ParsedDef compose_fn cls __repr__ f cls __name__ + join f field name =self field name field dataclasses fields cls field repr + signature= - str synthesize__hash__ cls - ParsedDef compose_fn cls __hash__ This just placeholder prevent compilation failing won t even get called all right now because TorchScript interpreter doesn t call custom __hash__ implementations raise NotImplementedError __hash__ supported dataclasses TorchScript signature= - int Implementation __eq__ __ne__ synthesize_equality cls name str converse str - ParsedDef synthesize_comparison cls name allow_eq=True raise_on_none=False inner= f val converse val False synthesize_inequality cls name str op str allow_eq bool - ParsedDef synthesize_comparison cls name allow_eq raise_on_none=True inner= f val op val True f val op val False synthesize_comparison cls name str allow_eq bool raise_on_none bool inner list str - ParsedDef body = field dataclasses fields cls field compare continue body extend f val = field name f val = other field name body extend inner is_optional field type Type refinement optional fields we need avoid type errors interpreter val None val None + line line inner val None = val None f raise TypeError Cannot compare cls __name__ None raise_on_none False body append f allow_eq compose_fn cls name body signature=f other cls __name__ - bool DATACLASS_MAGIC_METHODS dict str Callable = __init__ synthesize__init__ __repr__ synthesize__repr__ __hash__ synthesize__hash__ __eq__ partial synthesize_equality name= __eq__ converse= = __ne__ partial synthesize_equality name= __ne__ converse= == __lt__ partial synthesize_inequality name= __lt__ op= allow_eq=False __le__ partial synthesize_inequality name= __le__ op= allow_eq=True __gt__ partial synthesize_inequality name= __gt__ op= allow_eq=False __ge__ partial synthesize_inequality name= __ge__ op= allow_eq=True