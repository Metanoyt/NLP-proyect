mypy allow-untyped-defs Unpickler restricted loading only state dicts Restrict constructing types list defined _get_allowed_globals Restrict BUILD operation ` Tensor ` ` Parameter ` ` OrderedDict ` types only Restrict APPEND APPENDS ` list ` In ` GLOBALS ` operation do do lookup name rather rely dictionary defined ` _get_allowed_globals ` method contains - torch types Storage dtypes Tensor ` torch Size ` - ` torch _utils _rebuild ` functions - ` torch nn Parameter ` - ` collections Counter ` - ` collections OrderedDict ` Additionally users can use allowlist adding classes they have deemed safe using ` _add_safe_globals ` ` torch serialization add_safe_globals ` ` _clear_safe_globals ` ` torch serialization clear_safe_globals ` ` _get_safe_globals ` ` torch serialization get_safe_globals ` Based https github com python cpython blob main Lib pickle py Expected useful loading PyTorch model weights For example data = urllib request urlopen https download pytorch org models resnet - ba pth read buf = io BytesIO data weights = torch load buf weights_only = True functools _functools warnings _codecs encode collections Counter OrderedDict collections abc Callable pickle APPEND APPENDS BINFLOAT BINGET BININT BININT BININT BINPERSID BINPUT BINUNICODE BUILD bytes_types decode_long EMPTY_DICT EMPTY_LIST EMPTY_SET EMPTY_TUPLE GLOBAL LONG LONG_BINGET LONG_BINPUT MARK NEWFALSE NEWOBJ NEWTRUE NONE PROTO REDUCE SETITEM SETITEMS SHORT_BINSTRING STOP TUPLE TUPLE TUPLE TUPLE UnpicklingError struct unpack sys maxsize typing Any Union torch torch _utils _sparse_tensors_to_validate IMPORT_MAPPING NAME_MAPPING modules list never allowed even user attempts allowlist functions classes them _blocklisted_modules = sys os posix nt _marked_safe_globals_set set Union Callable tuple Callable str = set _add_safe_globals safe_globals list Union Callable tuple Callable str global _marked_safe_globals_set _marked_safe_globals_set = _marked_safe_globals_set union set safe_globals _get_safe_globals - list Union Callable tuple Callable str global _marked_safe_globals_set list _marked_safe_globals_set _clear_safe_globals global _marked_safe_globals_set _marked_safe_globals_set = set _remove_safe_globals globals_to_remove list Union Callable tuple Callable str global _marked_safe_globals_set _marked_safe_globals_set = _marked_safe_globals_set - set globals_to_remove _safe_globals __init__ safe_globals list Union Callable tuple Callable str safe_globals = safe_globals __enter__ _add_safe_globals safe_globals __exit__ type value tb _remove_safe_globals safe_globals Separate _get_allowed_globals because lru_cache _get_allowed_globals For example user had script like torch load file_a torch serialization _add_safe_globals torch foo torch load file_b dynamic additions safe_globals would picked up _get_allowed_globals due lru_cache _get_user_allowed_globals rc dict str Any = f _marked_safe_globals_set isinstance f tuple len f = raise ValueError f Expected tuple length global str callable full path got tuple length len f type f str raise TypeError f Expected second item tuple str callable full path got type f f name = f rc name = f module name = f __module__ f __qualname__ rc f module name = f rc _tensor_rebuild_functions torch _utils _rebuild_parameter torch _utils _rebuild_parameter_with_state torch _utils _rebuild_qtensor torch _utils _rebuild_tensor torch _utils _rebuild_tensor_v torch _utils _rebuild_tensor_v torch _utils _rebuild_sparse_tensor torch _utils _rebuild_meta_tensor_no_storage torch _utils _rebuild_nested_tensor torch _utils _rebuild_wrapper_subclass Allowlisting allowlisting numpy functions default Reasoning we don t have control over numpy functions utility provided pytorch torch _utils _rebuild_device_tensor_from_numpy In we should no longer have dependency numpy above _rebuild_device_tensor_from_numpy function torch _utils _rebuild_device_tensor_from_cpu_tensor Unpickling machinery _functools lru_cache maxsize= _get_allowed_globals rc dict str Any = collections OrderedDict OrderedDict collections Counter Counter torch nn parameter Parameter torch nn Parameter torch serialization _get_layout torch serialization _get_layout torch Size torch Size torch Tensor torch Tensor torch device torch device _codecs encode encode bytes builtins bytearray bytearray bytearray builtins set set set builtins complex complex complex dtype t torch storage _dtype_to_storage_type_map keys rc str t = t t torch storage _new_dtypes rc str t = t t getattr torch f uint x x range rc str t = t t getattr torch f int x x range rc str t = t Tensor classes tt torch _tensor_classes rc f tt __module__ tt __name__ = tt Storage classes ts torch _storage_classes ts torch storage TypedStorage torch storage UntypedStorage Wrap legacy storage types dummy rc f ts __module__ ts __name__ = torch serialization StorageType ts __name__ rc f ts __module__ ts __name__ = ts Quantization specific qt torch per_tensor_affine torch per_tensor_symmetric torch per_channel_affine torch per_channel_symmetric torch per_channel_affine_float_qparams rc str qt = qt Rebuild functions f _tensor_rebuild_functions rc f torch _utils f __name__ = f Handles Tensor Subclasses Tensor s attributes NOTE It calls into above rebuild functions regular Tensor types rc torch _tensor _rebuild_from_type_v = torch _tensor _rebuild_from_type_v rc _read_global_instruction readline Callable - tuple str str module = readline - decode utf- name = readline - decode utf- Patch since torch save default protocol users will running code python module name NAME_MAPPING module name = NAME_MAPPING module name module IMPORT_MAPPING module = IMPORT_MAPPING module module name get_globals_in_pkl file - set str globals_in_checkpoint = set read = file read readline = file readline op_to_bytes_to_read = NEWOBJ REDUCE BUILD APPEND APPENDS SETITEM SETITEMS MARK TUPLE TUPLE TUPLE TUPLE NONE NEWFALSE NEWTRUE EMPTY_TUPLE EMPTY_LIST EMPTY_DICT EMPTY_SET BINPERSID BININT BININT BININT BINFLOAT BINGET LONG_BINGET BINPUT LONG_BINPUT while True key = read key raise EOFError assert isinstance key bytes_types key == GLOBAL module name = _read_global_instruction readline globals_in_checkpoint add f module name key op_to_bytes_to_read bytes_to_read = op_to_bytes_to_read key bytes_to_read read bytes_to_read ops where bytes read depends data key == BINUNICODE strlen = unpack I read strlen maxsize raise UnpicklingError String too long read strlen key SHORT_BINSTRING LONG strlen = read read strlen first last op key == PROTO read key == STOP globals_in_checkpoint raise UnpicklingError f Unsupported operand key Unpickler __init__ file encoding str = bytes encoding = encoding readline = file readline read = file read memo dict int Any = proto int = - load Read pickled object representation open file Return reconstituted object hierarchy specified file metastack = stack list Any = append = stack append read = read while True key = read key raise EOFError assert isinstance key bytes_types Risky operators key == GLOBAL module name = _read_global_instruction readline full_path = f module name module _blocklisted_modules raise UnpicklingError f Trying load unsupported GLOBAL full_path whose module module blocked full_path _get_allowed_globals append _get_allowed_globals full_path full_path _get_user_allowed_globals append _get_user_allowed_globals full_path full_path torch nested _internal nested_tensor NestedTensor torch nested _internal nested_tensor _rebuild_njt torch _dynamo decorators _DimRange raise UnpicklingError ` ` torch nested ` ` ` ` torch _dynamo ` ` must imported load nested jagged tensors NJTs full_path torch distributed device_mesh DeviceMesh torch distributed tensor _dtensor_spec DTensorSpec torch distributed tensor _dtensor_spec TensorMeta torch distributed tensor DTensor torch distributed tensor placement_types Partial torch distributed tensor placement_types Replicate torch distributed tensor placement_types Shard raise UnpicklingError ` ` torch distributed tensor ` ` must imported load DTensors builtins_name = builtins builtins_name full_path builtins_name == full_path len builtins_name full_path = full_path len builtins_name full_path = full_path len full_path full_path == builtins_name + full_path raise UnpicklingError f Unsupported global GLOBAL full_path allowed global default f Please use ` torch serialization add_safe_globals full_path ` f ` torch serialization safe_globals full_path ` context manager allowlist global you trust function key == NEWOBJ args = stack pop cls = stack pop cls torch nn Parameter append torch nn Parameter args cls _get_user_allowed_globals values cls _get_allowed_globals values result = cls __new__ cls args cls torch _tensor_classes sparse cls __module__ _sparse_tensors_to_validate append result append result raise UnpicklingError Can only create new object nn Parameter classes allowlisted f via ` add_safe_globals ` got cls key == REDUCE args = stack pop func = stack - func _get_allowed_globals values func _get_user_allowed_globals values error_msg = f Trying call reduce unrecognized function func hasattr func __self__ error_msg += f which belongs func __self__ raise UnpicklingError error_msg result = func args func torch _tensor_classes sparse func __module__ _sparse_tensors_to_validate append result stack - = result key == BUILD state = stack pop inst = stack - type inst torch Tensor Legacy unpickling pyrefly ignore not-iterable inst set_ state type inst torch nn Parameter inst __setstate__ state type inst OrderedDict inst __dict__ update state type inst _get_user_allowed_globals values type inst _get_allowed_globals values hasattr inst __setstate__ inst __setstate__ state mimics load_build pickle https github com python cpython blob f c fccd f f d c Lib pickle py#L -L slotstate = None isinstance state tuple len state == state slotstate = state state inst __dict__ update state slotstate k v slotstate items setattr inst k v raise UnpicklingError Can only build Tensor Parameter OrderedDict types allowlisted f via ` add_safe_globals ` got type inst Stack manipulation key == APPEND item = stack pop list_obj = stack - type list_obj list raise UnpicklingError f Can only append lists got type list_obj list_obj append item key == APPENDS items = pop_mark list_obj = stack - type list_obj list raise UnpicklingError f Can only extend lists got type list_obj list_obj extend items key == SETITEM v k = stack pop stack pop stack - k = v key == SETITEMS items = pop_mark i range len items stack - items i = items i + key == MARK metastack append stack stack = append = stack append key == TUPLE items = pop_mark append tuple items key == TUPLE stack - = stack - key == TUPLE stack - = stack - stack - key == TUPLE stack - = stack - stack - stack - Basic types construction key == NONE append None key == NEWFALSE append False key == NEWTRUE append True key == EMPTY_TUPLE append key == EMPTY_LIST append key == EMPTY_DICT append key == EMPTY_SET append set key == BININT append unpack i read key == BININT append read key == BININT append unpack H read key == BINFLOAT append unpack d read key == BINUNICODE strlen = unpack I read strlen maxsize raise UnpicklingError String too long strval = str read strlen utf- surrogatepass append strval key == SHORT_BINSTRING strlen = read strdata = read strlen encoding = bytes strdata = strdata decode encoding strict append strdata key == BINPERSID pid = stack pop Only allow persistent load storage type pid tuple type pid int raise UnpicklingError f persistent_load id must tuple int got type pid type pid tuple len pid torch serialization _maybe_decode_ascii pid = storage raise UnpicklingError f Only persistent_load storage allowed got pid append persistent_load pid key BINGET LONG_BINGET idx = read key == BINGET unpack I read append memo idx key BINPUT LONG_BINPUT i = read key == BINPUT unpack I read i raise ValueError negative argument memo i = stack - key == LONG n = read data = read n append decode_long data First last deserializer ops key == PROTO proto = read proto = warnings warn f Detected pickle protocol proto checkpoint which default pickle protocol used ` torch load ` The weights_only Unpickler might support all instructions implemented protocol please file issue adding support you encounter stacklevel= key == STOP rc = stack pop rc raise UnpicklingError f Unsupported operand key Return list items pushed stack after last MARK instruction pop_mark items = stack stack = metastack pop append = stack append items persistent_load pid raise UnpicklingError unsupported persistent id encountered load file encoding str = ASCII Unpickler file encoding=encoding load