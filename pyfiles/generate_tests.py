mypy ignore-errors datetime difflib functools inspect json os re tempfile threading unittest collections abc Callable Sequence typing Any Optional Union torch torch _dynamo torch utils _pytree pytree torch _dynamo utils clone_input torch _library custom_ops CustomOpDef torch _subclasses schema_check_mode SchemaCheckMode torch _utils_internal get_file_path_ torch overrides TorchFunctionMode torch testing _internal optests aot_autograd_check autograd_registration_check fake_check dontGenerateOpCheckTests reason str inner fun fun _torch_dont_generate_opcheck_tests = True fun inner is_abstract tensor torch Tensor - bool tensor is_meta True torch _subclasses fake_tensor is_fake tensor True False safe_schema_check op torch _ops OpOverload args tuple Any kwargs dict str Any copy_inputs bool = True rtol Optional float = None atol Optional float = None - Any copy_inputs args kwargs = deepcopy_tensors args kwargs pytree tree_any_only torch Tensor is_abstract args kwargs None SchemaCheckMode result = op args kwargs result safe_autograd_registration_check op torch _ops OpOverload args tuple Any kwargs dict str Any copy_inputs bool = True rtol Optional float = None atol Optional float = None - None pytree tree_any_only torch Tensor is_abstract args kwargs copy_inputs args kwargs = deepcopy_tensors args kwargs Don t perform autograd_registration_check none inputs require grad pytree tree_any_only torch Tensor lambda x x requires_grad args kwargs autograd_registration_check op args kwargs safe_fake_check op torch _ops OpOverload args tuple Any kwargs dict str Any copy_inputs bool = True rtol Optional float = None atol Optional float = None - None pytree tree_any_only torch Tensor is_abstract args kwargs None copy_inputs args kwargs = deepcopy_tensors args kwargs fake_check op args kwargs safe_aot_autograd_check op torch _ops OpOverload args tuple Any kwargs dict str Any dynamic bool copy_inputs bool = True rtol Optional float = None atol Optional float = None - Any NB copy_inputs does nothing aot_autograd_check always needs copy inputs pytree tree_any_only torch Tensor is_abstract args kwargs None func args kwargs args kwargs = pytree tree_map_only torch Tensor torch clone args kwargs op args kwargs aot_autograd_check runs func args kwargs multiple times assumes ` func ` does modify its inputs rtol atol assert_equals_fn = functools partial torch testing assert_close rtol=rtol atol=atol assert_equals_fn = torch testing assert_close aot_autograd_check func args kwargs dynamic check_gradients= auto assert_equals_fn=assert_equals_fn deepcopy_tensors inputs Any - Any pytree tree_map_only torch Tensor clone_input inputs Test util requirements - The test util must have signature op OpOverload args kwargs - The test util must NOT mutate args kwargs - The test utils list must prefixes each other For example having both test_schema test_schema_is_functional NOT OK - The order items dict matters opcheck we ll run them order ALL_TEST_UTILS = test_schema safe_schema_check test_autograd_registration safe_autograd_registration_check test_faketensor safe_fake_check test_aot_dispatch_static functools partial safe_aot_autograd_check dynamic=False test_aot_dispatch_dynamic functools partial safe_aot_autograd_check dynamic=True GDOC = https docs google com document d Pj HRZvdOq xpFpbEjUZp hBovhy Wnxw m lF edit DEFAULT_TEST_UTILS = test_schema test_autograd_registration test_faketensor test_aot_dispatch_dynamic DEPRECATED_DEFAULT_TEST_UTILS = DEFAULT_TEST_UTILS + test_aot_dispatch_static generate_opcheck_tests testcase Any namespaces list str failures_dict_path Optional str = None additional_decorators Optional dict str Callable = None test_utils list str = DEFAULT_TEST_UTILS - None Given existing TestCase use existing tests generate additional validation tests custom operators For all existing tests TestCase x all test utils we will generate one new test The new test runs TorchFunctionMode intercepts ` ` op args kwargs ` ` calls invokes ` ` test_util op args kwargs ` ` where ` ` op ` ` operator The test_util we support ALL_TEST_UTILS They - test_schema This runs SchemaCheckMode - test_autograd_registration This runs autograd_registration_check - test_faketensor This runs CrossRefFakeMode - test_aot_dispatch_static This runs aot_autograd_check which checks outputs gradients they computable same under eager-mode PyTorch using AOTAutograd - test_aot_dispatch_dynamic Same aot_dispatch_static runs AOTAutograd using dynamic shapes instead static shapes The generated test will have name ` ` test_util __ original_name ` ` For example there method named ` ` test_cumsum ` ` then we will generate ` ` test_schema__test_cumsum ` ` ` ` test_faketensor__test_cumsum ` ` etc For more details see https docs google com document d Pj HRZvdOq xpFpbEjUZp hBovhy Wnxw m lF edit Args testcase The testcase we will modify generate additional tests namespaces We will only intercept calls custom operators these namespaces failures_dict_path See ` ` validate_failures_dict_structure ` ` more details test_utils list test_utils generate Example test_schema test_faketensor additional_decorators None additional_decorators = test_methods = m m dir testcase m startswith test_ callable getattr testcase m failures_dict_path None The default failures_dict_path failures_dict json same directory test file prev_frame = inspect currentframe f_back filename = inspect getframeinfo prev_frame failures_dict_path = get_file_path_ os path dirname filename failures_dict json failures_dict = FailuresDict load failures_dict_path create_file=should_update_failures_dict validate_failures_dict_structure failures_dict test_utils testcase validate_failures_dict_formatting failures_dict_path construct_method attr prefix tester method = getattr testcase attr getattr method _torch_dont_generate_opcheck_tests False new_method_name = prefix + __ + attr functools wraps method new_method args kwargs OpCheckMode namespaces prefix tester failures_dict f testcase __name__ new_method_name failures_dict_path result = method args kwargs result pytestmark = new_method __dict__ get pytestmark pytest check we need simplify parametrize marks NB you need add mark your pytest ini opcheck_only_one = False mark pytestmark isinstance mark pytest Mark mark name == opcheck_only_one opcheck_only_one = True opcheck_only_one new_pytestmark = mark pytestmark isinstance mark pytest Mark mark name == parametrize argnames argvalues = mark args assert mark kwargs NYI Special case device we want run all devices argnames = device new_pytestmark append pytest mark parametrize argnames next iter argvalues continue new_pytestmark append mark new_method __dict__ pytestmark = new_pytestmark new_method_name additional_decorators dec additional_decorators new_method_name new_method = dec new_method hasattr testcase new_method_name raise RuntimeError f Tried autogenerate new_method_name testcase already f has method named new_method_name Please rename original f method TestCase setattr testcase new_method_name new_method test_utils = name ALL_TEST_UTILS name name test_utils attr test_methods prefix tester test_utils items construct_method attr prefix tester generate_tag_tests testcase failures_dict additional_decorators generate_tag_tests testcase failures_dict additional_decorators generate_test qualname definitely_not_pt _compliant xfailed_tests inner try op = torch _library utils lookup_op qualname except AttributeError e Operator importable test file raise unittest SkipTest f Can t operator qualname e op_marked_as_compliant = torch Tag pt _compliant_tag op tags op_marked_as_compliant definitely_not_pt _compliant raise AssertionError f op qualname tagged torch Tag pt _compliant_tag f failed some generated opcheck tests f xfailed_tests This may lead silent correctness issues f please fix inner qualname test_dict failures_dict data items xfailed_tests = test test status_dict test_dict items We re about delete following test after Ed s PR specialize C++ size calls test_aot_dispatch_static test status_dict status == xfail definitely_not_pt _compliant = len xfailed_tests generated = generate_test qualname definitely_not_pt _compliant xfailed_tests Could result collisions unlikely We ll raise we see one below mangled_qualname = qualname replace _ replace _ test_name = test_pt _compliant_tag_ + mangled_qualname You can skip test via additional_decorators argument generate_opcheck_tests test_name additional_decorators decorator additional_decorators test_name generated = decorator generated hasattr testcase test_name raise RuntimeError f Tried generate test named test_name exists f already This could because name collision where f we generated two tests same name where we f generated test same name existing test setattr testcase test_name generated TEST_OPTIONS = xfail skip xsuccess validate_failures_dict_formatting failures_dict_path str - None open failures_dict_path fp actual = fp read failures_dict = FailuresDict load failures_dict_path expected = failures_dict _save to_str=True actual == expected should_update_failures_dict failures_dict = FailuresDict load failures_dict_path failures_dict save expected = expected splitlines actual = actual splitlines diff = difflib unified_diff actual expected diff = join diff raise RuntimeError f \n diff \n\nExpected failures dict formatted f certain way Please see above diff you can correct f either manually re-running test f PYTORCH_OPCHECK_ACCEPT= validate_failures_dict_structure failure_dict FailuresDict test_utils list str testcase Any - None Validates failures dict The failure dict looks something like following It maps operator name qualname list autogenerated tests Each autogenerated test may have check operator operator called test dictionary specifies we should skip check we expect some check fail fbgemm split_lengths test_schema__test_split_lengths comment you can put whatever you want into comment section status xfail test_schema__test_split_lengths_empty comment status skip fbgemm gather_lengths test_schema__test_gather_lengths comment status skip failure_dict = failure_dict data test_to_option failure_dict values test_name test_dict test_to_option items set test_dict keys = set comment status raise RuntimeError failures_dict expected sub-dict have keys comment status test_option = test_dict status test_option TEST_OPTIONS raise RuntimeError f In failures_dict got status= test_option needs TEST_OPTIONS test_class actual_test_name = test_name split any actual_test_name startswith test test test_utils raise RuntimeError f In failures_dict test name test_name should begin one test_utils test test_utils actual_test_name startswith test continue base_test_name = actual_test_name len test + remove potential pytest parametrization suffix base_test_name = re sub r \ \ base_test_name testcase __name__ = test_class continue hasattr testcase base_test_name continue raise RuntimeError f In failures dict got test name test_name We parsed f running test test base_test_name f base_test_name does exist TestCase testcase __name__ f Maybe you need change test name should_update_failures_dict - bool key = PYTORCH_OPCHECK_ACCEPT key os environ os environ key == _is_inside_opcheck_mode = threading local _is_inside_opcheck_mode value = False is_inside_opcheck_mode _is_inside_opcheck_mode value OpCheckMode TorchFunctionMode For given test OpCheckMode intercepts calls operators runs test_util op args kwargs each intercepted op args kwargs __init__ namespaces list str test_util_name str test_util Callable failures_dict FailuresDict test_name str failures_dict_path str We will intercept calls ops these namespaces namespaces = namespaces The test utility function Its signature should op args kwargs - None Examples test utilities schema_check make_fx_check test_util = test_util test_util_name = test_util_name The name test running OpCheckMode test_name = test_name Maps qualname - test_name - skip xfail Tells us we should skip test assert there failure failures_dict = failures_dict Location failures dict Makes so error message better failures_dict_path = failures_dict_path OpCheckMode suppresses errors collects them here then raises them exit Maps qualname - List Exception func maybe args maybe kwargs seen_ops_to_errors = maybe_raise_errors_on_exit - None Check expected failures first qualname seen_ops_to_errors keys option = failures_dict get_status qualname test_name len seen_ops_to_errors qualname == should_update_failures_dict failures_dict set_status qualname test_name xsuccess comment= option == xfail raise OpCheckError f generate_opcheck_tests Unexpected success operator f qualname test test_name This may mean f you have fixed test failure Please rerun test f PYTORCH_OPCHECK_ACCEPT= automatically update test runner f manually remove f expected failure failure dict f failures_dict_path f For more details see f GDOC continue failed_ops = qualname seen_ops_to_errors keys option = failures_dict get_status qualname test_name option = xsuccess continue len seen_ops_to_errors qualname == continue failed_ops append qualname failed_ops should_update_failures_dict op failed_ops failures_dict set_status op test_name xfail Raise first error also report about all them make recording xfails easier ex op args kwargs = seen_ops_to_errors failed_ops repro_command = generate_repro test_util_name op args kwargs save_data=should_print_better_repro raise OpCheckError f Test generated ` generate_opcheck_tests ` test_name f failed operators failed_ops This usually means f operators implemented correctly may lead silently f incorrect behavior Set PYTORCH_OPCHECK_PRINT_BETTER_REPRO= standalone repro f please see f GDOC f more recommendations f To reproduce problem locally try run following \n repro_command ex __enter__ args kwargs prev_is_opcheck_mode = _is_inside_opcheck_mode value prev_dynamo_disable = os environ get TORCHDYNAMO_DISABLE _is_inside_opcheck_mode value = True os environ TORCHDYNAMO_DISABLE = super __enter__ args kwargs __exit__ args kwargs _is_inside_opcheck_mode value = prev_is_opcheck_mode os environ TORCHDYNAMO_DISABLE = prev_dynamo_disable try maybe_raise_errors_on_exit should_update_failures_dict failures_dict save finally result = super __exit__ args kwargs result run_test_util op args kwargs try test_util op args kwargs copy_inputs=False except torch _subclasses fake_tensor UnsupportedFakeTensorException We might get here input already FakeTensor we re torch compile block Just ignore these since we can t handle them reporting them failures too noisy pass __torch_function__ func types args= kwargs=None kwargs = kwargs kwargs Only intercept calls operators isinstance func torch _ops OpOverloadPacket torch _ops OpOverload func args kwargs torch jit is_tracing torch jit is_scripting torch _dynamo is_compiling func args kwargs Pre-existing code may use default overload If we see OpOverloadPacket we cannot resolve overload then we just throw ask user clarify Otherwise we attempt resolve overload isinstance func torch _ops OpOverloadPacket func = resolve_unique_overload_or_throw func qualname = func name ns = qualname split ns namespaces func args kwargs args_c kwargs_c = deepcopy_tensors args kwargs result = func args kwargs option = failures_dict get_status qualname test_name option == xsuccess option == xfail Suppress all errors during execution Raise them during __exit__ try qualname seen_ops_to_errors seen_ops_to_errors qualname = run_test_util func args_c kwargs_c except Exception ex should_print_better_repro seen_ops_to_errors qualname append ex func args kwargs seen_ops_to_errors qualname append ex func None None option == skip pass result should_print_better_repro - None If set tests generated ` generate_opcheck_tests ` will print repro command failure In order print repro command we need save some tensors disk These will saved under following directory tempfile gettempdir pytorch_opcheck_safe_to_delete Although temp folder will usually automatically get cleaned up so you ll need manually delete key = PYTORCH_OPCHECK_PRINT_BETTER_REPRO key os environ False value = os environ key value == value == opcheck op Union torch _ops OpOverload torch _ops OpOverloadPacket CustomOpDef args tuple Any kwargs Optional dict str Any = None test_utils Union str Sequence str = DEFAULT_TEST_UTILS raise_exception bool = True rtol Optional float = None atol Optional float = None - dict str str See torch library opcheck docstring rtol None ^ atol None raise ValueError opcheck op you specify one rtol atol you must specify both kwargs None kwargs = isinstance op CustomOpDef op = op _opoverload isinstance op torch _ops OpOverloadPacket op = resolve_unique_overload_or_throw op isinstance op torch _ops OpOverload raise ValueError f opcheck op op must instance torch _ops OpOverload f e g torch ops aten sin default got type op test_utils == ALL test_utils = tuple ALL_TEST_UTILS keys isinstance test_utils str test_utils = test_utils isinstance test_utils tuple list set test_utils issubset ALL_TEST_UTILS keys raise ValueError f opcheck op test_utils= test_utils expected test_utils f subset tuple ALL_TEST_UTILS keys results_dict = test_util test_utils tester = ALL_TEST_UTILS test_util try tester op args kwargs rtol=rtol atol=atol results_dict test_util = SUCCESS except Exception ex raise_exception raise OpCheckError f opcheck op test_util failed ex f scroll up stack trace ex results_dict test_util = ex results_dict OpCheckError Exception pass generate_repro test str op torch _ops OpOverload args tuple Any kwargs dict str Any save_data bool dry_run bool = False - str save_data now = datetime datetime now path = os path join tempfile gettempdir pytorch_opcheck_safe_to_delete unix_timestamp = datetime datetime timestamp now filepath = os path join path f repro_ unix_timestamp pt dry_run os makedirs path exist_ok=True torch save args kwargs filepath args_kwargs = f args kwargs = torch load filepath args_kwargs = If you rerun your test PYTORCH_OPCHECK_PRINT_BETTER_REPRO= \n we will fill them same args kwargs your test\n args = args operator\n kwargs = kwargs operator ns name = op _schema name split overload = op _overloadname repro_command = f =========================================================\n f BEGIN REPRO SCRIPT\n f =========================================================\n f torch\n f torch testing _internal optests opcheck\n f \n f Make sure you have loaded library contains op\n f via torch ops load_library \n f op = torch ops ns name overload \n f \n f args_kwargs \n f opcheck op args kwargs test_utils= test \n f =========================================================\n f END REPRO SCRIPT\n f =========================================================\n repro_command resolve_unique_overload_or_throw op torch _ops OpOverloadPacket - torch _ops OpOverload all_schemas = torch _C _jit_get_schemas_for_operator op _qualified_op_name len all_schemas = raise RuntimeError f opcheck can only test operators without overloads f Got following overloads op _qualified_op_name f schema overload_name schema all_schemas overload_name = all_schemas overload_name overload_name == op default getattr op overload_name DUMP_OPTIONS = indent sort_keys True FailuresDictData = dict str dict str dict str str VERSION = DESCRIPTION = f This dict containing failures tests autogenerated f generate_opcheck_tests f For more details please see GDOC FailuresDict __init__ path str data FailuresDictData path = path data = data staticmethod load path create_file=False - FailuresDict create_file os path exists path result = FailuresDict path FailuresDict save result open path fp contents = fp read contents strip == dct = _description DESCRIPTION data _version VERSION dct = json loads contents assert data dct assert _version dct dct _version == VERSION FailuresDict path dct data _save to_str=False - Optional str to_dump = _description DESCRIPTION data data _version VERSION json dumps doesn t end newline Let s add one because files should end newlines serialized = json dumps to_dump DUMP_OPTIONS + \n to_str serialized open path w fp fp write serialized None save - None _save get_status qualname str test_name str - str qualname data xsuccess dct = data qualname test_name dct xsuccess dct test_name status set_status qualname str test_name str status str comment Optional str = None qualname data data qualname = dct = data qualname test_name dct dct test_name = status None comment status == xsuccess The default status xsuccess del dct test_name dct test_name status = status comment None dct test_name comment = comment