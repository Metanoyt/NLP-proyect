Owner s module inductor unittest torch torch _dynamo torch _dynamo logging torch _dynamo test_case torch distributed dist torch fx fx some reason importing functional collectives after dynamo breaks collectives handling torch _C FileCheck torch _inductor test_case TestCase InductorTestCase torch _subclasses fake_tensor FakeTensorMode torch fx experimental proxy_tensor make_fx torch testing _internal common_distributed requires_accelerator_dist_backend torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests torch testing _internal inductor_utils HAS_GPU torch utils _ordered_set OrderedSet flake noqa B Owner s module inductor aten = torch ops aten torch testing _internal common_fsdp get_devtype device_type = str get_devtype torch torch _dynamo torch _dynamo logging torch _dynamo test_case some reason importing functional collectives after dynamo breaks collectives handling requires_accelerator_dist_backend nccl xccl build_collective_info graph hiding_annotations Build CollectiveInfo dict manual hiding annotations hiding_annotations dict mapping collective_start - hiding_compute_node torch _inductor fx_passes overlap_scheduling CollectiveInfo collective_info = Find all collective starts their corresponding waits start_to_wait = node graph nodes node op == call_function wait_tensor str node target wait_input = node args isinstance wait_input fx Node start_to_wait wait_input = node Build CollectiveInfo each collective start_node wait_node start_to_wait items hiding_node = hiding_annotations get start_node Estimate size time size_bytes = x tensor floats estimated_time_ms = Dummy time exposed_time_ms = hiding_node Hidden has hiding_node collective_info start_node = CollectiveInfo start_node=start_node wait_node=wait_node size_bytes=size_bytes estimated_time_ms=estimated_time_ms exposed_time_ms=exposed_time_ms hiding_node=hiding_node collective_info compute_ancestors graph Compute ancestor sets all nodes graph node_ancestors = node graph nodes ancestors = OrderedSet stack = list node all_input_nodes visited = set while stack current = stack pop current visited continue visited add current ancestors add current stack extend current all_input_nodes node_ancestors node = ancestors node_ancestors requires_accelerator_dist_backend unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch instantiate_parametrized_tests TestOverlapPreservingBucketing InductorTestCase Unit tests overlap-preserving bucketing pass classmethod setUpClass cls super setUpClass torch testing _internal distributed fake_pg FakeStore store = FakeStore dist init_process_group backend= fake rank= world_size= store=store cls device = cuda classmethod tearDownClass cls super tearDownClass dist destroy_process_group test_can_bucket_independent_collectives Test independent collectives separate hiding nodes CAN bucket Graph structure ag _start - ag _start - mm hides ag - mm hides ag - ag _wait - ag _wait func b group_name = group_size = Start both collectives ag = torch ops _c d_functional all_gather_into_tensor group_size group_name ag = torch ops _c d_functional all_gather_into_tensor b group_size group_name Independent compute can hide both mm = torch mm mm = torch mm b b Wait both ag _out = torch ops _c d_functional wait_tensor ag ag _out = torch ops _c d_functional wait_tensor ag ag _out sum + ag _out sum + mm sum + mm sum Use fake mode trace without executing FakeTensorMode = torch ones device=self device b = torch ones device=self device Trace make_fx traced = make_fx func b Find nodes using find_nodes ag ag = traced graph find_nodes op= call_function target=torch ops _c d_functional all_gather_into_tensor default mm mm = traced graph find_nodes op= call_function target=torch ops aten mm default Manually annotate hiding relationships hiding_annotations = ag mm mm hides ag ag mm mm hides ag Build collective info ancestors collective_info = build_collective_info traced graph hiding_annotations node_ancestors = compute_ancestors traced graph scheduled = OrderedSet traced graph nodes Run bucketing torch _inductor fx_passes overlap_preserving_bucketer OverlapPreservingBucketer bucketer = OverlapPreservingBucketer traced graph collective_info node_ancestors scheduled bucketer bucket_collectives Verify should have bucketed collective all_gather_into_tensor_out graph_str = str traced graph FileCheck check_count all_gather_into_tensor_out exactly=False run graph_str test_cant_bucket_nested_hiding_intervals Test nested hiding intervals prevent bucketing Graph structure ag _start - ag _start - mm hides ag - ag _wait - mm hides ag - ag _wait ag s hiding interval nested inside ag s hiding interval func b group_name = group_size = ag starts first ag = torch ops _c d_functional all_gather_into_tensor group_size group_name ag starts inside ag s interval ag = torch ops _c d_functional all_gather_into_tensor b group_size group_name mm hides ag mm = torch mm b b ag waits still inside ag s interval ag _out = torch ops _c d_functional wait_tensor ag mm uses ag s result hides ag mm = torch mm + ag _out ag waits last ag _out = torch ops _c d_functional wait_tensor ag ag _out sum + ag _out sum + mm sum + mm sum Use fake mode trace without executing FakeTensorMode = torch ones device=self device b = torch ones device=self device Trace make_fx traced = make_fx func b Find nodes using find_nodes ag ag = traced graph find_nodes op= call_function target=torch ops _c d_functional all_gather_into_tensor default mm_nodes = traced graph find_nodes op= call_function target=torch ops aten mm default mm first mm mm second based graph order mm = mm_nodes mm = mm_nodes Manually annotate hiding relationships hiding_annotations = ag mm mm hides ag ag mm mm hides ag Build collective info ancestors collective_info = build_collective_info traced graph hiding_annotations node_ancestors = compute_ancestors traced graph scheduled = OrderedSet traced graph nodes Run bucketing torch _inductor fx_passes overlap_preserving_bucketer OverlapPreservingBucketer bucketer = OverlapPreservingBucketer traced graph collective_info node_ancestors scheduled bucketer bucket_collectives Verify nested hiding intervals should prevent bucketing Should have separate all_gathers bucketed one graph_str = str traced graph FileCheck check_count all_gather_into_tensor exactly=False run graph_str parametrize final_mm_hidden True False test_cant_bucket_ag_with_rs_hiding_interval_between final_mm_hidden Test all_gathers can t bucket when reduce_scatter s hiding interval between them Graph structure ag _start - mm hides ag - ag _wait - rs_start - mm hides rs - rs_wait - final_mm_hidden ag _start - mm hides ag - ag _wait final_mm_hidden Bucketing ag ag would require moving one them which would break hiding relationships - Moving ag earlier would break ag s hiding mm - Moving ag later would break ag s hiding mm - The rs hiding interval creates obstacle between them otherwise we can bucket func b c group_name = dist distributed_c d _get_default_group group_name group_size = First all_gather ag = torch ops _c d_functional all_gather_into_tensor group_size group_name mm = torch mm hides ag ag _out = torch ops _c d_functional wait_tensor ag Reduce scatter between rs = torch ops _c d_functional reduce_scatter_tensor b sum group_size group_name mm = torch mm b b hides rs rs_out = torch ops _c d_functional wait_tensor rs Second all_gather ag = torch ops _c d_functional all_gather_into_tensor c group_size group_name mm = torch mm c c hides ag ag _out = torch ops _c d_functional wait_tensor ag ag _out sum + rs_out sum + ag _out sum mm mm mm Use fake mode trace without executing FakeTensorMode = torch ones device=self device b = torch ones device=self device c = torch ones device=self device Trace make_fx traced = make_fx func b c ag ag = traced graph find_nodes op= call_function target=torch ops _c d_functional all_gather_into_tensor default rs = traced graph find_nodes op= call_function target=torch ops _c d_functional reduce_scatter_tensor default mm mm mm = traced graph find_nodes op= call_function target=torch ops aten mm default Manually annotate hiding relationships hiding_annotations = ag mm mm hides ag rs mm mm hides rs ag mm final_mm_hidden hiding_annotations rs = mm Build collective info ancestors collective_info = build_collective_info traced graph hiding_annotations node_ancestors = compute_ancestors traced graph scheduled = OrderedSet traced graph nodes Run bucketing logic find buckets without applying them which would require process groups torch _inductor fx_passes overlap_preserving_bucketer OverlapPreservingBucketer bucketer = OverlapPreservingBucketer traced graph collective_info node_ancestors scheduled bucketer bucket_collectives graph_str = str traced graph check order mms preserved FileCheck check mm check mm_ check mm_ run graph_str final_mm_hidden Should NOT bucket - separate all_gathers Count all_gather node names works even when wrapped control_deps FileCheck check_count all_gather_into_tensor exactly=False run graph_str Should bucket - bucketed all_gather all_gather_into_tensor_out FileCheck check_count all_gather_into_tensor_out exactly=False run graph_str test_can_bucket_all_reduce Test all_reduce operations CAN bucket together Graph structure ar _start - ar _start - mm hides ar - mm hides ar - ar _wait - ar _wait func b group_name = Start both all_reduce operations ar = torch ops _c d_functional all_reduce sum group_name ar = torch ops _c d_functional all_reduce b sum group_name Independent compute can hide both mm = torch mm mm = torch mm b b Wait both ar _out = torch ops _c d_functional wait_tensor ar ar _out = torch ops _c d_functional wait_tensor ar ar _out sum + ar _out sum + mm sum + mm sum Use fake mode trace without executing FakeTensorMode = torch ones device=self device b = torch ones device=self device Trace make_fx traced = make_fx func b Find nodes ar ar = traced graph find_nodes op= call_function target=torch ops _c d_functional all_reduce default mm mm = traced graph find_nodes op= call_function target=torch ops aten mm default For all_reduce start_node == wait_node no separate wait hiding_annotations = ar mm ar mm Build collective info collective_info = build_collective_info traced graph hiding_annotations node_ancestors = compute_ancestors traced graph scheduled = OrderedSet traced graph nodes Run bucketing torch _inductor fx_passes overlap_preserving_bucketer OverlapPreservingBucketer bucketer = OverlapPreservingBucketer traced graph collective_info node_ancestors scheduled bucketer bucket_collectives Verify should have bucketed all_reduce After bucketing there should only one all_reduce node bucketed one graph_str = str traced graph FileCheck check_count all_reduce exactly=True check_count mm run graph_str test_can_bucket_multidtype_collectives Test all_gathers different dtypes CAN bucket together Graph structure ag _float - mm hides ag - ag _wait ag _bfloat - mm hides ag - ag _wait func b group_name = group_size = Start both collectives different dtypes ag = torch ops _c d_functional all_gather_into_tensor group_size group_name float ag = torch ops _c d_functional all_gather_into_tensor b group_size group_name bfloat Independent compute can hide both mm = torch mm mm = torch mm b float b float Wait both ag _out = torch ops _c d_functional wait_tensor ag ag _out = torch ops _c d_functional wait_tensor ag ag _out sum + ag _out sum + mm sum + mm sum Use fake mode trace without executing FakeTensorMode = torch ones device=self device dtype=torch float b = torch ones device=self device dtype=torch bfloat Trace make_fx traced = make_fx func b Find nodes using find_nodes ag ag = traced graph find_nodes op= call_function target=torch ops _c d_functional all_gather_into_tensor default mm_nodes = traced graph find_nodes op= call_function target=torch ops aten mm default mm = mm_nodes mm = mm_nodes Manually annotate hiding relationships hiding_annotations = ag mm mm hides ag ag mm mm hides ag Build collective info ancestors collective_info = build_collective_info traced graph hiding_annotations node_ancestors = compute_ancestors traced graph scheduled = OrderedSet traced graph nodes Run bucketing multidtype mode torch _inductor fx_passes overlap_preserving_bucketer OverlapPreservingBucketer bucketer = OverlapPreservingBucketer traced graph collective_info node_ancestors scheduled bucket_mode= custom_ops_multidtype bucketer bucket_collectives Verify should have bucketed collective all_gather_into_tensor_out even though dtypes different graph_str = str traced graph FileCheck check_count all_gather_into_tensor_out exactly=False run graph_str __name__ == __main__ run_tests