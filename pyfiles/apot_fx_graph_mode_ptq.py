torch torch nn nn torch ao quantization torchvision models quantization resnet resnet torch ao quantization experimental quantization_helper evaluate prepare_data_loaders validation dataset full ImageNet dataset data_path = ~ my_imagenet data_loader data_loader_test = prepare_data_loaders data_path criterion = nn CrossEntropyLoss float_model = resnet pretrained=True float_model eval deepcopy model since we need keep original model around copy model_to_quantize = copy deepcopy float_model model_to_quantize eval Prepare models Note temporary we ll expose these functions torch ao quantization after official releasee torch ao quantization quantize_fx prepare_qat_fx calibrate model data_loader model eval torch no_grad image _ data_loader model image torch ao quantization experimental qconfig uniform_qconfig_ bit apot_weights_qconfig_ bit apot_qconfig_ bit uniform_qconfig_ bit apot_weights_qconfig_ bit apot_qconfig_ bit Prepare full precision model full_precision_model = float_model top top = evaluate full_precision_model criterion data_loader_test print f Model Evaluation accuracy test dataset top avg f top avg f Prepare model PTQ specified qconfig torch nn Linear prepare_ptq_linear qconfig qconfig_dict = object_type torch nn Linear qconfig prepared_model = prepare_qat_fx copy deepcopy float_model qconfig_dict fuse modules insert observers calibrate prepared_model data_loader_test run calibration sample data prepared_model Prepare model uniform activation uniform weight b= k= prepared_model = prepare_ptq_linear uniform_qconfig_ bit quantized_model = convert_fx prepared_model convert calibrated model quantized model noqa F top top = evaluate quantized_model criterion data_loader_test print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare model uniform activation uniform weight b= k= prepared_model = prepare_ptq_linear uniform_qconfig_ bit quantized_model = convert_fx prepared_model convert calibrated model quantized model noqa F top top = evaluate quantized_model criterion data_loader_test noqa F print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare model uniform activation APoT weight b= k= prepared_model = prepare_ptq_linear apot_weights_qconfig_ bit top top = evaluate prepared_model criterion data_loader_test print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare model uniform activation APoT weight b= k= prepared_model = prepare_ptq_linear apot_weights_qconfig_ bit top top = evaluate prepared_model criterion data_loader_test print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare model APoT activation weight b= k= prepared_model = prepare_ptq_linear apot_qconfig_ bit top top = evaluate prepared_model criterion data_loader_test print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare model APoT activation weight b= k= prepared_model = prepare_ptq_linear apot_qconfig_ bit top top = evaluate prepared_model criterion data_loader_test print f Model Evaluation accuracy test dataset b= k= top avg f top avg f Prepare eager mode quantized model eager_quantized_model = resnet pretrained=True quantize=True eval top top = evaluate eager_quantized_model criterion data_loader_test print f Eager mode quantized model evaluation accuracy test dataset top avg f top avg f