mypy allow-untyped-defs collections inspect logging weakref collections abc Callable Iterable Sequence contextlib contextmanager typing Any Optional overload Union torch torch _C _ops Tensor torch types _dtype torch utils _exposed_in exposed_in autograd utils device_types_t = Optional Union str Sequence str log = logging getLogger __name__ overload custom_op name str fn None = None mutates_args Union str Iterable str device_types device_types_t = None schema Optional str = None tags Optional Sequence _C Tag = None - Callable Callable object CustomOpDef overload custom_op name str fn Callable object mutates_args Union str Iterable str device_types device_types_t = None schema Optional str = None tags Optional Sequence _C Tag = None - CustomOpDef exposed_in torch library custom_op name str fn Optional Callable = None mutates_args Union str Iterable str device_types device_types_t = None schema Optional str = None tags Optional Sequence _C Tag = None - Union Callable Callable object CustomOpDef CustomOpDef Wraps function into custom operator Reasons why you may want create custom op include - Wrapping third-party library custom kernel work PyTorch subsystems like Autograd - Preventing torch compile export FX tracing peeking inside your function This API used decorator around function please see examples The provided function must have type hints these needed interface PyTorch s various subsystems Args name str A name custom op looks like namespace name e g mylib my_linear The name used op s stable identifier PyTorch subsystems e g torch export FX graphs To avoid name collisions please use your project name namespace e g all custom ops pytorch fbgemm use fbgemm namespace mutates_args Iterable str unknown The names args function mutates This MUST accurate otherwise behavior undefined If unknown pessimistically assumes all inputs operator being mutated device_types None &#124; str &#124; Sequence str The device type s function valid If no device type provided then function used default implementation all device types Examples cpu cuda When registering device-specific implementation operator accepts no Tensors we require operator have device torch device argument schema None &#124; str A schema string operator If None recommended we ll infer schema operator its type annotations We recommend letting us infer schema unless you have specific reason Example Tensor x int y - Tensor Tensor note We recommend passing ` ` schema ` ` arg instead letting us infer type annotations It error-prone write your own schema You may wish provide your own schema our interpretation type annotation what you want For more info how write schema string see ` here https github com pytorch pytorch blob main aten src ATen native README md#func ` _ Examples torch torch Tensor torch library custom_op numpy np custom_op mylib numpy_sin mutates_args= numpy_sin x Tensor - Tensor x_np = x cpu numpy y_np = np sin x_np torch from_numpy y_np device=x device x = torch randn y = numpy_sin x assert torch allclose y x sin Example custom op only works one device type custom_op mylib numpy_sin_cpu mutates_args= device_types= cpu numpy_sin_cpu x Tensor - Tensor x_np = x numpy y_np = np sin x_np torch from_numpy y_np x = torch randn y = numpy_sin_cpu x assert torch allclose y x sin Example custom op mutates input custom_op mylib numpy_sin_inplace mutates_args= x device_types= cpu numpy_sin_inplace x Tensor - None x_np = x numpy np sin x_np out=x_np x = torch randn expected = x sin numpy_sin_inplace x assert torch allclose x expected Example factory function torch library custom_op mylib bar mutates_args= device_types= cpu bar device torch device - Tensor torch ones bar cpu inner fn Callable object - CustomOpDef torch schema None schema_str = torch library infer_schema fn mutates_args=mutates_args schema_str = schema namespace opname = name split result = CustomOpDef namespace opname schema_str fn tags schema None Check schema s alias annotations match those ` mutates_args ` expected = set arg result _opoverload _schema arguments arg alias_info None arg alias_info is_write expected add arg name expected = set mutates_args raise ValueError f Attempted create custom op ` mutates_args= mutates_args ` f ` schema= schema The schema suggests op mutates expected f which different what provided us ` mutates_args ` f Please make these consistent result register_kernel device_types fn result fn None inner inner fn CustomOpDef CustomOpDef wrapper around function turns into custom op It has various methods registering additional behavior custom op You should instantiate CustomOpDef directly instead use func ` torch library custom_op ` API __init__ namespace str name str schema str fn Callable tags Optional Sequence _C Tag = None - None Fields used interface PyTorch dispatcher _namespace = namespace _name = name _schema = schema _tags = tags tags None _init_fn = fn _backend_fns dict Union str None Callable = _abstract_fn Optional Callable = None _setup_context_fn Optional Callable = None _backward_fn Optional Callable = None _torch_dispatch_fns dict type Callable = _vmap_fn Optional Callable = None _autocast_cuda_dtype Optional _dtype = None _autocast_cpu_dtype Optional _dtype = None _lib = get_library_allowing_overwrite _namespace _name _register_to_dispatcher _tags _disabled_kernel set = set _used_triton_kernels list Any = list OPDEFS _qualname = property _qualname - str f _namespace _name __repr__ - str f CustomOpDef _qualname contextmanager set_kernel_enabled device_type str enabled bool = True Disable re-enable already registered kernel custom operator If kernel already disabled enabled no-op Note If kernel first disabled then registered disabled until enabled again Args device_type str The device type disable enable kernel disable bool Whether disable enable kernel Example inp = torch randn define custom op ` f ` custom_op mylib f mutates_args= f x Tensor - Tensor torch zeros print f inp tensor default kernel f register_kernel cpu _ x torch ones print f inp tensor CPU kernel temporarily disable CPU kernel f set_kernel_enabled cpu enabled = False print f inp tensor CPU kernel disabled action = enable enabled disable originally_disabled = device_type _disabled_kernel device_type _backend_fns log warning Attempted s kernel s no kernel registered device type action device_type enabled originally_disabled log warning Attempted disable kernel s already disabled device_type _disabled_kernel add device_type enable kernel originally_disabled log warning Attempted enable kernel s already enabled device_type _disabled_kernel remove device_type try yield finally restore original state originally_disabled _disabled_kernel add device_type _disabled_kernel discard device_type register_kernel device_types device_types_t fn Optional Callable = None - Callable Register implementation device type operator Some valid device_types cpu cuda xla mps ipu xpu This API may used decorator Args fn Callable The function register implementation given device types device_types str &#124; Sequence str The device device_types register impl Examples xdoctest +REQUIRES env TORCH_DOCTEST_CUDA torch torch Tensor torch library custom_op numpy np Create custom op works cpu custom_op mylib numpy_sin mutates_args= device_types= cpu numpy_sin x Tensor - Tensor x_np = x numpy y_np = np sin x_np torch from_numpy y_np Add implementations cuda device numpy_sin register_kernel cuda _ x x_np = x cpu numpy y_np = np sin x_np torch from_numpy y_np device=x device x_cpu = torch randn x_cuda = x_cpu cuda assert torch allclose numpy_sin x_cpu x_cpu sin assert torch allclose numpy_sin x_cuda x_cuda sin inner fn device_types None isinstance device_types str dtypes list Union str None = device_types dtypes = list device_types device_type dtypes device_type _backend_fns backend_impl args kwargs result = _backend_fns device_type args kwargs get_module fn = _backend_fns device_type inspect getmodule fn schema = _opoverload _schema schema _is_view_op utils _c_check_aliasing_constraint _name args kwargs result get_module result device_type None _lib impl _name backend_impl CompositeExplicitAutograd _lib impl _name backend_impl _C _dispatch_key_for_device device_type Wrap function choose between default implementation device-specific implementation depending kernel disabled torch _disable_dynamo wrapped_fn args kwargs device_type _disabled_kernel _init_fn args kwargs fn args kwargs _backend_fns device_type = wrapped_fn fn device_types None utils has_tensor_arg _opoverload _schema device_arg_index = utils get_device_arg_index _opoverload _schema device_arg_index None raise ValueError Functions without tensor inputs required have ` device torch device ` argument _register_backend_select_dispatcher device_arg_index See NOTE Supporting decorator non-decorator usage fn None inner inner fn register_fake fn Callable - Callable r Register FakeTensor implementation custom op This necessary get operator work efficiently torch compile The Fake impl sometimes also known meta kernel abstract impl specifies behavior operator Tensors carry no data Given some input Tensors certain properties sizes strides storage_offset device specifies what properties output Tensors Please see func ` torch library register_fake ` more details Args fn Callable The function register FakeTensor implementation Examples torch numpy np torch Tensor Example operator without data-dependent output shape torch library custom_op mylib linear mutates_args= linear x Tensor weight Tensor bias Tensor - Tensor x weight t + bias linear register_fake _ x weight bias assert x dim == assert weight dim == assert bias dim == assert x shape == weight shape assert weight shape == bias shape assert x device == weight device x new_empty x size weight size x = torch randn weight = torch randn bias = torch randn xdoctest +SKIP Requires Python = out = torch compile linear fullgraph=True x weight bias xdoctest +SKIP Requires Python = assert torch allclose out torch nn functional linear x weight bias Example operator data-dependent output shape torch library custom_op mylib nonzero mutates_args= nonzero x Tensor - Tensor x_np = x cpu numpy res = np stack np nonzero x_np axis= torch tensor res device=x device nonzero register_fake _ x Number nonzero-elements data-dependent Since we cannot peek data abstract impl we use ctx object construct new symint represents data-dependent size ctx = torch library get_ctx nnz = ctx new_dynamic_size shape = nnz x dim result = x new_empty shape dtype=torch int result x = torch tensor xdoctest +SKIP Requires Python = out = torch compile nonzero fullgraph=True x xdoctest +SKIP Requires Python = assert torch allclose out x nonzero _abstract_fn = fn fn register_torch_dispatch torch_dispatch_class Any fn Optional Callable = None - Callable r Registers torch_dispatch rule given operator ` ` torch_dispatch_class ` ` This allows open registration specify behavior between operator ` ` torch_dispatch_class ` ` without needing modify ` ` torch_dispatch_class ` ` operator directly Please see func ` torch library register_torch_dispatch ` examples more details register fn torch_dispatch_class _torch_dispatch_fns inner args kwargs _torch_dispatch_fns torch_dispatch_class args kwargs _lib _register_torch_dispatch_rule _name torch_dispatch_class inner _torch_dispatch_fns torch_dispatch_class = fn fn fn None register register fn register_autograd backward Callable setup_context Optional Callable = None - None r Register backward formula custom op In order operator work autograd you need register backward formula You must tell us how compute gradients during backward pass providing us backward function If you need any values forward compute gradients you can use ` setup_context ` save values backward ` ` backward_fn ` ` runs during backward pass It accepts ` ` ctx grads ` ` - ` ` grads ` ` one more gradients The number gradients matches number outputs operator The ` ` ctx ` ` object ` same ctx object context_method_mixins ` _ used ` torch autograd Function ` The semantics ` ` backward_fn ` ` same meth ` torch autograd Function backward ` ` ` setup_context ctx inputs output ` ` runs during forward pass Please save quantities needed backward onto ` ` ctx ` ` object via either meth ` torch autograd function FunctionCtx save_for_backward ` assigning them attributes ` ` ctx ` ` If your custom op has kwarg-only arguments we expect signature ` ` setup_context ` ` ` ` setup_context ctx inputs keyword_only_inputs output ` ` Both ` ` setup_context_fn ` ` ` ` backward_fn ` ` must traceable That they may directly access meth ` torch Tensor data_ptr ` they must depend mutate global state If you need non-traceable backward you can make separate custom_op you call inside ` ` backward_fn ` ` If you need different autograd behavior different devices then we recommend creating two different custom operators one each device needs different behavior switching between them runtime Examples torch numpy np torch Tensor torch library custom_op mylib numpy_sin mutates_args= numpy_sin x Tensor - Tensor x_np = x cpu numpy y_np = np sin x_np torch from_numpy y_np device=x device setup_context ctx inputs output - Tensor x = inputs ctx save_for_backward x backward ctx grad x = ctx saved_tensors grad x cos numpy_sin register_autograd backward setup_context=setup_context x = torch randn requires_grad=True y = numpy_sin x grad_x = torch autograd grad y x torch ones_like y assert torch allclose grad_x x cos Example keyword-only arg torch library custom_op mylib numpy_mul mutates_args= numpy_mul x Tensor val float - Tensor x_np = x cpu numpy y_np = x_np val torch from_numpy y_np device=x device setup_context ctx inputs keyword_only_inputs output - Tensor ctx val = keyword_only_inputs val backward ctx grad grad ctx val numpy_mul register_autograd backward setup_context=setup_context x = torch randn requires_grad=True y = numpy_mul x val= grad_x = torch autograd grad y x torch ones_like y assert torch allclose grad_x torch full_like x schema = _opoverload _schema utils is_functional_schema schema allow_valid_view=True raise RuntimeError f Cannot register autograd formula non-functional operator f schema schema Please create f functional operator register autograd formula _backward_fn = backward _setup_context_fn = setup_context _register_to_dispatcher tags Sequence _C Tag - None lib = _lib schema_str = _name + _schema cpp_schema = _C parse_schema schema_str utils has_kwarg_only_tensors cpp_schema If you want support progression - supporting kwarg-only Tensors non-differentiable - supporting kwarg-only Tensors regardless differentiability raise NotImplementedError f custom_op kwarg-only Tensor args Please make your f tensors kwarg-only Got schema_str lib define schema_str tags= _C Tag pt _compliant_tag tags _opoverload = utils lookup_op _qualname fake_impl args kwargs _abstract_fn None utils can_generate_trivial_fake_impl _opoverload None raise RuntimeError f There no fake impl registered f This necessary torch compile export fx tracing work f Please use ` _init_fn __name__ register_fake ` add f fake impl _abstract_fn args kwargs lib _register_fake _name fake_impl _stacklevel= autograd_impl = autograd make_autograd_impl _opoverload lib impl _name autograd_impl Autograd with_keyset=True schema = _opoverload _schema schema _is_view_op schema is_mutable lib m register_ad_inplace_or_view_fallback _name type ignore union-attr schema is_mutable mutated_idxs mutated_keys = utils mutated_args_kwargs schema original_kernel = torch _C _dispatch_get_computed_kernel_for_dispatch_key f lib ns _name ADInplaceOrView adinplaceorview_impl keyset args kwargs Handle mutated idx user gave us explicitly idx mutated_idxs increment_version args idx key mutated_keys increment_version kwargs key Handle view + mutation schema original_kernel call_boxed keyset args kwargs lib impl _name adinplaceorview_impl ADInplaceOrView with_keyset=True _register_backend_select_dispatcher device_arg_index int Switch device argument select correct backend dispatch backend_select keyset args kwargs device = args device_arg_index type device _backend_fns raise RuntimeError f _name does have kernel registered device Please use register_kernel do so dispatch_key = _C _dispatch_key_for_device device dispatch_key = getattr _C DispatchKey dispatch_key _opoverload redispatch _C DispatchKeySet dispatch_key args kwargs _lib impl _name backend_select BackendSelect with_keyset=True __call__ args kwargs _opoverload args kwargs register_vmap func Optional Callable = None r Register vmap implementation support func ` torch vmap ` custom op This API may used decorator In order operator work func ` torch vmap ` you may need register vmap implementation following signature ` ` vmap_func info in_dims Tuple Optional int args kwargs ` ` where ` ` args ` ` ` ` kwargs ` ` arguments kwargs ` ` op ` ` It specifies how do we compute batched version ` ` op ` ` given inputs additional dimension specified ` ` in_dims ` ` For each arg ` ` args ` ` ` ` in_dims ` ` has corresponding ` ` Optional int ` ` It ` ` None ` ` arg Tensor arg being vmapped over otherwise integer specifying what dimension Tensor being vmapped over ` ` info ` ` collection additional metadata may helpful ` ` info batch_size ` ` specifies size dimension being vmapped over while ` ` info randomness ` ` ` ` randomness ` ` option passed func ` torch vmap ` The function ` ` func ` ` tuple ` ` output out_dims ` ` Similar ` ` in_dims ` ` ` ` out_dims ` ` should same structure ` ` output ` ` contain one ` ` out_dim ` ` per output specifies output has vmapped dimension what index Examples torch numpy np torch Tensor typing Tuple to_numpy tensor tensor cpu numpy lib = torch library Library mylib FRAGMENT torch library custom_op mylib numpy_cube mutates_args= numpy_cube x Tensor - Tuple Tensor Tensor x_np = to_numpy x dx = torch tensor x_np device=x device torch tensor x_np device=x device dx numpy_cube_vmap info in_dims x result = numpy_cube x result in_dims in_dims numpy_cube register_vmap numpy_cube_vmap x = torch randn torch vmap numpy_cube x torch library custom_op mylib numpy_mul mutates_args= numpy_mul x Tensor y Tensor - Tensor torch tensor to_numpy x to_numpy y device=x device numpy_mul register_vmap numpy_mul_vmap info in_dims x y x_bdim y_bdim = in_dims x = x movedim x_bdim - x_bdim None x unsqueeze - y = y movedim y_bdim - y_bdim None y unsqueeze - result = x y result = result movedim - result x = torch randn y = torch randn torch vmap numpy_mul x y torch _functorch autograd_function custom_function_call_vmap_helper torch _functorch pyfunctorch retrieve_current_functorch_interpreter register func need_register = _vmap_fn None _vmap_fn = func need_register wrapped_func keyset args kwargs interpreter = retrieve_current_functorch_interpreter custom_function_call_vmap_helper interpreter _vmap_fn _opoverload args kwargs _lib impl _name wrapped_func FuncTorchBatched with_keyset=True func None register register func register_autocast device_type str cast_inputs _dtype r Register autocast dispatch rule custom op Valid ` device_type ` include cpu cuda Args op str &#124; OpOverload The operator register autocast dispatch rule device_type str Device type use cuda cpu The type same ` type ` attribute ` torch device ` Thus you may obtain device type tensor using ` Tensor device type ` cast_inputs ` torch dtype ` When custom op runs autocast-enabled region casts incoming floating-point Tensors target dtype non-floating-point Tensors affected then executes custom op autocast disabled lib Optional Library If provided lifetime registration Examples xdoctest +REQUIRES env TORCH_DOCTEST_CUDA torch torch Tensor torch library custom_op Create custom op works cuda torch library custom_op mylib my_sin mutates_args= my_sin x Tensor - Tensor torch sin x Register autocast dispatch rule cuda device torch library register_autocast mylib my_sin cuda torch float x = torch randn dtype=torch float device= cuda torch autocast cuda dtype=torch float y = torch ops mylib my_sin x assert y dtype == torch float isinstance device_type str raise ValueError f Expected ` device_type ` type ` str ` got ` type device_type ` device_type cpu cuda raise ValueError f Unknown device type device_type need_register_cuda = _autocast_cuda_dtype None need_register_cpu = _autocast_cpu_dtype None device_type == cuda _autocast_cuda_dtype = cast_inputs _autocast_cpu_dtype = cast_inputs kernel _ args kwargs assert len kwargs == Custom ops do support kwargs yet autocast_keyset = torch _C DispatchKeySet torch _C DispatchKey AutocastCPU &#124; torch _C DispatchKeySet torch _C DispatchKey AutocastCUDA torch _C _ExcludeDispatchKeyGuard autocast_keyset _opoverload _cast args device_type cast_inputs need_register_cuda _autocast_cuda_dtype _lib impl _name kernel AutocastCUDA with_keyset=True need_register_cpu _autocast_cpu_dtype _lib impl _name kernel AutocastCPU with_keyset=True kernel TODO Merge function torch amp autocast_mode _cast refactor into utility function once custom ops support arbitrary input types _cast value device_type str dtype _dtype isinstance value torch Tensor is_eligible = value is_floating_point value device type == device_type value dtype torch float value dtype is_eligible value isinstance value str bytes value isinstance value collections abc Iterable iterable = _cast v device_type dtype v value isinstance value list tuple type value iterable iterable value increment_version val Any - None isinstance val Tensor torch autograd graph increment_version val isinstance val tuple list v val isinstance v Tensor torch autograd graph increment_version v NOTE Supporting decorator non-decorator usage Some APIs may both used decorator decorator For example fn x x sin Usage decorator numpy_sin register_kernel cuda fn Usage decorator numpy_sin register_kernel cuda fn x x sin The way we support ` register_kernel ` accepts optional ` fn ` If ` fn ` provided Usage then we know user using decorator If ` fn ` provided Usage then ` register_kernel ` needs decorator OPDEF_TO_LIB dict str torch library Library = OPDEFS weakref WeakValueDictionary = weakref WeakValueDictionary get_library_allowing_overwrite namespace str name str - torch library Library qualname = f namespace name qualname OPDEF_TO_LIB OPDEF_TO_LIB qualname _destroy del OPDEF_TO_LIB qualname lib = torch library Library namespace FRAGMENT noqa TOR OPDEF_TO_LIB qualname = lib lib _maybe_get_opdef op Union CustomOpDef _ops OpOverload str - Optional CustomOpDef isinstance op CustomOpDef op isinstance op _ops OpOverload op = op _name assert isinstance op str op OPDEFS OPDEFS op None