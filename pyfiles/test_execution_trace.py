Owner s oncall profiler json os tempfile unittest typing Any numpy np torch torch nn nn torch _dynamo torchdynamo torch autograd _record_function_with_args_enter _record_function_with_args_exit torch profiler ExecutionTraceObserver kineto_available profile record_function supported_activities torch testing _internal common_cuda TEST_CUDA torch testing _internal common_device_type instantiate_device_type_tests skipCPUIf torch testing _internal common_utils IS_WINDOWS run_tests skipIfHpu skipIfTorchDynamo TEST_HPU TEST_XPU TestCase torch utils _triton has_triton tqdm shutdown properly will leave monitor thread alive This causes issue multithreading test because we check all events test their tids The events correspond these lingering threads all have TID uint _t - which invalid The work around turning off monitoring thread when tqdm loaded Since these unit tests safe turn off monitor thread try tqdm tqdm tqdm monitor_interval = except ImportError pass Json = dict str Any TestExecutionTrace TestCase payload device use_device=False u = torch randn requires_grad=True record_function ## TEST ## inf_val = float inf neg_inf_val = float -inf nan_val = float nan rf_handle = _record_function_with_args_enter ## TEST ## False u u u u hello u inf_val neg_inf_val nan_val x = torch randn requires_grad=True use_device x = x device y = torch randn requires_grad=True use_device y = y device z = x + y + x y + x y z backward z gelu = nn GELU m = torch randn _ = gelu m use_device z = z cpu _record_function_with_args_exit rf_handle get_execution_trace_root output_file_name - Json gzip nodes = gzip open output_file_name output_file_name endswith gz open output_file_name f et_graph = json load f assert nodes et_graph nodes = et_graph nodes nodes get_execution_trace_rf_ids nodes list Json - list int Returns sorted list rf_id record function ids execution trace get_rf_id node attrs = node attrs attrs name == rf_id value None rf_ids_ = get_rf_id n n nodes n name = pytorch &#124; profiler &#124; execution_trace &#124; process n name = pytorch &#124; profiler &#124; execution_trace &#124; thread sorted rf_id rf_id rf_ids_ rf_id None get_kineto_rf_ids events list Json - list int Returns sorted list Record function IDs CPU operators user annotations ops_and_annotations = e e events e get cat cpu_op user_annotation sorted e get args get Record function id - e ops_and_annotations unittest skipIf kineto_available Kineto required skipIfHpu skipIfTorchDynamo profiler gets ignored dynamo activated test_execution_trace_with_kineto device trace_called_num = trace_handler p nonlocal trace_called_num trace_called_num += use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity XPU supported_activities torch profiler ProfilerActivity HPU supported_activities Create temp file save execution trace kineto data fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close kt = tempfile NamedTemporaryFile mode= w+t suffix= kineto json delete=False kt close profile activities=supported_activities schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= on_trace_ready=trace_handler execution_trace_observer= ExecutionTraceObserver register_callback fp name p idx range record_function f ## LOOP idx ## payload device use_device=use_device p step assertEqual fp name p execution_trace_observer get_output_file_path Uncomment debugging print Output kineto = kt name print Output ET = fp name p export_chrome_trace kt name assertEqual trace_called_num nodes = get_execution_trace_root fp name loop_count = found_root_node = False n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name found_root_node = True n name startswith ## LOOP loop_count += assertTrue found_root_node Since profiler trace active iterations assertEqual loop_count Compare collected Execution Trace Kineto Trace terms record func ID rf_id External IDs both these should match same trace window open kt name f kineto = json load f events = kineto traceEvents Look up rf_ids both Execution Kineto trace two lists rf_ids_et = get_execution_trace_rf_ids nodes rf_ids_kineto = get_kineto_rf_ids events assertCountEqual rf_ids_et rf_ids_kineto assertListEqual rf_ids_et rf_ids_kineto msg=f ET kineto rf_id should exactly match\n f rf_ids_et = rf_ids_et \n f rf_ids_kineto = rf_ids_kineto \n unittest skipIf kineto_available Kineto required skipIfHpu skipIfTorchDynamo profiler gets ignored dynamo activated test_execution_trace_env_enabled_with_kineto device os os environ ENABLE_PYTORCH_EXECUTION_TRACE = os environ ENABLE_PYTORCH_EXECUTION_TRACE_EXTRAS = trace_called_num = trace_handler p nonlocal trace_called_num trace_called_num += use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity XPU supported_activities torch profiler ProfilerActivity HPU supported_activities Create temp file save kineto data kt = tempfile NamedTemporaryFile mode= w+t suffix= kineto json delete=False kt close profile activities=supported_activities schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= on_trace_ready=trace_handler p idx range record_function f ## LOOP idx ## payload device use_device=use_device p step Uncomment debugging print Output kineto = kt name print Output ET = fp name p export_chrome_trace kt name assertEqual trace_called_num et_path = p execution_trace_observer get_output_file_path et_res_path = p execution_trace_observer get_resources_dir et_path path should set up due our env variables assertTrue et_path None et_res_path should empty directory assertTrue os path isdir et_res_path assertEqual len os listdir et_res_path Compare collected Execution Trace Kineto Trace terms record func nodes = get_execution_trace_root et_path loop_count = found_root_node = False n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name found_root_node = True n name startswith ## LOOP loop_count += assertTrue found_root_node Since profiler trace active iterations assertEqual loop_count Compare collected Execution Trace Kineto Trace terms record func ID rf_id External IDs both these should match same trace window open kt name f kineto = json load f events = kineto traceEvents Look up rf_ids both Execution Kineto trace two lists rf_ids_et = get_execution_trace_rf_ids nodes rf_ids_kineto = get_kineto_rf_ids events assertCountEqual rf_ids_et rf_ids_kineto assertListEqual rf_ids_et rf_ids_kineto msg=f ET kineto rf_id should exactly match\n f rf_ids_et = rf_ids_et \n f rf_ids_kineto = rf_ids_kineto \n test_execution_trace_alone device use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity HPU supported_activities torch profiler ProfilerActivity XPU supported_activities Create temp file save execution trace data Use gzip file test compression codepath fp = tempfile NamedTemporaryFile w suffix= et json gz delete=False fp close expected_loop_events = et = ExecutionTraceObserver register_callback fp name et start idx range expected_loop_events += record_function f ## LOOP idx ## payload device use_device=use_device et stop assert fp name == et get_output_file_path et unregister_callback nodes = get_execution_trace_root fp name loop_count = Expected tensor object tuple size th form tensor_id storage_id offset numel itemsize device_str tensor_tuple_size = found_root_node = False n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name found_root_node = True n name startswith ## LOOP loop_count += Check tensor tuple representation size correct n name == ## TEST ## assert len n inputs values == tensor_tuple_size assert found_root_node assert loop_count == expected_loop_events test_execution_trace_env_disabled device os os environ ENABLE_PYTORCH_EXECUTION_TRACE = os environ ENABLE_PYTORCH_EXECUTION_TRACE_EXTRAS = use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity HPU supported_activities torch profiler ProfilerActivity XPU supported_activities profile activities=torch profiler supported_activities record_shapes=True schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= p idx range record_function f ## LOOP idx ## payload device use_device=use_device p step assertTrue p execution_trace_observer None unittest skipIf IS_WINDOWS torch compile does support WINDOWS unittest skipIf has_triton TEST_CUDA TEST_XPU need triton device CUDA XPU availability run skipCPUIf True skip CPU device testing profiling triton test_execution_trace_with_pt device torchdynamo optimize inductor fn b c x = torch nn functional linear b x = x + c x cos b c = torch randn requires_grad=True device _ range inputs = b c torch _inductor config patch compile_threads= fn inputs Create temp file save execution trace data fp = tempfile NamedTemporaryFile w+t suffix= _et json delete=False fp close et = ExecutionTraceObserver et register_callback fp name et set_extra_resource_collection True profile activities=torch profiler supported_activities record_shapes=True schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= execution_trace_observer=et p idx range record_function f ## LOOP idx ## fn inputs p step nodes = get_execution_trace_root fp name found_captured_triton_kernel_node = False found_call_compiled_fx_graph = False n nodes assert name n triton_ n name attr n attrs attr name == kernel_file attr value = found_captured_triton_kernel_node = True assert len n inputs values assert len n outputs values == Call CompiledFxGraph n name found_call_compiled_fx_graph = True assert found_captured_triton_kernel_node assert found_call_compiled_fx_graph unittest skipIf IS_WINDOWS torch compile does support WINDOWS unittest skipIf has_triton TEST_CUDA TEST_XPU need triton device CUDA XPU availability run skipCPUIf True skip CPU device testing profiling triton test_execution_trace_env_enabled_with_pt device clean up local cache triton kernel torch _inductor codecache PyCodeCache PyCodeCache cache_clear purge=True os os environ ENABLE_PYTORCH_EXECUTION_TRACE = os environ ENABLE_PYTORCH_EXECUTION_TRACE_EXTRAS = torchdynamo optimize inductor fn b c x = torch nn functional linear b x = x + c x cos b c = torch randn requires_grad=True device _ range inputs = b c torch _inductor config patch compile_threads= fx_graph_cache=False fx_graph_remote_cache=False fn inputs profile activities=torch profiler supported_activities record_shapes=True schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= p idx range record_function f ## LOOP idx ## fn inputs p step et_path = p execution_trace_observer get_output_file_path et_res_path = p execution_trace_observer get_resources_dir et_path path should set up due our env variables assertTrue et_path None et_res_path should empty directory assertTrue os path isdir et_res_path assertEqual len os listdir et_res_path nodes = get_execution_trace_root et_path found_captured_triton_kernel_node = False n nodes assert name n triton_ n name attr n attrs attr name == kernel_file attr value = found_captured_triton_kernel_node = True assert len n inputs values assert len n outputs values == assert found_captured_triton_kernel_node unittest skipIf IS_WINDOWS torch compile does support WINDOWS unittest skipIf has_triton TEST_CUDA TEST_XPU need triton device CUDA XPU availability run skipCPUIf True skip CPU device testing profiling triton test_triton_fx_graph_with_et device clean up local cache triton kernel torch _inductor codecache PyCodeCache PyCodeCache cache_clear purge=True os torchdynamo optimize inductor fn b c x = torch nn functional linear b x = x sin x = x t + c x cos b c = torch randn requires_grad=False torch device cuda _ range inputs = b c torch _inductor config patch compile_threads= fx_graph_cache=False fx_graph_remote_cache=False fn inputs fp = tempfile NamedTemporaryFile w+t suffix= fx_graph_et json delete=False fp close et = ExecutionTraceObserver et register_callback fp name et set_extra_resource_collection True profile activities=torch profiler supported_activities record_shapes=True schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= execution_trace_observer=et p idx range record_function f ## LOOP idx ## fn inputs p step et_path = p execution_trace_observer get_output_file_path et_res_path = p execution_trace_observer get_resources_dir et_path path should set up due our env variables assertTrue et_path None et_res_path should empty directory assertTrue os path isdir et_res_path filename os listdir et_res_path file_path = os path join et_res_path filename os path isfile file_path open file_path file fx_graph_found = False fx_graph = line file line = line strip There two files directory one source code triton kernel other source code FX graph Only FX graph file contains string Graph fragment line startswith Graph fragment fx_graph_found = True fx_graph_found line startswith fx_graph append line fx_graph_found = False len fx_graph assert fx_graph == mm Tensor f cuda = PlaceHolder target=mm assert fx_graph == arg _ Tensor f cuda = PlaceHolder target=arg _ assert fx_graph == sin Tensor f cuda num_users= = call_function target=torch ops aten sin default args = mm kwargs = noqa B assert fx_graph == permute_ Tensor f cuda num_users= = call_function target=torch ops aten permute default args = sin kwargs = noqa B assert fx_graph == mul Tensor f cuda num_users= = call_function target=torch ops aten mul Tensor args = arg _ kwargs = noqa B assert fx_graph == add Tensor f cuda num_users= = call_function target=torch ops aten add Tensor args = permute_ mul kwargs = noqa B assert fx_graph == cos Tensor f cuda num_users= = call_function target=torch ops aten cos default args = add kwargs = noqa B assert fx_graph == cos test_execution_trace_start_stop device use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity XPU supported_activities torch profiler ProfilerActivity HPU supported_activities Create temp file save execution trace data fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close expected_loop_events = et = ExecutionTraceObserver register_callback fp name idx range idx == et start idx == et stop idx == et start idx == et stop et _execution_trace_running expected_loop_events += record_function f ## LOOP idx ## payload device use_device=use_device assert fp name == et get_output_file_path et unregister_callback nodes = get_execution_trace_root fp name loop_count = found_root_node = False n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name found_root_node = True n name startswith ## LOOP loop_count += assert found_root_node assert loop_count == expected_loop_events test_execution_trace_repeat_in_loop device use_device = torch profiler ProfilerActivity CUDA torch profiler ProfilerActivity XPU supported_activities torch profiler ProfilerActivity HPU supported_activities iter_list = expected_loop_events = len iter_list output_files = idx range idx iter_list Create temp file save execution trace data fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close output_files append fp name et = ExecutionTraceObserver register_callback fp name et start record_function f ## LOOP idx ## payload device use_device=use_device idx iter_list et stop et unregister_callback event_count = et_file output_files nodes = get_execution_trace_root et_file found_root_node = False n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name assert n id == found_root_node = True n name startswith ## LOOP event_count += assert found_root_node assert event_count == expected_loop_events test_execution_trace_no_capture fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close et = ExecutionTraceObserver register_callback fp name assert fp name == et get_output_file_path et unregister_callback nodes = get_execution_trace_root fp name n nodes assert name n pytorch &#124; profiler &#124; execution_trace &#124; process n name found_root_node = True assert found_root_node skipIfTorchDynamo https github com pytorch pytorch issues test_execution_trace_nested_tensor fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close observer = ExecutionTraceObserver register_callback fp name fn nt nt sin cos torch profiler profile execution_trace_observer=observer i range values = torch rand + i + i offsets = torch tensor + i nt = torch nested nested_tensor_from_jagged values offsets fn nt nodes = get_execution_trace_root fp name found_cos = False n nodes assert name n cos n name found_cos = True assert found_cos unittest skipIf TEST_CUDA need CUDA device availability run test_execution_trace_record_integral_tensor_range fp = tempfile NamedTemporaryFile w+t suffix= et json delete=False fp close os environ ENABLE_PYTORCH_EXECUTION_TRACE_SAVE_INTEGRAL_TENSOR_RANGE = t = torch tensor cuda t = torch tensor cuda profile activities=supported_activities schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= record_shapes=True execution_trace_observer= ExecutionTraceObserver register_callback fp name p torch gather t t p step nodes = get_execution_trace_root fp name n nodes assert name n aten gather n name attr n attrs attr name == tensor_range assert attr value == unittest skipIf TEST_CUDA need CUDA device availability run test_execution_trace_record_integral_tensor_data tempfile TemporaryDirectory temp_dir fp_name = os path join temp_dir test et json os environ ENABLE_PYTORCH_EXECUTION_TRACE_SAVE_INTEGRAL_TENSOR_DATA = aten gather et = ExecutionTraceObserver et register_callback fp_name et set_extra_resource_collection True t = torch tensor cuda t = torch tensor cuda profile activities=supported_activities schedule=torch profiler schedule skip_first= wait= warmup= active= repeat= record_shapes=True execution_trace_observer=et p torch gather t t p step resourceDir = fp_name replace json _resources assert os path exists resourceDir + nid_ _tid_ dat assert os path exists resourceDir + nid_ _tid_ dat t = np fromfile resourceDir + nid_ _tid_ dat dtype=np int t = np fromfile resourceDir + nid_ _tid_ dat dtype=np int assert t == np array all assert t == np array all devices = cpu cuda TEST_XPU devices append xpu TEST_HPU devices append hpu instantiate_device_type_tests TestExecutionTrace globals allow_xpu= xpu devices only_for=devices __name__ == __main__ run_tests