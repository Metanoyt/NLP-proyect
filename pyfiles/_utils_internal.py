mypy allow-untyped-defs functools logging os sys tempfile typing_extensions collections abc Callable typing Any Optional TypeVar typing_extensions ParamSpec torch torch _strobelight compile_time_profiler StrobelightCompileTimeProfiler _T = TypeVar _T _P = ParamSpec _P log = logging getLogger __name__ os environ get TORCH_COMPILE_STROBELIGHT False shutil shutil which strobeclient log info TORCH_COMPILE_STROBELIGHT true seems like you FB machine log info Strobelight profiler enabled via environment variable StrobelightCompileTimeProfiler enable arbitrary-looking assortment functionality provided here have central place overridable behavior The motivating use FB build environment where source file replaced equivalent os path basename os path dirname __file__ == shared torch_parent = os path dirname os path dirname os path dirname __file__ torch_parent = os path dirname os path dirname __file__ get_file_path path_components str - str os path join torch_parent path_components get_file_path_ path_components str - str os path join path_components get_writable_path path str - str os access path os W_OK path tempfile mkdtemp suffix=os path basename path prepare_multiprocessing_environment path str - None pass resolve_library_path path str - str os path realpath path throw_abstract_impl_not_imported_error opname module context module sys modules raise NotImplementedError f opname We could find fake impl operator raise NotImplementedError f opname We could find fake impl operator f The operator specified you may need module f Python module load fake impl context NB This treats skip kwarg specially compile_time_strobelight_meta phase_name str - Callable Callable _P _T Callable _P _T compile_time_strobelight_meta_inner function Callable _P _T - Callable _P _T functools wraps function wrapper_function args _P args kwargs _P kwargs - _T skip kwargs isinstance pyrefly ignore unsupported-operation skip = kwargs skip int kwargs skip = skip + This needed we have here avoid having profile_compile_time stack traces when profiling enabled StrobelightCompileTimeProfiler enabled function args kwargs StrobelightCompileTimeProfiler profile_compile_time function phase_name args kwargs wrapper_function compile_time_strobelight_meta_inner Meta only see https www internalfb com intern wiki ML_Workflow_Observability User_Guides Adding_instrumentation_to_your_code This will cause event get logged Scuba via signposts API You can view samples API https fburl com scuba workflow_signpost zh wmpqs we log subsystem torch category name you provide here Each arguments translate into Scuba column We re still figuring out local conventions PyTorch category should something like dynamo inductor name should specific string describing what kind event happened Killswitch https www internalfb com intern justknobs name=pytorch Fsignpost#event signpost_event category str name str parameters dict str Any log info s s r category name parameters add_mlhub_insight category str insight str insight_description str pass log_compilation_event metrics log info s metrics upload_graph graph pass set_pytorch_distributed_envs_from_justknobs pass log_export_usage kwargs pass log_draft_export_usage kwargs pass log_trace_structured_event args kwargs - None pass log_cache_bypass args kwargs - None pass log_torchscript_usage api str kwargs _ = api check_if_torch_exportable False export_training_ir_rollout_check - bool True full_aoti_runtime_assert - bool True log_torch_jit_trace_exportability api str type_of_export str export_outcome str result str _ _ _ _ = api type_of_export export_outcome result DISABLE_JUSTKNOBS = True justknobs_check name str default bool = True - bool This function can used killswitch functionality FB prod where you can toggle value False JK without having do code push In OSS we always have everything turned all time because downstream users can simply choose update PyTorch If more fine-grained enable disable needed we could potentially have map we lookup name toggle behavior But point s all tied source code OSS since there s no live server query This bare minimum functionality I needed do some killswitches We have more detailed plan https docs google com document d Ukerh _ SeGh J-tGtecpHBPwGlkQ pddkKb PU edit In particular some circumstances may necessary read knob once process start then use consistently rest process Future functionality will codify these patterns into better high level API WARNING Do NOT call function module time JK fork safe you will break anyone who forks process then hits JK again default justknobs_getval_int name str - int Read warning justknobs_check is_fb_unit_test - bool False functools cache max_clock_rate unit MHz torch version hip triton testing nvsmi nvsmi clocks max sm Manually set max-clock speeds ROCm until equivalent nvmsi functionality triton testing via pyamdsmi enablement Required test_snode_runtime unit tests gcn_arch = str torch cuda get_device_properties gcnArchName split gfx gcn_arch gfx gcn_arch gfx gcn_arch gfx gcn_arch gfx gcn_arch gfx gcn_arch gfx gcn_arch gfx gcn_arch TODO placeholder get actual value get_mast_job_name_version - Optional tuple str int None TEST_MASTER_ADDR = TEST_MASTER_PORT = USE_GLOBAL_DEPS controls whether __init__ py tries load libtorch_global_deps see Note Global dependencies USE_GLOBAL_DEPS = True USE_RTLD_GLOBAL_WITH_LIBTORCH controls whether __init__ py tries load _C so RTLD_GLOBAL during call dlopen USE_RTLD_GLOBAL_WITH_LIBTORCH = False If op defined C++ extended Python using torch library register_fake returns we require there m set_python_module mylib ops call C++ associates C++ op python module REQUIRES_SET_PYTHON_MODULE = False maybe_upload_prof_stats_to_manifold profile_path str - Optional str print Uploading profile stats fb-only otherwise no-op None log_chromium_event_internal event dict str Any stack list str logger_uuid str start_time_ns int None record_chromium_event_internal event dict str Any None profiler_allow_cudagraph_cupti_lazy_reinit_cuda True deprecated When we deprecate function might still use we make internal adding leading underscore This decorator used private function creates public alias without leading underscore has deprecation warning This tells users THIS FUNCTION IS DEPRECATED please use something without breaking them however they still really really want use deprecated function without warning they can do so using internal function name decorator func Callable _P _T - Callable _P _T Validate naming convention - single leading underscore dunder func __name__ startswith _ raise ValueError deprecate must decorate function whose name starts single leading underscore e g _foo api should considered internal deprecation public_name = func __name__ drop exactly one leading underscore module = sys modules func __module__ Don t clobber existing symbol accidentally hasattr module public_name raise RuntimeError f Cannot create alias public_name - symbol already exists module __name__ \ Please rename consult pytorch developer what do warning_msg = f func __name__ DEPRECATED please consider using alternative API s public deprecated alias alias = typing_extensions deprecated pyrefly ignore bad-argument-type warning_msg category=UserWarning stacklevel= func alias __name__ = public_name Adjust qualname nested inside another function func __qualname__ alias __qualname__ = func __qualname__ rsplit + + public_name alias __qualname__ = public_name setattr module public_name alias func decorator get_default_numa_options When using elastic agent no numa options provided we will use these default For external use cases we None i e no numa binding If you would like use torch s automatic numa binding capabilities you should provide NumaOptions your launch config directly use numa binding option available torchrun Must None NumaOptions specifying avoid circular None log_triton_builds fail Optional str pass find_compile_subproc_binary - Optional str Allows overriding binary used subprocesses None