mypy allow-untyped-defs typing cast torch torch distributed dist torch _C _distributed_c d ReduceOp torch distributed _shard sharded_tensor ShardedTensor torch distributed _shard sharding_spec ChunkShardingSpec torch distributed _shard sharding_spec api custom_sharding_spec_op torch distributed nn functional all_gather reduce_scatter _common _all_gather_base_input _handle_col_wise_sharding_base _handle_max_norm_col_wise _handle_row_wise_mask custom_sharding_spec_op ChunkShardingSpec torch nn functional embedding_bag sharded_embedding_bag types args kwargs pg Handles ` ` __torch_function__ ` ` dispatch ` ` torch nn functional embedding_bag ` ` This method computes sharded embedding bag aggregation has following limitations Supports only sharding ` ` weight ` ` Supports only ` ` ChunkShardingSpec ` ` Supports only single local shard per rank Supports all specs except scale_grad_by_freq sparse etc Based dimension weight sharded there two algorithms ROWWISE SHARDING ================ For row-wise sharding weight sharded dimension The overall algorithm can best explained example Let s assume dims input x W x W sharded across GPUs creating shard x The algorithm follows First input all gathered all ranks since SPMD input actually sharded across all ranks The inputs then become x tensor each rank For example given input tensor rank Then every rank we will have tensor If input itself already replicated no all-gather will done Next we mask ID which stored rank For example rank we store ID We only keep ID inside set numbers The rest them will masked extra row The masked matrix will used embedding look up like tensor If ` ` max_norm ` ` specified extra row guarantees mask ID will affect behavior weigh re-norm The example above only happens one rank each rank does very similar thing For Mean mode we need divide either column size D interval length defined offset excluding row specified ` ` padding_idx ` ` We also need mask unexisting row neg Inf so negative value does gets wiped out Max mode COLWISE SHARDING ================ For col-wise sharding weight sharded dimension The overall algorithm can best explained example Let s assume dims input x W x W sharded across GPUs creating shards x shard x The algorithm follows First input broadcasted all ranks since SPMD we actually do all_gather all inputs resulting x inputs each rank Next we perform local embedding bag operation under given mode apply each input x local shard x x last This results x x last matrices each rank We transpose aggregation result Next we concatenate these matrices perform all all share appropriate x x matrices each rank Now each rank receives x matrix which basically size result we need If placements order any appropriate rearrangement columns done x matrix finally we transpose output again If max_norm specified we manually sum up norm renorm Because renorm must place we need override local_shard mimic behavior Validate input params _validate_embedding_bag_param args kwargs input = args weight = args offsets = kwargs get offsets per_sample_weights = kwargs get per_sample_weights mode = kwargs get mode max_norm = kwargs get max_norm norm_type = kwargs get norm_type include_last_offset = kwargs get include_last_offset padding_idx = kwargs get padding_idx local_shard = weight local_tensor contiguous sharding_dim = weight _sharding_spec dim world_size = dist get_world_size pg rank = dist get_rank pg include_last_offset offsets = offsets - sharding_dim == output local_shard = _handle_col_wise_sharding input world_size weight local_shard offsets per_sample_weights mode max_norm norm_type padding_idx pg weight local_shards tensor = local_shard output sharding_dim == _handle_row_wise_sharding input world_size weight local_shard offsets per_sample_weights mode max_norm norm_type padding_idx rank pg raise RuntimeError f nn EmbeddingBag weight sharded dim sharding_dim supported _validate_embedding_bag_param args kwargs Validate input params sharded embeddingBag op Args input list ID used lookup aggregation weight sharded weight tensor kwargs same normal EmbeddingBag Return None input = args weight = args offsets = kwargs get offsets per_sample_weights = kwargs get per_sample_weights mode = kwargs get mode max_norm = kwargs get max_norm scale_grad_by_freq = kwargs get scale_grad_by_freq sparse = kwargs get sparse include_last_offset = kwargs get include_last_offset Validate types isinstance input torch Tensor raise TypeError input need torch Tensor offsets None isinstance offsets torch Tensor raise TypeError offsets need torch Tensor per_sample_weights None isinstance per_sample_weights torch Tensor raise TypeError per_sample_weights need torch Tensor isinstance weight ShardedTensor raise TypeError weight needs ShardedTensor len input size raise ValueError Input more than dims supported weight_size = weight size len weight_size = raise ValueError Weight needs have exactly dims int torch min input item raise ValueError Index out range Input d d int torch min input item weight_size int torch max input item = weight_size raise ValueError Index out range Input d d int torch max input item weight_size offsets None len input size = raise ValueError Input dimension needs exactly dim len input size == offsets None raise ValueError offsets required D input per_sample_weights None per_sample_weights size = input size raise ValueError f per_sample_weights size per_sample_weights size equal input size input size mode None mode = mean mode sum mean max raise ValueError f mode mode supported scale_grad_by_freq raise RuntimeError nn Embedding weight sharded flag scale_grad_by_freq supported sparse raise RuntimeError nn Embedding weight sharded flag sparse supported include_last_offset offsets None raise ValueError offsets required flag include_last_offset include_last_offset cast list int offsets - = input size raise ValueError offsets need have input size end when flag include_last_offset max_norm max_norm = raise ValueError max_norm must larger than zero isinstance weight _sharding_spec ChunkShardingSpec raise ValueError Only ChunkShardingSpec supported ShardedTensor ops len weight local_shards = raise ValueError Only one local shard supported _handle_col_wise_sharding input world_size weight local_shard offsets per_sample_weights mode max_norm norm_type padding_idx pg Entry-point function handle logic col-wise sharding weight embeddingBag Detailed explanations logic can found comment sharded_embedding_bag Args input list ID used lookup aggregation world_size number ranks weight sharded weight tensor local_shard col-wise shared local weight used lookup offsets list start positions each bag D input per_sample_weights weights weighted sum mode mode aggregation method each bag max_norm If given each embedding vector norm larger than max_norm renormalized have norm max_norm Note will modify weight in-place norm_type The p p-norm compute max_norm option padding_idx If specified entries padding_idx do contribute gradient therefore embedding vector padding_idx updated during training i e remains fixed pad Note embedding vector padding_idx excluded reduction pg process group Return output final result lookup aggregation local_shard col-wise shared local weight used lookup If max_norm will renormed weight allgather special input embedding bag first gathered_inputs gathered_per_sample_weights gathered_offsets = _all_gather_embedding_bag_input input per_sample_weights offsets pg max_norm None max_norm changes weight in-place local_shard = _handle_max_norm_col_wise max_norm norm_type local_shard input world_size gathered_inputs pg output = _handle_col_wise_sharding_base torch nn functional embedding_bag input world_size weight local_shard pg gathered_inputs mode=mode gathered_per_sample_weights=gathered_per_sample_weights gathered_offsets=gathered_offsets padding_idx=padding_idx output local_shard _handle_row_wise_sharding input world_size weight local_shard offsets per_sample_weights mode max_norm norm_type padding_idx rank pg Entry-point function handle logic row-wise sharding weight embeddingBag Detailed explanations logic can found comment sharded_embedding_bag Args input list ID used lookup aggregation world_size number ranks weight sharded weight tensor local_shard row-wise shared local weight used lookup offsets list start positions each bag D input per_sample_weights weights weighted sum mode mode aggregation method each bag max_norm If given each embedding vector norm larger than max_norm renormalized have norm max_norm Note will modify weight in-place norm_type The p p-norm compute max_norm option padding_idx If specified entries padding_idx do contribute gradient therefore embedding vector padding_idx updated during training i e remains fixed pad Note embedding vector padding_idx excluded reduction rank cuda process pg process group Returns gathered_output final result lookup aggregation input dim per_sample_weights None allgather inputs first non Replicated Tensor gather_inp = _all_gather_base_input input pg gathered_inputs gathered_per_sample_weights gathered_offsets = _all_gather_embedding_bag_input input per_sample_weights offsets pg cat_dim = input dim = - gather_inp = torch cat gathered_inputs dim=cat_dim per_sample_weights None per_sample_weights = torch cat gathered_per_sample_weights dim=cat_dim offset_add = input dim input size offsets None offsets_list = torch cat gathered_offsets i + offset_add i i range pg size dim=cat_dim Mask input according sharding spec lookup_input padding_local padding_row = _handle_row_wise_mask gather_inp padding_idx weight world_size rank mode == max padding_row = -float Inf When input large tensor value weight changed This walk-around now GH issue max_norm None torch nn functional embedding_bag torch unique lookup_input - local_shard offsets=torch tensor device=local_shard device dtype=torch long mode=mode per_sample_weights=None max_norm=max_norm norm_type=norm_type padding_idx=padding_local max_norm = None result = torch nn functional embedding_bag lookup_input torch cat local_shard padding_row offsets=offsets_list offsets None offsets type ignore possibly-undefined mode=mode mode = mean sum per_sample_weights=per_sample_weights max_norm=max_norm norm_type=norm_type padding_idx=padding_local op = ReduceOp SUM mode = max ReduceOp MAX TODO Make result PartialTensor move logic below there local_shards = result chunk pg size result = reduce_scatter torch empty_like local_shards list local_shards op=op group=pg For Mean we cannot do division until very end because sum means equal mean sum Divisor different mode == mean input dim padding_idx = padding_idx padding_idx None - split_sizes = torch sum torch ne input padding_idx dim=- dtype=local_shard dtype split_sizes = torch cat pyrefly ignore unsupported-operation offsets offsets size - offsets - pyrefly ignore unsupported-operation input size - offsets - unsqueeze dim=- torch div result split_sizes unsqueeze Return appropriate local result result _all_gather_embedding_bag_input input per_sample_weights offsets pg In case we need gather input all other parameters embeddingBag ops we need stack all input together perform ` ` all_gather ` ` collective communication just once Note since offsets does share same size input always smaller than input we resize during communication Args input tensor applied op per_sample_weights weights weighted sum mode offsets when input D offsets determines starting index position each bag sequence input pg process group Returns gathered_inputs list input tensor gathered each rank gathered_per_sample_weights list per_sample_weights each rank gathered_offsets list offsets each rank input_to_gather = input per_sample_weights None input_to_gather append per_sample_weights offsets None input_to_gather append offsets clone resize_ input size gathered_inputs = all_gather torch stack input_to_gather group=pg gathered_per_sample_weights = None per_sample_weights None gathered_per_sample_weights = t t gathered_inputs gathered_offsets = None offsets None idx = per_sample_weights None gathered_offsets = t idx resize_ offsets size offsets dtype t gathered_inputs gathered_inputs = t input dtype t gathered_inputs gathered_inputs gathered_per_sample_weights gathered_offsets