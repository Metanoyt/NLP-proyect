Owner s module inductor os unittest torch torch _inductor runtime benchmarking benchmarker torch _inductor test_case run_tests TestCase torch _inductor utils run_and_get_code torch testing _internal common_utils skipIfXpu torch testing _internal inductor_utils GPU_TYPE HAS_GPU skipIfXpu msg= Segmentation fault CI machine B BGEMMTest TestCase device = GPU_TYPE torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_left_assoc_good_shape left_assoc means pattern subgraph A B C good_shape means sizes good b b_gemm f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn GELU torch mm g torch mm m m m f_ m torch Tensor m torch Tensor m torch Tensor - torch Tensor When optimization applied Triton kernel more precise than above f because internally uses float accumulation while above f uses float To ensure fair comparison we promote baseline f float precision comparison This actually reduced some atol s tests m = m torch float m = m torch float m = m torch float f m m m torch float f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f_ A B C res atol= rtol= assertTrue B B_GEMM_LEFT_TRITON_ENTRANCE code torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_right_assoc_good_shape right_assoc means pattern A subgraph B C good_shape means sizes good b b_gemm f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn ReLU torch mm m g torch mm m m f_ m torch Tensor m torch Tensor m torch Tensor - torch Tensor m = m torch float m = m torch float m = m torch float f m m m torch float f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f_ A B C res atol= rtol= assertTrue B B_GEMM_RIGHT_TRITON_ENTRANCE code torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_trivial_left_assoc_good_shape trivial_left_assoc means pattern A B C good_shape means sizes good b b_gemm f m torch Tensor m torch Tensor m torch Tensor - torch Tensor torch mm torch mm m m m f_ m torch Tensor m torch Tensor m torch Tensor - torch Tensor m = m torch float m = m torch float m = m torch float f m m m torch float f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f_ A B C res atol= rtol= assertTrue B B_GEMM_LEFT_TRITON_ENTRANCE code torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_trivial_right_assoc_good_shape trivial_right_assoc means pattern A B C good_shape means sizes good b b_gemm f m torch Tensor m torch Tensor m torch Tensor - torch Tensor torch mm m torch mm m m f_ m torch Tensor m torch Tensor m torch Tensor - torch Tensor m = m torch float m = m torch float m = m torch float f m m m torch float f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f_ A B C res atol= rtol= assertTrue B B_GEMM_RIGHT_TRITON_ENTRANCE code torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_bad_pattern_good_shape bad_pattern means code does contain supported patterns f m torch Tensor m torch Tensor m torch Tensor - torch Tensor mm = torch mm m m mm = torch mm mm m torch mm mm mm f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f A B C res atol= rtol= assertTrue B B_GEMM_LEFT_TRITON_ENTRANCE code assertTrue B B_GEMM_RIGHT_TRITON_ENTRANCE code torch _dynamo config patch recompile_limit= torch _inductor config patch b b_gemm_pass=True test_b b_gemm_good_pattern_bad_shape bad_shape means sizes good b b_gemm f m torch Tensor m torch Tensor m torch Tensor - torch Tensor torch mm torch mm m m m f_opt = torch compile f A = torch randn device=GPU_TYPE dtype=torch float B = torch randn device=GPU_TYPE dtype=torch float C = torch randn device=GPU_TYPE dtype=torch float res code = run_and_get_code f_opt A B C assertTrue torch allclose f A B C res atol= rtol= assertTrue B B_GEMM_LEFT_TRITON_ENTRANCE code assertTrue B B_GEMM_RIGHT_TRITON_ENTRANCE code unittest skipIf os environ get DO_PERF_TEST = Perf test enabled torch _dynamo config patch recompile_limit= test_plain_b b_gemm_performance compare torch compile f b b_gemm = off torch compile f b b_gemm = run_with_b b_gemm_off m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor torch mm torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= torch _inductor config patch b b_gemm_pass=True run_with_b b_gemm_on m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor torch mm torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= Ms = Ns = speedups = print Perf Test Plain B B-GEMM print Speedups ljust end= N Ns print f N = N ljust end= print M Ms print f M = M ljust end= N Ns O P = M N A = torch randn M N device=GPU_TYPE dtype=torch float B = torch randn N O device=GPU_TYPE dtype=torch float C = torch randn O P device=GPU_TYPE dtype=torch float speedup = run_with_b b_gemm_off A B C run_with_b b_gemm_on A B C print f round speedup ljust end= speedups append speedup print average_speedup = s speedups average_speedup = s average_speedup = average_speedup len speedups print f Average speedup round average_speedup flaky test assertion disabled assertTrue average_speedup unittest skipIf os environ get DO_PERF_TEST = Perf test enabled torch _dynamo config patch recompile_limit= test_gelu_b b_gemm_performance compare torch compile f b b_gemm = off torch compile f b b_gemm = run_with_b b_gemm_off m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn GELU torch mm g torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= torch _inductor config patch b b_gemm_pass=True run_with_b b_gemm_on m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn GELU torch mm g torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= Ms = Ns = speedups = print Perf Test GELU B B-GEMM print Speedups ljust end= N Ns print f N = N ljust end= print M Ms print f M = M ljust end= N Ns O P = M N A = torch randn M N device=GPU_TYPE dtype=torch float B = torch randn N O device=GPU_TYPE dtype=torch float C = torch randn O P device=GPU_TYPE dtype=torch float speedup = run_with_b b_gemm_off A B C run_with_b b_gemm_on A B C print f round speedup ljust end= speedups append speedup print average_speedup = s speedups average_speedup = s average_speedup = average_speedup len speedups print f Average speedup round average_speedup flaky test assertion disabled assertTrue average_speedup unittest skipIf os environ get DO_PERF_TEST = Perf test enabled torch _dynamo config patch recompile_limit= test_gelu_mlp_b b_gemm_performance compare torch compile f b b_gemm = off torch compile f b b_gemm = run_with_b b_gemm_off m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn GELU torch mm g torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= torch _inductor config patch b b_gemm_pass=True run_with_b b_gemm_on m torch Tensor m torch Tensor m torch Tensor - float f m torch Tensor m torch Tensor m torch Tensor - torch Tensor g = torch nn GELU torch mm g torch mm m m m f_opt = torch compile f dynamic=False benchmarker benchmark f_opt m m m warmup= rep= Ms = Ns = speedups = print Perf Test GELU B B-GEMM MLP print Speedups ljust end= N Ns print f N = N ljust end= print M Ms print f M = M ljust end= N Ns O P = N N A = torch randn M N device=GPU_TYPE dtype=torch float B = torch randn N O device=GPU_TYPE dtype=torch float C = torch randn O P device=GPU_TYPE dtype=torch float speedup = run_with_b b_gemm_off A B C run_with_b b_gemm_on A B C print f round speedup ljust end= speedups append speedup print average_speedup = s speedups average_speedup = s average_speedup = average_speedup len speedups print f Average speedup round average_speedup flaky test assertion disabled assertTrue average_speedup __name__ == __main__ HAS_GPU run_tests