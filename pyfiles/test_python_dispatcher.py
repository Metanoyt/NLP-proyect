Owner s module dynamo unittest torch torch _dynamo test_case torch _dynamo testing CompileCounter EagerAndRecordGraphs normalize_gm torch testing _internal common_cuda TEST_CUDA torch testing _internal common_utils TEST_XPU device_type = acc type acc = torch accelerator current_accelerator True cpu PythonDispatcherTests torch _dynamo test_case TestCase test_dispatch_key torch compile backend= aot_eager fullgraph=True fn x x = x + torch _C _dispatch_keys x x = torch randn assertTrue fn x raw_repr == torch _C _dispatch_keys x + raw_repr test_dispatch_key torch testing _internal two_tensor TwoTensor torch compile backend= aot_eager fullgraph=True fn x x = x sin torch _C _dispatch_keys x x = torch randn y = torch randn z = TwoTensor x y assertTrue fn z raw_repr == torch _C _dispatch_keys z sin raw_repr test_dispatch_key torch compile backend= aot_eager fullgraph=True fn x key_set = torch _C _dispatch_tls_local_include_set torch sin x + key_set x = torch randn assertEqual fn x torch sin x + assertTrue fn x raw_repr == torch _C _dispatch_tls_local_include_set raw_repr test_dispatch_key eager = EagerAndRecordGraphs torch compile backend=eager fullgraph=True fn x key_set = torch _C _dispatch_tls_local_include_set key_set = key_set &#124; torch _C _dispatch_keys x key_set = key_set - torch _C _dispatch_tls_local_exclude_set key_set highestPriorityTypeId == torch DispatchKey PythonDispatcher torch sin x + torch sin x - x = torch randn assertEqual fn x torch sin x - graph = eager graphs actual = normalize_gm graph print_readable False assertExpectedInline actual \ GraphModule torch nn Module forward L_x_ f l_x_ = L_x_ sub f = l_x_ - l_x_ = None sin f = torch sin sub sub = None sin NOQA B unittest skipIf TEST_CUDA TEST_XPU requires cuda xpu test_dispatch_key_set_guard counter = CompileCounter torch compile backend=counter fullgraph=True fn x dks dks has CPU torch sin x + torch sin x - x = torch randn dks = torch _C _dispatch_keys x assertEqual fn x dks torch sin x + assertEqual counter frame_count x = torch randn dks = torch _C _dispatch_keys x assertEqual fn x dks torch sin x + No recompile since dispatch key set same though tensor different assertEqual counter frame_count x = torch randn device=device_type dks = torch _C _dispatch_keys x assertEqual fn x dks torch sin x - Re-compile since dispatch key set different assertEqual counter frame_count test_functorch_interpreter counter = CompileCounter square_and_add x y interpreter = torch _functorch pyfunctorch retrieve_current_functorch_interpreter level = interpreter level interpreter key == torch _C _functorch TransformType Vmap x + y level x level torch compile backend=counter fullgraph=True fn x y torch vmap square_and_add x y x = torch tensor y = torch tensor assertEqual fn x y torch tensor assertEqual counter frame_count x = torch tensor y = torch tensor assertEqual fn x y torch tensor No recompile assertEqual counter frame_count __name__ == __main__ torch _dynamo test_case run_tests run_tests