mypy ignore-errors Normalize arguments convert array_likes tensors dtypes torch dtypes so __future__ annotations functools inspect operator typing torch _dtypes _dtypes_impl _util ArrayLike = typing TypeVar ArrayLike Scalar = typing Union int float complex bool ArrayLikeOrScalar = typing Union ArrayLike Scalar DTypeLike = typing TypeVar DTypeLike AxisLike = typing TypeVar AxisLike NDArray = typing TypeVar NDArray CastingModes = typing TypeVar CastingModes KeepDims = typing TypeVar KeepDims OutArray annotate out= array argument This one special several respects First It needs NDArray we need preserve ` result out ` semantics Therefore we cannot just extract Tensor out array So we never pass out array implementer functions handle ` normalizer ` below Second out= argument can either keyword positional argument positional arg can anywhere signature To handle all we define special ` OutArray ` annotation dispatch OutArray = typing TypeVar OutArray try typing NotImplementedType except ImportError NotImplementedType = typing TypeVar NotImplementedType normalize_array_like x parm=None codespell ignore _ndarray asarray asarray x tensor normalize_array_like_or_scalar x parm=None codespell ignore _dtypes_impl is_scalar_or_symbolic x x normalize_array_like x parm codespell ignore normalize_optional_array_like_or_scalar x parm=None codespell ignore x None None normalize_array_like_or_scalar x parm codespell ignore normalize_optional_array_like x parm=None codespell ignore This explicit normalizer needed because otherwise normalize_array_like does run parameter annotated Optional ArrayLike None x None normalize_array_like x parm codespell ignore normalize_seq_array_like x parm=None codespell ignore tuple normalize_array_like value value x normalize_dtype dtype parm=None codespell ignore cf _decorators dtype_to_torch torch_dtype = None dtype None dtype = _dtypes dtype dtype torch_dtype = dtype torch_dtype torch_dtype normalize_not_implemented arg parm codespell ignore arg = parm default codespell ignore raise NotImplementedError f parm name parameter supported codespell ignore normalize_axis_like arg parm=None codespell ignore _ndarray ndarray isinstance arg ndarray arg = operator index arg arg normalize_ndarray arg parm=None codespell ignore check arg ndarray extract its tensor attribute arg None arg _ndarray ndarray isinstance arg ndarray raise TypeError f parm name must array codespell ignore arg tensor normalize_outarray arg parm=None codespell ignore almost normalize_ndarray only array its tensor arg None arg _ndarray ndarray Dynamo can pass torch tensors out arguments wrap ndarray before processing isinstance arg torch Tensor arg = ndarray arg isinstance arg ndarray raise TypeError f parm name must array codespell ignore arg normalize_casting arg parm=None codespell ignore arg no equiv safe same_kind unsafe raise ValueError f casting must one no equiv safe same_kind unsafe got arg arg normalizers = ArrayLike normalize_array_like ArrayLikeOrScalar normalize_array_like_or_scalar Optional ArrayLike normalize_optional_array_like Sequence ArrayLike normalize_seq_array_like Optional ArrayLikeOrScalar normalize_optional_array_like_or_scalar Optional NDArray normalize_ndarray Optional OutArray normalize_outarray NDArray normalize_ndarray Optional DTypeLike normalize_dtype AxisLike normalize_axis_like NotImplementedType normalize_not_implemented Optional CastingModes normalize_casting maybe_normalize arg parm codespell ignore Normalize arg normalizer registered normalizer = normalizers get parm annotation None codespell ignore normalizer arg parm normalizer arg codespell ignore ### Return value helpers ### maybe_copy_to out result promote_scalar_result=False NB here out either ndarray None out None result isinstance result torch Tensor result shape = out shape can_fit = result numel == out ndim == promote_scalar_result can_fit result = result squeeze raise ValueError f Bad size out array out shape = out shape f while result shape = result shape out tensor copy_ result out isinstance result tuple list type result maybe_copy_to o r promote_scalar_result o r zip out result raise AssertionError We should never hit path wrap_tensors result _ndarray ndarray isinstance result torch Tensor ndarray result isinstance result tuple list result = type result wrap_tensors x x result result array_or_scalar values py_type=float return_scalar=False return_scalar py_type values item _ndarray ndarray ndarray values ### The main decorator normalize arguments postprocess output ### normalizer _func=None promote_scalar_result=False normalizer_inner func functools wraps func wrapped args kwds sig = inspect signature func params = sig parameters first_param = next iter params values NumPy s API does have positional args before variadic positional args first_param kind == inspect Parameter VAR_POSITIONAL args = maybe_normalize arg first_param arg args NB extra unknown arguments pass through will raise func args below args = tuple maybe_normalize arg parm codespell ignore arg parm zip args params values codespell ignore + args len params values kwds = name maybe_normalize arg params name name params arg name arg kwds items result = func args kwds keepdims bound_args = None keepdims params params keepdims annotation == KeepDims keepdims can any position so we need sig bind bound_args = sig bind args kwds arguments bound_args get keepdims False In case first arg initial tensor second arg optionally axis tensor = args axis = bound_args get axis result = _util apply_keepdims result axis tensor ndim out out params out can any position so we need sig bind bound_args None bound_args = sig bind args kwds arguments out = bound_args get out result = maybe_copy_to out result promote_scalar_result result = wrap_tensors result result wrapped _func None normalizer_inner normalizer_inner _func