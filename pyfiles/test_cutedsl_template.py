Owner s module inductor unittest unittest mock MagicMock patch expecttest assert_expected_inline torch torch _inductor test_case TestCase torch _inductor virtualized V torch testing _internal inductor_utils MockGraphHandler try cutlass noqa F cutlass cute cute noqa F HAS_CUTLASS = True except ImportError HAS_CUTLASS = False HAS_CUTLASS torch _inductor codegen cutedsl cutedsl_kernel CuteDSLTemplateKernel torch _inductor codegen cutedsl cutedsl_template CuteDSLTemplate torch _inductor select_algorithm PartialRender CUTEDSL_ADD_TEMPLATE = r gen_defines cute kernel kernel_name _kernel gA cute Tensor gB cute Tensor gC cute Tensor tidx _ _ = cute arch thread_idx bidx _ _ = cute arch block_idx bdim _ _ = cute arch block_dim thread_idx = bidx bdim + tidx m n = gA shape thread_idx m n mi = thread_idx n ni = thread_idx n mi m ni n gC mi ni = gA mi ni + gB mi ni cute jit kernel_name _jit mA cute Tensor mB cute Tensor mC cute Tensor stream gen_defines m n = mA shape total_threads = m n num_blocks = total_threads + THREADS_PER_BLOCK - THREADS_PER_BLOCK kernel = kernel_name _kernel mA mB mC kernel launch grid= num_blocks block= THREADS_PER_BLOCK stream=stream def_kernel input_a input_b cute_a = from_dlpack input_a cute_b = from_dlpack input_b cute_c = from_dlpack get_output kernel_name _jit cute_a cute_b cute_c cuda CUstream stream get_output unittest skipUnless HAS_CUTLASS requires cutlass TestCuteDSLTemplate TestCase Test cases CuteDSL template functionality test_gen_imports kernel = CuteDSLTemplateKernel kernel_name= test_kernel input_nodes= output_node=None imports = kernel gen_imports assertIn torch imports assertIn cutlass imports assertIn cutlass cute cute imports assertIn cutlass cute runtime from_dlpack imports assertIsInstance imports str lines = imports strip split \n assertEqual len lines test_render_includes_imports template_source = cute kernel kernel_name _kernel pass def_kernel input output output mock_template = MagicMock mock_template render = MagicMock return_value=template_source kernel = CuteDSLTemplateKernel kernel_name= test_kernel input_nodes= output_node=None result = kernel render mock_template assertIsInstance result PartialRender rendered_code = result _code The imports might have leading whitespace so strip rendered_code_stripped = rendered_code lstrip assertTrue rendered_code_stripped startswith torch f Code should start torch got rendered_code_stripped assertIn cutlass rendered_code assertIn cutlass cute cute rendered_code assertIn cutlass cute runtime from_dlpack rendered_code assertIn cute kernel rendered_code test_template_env_contains_hooks kernel = CuteDSLTemplateKernel kernel_name= test_kernel input_nodes= output_node=None captured_env = mock_render kwargs captured_env update kwargs rendered mock_template = MagicMock mock_template render = mock_render kernel render mock_template assertIn def_kernel captured_env assertIn kernel_name captured_env assertTrue callable captured_env def_kernel test_multiple_templates_unique_names Clean registry first test_name = f unique_test_ id test_name CuteDSLTemplate all_templates del CuteDSLTemplate all_templates test_name _ = CuteDSLTemplate name=test_name source= template assertRaises AssertionError _ = CuteDSLTemplate name=test_name source= template test_indented_buffer_usage kernel = CuteDSLTemplateKernel kernel_name= test_kernel input_nodes= output_node=None imports = kernel gen_imports lines = imports strip split \n line lines line assertFalse line startswith f Line should indented line unittest skipIf torch cuda is_available CUDA available test_cutedsl_add_e e End-to-end test CuteDSL template including code generation verification torch _inductor ir TensorBox torch _inductor lowering lowerings torch _inductor utils run_and_get_code template = CuteDSLTemplate name= test_add_e e source=CUTEDSL_ADD_TEMPLATE cutedsl_add_lowering TensorBox b TensorBox - TensorBox choices = error = template maybe_append_choice choices input_nodes= b layout=a get_layout THREADS_PER_BLOCK= error choices default_lowering = lowerings torch ops aten add Tensor default_lowering b Use single choice directly no autotuning choices output_node patch dict lowerings torch ops aten add Tensor cutedsl_add_lowering Test function test_add x y x + y device = cuda x = torch randn device=device dtype=torch float y = torch randn device=device dtype=torch float Compile get generated code compiled_fn = torch compile test_add backend= inductor result code = run_and_get_code compiled_fn x y Verify CuteDSL code present assertIn cute code lower CuteDSL code should generated code Verify parameter generation worked assertIn THREADS_PER_BLOCK code Parameter should generated code Verify correctness expected = x + y assertTrue torch allclose result expected atol= e- unittest skipIf torch cuda is_available CUDA available test_cutedsl_add_e e_autotune E E test multiple CuteDSL template variants autotuning torch _inductor ir TensorBox torch _inductor lowering lowerings torch _inductor select_algorithm autotune_select_algorithm template = CuteDSLTemplate name= test_add_autotune source=CUTEDSL_ADD_TEMPLATE cutedsl_add_lowering TensorBox b TensorBox - TensorBox choices = Add multiple variants different thread counts autotuning thread_variants = threads thread_variants error = template maybe_append_choice choices input_nodes= b layout=a get_layout THREADS_PER_BLOCK=threads error Skip variant fails continue choices default_lowering = lowerings torch ops aten add Tensor default_lowering b Use autotuning select best variant autotune_select_algorithm cutedsl_add_autotune choices b get_layout patch dict lowerings torch ops aten add Tensor cutedsl_add_lowering Test function test_add x y x + y device = cuda x = torch randn device=device dtype=torch float y = torch randn device=device dtype=torch float Compile run compiled_fn = torch compile test_add backend= inductor result = compiled_fn x y Verify correctness expected = x + y assertTrue torch allclose result expected atol= e- test_gen_defines Test gen_defines correctly generates CuteDSL parameter definitions kernel = CuteDSLTemplateKernel kernel_name= test_kernel input_nodes= output_node=None Test integer parameters params = kernel gen_defines THREADS_PER_BLOCK= BLOCK_SIZE= ENABLE_FEATURE=True assert_expected_inline params \ THREADS_PER_BLOCK cutlass Constexpr = BLOCK_SIZE cutlass Constexpr = ENABLE_FEATURE cutlass Constexpr = True params_float = kernel gen_defines SCALE_FACTOR= assert_expected_inline params_float \ SCALE_FACTOR cutlass Constexpr = test_template_aliasing Test template variables correctly aliased function arguments torch _inductor ir Buffer mock_input = MagicMock spec=Buffer mock_input get_name return_value = buf_input mock_input = MagicMock spec=Buffer mock_input get_name return_value = buf_input mock_output = MagicMock spec=Buffer mock_output get_name return_value = buf_output mock_graph = MockGraphHandler V set_graph_handler mock_graph kernel = CuteDSLTemplateKernel kernel_name= test_aliasing input_nodes= mock_input mock_input output_node=mock_output def_kernel_hook = kernel def_kernel custom_a custom_b assertEqual def_kernel_hook DEF_KERNEL assertIn DEF_KERNEL kernel render_hooks hook_fn = kernel render_hooks DEF_KERNEL generated_code = hook_fn Check generated code contains expected aliasing statements assertIn custom_a = arg_custom_a generated_code assertIn custom_b = arg_custom_b generated_code test_get_output_hook Test get_output template hook torch _inductor ir Buffer mock_output = MagicMock spec=Buffer mock_output get_name return_value = buf_test_output mock_graph = MockGraphHandler V set_graph_handler mock_graph kernel = CuteDSLTemplateKernel kernel_name= test_output input_nodes= output_node=mock_output assertRaises ValueError error no output buffer result = kernel get_output kernel args output_buffers buf_test_output = arg_buf_test_output result = kernel get_output assertEqual result arg_buf_test_output test_modification_subgraph Test modification method subgraph processing torch _inductor ir Buffer mock_subgraph = MagicMock spec=Buffer mock_subgraph = MagicMock spec=Buffer subgraphs = mock_subgraph mock_subgraph mock_output = MagicMock spec=Buffer mock_output get_name return_value = buf_output kernel = CuteDSLTemplateKernel kernel_name= test_modification input_nodes= output_node=mock_output subgraphs=subgraphs result = kernel _get_subgraph assertEqual result mock_subgraph result = kernel _get_subgraph assertEqual result mock_subgraph assertRaises AssertionError kernel _get_subgraph test_cutedsl_op_overrides Test new CuteDSLOpOverrides torch torch _inductor codegen common CSEVariable torch _inductor codegen cutedsl cutedsl_op_overrides CuteDSLOpOverrides torch utils _sympy value_ranges ValueRanges mock_cse_a = MagicMock spec=CSEVariable mock_cse_a __str__ return_value = tensor_a mock_cse_a dtype = torch float mock_cse_a bounds = ValueRanges unknown mock_cse_b = MagicMock spec=CSEVariable mock_cse_b __str__ return_value = tensor_b mock_cse_b dtype = torch float mock_cse_b bounds = ValueRanges unknown mock_graph = MockGraphHandler V set_graph_handler mock_graph kernel = CuteDSLTemplateKernel kernel_name= test_ops input_nodes= output_node=None V set_kernel_handler kernel result = CuteDSLOpOverrides add mock_cse_a mock_cse_b assertIsInstance result CSEVariable result = CuteDSLOpOverrides mul mock_cse_a mock_cse_b assertIsInstance result CSEVariable result = CuteDSLOpOverrides truediv mock_cse_a mock_cse_b assertIsInstance result CSEVariable result = CuteDSLOpOverrides exp mock_cse_a assertIsInstance result CSEVariable result = CuteDSLOpOverrides sqrt mock_cse_a assertIsInstance result CSEVariable assertRaises NotImplementedError result = CuteDSLOpOverrides maximum mock_cse_a mock_cse_b result = CuteDSLOpOverrides minimum mock_cse_a mock_cse_b scalar_result = CuteDSLOpOverrides _ensure_tensor_ssa mock_cse_a assertEqual scalar_result cute full_like tensor_a tensor_result = CuteDSLOpOverrides _ensure_tensor_ssa mock_cse_a mock_cse_b assertEqual tensor_result tensor_a test_cse_integration Test CSE Common Subexpression Elimination integration torch _inductor codegen common CSE mock_graph = MockGraphHandler V set_graph_handler mock_graph kernel = CuteDSLTemplateKernel kernel_name= test_cse input_nodes= output_node=None assertIsInstance kernel cse CSE assertEqual kernel cse name_prefix tmp V set_kernel_handler kernel test_expr = x var = kernel cse generate kernel body test_expr dtype=None assertTrue str var startswith tmp __name__ == __main__ torch _inductor test_case run_tests run_tests