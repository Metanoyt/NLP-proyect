Owner s module tests collections doctest functools importlib inspect itertools math os re subprocess sys unittest mock typing Any collections abc Callable collections abc Iterator torch torch testing make_tensor torch testing _internal common_utils IS_FBCODE IS_JETSON IS_MACOS IS_SANDCASTLE IS_WINDOWS TestCase run_tests slowTest parametrize reparametrize subtest instantiate_parametrized_tests dtype_name TEST_WITH_ROCM decorateIf skipIfRocm torch testing _internal common_device_type \ PYTORCH_TESTING_DEVICE_EXCEPT_FOR_KEY PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY dtypes get_device_type_test_bases instantiate_device_type_tests onlyCPU onlyCUDA onlyNativeDeviceTypes deviceCountAtLeast ops expectedFailureMeta OpDTypes torch testing _internal common_methods_invocations op_db torch testing _internal opinfo torch testing _internal common_dtype all_types_and_complex_and floating_types torch testing _internal common_modules modules module_db ModuleInfo torch testing _internal opinfo core SampleInput DecorateInfo OpInfo operator string For testing TestCase methods torch testing functions TestTesting TestCase Ensure assertEqual handles numpy arrays properly dtypes all_types_and_complex_and torch bool torch half test_assertEqual_numpy device dtype S = test_sizes = S S S S S test_size test_sizes = make_tensor test_size dtype=dtype device=device low=- high= a_n = cpu numpy msg = f size test_size assertEqual a_n rtol= atol= msg=msg assertEqual a_n rtol= atol= msg=msg assertEqual a_n a_n rtol= atol= msg=msg test_assertEqual_longMessage actual = actual expected = expected long_message = longMessage try Capture default error message forcing TestCase longMessage = False longMessage = False try assertEqual actual expected except AssertionError error default_msg = str error raise AssertionError AssertionError raised longMessage = True extra_msg = sentinel assertRaisesRegex AssertionError re escape f default_msg \n extra_msg assertEqual actual expected msg=extra_msg finally longMessage = long_message _isclose_helper tests device dtype equal_nan atol= e- rtol= e- test tests = torch tensor test device=device dtype=dtype b = torch tensor test device=device dtype=dtype actual = torch isclose b equal_nan=equal_nan atol=atol rtol=rtol expected = test assertEqual actual item expected test_isclose_bool device tests = True True True False False True True False False False True False _isclose_helper tests device torch bool False dtypes torch uint torch int torch int torch int torch int test_isclose_integer device dtype tests = True False False _isclose_helper tests device dtype False atol rtol tests tests = True False True _isclose_helper tests device dtype False atol= rtol= dtype torch uint tests = - False - False tests = - True - True _isclose_helper tests device dtype False atol= rtol= onlyNativeDeviceTypes dtypes torch float torch float torch float test_isclose_float device dtype tests = True - False float inf float inf True -float inf float inf False float inf float nan False float nan float nan False float nan False True _isclose_helper tests device dtype False atol rtol tests eps = e- dtype torch half e- tests = True + eps False False True - eps False - True - - eps False - True + eps - False _isclose_helper tests device dtype False atol= rtol= equal_nan = True tests tests = float nan False float inf float nan False float nan float nan True _isclose_helper tests device dtype True unittest skipIf IS_SANDCASTLE Skipping because doesn t work sandcastle dtypes torch complex torch complex test_isclose_complex device dtype tests = complex complex + e- True complex complex False complex complex False complex complex float nan False complex float nan complex float nan False complex complex float inf False complex float inf complex float inf False complex -float inf complex float inf False complex -float inf complex float inf False complex float inf complex float inf True complex float inf complex float inf + e- False _isclose_helper tests device dtype False atol rtol tests atol rtol tests eps = e- tests = Complex versions float tests real part complex complex True complex complex + eps False complex complex False complex complex True complex - eps complex False complex - complex True complex - - eps complex False complex complex - True complex + eps complex - False Complex versions float tests imaginary part complex complex True complex complex + eps False complex complex False complex complex True complex - eps complex False complex - complex True complex - - eps complex False complex complex - True complex + eps complex - False _isclose_helper tests device dtype False atol= rtol= atol rtol tests isclose tests = Complex-specific tests complex - complex - False complex - complex - True complex -math sqrt math sqrt complex -math sqrt math sqrt True complex -math sqrt math sqrt complex -math sqrt math sqrt False complex complex True complex complex + eps False complex complex True _isclose_helper tests device dtype False atol= rtol= equal_nan = True tests tests = complex complex float nan False complex complex float nan False complex float nan complex float nan True complex float nan complex float nan True complex float nan float nan complex float nan float nan True _isclose_helper tests device dtype True Tests isclose rtol atol values less than zero throws RuntimeError dtypes torch bool torch uint torch int torch int torch int torch int torch float torch float torch float test_isclose_atol_rtol_greater_than_zero device dtype t = torch tensor device=device dtype=dtype assertRaises RuntimeError torch isclose t t atol=- rtol= assertRaises RuntimeError torch isclose t t atol= rtol=- assertRaises RuntimeError torch isclose t t atol=- rtol=- test_isclose_equality_shortcut For values = integers differing can no longer differentiated torch float lower precision floating point dtypes Thus even rtol == atol == these tensors would considered close they compared integers = torch tensor dtype=torch int b = + assertFalse torch isclose b rtol= atol= dtypes torch float torch float torch float torch complex torch complex test_isclose_nan_equality_shortcut device dtype dtype is_floating_point = b = torch nan = complex torch nan b = complex torch nan expected = True tests = b expected _isclose_helper tests device dtype equal_nan=True rtol= atol= The following tests test_cuda_assert_ added ensure test suite terminates early when CUDA assert thrown Because all subsequent test will fail happens These tests slow because spawn another process run test suite See https github com pytorch pytorch issues unittest skipIf TEST_WITH_ROCM ROCm doesn t support device side asserts onlyCUDA slowTest test_cuda_assert_should_stop_common_utils_test_suite device test ensure common_utils py override has early termination CUDA stderr = TestCase runWithPytorchAPIUsageStderr \ usr bin env python torch torch testing _internal common_utils TestCase run_tests slowTest TestThatContainsCUDAAssertFailure TestCase slowTest test_throw_unrecoverable_cuda_exception x = torch rand device= cuda cause unrecoverable CUDA exception recoverable CPU y = x torch tensor cpu slowTest test_trivial_passing_test_case_on_cpu_cuda x = torch tensor device= cuda x = torch tensor device= cpu assertEqual x x __name__ == __main__ run_tests should capture CUDA error assertIn CUDA error device-side assert triggered stderr should run only test because throws unrecoverable error assertIn errors= stderr unittest skipIf TEST_WITH_ROCM ROCm doesn t support device side asserts onlyCUDA slowTest test_cuda_assert_should_stop_common_device_type_test_suite device test ensure common_device_type py override has early termination CUDA stderr = TestCase runWithPytorchAPIUsageStderr \ usr bin env python torch torch testing _internal common_utils TestCase run_tests slowTest torch testing _internal common_device_type instantiate_device_type_tests TestThatContainsCUDAAssertFailure TestCase slowTest test_throw_unrecoverable_cuda_exception device x = torch rand device=device cause unrecoverable CUDA exception recoverable CPU y = x torch tensor cpu slowTest test_trivial_passing_test_case_on_cpu_cuda device x = torch tensor device=device x = torch tensor device= cpu assertEqual x x instantiate_device_type_tests TestThatContainsCUDAAssertFailure globals only_for= cuda __name__ == __main__ run_tests should capture CUDA error assertIn CUDA error device-side assert triggered stderr should run only test because throws unrecoverable error assertIn errors= stderr unittest skipIf TEST_WITH_ROCM ROCm doesn t support device side asserts onlyCUDA slowTest test_cuda_assert_should_not_stop_common_distributed_test_suite device test ensure common_distributed py override should early terminate CUDA stderr = TestCase runWithPytorchAPIUsageStderr \ usr bin env python torch torch testing _internal common_utils run_tests slowTest torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_distributed MultiProcessTestCase TestThatContainsCUDAAssertFailure MultiProcessTestCase slowTest test_throw_unrecoverable_cuda_exception device x = torch rand device=device cause unrecoverable CUDA exception recoverable CPU y = x torch tensor cpu slowTest test_trivial_passing_test_case_on_cpu_cuda device x = torch tensor device=device x = torch tensor device= cpu assertEqual x x instantiate_device_type_tests TestThatContainsCUDAAssertFailure globals only_for= cuda __name__ == __main__ run_tests we currently disabling CUDA early termination distributed tests assertIn errors= stderr expectedFailureMeta This only supported CPU CUDA onlyNativeDeviceTypes test_get_supported_dtypes device Test ` get_supported_dtypes ` helper function We acquire dtypes few Ops dynamically verify them against correct statically described values ops_to_test = list filter lambda op op name atan topk xlogy op_db op ops_to_test dynamic_dtypes = opinfo utils get_supported_dtypes op op sample_inputs_func device_type dynamic_dispatch = opinfo utils dtypes_dispatch_hint dynamic_dtypes device_type == cpu dtypes = op dtypes device_type = cuda dtypes = op dtypesIfCUDA assertTrue set dtypes == set dynamic_dtypes assertTrue set dtypes == set dynamic_dispatch dispatch_fn onlyCPU ops op op op_db len op supported_dtypes cpu symmetric_difference op supported_dtypes cuda dtypes=OpDTypes none test_supported_dtypes device op assertNotEqual op supported_dtypes cpu op supported_dtypes cuda assertEqual op supported_dtypes cuda op supported_dtypes cuda assertEqual op supported_dtypes torch device cuda op supported_dtypes torch device cuda index= test_setup_and_teardown_run_for_device_specific_tests device TODO Move other similar text blocks some fixtures subdir stderr = TestCase runWithPytorchAPIUsageStderr f \ usr bin env python torch torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_utils TestCase run_tests TestFoo TestCase classmethod setUpClass cls store something test query during teardown cls stored_thing = called + cls __name__ classmethod tearDownClass cls throw here so we know teardown run raise RuntimeError cls stored_thing test_bar device make sure test can access stored thing print stored_thing instantiate_device_type_tests TestFoo globals only_for= device_type __name__ == __main__ run_tests expected_device_class_name = f TestFoo device_type upper expected_error_text = f RuntimeError called expected_device_class_name assertIn expected_error_text stderr instantiate_device_type_tests TestTesting globals TestFrameworkUtils TestCase unittest skipIf IS_WINDOWS Skipping because doesn t work windows unittest skipIf IS_SANDCASTLE Skipping because doesn t work sandcastle test_filtering_env_var Test environment variable selected device type test generator test_filter_file_template = \ usr bin env python torch torch testing _internal common_utils TestCase run_tests torch testing _internal common_device_type instantiate_device_type_tests TestEnvironmentVariable TestCase test_trivial_passing_test device x = torch tensor device=device x = torch tensor device= cpu assertEqual x x instantiate_device_type_tests TestEnvironmentVariable globals __name__ == __main__ run_tests test_bases_count = len get_device_type_test_bases Test without setting env var should run everything env = dict os environ k CI PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY PYTORCH_TESTING_DEVICE_EXCEPT_FOR_KEY k env keys del env k _ stderr = TestCase run_process_no_exception test_filter_file_template env=env assertIn f Ran test_bases_count test stderr decode ascii Test setting only_for should only run test env PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY = cpu _ stderr = TestCase run_process_no_exception test_filter_file_template env=env assertIn Ran test stderr decode ascii Test setting except_for should run less device type default del env PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY env PYTORCH_TESTING_DEVICE_EXCEPT_FOR_KEY = cpu _ stderr = TestCase run_process_no_exception test_filter_file_template env=env assertIn f Ran test_bases_count - test stderr decode ascii Test setting both should throw exception env PYTORCH_TESTING_DEVICE_ONLY_FOR_KEY = cpu _ stderr = TestCase run_process_no_exception test_filter_file_template env=env assertNotIn OK stderr decode ascii make_assert_close_inputs actual Any expected Any - list tuple Any Any Makes inputs func ` torch testing assert_close ` functions based two examples Args actual Any Actual input expected Any Expected input Returns List Tuple Any Any Pair example inputs well example inputs wrapped sequences ` tuple ` ` list ` mappings ` dict ` ` ~collections OrderedDict ` actual expected tuple vs tuple actual expected list vs list actual expected tuple vs list actual expected dict vs dict t actual t expected OrderedDict vs OrderedDict collections OrderedDict t actual collections OrderedDict t expected dict vs OrderedDict t actual collections OrderedDict t expected list tuples vs tuple lists actual expected list dicts vs tuple OrderedDicts t actual collections OrderedDict t expected dict lists vs OrderedDict tuples t actual collections OrderedDict t expected assert_close_with_inputs actual Any expected Any - Iterator Callable Yields func ` torch testing assert_close ` predefined positional inputs based two examples note Every test does test specific input should iterate over maximize coverage Args actual Any Actual input expected Any Expected input Yields Callable func ` torch testing assert_close ` predefined positional inputs inputs make_assert_close_inputs actual expected yield functools partial torch testing assert_close inputs TestAssertClose TestCase test_mismatching_types_subclasses actual = torch rand expected = torch nn Parameter actual fn assert_close_with_inputs actual expected fn test_mismatching_types_type_equality actual = torch empty expected = torch nn Parameter actual fn assert_close_with_inputs actual expected assertRaisesRegex TypeError str type expected fn allow_subclasses=False test_mismatching_types actual = torch empty expected = actual numpy fn allow_subclasses itertools product assert_close_with_inputs actual expected True False assertRaisesRegex TypeError str type expected fn allow_subclasses=allow_subclasses test_unknown_type actual = expected = fn assert_close_with_inputs actual expected assertRaisesRegex TypeError str type actual fn test_mismatching_shape actual = torch empty expected = actual clone reshape fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError shape fn unittest skipIf torch backends mkldnn is_available reason= MKLDNN available test_unknown_layout actual = torch empty expected = actual to_mkldnn fn assert_close_with_inputs actual expected assertRaisesRegex ValueError layout fn test_meta actual = torch empty device= meta expected = torch empty device= meta fn assert_close_with_inputs actual expected fn test_mismatching_layout strided = torch empty sparse_coo = strided to_sparse sparse_csr = strided to_sparse_csr actual expected itertools combinations strided sparse_coo sparse_csr fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError layout fn test_mismatching_layout_no_check strided = torch randn sparse_coo = strided to_sparse sparse_csr = strided to_sparse_csr actual expected itertools combinations strided sparse_coo sparse_csr fn assert_close_with_inputs actual expected fn check_layout=False test_mismatching_dtype actual = torch empty dtype=torch float expected = actual clone torch int fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError dtype fn test_mismatching_dtype_no_check actual = torch ones dtype=torch float expected = actual clone torch int fn assert_close_with_inputs actual expected fn check_dtype=False test_mismatching_stride actual = torch empty expected = torch as_strided actual clone t contiguous actual shape actual stride - fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError stride fn check_stride=True test_mismatching_stride_no_check actual = torch rand expected = torch as_strided actual clone t contiguous actual shape actual stride - fn assert_close_with_inputs actual expected fn test_only_rtol actual = torch empty expected = actual clone fn assert_close_with_inputs actual expected assertRaises ValueError fn rtol= test_only_atol actual = torch empty expected = actual clone fn assert_close_with_inputs actual expected assertRaises ValueError fn atol= test_mismatching_values actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaises AssertionError fn test_mismatching_values_rtol eps = e- actual = torch tensor expected = torch tensor + eps fn assert_close_with_inputs actual expected assertRaises AssertionError fn rtol=eps atol= test_mismatching_values_atol eps = e- actual = torch tensor expected = torch tensor eps fn assert_close_with_inputs actual expected assertRaises AssertionError fn rtol= atol=eps test_matching actual = torch tensor expected = actual clone torch testing assert_close actual expected test_matching_rtol eps = e- actual = torch tensor expected = torch tensor + eps fn assert_close_with_inputs actual expected fn rtol=eps atol= test_matching_atol eps = e- actual = torch tensor expected = torch tensor eps fn assert_close_with_inputs actual expected fn rtol= atol=eps TODO code test designed removed https github com pytorch pytorch pull We need check test still needed behavior now enabled default test_matching_conjugate_bit actual = torch tensor complex conj expected = torch tensor complex - fn assert_close_with_inputs actual expected fn test_matching_nan nan = float NaN tests = nan nan complex nan complex nan complex nan nan complex nan complex nan nan complex nan nan actual expected tests fn assert_close_with_inputs actual expected assertRaises AssertionError fn test_matching_nan_with_equal_nan nan = float NaN tests = nan nan complex nan complex nan complex nan nan complex nan complex nan nan complex nan nan actual expected tests fn assert_close_with_inputs actual expected fn equal_nan=True test_numpy tensor = torch rand dtype=torch float actual = tensor numpy expected = actual copy fn assert_close_with_inputs actual expected fn test_scalar number = torch randint size= item actual expected itertools product int number float number complex number repeat= check_dtype = type actual type expected fn assert_close_with_inputs actual expected fn check_dtype=check_dtype test_bool actual = torch tensor True False expected = actual clone fn assert_close_with_inputs actual expected fn test_none actual = expected = None fn assert_close_with_inputs actual expected fn test_none_mismatch expected = None actual False torch nan torch tensor torch nan fn assert_close_with_inputs actual expected assertRaises AssertionError fn test_docstring_examples finder = doctest DocTestFinder verbose=False runner = doctest DocTestRunner verbose=False optionflags=doctest NORMALIZE_WHITESPACE globs = dict torch=torch doctests = finder find torch testing assert_close globs=globs failures = runner run doctests out=lambda report failures append report failures raise AssertionError f Doctest found len failures failures \n\n + \n join failures test_default_tolerance_selection_mismatching_dtypes If default tolerances where selected based promoted dtype i e float these tensors wouldn t considered close actual = torch tensor dtype=torch bfloat expected = torch tensor dtype=torch float fn assert_close_with_inputs actual expected fn check_dtype=False UnexpectedException Exception The only purpose exception test ` ` assert_close ` ` s handling unexpected exceptions Thus test should mock component raise instead regular behavior We avoid using builtin exception here avoid triggering possible handling them unittest mock patch torch testing _comparison TensorLikePair __init__ side_effect=UnexpectedException test_unexpected_error_originate _ actual = torch tensor expected = actual clone assertRaisesRegex RuntimeError unexpected exception torch testing assert_close actual expected unittest mock patch torch testing _comparison TensorLikePair compare side_effect=UnexpectedException test_unexpected_error_compare _ actual = torch tensor expected = actual clone assertRaisesRegex RuntimeError unexpected exception torch testing assert_close actual expected TestAssertCloseMultiDevice TestCase deviceCountAtLeast test_mismatching_device devices actual_device expected_device itertools permutations cpu devices actual = torch empty device=actual_device expected = actual clone expected_device fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError device fn deviceCountAtLeast test_mismatching_device_no_check devices actual_device expected_device itertools permutations cpu devices actual = torch rand device=actual_device expected = actual clone expected_device fn assert_close_with_inputs actual expected fn check_device=False instantiate_device_type_tests TestAssertCloseMultiDevice globals only_for= cuda TestAssertCloseErrorMessage TestCase test_identifier_tensor_likes actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Tensor-likes fn test_identifier_scalars actual = expected = fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Scalars fn test_not_equal actual = torch tensor dtype=torch float expected = torch tensor dtype=torch float fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape equal fn rtol= atol= test_not_close actual = torch tensor dtype=torch float expected = torch tensor dtype=torch float fn rtol atol itertools product assert_close_with_inputs actual expected e- e- e- e- assertRaisesRegex AssertionError re escape close fn rtol=rtol atol=atol test_mismatched_elements actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Mismatched elements fn test_abs_diff actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Greatest absolute difference index fn test_small_float_dtype dtype torch float _e m fn torch float _e m fnuz torch float _e m torch float _e m fnuz torch float _e m fnu w_vector = torch tensor dtype=dtype x_vector = torch tensor dtype=dtype y_vector = torch tensor dtype=dtype z_vector = torch tensor dtype=dtype additional_dims range new_shape = list w_vector shape + additional_dims w_tensor = w_vector reshape new_shape x_tensor = x_vector reshape new_shape y_tensor = y_vector reshape new_shape z_tensor = z_vector reshape new_shape fn assert_close_with_inputs x_tensor y_tensor expected_shape = + additional_dims assertRaisesRegex AssertionError re escape f The first mismatched element index expected_shape fn fn assert_close_with_inputs w_tensor y_tensor expected_shape = + additional_dims assertRaisesRegex AssertionError re escape f The first mismatched element index expected_shape fn fn assert_close_with_inputs x_tensor z_tensor fn test_abs_diff_scalar actual = expected = fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Absolute difference fn test_rel_diff actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Greatest relative difference index fn test_rel_diff_scalar actual = expected = fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Relative difference fn test_zero_div_zero actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected Although looks complicated regex just makes sure word nan part error message That would happen used mismatch computation although matches assertRaisesRegex AssertionError nan fn test_rtol rtol = e- actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape f up rtol allowed fn rtol=rtol atol= test_atol atol = e- actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape f up atol allowed fn rtol= atol=atol test_msg_str msg = Custom error message actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError msg fn msg=msg test_msg_callable msg = Custom error message actual = torch tensor expected = torch tensor fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError msg fn msg=lambda _ msg TestAssertCloseContainer TestCase test_sequence_mismatching_len actual = torch empty expected = assertRaises AssertionError torch testing assert_close actual expected test_sequence_mismatching_values_msg t = torch tensor t = torch tensor actual = t t expected = t t assertRaisesRegex AssertionError re escape item torch testing assert_close actual expected test_mapping_mismatching_keys actual = torch empty expected = assertRaises AssertionError torch testing assert_close actual expected test_mapping_mismatching_values_msg t = torch tensor t = torch tensor actual = t b t expected = t b t assertRaisesRegex AssertionError re escape item b torch testing assert_close actual expected TestAssertCloseSparseCOO TestCase test_matching_coalesced indices = values = actual = torch sparse_coo_tensor indices values size= coalesce expected = actual clone fn assert_close_with_inputs actual expected fn test_matching_uncoalesced indices = values = actual = torch sparse_coo_tensor indices values size= expected = actual clone fn assert_close_with_inputs actual expected fn test_mismatching_sparse_dims t = torch randn actual = t to_sparse expected = t to_sparse fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape number sparse dimensions sparse COO tensors fn test_mismatching_nnz actual_indices = actual_values = actual = torch sparse_coo_tensor actual_indices actual_values size= expected_indices = expected_values = expected = torch sparse_coo_tensor expected_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape number specified values sparse COO tensors fn test_mismatching_indices_msg actual_indices = actual_values = actual = torch sparse_coo_tensor actual_indices actual_values size= expected_indices = expected_values = expected = torch sparse_coo_tensor expected_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse COO indices fn test_mismatching_values_msg actual_indices = actual_values = actual = torch sparse_coo_tensor actual_indices actual_values size= expected_indices = expected_values = expected = torch sparse_coo_tensor expected_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse COO values fn unittest skipIf IS_FBCODE IS_SANDCASTLE Not all sandcastle jobs support CSR testing TestAssertCloseSparseCSR TestCase test_matching crow_indices = col_indices = values = actual = torch sparse_csr_tensor crow_indices col_indices values size= expected = actual clone fn assert_close_with_inputs actual expected fn test_mismatching_crow_indices_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_csr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = expected_col_indices = actual_col_indices expected_values = actual_values expected = torch sparse_csr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSR crow_indices fn test_mismatching_col_indices_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_csr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = actual_crow_indices expected_col_indices = expected_values = actual_values expected = torch sparse_csr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSR col_indices fn test_mismatching_values_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_csr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = actual_crow_indices expected_col_indices = actual_col_indices expected_values = expected = torch sparse_csr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSR values fn unittest skipIf IS_FBCODE IS_SANDCASTLE Not all sandcastle jobs support CSC testing TestAssertCloseSparseCSC TestCase test_matching ccol_indices = row_indices = values = actual = torch sparse_csc_tensor ccol_indices row_indices values size= expected = actual clone fn assert_close_with_inputs actual expected fn test_mismatching_ccol_indices_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_csc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = expected_row_indices = actual_row_indices expected_values = actual_values expected = torch sparse_csc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSC ccol_indices fn test_mismatching_row_indices_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_csc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = actual_ccol_indices expected_row_indices = expected_values = actual_values expected = torch sparse_csc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSC row_indices fn test_mismatching_values_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_csc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = actual_ccol_indices expected_row_indices = actual_row_indices expected_values = expected = torch sparse_csc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse CSC values fn unittest skipIf IS_FBCODE IS_SANDCASTLE Not all sandcastle jobs support BSR testing TestAssertCloseSparseBSR TestCase test_matching crow_indices = col_indices = values = actual = torch sparse_bsr_tensor crow_indices col_indices values size= expected = actual clone fn assert_close_with_inputs actual expected fn test_mismatching_crow_indices_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_bsr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = expected_col_indices = actual_col_indices expected_values = actual_values expected = torch sparse_bsr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSR crow_indices fn test_mismatching_col_indices_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_bsr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = actual_crow_indices expected_col_indices = expected_values = actual_values expected = torch sparse_bsr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSR col_indices fn test_mismatching_values_msg actual_crow_indices = actual_col_indices = actual_values = actual = torch sparse_bsr_tensor actual_crow_indices actual_col_indices actual_values size= expected_crow_indices = actual_crow_indices expected_col_indices = actual_col_indices expected_values = expected = torch sparse_bsr_tensor expected_crow_indices expected_col_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSR values fn unittest skipIf IS_FBCODE IS_SANDCASTLE Not all sandcastle jobs support BSC testing TestAssertCloseSparseBSC TestCase test_matching ccol_indices = row_indices = values = actual = torch sparse_bsc_tensor ccol_indices row_indices values size= expected = actual clone fn assert_close_with_inputs actual expected fn test_mismatching_ccol_indices_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_bsc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = expected_row_indices = actual_row_indices expected_values = actual_values expected = torch sparse_bsc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSC ccol_indices fn test_mismatching_row_indices_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_bsc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = actual_ccol_indices expected_row_indices = expected_values = actual_values expected = torch sparse_bsc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSC row_indices fn test_mismatching_values_msg actual_ccol_indices = actual_row_indices = actual_values = actual = torch sparse_bsc_tensor actual_ccol_indices actual_row_indices actual_values size= expected_ccol_indices = actual_ccol_indices expected_row_indices = actual_row_indices expected_values = expected = torch sparse_bsc_tensor expected_ccol_indices expected_row_indices expected_values size= fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError re escape Sparse BSC values fn TestAssertCloseQuantized TestCase test_mismatching_is_quantized actual = torch tensor expected = torch quantize_per_tensor actual scale= zero_point= dtype=torch qint fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError is_quantized fn test_mismatching_qscheme t = torch tensor actual = torch quantize_per_tensor t scale= zero_point= dtype=torch qint expected = torch quantize_per_channel t scales=torch tensor zero_points=torch tensor axis= dtype=torch qint fn assert_close_with_inputs actual expected assertRaisesRegex AssertionError qscheme fn test_matching_per_tensor actual = torch quantize_per_tensor torch tensor scale= zero_point= dtype=torch qint expected = actual clone fn assert_close_with_inputs actual expected fn test_matching_per_channel actual = torch quantize_per_channel torch tensor scales=torch tensor zero_points=torch tensor axis= dtype=torch qint expected = actual clone fn assert_close_with_inputs actual expected fn TestMakeTensor TestCase supported_dtypes = dtypes torch bool torch uint torch int torch int torch int torch int torch float torch bfloat torch float torch float torch complex torch complex torch complex supported_dtypes parametrize shape parametrize splat_shape False True test_smoke dtype device shape splat_shape t = torch testing make_tensor shape splat_shape shape dtype=dtype device=device assertIsInstance t torch Tensor assertEqual t shape shape assertEqual t dtype dtype assertEqual t device torch device device supported_dtypes parametrize requires_grad False True test_requires_grad dtype device requires_grad make_tensor = functools partial torch testing make_tensor dtype=dtype device=device requires_grad=requires_grad requires_grad dtype is_floating_point dtype is_complex t = make_tensor assertEqual t requires_grad requires_grad assertRaisesRegex ValueError ` requires_grad=True ` supported boolean integral dtypes make_tensor supported_dtypes parametrize noncontiguous False True parametrize shape test_noncontiguous dtype device noncontiguous shape numel = functools reduce operator mul shape t = torch testing make_tensor shape dtype=dtype device=device noncontiguous=noncontiguous assertEqual t is_contiguous noncontiguous numel supported_dtypes parametrize memory_format_and_shape None torch contiguous_format torch channels_last torch channels_last_ d torch preserve_format test_memory_format dtype device memory_format_and_shape memory_format shape = memory_format_and_shape t = torch testing make_tensor shape dtype=dtype device=device memory_format=memory_format assertTrue t is_contiguous memory_format=torch contiguous_format memory_format None memory_format supported_dtypes test_noncontiguous_memory_format dtype device assertRaisesRegex ValueError ` noncontiguous ` ` memory_format ` mutually exclusive torch testing make_tensor dtype=dtype device=device noncontiguous=True memory_format=torch channels_last supported_dtypes test_exclude_zero dtype device t = torch testing make_tensor _ dtype=dtype device=device exclude_zero=True low=- high= assertTrue t = all supported_dtypes test_low_high_smoke dtype device low_inclusive high_exclusive = t = torch testing make_tensor _ dtype=dtype device=device low=low_inclusive high=high_exclusive dtype is_complex t = torch view_as_real t assertTrue t = low_inclusive t high_exclusive all supported_dtypes test_low_high_default_smoke dtype device low_inclusive high_exclusive = torch bool torch uint dict fromkeys torch int torch int torch int torch int - get dtype - t = torch testing make_tensor _ dtype=dtype device=device low=low_inclusive high=high_exclusive dtype is_complex t = torch view_as_real t assertTrue t = low_inclusive t high_exclusive all parametrize low_high - parametrize value_types list itertools product int float repeat= supported_dtypes test_low_ge_high dtype device low_high value_types low high = value_type value value value_type zip low_high value_types low == high dtype is_floating_point dtype is_complex assertWarnsRegex FutureWarning Passing ` low==high ` ` torch testing make_tensor ` floating complex types deprecated t = torch testing make_tensor _ dtype=dtype device=device low=low high=high assertEqual t torch full_like t complex low low dtype is_complex low assertRaisesRegex ValueError ` low ` must less than ` high ` torch testing make_tensor dtype=dtype device=device low=low high=high supported_dtypes parametrize low_high None torch nan torch nan None torch nan torch nan test_low_high_nan dtype device low_high low high = low_high assertRaisesRegex ValueError ` low ` ` high ` cannot NaN torch testing make_tensor dtype=dtype device=device low=low high=high supported_dtypes test_low_high_outside_valid_range dtype device make_tensor = functools partial torch testing make_tensor dtype=dtype device=device get_dtype_limits dtype dtype torch bool info = torch finfo dtype is_floating_point dtype is_complex torch iinfo dtype We using integer bounds here because otherwise would impossible pass ` low ` ` high ` outside their valid range Python uses bit floating point numbers thus trying do something like ` torch ffinfo torch float max ` will always result ` inf ` On flipside Pythons ` int ` unbounded int info min int info max lowest_inclusive highest_inclusive = get_dtype_limits dtype assertRaisesRegex ValueError low high = - - lowest_inclusive == lowest_inclusive lowest_inclusive make_tensor low=low high=high assertRaisesRegex ValueError make_tensor low=highest_inclusive high=highest_inclusive dtypes torch bool torch uint torch int torch int torch int torch int test_low_high_boolean_integral dtype device shape = _ eps = e- actual = torch testing make_tensor shape dtype=dtype device=device low=- - eps high= - eps expected = torch zeros shape dtype=dtype device=device torch testing assert_close actual expected dtypes torch bool torch uint torch int torch int torch int torch int test_low_high_boolean_integral dtype device shape = _ dtype torch bool low = dtype torch int Due its internals ` make_tensor ` able sample ` torch iinfo torch int max ` low = torch iinfo dtype max - low = torch iinfo dtype max high = low + actual = torch testing make_tensor shape dtype=dtype device=device low=low high=high expected = torch full shape low dtype=dtype device=device torch testing assert_close actual expected instantiate_device_type_tests TestMakeTensor globals _get_test_names_for_test_class test_cls Convenience function get all test names given test test_names = f test_cls __name__ key key test_cls __dict__ key startswith test_ sorted test_names _get_test_funcs_for_test_class test_cls Convenience function get all test function parametrized_name pairs given test test_funcs = getattr test_cls key key key test_cls __dict__ key startswith test_ test_funcs TestTestParametrization TestCase test_default_names TestParametrized TestCase parametrize x range test_default_names x pass parametrize x y test_two_things_default_names x y pass instantiate_parametrized_tests TestParametrized expected_test_names = TestParametrized test_default_names_x_ TestParametrized test_default_names_x_ TestParametrized test_default_names_x_ TestParametrized test_default_names_x_ TestParametrized test_default_names_x_ TestParametrized test_two_things_default_names_x_ _y_ TestParametrized test_two_things_default_names_x_ _y_ TestParametrized test_two_things_default_names_x_ _y_ test_names = _get_test_names_for_test_class TestParametrized assertEqual expected_test_names test_names test_name_fn TestParametrized TestCase parametrize bias False True name_fn=lambda b bias b no_bias test_custom_names bias pass parametrize x name_fn=str parametrize y name_fn=str parametrize z name_fn=str test_three_things_composition_custom_names x y z pass parametrize x y name_fn=lambda x y f x __ y test_two_things_custom_names_alternate x y pass instantiate_parametrized_tests TestParametrized expected_test_names = TestParametrized test_custom_names_bias TestParametrized test_custom_names_no_bias TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_three_things_composition_custom_names_ _ _ TestParametrized test_two_things_custom_names_alternate_ __ TestParametrized test_two_things_custom_names_alternate_ __ TestParametrized test_two_things_custom_names_alternate_ __ test_names = _get_test_names_for_test_class TestParametrized assertEqual expected_test_names test_names test_reparametrize include_is_even_arg test_name param_kwargs x = param_kwargs x is_even = x == new_param_kwargs = dict param_kwargs new_param_kwargs is_even = is_even is_even_suffix = _even is_even _odd new_test_name = f test_name is_even_suffix yield new_test_name new_param_kwargs exclude_odds test_name param_kwargs x = param_kwargs x is_even = x == yield None is_even test_name param_kwargs TestParametrized TestCase reparametrize parametrize x range include_is_even_arg test_foo x is_even pass reparametrize parametrize x range exclude_odds test_bar x pass instantiate_parametrized_tests TestParametrized expected_test_names = TestParametrized test_bar_x_ TestParametrized test_bar_x_ TestParametrized test_bar_x_ TestParametrized test_foo_x_ _even TestParametrized test_foo_x_ _odd TestParametrized test_foo_x_ _even TestParametrized test_foo_x_ _odd TestParametrized test_foo_x_ _even test_names = _get_test_names_for_test_class TestParametrized assertEqual expected_test_names test_names test_subtest_names TestParametrized TestCase parametrize bias subtest True name= bias subtest False name= no_bias test_custom_names bias pass parametrize x y subtest name= double subtest name= triple subtest name= quadruple test_two_things_custom_names x y pass instantiate_parametrized_tests TestParametrized expected_test_names = TestParametrized test_custom_names_bias TestParametrized test_custom_names_no_bias TestParametrized test_two_things_custom_names_double TestParametrized test_two_things_custom_names_quadruple TestParametrized test_two_things_custom_names_triple test_names = _get_test_names_for_test_class TestParametrized assertEqual expected_test_names test_names test_apply_param_specific_decorators Test decorators can applied per-param basis test_dec func func _decorator_applied = True func TestParametrized TestCase parametrize x subtest name= one subtest name= two decorators= test_dec subtest name= three test_param x pass instantiate_parametrized_tests TestParametrized test_func name _get_test_funcs_for_test_class TestParametrized assertEqual hasattr test_func _decorator_applied name == test_param_two test_compose_param_specific_decorators Test multiple per-param decorators compose correctly test_dec func func _decorator_applied = True func TestParametrized TestCase parametrize x subtest subtest decorators= test_dec subtest parametrize y subtest False decorators= test_dec subtest True test_param x y pass instantiate_parametrized_tests TestParametrized test_func name _get_test_funcs_for_test_class TestParametrized Decorator should applied whenever either x == y == False should_apply = x_ name y_False name assertEqual hasattr test_func _decorator_applied should_apply test_modules_decorator_misuse_error Test modules errors out when used instantiate_parametrized_tests TestParametrized TestCase modules module_db test_modules module_info pass assertRaisesRegex RuntimeError intended used device-specific context instantiate_parametrized_tests TestParametrized test_ops_decorator_misuse_error Test ops errors out when used instantiate_parametrized_tests TestParametrized TestCase ops op_db test_ops module_info pass assertRaisesRegex RuntimeError intended used device-specific context instantiate_parametrized_tests TestParametrized test_multiple_handling_of_same_param_error Test multiple decorators handling same param errors out TestParametrized TestCase parametrize x range parametrize x range test_param x pass assertRaisesRegex RuntimeError multiple parametrization decorators instantiate_parametrized_tests TestParametrized parametrize x subtest decorators= unittest expectedFailure test_subtest_expected_failure x x == raise RuntimeError Boom parametrize x subtest decorators= unittest expectedFailure parametrize y subtest decorators= unittest expectedFailure test_two_things_subtest_expected_failure x y x == y == raise RuntimeError Boom TestTestParametrizationDeviceType TestCase test_unparametrized_names device This test exists protect against regressions device dtype test naming due parametrization logic device = device_type TestParametrized TestCase test_device_specific device pass dtypes torch float torch float test_device_dtype_specific device dtype pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_device_dtype_specific_ _float test_device_dtype_specific_ _float test_device_specific_ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_empty_param_names device If no param names passed ensure things still work without parametrization device = device_type TestParametrized TestCase parametrize test_foo device pass parametrize range test_bar device pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_bar_ test_foo_ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_empty_param_list device If no param values passed ensure helpful error message thrown In wild could indicate reuse exhausted generator device = device_type generator = range TestParametrized TestCase parametrize x generator test_foo device x pass Reuse generator first test function parametrize y generator test_bar device y pass assertRaisesRegex ValueError An empty arg_values passed locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device test_default_names device device = device_type TestParametrized TestCase parametrize x range test_default_names device x pass parametrize x y test_two_things_default_names device x y pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_default_names_x_ _ test_default_names_x_ _ test_default_names_x_ _ test_default_names_x_ _ test_default_names_x_ _ test_two_things_default_names_x_ _y_ _ test_two_things_default_names_x_ _y_ _ test_two_things_default_names_x_ _y_ _ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_default_name_non_primitive device device = device_type TestParametrized TestCase parametrize x foo object test_default_names device x pass parametrize x y object object object object test_two_things_default_names device x y pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = sorted name format device_cls __name__ device name test_default_names_x_ _ test_default_names_x_ _ _ test_default_names_x_foo_ test_default_names_x _ test_two_things_default_names_x_ _y _ test_two_things_default_names_x _y_ _ _ test_two_things_default_names_x _y _ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_name_fn device device = device_type TestParametrized TestCase parametrize bias False True name_fn=lambda b bias b no_bias test_custom_names device bias pass parametrize x name_fn=str parametrize y name_fn=str parametrize z name_fn=str test_three_things_composition_custom_names device x y z pass parametrize x y name_fn=lambda x y f x __ y test_two_things_custom_names_alternate device x y pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_custom_names_bias_ test_custom_names_no_bias_ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_three_things_composition_custom_names_ _ _ _ test_two_things_custom_names_alternate_ __ _ test_two_things_custom_names_alternate_ __ _ test_two_things_custom_names_alternate_ __ _ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_subtest_names device device = device_type TestParametrized TestCase parametrize bias subtest True name= bias subtest False name= no_bias test_custom_names device bias pass parametrize x y subtest name= double subtest name= triple subtest name= quadruple test_two_things_custom_names device x y pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_custom_names_bias_ test_custom_names_no_bias_ test_two_things_custom_names_double_ test_two_things_custom_names_quadruple_ test_two_things_custom_names_triple_ test_names = _get_test_names_for_test_class device_cls assertEqual expected_test_names test_names test_ops_composition_names device device = device_type TestParametrized TestCase ops op_db parametrize flag False True lambda f flag_enabled f flag_disabled test_op_parametrized device dtype op flag pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = op op_db dtype op supported_dtypes torch device device type flag_part flag_disabled flag_enabled expected_name = f device_cls __name__ test_op_parametrized_ op formatted_name _ flag_part _ device _ dtype_name dtype noqa B expected_test_names append expected_name test_names = _get_test_names_for_test_class device_cls assertEqual sorted expected_test_names sorted test_names test_modules_composition_names device device = device_type TestParametrized TestCase modules module_db parametrize flag False True lambda f flag_enabled f flag_disabled test_module_parametrized device dtype module_info training flag pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = module_info module_db dtype module_info dtypes flag_part flag_disabled flag_enabled expected_train_modes = train_mode eval_mode module_info train_and_eval_differ training_part expected_train_modes expected_name = test_module_parametrized_ _ _ _ format device_cls __name__ module_info formatted_name _ + training_part len training_part flag_part device dtype_name dtype expected_test_names append expected_name test_names = _get_test_names_for_test_class device_cls assertEqual sorted expected_test_names sorted test_names test_ops_decorator_applies_op_and_param_specific_decorators device Test decorators can applied per-op per-param basis Create test op OpInfo entry decorator apply test_op x -x test_dec func func _decorator_applied = True func test_op_info = OpInfo test_op op=test_op dtypes=floating_types sample_inputs_func=lambda _ decorators= DecorateInfo test_dec TestParametrized test_op_param device_type= cpu dtypes= torch float active_if=lambda p p x == TestParametrized TestCase ops op_db + test_op_info parametrize x test_op_param device dtype op x pass ops op_db + test_op_info parametrize y subtest subtest decorators= test_dec test_other device dtype op y pass decorateIf test_dec lambda p p dtype == torch int ops op_db test_three device dtype op pass device = device_type locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper test_func name _get_test_funcs_for_test_class device_cls should_apply = name == test_op_param_test_op_x_ _cpu_float test_other name y_ name test_three name name endswith _int assertEqual hasattr test_func _decorator_applied should_apply test_modules_decorator_applies_module_and_param_specific_decorators device Test decorators can applied per-module per-param basis Create test module ModuleInfo entry decorator apply TestModule torch nn Module __init__ - None super __init__ x = torch nn Parameter torch randn forward y x + y test_dec func func _decorator_applied = True func test_module_info = ModuleInfo TestModule module_inputs_func=lambda _ decorators= DecorateInfo test_dec TestParametrized test_module_param device_type= cpu dtypes= torch float active_if=lambda p p x == TestParametrized TestCase modules module_db + test_module_info parametrize x test_module_param device dtype module_info training x pass modules module_db + test_module_info parametrize y subtest subtest decorators= test_dec test_other device dtype module_info training y pass decorateIf test_dec lambda p p dtype == torch float modules module_db test_three device dtype module_info pass device = device_type locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper test_func name _get_test_funcs_for_test_class device_cls should_apply = name == test_module_param_TestModule_x_ _cpu_float test_other name y_ name test_three name name endswith float assertEqual hasattr test_func _decorator_applied should_apply test_param_specific_decoration device test_dec func func _decorator_applied = True func TestParametrized TestCase decorateIf test_dec lambda params params x == params y parametrize x range parametrize y False True test_param x y pass device = device_type locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper test_func name _get_test_funcs_for_test_class device_cls should_apply = test_param_x_ _y_True name assertEqual hasattr test_func _decorator_applied should_apply test_dtypes_composition_valid device Test checks parametrize dtypes compose expected when parametrize doesn t set dtype device = device_type TestParametrized TestCase dtypes torch float torch float parametrize x range test_parametrized x dtype pass locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device device_cls = locals_dict f TestParametrized device upper expected_test_names = name format device_cls __name__ device name test_parametrized_x_ _ _float test_parametrized_x_ _ _float test_parametrized_x_ _ _float test_parametrized_x_ _ _float test_parametrized_x_ _ _float test_parametrized_x_ _ _float test_names = _get_test_names_for_test_class device_cls assertEqual sorted expected_test_names sorted test_names test_dtypes_composition_invalid device Test checks dtypes cannot composed parametrization decorators when they also try set dtype device = device_type TestParametrized TestCase dtypes torch float torch float parametrize dtype torch int torch int test_parametrized dtype pass assertRaisesRegex RuntimeError handled multiple times locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device Verify proper error behavior ops + dtypes both try set dtype TestParametrized TestCase dtypes torch float torch float ops op_db test_parametrized op dtype pass assertRaisesRegex RuntimeError handled multiple times locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device test_multiple_handling_of_same_param_error device Test multiple decorators handling same param errors out Both modules ops handle dtype param TestParametrized TestCase ops op_db modules module_db test_param device dtype op module_info training pass assertRaisesRegex RuntimeError handled multiple times locals_dict = dict locals instantiate_device_type_tests TestParametrized locals_dict only_for=device parametrize x subtest decorators= unittest expectedFailure test_subtest_expected_failure device x x == raise RuntimeError Boom parametrize x subtest decorators= unittest expectedFailure parametrize y subtest decorators= unittest expectedFailure test_two_things_subtest_expected_failure device x y x == y == raise RuntimeError Boom instantiate_parametrized_tests TestTestParametrization instantiate_device_type_tests TestTestParametrizationDeviceType globals TestImports TestCase classmethod _check_python_output cls program - str subprocess check_output sys executable -W always -c program stderr=subprocess STDOUT On Windows opening subprocess default CWD makes ` torch ` fail so just set CWD script s directory cwd=os path dirname os path realpath __file__ decode utf- The test flaky ROCm XPU has been open close multiple times https github com pytorch pytorch issues skipIfRocm test_circular_dependencies - None Checks all modules inside torch can imported Prevents regression reported https github com pytorch pytorch issues ignored_modules = torch utils tensorboard deps tensorboard torch distributed elastic rendezvous depps etcd torch backends _coreml depends pycoreml torch contrib something weird torch testing _internal distributed just fails torch ao pruning _experimental depends pytorch_lightning user-facing torch onnx _internal depends onnx-script torch _inductor runtime triton_helpers depends triton torch _inductor codegen cuda depends cutlass torch _inductor codegen cutedsl depends cutlass torch distributed benchmarks depends RPC DDP Optim torch distributed examples requires CUDA torchvision torch distributed tensor examples example scripts torch distributed _tools sac_ilp depends pulp torch csrc files here devtools part torch torch include torch include files after install IS_WINDOWS IS_MACOS IS_JETSON Distributed should importable Windows except nn api Mac IS_MACOS IS_JETSON ignored_modules append torch distributed ignored_modules append torch distributed nn api ignored_modules append torch distributed optim ignored_modules append torch distributed rpc ignored_modules append torch testing _internal dist_utils And these both end up transitive dependencies distributed ignored_modules append torch nn parallel _replicated_tensor_ddp_interop ignored_modules append torch testing _internal common_fsdp ignored_modules append torch testing _internal common_distributed torch_dir = os path dirname torch __file__ base _ files os walk torch_dir prefix = os path relpath base os path dirname torch_dir replace os path sep f files f endswith py continue mod_name = f prefix f - f = __init__ py prefix Do attempt executable modules f == __main__ py continue any mod_name startswith x x ignored_modules continue try mod = importlib import_module mod_name except Exception e raise RuntimeError f Failed mod_name e e assertTrue inspect ismodule mod test_lazy_imports_are_lazy - None out = _check_python_output sys torch print all x sys modules x torch _lazy_modules assertEqual out strip True test_no_warning_on_import - None out = _check_python_output torch assertEqual out test_not_import_sympy - None out = _check_python_output torch sys print sympy sys modules assertEqual out strip True PyTorch should depend SymPy time importing SymPy very slow \n See beginning following blog post how profile find which file importing sympy \n https dev-discuss pytorch org t delving-into-what-happens-when-you-import-torch \n\n If you hit error you may want \n - Refactor your code avoid depending sympy files you may need depend\n - Use TYPE_CHECKING you using sympy + strings you using sympy type annotations\n - Import things depend SymPy locally parametrize path torch functorch test_no_mutate_global_logging_on_import path - None Calling logging basicConfig among other things modifies global logging state It OK modify global logging state ` torch ` other submodules we own because users do expect expected = string ascii_lowercase commands = logging f path _logger = logging getLogger torch_test_testing logging root addHandler logging StreamHandler logging root setLevel logging INFO f _logger info expected out = _check_python_output join commands assertEqual out strip expected TestOpInfos TestCase test_sample_input - None b c d e = object _ range Construction natural syntax s = SampleInput b c d=d e=e assert s input assert s args == b c assert s kwargs == dict d=d e=e Construction explicit args kwargs s = SampleInput args= b kwargs=dict c=c d=d e=e assert s input assert s args == b assert s kwargs == dict c=c d=d e=e Construction mixed form will error assertRaises AssertionError s = SampleInput b c args= d e assertRaises AssertionError s = SampleInput b c kwargs=dict d=d e=e assertRaises AssertionError s = SampleInput args= b c d=d e=e assertRaises AssertionError s = SampleInput b c=c kwargs=dict d=d e=e Mixing metadata into natural construction will error assertRaises AssertionError s = SampleInput b name= foo assertRaises AssertionError s = SampleInput b output_process_fn_grad=lambda x x assertRaises AssertionError s = SampleInput b broadcasts_input=True But when only input given metadata allowed backward compatibility s = SampleInput broadcasts_input=True assert s input assert s broadcasts_input test_sample_input_metadata - None b = object _ range s = SampleInput b=b assertIs s output_process_fn_grad None None assertFalse s broadcasts_input assertEqual s name s = s with_metadata output_process_fn_grad=lambda x broadcasts_input=True name= foo assertIs s s assertIs s output_process_fn_grad None assertTrue s broadcasts_input assertEqual s name foo Tests validate various sample generating functions each OpInfo TestOpInfoSampleFunctions TestCase ops op_db dtypes=OpDTypes any_one test_opinfo_sample_generators device dtype op Test op sample_inputs doesn t generate multiple samples when called samples = op sample_inputs device dtype assertIsInstance samples Iterator ops op op op_db op reference_inputs_func None dtypes=OpDTypes any_one test_opinfo_reference_generators device dtype op Test op reference_inputs doesn t generate multiple samples when called samples = op reference_inputs device dtype assertIsInstance samples Iterator ops op op op_db op error_inputs_func None dtypes=OpDTypes none test_opinfo_error_generators device op Test op error_inputs doesn t generate multiple inputs when called samples = op error_inputs device assertIsInstance samples Iterator instantiate_device_type_tests TestOpInfoSampleFunctions globals instantiate_parametrized_tests TestImports __name__ == __main__ run_tests