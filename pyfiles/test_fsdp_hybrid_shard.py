Owner s oncall distributed contextlib sys collections Counter enum auto Enum functools partial typing Optional torch torch distributed dist torch distributed fsdp _traversal_utils traversal_utils torch nn nn torch distributed device_mesh init_device_mesh torch distributed distributed_c d _rank_not_in_group torch distributed fsdp FullyShardedDataParallel FSDP ShardingStrategy StateDictType torch distributed fsdp _init_utils _init_intra_and_inter_node_groups HYBRID_SHARDING_STRATEGIES torch distributed fsdp wrap ModuleWrapPolicy torch nn TransformerDecoderLayer TransformerEncoderLayer torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp DEVICEInitMode FSDPInitMode FSDPTest TransformerWithSharedParams torch testing _internal common_utils instantiate_parametrized_tests run_tests TEST_WITH_DEV_DBG_ASAN dist is_available print Distributed available skipping tests file=sys stderr sys exit TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit device_type = acc type acc = torch accelerator current_accelerator cpu contextlib contextmanager patch_allreduce new_allreduce Patches dist all_reduce new all_reduce restores upon exiting orig_ar = dist all_reduce dist all_reduce = new_allreduce try yield finally dist all_reduce = orig_ar contextlib contextmanager patch_reduce_scatter new_reduce_scatter Patches dist reduce_scatter_tensor new reduce_scatter_tensor restores upon exiting orig_reduce_scatter = dist reduce_scatter_tensor dist reduce_scatter_tensor = new_reduce_scatter try yield finally dist reduce_scatter_tensor = orig_reduce_scatter MyModel nn Module __init__ - None super __init__ lin = nn Linear lin = nn Linear lin = nn Linear forward x lin lin lin x ShardingStrategyMode Enum ALL_HYBRID_SHARD = auto MIXED_HYBRID_FULL_SHARD = auto TestFSDPHybridShard FSDPTest property world_size max torch accelerator device_count property process_group dist distributed_c d _get_default_group skip_if_lt_x_gpu test_raises_manual_wrap_hybrid_shard_when_none_policy model = MyModel device_type err_ctx = assertRaisesRegex ValueError requires explicit specification process group device_mesh err_ctx model = FSDP model sharding_strategy=ShardingStrategy HYBRID_SHARD err_ctx model = FSDP model sharding_strategy=ShardingStrategy _HYBRID_SHARD_ZERO skip_if_lt_x_gpu test_hsdp_save_load_state_dict model = MyModel device_type num_node_devices = torch accelerator device_count shard_rank_lists = list range num_node_devices list range num_node_devices num_node_devices shard_groups = dist new_group shard_rank_lists dist new_group shard_rank_lists my_shard_group = shard_groups rank shard_rank_lists shard_groups my_replicate_group = None my_rank = rank Create groups like etc assign appropriately shard_factor = len shard_rank_lists i range num_node_devices replicate_group_ranks = list range i num_node_devices shard_factor replicate_group = dist new_group replicate_group_ranks my_rank replicate_group_ranks my_replicate_group = replicate_group fsdp_ctor = partial FSDP sharding_strategy=ShardingStrategy HYBRID_SHARD use_orig_params=True process_group= my_shard_group my_replicate_group model = fsdp_ctor model optim = torch optim AdamW model parameters Initialize optimizer states model torch randn sum backward optim step shard_g = model process_group replicate_g = model _inter_node_pg assert shard_g == my_shard_group assert replicate_g == my_replicate_group FSDP state_dict_type model StateDictType SHARDED_STATE_DICT msd = model state_dict osd = FSDP optim_state_dict model optim load_model = fsdp_ctor MyModel device_type load_optim = torch optim AdamW load_model parameters FSDP state_dict_type load_model StateDictType SHARDED_STATE_DICT load_model load_state_dict msd FSDP optim_state_dict_to_load load_model load_optim osd load_optim load_state_dict osd skip_if_lt_x_gpu test_hsdp_sync_module_state model = MyModel device_type num_node_devices = torch accelerator device_count shard_rank_lists = list range num_node_devices list range num_node_devices num_node_devices shard_groups = dist new_group shard_rank_lists dist new_group shard_rank_lists my_shard_group = shard_groups rank shard_rank_lists shard_groups my_replicate_group = None my_rank = rank Create groups like etc assign appropriately shard_factor = len shard_rank_lists i range num_node_devices replicate_group_ranks = list range i num_node_devices shard_factor replicate_group = dist new_group replicate_group_ranks my_rank replicate_group_ranks my_replicate_group = replicate_group nn init constant_ model lin weight rank nn init constant_ model lin weight rank nn init constant_ model lin weight rank fsdp_ctor = partial FSDP sharding_strategy=ShardingStrategy HYBRID_SHARD use_orig_params=True sync_module_states=True process_group= my_shard_group my_replicate_group model = fsdp_ctor model FSDP state_dict_type model StateDictType FULL_STATE_DICT assertTrue model lin weight == all assertTrue model lin weight == all assertTrue model lin weight == all skip_if_lt_x_gpu test_invalid_pg_specification_raises pol = ModuleWrapPolicy nn Linear model = MyModel device_type assertRaisesRegex ValueError Expected process_group passed model = FSDP model auto_wrap_policy=pol process_group=self process_group sharding_strategy=ShardingStrategy HYBRID_SHARD TODO - add test ZeRO- style sharding ensure params resharded after forward skip_if_lt_x_gpu test_fsdp_hybrid_shard_basic_setup Tests basic functionality HYBRID_SHARD _HYBRID_SHARD_ZERO Inter intra-node process groups correctly setup Process groups same across FSDP wrapped instances reduce_scatter allreduce called expected no times run_subtests hsdp_sharding_strategy ShardingStrategy HYBRID_SHARD ShardingStrategy _HYBRID_SHARD_ZERO sharding_strategy_mode ShardingStrategyMode ALL_HYBRID_SHARD ShardingStrategyMode MIXED_HYBRID_FULL_SHARD use_orig_params False True use_device_mesh False True _test_fsdp_hybrid_shard_basic_setup _test_fsdp_hybrid_shard_basic_setup hsdp_sharding_strategy ShardingStrategy sharding_strategy_mode ShardingStrategyMode use_orig_params bool use_device_mesh bool use_device_mesh device_mesh = init_device_mesh device_type world_size device_mesh = None hsdp_model = _init_hsdp_model hsdp_sharding_strategy sharding_strategy_mode use_orig_params hsdp_device_mesh=device_mesh All FSDP modules should have state process_group process group over which shard default process group state _inter_node_pg process group containing only rank intra_node_pgs = set inter_node_pgs = set fsdp_module hsdp_model fsdp_modules hsdp_model TODO This needs replaced we deprecate ` FSDP sharding_strategy ` only use handle one https github com pytorch pytorch issues fsdp_module sharding_strategy HYBRID_SHARDING_STRATEGIES assertEqual sharding_strategy_mode ShardingStrategyMode MIXED_HYBRID_FULL_SHARD assertEqual fsdp_module sharding_strategy ShardingStrategy FULL_SHARD continue process_group should across node which just whole world here assertEqual dist get_world_size fsdp_module process_group dist get_world_size process_group intra_node_pgs add fsdp_module process_group inter_node_pg = fsdp_module _inter_node_pg inter_node_pgs add inter_node_pg assertEqual dist get_world_size inter_node_pg assertFalse _rank_not_in_group inter_node_pg assertEqual hsdp_sharding_strategy fsdp_module sharding_strategy All fsdp modules should share same process groups assertEqual len intra_node_pgs assertEqual len inter_node_pgs orig_ar = dist all_reduce orig_rs = dist reduce_scatter_tensor patched_collective orig_collective counter args kwargs counter orig_collective += orig_collective args kwargs cntr = Counter patched_allreduce = partial patched_collective orig_ar cntr patched_reduce_scatter = partial patched_collective orig_rs cntr patch_allreduce patched_allreduce patch_reduce_scatter patched_reduce_scatter inp = hsdp_model get_input device=torch accelerator current_device_index out = hsdp_model inp inp loss = hsdp_model get_loss inp out loss backward sharding_strategy_mode == ShardingStrategyMode ALL_HYBRID_SHARD num_flat_params = len list traversal_utils _get_fsdp_handles hsdp_model assertEqual num_flat_params cntr orig_ar assertEqual num_flat_params cntr orig_rs sharding_strategy_mode == ShardingStrategyMode MIXED_HYBRID_FULL_SHARD num_hsdp_flat_params = len list traversal_utils _get_fsdp_handles hsdp_model transformer num_flat_params = len list traversal_utils _get_fsdp_handles hsdp_model assertEqual num_hsdp_flat_params cntr orig_ar assertEqual num_flat_params cntr orig_rs skip_if_lt_x_gpu test_fsdp_hybrid_shard_parity run_subtests hsdp_sharding_strategy ShardingStrategy HYBRID_SHARD ShardingStrategy _HYBRID_SHARD_ZERO use_orig_params False True _test_fsdp_hybrid_shard_parity _test_fsdp_hybrid_shard_parity hsdp_sharding_strategy ShardingStrategy use_orig_params bool fsdp_model = _init_fsdp_model use_orig_params global_pg = dist distributed_c d _get_default_group hsdp_pgs = _init_intra_and_inter_node_groups global_pg hsdp_model = _init_hsdp_model hsdp_sharding_strategy ShardingStrategyMode ALL_HYBRID_SHARD use_orig_params hsdp_process_groups=hsdp_pgs assert hsdp_model _inter_node_pg size HSDP model initialized without replication fsdp_optim = torch optim Adam fsdp_model parameters lr= e- hsdp_optim = torch optim Adam hsdp_model parameters lr= e- torch manual_seed global_pg rank + _ range inp = fsdp_model module get_input torch device device_type losses list torch Tensor = model optim fsdp_model fsdp_optim hsdp_model hsdp_optim optim zero_grad loss = model inp sum losses append loss loss backward optim step assertEqual losses losses _init_fsdp_model use_orig_params bool - nn Module auto_wrap_policy = ModuleWrapPolicy TransformerEncoderLayer TransformerDecoderLayer hsdp_kwargs = auto_wrap_policy auto_wrap_policy device_id torch accelerator current_device_index use_orig_params use_orig_params fsdp_model = TransformerWithSharedParams init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_BEFORE hsdp_kwargs deterministic=True fsdp_model _init_hsdp_model hsdp_sharding_strategy ShardingStrategy sharding_strategy_mode str use_orig_params bool hsdp_process_groups Optional tuple dist ProcessGroup dist ProcessGroup = None hsdp_device_mesh Optional = None assert hsdp_process_groups None hsdp_device_mesh None auto_wrap_policy = ModuleWrapPolicy TransformerEncoderLayer TransformerDecoderLayer hsdp_kwargs = device_id torch accelerator current_device_index auto_wrap_policy auto_wrap_policy sharding_strategy hsdp_sharding_strategy use_orig_params use_orig_params device_mesh hsdp_device_mesh sharding_strategy_mode == ShardingStrategyMode ALL_HYBRID_SHARD hsdp_model = TransformerWithSharedParams init hsdp_process_groups process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_BEFORE hsdp_kwargs deterministic=True sharding_strategy_mode == ShardingStrategyMode MIXED_HYBRID_FULL_SHARD model = TransformerWithSharedParams init hsdp_process_groups process_group FSDPInitMode NO_FSDP DEVICEInitMode DEVICE_BEFORE deterministic=True Use HSDP strategy transformer module model transformer = FSDP model transformer hsdp_kwargs Use ` FULL_SHARD ` embedding output projection hsdp_model = FSDP model device_id=torch accelerator current_device_index sharding_strategy=ShardingStrategy FULL_SHARD use_orig_params=use_orig_params hsdp_model instantiate_parametrized_tests TestFSDPHybridShard __name__ == __main__ run_tests