usr bin env python Generates matrix utilized through github actions Will output condensed version matrix pull request only includes latest version python we support built three different architectures CPU Latest CUDA Latest ROCM Latest XPU json os re pathlib Path typing Optional SCRIPT_DIR = Path __file__ absolute parent REPO_ROOT = SCRIPT_DIR parent parent CUDA_ARCHES = CUDA_STABLE = CUDA_ARCHES_FULL_VERSION = CUDA_ARCHES_CUDNN_VERSION = ROCM_ARCHES = XPU_ARCHES = xpu CPU_AARCH _ARCH = cpu-aarch CPU_S X_ARCH = cpu-s x CUDA_AARCH _ARCHES = -aarch -aarch -aarch -aarch PYTORCH_EXTRA_INSTALL_REQUIREMENTS = nvidia-cuda-nvrtc-cu == platform_system == Linux &#124; nvidia-cuda-runtime-cu == platform_system == Linux &#124; nvidia-cuda-cupti-cu == platform_system == Linux &#124; nvidia-cudnn-cu == platform_system == Linux &#124; nvidia-cublas-cu == platform_system == Linux &#124; nvidia-cufft-cu == platform_system == Linux &#124; nvidia-curand-cu == platform_system == Linux &#124; nvidia-cusolver-cu == platform_system == Linux &#124; nvidia-cusparse-cu == platform_system == Linux &#124; nvidia-cusparselt-cu == platform_system == Linux &#124; nvidia-nccl-cu == platform_system == Linux &#124; nvidia-nvshmem-cu == platform_system == Linux &#124; nvidia-nvtx-cu == platform_system == Linux &#124; nvidia-nvjitlink-cu == platform_system == Linux &#124; nvidia-cufile-cu == platform_system == Linux nvidia-cuda-nvrtc-cu == platform_system == Linux &#124; nvidia-cuda-runtime-cu == platform_system == Linux &#124; nvidia-cuda-cupti-cu == platform_system == Linux &#124; nvidia-cudnn-cu == platform_system == Linux &#124; nvidia-cublas-cu == platform_system == Linux &#124; nvidia-cufft-cu == platform_system == Linux &#124; nvidia-curand-cu == platform_system == Linux &#124; nvidia-cusolver-cu == platform_system == Linux &#124; nvidia-cusparse-cu == platform_system == Linux &#124; nvidia-cusparselt-cu == platform_system == Linux &#124; nvidia-nccl-cu == platform_system == Linux &#124; nvidia-nvshmem-cu == platform_system == Linux &#124; nvidia-nvtx-cu == platform_system == Linux &#124; nvidia-nvjitlink-cu == platform_system == Linux &#124; nvidia-cufile-cu == platform_system == Linux nvidia-cuda-nvrtc-cu == platform_system == Linux &#124; nvidia-cuda-runtime-cu == platform_system == Linux &#124; nvidia-cuda-cupti-cu == platform_system == Linux &#124; nvidia-cudnn-cu == platform_system == Linux &#124; nvidia-cublas-cu == platform_system == Linux &#124; nvidia-cufft-cu == platform_system == Linux &#124; nvidia-curand-cu == platform_system == Linux &#124; nvidia-cusolver-cu == platform_system == Linux &#124; nvidia-cusparse-cu == platform_system == Linux &#124; nvidia-cusparselt-cu == platform_system == Linux &#124; nvidia-nccl-cu == platform_system == Linux &#124; nvidia-nvshmem-cu == platform_system == Linux &#124; nvidia-nvtx-cu == platform_system == Linux &#124; nvidia-nvjitlink-cu == platform_system == Linux &#124; nvidia-cufile-cu == platform_system == Linux nvidia-cuda-nvrtc== platform_system == Linux &#124; nvidia-cuda-runtime== platform_system == Linux &#124; nvidia-cuda-cupti== platform_system == Linux &#124; nvidia-cudnn-cu == platform_system == Linux &#124; nvidia-cublas== platform_system == Linux &#124; nvidia-cufft== platform_system == Linux &#124; nvidia-curand== platform_system == Linux &#124; nvidia-cusolver== platform_system == Linux &#124; nvidia-cusparse== platform_system == Linux &#124; nvidia-cusparselt-cu == platform_system == Linux &#124; nvidia-nccl-cu == platform_system == Linux &#124; nvidia-nvshmem-cu == platform_system == Linux &#124; nvidia-nvtx== platform_system == Linux &#124; nvidia-nvjitlink== platform_system == Linux &#124; nvidia-cufile== platform_system == Linux xpu intel-cmplr-lib-rt== &#124; intel-cmplr-lib-ur== &#124; intel-cmplr-lic-rt== &#124; intel-sycl-rt== &#124; oneccl-devel== platform_system == Linux platform_machine == x _ &#124; oneccl== platform_system == Linux platform_machine == x _ &#124; impi-rt== platform_system == Linux platform_machine == x _ &#124; onemkl-sycl-blas== &#124; onemkl-sycl-dft== &#124; onemkl-sycl-lapack== &#124; onemkl-sycl-rng== &#124; onemkl-sycl-sparse== &#124; dpcpp-cpp-rt== &#124; intel-opencl-rt== &#124; mkl== &#124; intel-openmp== &#124; tbb== &#124; tcmlib== &#124; umf== &#124; intel-pti== Used tools nightly py PYTORCH_NIGHTLY_PIP_INDEX_URL = https download pytorch org whl nightly NIGHTLY_SOURCE_MATRIX = cpu dict name= cpu index_url=f PYTORCH_NIGHTLY_PIP_INDEX_URL cpu supported_platforms= Linux macOS Windows accelerator= cpu CUDA_NIGHTLY_SOURCE_MATRIX = f cuda- major minor dict name=f cuda- major minor index_url=f PYTORCH_NIGHTLY_PIP_INDEX_URL cu major minor supported_platforms= Linux Windows accelerator= cuda major minor map int version split version CUDA_ARCHES ROCM_NIGHTLY_SOURCE_MATRIX = f rocm- major minor dict name=f rocm- major minor index_url=f PYTORCH_NIGHTLY_PIP_INDEX_URL rocm major minor supported_platforms= Linux accelerator= rocm major minor map int version split version ROCM_ARCHES XPU_NIGHTLY_SOURCE_MATRIX = xpu dict name= xpu index_url=f PYTORCH_NIGHTLY_PIP_INDEX_URL xpu supported_platforms= Linux accelerator= xpu NIGHTLY_SOURCE_MATRIX update CUDA_NIGHTLY_SOURCE_MATRIX NIGHTLY_SOURCE_MATRIX update ROCM_NIGHTLY_SOURCE_MATRIX NIGHTLY_SOURCE_MATRIX update XPU_NIGHTLY_SOURCE_MATRIX get_nccl_wheel_version arch_version str - str requirements = map str strip re split &#124; PYTORCH_EXTRA_INSTALL_REQUIREMENTS arch_version next x x requirements x startswith nvidia-nccl split == read_nccl_pin arch_version str - str nccl_pin_path = REPO_ROOT ci docker ci_commit_pins f nccl-cu arch_version txt nccl_pin_path read_text strip validate_nccl_dep_consistency arch_version str - None nccl_release_tag = read_nccl_pin arch_version wheel_ver = get_nccl_wheel_version arch_version nccl_release_tag startswith f v wheel_ver raise RuntimeError f arch_version NCCL release tag version nccl_release_tag f does correspond wheel version wheel_ver arch_type arch_version str - str arch_version CUDA_ARCHES cuda arch_version ROCM_ARCHES rocm arch_version XPU_ARCHES xpu arch_version CPU_AARCH _ARCH cpu-aarch arch_version CPU_S X_ARCH cpu-s x arch_version CUDA_AARCH _ARCHES cuda-aarch arch_version should always cpu case cpu DEFAULT_TAG = os getenv RELEASE_VERSION_TAG main WHEEL_CONTAINER_IMAGES = gpu_arch f manylinux _ -builder cuda gpu_arch gpu_arch CUDA_ARCHES gpu_arch f manylinuxaarch -builder cuda gpu_arch replace -aarch gpu_arch CUDA_AARCH _ARCHES gpu_arch f manylinux _ -builder rocm gpu_arch gpu_arch ROCM_ARCHES xpu manylinux _ -builder xpu cpu manylinux _ -builder cpu cpu-aarch manylinux _ _aarch -builder cpu-aarch cpu-s x pytorch manylinuxs x-builder cpu-s x RELEASE = release DEBUG = debug LIBTORCH_CONTAINER_IMAGES dict str str = gpu_arch f libtorch-cxx -builder cuda gpu_arch gpu_arch CUDA_ARCHES gpu_arch f libtorch-cxx -builder rocm gpu_arch gpu_arch ROCM_ARCHES cpu libtorch-cxx -builder cpu FULL_PYTHON_VERSIONS = t t translate_desired_cuda gpu_arch_type str gpu_arch_version str - str cpu cpu cpu-aarch cpu cpu-s x cpu cuda f cu gpu_arch_version replace cuda-aarch f cu gpu_arch_version replace -aarch replace rocm f rocm gpu_arch_version xpu xpu get gpu_arch_type gpu_arch_version list_without in_list list str without list str - list str item item in_list item without generate_libtorch_matrix os str release_type str arches Optional list str = None libtorch_variants Optional list str = None - list dict str str arches None arches = cpu os == linux arches += CUDA_ARCHES arches += ROCM_ARCHES os == windows TODO huydhn Only build CUDA Linux This logic cleaned up windows_cuda_arches = CUDA_ARCHES copy windows_cuda_arches remove arches += windows_cuda_arches libtorch_variants None libtorch_variants = shared-with-deps shared-without-deps static-with-deps static-without-deps ret list dict str str = arch_version arches libtorch_variant libtorch_variants gpu_arch_type = arch_type arch_version gpu_arch_version = arch_version == cpu arch_version ROCm builds without-deps failed even ROCm runners skip now gpu_arch_type == rocm without-deps libtorch_variant continue ret append gpu_arch_type gpu_arch_type gpu_arch_version gpu_arch_version desired_cuda translate_desired_cuda gpu_arch_type gpu_arch_version libtorch_config release_type libtorch_variant libtorch_variant container_image LIBTORCH_CONTAINER_IMAGES arch_version split os windows windows-arm container_image_tag_prefix LIBTORCH_CONTAINER_IMAGES arch_version split os windows windows-arm package_type libtorch build_name f libtorch- gpu_arch_type gpu_arch_version - libtorch_variant - release_type replace _ ret generate_wheels_matrix os str arches Optional list str = None python_versions Optional list str = None - list dict str str package_type = wheel os == linux os == linux-aarch os == linux-s x NOTE We only build manywheel packages x _ aarch s x linux package_type = manywheel python_versions None python_versions = FULL_PYTHON_VERSIONS arches None Define default compute archivectures arches = cpu os == linux arches += CUDA_ARCHES + ROCM_ARCHES + XPU_ARCHES os == windows TODO huydhn Only build CUDA Linux This logic cleaned up windows_cuda_arches = CUDA_ARCHES copy windows_cuda_arches remove arches += windows_cuda_arches + XPU_ARCHES os == linux-aarch Separate new CPU type different uses different build test scripts arches = CPU_AARCH _ARCH + CUDA_AARCH _ARCHES os == linux-s x Only want one arch CPU type different uses different build test scripts arches = cpu-s x ret list dict str str = python_version python_versions arch_version arches gpu_arch_type = arch_type arch_version gpu_arch_version = arch_version == cpu arch_version == cpu-aarch arch_version == cpu-s x arch_version == xpu arch_version TODO Enable python rest os linux linux-aarch linux-s x macos-arm windows python_version == python_version == t continue cuda linux wheels require PYTORCH_EXTRA_INSTALL_REQUIREMENTS install arch_version os == linux arch_version CUDA_AARCH _ARCHES desired_cuda = translate_desired_cuda gpu_arch_type gpu_arch_version ret append python_version python_version gpu_arch_type gpu_arch_type gpu_arch_version gpu_arch_version desired_cuda desired_cuda container_image WHEEL_CONTAINER_IMAGES arch_version split container_image_tag_prefix WHEEL_CONTAINER_IMAGES arch_version split package_type package_type pytorch_extra_install_requirements PYTORCH_EXTRA_INSTALL_REQUIREMENTS f desired_cuda desired_cuda cuda-aarch cu - os == linux-aarch PYTORCH_EXTRA_INSTALL_REQUIREMENTS arch_version build_name f package_type -py python_version - gpu_arch_type f - aarch gpu_arch_type gpu_arch_version replace -aarch replace _ include special case aarch build remove -aarch postfix ret append python_version python_version gpu_arch_type gpu_arch_type gpu_arch_version gpu_arch_version desired_cuda translate_desired_cuda gpu_arch_type gpu_arch_version container_image WHEEL_CONTAINER_IMAGES arch_version split container_image_tag_prefix WHEEL_CONTAINER_IMAGES arch_version split package_type package_type build_name f package_type -py python_version - gpu_arch_type gpu_arch_version replace _ pytorch_extra_install_requirements PYTORCH_EXTRA_INSTALL_REQUIREMENTS xpu gpu_arch_type == xpu ret arch_version = arch_version CUDA_ARCHES validate_nccl_dep_consistency arch_version del arch_version __name__ == __main__ Used tools nightly py SCRIPT_DIR nightly_source_matrix json write_text json dumps NIGHTLY_SOURCE_MATRIX indent= + \n