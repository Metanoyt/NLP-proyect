Owner s module nn tempfile copy deepcopy functools partial unittest expectedFailure torch torch nn torch nn modules lazy LazyModuleMixin torch nn utils parametrize register_parametrization remove_parametrizations torch testing _internal common_subclass DiagTensorBelow subclass_db torch testing _internal common_utils TestCase instantiate_parametrized_tests parametrize run_tests skipIfTorchDynamo subtest torch testing _internal logging_tensor LoggingTensor torch utils _pytree tree_map The current test methodology file test variety real use cases set fully-fledged tensor subclasses In future may change more narrowly specify toy subclasses each specific invariants under test avoiding need maintain set fully-fledged tensor subclasses Decorator parametrizing tests across various tensor classes parametrize_tensor_cls = parametrize tensor_cls subtest tensor_cls name=info name tensor_cls info subclass_db items TestSubclass TestCase _create_tensor tensor_cls subclass_db tensor_cls create_fn parametrize_tensor_cls parametrize tensor_requires_grad False True test_param_invariants tensor_cls tensor_requires_grad x = _create_tensor tensor_cls requires_grad_ tensor_requires_grad param = nn Parameter x requires_grad= tensor_requires_grad assertIsInstance param nn Parameter Ensure requires_grad passed Parameter s constructor takes precedence assertEqual param requires_grad tensor_requires_grad Ensure original tensor mutated Parameter construction assertNotIsInstance x nn Parameter assertEqual x requires_grad tensor_requires_grad UninitializedParam nn Parameter pass assertNotIsInstance param UninitializedParam skipIfTorchDynamo parametrize_tensor_cls parametrize as_param False True test_deepcopy tensor_cls as_param x = _create_tensor tensor_cls as_param x = nn Parameter x x_copy = deepcopy x assertEqual x x_copy assertEqual x __class__ x_copy __class__ assertIsNot x x_copy assertIsInstance x_copy tensor_cls as_param Deepcopy should preserve both custom type parameter-ness assertIsInstance x_copy nn Parameter parametrize_tensor_cls parametrize as_param False True test_serialization tensor_cls as_param tempfile TemporaryFile f x = _create_tensor tensor_cls as_param x = nn Parameter x torch save x f f seek torch serialization safe_globals tensor_cls x_loaded = torch load f assertEqual x x_loaded assertIsNot x x_loaded assertIsInstance x_loaded tensor_cls as_param Serialization should preserve both custom type parameter-ness assertIsInstance x_loaded nn Parameter skipIfTorchDynamo Visible only functorch functorch monkeypatches tensor str parametrize_tensor_cls parametrize as_param False True test_repr tensor_cls as_param x = _create_tensor tensor_cls as_param x = nn Parameter x str_repr = x __repr__ tensor_cls torch Tensor assertEqual str_repr count f tensor_cls __name__ assertEqual str_repr count Parameter as_param parametrize_tensor_cls parametrize as_param False True test_type_propagation tensor_cls as_param x = _create_tensor tensor_cls as_param x = nn Parameter x Call add operator produce output tensor output = x + _create_tensor torch Tensor Custom type should propagated across operations closed under op parameter-ness should subclass_db tensor_cls closed_under_ops assertIsInstance output tensor_cls assertIsInstance output torch Tensor assertNotIsInstance output nn Parameter parametrize_tensor_cls test_module_optimization tensor_cls create_fn = partial _create_tensor tensor_cls MyModule nn Module __init__ - None super __init__ p = nn Parameter create_fn p_list = nn ParameterList create_fn _ range p_list append create_fn p_dict = nn ParameterDict foo create_fn bar create_fn p_dict baz = create_fn torch no_grad nn init normal_ p p p_list nn init uniform_ p p p_dict values nn init uniform_ p forward x out = p + x p p_list out = p + out v p_dict values out = v + out out m = MyModule assertEqual len m state_dict optimizer = torch optim SGD m parameters lr= m create_fn sum backward torch tensor optimizer step parametrize_tensor_cls parametrize leave_parametrized False True test_parametrization tensor_cls leave_parametrized TODO Either implement set_ properly these tensor subclasses apply more general fix avoid need special set_ handling For now skip testing these they re expected fail tensor_cls LoggingTensor DiagTensorBelow create_fn = partial _create_tensor tensor_cls MyModule nn Module __init__ - None super __init__ weight = nn Parameter create_fn forward x weight + x MyParametrization nn Module forward X -X m = MyModule assertEqual len m state_dict register_parametrization m weight MyParametrization assertIsInstance m weight tensor_cls output = m _create_tensor torch Tensor assertIsInstance output tensor_cls remove_parametrizations m weight leave_parametrized=leave_parametrized Lazy modules custom tensors supported yet expectedFailure parametrize_tensor_cls test_lazy_module tensor_cls tensor_cls torch Tensor fail dummy fail base tensor until test passes subclasses MyLazyModule LazyModuleMixin nn Module __init__ - None super __init__ param = nn UninitializedParameter initialize_parameters input - None type ignore override has_uninitialized_params torch no_grad param materialize input shape nn init uniform_ param forward x param + x m = MyLazyModule assertTrue m has_uninitialized_params m _create_tensor tensor_cls assertFalse m has_uninitialized_params assertIsInstance m param tensor_cls test_non_rewrapping_torch_dispatch_subclass_as_parameter_throws_for_detach Define subclass does rewrap any function its __torch_dispatch__ impl NonRewrappingTensor torch Tensor staticmethod __new__ cls t torch Tensor r = super _make_wrapper_subclass cls t shape dtype=t dtype requires_grad=t requires_grad device=t device r __init__ t - None tensor torch Tensor = t classmethod __torch_dispatch__ cls func types args= kwargs=None unwrap e - torch Tensor isinstance e NonRewrappingTensor t = e tensor t e r = func tree_map unwrap args tree_map unwrap kwargs Return unwrapped tensor no longer original subclass type r assertRaisesRegex RuntimeError r requires detach\ \ returns instance same type nn Parameter NonRewrappingTensor torch randn test_tensor_subclass_storage_data_accesses_throw torch testing _internal logging_tensor LoggingTensor x = torch ones x_log = LoggingTensor x Accessing storage tensor subclass valid storage = x_log untyped_storage This includes accessing metadata storage But storage methods access data will throw assertRaisesRegex RuntimeError invalid python storage storage data_ptr assertRaisesRegex RuntimeError invalid python storage storage resize_ assertRaisesRegex RuntimeError invalid python storage storage copy_ storage assertRaisesRegex RuntimeError invalid python storage storage fill_ assertRaisesRegex RuntimeError invalid python storage storage _write_file file instantiate_parametrized_tests TestSubclass __name__ == __main__ run_tests