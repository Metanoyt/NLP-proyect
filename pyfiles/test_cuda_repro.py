Owner s module inductor ruff noqa F copy functools gc math os sys unittest torch torch _dynamo config dynamo_config torch backends cuda torch nn functional F torch nn torch _dynamo debug_utils same_two_models torch _dynamo testing rand_strided torch _dynamo utils same torch _inductor config torch _inductor compile_fx compile_fx_inner torch _inductor runtime benchmarking benchmarker torch _inductor runtime hints DeviceProperties torch _inductor utils run_and_get_code run_and_get_graph_lowering run_fw_bw_and_get_code torch fx experimental proxy_tensor make_fx torch nn attention sdpa_kernel SDPBackend torch testing FileCheck torch testing _internal common_cuda PLATFORM_SUPPORTS_FLASH_ATTENTION SM OrLater SM OrLater TEST_MULTIGPU torch testing _internal common_utils DeterministicGuard freeze_rng_state instantiate_parametrized_tests IS_FBCODE MI _ARCH parametrize skipIfRocmArch TEST_WITH_ASAN TEST_WITH_ROCM xfailIfPy Plus torch testing _internal inductor_utils IS_BIG_GPU TEST_WITH_ROCM config force_layout_optimization = os environ PYTORCH_MIOPEN_SUGGEST_NHWC = DO_PERF_TEST = os environ get DO_PERF_TEST == requires_multigpu = functools partial unittest skipIf TEST_MULTIGPU requires multiple cuda devices torch testing _internal inductor_utils skipCUDAIf try try triton manual triton language tl manual except ImportError raise unittest SkipTest requires triton noqa B try test_torchinductor except ImportError test_torchinductor manual=fbcode caffe test inductor test_inductor-library except unittest SkipTest __name__ == __main__ sys exit raise TestCase = test_torchinductor TestCase ToTuple = test_torchinductor ToTuple check_model_cuda = test_torchinductor check_model_cuda aten = torch ops aten instantiate_parametrized_tests CudaReproTests TestCase device = cuda common = check_model_cuda test_mm_out_dtype_compile = torch randn device= cuda dtype=torch float b = torch randn device= cuda dtype=torch float fn x y torch mm x y out_dtype=torch float compiled = torch compile fn backend= inductor fullgraph=True result = compiled b expected = fn b assertEqual result dtype expected dtype assertEqual result expected test_index_put_issue forward arg _ expand_default full_like_default _to_copy_default_ zeros sum_sym_int_ = torch ops aten sum _to_copy_default_ True view_default_ = torch ops aten view default sum_sym_int_ where_self = torch ops aten where expand_default view_default_ full_like_default clone_default_ = torch ops aten clone default zeros index_put__default = torch ops aten index_put_ default clone_default_ arg _ where_self True index_put__default inps = torch Size torch int torch Size torch bool torch Size torch float torch Size torch float torch Size torch float inps = torch zeros + torch ones shape dtype=dtype device= cuda shape dtype inps mod = make_fx forward inps compiled = compile_fx_inner mod inps compiled inps test_view_replay_padding_issue_ ReproModule nn Module __init__ super __init__ num_points_out = lc_num = input_channels = linear_main = nn Linear input_channels num_points_out linear_lc = nn Linear input_channels num_points_out forward x torch Tensor bs num_lat num_lon channels = x shape index = num_lat - lc_num main_x = x index reshape bs index num_lon channels lc_x = x index reshape bs lc_num num_lon channels refline = linear_main main_x reshape bs index num_lon - lc_refline = linear_lc lc_x reshape bs lc_num num_lon - base = torch cat refline lc_refline dim= contiguous out = base reshape bs num_lat num_lon num_points_out out = base reshape bs num_lat num_lon num_points_out ten out ten out torch manual_seed model = ReproModule cuda inputs = torch randn device= cuda requires_grad=True eager_out = model inputs compiled_model = torch compile copy deepcopy model backend= inductor mode= reduce-overhead fullgraph=True compiled_out = compiled_model inputs assertEqual compiled_out ten eager_out ten assertEqual compiled_out ten eager_out ten test_effn_attn_bias_padding batch_size num_heads seq_len head_dim = fn query torch Tensor key torch Tensor value torch Tensor input_tensor torch Tensor This will our starting point Input tensor should appropriate strides bias = torch ops aten expand input_tensor seq_len seq_len Expands stride pattern torch ops aten _scaled_dot_product_efficient_attention query key value bias compute_log_sumexp=True dropout_p= is_causal=False scale=None query = torch randn batch_size num_heads seq_len head_dim device= cuda key = torch randn batch_size num_heads seq_len head_dim device= cuda value = torch randn batch_size num_heads seq_len head_dim device= cuda input_tensor = torch rand seq_len device= cuda out code = run_and_get_code torch compile fn query key value input_tensor input_tensor = torch rand seq_len seq_len device= cuda copy_ input_tensor even though last dim broadcasted needs stride alignment dim stride can FileCheck check buf check run code dont check rng state assertEqual out fn query key value input_tensor skipIfRocmArch MI _ARCH test_effn_attn_bias_padding_misaligned seqlen_start = offset range - seqlen = seqlen_start + offset torch _dynamo reset bsz = q = torch randn bsz seqlen dtype=torch bfloat device= cuda k = torch randn bsz seqlen dtype=torch bfloat device= cuda v = torch randn bsz seqlen dtype=torch bfloat device= cuda mask = torch ones bsz seqlen seqlen dtype=torch bool device= cuda inputs = q k v mask f q k v mask sdpa_kernel SDPBackend EFFICIENT_ATTENTION F scaled_dot_product_attention q k v attn_mask=mask dropout_p= f_compiled = torch compile f out code = run_and_get_code f_compiled inputs padded bias should have expanded dim FileCheck check buf = check_same run code single fused padded kernel FileCheck check_count empty_strided_cuda exactly=True check run code assertEqual out f inputs test_input_channels_last m = torch nn Sequential torch nn Conv d ToTuple cuda inp = torch randn memory_format=torch channels_last cuda common m inp check_lowp=False torch compile foo m inp m inp assertTrue foo m inp is_contiguous memory_format=torch channels_last https github com pytorch torchdynamo issues #issuecomment- test_unspec_inputs_interop Repro torch nn Module forward x y unsqueeze = torch ops aten unsqueeze default x permute = torch ops aten permute default unsqueeze add = torch ops aten add Tensor y permute add inps = rand_strided torch float cuda rand_strided torch int cpu mod = make_fx Repro device= cuda inps compiled = compile_fx_inner mod inps compiled inps unittest skipIf IS_FBCODE RuntimeError Triton Error CUDA invalid device context test_backward_context fn x x x = torch randn device= cuda requires_grad=True gO = torch rand_like x opt_fn = torch compile fn out = opt_fn x out backward gO config patch fallback_random=True test_dtype_factory_issue forward randn = torch ops aten randn default dtype=torch float device=torch device type= cuda index= pin_memory=False unsqueeze_default_ = torch ops aten unsqueeze default randn - unsqueeze_default_ mod = make_fx forward compiled = compile_fx_inner mod assert compiled device type == cuda config patch triton cudagraphs True dynamo_config patch automatic_dynamic_shapes=True test_no_device_idx_repro_cudagraphs Repro torch nn Module __init__ - None super __init__ forward full = torch ops aten full default dtype=torch float layout=torch strided device=torch device type= cuda index= pin_memory=False full_ = torch ops aten full default dtype=torch int layout=torch strided device=torch device type= cuda index= pin_memory=False full_ full common Repro config patch triton cudagraphs True dynamo_config patch automatic_dynamic_shapes=True test_expanded_inputs_cudagraphs torch compile backend= inductor fn x y x + y inputs = rand_strided device= cuda rand_strided device= cuda assertTrue same fn inputs inputs + inputs config patch triton cudagraphs True dynamo_config patch automatic_dynamic_shapes=True assume_static_by_default=False test_dynamic_to_static_cudagraphs b False True config patch triton cudagraph_trees b torch compile backend= inductor fn x y r = x + y r r size inputs = torch randn device= cuda torch randn device= cuda assertTrue same fn inputs inputs + inputs inputs = torch randn device= cuda torch randn device= cuda assertTrue same fn inputs inputs + inputs _test_split_reduction_impl x max x torch max x max_c = torch compile max out code = run_and_get_code max_c x assertEqual out max x DO_PERF_TEST ms_c = benchmarker benchmark_gpu lambda max_c x ms_eager = benchmarker benchmark_gpu lambda max x print f compile ms_c= f eager ms_eager= f test_split_reduction_transposed x = torch randn dtype=torch bfloat device= cuda x = x t contiguous t _test_split_reduction_impl x test_split_reduction_channels_last x = torch randn dtype=torch bfloat device= cuda x = x reshape memory_format=torch channels_last _test_split_reduction_impl x config patch emulate_precision_casts True test_bool_emulate_low_precision torch device inf = float inf forward full_ = torch ops aten full default dtype=torch float layout=torch strided device=device type= cpu pin_memory=False device_put_ = torch ops prims device_put default full_ device type= cuda index= full_ = None convert_element_type_ = torch ops prims convert_element_type default device_put_ torch bool device_put_ = None unsqueeze_ = torch ops aten unsqueeze default convert_element_type_ convert_element_type_ = None unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ unsqueeze_ = None expand = torch ops aten expand default unsqueeze_ - - unsqueeze_ = None clone = torch ops aten clone default expand memory_format=torch contiguous_format expand = None view_ = torch ops aten reshape default clone clone = None scalar_tensor = torch ops aten scalar_tensor default -inf dtype=torch float device=device type= cuda index= scalar_tensor_ = torch ops aten scalar_tensor default dtype=torch float layout=torch strided device=device type= cuda index= where = torch ops aten where view_ scalar_tensor_ scalar_tensor view_ = scalar_tensor_ = scalar_tensor = None where torch _inductor config config emulate_precision_casts = True assertEqual torch compile forward forward config patch emulate_precision_casts True test_emulate_low_precision foo x torch nn functional gelu x inp = torch rand device= cuda requires_grad=True dtype=torch bfloat out codes = run_fw_bw_and_get_code lambda torch compile foo inp fwd backward code codes f = FileCheck eager there two down casts _ range f check tl bfloat check_next tl float f run code assertEqual foo inp out TODO Abstract out test more extensively torch _dynamo config patch assume_static_by_default=False test_dynamic_shapes torch _dynamo reset Needed since everywhere uses inductor f x x cos view x shape sin cnts = torch _dynamo testing CompileCounterWithBackend inductor f = torch compile f backend=cnts f torch randn inp = torch randn real_out = f inp compiled_out = f inp assertEqual cnts frame_count assertEqual real_out compiled_out torch _dynamo reset config patch triton cudagraphs True size_asserts False dynamo_config patch automatic_dynamic_shapes=True test_expanded_inputs_cudagraphs_no_size_asserts torch compile backend= inductor fn x y x + y inputs = rand_strided device= cuda rand_strided device= cuda assertTrue same fn inputs inputs + inputs config patch triton cudagraph_trees False config patch triton cudagraphs True dynamo_config patch automatic_dynamic_shapes=True test_inplace_updates_cudagraphs Repro torch nn Module __init__ - None super __init__ weight = torch nn Parameter torch randn requires_grad=True forward x x = torch matmul x weight x copy deepcopy model = Repro cuda model_ref = deepcopy model model_opt = torch compile model backend= inductor input = torch randn device= cuda requires_grad=True _ range output_ref = model_ref input output_res = model_opt input output_ref sum backward output_res sum backward p_ref p_res zip model_ref parameters model_opt parameters assertEqual p_ref grad p_res grad torch no_grad param model_ref parameters param add_ param model_opt parameters param add_ https github com pytorch torchdynamo issues test_inductor_output_aliases_intermediate foo x out = x + x out t foo_opt = torch compile foo backend= inductor inpt = torch randn device= cuda requires_grad=True TODO broken fix later out = foo_opt inpt out add_ out_ref = foo inpt out_ref add_ assertEqual out_ref out test_accuracy_issue Repro torch nn Module __init__ - None super __init__ linear = torch nn Linear in_features= out_features= bias=True forward start_positions torch Tensor x torch Tensor linear = linear x split = linear split dim=- getitem = split squeeze = getitem squeeze - clamp = start_positions clamp cross_entropy = torch nn functional cross_entropy squeeze clamp None None None mean cross_entropy mod = Repro cuda opt_mod = torch compile mod backend= inductor mod eval opt_mod eval args = torch int cuda False torch float cuda True args = rand_strided sh st dt dev requires_grad_ rg sh st dt dev rg args torch cuda amp autocast enabled=False assert same_two_models mod opt_mod args Dynamo failed config patch allow_buffer_reuse=False test_issue forward add_ var_mean = torch ops aten var_mean correction add_ correction= keepdim=True getitem_ = var_mean getitem_ x = torch randn device= cuda correct = forward x actual = torch compile forward fullgraph=True x assertEqual actual correct test_full_copy forward x full_ = torch ops aten full default dtype=torch float layout=torch strided device= cuda pin_memory=False x + full_ cpu o = torch randn dtype=torch float correct = forward o actual = torch compile forward fullgraph=True o assertEqual actual correct test_autotune_inplace_kernel This UT tests autotune inplace kernel The autotune should contaminate input buffers when tuning multiple configs For more details refer https github com triton-lang triton issues https github com pytorch torchdynamo issues torch _C _cuda_getCurrentRawStream get_cuda_stream torch _inductor runtime hints AttrsDescriptorWrapper HeuristicType torch _inductor runtime triton_heuristics CachingAutotuner torch _inductor utils triton_version_uses_attrs_dict autotune configs meta decorator fn triton_version_uses_attrs_dict Newer versions Triton puts constexpr signature Ref https github com pytorch pytorch pull meta signature XBLOCK = constexpr CachingAutotuner force autotune setting save_cache_hook False fn triton_meta=meta configs=configs save_cache_hook=False mutated_arg_names= in_out_ptr reset_to_zero_arg_names= optimize_mem=True heuristic_type=HeuristicType POINTWISE inductor_meta= grid_type Grid D decorator autotune configs= triton Config XBLOCK triton Config XBLOCK meta= signature in_out_ptr fp in_ptr fp xnumel i device DeviceProperties create torch device cuda configs AttrsDescriptorWrapper divisible_by_ = equal_to_ = constants triton jit kernel in_out_ptr in_ptr xnumel XBLOCK tl constexpr pid = tl program_id block_start = pid XBLOCK offsets = block_start + tl arange XBLOCK mask = offsets xnumel x = tl load in_out_ptr + offsets mask=mask other= y = tl load in_ptr + offsets mask=mask other= output = x + y tl store in_out_ptr + offsets output mask=mask xnumel = = rand_strided xnumel device= cuda dtype=torch float inout = rand_strided xnumel device= cuda dtype=torch float inout = inout clone stream = get_cuda_stream kernel run inout xnumel stream=stream kernel run inout xnumel stream=stream assert same inout inout tol= equal_nan=True failed autotune inplace kernel test_sort_stride_issue This minified testcase comes detectron _maskrcnn_r_ _fpn There false error our size_assert code torch compile fullgraph=True forward pred_objectness_logits_ _ torch Tensor sort_ = pred_objectness_logits_ _ sort descending=True dim= getitem_ = sort_ getitem_ args = torch float cuda False args = rand_strided sh st dt dev requires_grad_ rg sh st dt dev rg args result = forward args assert same result torch sort args descending=True dim= test_scalar_triton_index The indirect indexing via scalar like below used lead bad triton code made triton segfault when compiling See https github com pytorch torchdynamo issues fn zero = torch zeros device=a device dtype=torch int zero = torch randn dtype=torch float device= cuda fn_optimized = torch compile fn backend= inductor assert same fn fn_optimized test_indirect_indexing_dense_mask fn x y ne = torch ops aten ne Scalar x sum_ = torch ops aten sum dim_IntList ne sub = torch ops aten sub Tensor sum_ unsqueeze = torch ops aten unsqueeze default sub - gather = torch ops aten gather default x unsqueeze squeeze = torch ops aten squeeze default gather out = torch ops aten multiply y squeeze out = torch zeros dtype=torch int device= cuda b = torch zeros dtype=torch int device= cuda fn_optimized = torch compile fn backend= inductor assert same fn b fn_optimized b test_simplify_dims fn + common fn torch randn device= cuda config patch permute_fusion=True test_permute_fusion Repro torch nn Module forward view reshape_ permute = view permute view = None reshape = torch reshape permute - bmm = torch bmm permute reshape_ bmm args = torch float cuda True torch float cuda True args = rand_strided sh st dt dev requires_grad_ rg sh st dt dev rg args mod = Repro opt_mod = torch compile mod backend= inductor ref = mod args res = opt_mod args assertTrue same ref res config patch triton autotune_pointwise True test_inplace_add_alpha_autotune fn x y aten add_ Tensor x y alpha= x x = torch zeros device= cuda x = torch zeros device= cuda x = torch zeros device= cuda y = torch randn device= cuda memory_format=torch channels_last fn_fx = make_fx fn x y fn_compiled = compile_fx_inner fn_fx x y fn x y fn_compiled x y assert same x x config patch triton autotune_pointwise True test_inplace_buffer_autotune foo x y z = x y unsqueeze unsqueeze + z x = torch zeros device= cuda y = torch zeros device= cuda z = torch zeros device= cuda memory_format=torch channels_last common foo x y z check_lowp=False test_memory_history_inductor called_inside_compile x w b = x w + b torch sigmoid torch compile fn x w b x = called_inside_compile x w b called_inside_compile x w b w = torch rand device= cuda b = torch rand device= cuda x = torch rand device= cuda try torch cuda memory empty_cache torch cuda memory _record_memory_history True r = fn x w b finally torch cuda memory _record_memory_history False snapshot = str torch cuda memory _snapshot assertTrue called_inside_compile snapshot test_negative_arange_dynamic_shapes Repro alibi relative encodings sign x x - x Repro torch nn Module __init__ - None super __init__ nheads = start = math log end = math log scales = nn Buffer torch arange start end + e- sign end - start end - start nheads - view nheads emb = nn Embedding dec_layer = nn TransformerDecoderLayer batch_first=True norm_first=True head = nn Linear forward enc_out torch Tensor dec_in torch Tensor padmask = dec_in == dec_mask = padmask unsqueeze - == padmask unsqueeze - dec_mask = dec_mask dtype=torch float dec_mask = dec_mask tril diagonal= cuda q_pos = torch arange dec_in size dtype=torch long device= cuda k_pos = torch arange dec_in size dtype=torch long device= cuda rel_pos = k_pos None - q_pos None values = rel_pos abs neg unsqueeze unsqueeze dec_bias = values scales dec_bias tril_ diagonal= dec_mask = dec_mask + dec_bias out = emb dec_in out = dec_layer out enc_out tgt_mask=dec_mask head out mod = Repro cuda opt_mod = torch compile mod backend= inductor dynamic=True mod eval opt_mod eval enc_out = torch rand cuda dec_inputs = torch randint i + dtype=torch long cuda i range dec_inp dec_inputs assert same_two_models mod opt_mod enc_out dec_inp only_fwd=True Inductor dynamic shapes failed test_issue _ input fn arg _ relu permute_ addmm_ = torch ops aten addmm default arg _ relu permute_ cat_ = torch ops aten cat default addmm_ cat_ args = torch float cuda torch float cuda torch float cuda args = rand_strided sh st dt dev sh st dt dev args correct = fn args mod = make_fx fn tracing_mode= real args compiled = compile_fx_inner mod args ref = compiled list args assert same ref correct ref = torch compile fn fullgraph=True args assert same ref correct test_issue_ MyModule torch nn Module __init__ - None super __init__ temperature = layer = torch nn Softmax dim= forward x n_samples _ = x shape y = torch ones n_samples dtype=x dtype device=x device inp = x y None layer inp x = torch rand device= cuda m = MyModule opt_m = torch compile backend= inductor m assertEqual opt_m x m x test_issue _ input fn arg _ arg _ relu permute_ addmm_ = torch ops aten addmm default arg _ relu permute_ addmm_ = torch ops aten addmm default arg _ relu permute_ cat_ = torch ops aten cat default addmm_ addmm_ cat_ args = torch float cuda torch float cuda torch float cuda torch float cuda args = rand_strided sh st dt dev sh st dt dev args correct = fn args ref = torch compile fn fullgraph=True args assert same ref correct test_scatter_index_not_wrapped src = torch tensor device=self device index = torch tensor device=self device input = torch tensor device=self device compiled_sr = torch compile torch scatter_reduce input_orig = input clone out code = run_and_get_code compiled_sr input index src sum tmp - wrapping negative numbers FileCheck check tl device_assert = tmp tmp check_next atomic_add run code assertEqual out torch scatter_reduce input_orig clone index src sum test_normalize_norm_leq_one fn x torch Tensor - torch Tensor torch nn functional normalize x dim=- inp = torch tensor device= cuda dtype=torch float compiled = torch compile fn backend= inductor fullgraph=True out = compiled inp norm = out norm dim=- assertTrue torch all norm = f expected norm = got norm item test_libdevice_routing foo x x exp inp = torch ones device= cuda torch float out code = run_and_get_code torch compile foo inp FileCheck check libdevice exp run code assertEqual foo inp out inp = inp torch float out code = run_and_get_code torch compile foo inp FileCheck check_not tl_math exp check libdevice exp run code assertEqual foo inp out foo x x sigmoid inp = torch ones device= cuda torch float out code = run_and_get_code torch compile foo inp FileCheck check libdevice exp run code assertEqual foo inp out test_uint_view_copy torch compile view_copy target source assert target dtype == torch bfloat assert source dtype == torch uint target view torch uint copy_ source target = torch ones dtype=torch bfloat device= cuda source = torch full_like target dtype=torch uint out = target view torch uint copy_ source clone view_copy target source assertEqual out target view torch uint test_embedding_var_mean forward arg _ full = torch ops aten full default dtype=torch float layout=torch strided device=torch device type= cuda index= pin_memory=False convert_element_type_ = torch ops prims convert_element_type default full torch int cumsum = torch ops aten cumsum default convert_element_type_ mul = torch ops aten mul Tensor cumsum convert_element_type_ sub_ = torch ops aten sub Tensor mul slice_ = torch ops aten slice Tensor sub_ slice_ = torch ops aten slice Tensor slice_ add_ = torch ops aten add Tensor slice_ embedding_ = torch ops aten embedding default arg _ add_ var_mean = torch ops aten var_mean correction embedding_ correction= keepdim=True var_mean var_mean add_ emb = torch randn device= cuda gm = make_fx forward emb opt = torch _inductor compile_fx compile_fx_inner gm emb opt emb torch cuda synchronize test_deterministic_algorithms N = torch compile fn idx values x = torch zeros device= cuda x idx += values x idx = torch zeros N dtype=torch int device= cuda values = torch randn N device= cuda r = fn idx values DeterministicGuard True r = fn idx values _ range rn = fn idx values assertEqual r rn atol= rtol= https github com pytorch pytorch issues test_linear_cpu_input Model nn Module __init__ - None super __init__ linear = nn Linear forward data data = data cuda linear data mod = Model cuda eval torch no_grad common mod torch randn config patch fallback_random True triton cudagraphs True test_xlnet_lm_stride_repro Repro nn Module __init__ - None super __init__ dropout = nn Dropout p= inplace=False forward x y = torch _C _nn gelu x dropout y mod = Repro x = torch randn requires_grad=True device= cuda y = torch compile mod x Inductor claims output layout gelu s saved variable backwards will actuality Fortunately doesn t actually matter practice y sum backward test_lookup_seed_backward torch compile fullgraph=True forward inductor_seeds mul_ view_ inductor_lookup_seed_ = torch ops prims inductor_lookup_seed default inductor_seeds inductor_random_ = torch ops prims inductor_random default inductor_lookup_seed_ rand gt_ = torch ops aten gt Scalar inductor_random_ mul_ = torch ops aten mul Tensor gt_ view_ mul_ = torch ops aten mul Tensor mul_ add_ = torch ops aten add Tensor mul_ mul_ var_mean_ = torch ops aten var_mean correction add_ correction= keepdim=True getitem_ = var_mean_ sub_ = torch ops aten sub Tensor add_ getitem_ sub_ buf = torch zeros dtype=torch int device= cuda buf = torch zeros device= cuda buf = torch zeros device= cuda forward buf buf buf test_issue Model torch nn Module __init__ - None super __init__ linear = torch nn Linear linear = torch nn Linear relu = torch nn ReLU forward x x = linear x x = linear x x = torch cat x x dim= x = x view - x = x x = relu x x device = cuda batch_size = x = torch randn batch_size device func = Model device torch no_grad func train False jit_func = torch compile func res = func x res = jit_func x assertEqual res res test_issue fn x y NOTE dimensions important does fail dimensions mean = torch mean x keepdim=True add = mean + y add x = torch rand device= cuda y = torch rand device= cuda expect = fn x y opt_fn = torch compile fn actual = opt_fn x y assertEqual expect actual config patch triton dense_indexing True dynamo_config patch automatic_dynamic_shapes=True test_bucketize_dynamic_dense Make sure ops bucketize can handle dense_indexing which previously caused issues due incorrect handling size offsets fn values offsets torch bucketize values offsets values = torch rand device= cuda offsets = torch tensor device= cuda expect = fn values offsets opt_fn = torch compile fn dynamic=True actual = opt_fn values offsets assertEqual expect actual unittest skipIf IS_BIG_GPU Skipping triton backend only since big GPU enough SM config patch max_autotune_gemm_backends TRITON triton disallow_failing_autotune_kernels_TESTING_ONLY True compile_threads test_bucketize_epilogue See https github com pytorch pytorch issues Make sure when torch bucketize appears epilogue codegen valid Note during autotuning there s also option _not_ do fusion So you run test standard configs fused kernel would fail during autotuning another non-fused kernel would selected Inductor would throw some errors test would pass So we set disallow_failing_autotune_kernels_TESTING_ONLY=True prevent autotuner catching failures And set compile_threads= so compile failures aren t caught asyn runner infra fn x torch Tensor y torch Tensor buckets torch Tensor - torch Tensor z = torch mm x y torch bucketize z buckets buckets = torch arange - device= cuda x = torch randn device= cuda clamp - y = torch randn device= cuda clamp - opt_fn = torch compile fn mode= max-autotune expected = fn x y buckets actual = opt_fn x y buckets assertEqual expected actual test_float _constants fn NOTE tensors all same value constant folded so we need tensor two distinct values = torch tensor dtype=torch float device= cuda e cfn = torch compile fn expect = fn actual = cfn assertEqual expect actual atol= rtol= test_issue fn arg _ add_ permute_ select_scatter slice_ slice_scatter_ = torch ops aten slice_scatter default permute_ select_scatter permute_ = torch ops aten permute default slice_scatter_ view_ = torch ops aten view default permute_ view_ = torch ops aten view default view_ view_ = torch ops aten view default view_ view_ = torch ops aten view default view_ permute_ = torch ops aten permute default view_ slice_ = torch ops aten slice Tensor permute_ slice_scatter_ = torch ops aten slice_scatter default slice_ slice_ slice_scatter_ = torch ops aten slice_scatter default arg _ slice_scatter_ mul_ = torch ops aten mul Scalar add_ slice_ = torch ops aten slice Tensor slice_scatter_ slice_ = torch ops aten slice Tensor slice_ select_ = torch ops aten select int slice_ permute_ = torch ops aten permute default select_ mul_ = torch ops aten mul Scalar permute_ expand = torch ops aten expand default mul_ view_ = torch ops aten view default expand expand_ = torch ops aten expand default mul_ view_ = torch ops aten view default expand_ bmm = torch ops aten bmm default view_ view_ bmm args = args append torch randn dtype=torch float device= cuda args append rand_strided dtype=torch float device= cuda args append rand_strided dtype=torch float device= cuda args append rand_strided dtype=torch float device= cuda args append rand_strided dtype=torch float device= cuda correct = fn args mod = make_fx fn tracing_mode= real args compiled = compile_fx_inner mod args ref = compiled list args assert same ref correct config patch triton cudagraphs True test_index_put_inplace_cudagraph fn x y z x = torch zeros_like x x index_put_ y z True x = torch zeros device= cuda dtype=torch bool y = torch zeros device= cuda dtype=torch int z = torch ones device= cuda dtype=torch bool opt_fn = torch compile fn backend= inductor ref = fn x y z run twice test cuda graph issue res = opt_fn x y z res = opt_fn x y z assertEqual ref res config patch triton cudagraphs True config patch fx_graph_cache True test_index_put_cudagraph _ range fn x y z x = torch zeros_like x x index_put y z True x = torch zeros device= cuda dtype=torch bool y = torch zeros device= cuda dtype=torch int z = torch ones device= cuda dtype=torch bool opt_fn = torch compile fn backend= inductor ref = fn x y z run twice test cuda graph issue res = opt_fn x y z res = opt_fn x y z assertEqual ref res torch _dynamo reset gc collect unittest skipIf PLATFORM_SUPPORTS_FLASH_ATTENTION flash attention supported test_flash_attention_dynamic Model nn Module __init__ args kwargs - None super __init__ args kwargs q = nn Linear k = nn Linear v = nn Linear forward x batch_size seq_len _ = x size queries = q x view batch_size seq_len transpose keys = k x view batch_size seq_len transpose values = v x view batch_size seq_len transpose attn = F scaled_dot_product_attention queries keys values attn cnts = torch _dynamo testing CompileCounterWithBackend inductor model = Model cuda half model = torch compile model backend=cnts dynamic=True torch backends cuda sdp_kernel enable_flash=True enable_math=False enable_mem_efficient=False enable_cudnn=False input = torch rand device= cuda dtype=torch float input = torch rand device= cuda dtype=torch float input = torch rand device= cuda dtype=torch float out = model input out = model input out = model input assertEqual cnts frame_count config patch triton cudagraphs True test_index_put_no_fallback_cudagraph fn x y z x = torch zeros_like x x index_put y z True x = torch zeros device= cuda dtype=torch int y = torch zeros device= cuda dtype=torch int z = torch ones device= cuda dtype=torch int opt_fn = torch compile fn backend= inductor ref = fn x y z run twice test cuda graph issue res = opt_fn x y z res = opt_fn x y z assertEqual ref res torch _inductor config patch emulate_precision_casts=True test_emulate_precision_casts_norm_rounding torch manual_seed torch cuda manual_seed_all x = torch rand device= cuda dtype=torch bfloat scalar = torch rand device= cuda dtype=torch float fn inp scale y = inp norm y y + scale opt_fn = torch compile fn backend= inductor fullgraph=True dynamic=True expected = fn x scalar actual = opt_fn x scalar assertEqual expected actual torch _inductor config patch emulate_precision_casts=True test_emulate_precision_casts_min_pow_chain torch manual_seed torch cuda manual_seed_all dynamo_config patch capture_scalar_outputs=True capture_dynamic_output_shape_ops=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch bfloat device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True fn t = min dim= values t = t sum dim= t = - - - - t = t + t t = torch pow torch pow torch pow torch pow t t t t t t t opt_fn = torch compile fn backend= inductor fullgraph=True dynamic=True eager_out = fn arg arg arg arg compiled_args = arg clone detach requires_grad_ True arg clone detach requires_grad_ True arg clone detach requires_grad_ True arg clone detach requires_grad_ True compiled_out = opt_fn compiled_args eager_tensor compiled_tensor zip eager_out compiled_out torch testing assert_close eager_tensor compiled_tensor rtol= e- atol= e- torch _inductor config patch emulate_precision_casts=True test_emulate_precision_casts_mean_ratio_chain torch manual_seed torch cuda manual_seed_all dynamo_config patch capture_scalar_outputs=True capture_dynamic_output_shape_ops=True arg = torch rand dtype=torch bfloat device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True arg = torch rand dtype=torch float device= cuda requires_grad=True fn t = view mean dim= t = - - - - t = t view t = torch nn functional relu mean dim= t = t - t t = t t t t t opt_fn = torch compile fn backend= inductor fullgraph=True dynamic=True eager_out = fn arg arg arg arg arg arg compiled_args = tensor clone detach requires_grad_ True tensor arg arg arg arg arg arg compiled_out = opt_fn compiled_args torch testing assert_close eager_out compiled_out rtol= e- atol= e- torch _inductor config patch emulate_precision_casts=True test_dont_inplace_disjoint_accesses TODO - would need mms we could annotate donated buffer forward noqa F F arg _ bf cuda noqa F F arg _ bf cuda noqa F F arg _ bf cuda noqa F F arg _ bf cuda noqa F F arg _ bf cuda noqa F F arg _ bf cuda noqa F F arg _ f cuda noqa F F arg _ f cuda noqa F F permute = torch ops aten permute default arg _ arg _ = None view = torch ops aten view default arg _ mm = torch ops aten mm default view permute view = permute = None view_ = torch ops aten view default mm mm = None permute_ = torch ops aten permute default arg _ arg _ = None view_ = torch ops aten view default arg _ mm_ = torch ops aten mm default view_ permute_ view_ = permute_ = None view_ = torch ops aten view default mm_ mm_ = None permute_ = torch ops aten permute default arg _ arg _ = None view_ = torch ops aten view default arg _ arg _ = None mm_ = torch ops aten mm default view_ permute_ view_ = permute_ = None view_ = torch ops aten view default mm_ mm_ = None convert_element_type_ = torch ops prims convert_element_type default view_ torch float view_ = None pow_ = torch ops aten pow Tensor_Scalar convert_element_type_ mean = torch ops aten mean dim pow_ - True pow_ = None add = torch ops aten add Tensor mean e- mean = None rsqrt = torch ops aten rsqrt default add add = None mul = torch ops aten mul Tensor convert_element_type_ rsqrt convert_element_type_ = rsqrt = None convert_element_type_ = torch ops prims convert_element_type default arg _ torch float arg _ = None mul_ = torch ops aten mul Tensor convert_element_type_ mul convert_element_type_ = mul = None convert_element_type_ = torch ops prims convert_element_type default mul_ torch bfloat mul_ = None convert_element_type_ = torch ops prims convert_element_type default view_ torch float view_ = None pow_ = torch ops aten pow Tensor_Scalar convert_element_type_ mean_ = torch ops aten mean dim pow_ - True pow_ = None add_ = torch ops aten add Tensor mean_ e- mean_ = None rsqrt_ = torch ops aten rsqrt default add_ add_ = None mul_ = torch ops aten mul Tensor convert_element_type_ rsqrt_ convert_element_type_ = rsqrt_ = None convert_element_type_ = torch ops prims convert_element_type default arg _ torch float arg _ = None mul_ = torch ops aten mul Tensor convert_element_type_ mul_ convert_element_type_ = mul_ = None convert_element_type_ = torch ops prims convert_element_type default mul_ torch bfloat mul_ = None view_ = torch ops aten view default convert_element_type_ - convert_element_type_ = None view_ = torch ops aten view default convert_element_type_ - convert_element_type_ = None view_ = torch ops aten view default view_ - view_ = None convert_element_type_ = torch ops prims convert_element_type default view_ torch float view_ = None convert_element_type_ = torch ops prims convert_element_type default view_ torch float view_ = None unsqueeze = torch ops aten unsqueeze default arg _ unsqueeze_ = torch ops aten unsqueeze default unsqueeze unsqueeze = None unsqueeze_ = torch ops aten unsqueeze default arg _ unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ unsqueeze_ = None mul_ = torch ops aten mul Tensor convert_element_type_ unsqueeze_ unsqueeze_ = None view_ = torch ops aten view default convert_element_type_ convert_element_type_ = None unbind = torch ops aten unbind int view_ - view_ = None getitem = unbind getitem_ = unbind unbind = None neg = torch ops aten neg default getitem_ getitem_ = None cat = torch ops aten cat default neg getitem - neg = getitem = None mul_ = torch ops aten mul Tensor cat unsqueeze_ cat = unsqueeze_ = None add_ = torch ops aten add Tensor mul_ mul_ mul_ = mul_ = None unsqueeze_ = torch ops aten unsqueeze default arg _ arg _ = None unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ unsqueeze_ = None unsqueeze_ = torch ops aten unsqueeze default arg _ arg _ = None unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ unsqueeze_ = None mul_ = torch ops aten mul Tensor convert_element_type_ unsqueeze_ unsqueeze_ = None view_ = torch ops aten view default convert_element_type_ convert_element_type_ = None unbind_ = torch ops aten unbind int view_ - view_ = None getitem_ = unbind_ getitem_ = unbind_ unbind_ = None neg_ = torch ops aten neg default getitem_ getitem_ = None cat_ = torch ops aten cat default neg_ getitem_ - neg_ = getitem_ = None mul_ = torch ops aten mul Tensor cat_ unsqueeze_ cat_ = unsqueeze_ = None add_ = torch ops aten add Tensor mul_ mul_ mul_ = mul_ = None convert_element_type_ = torch ops prims convert_element_type default add_ torch bfloat add_ = None convert_element_type_ = torch ops prims convert_element_type default add_ torch bfloat add_ = None permute_ = torch ops aten permute default convert_element_type_ convert_element_type_ = None permute_ = torch ops aten permute default convert_element_type_ convert_element_type_ = None permute_ = torch ops aten permute default view_ view_ = None permute_ permute_ permute_ torch _dynamo debug_utils aot_graph_input_parser kwargs = aot_graph_input_parser forward out code = run_and_get_code torch compile forward kwargs ignore tiny values prior fix absolute error ~ assertEqual forward kwargs out atol= rtol= FileCheck check_not in_out run code https github com pytorch pytorch issues test_linear_with_zero_infeature_size m = nn Linear in_features= out_features= bias=True cuda x = torch rand device= cuda expect = m x opt_fn = torch compile m actual = opt_fn x assertEqual expect actual config patch fallback_random=True test_multi_output_layout_fallback mod = nn RReLU lower= upper= inplace=True inp = torch rand cuda m = torch compile mod freeze_rng_state o = m inp clone o = mod inp clone assertEqual o o test_sorted_masks torch compile foo x y x + y sum dim= x = torch rand device= cuda y = torch rand device= cuda _ code = run_and_get_code foo x y FileCheck check tl load check_same r _mask check_same xmask run code test_cat_int _one_kernel torch compile cat inps torch cat inps + dtype torch uint torch int inps = torch empty dtype=dtype device= cuda _ range out code = run_and_get_code cat inps assertEqual torch cat inps + out FileCheck check_not aten cat default check_count run exactly=True run code config patch triton use_block_ptr True test_selecsls b_misaligned_address https github com triton-lang triton issues torch compile fullgraph=True fn arg _ arg _ convert_element_type_ expand full mul_ div = torch ops aten div Scalar expand where = torch ops aten where arg _ full div convert_element_type_ = torch ops prims convert_element_type default where torch float sum_ = torch ops aten sum dim_IntList convert_element_type_ sub = torch ops aten sub Tensor convert_element_type_ arg _ mul = torch ops aten mul Tensor convert_element_type_ sub sum_ = torch ops aten sum dim_IntList mul mul_ = torch ops aten mul Tensor sum_ unsqueeze = torch ops aten unsqueeze default mul_ unsqueeze_ = torch ops aten unsqueeze default unsqueeze unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ mul_ = torch ops aten mul Tensor sum_ mul_ = torch ops aten mul Tensor mul_ mul_ unsqueeze_ = torch ops aten unsqueeze default mul_ unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ unsqueeze_ = torch ops aten unsqueeze default unsqueeze_ mul_ = torch ops aten mul Tensor sub unsqueeze_ sub_ = torch ops aten sub Tensor convert_element_type_ mul_ sub_ = torch ops aten sub Tensor sub_ unsqueeze_ sub_ args = torch randn device= cuda torch bool tensor torch randn device= cuda torch randn device= cuda torch randn dtype=torch float device= cuda expand torch randn device= cuda torch randn device= cuda fn args torch cuda synchronize shake out Triton Error CUDA misaligned address test_mutated_aligned_tensor t = torch rand device= cuda dtype=torch float foo x x add_ foo_c = torch compile dynamic=False foo t_orig = t clone First invocation assume alignment second invocation copy alignment then mutate after fn invocation assertEqual foo_c t - foo t_orig - assertEqual t t_orig assertEqual foo_c t foo t_orig assertEqual t t_orig test_non_commutative_scan_op torch _higher_order_ops associative_scan associative_scan = torch randn dtype=torch float device= cuda b = torch randn dtype=torch float device= cuda baseline v u A = A append b i range v shape A append i A i - + b i torch stack A dim= combine_fn i j ia ib = i ja jb = j ia ja ib ja + jb torch compile compiled_scan b associative_scan combine_fn b dim=- out = baseline b out = compiled_scan b assertEqual out out test_dynamic_persistent_reductions torch compile dynamic=True inner_reduce x assert x shape = x sum = torch randn device= cuda out code = run_and_get_code inner_reduce assertEqual inner_reduce out assertTrue roffset code torch compile dynamic=True outer_reduce x assert x shape = x sum out code = run_and_get_code outer_reduce assertEqual outer_reduce out assertTrue roffset code test_scaled_dot_product_efficient_attention_backward torch nn Tensor SelfAttention nn Module __init__ num_attention_heads int = hidden_size int = attention_probs_dropout_prob float = super __init__ num_attention_heads = num_attention_heads attention_head_size = hidden_size num_attention_heads query = nn Linear hidden_size hidden_size key = nn Linear hidden_size hidden_size value = nn Linear hidden_size hidden_size dropout_prob = attention_probs_dropout_prob transpose_for_scores x Tensor - Tensor new_x_shape = x size - + num_attention_heads attention_head_size x view new_x_shape permute forward hidden_states Tensor attention_mask Tensor - Tensor query_layer = transpose_for_scores query hidden_states key_layer = transpose_for_scores key hidden_states value_layer = transpose_for_scores value hidden_states attn_output = torch nn functional scaled_dot_product_attention query_layer key_layer value_layer attn_mask=attention_mask dropout_p=self dropout_prob training is_causal=False attn_output device = torch device cuda num_attention_heads = hidden_size = attention_probs_dropout_prob = model = SelfAttention num_attention_heads=num_attention_heads hidden_size=hidden_size attention_probs_dropout_prob=attention_probs_dropout_prob device model = torch compile model runs without failure batch_size = length = inputs_embeds = torch randn batch_size length hidden_size device=device attention_mask = torch ones batch_size length length device=device attn_output = model hidden_states=inputs_embeds attention_mask=attention_mask loss = attn_output mean loss backward test_non_contiguous_unaligned_input_indices torch _inductor compile_fx remove_unaligned_input_idxs inputs = torch ones device= cuda torch ones device= cuda idxs = remove_unaligned_input_idxs inputs assertEqual idxs inputs = torch ones device= cuda torch ones device= cuda torch ones device= cuda idxs = remove_unaligned_input_idxs inputs assertEqual idxs config patch triton cudagraphs True test_unused_cpu_input_cudagraphs fn x y x sin sin sin sin cos + fx_graph = torch fx symbolic_trace fn inp = torch randn device= cuda torch randn device= cpu compiled_fn graph = run_and_get_graph_lowering torch _inductor compile fx_graph inp assertEqual graph disable_cudagraphs_reason None assertEqual graph device_types cuda assertEqual compiled_fn inp fn inp test_epilogue_fusion_with_view ToyModel torch nn Module __init__ - None super __init__ conv = torch nn Conv d kernel_size= stride= padding= linear = torch nn Linear relu = torch nn ReLU forward x x = conv x x = x view x size - relu linear x m = ToyModel device= cuda input_tensor = torch randn device= cuda torch _inductor utils fresh_cache fresh_cache cm = torch compile m mode= max-autotune out = cm input_tensor out = m input_tensor assertEqual out out atol= e- rtol= e- config patch triton cudagraphs True test_cpu_index torch compile fullgraph=True fn x x torch arange result graph = run_and_get_graph_lowering fn torch randn device= cuda assertEqual graph disable_cudagraphs_reason None assertEqual graph device_types cuda inp = torch randn device= cuda requires_grad=True result graph = run_and_get_graph_lowering fn inp assertEqual graph disable_cudagraphs_reason None assertEqual graph device_types cuda result graph = run_and_get_graph_lowering lambda result sum backward assertEqual graph disable_cudagraphs_reason None assertEqual graph device_types cuda unittest skipIf IS_FBCODE Not runnable fbcode test_triton_interpret subprocess script = os os environ TRITON_INTERPRET = torch torch compile foo x x + somehow gives different results still check doesn t error foo torch rand device= cuda subprocess run sys executable -c script check=True test_reflection_pad_loop_order fn x y = torch nn functional pad x mode= reflect b = torch nn functional pad y mode= reflect + b cfn = torch compile fn = torch rand device= cuda b = torch rand device= cuda expect = fn b actual code = run_and_get_code cfn b assertEqual expect actual Expect code iterates contiguous order tiled lines = code split \n start = lines index triton jit kernel_code = \n join lines start start + assertExpectedInline kernel_code \ triton jit triton_poi_fused_add_reflection_pad d_ in_ptr in_ptr out_ptr xnumel XBLOCK tl constexpr xnumel = xoffset = tl program_id XBLOCK xindex = xoffset + tl arange XBLOCK xmask = xindex xnumel x = xindex x = xindex x = xindex x = xindex tmp = tl load in_ptr + + - tl_math abs - + tl_math abs - + x + - tl_math abs - + tl_math abs - + x + x xmask eviction_policy= evict_last tmp = tl load in_ptr + + - tl_math abs - + tl_math abs - + x + - tl_math abs - + tl_math abs - + x + x xmask eviction_policy= evict_last tmp = tmp + tmp tl store out_ptr + x tmp xmask noqa B skipCUDAIf SM OrLater uses bfloat which requires SM = test_int _index_intermediate foo inp view_ = torch ops aten view default inp - split_ = torch ops aten split Tensor view_ view_ = None getitem_ = split_ getitem_ = split_ getitem_ = split_ getitem_ = split_ getitem_ = split_ getitem_ = split_ getitem_ = split_ getitem_ = split_ split_ = None cat_ = torch ops aten cat default getitem_ getitem_ getitem_ getitem_ getitem_ getitem_ getitem_ getitem_ getitem_ = getitem_ = getitem_ = getitem_ = getitem_ = getitem_ = getitem_ = getitem_ = None cat_ mark_dynamic False True inp = torch rand dtype=torch bfloat device= cuda mark_dynamic torch _dynamo mark_dynamic inp foo_c = torch compile foo torch testing assert_allclose foo inp foo_c inp skipCUDAIf SM OrLater uses bfloat atomic add instrs which requires SM = test_float _e m fnu device = cuda dtype = torch float _e m fnu hp_dtype = torch float torch bfloat foo x x = x dtype x = x hp_dtype x x = torch randn device=device dtype=hp_dtype foo_c = torch compile foo backend= inductor fullgraph=True torch no_grad y_c = foo_c x assertEqual foo x y_c dtype = torch float _e m fnu foo x x = x + x = x view dtype view x x = torch randint device=device dtype=torch uint foo_c = torch compile foo backend= inductor fullgraph=True torch no_grad result code = run_and_get_code foo_c x FileCheck check call check_not torch ops aten reshape default run code assertEqual foo x result unittest skipIf config is_fbcode bfloat atomic add only supported fbcode today skipCUDAIf SM OrLater uses bfloat atomic add instrs which requires SM = test_atomic_add_bfloat f x y torch index_select x y x = torch randn dtype=torch bfloat device= cuda requires_grad=True y = torch ones dtype=torch int device= cuda x_ref = x clone detach requires_grad_ True y_ref = y clone detach out _ bw_code = run_fw_bw_and_get_code lambda torch compile f x y fc = FileCheck fc check tl atomic_add fc run bw_code assertEqual f x_ref y_ref out test_red_dtype_mismatch per True False torch _dynamo reset per torch _inductor config triton persistent_reductions = False f arg _ arg _ embedding = torch ops aten embedding default arg _ arg _ view = torch ops aten view default embedding unsqueeze = torch ops aten unsqueeze default view expand = torch ops aten expand default unsqueeze - - view_ = torch ops aten view default expand permute = torch ops aten permute default view_ clone = torch ops aten clone default permute memory_format=torch contiguous_format view_ = torch ops aten view default clone iota = torch ops prims iota default start= step= dtype=torch int device= cuda requires_grad=False view_ = torch ops aten view default iota max_ = torch ops aten max default view_ max_ x = torch ones device= cuda dtype=torch int y = torch randn device= cuda dtype=torch bfloat out = f x y assertEqual torch compile f x y out unittest skipIf config is_fbcode bfloat atomic add only supported fbcode today skipCUDAIf SM OrLater uses bfloat atomic add instrs which requires SM = config patch bfloat _atomic_adds_enabled False test_atomic_add_bfloat _config f x y torch index_select x y x = torch randn dtype=torch bfloat device= cuda requires_grad=True y = torch ones dtype=torch int device= cuda x_ref = x clone detach requires_grad_ True y_ref = y clone detach out _ bw_code = run_fw_bw_and_get_code lambda torch compile f x y fc = FileCheck fc check_not tl atomic_add fc run bw_code assertEqual f x_ref y_ref out skipCUDAIf SM OrLater uses bfloat atomic add instrs which requires SM = unittest skipIf config is_fbcode bfloat atomic add supported fbcode so we won t fallback test_index_add_fallback f x y torch index_select x y x = torch randn dtype=torch bfloat device= cuda requires_grad=True y = torch ones dtype=torch int device= cuda x_ref = x clone detach requires_grad_ True y_ref = y clone detach out _ bw_code = run_fw_bw_and_get_code lambda torch compile f x y fc = FileCheck fc check aten index_add fc run bw_code assertEqual f x_ref y_ref out requires_multigpu test_not_initializing_wrong_device device_stats = torch cuda memory_stats cuda torch compile foo x y x y x = torch rand device= cuda requires_grad=True y = torch rand device= cuda requires_grad=True foo x y sum backward device_stats = torch cuda memory_stats cuda assertTrue device_stats active all peak = device_stats active all peak config patch triton prefer_nd_tiling True triton max_tiles test_ d_tiling full_size view_size num_block_pointers num_tiles = GPU_TYPE = cuda get_input - torch Tensor device = torch device GPU_TYPE full = torch randn full_size device torch as_strided full view_size full stride b = get_input get_input opt_fn = torch compile functools partial torch add result code = run_and_get_code opt_fn b assertEqual result + b assertIn znumel code xfailIfPy Plus https github com pytorch pytorch issues unittest skipIf config is_fbcode Dependence functorch einops test_repeated_masked_load target_size = mem_eff_temporal_upsampling_interp_chunks = functorch einops rearrange x = torch randn dtype=torch float device= cuda x = x permute make non-contiguous x = rearrange x b c t h w - b c t h w interpolate_chunked x chunk along c chunks = x chunk chunks=mem_eff_temporal_upsampling_interp_chunks dim= r = t chunks r append torch nn functional interpolate t float size=target_size mode= nearest t dtype out_chunked = torch cat r dim= out_chunked out_eager = interpolate_chunked x out_compiled = torch compile interpolate_chunked x assertEqual out_eager out_compiled test_max_autotune_nograd https github com pytorch pytorch issues Smallest repro max-autotune working no_grad Before adding __int__ function torch utils _sympy functions Identity running max_autotune mode would raise error TypeError Expected number got Identity ToyModel torch nn Module __init__ super __init__ linear_layers = nn ModuleList nn Linear bias=True nn Linear bias=True nn Linear bias=True nn Linear bias=True nn Linear bias=True forward x layer linear_layers x = layer x x = F relu x x = torch cat x x dim= x model = ToyModel cuda input_tensor = torch randn cuda compile_default = torch compile model mode= default compile_max_autotune = torch compile model mode= max-autotune torch no_grad default_output = compile_default input_tensor max_autotune_output = compile_max_autotune input_tensor assertEqual default_output max_autotune_output test_adaptive_avg_pool d_issue_ Test GitHub issue Conv d-unsqueeze-AdaptiveAvgPool d produces incorrect results Model torch nn Module __init__ super __init__ conv = torch nn Conv d kernel_size= stride= padding= adaptive_pool = torch nn AdaptiveAvgPool d forward x x = conv x This specific unsqueeze position problematic due zero strides x = x unsqueeze x = adaptive_pool x x model = Model cuda model eval test_cases = batch channels h w test_cases subTest input_shape= batch channels h w input_tensor = torch randn batch channels h w device= cuda Test eager mode torch no_grad eager_output = model input_tensor Test compiled mode inductor compiled_model = torch compile model backend= inductor torch no_grad compiled_output = compiled_model input_tensor They should identical very close assertTrue torch allclose eager_output compiled_output rtol= e- atol= e- f Results differ input shape batch channels h w f Max diff torch max torch abs eager_output - compiled_output f parametrize quantiles_shape quantiles_strides batch_size Contiguous C-order Transposed F-order Transposed different size Transposed medium Transposed large x small Transposed small x large D case mixed strides D case different stride order test_searchsorted_stride_permutations quantiles_shape quantiles_strides batch_size Foo torch nn Module __init__ quantiles torch Tensor - None super __init__ assert quantiles shape quantiles = quantiles T q = torch nn Parameter quantiles requires_grad=False forward x torch Tensor - torch Tensor torch searchsorted q x T T torch manual_seed Create contiguous tensor first numel = dim quantiles_shape numel = dim data = torch randn numel dtype=torch float device= cuda Create tensor specified shape strides quantiles = torch as_strided data size=quantiles_shape stride=quantiles_strides quantiles = torch sort quantiles dim= x_shape = batch_size + quantiles_shape x = torch randn x_shape dtype=torch float device= cuda foo = Foo quantiles foo_compiled = torch compile Foo quantiles fullgraph=True Test eager vs compiled torch no_grad eager = foo x compiled = foo_compiled x assertEqual eager compiled test_identity_load device = cuda f x y y = torch cat x y None + dim= x = x None y = y - None torch cat x y dim= + torch arange - device=device None None reshape This succeeds eager_out = f torch zeros dtype=torch int device=device torch zeros dtype=torch int device=device This crashes compile_out code = run_and_get_code torch compile f torch zeros dtype=torch int device=device torch zeros dtype=torch int device=device make sure identity maintained FileCheck check + run code assertEqual eager_out compile_out test_qwen _ b_sdpa_input_alignment_requires_recompile SDPA constraints ensures inputs have alignment device = cuda forward q_proj k_proj attn_mask scale = sqrt B = attn_mask size S = attn_mask size D = d_model = q_proj size query_states = q_proj view B S - D transpose B Hq S D q = query_states contiguous Hkv = k_proj size D Hq = query_states size nrepeats = Hq Hkv key_states = k_proj view B S - D transpose B Hkv S D kv_repeated = key_states None expand B Hkv nrepeats S D kv_repeated = kv_repeated contiguous k = kv_repeated reshape B Hq S D v = k clone value tensor inf = torch scalar_tensor float -inf dtype=torch bfloat device=device zero = torch scalar_tensor dtype=torch bfloat device=device where = torch where condition=attn_mask input=zero other=inf pad_amount = - S padded = torch nn functional pad where pad_amount value= pad last-dim sliced = padded S back B S S attn_bias = sliced expand B Hq S S sdpa_out logsumexp seed offset = torch ops aten _scaled_dot_product_efficient_attention default q k v attn_bias dropout_p= is_causal=True scale=scale compute_log_sumexp=True zeros = torch zeros B S d_model device=device dtype=torch bfloat zeros = zeros reshape B S Hq D grad_out = zeros permute out = torch ops aten _scaled_dot_product_efficient_attention_backward default grad_out q k v attn_bias sdpa_out logsumexp seed offset dropout_p= scale=scale grad_input_mask= True True True False out B = S = D = Hq = Hkv = example_inputs = torch randn B S Hq D dtype=torch bfloat device=device q_proj torch randn B S Hkv D dtype=torch bfloat device=device k_proj torch zeros B S S dtype=torch bool device=device attn_mask correct = forward example_inputs compiled = torch compile forward dynamic=True actual = compiled example_inputs assertEqual actual correct run once more seqlen isn t divisible S = example_inputs = torch randn S B Hq D dtype=torch bfloat device=device q_proj torch randn S B Hkv D dtype=torch bfloat device=device k_proj torch zeros B S S dtype=torch bool device=device attn_mask correct = forward example_inputs actual = compiled example_inputs assertEqual actual correct config patch emulate_divison_rounding True test_truediv_emulate_divison_rounding decimal Decimal y x = torch compile compiled_divide x y x y y_dtype torch float torch bfloat torch float torch float x_dtype torch float torch bfloat torch float torch float y_ten = torch tensor y dtype=y_dtype device= cuda x_ten = torch tensor x dtype=x_dtype device= cuda torch _dynamo reset compiled_div = Decimal compiled_divide x_ten y_ten item eager_div = Decimal x_ten y_ten item assertEqual eager_div compiled_div config patch emulate_divison_rounding False test_truediv_base_not_bitwise_equivalent decimal Decimal y x = y_ten = torch tensor y dtype=torch float device= cuda x_ten = torch tensor x dtype=torch float device= cuda compile_out code = run_and_get_code torch compile lambda x y x y x_ten y_ten compiled_div = Decimal compile_out item eager_div = Decimal x_ten y_ten item assertNotEqual eager_div compiled_div assertTrue div_rn code __name__ == __main__ torch _inductor test_case run_tests torch testing _internal inductor_utils HAS_CUDA_AND_TRITON HAS_CUDA_AND_TRITON TEST_WITH_ASAN run_tests needs= filelock