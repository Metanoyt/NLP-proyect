Owner s module distributions Note Randomized statistical tests ----------------------------------- This note describes how maintain tests file random sources change This file contains two types randomized tests The easier type randomized test tests should always pass initialized random data If these fail something wrong s fine use fixed seed inheriting common TestCase The trickier tests statistical tests These tests explicitly call set_rng_seed n marked see Note Randomized statistical tests These statistical tests have known positive failure rate we set failure_rate= e- default We need balance strength these tests annoyance false alarms One way works specifically set seeds each randomized tests When random generator occasionally changes vectorizing Box-Muller sampler some these statistical tests may rarely fail If one fails case s fine increment seed failing test you shouldn t need increment more than once otherwise something probably actually wrong ` test_geometric_sample ` ` test_binomial_sample ` ` test_poisson_sample ` validated against ` scipy stats ` which guaranteed identical across different versions scipy namely they yield invalid results + math numbers unittest collections namedtuple itertools product random shuffle packaging version torch torch autograd forward_ad fwAD torch inf nan torch autograd grad torch autograd functional jacobian torch distributions Bernoulli Beta Binomial Categorical Cauchy Chi constraints ContinuousBernoulli Dirichlet Distribution Exponential ExponentialFamily FisherSnedecor Gamma GeneralizedPareto Geometric Gumbel HalfCauchy HalfNormal Independent InverseGamma kl_divergence Kumaraswamy Laplace LKJCholesky LogisticNormal LogNormal LowRankMultivariateNormal MixtureSameFamily Multinomial MultivariateNormal NegativeBinomial Normal OneHotCategorical OneHotCategoricalStraightThrough Pareto Poisson RelaxedBernoulli RelaxedOneHotCategorical StudentT TransformedDistribution Uniform VonMises Weibull Wishart torch distributions constraint_registry transform_to torch distributions constraints Constraint is_dependent torch distributions dirichlet _Dirichlet_backward torch distributions kl _kl_expfamily_expfamily torch distributions transforms AffineTransform CatTransform ExpTransform identity_transform StackTransform torch distributions utils lazy_property probs_to_logits tril_matrix_to_vec vec_to_tril_matrix torch nn functional softmax torch testing _internal common_cuda TEST_CUDA torch testing _internal common_utils gradcheck load_tests run_tests set_default_dtype set_rng_seed skipIfTorchDynamo TEST_XPU TestCase device_type = acc type acc = torch accelerator current_accelerator cpu load_tests torch testing _internal common_utils used automatically filter tests sharding sandcastle This line silences flake warnings load_tests = load_tests noqa PLW TEST_NUMPY = True try numpy np scipy special scipy stats except ImportError TEST_NUMPY = False pairwise Dist params Creates pair distributions ` Dist ` initialized test each element param each other params = torch tensor p len p p params params = p transpose p params Dist params Dist params is_all_nan tensor Checks all entries tensor nan tensor = tensor all Example = namedtuple Example Dist params Register all distributions generic tests appending list _get_examples Example Bernoulli probs torch tensor requires_grad=True probs torch tensor requires_grad=True probs logits torch tensor requires_grad=True Example Geometric probs torch tensor requires_grad=True probs torch tensor requires_grad=True probs Example Beta concentration torch randn exp requires_grad_ concentration torch randn exp requires_grad_ concentration torch randn exp requires_grad_ concentration torch randn exp requires_grad_ Example Categorical probs torch tensor requires_grad=True probs torch tensor requires_grad=True logits torch tensor requires_grad=True Example Binomial probs torch tensor requires_grad=True total_count probs torch tensor requires_grad=True total_count probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor Example NegativeBinomial probs torch tensor requires_grad=True total_count probs torch tensor requires_grad=True total_count probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor probs torch tensor requires_grad=True total_count torch tensor Example Multinomial probs torch tensor requires_grad=True total_count probs torch tensor requires_grad=True total_count Example Cauchy loc scale loc torch tensor scale loc torch tensor scale torch tensor Example Chi df torch randn exp requires_grad_ df torch randn exp requires_grad_ Example StudentT df torch randn exp requires_grad_ df torch randn exp requires_grad_ Example Dirichlet concentration torch randn exp requires_grad_ concentration torch randn exp requires_grad_ Example Exponential rate torch randn abs requires_grad_ rate torch randn abs requires_grad_ Example FisherSnedecor df torch randn abs requires_grad_ df torch randn abs requires_grad_ df torch randn abs requires_grad_ df torch randn abs requires_grad_ df torch tensor df Example Gamma concentration torch randn exp requires_grad_ rate torch randn exp requires_grad_ concentration torch randn exp requires_grad_ rate torch randn exp requires_grad_ Example Gumbel loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch randn requires_grad=True scale torch randn abs requires_grad_ Example HalfCauchy scale scale torch tensor Example HalfNormal scale torch randn abs requires_grad_ scale torch randn abs requires_grad_ scale torch tensor e- e- requires_grad=True Example Independent base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ reinterpreted_batch_ndims base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ reinterpreted_batch_ndims base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ reinterpreted_batch_ndims base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ reinterpreted_batch_ndims base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ reinterpreted_batch_ndims Example Kumaraswamy concentration torch empty uniform_ requires_grad_ concentration torch empty uniform_ requires_grad_ concentration torch rand uniform_ requires_grad_ concentration torch rand uniform_ requires_grad_ Example LKJCholesky dim concentration dim concentration torch tensor dim concentration Example Laplace loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch tensor requires_grad=True scale torch tensor e- e- requires_grad=True Example LogNormal loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch tensor requires_grad=True scale torch tensor e- e- requires_grad=True Example LogisticNormal loc torch randn requires_grad_ scale torch randn abs requires_grad_ loc torch randn requires_grad_ scale torch randn abs requires_grad_ loc torch tensor requires_grad=True scale torch tensor e- e- requires_grad=True Example LowRankMultivariateNormal loc torch randn requires_grad=True cov_factor torch randn requires_grad=True cov_diag torch tensor requires_grad=True loc torch randn requires_grad=True cov_factor torch randn requires_grad=True cov_diag torch tensor requires_grad=True Example MultivariateNormal loc torch randn requires_grad=True covariance_matrix torch tensor requires_grad=True loc torch randn requires_grad=True precision_matrix torch tensor requires_grad=True loc torch randn requires_grad=True scale_tril torch tensor - - requires_grad=True loc torch tensor - covariance_matrix torch tensor - - Example Normal loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch randn requires_grad=True scale torch randn abs requires_grad_ loc torch tensor requires_grad=True scale torch tensor e- e- requires_grad=True Example OneHotCategorical probs torch tensor requires_grad=True probs torch tensor requires_grad=True logits torch tensor requires_grad=True Example OneHotCategoricalStraightThrough probs torch tensor requires_grad=True probs torch tensor requires_grad=True logits torch tensor requires_grad=True Example Pareto scale alpha scale torch randn abs + requires_grad_ alpha torch randn abs + requires_grad_ scale torch tensor alpha Example Poisson rate torch randn abs requires_grad_ rate torch randn abs requires_grad_ rate rate torch tensor requires_grad=True rate Example RelaxedBernoulli temperature torch tensor requires_grad=True probs torch tensor requires_grad=True temperature torch tensor probs torch tensor temperature torch tensor logits torch tensor - Example RelaxedOneHotCategorical temperature torch tensor requires_grad=True probs torch tensor requires_grad=True temperature torch tensor probs torch tensor temperature torch tensor logits torch tensor - Example TransformedDistribution base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ transforms base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ transforms ExpTransform base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ transforms AffineTransform torch randn torch randn ExpTransform base_distribution Normal torch randn requires_grad=True torch randn abs requires_grad_ transforms AffineTransform base_distribution Uniform torch tensor e log torch tensor e log transforms ExpTransform Example Uniform low torch zeros requires_grad=True high torch ones requires_grad=True low torch zeros requires_grad=True high torch ones requires_grad=True low torch tensor requires_grad=True high torch tensor requires_grad=True Example Weibull scale torch randn abs requires_grad_ concentration torch randn abs requires_grad_ Example Wishart covariance_matrix torch tensor requires_grad=True df torch tensor requires_grad=True precision_matrix torch tensor requires_grad=True df torch tensor requires_grad=True scale_tril torch tensor - - requires_grad=True df torch tensor requires_grad=True covariance_matrix torch tensor - - df torch tensor covariance_matrix torch tensor - - df Example MixtureSameFamily mixture_distribution Categorical torch rand requires_grad=True component_distribution Normal torch randn requires_grad=True torch rand requires_grad=True mixture_distribution Categorical torch rand requires_grad=True component_distribution MultivariateNormal loc=torch randn requires_grad=True covariance_matrix=torch tensor requires_grad=True Example VonMises loc torch tensor requires_grad=True concentration torch tensor requires_grad=True loc torch tensor math pi requires_grad=True concentration torch tensor requires_grad=True Example ContinuousBernoulli probs torch tensor requires_grad=True probs torch tensor requires_grad=True probs logits torch tensor requires_grad=True Example InverseGamma concentration torch randn exp requires_grad_ rate torch randn exp requires_grad_ concentration torch randn exp requires_grad_ rate torch randn exp requires_grad_ Example GeneralizedPareto loc torch randn requires_grad=True mul scale torch randn abs requires_grad_ concentration torch randn div requires_grad_ Register all distributions bad examples appending list _get_bad_examples Example Bernoulli probs torch tensor requires_grad=True probs torch tensor - requires_grad=True probs Example Beta concentration torch tensor requires_grad=True concentration torch tensor requires_grad=True concentration torch tensor - requires_grad=True concentration torch tensor - requires_grad=True Example Geometric probs torch tensor requires_grad=True probs torch tensor - requires_grad=True probs Example Categorical probs torch tensor - requires_grad=True probs torch tensor - - requires_grad=True Example Binomial probs torch tensor - requires_grad=True total_count probs torch tensor requires_grad=True total_count Example NegativeBinomial probs torch tensor - requires_grad=True total_count probs torch tensor requires_grad=True total_count Example Cauchy loc scale - loc torch tensor scale loc torch tensor - scale torch tensor - Example Chi df torch tensor requires_grad=True df torch tensor - requires_grad=True Example StudentT df torch tensor requires_grad=True df torch tensor - requires_grad=True Example Dirichlet concentration torch tensor requires_grad=True concentration torch tensor - requires_grad=True Example Exponential rate torch tensor requires_grad=True rate torch tensor - requires_grad=True Example FisherSnedecor df torch tensor requires_grad=True df torch tensor - - requires_grad=True df torch tensor requires_grad=True df torch tensor requires_grad=True Example Gamma concentration torch tensor requires_grad=True rate torch tensor - - requires_grad=True concentration torch tensor requires_grad=True rate torch tensor requires_grad=True Example Gumbel loc torch tensor requires_grad=True scale torch tensor requires_grad=True loc torch tensor requires_grad=True scale torch tensor - requires_grad=True Example HalfCauchy scale - scale scale torch tensor - Example HalfNormal scale torch tensor requires_grad=True scale torch tensor - requires_grad=True Example LKJCholesky dim - concentration dim concentration dim concentration Example Laplace loc torch tensor requires_grad=True scale torch tensor requires_grad=True loc torch tensor requires_grad=True scale torch tensor - requires_grad=True Example LogNormal loc torch tensor requires_grad=True scale torch tensor requires_grad=True loc torch tensor requires_grad=True scale torch tensor - requires_grad=True Example MultivariateNormal loc torch tensor requires_grad=True covariance_matrix torch tensor - requires_grad=True Example Normal loc torch tensor requires_grad=True scale torch tensor requires_grad=True loc torch tensor requires_grad=True scale torch tensor - requires_grad=True loc torch tensor requires_grad=True scale torch tensor e- - e- requires_grad=True Example OneHotCategorical probs torch tensor - requires_grad=True probs torch tensor requires_grad=True Example OneHotCategoricalStraightThrough probs torch tensor - requires_grad=True probs torch tensor requires_grad=True Example Pareto scale alpha scale torch tensor requires_grad=True alpha torch tensor - e- requires_grad=True scale torch tensor alpha - Example Poisson rate torch tensor - requires_grad=True rate - Example RelaxedBernoulli temperature torch tensor requires_grad=True probs torch tensor requires_grad=True temperature torch tensor probs torch tensor - Example RelaxedOneHotCategorical temperature torch tensor requires_grad=True probs torch tensor - requires_grad=True temperature torch tensor probs torch tensor - - Example TransformedDistribution base_distribution Normal transforms lambda x x base_distribution Normal transforms lambda x x Example Uniform low torch tensor requires_grad=True high torch tensor requires_grad=True low torch tensor requires_grad=True high torch tensor requires_grad=True low torch tensor requires_grad=True high torch tensor requires_grad=True Example Weibull scale torch tensor requires_grad=True concentration torch tensor requires_grad=True scale torch tensor requires_grad=True concentration torch tensor - requires_grad=True Example Wishart covariance_matrix torch tensor - requires_grad=True df torch tensor requires_grad=True covariance_matrix torch tensor - requires_grad=True df torch tensor requires_grad=True covariance_matrix torch tensor - requires_grad=True df Example ContinuousBernoulli probs torch tensor requires_grad=True probs torch tensor - requires_grad=True probs Example InverseGamma concentration torch tensor requires_grad=True rate torch tensor - - requires_grad=True concentration torch tensor requires_grad=True rate torch tensor requires_grad=True Example GeneralizedPareto loc torch tensor requires_grad=True scale torch tensor - - requires_grad=True concentration torch tensor requires_grad=True loc torch tensor requires_grad=True scale torch tensor requires_grad=True concentration torch tensor - - requires_grad=True DistributionsTestCase TestCase setUp The tests assume validation flag set torch distributions Distribution set_default_validate_args True super setUp skipIfTorchDynamo Not TorchDynamo suitable test TestDistributions DistributionsTestCase _do_cuda_memory_leak_check = True _do_cuda_non_default_stream = True _gradcheck_log_prob dist_ctor ctor_params performs gradient checks log_prob distribution = dist_ctor ctor_params s = distribution sample distribution support is_discrete s = s detach requires_grad_ expected_shape = distribution batch_shape + distribution event_shape assertEqual s size expected_shape apply_fn s params dist_ctor params log_prob s gradcheck apply_fn s + tuple ctor_params raise_exception=True _check_forward_ad fn fwAD dual_level x = torch tensor t = torch tensor dual = fwAD make_dual x t dual_out = fn dual assertEqual torch count_nonzero fwAD unpack_dual dual_out tangent item _check_log_prob dist asset_fn checks log_prob matches reference function s = dist sample log_probs = dist log_prob s log_probs_data_flat = log_probs view - s_data_flat = s view len log_probs_data_flat - i val log_prob enumerate zip s_data_flat log_probs_data_flat asset_fn i val squeeze log_prob _check_sampler_sampler torch_dist ref_dist message multivariate=False circular=False num_samples= failure_rate= e- Checks sample method matches reference function torch_samples = torch_dist sample num_samples squeeze torch_samples = torch_samples cpu numpy ref_samples = ref_dist rvs num_samples astype np float multivariate Project onto random axis axis = np random normal size= + torch_samples shape axis = np linalg norm axis torch_samples = axis torch_samples reshape num_samples - sum - ref_samples = axis ref_samples reshape num_samples - sum - samples = x + x torch_samples + x - x ref_samples circular samples = np cos x v x v samples shuffle samples necessary prevent stable sort making uneven bins discrete samples sort key=lambda x x samples = np array samples Aggregate into bins filled roughly zero-mean unit-variance RVs num_bins = samples_per_bin = len samples num_bins bins = samples reshape num_bins samples_per_bin mean axis= stddev = samples_per_bin - threshold = stddev scipy special erfinv - failure_rate num_bins message = f message sample biased \n bins bias bins assertLess -threshold bias message assertLess bias threshold message unittest skipIf TEST_NUMPY NumPy found _check_sampler_discrete torch_dist ref_dist message num_samples= failure_rate= e- Runs Chi -test support ignores tail instead combining torch_samples = torch_dist sample num_samples squeeze torch_samples = torch_samples float torch_samples dtype == torch bfloat torch_samples torch_samples = torch_samples cpu numpy unique counts = np unique torch_samples return_counts=True pmf = ref_dist pmf unique pmf = pmf pmf sum renormalize chisq test msk = counts pmf num_samples assertGreater pmf msk sum Distribution too sparse test try increasing num_samples Add remainder bucket combines counts all values below threshold such values exist i e mask has False entries msk all counts = np concatenate counts msk np sum counts ~msk keepdims=True pmf = np concatenate pmf msk np sum pmf ~msk keepdims=True _ p = scipy stats chisquare counts pmf num_samples assertGreater p failure_rate message _check_enumerate_support dist examples params expected examples params = k torch tensor v k v params items d = dist params actual = d enumerate_support expand=False expected = torch tensor expected dtype=actual dtype assertEqual actual expected actual = d enumerate_support expand=True expected_with_expand = expected expand - + d batch_shape + d event_shape assertEqual actual expected_with_expand test_repr Dist params _get_examples param params dist = Dist param assertTrue repr dist startswith dist __class__ __name__ test_sample_detached Dist params _get_examples i param enumerate params variable_params = p p param values getattr p requires_grad False variable_params continue dist = Dist param sample = dist sample assertFalse sample requires_grad msg=f Dist __name__ example i + len params sample detached skipIfTorchDynamo Not TorchDynamo suitable test test_rsample_requires_grad Dist params _get_examples i param enumerate params any getattr p requires_grad False p param values continue dist = Dist param dist has_rsample continue sample = dist rsample assertTrue sample requires_grad msg=f Dist __name__ example i + len params rsample does require grad test_enumerate_support_type Dist params _get_examples i param enumerate params dist = Dist param try assertTrue type dist sample type dist enumerate_support msg= example type mismatch between + sample enumerate_support format Dist __name__ i + len params except NotImplementedError pass test_lazy_property_grad x = torch randn requires_grad=True Dummy lazy_property y x + test x grad = None Dummy y backward assertEqual x grad torch ones test torch no_grad test mean = torch randn cov = torch eye requires_grad=True distn = MultivariateNormal mean cov torch no_grad distn scale_tril distn scale_tril sum backward assertIsNotNone cov grad test_has_examples distributions_with_examples = e Dist e _get_examples Dist globals values isinstance Dist type issubclass Dist Distribution Dist Distribution Dist ExponentialFamily assertIn Dist distributions_with_examples f Please add Dist __name__ _get_examples list test_distributions py test_support_attributes Dist params _get_examples param params d = Dist param event_dim = len d event_shape assertEqual d support event_dim event_dim try assertEqual Dist support event_dim event_dim except NotImplementedError pass is_discrete = d support is_discrete try assertEqual Dist support is_discrete is_discrete except NotImplementedError pass test_distribution_expand shapes = torch Size torch Size torch Size Dist params _get_examples param params shape shapes d = Dist param expanded_shape = shape + d batch_shape original_shape = d batch_shape + d event_shape expected_shape = shape + original_shape expanded = d expand batch_shape=list expanded_shape sample = expanded sample actual_shape = expanded sample shape assertEqual expanded __class__ d __class__ assertEqual d sample shape original_shape assertEqual expanded log_prob sample d log_prob sample assertEqual actual_shape expected_shape assertEqual expanded batch_shape expanded_shape try assertEqual expanded mean d mean expand expanded_shape + d event_shape assertEqual expanded variance d variance expand expanded_shape + d event_shape except NotImplementedError pass test_distribution_subclass_expand expand_by = torch Size Dist params _get_examples SubClass Dist pass param params d = SubClass param expanded_shape = expand_by + d batch_shape original_shape = d batch_shape + d event_shape expected_shape = expand_by + original_shape expanded = d expand batch_shape=expanded_shape sample = expanded sample actual_shape = expanded sample shape assertEqual expanded __class__ d __class__ assertEqual d sample shape original_shape assertEqual expanded log_prob sample d log_prob sample assertEqual actual_shape expected_shape set_default_dtype torch double test_bernoulli p = torch tensor requires_grad=True r = torch tensor requires_grad=True s = assertEqual Bernoulli p sample size assertFalse Bernoulli p sample requires_grad assertEqual Bernoulli r sample size assertEqual Bernoulli r sample size assertEqual Bernoulli r sample size assertEqual Bernoulli s sample size _gradcheck_log_prob Bernoulli p ref_log_prob idx val log_prob prob = p idx assertEqual log_prob math log prob val - prob _check_log_prob Bernoulli p ref_log_prob _check_log_prob Bernoulli logits=p log - -p log p ref_log_prob assertRaises NotImplementedError Bernoulli r rsample check entropy computation assertEqual Bernoulli p entropy torch tensor atol= e- rtol= assertEqual Bernoulli torch tensor entropy torch tensor assertEqual Bernoulli s entropy torch tensor atol= e- rtol= _check_forward_ad torch bernoulli _check_forward_ad lambda x x bernoulli_ _check_forward_ad lambda x x bernoulli_ x detach clone _check_forward_ad lambda x x bernoulli_ x test_bernoulli_enumerate_support examples = probs probs probs _check_enumerate_support Bernoulli examples test_bernoulli_ d p = torch full requires_grad_ assertEqual Bernoulli p sample size assertEqual Bernoulli p sample sample_shape= size assertEqual Bernoulli p sample size set_default_dtype torch double test_geometric p = torch tensor requires_grad=True r = torch tensor requires_grad=True s = assertEqual Geometric p sample size assertEqual Geometric sample assertEqual Geometric log_prob torch tensor -inf assertEqual Geometric log_prob torch tensor assertFalse Geometric p sample requires_grad assertEqual Geometric r sample size assertEqual Geometric r sample size assertEqual Geometric r sample size assertEqual Geometric s sample size _gradcheck_log_prob Geometric p assertRaises ValueError lambda Geometric assertRaises NotImplementedError Geometric r rsample _check_forward_ad lambda x x geometric_ unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_geometric_log_prob_and_entropy p = torch tensor requires_grad=True s = ref_log_prob idx val log_prob prob = p idx detach assertEqual log_prob scipy stats geom prob loc=- logpmf val _check_log_prob Geometric p ref_log_prob _check_log_prob Geometric logits=p log - -p log p ref_log_prob check entropy computation assertEqual Geometric p entropy scipy stats geom p detach numpy loc=- entropy atol= e- rtol= assertEqual float Geometric s entropy scipy stats geom s loc=- entropy item atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found test_geometric_sample set_rng_seed see Note Randomized statistical tests prob _check_sampler_discrete Geometric prob scipy stats geom p=prob loc=- f Geometric prob= prob set_default_dtype torch double test_binomial p = torch arange requires_grad_ total_count _gradcheck_log_prob lambda p Binomial total_count p p _gradcheck_log_prob lambda p Binomial total_count None p log p assertRaises NotImplementedError Binomial p rsample test_binomial_half = set_default_dtype torch float test_binomial test_binomial_bfloat = set_default_dtype torch bfloat test_binomial unittest skipIf TEST_NUMPY NumPy found test_binomial_sample set_rng_seed see Note Randomized statistical tests prob count _check_sampler_discrete Binomial total_count=count probs=prob scipy stats binom count prob f Binomial total_count= count probs= prob unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_binomial_log_prob_and_entropy probs = torch arange total_count ref_log_prob idx x log_prob p = probs view - idx item expected = scipy stats binom total_count p logpmf x assertEqual log_prob expected atol= e- rtol= _check_log_prob Binomial total_count probs ref_log_prob logits = probs_to_logits probs is_binary=True _check_log_prob Binomial total_count logits=logits ref_log_prob bin = Binomial total_count logits=logits assertEqual bin entropy scipy stats binom total_count bin probs detach numpy loc=- entropy atol= e- rtol= test_binomial_stable logits = torch tensor - dtype=torch float total_count = x = torch tensor dtype=torch float log_prob = Binomial total_count logits=logits log_prob x assertTrue torch isfinite log_prob all make sure grad logits= value= x = torch tensor requires_grad=True y = Binomial total_count logits=x log_prob torch tensor assertEqual grad y x torch tensor - unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_binomial_log_prob_vectorized_count probs = torch tensor total_count sample torch tensor torch tensor torch tensor torch tensor log_prob = Binomial total_count probs log_prob sample expected = scipy stats binom total_count cpu numpy probs cpu numpy logpmf sample assertEqual log_prob expected atol= e- rtol= test_binomial_enumerate_support examples = probs total_count probs total_count probs total_count _check_enumerate_support Binomial examples set_default_dtype torch double test_binomial_extreme_vals total_count = bin = Binomial total_count assertEqual bin sample assertEqual bin log_prob torch tensor atol= e- rtol= assertEqual float bin log_prob torch tensor exp bin = Binomial total_count assertEqual bin sample total_count assertEqual bin log_prob torch tensor float total_count atol= e- rtol= assertEqual float bin log_prob torch tensor float total_count - exp zero_counts = torch zeros torch Size bin = Binomial zero_counts assertEqual bin sample zero_counts assertEqual bin log_prob zero_counts zero_counts set_default_dtype torch double test_binomial_vectorized_count set_rng_seed see Note Randomized statistical tests total_count = torch tensor dtype=torch float bin = Binomial total_count torch tensor assertEqual bin sample total_count bin = Binomial total_count torch tensor samples = bin sample torch Size assertTrue samples = total_count type_as samples all assertEqual samples mean dim= bin mean atol= rtol= assertEqual samples var dim= bin variance atol= rtol= set_default_dtype torch double test_negative_binomial p = torch arange requires_grad_ total_count _gradcheck_log_prob lambda p NegativeBinomial total_count p p _gradcheck_log_prob lambda p NegativeBinomial total_count None p log p assertRaises NotImplementedError NegativeBinomial p rsample assertRaises NotImplementedError NegativeBinomial p entropy unittest skipIf TEST_NUMPY NumPy found test_negative_binomial_log_prob probs = torch arange total_count ref_log_prob idx x log_prob p = probs view - idx item expected = scipy stats nbinom total_count - p logpmf x assertEqual log_prob expected atol= e- rtol= _check_log_prob NegativeBinomial total_count probs ref_log_prob logits = probs_to_logits probs is_binary=True _check_log_prob NegativeBinomial total_count logits=logits ref_log_prob unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_negative_binomial_log_prob_vectorized_count probs = torch tensor total_count sample torch tensor torch tensor torch tensor torch tensor log_prob = NegativeBinomial total_count probs log_prob sample expected = scipy stats nbinom total_count cpu numpy - probs cpu numpy logpmf sample assertEqual log_prob expected atol= e- rtol= unittest skipIf TEST_CUDA TEST_XPU CUDA XPU found test_zero_excluded_binomial vals = Binomial total_count=torch tensor device_type probs=torch tensor device_type sample torch Size assertTrue vals = all vals = Binomial total_count=torch tensor device_type probs=torch tensor device_type sample torch Size assertTrue vals all vals = Binomial total_count=torch tensor device_type probs=torch tensor device_type sample torch Size vals should roughly half zeroes half ones assert vals == sum assert vals == sum test_torch_binomial_dtype_errors dtypes = torch int torch long torch short count_dtype dtypes total_count = torch tensor dtype=count_dtype total_prob = torch tensor dtype=torch float assertRaisesRegex ValueError binomial only supports floating-point dtypes count torch binomial total_count total_prob prob_dtype dtypes total_count = torch tensor dtype=torch float total_prob = torch tensor dtype=prob_dtype assertRaisesRegex ValueError binomial only supports floating-point dtypes prob torch binomial total_count total_prob set_default_dtype torch double test_multinomial_ d total_count = p = torch tensor requires_grad=True assertEqual Multinomial total_count p sample size assertEqual Multinomial total_count p sample size assertEqual Multinomial total_count p sample size _gradcheck_log_prob lambda p Multinomial total_count p p _gradcheck_log_prob lambda p Multinomial total_count None p log p assertRaises NotImplementedError Multinomial p rsample unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_multinomial_ d_log_prob_and_entropy total_count = p = torch tensor requires_grad=True dist = Multinomial total_count probs=p x = dist sample log_prob = dist log_prob x expected = torch tensor scipy stats multinomial logpmf x numpy n=total_count p=dist probs detach numpy assertEqual log_prob expected dist = Multinomial total_count logits=p log x = dist sample log_prob = dist log_prob x expected = torch tensor scipy stats multinomial logpmf x numpy n=total_count p=dist probs detach numpy assertEqual log_prob expected expected = scipy stats multinomial entropy total_count dist probs detach numpy assertEqual dist entropy expected atol= e- rtol= set_default_dtype torch double test_multinomial_ d total_count = probabilities = probabilities_ = p = torch tensor probabilities requires_grad=True s = torch tensor probabilities_ requires_grad=True assertEqual Multinomial total_count p sample size assertEqual Multinomial total_count p sample sample_shape= size assertEqual Multinomial total_count p sample size set_rng_seed _gradcheck_log_prob lambda p Multinomial total_count p p _gradcheck_log_prob lambda p Multinomial total_count None p log p sample check extreme value probs assertEqual Multinomial total_count s sample torch tensor total_count total_count dtype=torch float test_multinomial_sequential_draw Adapted after script mentioned https github com pytorch pytorch issues torch manual_seed xDE B B A E prob = torch ones dups_mult = perm_counts_mult = _ range _ p = tuple torch multinomial prob prob numel replacement=False tolist p perm_counts_mult dups_mult += perm_counts_mult p += perm_counts_mult p = assertLess dups_mult set_default_dtype torch double test_categorical_ d p = torch tensor requires_grad=True assertTrue is_all_nan Categorical p mean assertTrue is_all_nan Categorical p variance assertEqual Categorical p sample size assertFalse Categorical p sample requires_grad assertEqual Categorical p sample size assertEqual Categorical p sample size _gradcheck_log_prob Categorical p assertRaises NotImplementedError Categorical p rsample set_default_dtype torch double test_categorical_ d probabilities = probabilities_ = p = torch tensor probabilities requires_grad=True s = torch tensor probabilities_ requires_grad=True assertEqual Categorical p mean size assertEqual Categorical p variance size assertTrue is_all_nan Categorical p mean assertTrue is_all_nan Categorical p variance assertEqual Categorical p sample size assertEqual Categorical p sample sample_shape= size assertEqual Categorical p sample size _gradcheck_log_prob Categorical p sample check extreme value probs set_rng_seed assertEqual Categorical s sample sample_shape= torch tensor ref_log_prob idx val log_prob sample_prob = p idx val p idx sum assertEqual log_prob math log sample_prob _check_log_prob Categorical p ref_log_prob _check_log_prob Categorical logits=p log ref_log_prob check entropy computation assertEqual Categorical p entropy torch tensor atol= e- rtol= assertEqual Categorical s entropy torch tensor issue gh- logits = p log logits = logits = float -inf e = Categorical logits=logits entropy assertEqual e torch tensor atol= e- rtol= test_categorical_enumerate_support examples = probs probs _check_enumerate_support Categorical examples set_default_dtype torch double test_one_hot_categorical_ d p = torch tensor requires_grad=True assertEqual OneHotCategorical p sample size assertFalse OneHotCategorical p sample requires_grad assertEqual OneHotCategorical p sample size assertEqual OneHotCategorical p sample size _gradcheck_log_prob OneHotCategorical p assertRaises NotImplementedError OneHotCategorical p rsample set_default_dtype torch double test_one_hot_categorical_ d probabilities = p = torch tensor probabilities requires_grad=True assertEqual OneHotCategorical p sample size assertEqual OneHotCategorical p sample sample_shape= size assertEqual OneHotCategorical p sample size _gradcheck_log_prob OneHotCategorical p dist = OneHotCategorical p x = dist sample assertEqual dist log_prob x Categorical p log_prob x max - test_one_hot_categorical_enumerate_support examples = probs probs _check_enumerate_support OneHotCategorical examples test_poisson_forward_ad _check_forward_ad torch poisson test_poisson_shape rate = torch randn abs requires_grad_ rate_ d = torch randn abs requires_grad_ assertEqual Poisson rate sample size assertEqual Poisson rate sample size assertEqual Poisson rate_ d sample size assertEqual Poisson rate_ d sample size assertEqual Poisson sample size unittest skipIf TEST_NUMPY Numpy found set_default_dtype torch double test_poisson_log_prob rate = torch randn abs requires_grad_ rate_ d = torch randn abs requires_grad_ rate_zero = torch zeros requires_grad=True ref_log_prob ref_rate idx x log_prob l = ref_rate view - idx detach expected = scipy stats poisson logpmf x l assertEqual log_prob expected atol= e- rtol= set_rng_seed _check_log_prob Poisson rate lambda args ref_log_prob rate args _check_log_prob Poisson rate_zero lambda args ref_log_prob rate_zero args _gradcheck_log_prob Poisson rate _gradcheck_log_prob Poisson rate_ d We cannot check gradients automatically zero rates because finite difference approximation enters forbidden parameter space We instead compare theoretical results dist = Poisson rate_zero dist log_prob torch ones_like rate_zero backward assertEqual rate_zero grad torch inf unittest skipIf TEST_NUMPY Numpy found test_poisson_sample set_rng_seed see Note Randomized statistical tests saved_dtype = torch get_default_dtype dtype torch float torch double torch bfloat torch half torch set_default_dtype dtype rate _check_sampler_discrete Poisson rate scipy stats poisson rate f Poisson lambda= rate failure_rate= e- torch set_default_dtype saved_dtype unittest skipIf TEST_CUDA TEST_XPU CUDA XPU found unittest skipIf TEST_NUMPY Numpy found test_poisson_gpu_sample set_rng_seed rate _check_sampler_discrete Poisson torch tensor rate device_type scipy stats poisson rate f Poisson lambda= rate device_type failure_rate= e- set_default_dtype torch double test_relaxed_bernoulli p = torch tensor requires_grad=True r = torch tensor requires_grad=True s = temp = torch tensor requires_grad=True assertEqual RelaxedBernoulli temp p sample size assertFalse RelaxedBernoulli temp p sample requires_grad assertEqual RelaxedBernoulli temp r sample size assertEqual RelaxedBernoulli temp r sample size assertEqual RelaxedBernoulli temp r sample size assertEqual RelaxedBernoulli temp s sample size _gradcheck_log_prob RelaxedBernoulli temp p _gradcheck_log_prob RelaxedBernoulli temp r test rsample doesn t fail s = RelaxedBernoulli temp p rsample s backward torch ones_like s unittest skipIf TEST_NUMPY Numpy found test_rounded_relaxed_bernoulli set_rng_seed see Note Randomized statistical tests Rounded __init__ dist dist = dist sample args kwargs torch round dist sample args kwargs probs temp product _check_sampler_discrete Rounded RelaxedBernoulli temp probs scipy stats bernoulli probs f Rounded RelaxedBernoulli temp= temp probs= probs failure_rate= e- probs equal_probs = torch tensor dist = RelaxedBernoulli e probs s = dist rsample assertEqual equal_probs s set_default_dtype torch double test_relaxed_one_hot_categorical_ d p = torch tensor requires_grad=True temp = torch tensor requires_grad=True assertEqual RelaxedOneHotCategorical probs=p temperature=temp sample size assertFalse RelaxedOneHotCategorical probs=p temperature=temp sample requires_grad assertEqual RelaxedOneHotCategorical probs=p temperature=temp sample size assertEqual RelaxedOneHotCategorical probs=p temperature=temp sample size _gradcheck_log_prob lambda t p RelaxedOneHotCategorical t p validate_args=False temp p set_default_dtype torch double test_relaxed_one_hot_categorical_ d probabilities = temp = torch tensor requires_grad=True The lower temperature more unstable log_prob gradcheck w r t sample Values below empirically fail default tol temp_ = torch tensor requires_grad=True p = torch tensor probabilities requires_grad=True assertEqual RelaxedOneHotCategorical temp p sample size assertEqual RelaxedOneHotCategorical temp p sample sample_shape= size assertEqual RelaxedOneHotCategorical temp p sample size _gradcheck_log_prob lambda t p RelaxedOneHotCategorical t p validate_args=False temp p _gradcheck_log_prob lambda t p RelaxedOneHotCategorical t p validate_args=False temp_ p unittest skipIf TEST_NUMPY Numpy found test_argmax_relaxed_categorical set_rng_seed see Note Randomized statistical tests ArgMax __init__ dist dist = dist sample args kwargs s = dist sample args kwargs _ idx = torch max s - idx ScipyCategorical __init__ dist dist = dist pmf samples new_samples = np zeros samples shape + dist p shape new_samples np arange samples shape samples = dist pmf new_samples probs temp product torch tensor torch tensor _check_sampler_discrete ArgMax RelaxedOneHotCategorical temp probs ScipyCategorical scipy stats multinomial probs f Rounded RelaxedOneHotCategorical temp= temp probs= probs failure_rate= e- probs torch tensor torch tensor equal_probs = torch ones probs size probs size dist = RelaxedOneHotCategorical e probs s = dist rsample assertEqual equal_probs s set_default_dtype torch double test_uniform low = torch zeros requires_grad=True high = torch ones requires_grad_ low_ d = torch zeros requires_grad=True high_ d = torch ones requires_grad_ assertEqual Uniform low high sample size assertEqual Uniform low high sample size assertEqual Uniform low_ d high_ d sample size assertEqual Uniform low_ d high_ d sample size assertEqual Uniform sample size Check log_prob computation when value outside range uniform = Uniform low_ d high_ d validate_args=False above_high = torch tensor below_low = torch tensor - assertEqual uniform log_prob above_high item -inf assertEqual uniform log_prob below_low item -inf check cdf computation when value outside range assertEqual uniform cdf below_low item assertEqual uniform cdf above_high item set_rng_seed _gradcheck_log_prob Uniform low high _gradcheck_log_prob Uniform low _gradcheck_log_prob Uniform high state = torch get_rng_state rand = low new low size uniform_ torch set_rng_state state u = Uniform low high rsample u backward torch ones_like u assertEqual low grad - rand assertEqual high grad rand low grad zero_ high grad zero_ _check_forward_ad lambda x x uniform_ unittest skipIf TEST_NUMPY NumPy found test_vonmises_sample loc math pi concentration _check_sampler_sampler VonMises loc concentration scipy stats vonmises loc=loc kappa=concentration f VonMises loc= loc concentration= concentration num_samples=int e circular=True test_vonmises_logprob concentrations = concentration concentrations grid = torch arange math pi e- prob = VonMises concentration log_prob grid exp norm = prob mean item math pi assertLess abs norm - e- set_default_dtype torch double test_cauchy loc = torch zeros requires_grad=True scale = torch ones requires_grad=True loc_ d = torch zeros requires_grad=True scale_ d = torch ones requires_grad=True assertTrue is_all_nan Cauchy loc_ d scale_ d mean assertEqual Cauchy loc_ d scale_ d variance inf assertEqual Cauchy loc scale sample size assertEqual Cauchy loc scale sample size assertEqual Cauchy loc_ d scale_ d sample size assertEqual Cauchy loc_ d scale_ d sample size assertEqual Cauchy sample size set_rng_seed _gradcheck_log_prob Cauchy loc scale _gradcheck_log_prob Cauchy loc _gradcheck_log_prob Cauchy scale state = torch get_rng_state eps = loc new loc size cauchy_ torch set_rng_state state c = Cauchy loc scale rsample c backward torch ones_like c assertEqual loc grad torch ones_like scale assertEqual scale grad eps loc grad zero_ scale grad zero_ _check_forward_ad lambda x x cauchy_ set_default_dtype torch double test_halfcauchy scale = torch ones requires_grad=True scale_ d = torch ones requires_grad=True assertTrue torch isinf HalfCauchy scale_ d mean all assertEqual HalfCauchy scale_ d variance inf assertEqual HalfCauchy scale sample size assertEqual HalfCauchy scale sample size assertEqual HalfCauchy scale_ d sample size assertEqual HalfCauchy scale_ d sample size assertEqual HalfCauchy sample size set_rng_seed _gradcheck_log_prob HalfCauchy scale _gradcheck_log_prob HalfCauchy state = torch get_rng_state eps = scale new scale size cauchy_ abs_ torch set_rng_state state c = HalfCauchy scale rsample c backward torch ones_like c assertEqual scale grad eps scale grad zero_ set_default_dtype torch double test_halfnormal std = torch randn abs requires_grad_ std_ d = torch randn abs requires_grad_ std_delta = torch tensor e- e- assertEqual HalfNormal std sample size assertEqual HalfNormal std sample size assertEqual HalfNormal std_ d sample size assertEqual HalfNormal std_ d sample size assertEqual HalfNormal sample size assertEqual HalfNormal sample size sample check extreme value std set_rng_seed assertEqual HalfNormal std_delta sample sample_shape= torch tensor atol= e- rtol= _gradcheck_log_prob HalfNormal std _gradcheck_log_prob HalfNormal check log_prob can broadcast dist = HalfNormal torch ones log_prob = dist log_prob torch ones assertEqual log_prob shape unittest skipIf TEST_NUMPY NumPy found test_halfnormal_logprob std = torch randn abs requires_grad_ ref_log_prob idx x log_prob s = std view - idx detach expected = scipy stats halfnorm scale=s logpdf x assertEqual log_prob expected atol= e- rtol= _check_log_prob HalfNormal std ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_halfnormal_sample set_rng_seed see Note Randomized statistical tests std _check_sampler_sampler HalfNormal std scipy stats halfnorm scale=std f HalfNormal scale= std set_default_dtype torch double test_inversegamma alpha = torch randn exp requires_grad_ beta = torch randn exp requires_grad_ alpha_ d = torch randn exp requires_grad_ beta_ d = torch randn exp requires_grad_ assertEqual InverseGamma alpha beta sample size assertEqual InverseGamma alpha beta sample size assertEqual InverseGamma alpha_ d beta_ d sample size assertEqual InverseGamma alpha_ d beta_ d sample size assertEqual InverseGamma sample size assertEqual InverseGamma sample size _gradcheck_log_prob InverseGamma alpha beta dist = InverseGamma torch ones torch ones log_prob = dist log_prob torch ones assertEqual log_prob shape unittest skipIf TEST_NUMPY NumPy found test_inversegamma_sample set_rng_seed see Note Randomized statistical tests concentration rate product _check_sampler_sampler InverseGamma concentration rate scipy stats invgamma concentration scale=rate InverseGamma set_default_dtype torch double test_lognormal mean = torch randn requires_grad=True std = torch randn abs requires_grad_ mean_ d = torch randn requires_grad=True std_ d = torch randn abs requires_grad_ mean_delta = torch tensor std_delta = torch tensor e- e- assertEqual LogNormal mean std sample size assertEqual LogNormal mean std sample size assertEqual LogNormal mean_ d std_ d sample size assertEqual LogNormal mean_ d std_ d sample size assertEqual LogNormal sample size assertEqual LogNormal - sample size sample check extreme value mean std set_rng_seed assertEqual LogNormal mean_delta std_delta sample sample_shape= torch tensor math exp math exp atol= e- rtol= _gradcheck_log_prob LogNormal mean std _gradcheck_log_prob LogNormal mean _gradcheck_log_prob LogNormal std check log_prob can broadcast dist = LogNormal torch zeros torch ones log_prob = dist log_prob torch ones assertEqual log_prob shape _check_forward_ad lambda x x log_normal_ unittest skipIf TEST_NUMPY NumPy found test_lognormal_logprob mean = torch randn requires_grad=True std = torch randn abs requires_grad_ ref_log_prob idx x log_prob m = mean view - idx detach s = std view - idx detach expected = scipy stats lognorm s=s scale=math exp m logpdf x assertEqual log_prob expected atol= e- rtol= _check_log_prob LogNormal mean std ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_lognormal_sample set_rng_seed see Note Randomized statistical tests mean std product - _check_sampler_sampler LogNormal mean std scipy stats lognorm scale=math exp mean s=std f LogNormal loc= mean scale= std set_default_dtype torch double test_logisticnormal set_rng_seed see Note Randomized statistical tests mean = torch randn requires_grad_ std = torch randn abs requires_grad_ mean_ d = torch randn requires_grad_ std_ d = torch randn abs requires_grad_ mean_delta = torch tensor std_delta = torch tensor e- e- assertEqual LogisticNormal mean std sample size assertEqual LogisticNormal mean std sample size assertEqual LogisticNormal mean_ d std_ d sample size assertEqual LogisticNormal mean_ d std_ d sample size assertEqual LogisticNormal sample size assertEqual LogisticNormal - sample size sample check extreme value mean std set_rng_seed assertEqual LogisticNormal mean_delta std_delta sample torch tensor math exp + + math exp + + math exp + + math exp atol= e- rtol= TODO gradcheck seems mutate sample values so simplex constraint fails very small margin _gradcheck_log_prob lambda m s LogisticNormal m s validate_args=False mean std _gradcheck_log_prob lambda m s LogisticNormal m s validate_args=False mean _gradcheck_log_prob lambda m s LogisticNormal m s validate_args=False std unittest skipIf TEST_NUMPY NumPy found test_logisticnormal_logprob mean = torch randn requires_grad_ std = torch randn abs requires_grad_ Smoke test now TODO Once _check_log_prob works multidimensional distributions add proper testing log probabilities dist = LogisticNormal mean std assert dist log_prob dist sample detach cpu numpy shape == _get_logistic_normal_ref_sampler base_dist _sampler num_samples x = base_dist rvs num_samples offset = np log x shape - + - np ones_like x cumsum - z = + np exp offset - x z_cumprod = np cumprod - z axis=- y = np pad z mode= constant constant_values= y = np pad z_cumprod mode= constant constant_values= y y _sampler unittest skipIf TEST_NUMPY NumPy found test_logisticnormal_sample set_rng_seed see Note Randomized statistical tests means = map np asarray - - covs = map np diag mean cov product means covs base_dist = scipy stats multivariate_normal mean=mean cov=cov ref_dist = scipy stats multivariate_normal mean=mean cov=cov ref_dist rvs = _get_logistic_normal_ref_sampler base_dist mean_th = torch tensor mean std_th = torch tensor np sqrt np diag cov _check_sampler_sampler LogisticNormal mean_th std_th ref_dist f LogisticNormal loc= mean_th scale= std_th multivariate=True test_mixture_same_family_shape normal_case_ d = MixtureSameFamily Categorical torch rand Normal torch randn torch rand normal_case_ d_batch = MixtureSameFamily Categorical torch rand Normal torch randn torch rand normal_case_ d_multi_batch = MixtureSameFamily Categorical torch rand Normal torch randn torch rand normal_case_ d = MixtureSameFamily Categorical torch rand Independent Normal torch randn torch rand normal_case_ d_batch = MixtureSameFamily Categorical torch rand Independent Normal torch randn torch rand normal_case_ d_multi_batch = MixtureSameFamily Categorical torch rand Independent Normal torch randn torch rand assertEqual normal_case_ d sample size assertEqual normal_case_ d sample size assertEqual normal_case_ d sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_multi_batch sample size assertEqual normal_case_ d_multi_batch sample size assertEqual normal_case_ d_multi_batch sample size assertEqual normal_case_ d sample size assertEqual normal_case_ d sample size assertEqual normal_case_ d sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_batch sample size assertEqual normal_case_ d_multi_batch sample size assertEqual normal_case_ d_multi_batch sample size assertEqual normal_case_ d_multi_batch sample size unittest skipIf TEST_NUMPY Numpy found test_mixture_same_family_normal_log_prob probs = torch rand softmax dim=- loc = torch randn scale = torch rand ref_log_prob idx x log_prob p = probs idx numpy m = loc idx numpy s = scale idx numpy mix = scipy stats multinomial p comp = scipy stats norm m s expected = scipy special logsumexp comp logpdf x + np log mix p assertEqual log_prob expected atol= e- rtol= _check_log_prob MixtureSameFamily Categorical probs=probs Normal loc scale ref_log_prob unittest skipIf TEST_NUMPY Numpy found test_mixture_same_family_binomial_log_prob max_count = probs = torch rand softmax dim=- binom_probs = torch rand ref_log_prob idx x log_prob p = probs idx numpy binom_p = binom_probs idx numpy mix = scipy stats multinomial p comp = scipy stats binom max_count binom_p expected = scipy special logsumexp comp logpmf x + np log mix p assertEqual log_prob expected atol= e- rtol= _check_log_prob MixtureSameFamily Categorical probs=probs Binomial max_count binom_probs ref_log_prob unittest skipIf TEST_NUMPY Numpy found test_mixture_same_family_sample probs = torch rand softmax dim=- loc = torch randn scale = torch rand ScipyMixtureNormal __init__ probs mu std probs = probs mu = mu std = std rvs n_sample comp_samples = scipy stats norm m s rvs n_sample m s zip mu std mix_samples = scipy stats multinomial probs rvs n_sample samples = i range n_sample samples append comp_samples mix_samples i argmax i np asarray samples _check_sampler_sampler MixtureSameFamily Categorical probs=probs Normal loc scale ScipyMixtureNormal probs numpy loc numpy scale numpy f MixtureSameFamily Categorical probs= probs Normal loc= loc scale= scale set_default_dtype torch double test_normal loc = torch randn requires_grad=True scale = torch randn abs requires_grad_ loc_ d = torch randn requires_grad=True scale_ d = torch randn abs requires_grad_ loc_delta = torch tensor scale_delta = torch tensor e- e- assertEqual Normal loc scale sample size assertEqual Normal loc scale sample size assertEqual Normal loc_ d scale_ d sample size assertEqual Normal loc_ d scale_ d sample size assertEqual Normal sample size assertEqual Normal - sample size sample check extreme value mean std set_rng_seed assertEqual Normal loc_delta scale_delta sample sample_shape= torch tensor atol= e- rtol= _gradcheck_log_prob Normal loc scale _gradcheck_log_prob Normal loc _gradcheck_log_prob Normal scale state = torch get_rng_state eps = torch normal torch zeros_like loc torch ones_like scale torch set_rng_state state z = Normal loc scale rsample z backward torch ones_like z assertEqual loc grad torch ones_like loc assertEqual scale grad eps loc grad zero_ scale grad zero_ assertEqual z size ref_log_prob idx x log_prob m = loc view - idx s = scale view - idx expected = math exp - x - m s math sqrt math pi s assertEqual log_prob math log expected atol= e- rtol= _check_log_prob Normal loc scale ref_log_prob _check_forward_ad torch normal _check_forward_ad lambda x torch normal x _check_forward_ad lambda x torch normal x _check_forward_ad lambda x torch normal x x _check_forward_ad lambda x x normal_ unittest skipIf TEST_NUMPY NumPy found test_normal_sample set_rng_seed see Note Randomized statistical tests loc scale product - _check_sampler_sampler Normal loc scale scipy stats norm loc=loc scale=scale f Normal mean= loc std= scale set_default_dtype torch double test_lowrank_multivariate_normal_shape mean = torch randn requires_grad=True mean_no_batch = torch randn requires_grad=True mean_multi_batch = torch randn requires_grad=True construct PSD covariance cov_factor = torch randn requires_grad=True cov_diag = torch randn abs requires_grad_ construct batch PSD covariances cov_factor_batched = torch randn requires_grad=True cov_diag_batched = torch randn abs requires_grad_ ensure sample batch event shapes all handled correctly assertEqual LowRankMultivariateNormal mean cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_no_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_multi_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_no_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_multi_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_no_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean_multi_batch cov_factor cov_diag sample size assertEqual LowRankMultivariateNormal mean cov_factor_batched cov_diag_batched sample size assertEqual LowRankMultivariateNormal mean_no_batch cov_factor_batched cov_diag_batched sample size assertEqual LowRankMultivariateNormal mean_multi_batch cov_factor_batched cov_diag_batched sample size check gradients _gradcheck_log_prob LowRankMultivariateNormal mean cov_factor cov_diag _gradcheck_log_prob LowRankMultivariateNormal mean_multi_batch cov_factor cov_diag _gradcheck_log_prob LowRankMultivariateNormal mean_multi_batch cov_factor_batched cov_diag_batched unittest skipIf TEST_NUMPY Numpy found test_lowrank_multivariate_normal_log_prob mean = torch randn requires_grad=True cov_factor = torch randn requires_grad=True cov_diag = torch randn abs requires_grad_ cov = cov_factor matmul cov_factor t + cov_diag diag check logprob values match scipy logpdf covariance scale_tril parameters equivalent dist = LowRankMultivariateNormal mean cov_factor cov_diag ref_dist = scipy stats multivariate_normal mean detach numpy cov detach numpy x = dist sample expected = ref_dist logpdf x numpy assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= Double-check batched versions behave same unbatched mean = torch randn requires_grad=True cov_factor = torch randn requires_grad=True cov_diag = torch randn abs requires_grad_ dist_batched = LowRankMultivariateNormal mean cov_factor cov_diag dist_unbatched = LowRankMultivariateNormal mean i cov_factor i cov_diag i i range mean size x = dist_batched sample batched_prob = dist_batched log_prob x unbatched_prob = torch stack dist_unbatched i log_prob x i i range t assertEqual batched_prob shape unbatched_prob shape assertEqual batched_prob unbatched_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found test_lowrank_multivariate_normal_sample set_rng_seed see Note Randomized statistical tests mean = torch randn requires_grad=True cov_factor = torch randn requires_grad=True cov_diag = torch randn abs requires_grad_ cov = cov_factor matmul cov_factor t + cov_diag diag _check_sampler_sampler LowRankMultivariateNormal mean cov_factor cov_diag scipy stats multivariate_normal mean detach numpy cov detach numpy f LowRankMultivariateNormal loc= mean cov_factor= cov_factor cov_diag= cov_diag multivariate=True test_lowrank_multivariate_normal_properties loc = torch randn cov_factor = torch randn cov_diag = torch randn abs cov = cov_factor matmul cov_factor t + cov_diag diag m = LowRankMultivariateNormal loc cov_factor cov_diag m = MultivariateNormal loc=loc covariance_matrix=cov assertEqual m mean m mean assertEqual m variance m variance assertEqual m covariance_matrix m covariance_matrix assertEqual m scale_tril m scale_tril assertEqual m precision_matrix m precision_matrix assertEqual m entropy m entropy test_lowrank_multivariate_normal_moments set_rng_seed see Note Randomized statistical tests mean = torch randn cov_factor = torch randn cov_diag = torch randn abs d = LowRankMultivariateNormal mean cov_factor cov_diag samples = d rsample empirical_mean = samples mean assertEqual d mean empirical_mean atol= rtol= empirical_var = samples var assertEqual d variance empirical_var atol= rtol= set_default_dtype torch double test_multivariate_normal_shape mean = torch randn requires_grad=True mean_no_batch = torch randn requires_grad=True mean_multi_batch = torch randn requires_grad=True construct PSD covariance tmp = torch randn cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ construct batch PSD covariances tmp = torch randn cov_batched = tmp unsqueeze - tmp unsqueeze - mean - requires_grad_ prec_batched = cov_batched inverse scale_tril_batched = torch linalg cholesky cov_batched ensure sample batch event shapes all handled correctly assertEqual MultivariateNormal mean cov sample size assertEqual MultivariateNormal mean_no_batch cov sample size assertEqual MultivariateNormal mean_multi_batch cov sample size assertEqual MultivariateNormal mean cov sample size assertEqual MultivariateNormal mean_no_batch cov sample size assertEqual MultivariateNormal mean_multi_batch cov sample size assertEqual MultivariateNormal mean cov sample size assertEqual MultivariateNormal mean_no_batch cov sample size assertEqual MultivariateNormal mean_multi_batch cov sample size assertEqual MultivariateNormal mean cov_batched sample size assertEqual MultivariateNormal mean_no_batch cov_batched sample size assertEqual MultivariateNormal mean_multi_batch cov_batched sample size assertEqual MultivariateNormal mean precision_matrix=prec sample size assertEqual MultivariateNormal mean precision_matrix=prec_batched sample size assertEqual MultivariateNormal mean scale_tril=scale_tril sample size assertEqual MultivariateNormal mean scale_tril=scale_tril_batched sample size check gradients We write custom gradcheck function maintain symmetry perturbed covariances their inverses precision multivariate_normal_log_prob_gradcheck mean covariance=None precision=None scale_tril=None mvn_samples = MultivariateNormal mean covariance precision scale_tril sample requires_grad_ gradcheck_func samples mu sigma prec scale_tril sigma None sigma = sigma + sigma mT Ensure symmetry covariance prec None prec = prec + prec mT Ensure symmetry precision scale_tril None scale_tril = scale_tril tril MultivariateNormal mu sigma prec scale_tril log_prob samples gradcheck gradcheck_func mvn_samples mean covariance precision scale_tril raise_exception=True multivariate_normal_log_prob_gradcheck mean cov multivariate_normal_log_prob_gradcheck mean_multi_batch cov multivariate_normal_log_prob_gradcheck mean_multi_batch cov_batched multivariate_normal_log_prob_gradcheck mean None prec multivariate_normal_log_prob_gradcheck mean_no_batch None prec_batched multivariate_normal_log_prob_gradcheck mean None None scale_tril multivariate_normal_log_prob_gradcheck mean_no_batch None None scale_tril_batched set_default_dtype torch double test_multivariate_normal_stable_with_precision_matrix x = torch randn P = torch exp - x - x unsqueeze - RBF kernel MultivariateNormal x new_zeros precision_matrix=P unittest skipIf TEST_NUMPY Numpy found test_multivariate_normal_log_prob mean = torch randn requires_grad=True tmp = torch randn cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ check logprob values match scipy logpdf covariance scale_tril parameters equivalent dist = MultivariateNormal mean cov dist = MultivariateNormal mean precision_matrix=prec dist = MultivariateNormal mean scale_tril=scale_tril ref_dist = scipy stats multivariate_normal mean detach numpy cov detach numpy x = dist sample expected = ref_dist logpdf x numpy assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= Double-check batched versions behave same unbatched mean = torch randn requires_grad=True tmp = torch randn cov = tmp unsqueeze - tmp unsqueeze - mean - requires_grad_ dist_batched = MultivariateNormal mean cov dist_unbatched = MultivariateNormal mean i cov i i range mean size x = dist_batched sample batched_prob = dist_batched log_prob x unbatched_prob = torch stack dist_unbatched i log_prob x i i range t assertEqual batched_prob shape unbatched_prob shape assertEqual batched_prob unbatched_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found test_multivariate_normal_sample set_rng_seed see Note Randomized statistical tests mean = torch randn requires_grad=True tmp = torch randn cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ _check_sampler_sampler MultivariateNormal mean cov scipy stats multivariate_normal mean detach numpy cov detach numpy f MultivariateNormal loc= mean cov= cov multivariate=True _check_sampler_sampler MultivariateNormal mean precision_matrix=prec scipy stats multivariate_normal mean detach numpy cov detach numpy f MultivariateNormal loc= mean atol= prec multivariate=True _check_sampler_sampler MultivariateNormal mean scale_tril=scale_tril scipy stats multivariate_normal mean detach numpy cov detach numpy f MultivariateNormal loc= mean scale_tril= scale_tril multivariate=True set_default_dtype torch double test_multivariate_normal_properties loc = torch randn scale_tril = transform_to constraints lower_cholesky torch randn m = MultivariateNormal loc=loc scale_tril=scale_tril assertEqual m covariance_matrix m scale_tril mm m scale_tril t assertEqual m covariance_matrix mm m precision_matrix torch eye m event_shape assertEqual m scale_tril torch linalg cholesky m covariance_matrix set_default_dtype torch double test_multivariate_normal_moments set_rng_seed see Note Randomized statistical tests mean = torch randn scale_tril = transform_to constraints lower_cholesky torch randn d = MultivariateNormal mean scale_tril=scale_tril samples = d rsample empirical_mean = samples mean assertEqual d mean empirical_mean atol= rtol= empirical_var = samples var assertEqual d variance empirical_var atol= rtol= We applied same tests Multivariate Normal distribution Wishart distribution set_default_dtype torch double test_wishart_shape set_rng_seed see Note Randomized statistical tests ndim = df = torch rand requires_grad=True + ndim df_no_batch = torch rand requires_grad=True + ndim df_multi_batch = torch rand requires_grad=True + ndim construct PSD covariance tmp = torch randn ndim cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ construct batch PSD covariances tmp = torch randn ndim cov_batched = tmp unsqueeze - tmp unsqueeze - mean - requires_grad_ prec_batched = cov_batched inverse scale_tril_batched = torch linalg cholesky cov_batched ensure sample batch event shapes all handled correctly assertEqual Wishart df cov sample size ndim ndim assertEqual Wishart df_no_batch cov sample size ndim ndim assertEqual Wishart df_multi_batch cov sample size ndim ndim assertEqual Wishart df cov sample size ndim ndim assertEqual Wishart df_no_batch cov sample size ndim ndim assertEqual Wishart df_multi_batch cov sample size ndim ndim assertEqual Wishart df cov sample size ndim ndim assertEqual Wishart df_no_batch cov sample size ndim ndim assertEqual Wishart df_multi_batch cov sample size ndim ndim assertEqual Wishart df cov_batched sample size ndim ndim assertEqual Wishart df_no_batch cov_batched sample size ndim ndim assertEqual Wishart df_multi_batch cov_batched sample size ndim ndim assertEqual Wishart df precision_matrix=prec sample size ndim ndim assertEqual Wishart df precision_matrix=prec_batched sample size ndim ndim assertEqual Wishart df scale_tril=scale_tril sample size ndim ndim assertEqual Wishart df scale_tril=scale_tril_batched sample size ndim ndim check gradients Modified applied same tests multivariate_normal wishart_log_prob_gradcheck df=None covariance=None precision=None scale_tril=None wishart_samples = Wishart df covariance precision scale_tril sample requires_grad_ gradcheck_func samples nu sigma prec scale_tril sigma None sigma = sigma + sigma mT Ensure symmetry covariance prec None prec = prec + prec mT Ensure symmetry precision scale_tril None scale_tril = scale_tril tril Wishart nu sigma prec scale_tril log_prob samples gradcheck gradcheck_func wishart_samples df covariance precision scale_tril raise_exception=True wishart_log_prob_gradcheck df cov wishart_log_prob_gradcheck df_multi_batch cov wishart_log_prob_gradcheck df_multi_batch cov_batched wishart_log_prob_gradcheck df None prec wishart_log_prob_gradcheck df_no_batch None prec_batched wishart_log_prob_gradcheck df None None scale_tril wishart_log_prob_gradcheck df_no_batch None None scale_tril_batched test_wishart_stable_with_precision_matrix set_rng_seed see Note Randomized statistical tests ndim = x = torch randn ndim P = torch exp - x - x unsqueeze - RBF kernel Wishart torch tensor ndim precision_matrix=P unittest skipIf TEST_NUMPY Numpy found set_default_dtype torch double test_wishart_log_prob set_rng_seed see Note Randomized statistical tests ndim = df = torch rand requires_grad=True + ndim - SciPy allowed ndim - df ndim Wishar distribution after version version parse scipy __version__ version parse df += tmp = torch randn ndim cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ check logprob values match scipy logpdf covariance scale_tril parameters equivalent dist = Wishart df cov dist = Wishart df precision_matrix=prec dist = Wishart df scale_tril=scale_tril ref_dist = scipy stats wishart df item cov detach numpy x = dist sample expected = ref_dist logpdf x transpose numpy assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= assertEqual np mean dist log_prob x detach numpy - expected atol= e- rtol= Double-check batched versions behave same unbatched df = torch rand requires_grad=True + ndim - SciPy allowed ndim - df ndim Wishar distribution after version version parse scipy __version__ version parse df += tmp = torch randn ndim cov = tmp unsqueeze - tmp unsqueeze - mean - requires_grad_ dist_batched = Wishart df cov dist_unbatched = Wishart df i cov i i range df size x = dist_batched sample batched_prob = dist_batched log_prob x unbatched_prob = torch stack dist_unbatched i log_prob x i i range t assertEqual batched_prob shape unbatched_prob shape assertEqual batched_prob unbatched_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_wishart_sample set_rng_seed see Note Randomized statistical tests ndim = df = torch rand requires_grad=True + ndim - SciPy allowed ndim - df ndim Wishar distribution after version version parse scipy __version__ version parse df += tmp = torch randn ndim cov = torch matmul tmp tmp t tmp size - requires_grad_ prec = cov inverse requires_grad_ scale_tril = torch linalg cholesky cov requires_grad_ ref_dist = scipy stats wishart df item cov detach numpy _check_sampler_sampler Wishart df cov ref_dist f Wishart df= df covariance_matrix= cov multivariate=True _check_sampler_sampler Wishart df precision_matrix=prec ref_dist f Wishart df= df precision_matrix= prec multivariate=True _check_sampler_sampler Wishart df scale_tril=scale_tril ref_dist f Wishart df= df scale_tril= scale_tril multivariate=True test_wishart_properties set_rng_seed see Note Randomized statistical tests ndim = df = torch rand + ndim - scale_tril = transform_to constraints lower_cholesky torch randn ndim ndim m = Wishart df=df scale_tril=scale_tril assertEqual m covariance_matrix m scale_tril mm m scale_tril t assertEqual m covariance_matrix mm m precision_matrix torch eye m event_shape assertEqual m scale_tril torch linalg cholesky m covariance_matrix test_wishart_moments set_rng_seed see Note Randomized statistical tests ndim = df = torch rand + ndim - scale_tril = transform_to constraints lower_cholesky torch randn ndim ndim d = Wishart df=df scale_tril=scale_tril samples = d rsample ndim ndim empirical_mean = samples mean assertEqual d mean empirical_mean atol= rtol= empirical_var = samples var assertEqual d variance empirical_var atol= rtol= set_default_dtype torch double test_exponential rate = torch randn abs requires_grad_ rate_ d = torch randn abs requires_grad_ assertEqual Exponential rate sample size assertEqual Exponential rate sample size assertEqual Exponential rate_ d sample size assertEqual Exponential rate_ d sample size assertEqual Exponential sample size assertEqual Exponential sample size _gradcheck_log_prob Exponential rate state = torch get_rng_state eps = rate new rate size exponential_ torch set_rng_state state z = Exponential rate rsample z backward torch ones_like z assertEqual rate grad -eps rate rate grad zero_ assertEqual z size ref_log_prob idx x log_prob m = rate view - idx expected = math log m - m x assertEqual log_prob expected atol= e- rtol= _check_log_prob Exponential rate ref_log_prob _check_forward_ad lambda x x exponential_ mean_var lambd sample sample exponential_ lambd mean = sample float mean var = sample float var assertEqual lambd mean atol= e- rtol= e- assertEqual lambd var atol= e- rtol= e- dtype torch float torch double torch bfloat torch float lambd sample_len = mean_var lambd torch rand sample_len dtype=dtype unittest skipIf TEST_NUMPY NumPy found test_exponential_sample set_rng_seed see Note Randomized statistical tests rate e- _check_sampler_sampler Exponential rate scipy stats expon scale= rate f Exponential rate= rate set_default_dtype torch double test_laplace loc = torch randn requires_grad=True scale = torch randn abs requires_grad_ loc_ d = torch randn requires_grad=True scale_ d = torch randn requires_grad=True loc_delta = torch tensor scale_delta = torch tensor e- e- assertEqual Laplace loc scale sample size assertEqual Laplace loc scale sample size assertEqual Laplace loc_ d scale_ d sample size assertEqual Laplace loc_ d scale_ d sample size assertEqual Laplace sample size assertEqual Laplace - sample size sample check extreme value mean std set_rng_seed assertEqual Laplace loc_delta scale_delta sample sample_shape= torch tensor atol= e- rtol= _gradcheck_log_prob Laplace loc scale _gradcheck_log_prob Laplace loc _gradcheck_log_prob Laplace scale state = torch get_rng_state eps = torch ones_like loc uniform_ - torch set_rng_state state z = Laplace loc scale rsample z backward torch ones_like z assertEqual loc grad torch ones_like loc assertEqual scale grad -eps sign torch log p - eps abs loc grad zero_ scale grad zero_ assertEqual z size ref_log_prob idx x log_prob m = loc view - idx s = scale view - idx expected = -math log s - abs x - m s assertEqual log_prob expected atol= e- rtol= _check_log_prob Laplace loc scale ref_log_prob unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_laplace_sample set_rng_seed see Note Randomized statistical tests loc scale product - _check_sampler_sampler Laplace loc scale scipy stats laplace loc=loc scale=scale f Laplace loc= loc scale= scale unittest skipIf TEST_NUMPY NumPy found test_gamma_shape alpha = torch randn exp requires_grad_ beta = torch randn exp requires_grad_ alpha_ d = torch randn exp requires_grad_ beta_ d = torch randn exp requires_grad_ assertEqual Gamma alpha beta sample size assertEqual Gamma alpha beta sample size assertEqual Gamma alpha_ d beta_ d sample size assertEqual Gamma alpha_ d beta_ d sample size assertEqual Gamma sample size assertEqual Gamma sample size ref_log_prob idx x log_prob = alpha view - idx detach b = beta view - idx detach expected = scipy stats gamma logpdf x scale= b assertEqual log_prob expected atol= e- rtol= _check_log_prob Gamma alpha beta ref_log_prob unittest skipIf TEST_CUDA TEST_XPU CUDA XPU found unittest skipIf TEST_NUMPY NumPy found test_gamma_gpu_shape alpha = torch randn device_type exp requires_grad_ beta = torch randn device_type exp requires_grad_ alpha_ d = torch randn device_type exp requires_grad_ beta_ d = torch randn device_type exp requires_grad_ assertEqual Gamma alpha beta sample size assertEqual Gamma alpha beta sample size assertEqual Gamma alpha_ d beta_ d sample size assertEqual Gamma alpha_ d beta_ d sample size assertEqual Gamma sample size assertEqual Gamma sample size ref_log_prob idx x log_prob = alpha view - idx detach cpu b = beta view - idx detach cpu expected = scipy stats gamma logpdf x cpu scale= b assertEqual log_prob expected atol= e- rtol= _check_log_prob Gamma alpha beta ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_gamma_sample set_rng_seed see Note Randomized statistical tests alpha beta product _check_sampler_sampler Gamma alpha beta scipy stats gamma alpha scale= beta f Gamma concentration= alpha rate= beta unittest skipIf TEST_CUDA CUDA found unittest skipIf TEST_NUMPY Numpy found test_gamma_gpu_sample set_rng_seed alpha beta product b = torch tensor alpha device_type torch tensor beta device_type _check_sampler_sampler Gamma b scipy stats gamma alpha scale= beta f Gamma alpha= alpha beta= beta failure_rate= e- unittest skipIf TEST_NUMPY NumPy found test_pareto scale = torch randn abs requires_grad_ alpha = torch randn abs requires_grad_ scale_ d = torch randn abs requires_grad_ alpha_ d = torch randn abs requires_grad_ assertEqual Pareto scale_ d mean inf assertEqual Pareto scale_ d variance inf assertEqual Pareto scale alpha sample size assertEqual Pareto scale alpha sample size assertEqual Pareto scale_ d alpha_ d sample size assertEqual Pareto scale_ d alpha_ d sample size assertEqual Pareto sample size assertEqual Pareto sample size ref_log_prob idx x log_prob s = scale view - idx detach = alpha view - idx detach expected = scipy stats pareto logpdf x scale=s assertEqual log_prob expected atol= e- rtol= _check_log_prob Pareto scale alpha ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_pareto_sample set_rng_seed see Note Randomized statistical tests scale alpha product _check_sampler_sampler Pareto scale alpha scipy stats pareto alpha scale=scale f Pareto scale= scale alpha= alpha unittest skipIf TEST_NUMPY NumPy found test_generalized_pareto loc = torch randn requires_grad_ scale = torch randn abs requires_grad_ concentration = torch randn requires_grad_ loc_ d = torch randn requires_grad_ scale_ d = torch randn abs requires_grad_ concentration_ d = torch randn requires_grad_ assertEqual GeneralizedPareto loc scale concentration sample size assertEqual GeneralizedPareto loc scale concentration sample size assertEqual GeneralizedPareto loc_ d scale_ d concentration_ d sample size assertEqual GeneralizedPareto loc_ d scale_ d concentration_ d sample size assertEqual GeneralizedPareto sample size assertEqual GeneralizedPareto sample size ref_log_prob idx x log_prob l = loc view - idx detach s = scale view - idx detach c = concentration view - idx detach expected = scipy stats genpareto logpdf x c loc=l scale=s assertEqual log_prob expected atol= e- rtol= _check_log_prob GeneralizedPareto loc scale concentration ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_generalized_pareto_sample set_rng_seed see note Randomized statistical tests loc scale concentration product - - _check_sampler_sampler GeneralizedPareto loc scale concentration scipy stats genpareto c=concentration loc=loc scale=scale f GeneralizedPareto loc= loc scale= scale concentration= concentration failure_rate= e- test_gumbel loc = torch randn requires_grad=True scale = torch randn abs requires_grad_ loc_ d = torch randn requires_grad=True scale_ d = torch randn abs requires_grad_ assertEqual Gumbel loc scale sample size assertEqual Gumbel loc scale sample size assertEqual Gumbel loc_ d scale_ d sample size assertEqual Gumbel loc_ d scale_ d sample size assertEqual Gumbel sample size assertEqual Gumbel sample size assertEqual Gumbel torch tensor dtype=torch float torch tensor dtype=torch float validate_args=False cdf atol= e- rtol= assertEqual Gumbel torch tensor dtype=torch float torch tensor dtype=torch float validate_args=False cdf atol= e- rtol= assertEqual Gumbel torch tensor dtype=torch float torch tensor dtype=torch float validate_args=False cdf - atol= e- rtol= assertEqual Gumbel torch tensor dtype=torch float torch tensor dtype=torch float validate_args=False cdf - atol= e- rtol= ref_log_prob idx x log_prob l = loc view - idx detach s = scale view - idx detach expected = scipy stats gumbel_r logpdf x loc=l scale=s assertEqual log_prob expected atol= e- rtol= _check_log_prob Gumbel loc scale ref_log_prob unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_gumbel_sample set_rng_seed see note Randomized statistical tests loc scale product - - - _check_sampler_sampler Gumbel loc scale scipy stats gumbel_r loc=loc scale=scale f Gumbel loc= loc scale= scale test_kumaraswamy_shape concentration = torch randn abs requires_grad_ concentration = torch randn abs requires_grad_ concentration _ d = torch randn abs requires_grad_ concentration _ d = torch randn abs requires_grad_ assertEqual Kumaraswamy concentration concentration sample size assertEqual Kumaraswamy concentration concentration sample size assertEqual Kumaraswamy concentration _ d concentration _ d sample size assertEqual Kumaraswamy concentration _ d concentration _ d sample size assertEqual Kumaraswamy sample size assertEqual Kumaraswamy sample size Kumaraswamy distribution implemented SciPy Hence these tests explicit test_kumaraswamy_mean_variance c _ = torch randn abs requires_grad_ c _ = torch randn abs requires_grad_ c _ = torch randn abs requires_grad_ c _ = torch randn abs requires_grad_ cases = c _ c _ c _ c _ i b enumerate cases m = Kumaraswamy b samples = m sample expected = samples mean actual = m mean error = expected - actual abs max_error = max error error == error assertLess max_error f Kumaraswamy example i + len cases incorrect mean expected = samples var actual = m variance error = expected - actual abs max_error = max error error == error assertLess max_error f Kumaraswamy example i + len cases incorrect variance unittest skipIf TEST_NUMPY NumPy found test_fishersnedecor df = torch randn abs requires_grad_ df = torch randn abs requires_grad_ df _ d = torch randn abs df _ d = torch randn abs assertTrue is_all_nan FisherSnedecor mean assertTrue is_all_nan FisherSnedecor variance assertEqual FisherSnedecor df df sample size assertEqual FisherSnedecor df df sample size assertEqual FisherSnedecor df _ d df _ d sample size assertEqual FisherSnedecor df _ d df _ d sample size assertEqual FisherSnedecor sample size assertEqual FisherSnedecor sample size ref_log_prob idx x log_prob f = df view - idx detach f = df view - idx detach expected = scipy stats f logpdf x f f assertEqual log_prob expected atol= e- rtol= _check_log_prob FisherSnedecor df df ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_fishersnedecor_sample set_rng_seed see note Randomized statistical tests df df product _check_sampler_sampler FisherSnedecor df df scipy stats f df df f FisherSnedecor loc= df scale= df unittest skipIf TEST_NUMPY NumPy found test_chi _shape df = torch randn exp requires_grad_ df_ d = torch randn exp requires_grad_ assertEqual Chi df sample size assertEqual Chi df sample size assertEqual Chi df_ d sample size assertEqual Chi df_ d sample size assertEqual Chi torch tensor requires_grad=True sample size assertEqual Chi sample size assertEqual Chi sample size ref_log_prob idx x log_prob d = df view - idx detach expected = scipy stats chi logpdf x d assertEqual log_prob expected atol= e- rtol= _check_log_prob Chi df ref_log_prob unittest skipIf TEST_NUMPY NumPy found test_chi _sample set_rng_seed see Note Randomized statistical tests df _check_sampler_sampler Chi df scipy stats chi df f Chi df= df unittest skipIf TEST_NUMPY Numpy found test_studentT df = torch randn exp requires_grad_ df_ d = torch randn exp requires_grad_ assertTrue is_all_nan StudentT mean assertTrue is_all_nan StudentT variance assertEqual StudentT variance inf assertEqual StudentT df sample size assertEqual StudentT df sample size assertEqual StudentT df_ d sample size assertEqual StudentT df_ d sample size assertEqual StudentT torch tensor requires_grad=True sample size assertEqual StudentT sample size assertEqual StudentT sample size ref_log_prob idx x log_prob d = df view - idx detach expected = scipy stats t logpdf x d assertEqual log_prob expected atol= e- rtol= _check_log_prob StudentT df ref_log_prob unittest skipIf TEST_NUMPY Numpy found set_default_dtype torch double test_studentT_sample set_rng_seed see Note Randomized statistical tests df loc scale product - _check_sampler_sampler StudentT df=df loc=loc scale=scale scipy stats t df=df loc=loc scale=scale f StudentT df= df loc= loc scale= scale unittest skipIf TEST_NUMPY Numpy found test_studentT_log_prob set_rng_seed see Note Randomized statistical tests num_samples = df loc scale product - dist = StudentT df=df loc=loc scale=scale x = dist sample num_samples actual_log_prob = dist log_prob x i range num_samples expected_log_prob = scipy stats t logpdf x i df=df loc=loc scale=scale assertEqual float actual_log_prob i float expected_log_prob atol= e- rtol= test_dirichlet_shape alpha = torch randn exp requires_grad_ alpha_ d = torch randn exp requires_grad_ assertEqual Dirichlet alpha sample size assertEqual Dirichlet alpha sample size assertEqual Dirichlet alpha_ d sample size assertEqual Dirichlet alpha_ d sample size unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_dirichlet_log_prob num_samples = alpha = torch exp torch randn dist = Dirichlet alpha x = dist sample num_samples actual_log_prob = dist log_prob x i range num_samples expected_log_prob = scipy stats dirichlet logpdf x i numpy alpha numpy assertEqual actual_log_prob i expected_log_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found test_dirichlet_log_prob_zero Specifically test special case where x= alpha= The PDF proportional x alpha- which case works out = The log PDF term should therefore However s easy accidentally introduce NaNs calculating log x without regard value alpha- alpha = torch tensor dist = Dirichlet alpha x = torch tensor actual_log_prob = dist log_prob x expected_log_prob = scipy stats dirichlet logpdf x numpy alpha numpy assertEqual actual_log_prob expected_log_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found test_dirichlet_sample set_rng_seed see Note Randomized statistical tests alpha = torch exp torch randn _check_sampler_sampler Dirichlet alpha scipy stats dirichlet alpha numpy f Dirichlet alpha= list alpha multivariate=True test_dirichlet_mode Test few edge cases Dirichlet distribution mode This also covers beta distributions concentrations_and_modes = nan nan nan concentration mode concentrations_and_modes dist = Dirichlet torch tensor concentration assertEqual dist mode torch tensor mode test_beta_shape con = torch randn exp requires_grad_ con = torch randn exp requires_grad_ con _ d = torch randn exp requires_grad_ con _ d = torch randn exp requires_grad_ assertEqual Beta con con sample size assertEqual Beta con con sample size assertEqual Beta con _ d con _ d sample size assertEqual Beta con _ d con _ d sample size assertEqual Beta sample size assertEqual Beta sample size unittest skipIf TEST_NUMPY NumPy found test_beta_log_prob _ range con = np exp np random normal con = np exp np random normal dist = Beta con con x = dist sample actual_log_prob = dist log_prob x sum expected_log_prob = scipy stats beta logpdf x con con assertEqual float actual_log_prob float expected_log_prob atol= e- rtol= unittest skipIf TEST_NUMPY NumPy found set_default_dtype torch double test_beta_sample set_rng_seed see Note Randomized statistical tests con con product _check_sampler_sampler Beta con con scipy stats beta con con f Beta alpha= con beta= con Check small alphas do cause NANs Tensor torch FloatTensor torch DoubleTensor x = Beta Tensor e- Tensor e- sample assertTrue np isfinite x x f Invalid Beta sample x test_beta_underflow For low values alpha beta gamma samples can underflow float result spurious mode To prevent torch _sample_dirichlet works double precision intermediate calculations set_rng_seed num_samples = dtype torch float torch double conc = torch tensor e- dtype=dtype beta_samples = Beta conc conc sample num_samples assertEqual beta_samples == sum assertEqual beta_samples == sum assert support concentrated around frac_zeros = float beta_samples sum num_samples frac_ones = float beta_samples sum num_samples assertEqual frac_zeros atol= rtol= assertEqual frac_ones atol= rtol= unittest skipIf TEST_CUDA TEST_XPU CUDA XPU found test_beta_underflow_gpu set_rng_seed num_samples = conc = torch tensor e- dtype=torch float device_type beta_samples = Beta conc conc sample num_samples assertEqual beta_samples == sum assertEqual beta_samples == sum assert support concentrated around frac_zeros = float beta_samples sum num_samples frac_ones = float beta_samples sum num_samples TODO increase precision once imbalance GPU fixed assertEqual frac_zeros atol= rtol= assertEqual frac_ones atol= rtol= set_default_dtype torch double test_continuous_bernoulli p = torch tensor requires_grad=True r = torch tensor requires_grad=True s = assertEqual ContinuousBernoulli p sample size assertFalse ContinuousBernoulli p sample requires_grad assertEqual ContinuousBernoulli r sample size assertEqual ContinuousBernoulli r sample size assertEqual ContinuousBernoulli r sample size assertEqual ContinuousBernoulli s sample size _gradcheck_log_prob ContinuousBernoulli p ref_log_prob idx val log_prob prob = p idx prob prob using default value lim here log_norm_const = math log + math pow prob - + math pow prob - log_norm_const = math log math atanh - prob - prob res = val math log prob + - val math log p -prob + log_norm_const assertEqual log_prob res _check_log_prob ContinuousBernoulli p ref_log_prob _check_log_prob ContinuousBernoulli logits=p log - -p log p ref_log_prob check entropy computation assertEqual ContinuousBernoulli p entropy torch tensor - - - atol= e- rtol= entropy below corresponds clamped value prob when using float value float should - assertEqual ContinuousBernoulli torch tensor entropy torch tensor - atol= e- rtol= assertEqual ContinuousBernoulli s entropy torch tensor - atol= e- rtol= test_continuous_bernoulli_ d p = torch full requires_grad_ assertEqual ContinuousBernoulli p sample size assertEqual ContinuousBernoulli p sample sample_shape= size assertEqual ContinuousBernoulli p sample size test_lkj_cholesky_log_prob tril_cholesky_to_tril_corr x x = vec_to_tril_matrix x - diag = - x x sum - sqrt diag_embed x = x + diag tril_matrix_to_vec x x T - dim range log_probs = lkj = LKJCholesky dim concentration= validate_args=True _ range sample = lkj sample sample_tril = tril_matrix_to_vec sample diag=- log_prob = lkj log_prob sample log_abs_det_jacobian = torch slogdet jacobian tril_cholesky_to_tril_corr sample_tril logabsdet log_probs append log_prob - log_abs_det_jacobian concentration= density uniform over space all correlation matrices dim == dim= pdf = jacobian adjustment factor assertTrue all torch allclose x torch tensor log atol= e- x log_probs assertEqual log_probs log_probs invalid_sample = torch cat sample sample new_ones dim dim= assertRaises ValueError lambda lkj log_prob invalid_sample test_independent_shape Dist params _get_examples param params base_dist = Dist param x = base_dist sample base_log_prob_shape = base_dist log_prob x shape reinterpreted_batch_ndims range len base_dist batch_shape + indep_dist = Independent base_dist reinterpreted_batch_ndims indep_log_prob_shape = base_log_prob_shape len base_log_prob_shape - reinterpreted_batch_ndims assertEqual indep_dist log_prob x shape indep_log_prob_shape assertEqual indep_dist sample shape base_dist sample shape assertEqual indep_dist has_rsample base_dist has_rsample indep_dist has_rsample assertEqual indep_dist sample shape base_dist sample shape try assertEqual indep_dist enumerate_support shape base_dist enumerate_support shape assertEqual indep_dist mean shape base_dist mean shape except NotImplementedError pass try assertEqual indep_dist variance shape base_dist variance shape except NotImplementedError pass try assertEqual indep_dist entropy shape indep_log_prob_shape except NotImplementedError pass test_independent_expand Dist params _get_examples param params base_dist = Dist param reinterpreted_batch_ndims range len base_dist batch_shape + s torch Size torch Size torch Size indep_dist = Independent base_dist reinterpreted_batch_ndims expanded_shape = s + indep_dist batch_shape expanded = indep_dist expand expanded_shape expanded_sample = expanded sample expected_shape = expanded_shape + indep_dist event_shape assertEqual expanded_sample shape expected_shape assertEqual expanded log_prob expanded_sample indep_dist log_prob expanded_sample assertEqual expanded event_shape indep_dist event_shape assertEqual expanded batch_shape expanded_shape set_default_dtype torch double test_cdf_icdf_inverse Tests invertibility property distributions Dist params _get_examples i param enumerate params dist = Dist param samples = dist sample sample_shape= try cdf = dist cdf samples actual = dist icdf cdf except NotImplementedError continue rel_error = torch abs actual - samples e- + torch abs samples assertLess rel_error max e- msg= \n join f Dist __name__ example i + len params icdf cdf x = x f x = samples f cdf x = cdf f icdf cdf x = actual unittest skipIf TEST_NUMPY NumPy found test_gamma_log_prob_at_boundary concentration log_prob inf -inf dist = Gamma concentration scipy_dist = scipy stats gamma concentration assertAlmostEqual dist log_prob log_prob assertAlmostEqual dist log_prob scipy_dist logpdf set_default_dtype torch double test_cdf_log_prob Tests differentiation CDF gives PDF given value Dist params _get_examples i param enumerate params We do need grads wrt params here e g shape gamma distribution param = key value detach isinstance value torch Tensor value key value param items dist = Dist param samples = dist sample dist support is_discrete samples requires_grad_ try cdfs = dist cdf samples pdfs = dist log_prob samples exp except NotImplementedError continue cdfs_derivative = grad cdfs sum samples should wrapped torch abs assertEqual cdfs_derivative pdfs msg= \n join f Dist __name__ example i + len params d cdf dx = pdf x f x = samples f cdf = cdfs f pdf = pdfs f grad cdf = cdfs_derivative test_valid_parameter_broadcasting Test correct broadcasting parameter sizes distributions have multiple parameters example type distribution instance expected sample shape valid_examples = Normal loc=torch tensor scale= Normal loc= scale=torch tensor Normal loc=torch tensor scale=torch tensor Normal loc=torch tensor scale=torch tensor Normal loc=torch tensor scale=torch tensor Normal loc=torch tensor scale=torch tensor FisherSnedecor df =torch tensor df = FisherSnedecor df = df =torch tensor FisherSnedecor df =torch tensor df =torch tensor FisherSnedecor df =torch tensor df =torch tensor FisherSnedecor df =torch tensor df =torch tensor FisherSnedecor df =torch tensor df =torch tensor Gamma concentration=torch tensor rate= Gamma concentration= rate=torch tensor Gamma concentration=torch tensor rate=torch tensor Gamma concentration=torch tensor rate=torch tensor Gamma concentration=torch tensor rate=torch tensor Gamma concentration=torch tensor rate=torch tensor Gumbel loc=torch tensor scale= Gumbel loc= scale=torch tensor Gumbel loc=torch tensor scale=torch tensor Gumbel loc=torch tensor scale=torch tensor Gumbel loc=torch tensor scale=torch tensor Gumbel loc=torch tensor scale=torch tensor Kumaraswamy concentration =torch tensor concentration = Kumaraswamy concentration = concentration =torch tensor Kumaraswamy concentration =torch tensor concentration =torch tensor Kumaraswamy concentration =torch tensor concentration =torch tensor Kumaraswamy concentration =torch tensor concentration =torch tensor Kumaraswamy concentration =torch tensor concentration =torch tensor Laplace loc=torch tensor scale= Laplace loc= scale=torch tensor Laplace loc=torch tensor scale=torch tensor Laplace loc=torch tensor scale=torch tensor Laplace loc=torch tensor scale=torch tensor Laplace loc=torch tensor scale=torch tensor Pareto scale=torch tensor alpha= Pareto scale= alpha=torch tensor Pareto scale=torch tensor alpha=torch tensor Pareto scale=torch tensor alpha=torch tensor Pareto scale=torch tensor alpha=torch tensor Pareto scale=torch tensor alpha=torch tensor StudentT df=torch tensor loc= StudentT df= scale=torch tensor StudentT df=torch tensor loc=torch tensor StudentT df=torch tensor scale=torch tensor StudentT df=torch tensor loc=torch tensor StudentT df=torch tensor scale=torch tensor StudentT df= loc=torch zeros scale=torch ones dist expected_size valid_examples actual_size = dist sample size assertEqual actual_size expected_size msg=f dist actual size actual_size = expected size expected_size sample_shape = torch Size expected_size = sample_shape + expected_size actual_size = dist sample sample_shape size assertEqual actual_size expected_size msg=f dist actual size actual_size = expected size expected_size test_invalid_parameter_broadcasting invalid broadcasting cases should throw error example type distribution distribution params invalid_examples = Normal loc torch tensor scale torch tensor Normal loc torch tensor scale torch tensor FisherSnedecor df torch tensor df torch tensor Gumbel loc torch tensor scale torch tensor Gumbel loc torch tensor scale torch tensor Gamma concentration torch tensor rate torch tensor Kumaraswamy concentration torch tensor concentration torch tensor Kumaraswamy concentration torch tensor concentration torch tensor Laplace loc torch tensor scale torch tensor Pareto scale torch tensor alpha torch tensor StudentT df torch tensor scale torch tensor StudentT df torch tensor loc torch tensor dist kwargs invalid_examples assertRaises RuntimeError dist kwargs _test_discrete_distribution_mode dist sanitized_mode batch_isfinite We cannot easily check mode discrete distributions we can look left right ensure log probability smaller than mode step - log_prob_mode = dist log_prob sanitized_mode isinstance dist OneHotCategorical idx = dist _categorical mode + dist probs shape - other = torch nn functional one_hot idx num_classes=dist probs shape - dist mode other = dist mode + step mask = batch_isfinite dist support check other assertTrue mask any dist mode unique numel == Add dimension right event shape scalar e g OneHotCategorical other = torch where mask None mask ndim other ndim mask other dist sample log_prob_other = dist log_prob other delta = log_prob_mode - log_prob_other assertTrue - e- delta mask detach all Allow up e- rounding error _test_continuous_distribution_mode dist sanitized_mode batch_isfinite We perturb mode unconstrained space expect log probability decrease num_points = transform = transform_to dist support unconstrained_mode = transform inv sanitized_mode perturbation = e- torch rand num_points + unconstrained_mode shape - perturbed_mode = transform perturbation + unconstrained_mode log_prob_mode = dist log_prob sanitized_mode log_prob_other = dist log_prob perturbed_mode delta = log_prob_mode - log_prob_other We pass test small tolerance allow rounding manually set difference zero both log probs infinite same sign both_infinite_with_same_sign = log_prob_mode == log_prob_other log_prob_mode abs == inf delta both_infinite_with_same_sign = ordering = delta - e- all axis= assertTrue ordering batch_isfinite all set_default_dtype torch double test_mode discrete_distributions = Bernoulli Binomial Categorical Geometric NegativeBinomial OneHotCategorical Poisson no_mode_available = ContinuousBernoulli LKJCholesky LogisticNormal MixtureSameFamily Multinomial RelaxedBernoulli RelaxedOneHotCategorical dist_cls params _get_examples param params dist = dist_cls param isinstance dist no_mode_available type dist TransformedDistribution assertRaises NotImplementedError dist mode continue Check either all no elements event shape nan mode cannot defined part event isfinite = dist mode isfinite reshape dist batch_shape + dist event_shape numel batch_isfinite = isfinite all axis=- assertTrue batch_isfinite &#124; ~isfinite any axis=- all We sanitize undefined modes sampling distribution sanitized_mode = torch where ~dist mode isnan dist mode dist sample isinstance dist discrete_distributions _test_discrete_distribution_mode dist sanitized_mode batch_isfinite _test_continuous_distribution_mode dist sanitized_mode batch_isfinite assertFalse dist log_prob sanitized_mode isnan any These tests only needed few distributions implement custom reparameterized gradients Most rsample implementations simply rely reparameterization trick do need tested accuracy skipIfTorchDynamo Not TorchDynamo suitable test TestRsample DistributionsTestCase unittest skipIf TEST_NUMPY NumPy found test_gamma num_samples = alpha e- e- e e e e e alphas = torch tensor alpha num_samples dtype=torch float requires_grad=True betas = alphas new_ones num_samples x = Gamma alphas betas rsample x sum backward x ind = x sort x = x detach numpy actual_grad = alphas grad ind numpy Compare expected gradient dx dalpha along constant cdf x alpha cdf = scipy stats gamma cdf pdf = scipy stats gamma pdf eps = alpha + alpha cdf_alpha = cdf x alpha + eps - cdf x alpha - eps eps cdf_x = pdf x alpha expected_grad = -cdf_alpha cdf_x rel_error = np abs actual_grad - expected_grad expected_grad + e- assertLess np max rel_error \n join f Bad gradient dx alpha x ~ Gamma alpha f x x f expected expected_grad f actual actual_grad f rel error rel_error f max error rel_error max f alpha= alpha x= x rel_error argmax unittest skipIf TEST_NUMPY NumPy found test_chi num_samples = df e- e- e e e e e dfs = torch tensor df num_samples dtype=torch float requires_grad=True x = Chi dfs rsample x sum backward x ind = x sort x = x detach numpy actual_grad = dfs grad ind numpy Compare expected gradient dx ddf along constant cdf x df cdf = scipy stats chi cdf pdf = scipy stats chi pdf eps = df + df cdf_df = cdf x df + eps - cdf x df - eps eps cdf_x = pdf x df expected_grad = -cdf_df cdf_x rel_error = np abs actual_grad - expected_grad expected_grad + e- assertLess np max rel_error \n join f Bad gradient dx ddf x ~ Chi df f x x f expected expected_grad f actual actual_grad f rel error rel_error f max error rel_error max unittest skipIf TEST_NUMPY NumPy found test_dirichlet_on_diagonal num_samples = grid = e- e e product grid grid grid alphas = torch tensor num_samples dtype=torch float requires_grad=True x = Dirichlet alphas rsample x sum backward x ind = x sort x = x detach numpy actual_grad = alphas grad ind numpy Compare expected gradient dx dalpha along constant cdf x alpha This reduces distribution Beta alpha alpha + alpha cdf = scipy stats beta cdf pdf = scipy stats beta pdf alpha beta = + eps = alpha + np sqrt alpha cdf_alpha = cdf x alpha + eps beta - cdf x alpha - eps beta eps cdf_x = pdf x alpha beta expected_grad = -cdf_alpha cdf_x rel_error = np abs actual_grad - expected_grad expected_grad + e- assertLess np max rel_error \n join f Bad gradient dx dalpha Dirichlet f x x f expected expected_grad f actual actual_grad f rel error rel_error f max error rel_error max f x= x rel_error argmax unittest skipIf TEST_NUMPY NumPy found test_beta_wrt_alpha num_samples = grid = e- e- e e e con con product grid grid con s = torch tensor con num_samples dtype=torch float requires_grad=True con s = con s new_tensor con num_samples x = Beta con s con s rsample x sum backward x ind = x sort x = x detach numpy actual_grad = con s grad ind numpy Compare expected gradient dx dcon along constant cdf x con con cdf = scipy stats beta cdf pdf = scipy stats beta pdf eps = con + np sqrt con cdf_alpha = cdf x con + eps con - cdf x con - eps con eps cdf_x = pdf x con con expected_grad = -cdf_alpha cdf_x rel_error = np abs actual_grad - expected_grad expected_grad + e- assertLess np max rel_error \n join f Bad gradient dx dcon x ~ Beta con con f x x f expected expected_grad f actual actual_grad f rel error rel_error f max error rel_error max f x = x rel_error argmax unittest skipIf TEST_NUMPY NumPy found test_beta_wrt_beta num_samples = grid = e- e- e e e con con product grid grid con s = torch tensor con num_samples dtype=torch float requires_grad=True con s = con s new_tensor con num_samples x = Beta con s con s rsample x sum backward x ind = x sort x = x detach numpy actual_grad = con s grad ind numpy Compare expected gradient dx dcon along constant cdf x con con cdf = scipy stats beta cdf pdf = scipy stats beta pdf eps = con + np sqrt con cdf_beta = cdf x con con + eps - cdf x con con - eps eps cdf_x = pdf x con con expected_grad = -cdf_beta cdf_x rel_error = np abs actual_grad - expected_grad expected_grad + e- assertLess np max rel_error \n join f Bad gradient dx dcon x ~ Beta con con f x x f expected expected_grad f actual actual_grad f rel error rel_error f max error rel_error max f x = x rel_error argmax r test_dirichlet_multivariate alpha_crit = - num_samples = shift - - - alpha = alpha_crit + shift alpha = torch tensor alpha dtype=torch float requires_grad=True alpha_vec = torch cat alpha alpha alpha new z = Dirichlet alpha_vec expand num_samples rsample mean_z = alpha + loss = torch pow z - mean_z mean actual_grad = grad loss alpha Compute expected gradient hand num = - alpha - alpha den = + alpha + alpha expected_grad = num den assertEqual actual_grad expected_grad atol= rtol= msg= \n join alpha = alpha_c + g shift noqa UP expected_grad g expected_grad noqa UP actual_grad g actual_grad noqa UP error = g noqa UP torch abs expected_grad - actual_grad max noqa UP set_default_dtype torch double test_dirichlet_tangent_field num_samples = alpha_grid = v = dx dalpha reparameterized gradient aka tangent field compute_v x alpha torch stack _Dirichlet_backward x alpha torch eye i expand_as x i range dim=- product alpha_grid alpha_grid alpha_grid alpha = torch tensor requires_grad=True expand num_samples x = Dirichlet alpha rsample dlogp_da = grad Dirichlet alpha log_prob x detach sum alpha retain_graph=True dlogp_dx = grad Dirichlet alpha detach log_prob x sum x retain_graph=True v = torch stack grad x i sum alpha retain_graph=True i range dim=- Compute ramaining properties finite difference assertEqual compute_v x alpha v msg= Bug compute_v helper dx arbitrary orthonormal basis tangent simplex dx = torch tensor - - - dx = dx norm - True eps = e- x min - True avoid boundary dv = compute_v x + eps dx alpha - compute_v x - eps dx alpha eps dv = compute_v x + eps dx alpha - compute_v x - eps dx alpha eps div_v = dv dx + dv dx sum - This modification standard continuity equation using product rule allow expression terms log_prob rather than less numerically stable log_prob exp error = dlogp_da + dlogp_dx v sum - + div_v assertLess torch abs error max \n join f Dirichlet gradient violates continuity equation f error = error TestDistributionShapes DistributionsTestCase setUp super setUp scalar_sample = tensor_sample_ = torch ones tensor_sample_ = torch ones test_entropy_shape Dist params _get_examples i param enumerate params dist = Dist validate_args=False param try actual_shape = dist entropy size expected_shape = dist batch_shape dist batch_shape torch Size message = f Dist __name__ example i + len params shape mismatch expected expected_shape actual actual_shape noqa B assertEqual actual_shape expected_shape msg=message except NotImplementedError continue test_bernoulli_shape_scalar_params bernoulli = Bernoulli assertEqual bernoulli _batch_shape torch Size assertEqual bernoulli _event_shape torch Size assertEqual bernoulli sample size torch Size assertEqual bernoulli sample size torch Size assertRaises ValueError bernoulli log_prob scalar_sample assertEqual bernoulli log_prob tensor_sample_ size torch Size assertEqual bernoulli log_prob tensor_sample_ size torch Size test_bernoulli_shape_tensor_params bernoulli = Bernoulli torch tensor assertEqual bernoulli _batch_shape torch Size assertEqual bernoulli _event_shape torch Size assertEqual bernoulli sample size torch Size assertEqual bernoulli sample size torch Size assertEqual bernoulli log_prob tensor_sample_ size torch Size assertRaises ValueError bernoulli log_prob tensor_sample_ assertEqual bernoulli log_prob torch ones size torch Size test_geometric_shape_scalar_params geometric = Geometric assertEqual geometric _batch_shape torch Size assertEqual geometric _event_shape torch Size assertEqual geometric sample size torch Size assertEqual geometric sample size torch Size assertRaises ValueError geometric log_prob scalar_sample assertEqual geometric log_prob tensor_sample_ size torch Size assertEqual geometric log_prob tensor_sample_ size torch Size test_geometric_shape_tensor_params geometric = Geometric torch tensor assertEqual geometric _batch_shape torch Size assertEqual geometric _event_shape torch Size assertEqual geometric sample size torch Size assertEqual geometric sample size torch Size assertEqual geometric log_prob tensor_sample_ size torch Size assertRaises ValueError geometric log_prob tensor_sample_ assertEqual geometric log_prob torch ones size torch Size test_beta_shape_scalar_params dist = Beta assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertRaises ValueError dist log_prob scalar_sample assertEqual dist log_prob tensor_sample_ size torch Size assertEqual dist log_prob tensor_sample_ size torch Size test_beta_shape_tensor_params dist = Beta torch tensor torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertRaises ValueError dist log_prob tensor_sample_ assertEqual dist log_prob torch ones size torch Size test_binomial_shape dist = Binomial torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertRaises ValueError dist log_prob tensor_sample_ test_binomial_shape_vectorized_n dist = Binomial torch tensor torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertRaises ValueError dist log_prob tensor_sample_ test_multinomial_shape dist = Multinomial torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertRaises ValueError dist log_prob tensor_sample_ assertEqual dist log_prob torch ones size torch Size test_categorical_shape unbatched dist = Categorical torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertEqual dist log_prob torch ones size torch Size batched dist = Categorical torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertRaises ValueError dist log_prob tensor_sample_ assertEqual dist log_prob tensor_sample_ size torch Size assertEqual dist log_prob torch ones size torch Size test_one_hot_categorical_shape unbatched dist = OneHotCategorical torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertRaises ValueError dist log_prob tensor_sample_ sample = torch tensor expand assertEqual dist log_prob sample size torch Size assertEqual dist log_prob dist enumerate_support size torch Size sample = torch eye assertEqual dist log_prob sample size torch Size batched dist = OneHotCategorical torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size sample = torch tensor assertEqual dist log_prob sample size torch Size assertRaises ValueError dist log_prob tensor_sample_ assertEqual dist log_prob dist enumerate_support size torch Size sample = torch tensor expand assertEqual dist log_prob sample size torch Size test_cauchy_shape_scalar_params cauchy = Cauchy assertEqual cauchy _batch_shape torch Size assertEqual cauchy _event_shape torch Size assertEqual cauchy sample size torch Size assertEqual cauchy sample torch Size size torch Size assertRaises ValueError cauchy log_prob scalar_sample assertEqual cauchy log_prob tensor_sample_ size torch Size assertEqual cauchy log_prob tensor_sample_ size torch Size test_cauchy_shape_tensor_params cauchy = Cauchy torch tensor torch tensor assertEqual cauchy _batch_shape torch Size assertEqual cauchy _event_shape torch Size assertEqual cauchy sample size torch Size assertEqual cauchy sample torch Size size torch Size assertEqual cauchy log_prob tensor_sample_ size torch Size assertRaises ValueError cauchy log_prob tensor_sample_ assertEqual cauchy log_prob torch ones size torch Size test_halfcauchy_shape_scalar_params halfcauchy = HalfCauchy assertEqual halfcauchy _batch_shape torch Size assertEqual halfcauchy _event_shape torch Size assertEqual halfcauchy sample size torch Size assertEqual halfcauchy sample torch Size size torch Size assertRaises ValueError halfcauchy log_prob scalar_sample assertEqual halfcauchy log_prob tensor_sample_ size torch Size assertEqual halfcauchy log_prob tensor_sample_ size torch Size test_halfcauchy_shape_tensor_params halfcauchy = HalfCauchy torch tensor assertEqual halfcauchy _batch_shape torch Size assertEqual halfcauchy _event_shape torch Size assertEqual halfcauchy sample size torch Size assertEqual halfcauchy sample torch Size size torch Size assertEqual halfcauchy log_prob tensor_sample_ size torch Size assertRaises ValueError halfcauchy log_prob tensor_sample_ assertEqual halfcauchy log_prob torch ones size torch Size test_dirichlet_shape dist = Dirichlet torch tensor assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size simplex_sample = tensor_sample_ tensor_sample_ sum - keepdim=True assertEqual dist log_prob simplex_sample size torch Size assertRaises ValueError dist log_prob tensor_sample_ simplex_sample = torch ones simplex_sample = simplex_sample simplex_sample sum - unsqueeze - assertEqual dist log_prob simplex_sample size torch Size test_mixture_same_family_shape dist = MixtureSameFamily Categorical torch rand Normal torch randn torch rand assertEqual dist _batch_shape torch Size assertEqual dist _event_shape torch Size assertEqual dist sample size torch Size assertEqual dist sample size torch Size assertEqual dist log_prob tensor_sample_ size torch Size assertEqual dist log_prob tensor_sample_ size torch Size test_gamma_shape_scalar_params gamma = Gamma assertEqual gamma _batch_shape torch Size assertEqual gamma _event_shape torch Size assertEqual gamma sample size torch Size assertEqual gamma sample size torch Size assertEqual gamma log_prob scalar_sample size torch Size assertEqual gamma log_prob tensor_sample_ size torch Size assertEqual gamma log_prob tensor_sample_ size torch Size test_gamma_shape_tensor_params gamma = Gamma torch tensor torch tensor assertEqual gamma _batch_shape torch Size assertEqual gamma _event_shape torch Size assertEqual gamma sample size torch Size assertEqual gamma sample size torch Size assertEqual gamma log_prob tensor_sample_ size torch Size assertRaises ValueError gamma log_prob tensor_sample_ assertEqual gamma log_prob torch ones size torch Size test_chi _shape_scalar_params chi = Chi assertEqual chi _batch_shape torch Size assertEqual chi _event_shape torch Size assertEqual chi sample size torch Size assertEqual chi sample size torch Size assertEqual chi log_prob scalar_sample size torch Size assertEqual chi log_prob tensor_sample_ size torch Size assertEqual chi log_prob tensor_sample_ size torch Size test_chi _shape_tensor_params chi = Chi torch tensor assertEqual chi _batch_shape torch Size assertEqual chi _event_shape torch Size assertEqual chi sample size torch Size assertEqual chi sample size torch Size assertEqual chi log_prob tensor_sample_ size torch Size assertRaises ValueError chi log_prob tensor_sample_ assertEqual chi log_prob torch ones size torch Size test_studentT_shape_scalar_params st = StudentT assertEqual st _batch_shape torch Size assertEqual st _event_shape torch Size assertEqual st sample size torch Size assertEqual st sample size torch Size assertRaises ValueError st log_prob scalar_sample assertEqual st log_prob tensor_sample_ size torch Size assertEqual st log_prob tensor_sample_ size torch Size test_studentT_shape_tensor_params st = StudentT torch tensor assertEqual st _batch_shape torch Size assertEqual st _event_shape torch Size assertEqual st sample size torch Size assertEqual st sample size torch Size assertEqual st log_prob tensor_sample_ size torch Size assertRaises ValueError st log_prob tensor_sample_ assertEqual st log_prob torch ones size torch Size test_pareto_shape_scalar_params pareto = Pareto assertEqual pareto _batch_shape torch Size assertEqual pareto _event_shape torch Size assertEqual pareto sample size torch Size assertEqual pareto sample size torch Size assertEqual pareto log_prob tensor_sample_ + size torch Size assertEqual pareto log_prob tensor_sample_ + size torch Size test_gumbel_shape_scalar_params gumbel = Gumbel assertEqual gumbel _batch_shape torch Size assertEqual gumbel _event_shape torch Size assertEqual gumbel sample size torch Size assertEqual gumbel sample size torch Size assertEqual gumbel log_prob tensor_sample_ size torch Size assertEqual gumbel log_prob tensor_sample_ size torch Size test_kumaraswamy_shape_scalar_params kumaraswamy = Kumaraswamy assertEqual kumaraswamy _batch_shape torch Size assertEqual kumaraswamy _event_shape torch Size assertEqual kumaraswamy sample size torch Size assertEqual kumaraswamy sample size torch Size assertEqual kumaraswamy log_prob tensor_sample_ size torch Size assertEqual kumaraswamy log_prob tensor_sample_ size torch Size test_vonmises_shape_tensor_params von_mises = VonMises torch tensor torch tensor assertEqual von_mises _batch_shape torch Size assertEqual von_mises _event_shape torch Size assertEqual von_mises sample size torch Size assertEqual von_mises sample torch Size size torch Size assertEqual von_mises log_prob tensor_sample_ size torch Size assertEqual von_mises log_prob torch ones size torch Size test_vonmises_shape_scalar_params von_mises = VonMises assertEqual von_mises _batch_shape torch Size assertEqual von_mises _event_shape torch Size assertEqual von_mises sample size torch Size assertEqual von_mises sample torch Size size torch Size assertEqual von_mises log_prob tensor_sample_ size torch Size assertEqual von_mises log_prob tensor_sample_ size torch Size test_weibull_scale_scalar_params weibull = Weibull assertEqual weibull _batch_shape torch Size assertEqual weibull _event_shape torch Size assertEqual weibull sample size torch Size assertEqual weibull sample size torch Size assertEqual weibull log_prob tensor_sample_ size torch Size assertEqual weibull log_prob tensor_sample_ size torch Size test_wishart_shape_scalar_params wishart = Wishart torch tensor torch tensor assertEqual wishart _batch_shape torch Size assertEqual wishart _event_shape torch Size assertEqual wishart sample size torch Size assertEqual wishart sample size torch Size assertRaises ValueError wishart log_prob scalar_sample test_wishart_shape_tensor_params wishart = Wishart torch tensor torch tensor assertEqual wishart _batch_shape torch Size assertEqual wishart _event_shape torch Size assertEqual wishart sample size torch Size assertEqual wishart sample size torch Size assertRaises ValueError wishart log_prob tensor_sample_ assertEqual wishart log_prob torch ones size torch Size test_normal_shape_scalar_params normal = Normal assertEqual normal _batch_shape torch Size assertEqual normal _event_shape torch Size assertEqual normal sample size torch Size assertEqual normal sample size torch Size assertRaises ValueError normal log_prob scalar_sample assertEqual normal log_prob tensor_sample_ size torch Size assertEqual normal log_prob tensor_sample_ size torch Size test_normal_shape_tensor_params normal = Normal torch tensor torch tensor assertEqual normal _batch_shape torch Size assertEqual normal _event_shape torch Size assertEqual normal sample size torch Size assertEqual normal sample size torch Size assertEqual normal log_prob tensor_sample_ size torch Size assertRaises ValueError normal log_prob tensor_sample_ assertEqual normal log_prob torch ones size torch Size test_uniform_shape_scalar_params uniform = Uniform assertEqual uniform _batch_shape torch Size assertEqual uniform _event_shape torch Size assertEqual uniform sample size torch Size assertEqual uniform sample torch Size size torch Size assertRaises ValueError uniform log_prob scalar_sample assertEqual uniform log_prob tensor_sample_ size torch Size assertEqual uniform log_prob tensor_sample_ size torch Size test_uniform_shape_tensor_params uniform = Uniform torch tensor torch tensor assertEqual uniform _batch_shape torch Size assertEqual uniform _event_shape torch Size assertEqual uniform sample size torch Size assertEqual uniform sample torch Size size torch Size assertEqual uniform log_prob tensor_sample_ size torch Size assertRaises ValueError uniform log_prob tensor_sample_ assertEqual uniform log_prob torch ones size torch Size test_exponential_shape_scalar_param expon = Exponential assertEqual expon _batch_shape torch Size assertEqual expon _event_shape torch Size assertEqual expon sample size torch Size assertEqual expon sample size torch Size assertRaises ValueError expon log_prob scalar_sample assertEqual expon log_prob tensor_sample_ size torch Size assertEqual expon log_prob tensor_sample_ size torch Size test_exponential_shape_tensor_param expon = Exponential torch tensor assertEqual expon _batch_shape torch Size assertEqual expon _event_shape torch Size assertEqual expon sample size torch Size assertEqual expon sample size torch Size assertEqual expon log_prob tensor_sample_ size torch Size assertRaises ValueError expon log_prob tensor_sample_ assertEqual expon log_prob torch ones size torch Size test_laplace_shape_scalar_params laplace = Laplace assertEqual laplace _batch_shape torch Size assertEqual laplace _event_shape torch Size assertEqual laplace sample size torch Size assertEqual laplace sample size torch Size assertRaises ValueError laplace log_prob scalar_sample assertEqual laplace log_prob tensor_sample_ size torch Size assertEqual laplace log_prob tensor_sample_ size torch Size test_laplace_shape_tensor_params laplace = Laplace torch tensor torch tensor assertEqual laplace _batch_shape torch Size assertEqual laplace _event_shape torch Size assertEqual laplace sample size torch Size assertEqual laplace sample size torch Size assertEqual laplace log_prob tensor_sample_ size torch Size assertRaises ValueError laplace log_prob tensor_sample_ assertEqual laplace log_prob torch ones size torch Size test_continuous_bernoulli_shape_scalar_params continuous_bernoulli = ContinuousBernoulli assertEqual continuous_bernoulli _batch_shape torch Size assertEqual continuous_bernoulli _event_shape torch Size assertEqual continuous_bernoulli sample size torch Size assertEqual continuous_bernoulli sample size torch Size assertRaises ValueError continuous_bernoulli log_prob scalar_sample assertEqual continuous_bernoulli log_prob tensor_sample_ size torch Size assertEqual continuous_bernoulli log_prob tensor_sample_ size torch Size test_continuous_bernoulli_shape_tensor_params continuous_bernoulli = ContinuousBernoulli torch tensor assertEqual continuous_bernoulli _batch_shape torch Size assertEqual continuous_bernoulli _event_shape torch Size assertEqual continuous_bernoulli sample size torch Size assertEqual continuous_bernoulli sample size torch Size assertEqual continuous_bernoulli log_prob tensor_sample_ size torch Size assertRaises ValueError continuous_bernoulli log_prob tensor_sample_ assertEqual continuous_bernoulli log_prob torch ones size torch Size skipIfTorchDynamo Not TorchDynamo suitable test test_mixture_same_family_mean_shape mix_distribution = Categorical torch ones component_distribution = Normal torch zeros torch ones gmm = MixtureSameFamily mix_distribution component_distribution assertEqual len gmm mean shape skipIfTorchDynamo Not TorchDynamo suitable test TestKL DistributionsTestCase setUp super setUp Binomial Binomial __init__ probs super __init__ probs These pairs distributions x parameters specified The first pair e g bernoulli varies column-wise second e g bernoulli varies row-wise way we test all param pairs bernoulli = pairwise Bernoulli binomial = pairwise Binomial binomial_vectorized_count = Binomial torch tensor torch tensor Binomial torch tensor torch tensor beta = pairwise Beta categorical = pairwise Categorical cauchy = pairwise Cauchy - - chi = pairwise Chi dirichlet = pairwise Dirichlet exponential = pairwise Exponential gamma = pairwise Gamma gumbel = pairwise Gumbel - - halfnormal = pairwise HalfNormal inversegamma = pairwise InverseGamma laplace = pairwise Laplace - - lognormal = pairwise LogNormal - - normal = pairwise Normal - - independent = Independent normal Independent normal onehotcategorical = pairwise OneHotCategorical pareto = Pareto torch tensor expand torch tensor expand Pareto torch tensor expand torch tensor expand poisson = pairwise Poisson uniform_within_unit = pairwise Uniform uniform_positive = pairwise Uniform uniform_real = pairwise Uniform - - - uniform_pareto = pairwise Uniform continuous_bernoulli = pairwise ContinuousBernoulli These tests should pass precision = makes tests very expensive Instead we test precision = only test higher precision locally when adding new KL implementation The following pairs tested due very high variance monte carlo estimator their implementations have been reviewed extra care - pareto normal precision = Set when testing new KL implementation max_samples = int e Increase when testing smaller precision samples_per_batch = int e finite_examples = bernoulli bernoulli bernoulli poisson beta beta beta chi beta exponential beta gamma beta normal binomial binomial binomial_vectorized_count binomial_vectorized_count categorical categorical cauchy cauchy chi chi chi exponential chi gamma chi normal dirichlet dirichlet exponential chi exponential exponential exponential gamma exponential gumbel exponential normal gamma chi gamma exponential gamma gamma gamma gumbel gamma normal gumbel gumbel gumbel normal halfnormal halfnormal independent independent inversegamma inversegamma laplace laplace lognormal lognormal laplace normal normal gumbel normal laplace normal normal onehotcategorical onehotcategorical pareto chi pareto pareto pareto exponential pareto gamma poisson poisson uniform_within_unit beta uniform_positive chi uniform_positive exponential uniform_positive gamma uniform_real gumbel uniform_real normal uniform_pareto pareto continuous_bernoulli continuous_bernoulli continuous_bernoulli exponential continuous_bernoulli normal beta continuous_bernoulli infinite_examples = Bernoulli Bernoulli Bernoulli Bernoulli Categorical torch tensor Categorical torch tensor Categorical torch tensor Categorical torch tensor Beta Uniform Beta Uniform Beta Uniform Beta Pareto Binomial Binomial Binomial torch tensor torch tensor Binomial torch tensor torch tensor Chi Beta Chi Pareto Chi Uniform - Exponential Beta Exponential Pareto Exponential Uniform - Gamma Beta Gamma Pareto Gamma Uniform - Gumbel - Beta Gumbel - Chi Gumbel - Exponential Gumbel - Gamma Gumbel - Pareto Gumbel - Uniform - Laplace - Beta Laplace - Chi Laplace - Exponential Laplace - Gamma Laplace - Pareto Laplace - Uniform - Normal - Beta Normal - Chi Normal - Exponential Normal - Gamma Normal - Pareto Normal - Uniform - Pareto Chi Pareto Exponential Pareto Gamma Pareto Normal - Pareto Pareto Poisson Bernoulli Poisson Binomial Uniform - Beta Uniform Beta Uniform - Beta Uniform - Chi Uniform - Exponential Uniform - Gamma Uniform - Pareto ContinuousBernoulli Uniform ContinuousBernoulli Uniform ContinuousBernoulli Uniform ContinuousBernoulli Pareto Exponential ContinuousBernoulli Gamma ContinuousBernoulli Gumbel - ContinuousBernoulli Laplace - ContinuousBernoulli Normal - ContinuousBernoulli Uniform - ContinuousBernoulli Uniform ContinuousBernoulli Uniform - ContinuousBernoulli test_kl_monte_carlo set_rng_seed see Note Randomized statistical tests p _ _ q finite_examples actual = kl_divergence p q numerator = denominator = while denominator max_samples x = p sample sample_shape= samples_per_batch numerator += p log_prob x - q log_prob x sum denominator += x size expected = numerator denominator error = torch abs expected - actual + expected error error == error max precision break assertLess error error == error max precision \n join f Incorrect KL type p __name__ type q __name__ f Expected denominator Monte Carlo samples expected f Actual analytic actual Multivariate normal has separate Monte Carlo based test due requirement random generation positive semi definite matrices n set can increased during testing test_kl_multivariate_normal set_rng_seed see Note Randomized statistical tests n = Number tests multivariate_normal i range n loc = torch randn _ range scale_tril = transform_to constraints lower_cholesky torch randn _ range p = MultivariateNormal loc=loc scale_tril=scale_tril q = MultivariateNormal loc=loc scale_tril=scale_tril actual = kl_divergence p q numerator = denominator = while denominator max_samples x = p sample sample_shape= samples_per_batch numerator += p log_prob x - q log_prob x sum denominator += x size expected = numerator denominator error = torch abs expected - actual + expected error error == error max precision break assertLess error error == error max precision \n join f Incorrect KL MultivariateNormal MultivariateNormal instance i + n f Expected denominator Monte Carlo sample expected f Actual analytic actual test_kl_multivariate_normal_batched b = Number batches loc = torch randn b _ range scale_tril = transform_to constraints lower_cholesky torch randn b _ range expected_kl = torch stack kl_divergence MultivariateNormal loc i scale_tril=scale_tril i MultivariateNormal loc i scale_tril=scale_tril i i range b actual_kl = kl_divergence MultivariateNormal loc scale_tril=scale_tril MultivariateNormal loc scale_tril=scale_tril assertEqual expected_kl actual_kl test_kl_multivariate_normal_batched_broadcasted b = Number batches loc = torch randn b _ range scale_tril = transform_to constraints lower_cholesky torch randn b transform_to constraints lower_cholesky torch randn expected_kl = torch stack kl_divergence MultivariateNormal loc i scale_tril=scale_tril i MultivariateNormal loc i scale_tril=scale_tril i range b actual_kl = kl_divergence MultivariateNormal loc scale_tril=scale_tril MultivariateNormal loc scale_tril=scale_tril assertEqual expected_kl actual_kl test_kl_lowrank_multivariate_normal set_rng_seed see Note Randomized statistical tests n = Number tests lowrank_multivariate_normal i range n loc = torch randn _ range cov_factor = torch randn _ range cov_diag = transform_to constraints positive torch randn _ range covariance_matrix = cov_factor i matmul cov_factor i t + cov_diag i diag i range p = LowRankMultivariateNormal loc cov_factor cov_diag q = LowRankMultivariateNormal loc cov_factor cov_diag p_full = MultivariateNormal loc covariance_matrix q_full = MultivariateNormal loc covariance_matrix expected = kl_divergence p_full q_full actual_lowrank_lowrank = kl_divergence p q actual_lowrank_full = kl_divergence p q_full actual_full_lowrank = kl_divergence p_full q error_lowrank_lowrank = torch abs actual_lowrank_lowrank - expected max assertLess error_lowrank_lowrank precision \n join f Incorrect KL LowRankMultivariateNormal LowRankMultivariateNormal instance i + n f Expected KL MultivariateNormal expected f Actual analytic actual_lowrank_lowrank error_lowrank_full = torch abs actual_lowrank_full - expected max assertLess error_lowrank_full precision \n join f Incorrect KL LowRankMultivariateNormal MultivariateNormal instance i + n f Expected KL MultivariateNormal expected f Actual analytic actual_lowrank_full error_full_lowrank = torch abs actual_full_lowrank - expected max assertLess error_full_lowrank precision \n join f Incorrect KL MultivariateNormal LowRankMultivariateNormal instance i + n f Expected KL MultivariateNormal expected f Actual analytic actual_full_lowrank test_kl_lowrank_multivariate_normal_batched b = Number batches loc = torch randn b _ range cov_factor = torch randn b _ range cov_diag = transform_to constraints positive torch randn b _ range expected_kl = torch stack kl_divergence LowRankMultivariateNormal loc i cov_factor i cov_diag i LowRankMultivariateNormal loc i cov_factor i cov_diag i i range b actual_kl = kl_divergence LowRankMultivariateNormal loc cov_factor cov_diag LowRankMultivariateNormal loc cov_factor cov_diag assertEqual expected_kl actual_kl test_kl_exponential_family p _ _ q finite_examples type p type q issubclass type p ExponentialFamily actual = kl_divergence p q expected = _kl_expfamily_expfamily p q assertEqual actual expected msg= \n join f Incorrect KL type p __name__ type q __name__ f Expected using Bregman Divergence expected f Actual analytic actual f max error = torch abs actual - expected max test_kl_infinite p q infinite_examples assertTrue kl_divergence p q == inf all f Incorrect KL type p __name__ type q __name__ test_kl_edgecases assertEqual kl_divergence Bernoulli Bernoulli assertEqual kl_divergence Bernoulli Bernoulli assertEqual kl_divergence Categorical torch tensor Categorical torch tensor assertEqual kl_divergence Uniform Beta test_kl_shape Dist params _get_examples i param enumerate params dist = Dist param try kl = kl_divergence dist dist except NotImplementedError continue expected_shape = dist batch_shape dist batch_shape torch Size assertEqual kl shape expected_shape msg= \n join f Dist __name__ example i + len params f Expected expected_shape f Actual kl shape test_kl_transformed Regression test https github com pytorch pytorch issues scale = torch ones loc = torch zeros normal = Normal loc=loc scale=scale diag_normal = Independent normal reinterpreted_batch_ndims= trans_dist = TransformedDistribution diag_normal AffineTransform loc= scale= assertEqual kl_divergence diag_normal diag_normal shape assertEqual kl_divergence trans_dist trans_dist shape set_default_dtype torch double test_entropy_monte_carlo set_rng_seed see Note Randomized statistical tests Dist params _get_examples i param enumerate params dist = Dist param try actual = dist entropy except NotImplementedError continue x = dist sample sample_shape= expected = -dist log_prob x mean ignore = expected == inf &#124; expected == -inf expected ignore = actual ignore assertEqual actual expected atol= rtol= msg= \n join f Dist __name__ example i + len params incorrect entropy f Expected monte carlo expected f Actual analytic actual f max error = torch abs actual - expected max set_default_dtype torch double test_entropy_exponential_family Dist params _get_examples issubclass Dist ExponentialFamily continue i param enumerate params dist = Dist param try actual = dist entropy except NotImplementedError continue try expected = ExponentialFamily entropy dist except NotImplementedError continue assertEqual actual expected msg= \n join f Dist __name__ example i + len params incorrect entropy f Expected Bregman Divergence expected f Actual analytic actual f max error = torch abs actual - expected max TestConstraints DistributionsTestCase test_params_constraints normalize_probs_dists = Categorical Multinomial OneHotCategorical OneHotCategoricalStraightThrough RelaxedOneHotCategorical Dist params _get_examples i param enumerate params dist = Dist param name value param items isinstance value numbers Number value = torch tensor value Dist normalize_probs_dists name == probs These distributions accept positive probs elsewhere we use stricter constraint simplex value = value value sum - True try constraint = dist arg_constraints name except KeyError continue ignore optional parameters Check param shape compatible distribution shape assertGreaterEqual value dim constraint event_dim value_batch_shape = value shape value dim - constraint event_dim torch broadcast_shapes dist batch_shape value_batch_shape is_dependent constraint continue message = f Dist __name__ example i + len params parameter name = value assertTrue constraint check value all msg=message test_support_constraints Dist params _get_examples assertIsInstance Dist support Constraint i param enumerate params dist = Dist param value = dist sample constraint = dist support message = f Dist __name__ example i + len params sample = value assertEqual constraint event_dim len dist event_shape msg=message ok = constraint check value assertEqual ok shape dist batch_shape msg=message assertTrue ok all msg=message skipIfTorchDynamo Not TorchDynamo suitable test TestNumericalStability DistributionsTestCase _test_pdf_score dist_class x expected_value probs=None logits=None expected_gradient=None atol= e- probs None p = probs detach requires_grad_ dist = dist_class p p = logits detach requires_grad_ dist = dist_class logits=p log_pdf = dist log_prob x log_pdf sum backward assertEqual log_pdf expected_value atol=atol rtol= msg=f Incorrect value tensor type type x Expected = expected_value Actual = log_pdf expected_gradient None assertEqual p grad expected_gradient atol=atol rtol= msg=f Incorrect gradient tensor type type x Expected = expected_gradient Actual = p grad test_bernoulli_gradient tensor_type torch FloatTensor torch DoubleTensor _test_pdf_score dist_class=Bernoulli probs=tensor_type x=tensor_type expected_value=tensor_type expected_gradient=tensor_type _test_pdf_score dist_class=Bernoulli probs=tensor_type x=tensor_type expected_value=tensor_type torch finfo tensor_type dtype eps log expected_gradient=tensor_type _test_pdf_score dist_class=Bernoulli probs=tensor_type e- x=tensor_type expected_value=tensor_type math log e- expected_gradient=tensor_type Lower precision due - torch FloatTensor torch FloatTensor size _test_pdf_score dist_class=Bernoulli probs=tensor_type - e- x=tensor_type expected_value=tensor_type math log e- expected_gradient=tensor_type - atol= _test_pdf_score dist_class=Bernoulli logits=tensor_type math log x=tensor_type expected_value=tensor_type math log e- expected_gradient=tensor_type - atol= e- test_bernoulli_with_logits_underflow tensor_type lim torch FloatTensor - e torch DoubleTensor - e _test_pdf_score dist_class=Bernoulli logits=tensor_type lim x=tensor_type expected_value=tensor_type expected_gradient=tensor_type test_bernoulli_with_logits_overflow tensor_type lim torch FloatTensor e torch DoubleTensor e _test_pdf_score dist_class=Bernoulli logits=tensor_type lim x=tensor_type expected_value=tensor_type expected_gradient=tensor_type test_categorical_log_prob dtype torch float torch double p = torch tensor dtype=dtype requires_grad=True categorical = OneHotCategorical p log_pdf = categorical log_prob torch tensor dtype=dtype assertEqual log_pdf item test_categorical_log_prob_with_logits dtype torch float torch double p = torch tensor -inf dtype=dtype requires_grad=True categorical = OneHotCategorical logits=p log_pdf_prob_ = categorical log_prob torch tensor dtype=dtype assertEqual log_pdf_prob_ item log_pdf_prob_ = categorical log_prob torch tensor dtype=dtype assertEqual log_pdf_prob_ item -inf test_multinomial_log_prob dtype torch float torch double p = torch tensor dtype=dtype requires_grad=True s = torch tensor dtype=dtype multinomial = Multinomial p log_pdf = multinomial log_prob s assertEqual log_pdf item test_multinomial_log_prob_with_logits dtype torch float torch double p = torch tensor -inf dtype=dtype requires_grad=True multinomial = Multinomial logits=p log_pdf_prob_ = multinomial log_prob torch tensor dtype=dtype assertEqual log_pdf_prob_ item log_pdf_prob_ = multinomial log_prob torch tensor dtype=dtype assertEqual log_pdf_prob_ item -inf test_continuous_bernoulli_gradient expec_val x probs=None logits=None assert probs None logits None logits None probs = + math exp -logits bern_log_lik = x math log probs + - x math log p -probs probs probs using default values lims here log_norm_const = math log math fabs math atanh - probs - math log math fabs - probs + math log aux = math pow probs - log_norm_const = math log + + aux aux log_lik = bern_log_lik + log_norm_const log_lik expec_grad x probs=None logits=None assert probs None logits None logits None probs = + math exp -logits grad_bern_log_lik = x probs - - x - probs probs probs using default values lims here grad_log_c = probs - probs - probs math atanh - probs - grad_log_c = probs - probs probs - math atanh - probs grad_log_c = probs - + math pow probs - grad = grad_bern_log_lik + grad_log_c logits None grad = + math exp logits - math pow + math exp logits grad tensor_type torch FloatTensor torch DoubleTensor _test_pdf_score dist_class=ContinuousBernoulli probs=tensor_type x=tensor_type expected_value=tensor_type expec_val probs= expected_gradient=tensor_type expec_grad probs= _test_pdf_score dist_class=ContinuousBernoulli probs=tensor_type x=tensor_type expected_value=tensor_type expec_val probs= expected_gradient=tensor_type expec_grad probs= _test_pdf_score dist_class=ContinuousBernoulli probs=tensor_type x=tensor_type expected_value=tensor_type expec_val probs= expected_gradient=tensor_type expec_grad probs= _test_pdf_score dist_class=ContinuousBernoulli probs=tensor_type e- x=tensor_type expected_value=tensor_type expec_val probs= e- expected_gradient=tensor_type tensor_type expec_grad probs= e- atol= e- _test_pdf_score dist_class=ContinuousBernoulli probs=tensor_type - e- x=tensor_type expected_value=tensor_type expec_val probs= - e- expected_gradient=tensor_type expec_grad probs= - e- atol= _test_pdf_score dist_class=ContinuousBernoulli logits=tensor_type math log x=tensor_type expected_value=tensor_type expec_val logits=math log expected_gradient=tensor_type expec_grad logits=math log atol= e- _test_pdf_score dist_class=ContinuousBernoulli logits=tensor_type x=tensor_type expected_value=tensor_type expec_val logits= expected_gradient=tensor_type expec_grad logits= test_continuous_bernoulli_with_logits_underflow tensor_type lim expected torch FloatTensor - e torch DoubleTensor - e _test_pdf_score dist_class=ContinuousBernoulli logits=tensor_type lim x=tensor_type expected_value=tensor_type expected expected_gradient=tensor_type test_continuous_bernoulli_with_logits_overflow tensor_type lim expected torch FloatTensor e torch DoubleTensor e _test_pdf_score dist_class=ContinuousBernoulli logits=tensor_type lim x=tensor_type expected_value=tensor_type expected expected_gradient=tensor_type TODO make pytest parameterized test TestLazyLogitsInitialization DistributionsTestCase setUp super setUp ContinuousBernoulli tested because log_prob computed simply logits probs also needed examples = e e _get_examples e Dist Categorical OneHotCategorical Bernoulli Binomial Multinomial test_lazy_logits_initialization Dist params examples param = params copy probs param continue probs = param pop probs param logits = probs_to_logits probs dist = Dist param Create new instance generate valid sample dist log_prob Dist param sample message = f Failed Dist __name__ example len params assertNotIn probs dist __dict__ msg=message try dist enumerate_support except NotImplementedError pass assertNotIn probs dist __dict__ msg=message _ = dist batch_shape dist event_shape assertNotIn probs dist __dict__ msg=message test_lazy_probs_initialization Dist params examples param = params copy probs param continue dist = Dist param dist sample message = f Failed Dist __name__ example len params assertNotIn logits dist __dict__ msg=message try dist enumerate_support except NotImplementedError pass assertNotIn logits dist __dict__ msg=message _ = dist batch_shape dist event_shape assertNotIn logits dist __dict__ msg=message unittest skipIf TEST_NUMPY NumPy found skipIfTorchDynamo FIXME Tries trace through SciPy fails TestAgainstScipy DistributionsTestCase setUp super setUp positive_var = torch randn dtype=torch double exp positive_var = torch randn dtype=torch double exp random_var = torch randn dtype=torch double simplex_tensor = softmax torch randn dtype=torch double dim=- cov_tensor = torch randn dtype=torch double cov_tensor = cov_tensor cov_tensor mT distribution_pairs = Bernoulli simplex_tensor scipy stats bernoulli simplex_tensor Beta positive_var positive_var scipy stats beta positive_var positive_var Binomial simplex_tensor scipy stats binom np ones simplex_tensor shape simplex_tensor numpy Cauchy random_var positive_var scipy stats cauchy loc=random_var scale=positive_var Dirichlet positive_var scipy stats dirichlet positive_var Exponential positive_var scipy stats expon scale=positive_var reciprocal FisherSnedecor positive_var + positive_var var df = undefined scipy stats f positive_var + positive_var Gamma positive_var positive_var scipy stats gamma positive_var scale=positive_var reciprocal Geometric simplex_tensor scipy stats geom simplex_tensor loc=- Gumbel random_var positive_var scipy stats gumbel_r random_var positive_var GeneralizedPareto loc=random_var scale=positive_var concentration=random_var scipy stats genpareto c=random_var loc=random_var scale=positive_var HalfCauchy positive_var scipy stats halfcauchy scale=positive_var HalfNormal positive_var scipy stats halfnorm scale=positive_var InverseGamma positive_var positive_var scipy stats invgamma positive_var scale=positive_var Laplace random_var positive_var scipy stats laplace random_var positive_var Tests fail e- threshold scale LogNormal random_var positive_var clamp max= scipy stats lognorm s=positive_var clamp max= scale=random_var exp LowRankMultivariateNormal random_var torch zeros dtype=torch double positive_var scipy stats multivariate_normal random_var torch diag positive_var Multinomial simplex_tensor scipy stats multinomial simplex_tensor MultivariateNormal random_var torch diag positive_var scipy stats multivariate_normal random_var torch diag positive_var MultivariateNormal random_var cov_tensor scipy stats multivariate_normal random_var cov_tensor Normal random_var positive_var scipy stats norm random_var positive_var OneHotCategorical simplex_tensor scipy stats multinomial simplex_tensor Pareto positive_var + positive_var scipy stats pareto + positive_var scale=positive_var Poisson positive_var scipy stats poisson positive_var StudentT + positive_var random_var positive_var scipy stats t + positive_var random_var positive_var Uniform random_var random_var + positive_var scipy stats uniform random_var positive_var VonMises random_var positive_var scipy stats vonmises positive_var loc=random_var Weibull positive_var positive_var scipy var Weibull only supports scalars scipy stats weibull_min c=positive_var scale=positive_var scipy var Wishart only supports scalars SciPy allowed ndim - df ndim Wishar distribution after version Wishart version parse scipy __version__ version parse + positive_var cov_tensor scipy stats wishart version parse scipy __version__ version parse + positive_var item cov_tensor test_mean pytorch_dist scipy_dist distribution_pairs isinstance pytorch_dist Cauchy HalfCauchy Cauchy HalfCauchy distributions mean nan skipping check continue isinstance pytorch_dist LowRankMultivariateNormal MultivariateNormal assertEqual pytorch_dist mean scipy_dist mean msg=pytorch_dist assertEqual pytorch_dist mean scipy_dist mean msg=pytorch_dist test_variance_stddev pytorch_dist scipy_dist distribution_pairs isinstance pytorch_dist Cauchy HalfCauchy VonMises Cauchy HalfCauchy distributions standard deviation nan skipping check VonMises variance circular scipy doesn t produce correct result continue isinstance pytorch_dist Multinomial OneHotCategorical assertEqual pytorch_dist variance np diag scipy_dist cov msg=pytorch_dist assertEqual pytorch_dist stddev np diag scipy_dist cov msg=pytorch_dist isinstance pytorch_dist LowRankMultivariateNormal MultivariateNormal assertEqual pytorch_dist variance np diag scipy_dist cov msg=pytorch_dist assertEqual pytorch_dist stddev np diag scipy_dist cov msg=pytorch_dist assertEqual pytorch_dist variance scipy_dist var msg=pytorch_dist assertEqual pytorch_dist stddev scipy_dist var msg=pytorch_dist set_default_dtype torch double test_cdf pytorch_dist scipy_dist distribution_pairs samples = pytorch_dist sample try cdf = pytorch_dist cdf samples except NotImplementedError continue assertEqual cdf scipy_dist cdf samples msg=pytorch_dist test_icdf pytorch_dist scipy_dist distribution_pairs samples = torch rand + pytorch_dist batch_shape dtype=torch double try icdf = pytorch_dist icdf samples except NotImplementedError continue assertEqual icdf scipy_dist ppf samples msg=pytorch_dist TestFunctors DistributionsTestCase test_cat_transform x = - torch arange dtype=torch float view - x = torch arange dtype=torch float view - - x = torch arange dtype=torch float view - t t t = ExpTransform AffineTransform identity_transform dim = x = torch cat x x x dim=dim t = CatTransform t t t dim=dim actual_dom_check = t domain check x expected_dom_check = torch cat t domain check x t domain check x t domain check x dim=dim assertEqual expected_dom_check actual_dom_check actual = t x expected = torch cat t x t x t x dim=dim assertEqual expected actual y = torch arange dtype=torch float view - y = torch arange dtype=torch float view - y = torch arange dtype=torch float view - y = torch cat y y y dim=dim actual_cod_check = t codomain check y expected_cod_check = torch cat t codomain check y t codomain check y t codomain check y dim=dim assertEqual actual_cod_check expected_cod_check actual_inv = t inv y expected_inv = torch cat t inv y t inv y t inv y dim=dim assertEqual expected_inv actual_inv actual_jac = t log_abs_det_jacobian x y expected_jac = torch cat t log_abs_det_jacobian x y t log_abs_det_jacobian x y t log_abs_det_jacobian x y dim=dim assertEqual actual_jac expected_jac test_cat_transform_non_uniform x = - torch arange dtype=torch float view - x = torch cat torch arange dtype=torch float view - - torch arange dtype=torch float view - t = ExpTransform t = CatTransform AffineTransform identity_transform dim= dim = x = torch cat x x dim=dim t = CatTransform t t dim=dim lengths= actual_dom_check = t domain check x expected_dom_check = torch cat t domain check x t domain check x dim=dim assertEqual expected_dom_check actual_dom_check actual = t x expected = torch cat t x t x dim=dim assertEqual expected actual y = torch arange dtype=torch float view - y = torch cat torch arange dtype=torch float view - torch arange dtype=torch float view - y = torch cat y y dim=dim actual_cod_check = t codomain check y expected_cod_check = torch cat t codomain check y t codomain check y dim=dim assertEqual actual_cod_check expected_cod_check actual_inv = t inv y expected_inv = torch cat t inv y t inv y dim=dim assertEqual expected_inv actual_inv actual_jac = t log_abs_det_jacobian x y expected_jac = torch cat t log_abs_det_jacobian x y t log_abs_det_jacobian x y dim=dim assertEqual actual_jac expected_jac test_cat_event_dim t = AffineTransform torch ones event_dim= t = AffineTransform torch ones event_dim= dim = bs = x = torch randn bs x = torch randn bs x = torch cat x x dim= t = CatTransform t t dim=dim lengths= y = t x y = t x y = t x actual_jac = t log_abs_det_jacobian x y expected_jac = sum t log_abs_det_jacobian x y t log_abs_det_jacobian x y assertEqual actual_jac expected_jac test_stack_transform x = - torch arange dtype=torch float x = torch arange dtype=torch float - x = torch arange dtype=torch float t t t = ExpTransform AffineTransform identity_transform dim = x = torch stack x x x dim=dim t = StackTransform t t t dim=dim actual_dom_check = t domain check x expected_dom_check = torch stack t domain check x t domain check x t domain check x dim=dim assertEqual expected_dom_check actual_dom_check actual = t x expected = torch stack t x t x t x dim=dim assertEqual expected actual y = torch arange dtype=torch float y = torch arange dtype=torch float y = torch arange dtype=torch float y = torch stack y y y dim=dim actual_cod_check = t codomain check y expected_cod_check = torch stack t codomain check y t codomain check y t codomain check y dim=dim assertEqual actual_cod_check expected_cod_check actual_inv = t inv x expected_inv = torch stack t inv x t inv x t inv x dim=dim assertEqual expected_inv actual_inv actual_jac = t log_abs_det_jacobian x y expected_jac = torch stack t log_abs_det_jacobian x y t log_abs_det_jacobian x y t log_abs_det_jacobian x y dim=dim assertEqual actual_jac expected_jac TestValidation DistributionsTestCase test_valid Dist params _get_examples param params Dist validate_args=True param set_default_dtype torch double test_invalid_log_probs_arg Check validation errors indeed disabled they might raise another error Dist params _get_examples Dist == TransformedDistribution TransformedDistribution has distribution instance argument so we cannot do much about continue i param enumerate params d_nonval = Dist validate_args=False param d_val = Dist validate_args=True param v torch tensor - - samples incorrect shape must throw ValueError only try d_val log_prob v except ValueError pass get sample correct shape val = torch full d_val batch_shape + d_val event_shape v check samples incorrect support try d_val log_prob val except ValueError e e args must within support e args try d_nonval log_prob val except RuntimeError pass check correct samples ok valid_value = d_val sample d_val log_prob valid_value check invalid values raise ValueError valid_value dtype == torch long valid_value = valid_value float invalid_value = torch full_like valid_value math nan try assertRaisesRegex ValueError Expected value argument within support d_val log_prob invalid_value except AssertionError e fail_string = Support ValueError raised example raise AssertionError fail_string format Dist __name__ i + len params e set_default_dtype torch double test_invalid Dist params _get_bad_examples i param enumerate params try assertRaises ValueError Dist validate_args=True param except AssertionError e fail_string = ValueError raised example raise AssertionError fail_string format Dist __name__ i + len params e test_warning_unimplemented_constraints Delta Distribution __init__ validate_args=True super __init__ validate_args=validate_args sample sample_shape=torch Size torch tensor expand sample_shape log_prob value _validate_args _validate_sample value value value = = -float inf value value == = value assertWarns UserWarning d = Delta sample = d sample assertWarns UserWarning d log_prob sample TestJit DistributionsTestCase _examples Dist params _get_examples param params keys = param keys values = tuple param key key keys all isinstance x torch Tensor x values continue sample = Dist param sample yield Dist keys values sample _perturb_tensor value constraint isinstance constraint constraints _IntegerGreaterThan value + isinstance constraint constraints _LessThan value - torch rand value shape isinstance constraint constraints _GreaterThan constraints _GreaterThanEq value + torch rand value shape isinstance constraint constraints _PositiveDefinite constraints _PositiveSemidefinite value + torch eye value shape - value dtype torch float torch double transform = transform_to constraint delta = value new value shape normal_ transform transform inv value + delta value dtype == torch long result = value clone result value == = result value == = result raise NotImplementedError _perturb Dist keys values sample torch no_grad isinstance Dist arg_constraints dict values = _perturb_tensor value Dist arg_constraints get key constraints real key value zip keys values arg_constraints parameter-dependent dist = Dist dict zip keys values values = _perturb_tensor value dist arg_constraints get key constraints real key value zip keys values param = dict zip keys values sample = Dist param sample values sample set_default_dtype torch double test_sample Dist keys values sample _examples f values param = dict zip keys values dist = Dist param dist sample traced_f = torch jit trace f values check_trace=False FIXME Schema found node xfail = Cauchy aten cauchy Double float float Generator HalfCauchy aten cauchy Double float float Generator VonMises Variance Euclidean Dist xfail continue torch random fork_rng sample = f values traced_sample = traced_f values assertEqual sample traced_sample FIXME no nondeterministic nodes found trace xfail = Beta Dirichlet Dist xfail assertTrue any n isNondeterministic n traced_f graph nodes test_rsample Dist keys values sample _examples Dist has_rsample continue f values param = dict zip keys values dist = Dist param dist rsample traced_f = torch jit trace f values check_trace=False FIXME Schema found node xfail = Cauchy aten cauchy Double float float Generator HalfCauchy aten cauchy Double float float Generator Dist xfail continue torch random fork_rng sample = f values traced_sample = traced_f values assertEqual sample traced_sample FIXME no nondeterministic nodes found trace xfail = Beta Dirichlet Dist xfail assertTrue any n isNondeterministic n traced_f graph nodes set_default_dtype torch double test_log_prob Dist keys values sample _examples FIXME traced functions produce incorrect results xfail = LowRankMultivariateNormal MultivariateNormal Dist xfail continue f sample values param = dict zip keys values dist = Dist param dist log_prob sample traced_f = torch jit trace f sample + values check different data values sample = _perturb Dist keys values sample expected = f sample values actual = traced_f sample values assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual test_enumerate_support Dist keys values sample _examples FIXME traced functions produce incorrect results xfail = Binomial Dist xfail continue f values param = dict zip keys values dist = Dist param dist enumerate_support try traced_f = torch jit trace f values except NotImplementedError continue check different data values sample = _perturb Dist keys values sample expected = f values actual = traced_f values assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual test_mean Dist keys values sample _examples f values param = dict zip keys values dist = Dist param dist mean try traced_f = torch jit trace f values except NotImplementedError continue check different data values sample = _perturb Dist keys values sample expected = f values actual = traced_f values expected expected == float inf = actual actual == float inf = assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual test_variance Dist keys values sample _examples Dist Cauchy HalfCauchy continue infinite variance f values param = dict zip keys values dist = Dist param dist variance try traced_f = torch jit trace f values except NotImplementedError continue check different data values sample = _perturb Dist keys values sample expected = f values clone actual = traced_f values clone expected expected == float inf = actual actual == float inf = assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual set_default_dtype torch double test_entropy Dist keys values sample _examples FIXME traced functions produce incorrect results xfail = LowRankMultivariateNormal MultivariateNormal Dist xfail continue f values param = dict zip keys values dist = Dist param dist entropy try traced_f = torch jit trace f values except NotImplementedError continue check different data values sample = _perturb Dist keys values sample expected = f values actual = traced_f values assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual set_default_dtype torch double test_cdf Dist keys values sample _examples f sample values param = dict zip keys values dist = Dist param cdf = dist cdf sample dist icdf cdf try traced_f = torch jit trace f sample + values except NotImplementedError continue check different data values sample = _perturb Dist keys values sample expected = f sample values actual = traced_f sample values assertEqual expected actual msg=f Dist __name__ \nExpected \n expected \nActual \n actual __name__ == __main__ torch _C has_lapack TestCase _default_dtype_check_enabled = True run_tests