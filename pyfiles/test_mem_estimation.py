Owner s module inductor functools weakref collections Counter typing Callable Optional torch torch _inductor fx_passes memory_estimator build_memory_profile MemoryTracker torch _inductor test_case run_tests TestCase InductorTestCase torch _subclasses fake_tensor FakeTensorMode torch fx experimental proxy_tensor make_fx torch testing _internal inductor_utils GPU_TYPE HAS_GPU torch utils _python_dispatch TorchDispatchMode torch utils _pytree tree_map_only torch utils weak WeakIdKeyDictionary tensor_storage_id tensor tensor _typed_storage _cdata device_filter device device type == GPU_TYPE FakeTensorMemoryProfilerMode TorchDispatchMode __init__ device_filter Optional Callable torch device bool = None counter storage ids live references storage_count dict int int = Counter live fake tensors live_tensors = WeakIdKeyDictionary memory_use = max_memory = device_filter = device_filter __torch_dispatch__ func types args= kwargs=None kwargs = kwargs kwargs None rs = func args kwargs tree_map_only torch _subclasses FakeTensor increase_memory_use rs rs increase_memory_use tensor already accounted tensor live_tensors device_filter None device_filter tensor device live_tensors tensor = True nbytes = tensor untyped_storage nbytes storage_id = tensor_storage_id tensor new storage add memory storage_id storage_count change_memory nbytes storage_count storage_id += when tensor dies we need adjust memory weakref finalize tensor functools partial tensor_cleanup storage_id nbytes tensor_cleanup storage_id nbytes storage_count storage_id -= storage_count storage_id == del storage_count storage_id change_memory -nbytes change_memory delta memory_use += delta max_memory = max memory_use max_memory TestMemoryProfilingResNet InductorTestCase test_simple_linear_layers Test simple sequential model explicit weights CUDA create_inputs_and_weights Create inputs weights CUDA x = torch randn device=GPU_TYPE w = torch randn device=GPU_TYPE w = torch randn device=GPU_TYPE w = torch randn device=GPU_TYPE x w w w fn x w w w h = torch nn functional linear x w h = torch nn functional relu h h = torch nn functional linear h w h = torch nn functional relu h out = torch nn functional linear h w out FakeTensorMode Trace make_fx x w w w = create_inputs_and_weights fx_graph = make_fx fn x w w w Static analysis is_releasable node node op placeholder get_attr fx_memory_profile = build_memory_profile fx_graph graph is_releasable fx_peak = max fx_memory_profile Runtime profiling profiler = FakeTensorMemoryProfilerMode profiler x_runtime w _runtime w _runtime w _runtime = create_inputs_and_weights result = fn x_runtime w _runtime w _runtime w _runtime del result runtime_peak = profiler max_memory assertEqual fx_peak runtime_peak test_conv_network Test convolutional network create_inputs_and_weights Create inputs weights CUDA x = torch randn device=GPU_TYPE conv _weight = torch randn device=GPU_TYPE conv _weight = torch randn device=GPU_TYPE linear_weight = torch randn device=GPU_TYPE x conv _weight conv _weight linear_weight fn x conv _weight conv _weight linear_weight h = torch nn functional conv d x conv _weight padding= h = torch nn functional relu h h = torch nn functional max_pool d h h = torch nn functional conv d h conv _weight padding= h = torch nn functional relu h h = torch nn functional max_pool d h h = torch flatten h out = torch nn functional linear h linear_weight out FakeTensorMode Trace make_fx x conv _weight conv _weight linear_weight = create_inputs_and_weights fx_graph = make_fx fn x conv _weight conv _weight linear_weight is_releasable node node op placeholder get_attr fx_memory_profile = build_memory_profile fx_graph graph is_releasable fx_peak = max fx_memory_profile Runtime profiling profiler = FakeTensorMemoryProfilerMode profiler x_runtime conv _w conv _w linear_w = create_inputs_and_weights result = fn x_runtime conv _w conv _w linear_w del result runtime_peak = profiler max_memory assertEqual fx_peak runtime_peak TestMemoryTracker InductorTestCase test_memory_tracker_original_order Test MemoryTracker works correctly original scheduling order matches runtime profiling create_inputs_and_weights Create inputs weights CUDA x = torch randn device=GPU_TYPE w = torch randn device=GPU_TYPE w = torch randn device=GPU_TYPE x w w fn x w w Create simple function allocates intermediate tensors h = torch matmul x w Allocates h h = torch relu h h can freed h allocated out = torch matmul h w h can freed out allocated out FakeTensorMode Create inputs x w w = create_inputs_and_weights Trace function fx_graph = make_fx fn x w w Test MemoryTracker original order memory_tracker = MemoryTracker fx_graph graph device_filter=device_filter Schedule nodes original order compute_nodes = node node fx_graph graph nodes node op placeholder get_attr output node compute_nodes memory_tracker schedule_node node memory_tracker_peak = memory_tracker get_current_memory_bytes Compare runtime profiling using FakeTensorMemoryProfilerMode profiler = FakeTensorMemoryProfilerMode device_filter=device_filter profiler x_runtime w _runtime w _runtime = create_inputs_and_weights result = fn x_runtime w _runtime w _runtime del result runtime_peak = profiler max_memory Verify both approaches track meaningful memory usage assertGreater memory_tracker_peak MemoryTracker should track memory usage assertGreater runtime_peak Runtime profiler should track memory usage test_memory_tracker_different_scheduling Test different scheduling orders produce different memory usage patterns foo primals_ zeros = torch zeros_like primals_ Create zeros tensor add_result = zeros + Use zeros first use sum_result = zeros sum Use zeros second use cpu = torch zeros device= cpu cpu_ = cpu + add_result sum_result cpu_ FakeTensorMode Create input primals_ = torch randn device=GPU_TYPE Trace function fx_graph = make_fx foo primals_ Get compute nodes excluding placeholders get_attr output compute_nodes = node node fx_graph graph nodes node op placeholder get_attr output Test original order zeros_like add sum zeros gets freed after sum last use zeros memory_tracker = MemoryTracker fx_graph graph device_filter=device_filter memory_profile = initial_mem = memory_tracker get_current_memory_bytes node compute_nodes memory_tracker schedule_node node memory_profile append memory_tracker get_current_memory_bytes use primals should deallocate assertEqual memory_profile initial_mem Test different order zeros_like sum add zeros gets freed after add last use zeros new order memory_tracker = MemoryTracker fx_graph graph device_filter=device_filter memory_profile = Alternative schedule change which operation last use zeros Original zeros_like add sum zeros freed after sum Alternative zeros_like sum add zeros freed after add assert len compute_nodes == f Expected compute nodes got len compute_nodes reordered_nodes = compute_nodes zeros_like zeros = torch zeros_like primals_ compute_nodes sum sum_result = zeros sum zeros still alive compute_nodes add add_result = zeros + last use zeros freed here compute_nodes cpu = torch zeros device= cpu compute_nodes cpu_ = cpu + node reordered_nodes memory_tracker schedule_node node memory_profile append memory_tracker get_current_memory_bytes Compare peak memories peak = max memory_profile peak = max memory_profile Both should end same final memory all intermediate tensors freed assertEqual memory_profile - memory_profile - The profiles should different showing different memory patterns assertNotEqual memory_profile memory_profile Different scheduling should produce different memory profiles The different scheduling should produce different peak memory Original zeros + add_result both alive → higher peak Reordered zeros freed before add_result created → lower peak assertGreater peak peak Original order should have higher peak memory Specifically original has both zeros add_result alive simultaneously assertGreater memory_profile memory_profile Original order keeps more tensors alive simultaneously The reordered version should have lower intermediate memory usage assertLess peak peak Reordered schedule reduces peak memory through better deallocation timing Verify MemoryTracker correctly tracks different scheduling The first tracker should match since we tested accuracy against FakeTensorMemoryProfilerMode assertLessEqual abs memory_tracker peak_memory - peak First tracker peak should match profile peak The key test profiles show different peaks due different deallocation timing assertNotEqual peak peak Different scheduling produces different peak memory __name__ == __main__ HAS_GPU run_tests needs= filelock