__future__ annotations contextlib dataclasses functools threading typing weakref abc abstractmethod contextlib AbstractContextManager contextmanager dataclasses dataclass typing Any ClassVar Generic NewType Optional Protocol TYPE_CHECKING TypeGuard TypeVar Union typing_extensions override TypedDict TypeIs Unpack torch torch _C _autograd CreationMeta torch _C _functorch _add_batch_dim _unwrap_functional_tensor _wrap_functional_tensor get_unwrapped is_batchedtensor is_functorch_wrapped_tensor is_gradtrackingtensor is_legacy_batchedtensor maybe_get_bdim maybe_get_level peek_interpreter_stack torch _dispatch python enable_python_dispatcher torch _logging trace_structured torch utils _mode_utils no_dispatch torch utils _python_dispatch is_traceable_wrapper_subclass torch utils weak WeakIdKeyDictionary TYPE_CHECKING collections abc Callable Generator torch _C _functorch CInterpreter torch _guards Source torch _subclasses fake_tensor FakeTensor FakeTensorMode Import here avoid cycle Import following modules during type checking enable code intelligence features Do unconditionally they sympy importing sympy very slow torch fx experimental symbolic_shapes ShapeEnv SymbolicContext _is_fake_tensor t object - TypeIs FakeTensor torch _subclasses fake_tensor FakeTensor isinstance t FakeTensor DimList = list _TensorLikeT = TypeVar _TensorLikeT MetaTensorDesc torch Tensor _T = TypeVar _T _TensorT = TypeVar _TensorT bound=torch Tensor _TensorT_cov = TypeVar _TensorT_cov bound=torch Tensor covariant=True safe_is_leaf t Union MetaTensorDesc torch Tensor - bool try t is_leaf except RuntimeError inference mode can trigger False safe_grad t _TensorLikeT - Optional _TensorLikeT torch _logging hide_warnings torch _logging _internal safe_grad_filter pyrefly ignore bad-return t grad _expect_safe_grad t _TensorLikeT - _TensorLikeT grad = safe_grad t assert grad None grad assert_eq _T b _T - None assert == b f = b tls = threading local Turns off inference mode fake tensor propagation This turned True only ` torch compile ` Also look _dynamo config fake_tensor_disable_inference_mode tls disable_inference_mode = False contextmanager disable_inference_mode_for_fake_prop - Generator None None None prior = getattr tls disable_inference_mode False tls disable_inference_mode = True try yield finally tls disable_inference_mode = prior assert_metadata_eq assert_eq Callable object object None m Union MetaTensorDesc torch Tensor m torch Tensor skip_symbolic bool = False skip_leaf bool = False - None m = MetaTensorDescriber describe_tensor m isinstance m torch Tensor m go m MetaTensorDesc m torch Tensor - None assert_eq m dtype m dtype skip_symbolic assert_eq m shape m shape assert_eq m requires_grad m requires_grad skip_leaf assert_eq m is_leaf m is_leaf MetaTensorDesc doesn t store grad_fn inferred leaf assert_eq m grad_fn None m grad_fn None assert_eq m is_sparse m is_sparse getattr tls disable_inference_mode False assert_eq m is_inference m is_inference assert_eq m is_inference False assert_eq m is_conj m is_conj assert_eq m is_neg m is_neg assert_eq m grad None safe_grad m None m grad None go m grad _expect_safe_grad m TODO move assert_eq m layout m layout out sparse branches ready prime time yet m is_sparse assert_eq m layout m layout assert_eq m dense_dim m dense_dim assert_eq m sparse_dim m sparse_dim assert_eq m is_coalesced m is_coalesced is_sparse_compressed m assert_eq m layout m layout assert_eq m dense_dim m dense_dim assert_eq m sparse_dim m sparse_dim skip_symbolic assert_eq m stride m stride assert_eq m storage_offset m storage_offset assert_eq m is_view m _is_view m is_view assert m base None assert m _base None go m base m _base TODO test resizable no direct query atm TODO audit AutogradMeta see matches TODO test forward AD go m m TypeGuard TypeIs False does imply torch Tensor is_sparse_coo t object - TypeGuard torch Tensor isinstance t torch Tensor t layout torch sparse_coo is_sparse_compressed_layout layout torch layout - bool layout torch sparse_csr torch sparse_csc torch sparse_bsr torch sparse_bsc TypeGuard TypeIs False does imply torch Tensor is_sparse_compressed t object - TypeGuard torch Tensor isinstance t torch Tensor is_sparse_compressed_layout t layout TypeGuard TypeIs False does imply torch Tensor is_sparse_any t object - TypeGuard torch Tensor is_sparse_coo t is_sparse_compressed t _checked_cast ty type _T obj object - _T assert isinstance obj ty f expected ty got type obj obj _get_real_storage base torch UntypedStorage - torch UntypedStorage base real_storage type ignore attr-defined _set_real_storage base torch UntypedStorage real_storage torch UntypedStorage - None base real_storage = real_storage type ignore attr-defined Don t use id directly because those can get reallocated over time MetaStorageId = NewType MetaStorageId int MetaTensorId = NewType MetaTensorId int _DescriberId = NewType _DescriberId int DESCRIBER_NEXT_ID = _DescriberId MetaTensorDescriber Given Tensor Storage generate MetaTensorDesc MetaStorageDesc which enough information reconstruct meta tensor fake tensor corresponding Tensor faithfully possible This stateful conversion object because we keep track IDs tensors storages passed us so we can consistently give same ID when we see same tensor storage __init__ copy_data bool = False - None global DESCRIBER_NEXT_ID id = DESCRIBER_NEXT_ID DESCRIBER_NEXT_ID = _DescriberId DESCRIBER_NEXT_ID + next_tensor_id MetaTensorId = MetaTensorId next_storage_id MetaStorageId = MetaStorageId Tensor - int lookup_tensor = WeakIdKeyDictionary Storage - int lookup_storage = WeakIdKeyDictionary copy_data = copy_data traced_tensors set int = set traced_storages set int = set get_tensor_id t torch Tensor - MetaTensorId t lookup_tensor lookup_tensor t = next_tensor_id next_tensor_id = MetaTensorId next_tensor_id + lookup_tensor t get_storage_id s torch UntypedStorage - MetaStorageId s lookup_storage lookup_storage s = next_storage_id next_storage_id = MetaStorageId next_storage_id + lookup_storage s describe_storage s torch UntypedStorage trace bool = False - MetaStorageDesc r = MetaStorageDesc id=self get_storage_id s size=s size NB We don t do copy yet copy happens when we start creating new storages data=s copy_data None trace r id traced_storages trace_structured describe_storage metadata_fn=lambda r as_json id traced_storages add r id r describe_tensor t torch Tensor recurse bool = True trace bool = False - MetaTensorDesc is_leaf = safe_is_leaf t is_view = t _is_view is_sparse = t is_sparse layout = t layout is_nested = t is_nested is_traceable_wrapper_subclass_v = is_traceable_wrapper_subclass t is_functorch_wrapped = is_functorch_wrapped_tensor t is_mkldnn = t is_mkldnn is_batchedtensor_v = is_batchedtensor t is_legacy_batchedtensor_v = is_legacy_batchedtensor t is_gradtrackingtensor_v = is_gradtrackingtensor t is_functional = torch _is_functional_tensor t storage = None NB For compatibility I default zero sometimes people still have stuffed zero into storage offset even though tensor doesn t meaningfully have offset storage_offset = is_sparse is_sparse_compressed_layout layout is_nested is_traceable_wrapper_subclass_v is_mkldnn TODO TBH functorch wrapped tensors probably should have storage associated them is_functorch_wrapped is_legacy_batchedtensor_v NB We actually don t use storage do views might well put accuracy storage = describe_storage t untyped_storage trace=trace storage_offset = t storage_offset type ignore assignment stride = None is_sparse is_sparse_compressed_layout layout is_nested is_traceable_wrapper_subclass_v stride storage_offset called is_functorch_wrapped view_from_base empty_create_subclass sym_sizes_strides_storage_offset empty_create stride = t stride NB technically should refer functorch unwrapped tensor I am perhaps abusively using store both functorch non-functorch functional tensor unwrapped = None autograd_meta_from = None current_level = None is_batchedtensor_v is_gradtrackingtensor_v unwrapped = describe_tensor get_unwrapped t trace=trace xla lazy tensors present functional tensors we want them handled specially is_functional t device type xla lazy t _is_view raise RuntimeError Cannot safely fakify view because process drops view information right now is_functorch_wrapped torch _sync t unwrapped = describe_tensor torch _from_functional_tensor t trace=trace autograd_meta_from = t reapply_views = torch _C _functionalization_reapply_views_tls NB has side effects unwrapped = describe_tensor _unwrap_functional_tensor t reapply_views trace=trace TODO It s pretty suspicious functional tensors don t have valid level thus we just grab whatever current level current_level = torch _C _functorch current_level maybe_functorch_stack = None is_functorch_wrapped torch _functorch pyfunctorch temporarily_clear_interpreter_stack maybe_functorch_stack pass attrs = None ctx = None type_v = None is_traceable_wrapper_subclass_v assert hasattr t __tensor_flatten__ raw_attrs ctx = t __tensor_flatten__ attrs = attr describe_tensor getattr t attr trace=trace attr raw_attrs type_v = type t torch nested _internal nested_tensor _tensor_symint_registry view_func = ViewFunc from_tensor t TODO Is important enable torch inference_mode before querying these values is_inference_mode_disabled = getattr tls disable_inference_mode False r MetaTensorDesc = MetaTensorDesc id=self get_tensor_id t storage=storage is_inference=False is_inference_mode_disabled t is_inference is_leaf=is_leaf requires_grad=t requires_grad NB ndim should OK too there disaster python test dynamo test_subclasses py -k test_user_overridden_property_unsupported Actually means we have little bit problem here which there some sensitivity how exactly access done you have __torch_function__ subclass Maybe should disable torch function before doing accesses ndim=t dim dtype=t dtype is_sparse=is_sparse is_mkldnn=is_mkldnn is_functorch_wrapped=is_functorch_wrapped is_batchedtensor=is_batchedtensor_v is_legacy_batchedtensor=is_legacy_batchedtensor_v is_gradtrackingtensor=is_gradtrackingtensor_v is_view=is_view is_conj=t is_conj is_neg=t is_neg is_parameter=isinstance t torch nn Parameter is_traceable_wrapper_subclass=is_traceable_wrapper_subclass_v is_nested=is_nested nested_int= _tensor_symint_registry t node nested_int t _tensor_symint_registry None is_functional=is_functional layout=layout device=t device size=t size stride=stride pyrefly ignore bad-argument-type storage_offset=storage_offset dynamo_dynamic_indices=list getattr t _dynamo_dynamic_indices set dynamo_hint_overrides=getattr t _dynamo_hint_overrides sparse_dim= t sparse_dim t is_sparse is_sparse_compressed t None dense_dim=t dense_dim t is_sparse is_sparse_compressed t None is_coalesced=t is_coalesced t is_sparse None TODO I actually think recursing here correct we have least infinite cycle base - values - base https github com pytorch pytorch issues crow_indices= describe_tensor t crow_indices recurse=False trace=trace recurse t layout torch sparse_csr torch sparse_bsr None col_indices= describe_tensor t col_indices recurse=False trace=trace recurse t layout torch sparse_csr torch sparse_bsr None ccol_indices= describe_tensor t ccol_indices recurse=False trace=trace recurse t layout torch sparse_csc torch sparse_bsc None row_indices= describe_tensor t row_indices recurse=False trace=trace recurse t layout torch sparse_csc torch sparse_bsc None values= describe_tensor t values recurse=False trace=trace recurse is_sparse_compressed t None grad= describe_tensor grad trace=trace grad = safe_grad t None None creation_meta= torch _C _autograd _get_creation_meta t t _is_view None unwrapped=unwrapped level= maybe_get_level t is_batchedtensor_v is_gradtrackingtensor_v None bdim=maybe_get_bdim t is_batchedtensor_v None base= describe_tensor t _base trace=trace recurse t _is_view t _base None None fake_mode=torch _subclasses fake_tensor maybe_get_fake_mode t view_func=view_func attrs=attrs ctx=ctx type=type_v NB even functorch enabled don t actually save interpreter stack here unless we actually functorch wrapped s irrelevant non-functorch stuff functorch_stack=maybe_functorch_stack autograd_meta_from=autograd_meta_from current_level=current_level data=t copy_data None trace r id traced_tensors trace_structured describe_tensor metadata_fn=lambda r as_json id traced_tensors add r id r dataclass frozen=True MetaStorageDesc id MetaStorageId size int NB only populated copy_data True directly serializable JSON you want do something special here anyway data Optional torch UntypedStorage as_json describer_id _DescriberId - dict str object id id describer_id describer_id size size isinstance size int repr size dataclass frozen=True ViewFunc Generic _TensorT abstractmethod apply t _TensorT new_base _TensorT symint_visitor_fn Optional Callable int int = None tensor_visitor_fn Optional Callable torch Tensor _TensorT = None - _TensorT staticmethod from_tensor t torch Tensor - ViewFunc _is_fake_tensor t _FakeTensorViewFunc _CustomViewFunc t _view_func_unsafe dataclass frozen=True _FakeTensorViewFunc ViewFunc FakeTensor override apply t torch Tensor new_base torch Tensor symint_visitor_fn Optional Callable int int = None tensor_visitor_fn Optional Callable torch Tensor FakeTensor = None - FakeTensor torch _subclasses fake_tensor FakeTensor _view_func_unsafe pyrefly ignore bad-argument-type t new_base symint_visitor_fn tensor_visitor_fn dataclass frozen=True _CustomViewFunc ViewFunc _TensorT Generic _TensorT func Callable torch Tensor Optional Callable int int Optional Callable torch Tensor _TensorT _TensorT override apply t torch Tensor new_base torch Tensor symint_visitor_fn Optional Callable int int = None tensor_visitor_fn Optional Callable torch Tensor _TensorT = None - _TensorT ignore ` t ` func new_base symint_visitor_fn tensor_visitor_fn A callback where device either optional required All these satisfy protocol mk arg Callable torch Tensor device Union torch device str mk arg Callable torch Tensor device Union torch device str = meta mk arg Callable torch Tensor device Optional Union torch device str = None _MetaTensorCallback Protocol Generic _TensorT_cov __call__ arg Callable torch Tensor device Union torch device str - _TensorT_cov _MetaTensorCallbackKwargs TypedDict total=False device Union torch device str A callback where device may provided optional All these satisfy protocol mk arg Callable torch Tensor device Union torch device str = meta mk arg Callable torch Tensor device Optional Union torch device str = None _MetaTensorCallbackOptDevice Protocol Generic _TensorT_cov __call__ arg Callable torch Tensor kwargs Unpack _MetaTensorCallbackKwargs - _TensorT_cov dataclass frozen=True MetaTensorDesc Generic _TensorT id MetaTensorId ndim int dtype torch dtype device torch device NB Sometimes size stride storage_offset contain SymInt which case NOT serializable That only happens when you re re-fakeifying fake tensor existing ShapeEnv maybe we can get rid use case entirely Notably even we fakeifying real tensor into fake tensor symbolic shapes size here NOT dynamic NB These also contain SymInt because wrap_meta_outputs_with_default_device_logic goes through codepath But really should LOL NB size could potentially None you can override make throw error we don t currently have any subclasses do except C++ nested tensor we re going have nested int make defined NJT size tuple int dynamo_dynamic_indices list int dynamo_hint_overrides dict int int layout torch layout = torch strided is_inference bool = False is_leaf bool = False requires_grad bool = False is_sparse bool = False is_mkldnn bool = False is_functorch_wrapped bool = False is_batchedtensor bool = False is_legacy_batchedtensor bool = False is_gradtrackingtensor bool = False is_view bool = False is_nested bool = False We eagerly symbolicize associated nested int e g offsets lengths metadata offsets already associated nested int See test_construct_from_jagged_with_input_offsets_mixed_case nested_int Optional int = None is_traceable_wrapper_subclass bool = False is_functional bool = False is_conj bool = False is_neg bool = False is_parameter bool = False stride Optional tuple int = None storage_offset int = NB We have choice whether store id direct pointer data structure For ease use we store data structure means when we serialize we have swizzle these pointers back into ids so we have accurate aliasing relationships storage Optional MetaStorageDesc = None sparse_dim Optional int = None is_sparse is_sparse_compressed dense_dim Optional int = None is_sparse is_sparse_compressed is_coalesced Optional bool = None is_sparse crow_indices Optional MetaTensorDesc = None is_sparse_compressed col_indices Optional MetaTensorDesc = None is_sparse_compressed ccol_indices Optional MetaTensorDesc = None is_sparse_compressed row_indices Optional MetaTensorDesc = None is_sparse_compressed values Optional MetaTensorDesc = None is_sparse_compressed unwrapped Optional MetaTensorDesc = None is_functorch_wrapped bdim Optional int = None is_functorch_wrapped base Optional MetaTensorDesc = None is_view attrs Optional dict str MetaTensorDesc = None is_traceable_wrapper_subclass creation_meta Optional CreationMeta = None grad Optional MetaTensorDesc = None Everything below NOT serializable need some more work _UNSERIALIZABLE ClassVar set str = ctx type fake_mode view_func isn t serializable when s _CustomViewFunc view_func level current_level functorch_stack autograd_meta_from data nested_int ctx Optional object = None is_traceable_wrapper_subclass type Optional type = None is_traceable_wrapper_subclass fake_mode Optional FakeTensorMode = None view_func Optional ViewFunc = None level looks serializable actually meaningless without functorch_stack below level Optional int = None is_functorch_wrapped current_level Optional int = None functorch_stack Optional list CInterpreter = None autograd_meta_from Optional torch Tensor = None This only populated copy_data typically used all except some our meta-ification paths don t properly use storage pro-tip you should use storage data Optional torch Tensor = None Faithfully serializing functorch tensors will too difficult We only need consider grad vmap interpreters their internal state only bools mostly what grad enabled disabled state should lower layer Beyond tensors just need precisely indicate which particular interpreter they correspond we then replace level pointer interpreter stack However use functorch very non-lexical so s entirely clear how make all lexical again so we haven t done now NB This will reference numeric IDs assumed you ve already serialized everything recursively references as_json describer_id _DescriberId - dict str object json k str v object - object Some best-effort debugging serialization unserializable fields feel free add other special cases appropriate k data autograd_meta_from None never repr these k MetaTensorDesc _UNSERIALIZABLE repr v isinstance v torch device torch dtype torch layout repr v isinstance v torch SymInt repr v isinstance v tuple list json k v v v isinstance v MetaStorageDesc MetaTensorDesc v id isinstance v CreationMeta str v k == attrs isinstance v dict k v id k v v items v r = field name json field name getattr field name field dataclasses fields getattr field name field default field name == dynamo_dynamic_indices getattr field name r update describer_id describer_id r property shape - tuple int size A more faithful reproduction would do copy entire storage needs done carefully because underlying storage could have larger extent than implied size stride The real fix properly call meta_storage recursively here These safe functions intended used under no_dispatch mode The no_dispatch here intended prevent ambient fake tensor mode fakeifying operation But we given honest goodness FakeTensor src we MUST NOT run copy clone operation A better way do would use no_dispatch instead just disable fake tensor mode only allowing subclass dispatch occur _safe_copy dst torch Tensor src Optional torch Tensor - None type src torch Tensor dst copy_ src _safe_clone src torch Tensor - Optional torch Tensor type src torch Tensor None src clone This converting multiple tensors into meta tensors which share same view storage structure The operation model you allocate one these then call repeatedly all tensors you want convert It s important use same object tensors you want share storage because how we correlate shared storages same meta storages This will hold weak references cached tenosrs tensor storages MetaConverter Generic _TensorT __init__ copy_data bool = False - None Maps MetaStorageId UntypedStorage storage_memo weakref WeakValueDictionary MetaStorageId torch UntypedStorage = weakref WeakValueDictionary Maps MetaTensorId torch Tensor typically meta tensor FakeTensor tensor_memo weakref WeakValueDictionary MetaTensorId _TensorT = weakref WeakValueDictionary hit = miss = del_hook = None arg_cnt = Ensures real_storage real_tensor populated resulting metaified storage tensor The naming attribute load bearing FakeTensor relies real tensor being set exactly value copy_data = copy_data describer = MetaTensorDescriber copy_data=copy_data successful - bool hit miss == get_tensor_memo t MetaTensorDesc - Optional torch Tensor tensor_memo get t id None _checked_get_tensor_memo t MetaTensorDesc - _TensorT r = tensor_memo get t id None assert r None r set_tensor_memo t MetaTensorDesc v _TensorT - None tensor_memo t id = v get_storage_memo s MetaStorageDesc - Optional torch UntypedStorage storage_memo get s id None set_storage_memo s MetaStorageDesc v torch UntypedStorage - None storage_memo s id = v meta_storage s MetaStorageDesc callback Callable Callable torch Tensor _TensorT - torch UntypedStorage If we fakeifying tensor has secretly-zero-sized storage Need make sure resize meta storage too memo = get_storage_memo s None r_s = callback lambda torch empty s size dtype=torch uint device= meta untyped_storage copy_data NB no_dispatch needed because internally storage copy implemented Tensor operations torch no_grad no_dispatch assert s data None _set_real_storage r_s s data clone set_storage_memo s r_s r_s memo classmethod _checked_cast_tensor_t cls t torch Tensor - _TensorT TODO how check _TensorT typing cast _TensorT t classmethod _identity_callable cls t Callable torch Tensor device Optional Union torch device str = None - _TensorT cls _checked_cast_tensor_t t classmethod _backward_error cls t _TensorT - _TensorT errfn = torch _C _functions DelayedError Internal error Tried backward through example input err = errfn t typing cast _TensorT err This function assumes s possible do conversion NB name here used conventional way Dynamo corresponds precisely Source name tensor we re fakeifying corresponds valid Python expression When we construct sub-names part process we will maintain invariant Even though other users may need property upheld meta_tensor t MetaTensorDesc shape_env Optional ShapeEnv callback_ _MetaTensorCallback _TensorT source Optional Source symbolic_context Optional SymbolicContext - _TensorT callback _MetaTensorCallbackOptDevice = functools partial callback_ device=t device source None torch _dynamo source ConstantSource TODO make dedicated UnknownSource source = ConstantSource f __meta_utils_unknown_tensor len tensor_memo msg = This indicates you set no_dispatch before calling into function This error we may creating fake tensors will perform operations them which need fake tensor mode active You will segfault you no_dispatch block assert torch _C _dispatch_tls_local_exclude_set has torch _C DispatchKey Python msg arg_cnt += When we make as_strided calls we end up generating guard new as_strided tensor bounds old storage base since as_strided calls can bust out their bounding box This guard unnecessary user able provide us tensor view base setup way we don t need produce guard because fact they able produce view base means its bounds Now ordinarily guard would harmless However generated guard refers variables bound base variable At moment Dynamo doesn t actually guard x _base because according Voz results lot spurious invalidations also user doesn t directly make use _base its pointless anyway because programs should parametric over whether input tensor view -- unless you re mutating input s whole nother ballgame So expediency we suppress these guards so we don t have deal yet anyway NB An old version code suppressed guards ALL operations happening during meta conversion just as_strided calls This too aggressive we do duck sizing simplification we allocate variables we do need register guards these cases maybe_suppress Callable Any = contextlib nullcontext shape_env None maybe_suppress = shape_env suppress_guards sym_sizes_strides_storage_offset t MetaTensorDesc src torch _guards Source symbolic_context Optional torch fx experimental symbolic_shapes SymbolicContext = symbolic_context - tuple tuple int tuple int int assert t stride None shape_env None fake_mode = t fake_mode fake_mode None fake_mode shape_env shape_env Don t reallocate sizes shape envs same so reuse old sizes strides etc t size t stride t storage_offset TODO deduplicate t_size = tuple shape_env _maybe_specialize_sym_int_with_hint sz sz t size t_stride = tuple shape_env _maybe_specialize_sym_int_with_hint sd sd t stride t_storage_offset = shape_env _maybe_specialize_sym_int_with_hint t storage_offset shape_env _create_symbolic_sizes_strides_storage_offset t_size t_stride t_storage_offset d t dynamo_dynamic_indices d range t ndim src symbolic_context=symbolic_context hint_overrides=t dynamo_hint_overrides t size t stride t storage_offset empty_create inner_t MetaTensorDesc inner_src torch _guards Source symbolic_context Optional torch fx experimental symbolic_shapes SymbolicContext = symbolic_context - torch Tensor inner_sizes inner_strides _inner_storage_offset = sym_sizes_strides_storage_offset inner_t inner_src symbolic_context torch empty_strided inner_sizes inner_strides dtype=inner_t dtype device= meta Creates subclass instance empty inner tensors according specified symbolic context empty_create_subclass t MetaTensorDesc outer_size tuple int outer_stride tuple int symbolic_context Optional torch fx experimental symbolic_shapes SymbolicContext = symbolic_context source Optional torch _guards Source = source - _TensorT torch _dynamo source AttrSource torch fx experimental symbolic_shapes SubclassSymbolicContext assert t attrs None assert t type None NB t ctx could None subclass question has no meaningful context Note transform_subclass will use __tensor_unflatten__ generate fresh subclass wrapper outer sizes strides according outer symbolic context passed function Inner size stride storage offset symbols allocated according appropriate inner symbolic contexts after which checks transform_subclass will relate them outer metadata possible Morally code here same transform_subclass we ve written scratch read EmptyCreateSubclass outer_size = outer_size outer_size None t size pyrefly ignore bad-assignment outer_stride = outer_stride outer_stride None t stride assert symbolic_context None isinstance symbolic_context SubclassSymbolicContext _empty_create_subclass t MetaTensorDesc outer_size Optional tuple int outer_stride Optional tuple int symbolic_context Optional torch fx experimental symbolic_shapes SymbolicContext callback _MetaTensorCallbackOptDevice _TensorT source torch _guards Source - _TensorT We hitting plain meta_desc tensor so actually create tensor here t attrs None meta_tensor t shape_env callback source symbolic_context inner_tensors = attr meta_tensor_desc t attrs items current_context = None symbolic_context None assert isinstance symbolic_context SubclassSymbolicContext current_context_ = symbolic_context inner_contexts attr None current_context = _checked_cast torch fx experimental symbolic_shapes SymbolicContext current_context_ current_source = AttrSource source attr inner_callback = functools partial callback device=meta_tensor_desc device new_empty_tensor = _empty_create_subclass meta_tensor_desc meta_tensor_desc size meta_tensor_desc stride current_context inner_callback current_source inner_tensors attr = new_empty_tensor assert t type None t type __tensor_unflatten__ type ignore attr-defined inner_tensors t ctx outer_size outer_stride assert source None sub = _empty_create_subclass t outer_size outer_stride symbolic_context callback source NB Purposefully guard here simplify inner outer symbols Using sym_eq symbolic comparison can result expression s too difficult guard so we use == here assert sub shape == outer_size f Expected value t type __tensor_unflatten__ have f shape equal outer_size got sub shape assert sub stride == outer_stride f Expected value t type __tensor_unflatten__ have f stride equal outer_stride got sub stride sub Returns all-dynamic symbolic context used metafying given tensor fully dynamic dims This useful when fake-ifying intermediate tensors closed-over ViewFunc state we don t have symbolic contexts them we don t want over-specialize during view replay all_dynamic_symbolic_context t MetaTensorDesc source torch _guards Source shape_env Optional torch fx experimental symbolic_shapes ShapeEnv callback _MetaTensorCallback _TensorT - torch fx experimental symbolic_shapes SymbolicContext torch _dynamo source AttrSource torch fx experimental symbolic_shapes DimDynamic StatelessSymbolicContext SubclassSymbolicContext view_base_context Optional torch fx experimental symbolic_shapes SymbolicContext = None t is_view assert t base None view_base_context = all_dynamic_symbolic_context t base AttrSource source _base shape_env callback t_symbolic_context torch fx experimental symbolic_shapes SymbolicContext t_dynamic_sizes = DimDynamic DYNAMIC t ndim t is_traceable_wrapper_subclass assert t attrs None inner_contexts dict str torch fx experimental symbolic_shapes SymbolicContext = attr inner t attrs items assert isinstance attr str inner_contexts attr = all_dynamic_symbolic_context inner AttrSource source attr shape_env callback t_symbolic_context = SubclassSymbolicContext dynamic_sizes=t_dynamic_sizes constraint_sizes= None t ndim inner_contexts=inner_contexts type ignore arg-type tensor_source=source view_base_context=view_base_context t_symbolic_context = StatelessSymbolicContext dynamic_sizes=t_dynamic_sizes constraint_sizes= None t ndim view_base_context=view_base_context t_symbolic_context Returns fake-ified version input view tensor t given already fake-ified base At high level we want two things fake_t should have same view relationship given fake base input t has its _base fake_t should have symbolic sizes strides storage offset according appropriate symbolic context i e automatic dynamic algorithm We currently take different strategies across view types For dense - dense views accomplish both simultaneously via as_strided call fake-ified base passing symbolic metadata For views involving subclasses perform view replay using view funcs achieve It s necessary swap out any closed-over state view funcs symbolicized SymInts fake-ified tensors Doing avoids specialization thus over-eager simplification symbols could occur during view replay fake-ified base Examples t unsqueeze - dense t dense - dense view It can modeled as_strided call fake base passing symbolic metadata sub select dim= index= subclass - subclass view The index arg made symbolic avoid invalid specialization view replay then done reconstruct view _nested_from_jagged values offsets dense - subclass view returns subclass instance dense values tensor The offsets tensor closed over view func can considered view metadata First offsets tensor fake-ified according inner symbolic context correct relationship outer size stride metadata Then view replay done swapping fake offsets so view replay output fully fake no invalid specialization view_from_base base _TensorT t MetaTensorDesc shape_env Optional torch fx experimental symbolic_shapes ShapeEnv = shape_env - _TensorT enable_python_dispatcher fake-ify t s metadata according outer symbolic context sizes strides storage_offset = sym_sizes_strides_storage_offset t source t is_traceable_wrapper_subclass is_traceable_wrapper_subclass base Dense - Dense view case uses as_strided construct view relationship TODO Change logic use view replay consistency It s likely there no view func available maybe_suppress _checked_cast_tensor_t base as_strided sizes strides storage_offset torch _dynamo source EphemeralSource torch fx experimental symbolic_shapes StatelessSymbolicContext sym_eq symint_visitor_fn s int - int nonlocal symbolic_context torch fx experimental symbolic_shapes DimDynamic all_static_sizes = symbolic_context None isinstance symbolic_context StatelessSymbolicContext all x DimDynamic STATIC x symbolic_context dynamic_sizes Can t just rely shape env being None - dynamo always initializes all_static_sizes shape_env None s NB The symbol here expected simplified out because we priori allocate inner outer symbols according appropriate symbolic contexts prefer those over symbol during symbol simplification via usage EphemeralSource below This -shouldn t- happen symbol somehow leaks out beyond view tensor s shape metadata our assumption being simplified out will fail may guarded which will hard error sym_source = EphemeralSource symint_visitor_fn symbol = shape_env create_symbol s sym_source positive=None shape_env create_symintnode symbol hint=s source=sym_source real_to_fake_mapping = t is_traceable_wrapper_subclass assert t attrs None NB t ctx could None subclass question has no meaningful context assert t type None Fake-ify t naively here only done so we can get fake-ified inner tensors correct relationships outer sizes strides use view replay It s done beforehand here because s easy do when visiting tensors one-by-one during view replay Example Consider Dense - NJT view NJT has values offsets components we want view values offsets closed over As offsets component needed describe output view s important s fakeified correctly fake_t _TensorT = empty_create_subclass t outer_size=sizes outer_stride=strides attrs _ = fake_t __tensor_flatten__ type ignore attr-defined attr attrs real_to_fake_mapping t attrs attr id = getattr fake_t attr tensor_visitor_fn visited_t torch Tensor These arguments never passed we just use them close over these relevant values shape_env Optional torch fx experimental symbolic_shapes ShapeEnv = shape_env callback _MetaTensorCallbackOptDevice _TensorT = callback - torch Tensor It s possible close over undefined tensor e g NJT s lengths visited_t None pyrefly ignore bad-return None NB visited_t being Tensor here very naughty Should have already been described Fake inner tensors view subclasses will come mapping built above visited_id = describer get_tensor_id visited_t fake_visited_t = real_to_fake_mapping get visited_id fake_visited_t None fake_visited_t visited_desc = describer describe_tensor visited_t For other closed-over tensor state fake-ify all dynamic ephemeral source This avoids invalid specialization during view replay If we find practice usage ephemeral sources isn t enough guarantee we don t have guards these symbols we may need explicitly suppress guards done _base dense - dense view case temp_source = EphemeralSource tensor_visitor_fn meta_tensor visited_desc shape_env callback temp_source all_dynamic_symbolic_context visited_desc temp_source shape_env callback Replay view swapping out any non-symbolic SymInts real tensors symbolic SymInts fake tensors assert t view_func None NB we do NOT suppress guards here we need remove ephemeral sources fake_t = t view_func apply t base symint_visitor_fn tensor_visitor_fn Ensure output has symbolic shapes according outer symbolic context These checks should simplify out any symbols created closed-over view func SymInts torch _check sym_eq fake_t size sizes torch _check sym_eq fake_t stride strides torch _check sym_eq fake_t storage_offset storage_offset fake_t get_tensor_memo t None GRAD_TENSOR_SENTINEL_VALUE = - torch inference_mode t is_inference t is_sparse is_leaf = t is_leaf The lambda function below similar ` t device= meta ` except latter preserves nnz value r = callback lambda torch ops aten _sparse_coo_tensor_with_dims t sparse_dim t dense_dim t size dtype=t dtype layout=torch sparse_coo device= meta copy_data Pray sparse clone doesn t lose information assert t data None torch no_grad no_dispatch assert _is_fake_tensor r r real_tensor = _safe_clone t data assert safe_is_leaf r callback you passed doesn t detach Note is_coalesced dispatched Strangely enough is_coalesced dispatched operator which means will get caught fake tensor mode Ordinarily would error there s some logic fake tensor ensure doesn t happen r _coalesced_ bool t is_coalesced t requires_grad r requires_grad = True t requires_grad is_leaf This should probably use DelayedError clone fine now sparse tensors DelayedError does work sparse because causes Fake sparse tensor lose its fakeness r = _checked_cast_tensor_t r clone torch enable_grad r _coalesced_ bool t is_coalesced is_sparse_compressed_layout t layout is_leaf = t is_leaf t layout torch sparse_bsr torch sparse_bsc assert t sparse_dim None assert t dense_dim None assert t values None batch_dim = t ndim - t sparse_dim - t dense_dim blocksize = t values shape batch_dim + batch_dim + blocksize = t layout torch sparse_csr torch sparse_bsr assert t crow_indices None index_dtype = t crow_indices dtype assert t ccol_indices None index_dtype = t ccol_indices dtype r = callback lambda torch ops aten _sparse_compressed_tensor_with_dims t dense_dim t shape blocksize index_dtype layout=t layout dtype=t dtype device= meta copy_data Pray sparse clone doesn t lose information assert t data None torch no_grad no_dispatch assert _is_fake_tensor r r real_tensor = _safe_clone t data assert safe_is_leaf r callback you passed doesn t detach t requires_grad r requires_grad = True t requires_grad is_leaf pyrefly ignore bad-argument-type r = _backward_error r t is_nested t is_traceable_wrapper_subclass TODO Handle better Dynamo There checks there now can still triggered dense tensor graph input view strided NT torch _dynamo exc unimplemented unimplemented strided nested tensors supported meta conversion t is_mkldnn is_leaf = t is_leaf sizes strides _storage_offset = sym_sizes_strides_storage_offset t source TODO This doesn t seem right where s MKLDNN ness lol r = callback lambda torch empty_strided sizes strides dtype=t dtype device= meta copy_data torch no_grad no_dispatch assert t size None assert t stride None assert _is_fake_tensor r r real_tensor = torch empty_strided t size t stride dtype=t dtype device=t device assert t data None _safe_copy r real_tensor t data assert safe_is_leaf r callback you passed doesn t detach t requires_grad r requires_grad = True t requires_grad is_leaf pyrefly ignore bad-argument-type r = _backward_error r t is_functorch_wrapped t is_view torch _dynamo exc unimplemented unimplemented view functorch tensors supported meta conversion Wraps functorch tensor BatchedTensor GradTrackingTensor FakeTensor _to_fake_tensor t MetaTensorDesc - _TensorT TODO why aren t recursive calls going meta_tensor r _TensorT t is_batchedtensor assert t unwrapped None assert t level None assert t bdim None ft = _to_fake_tensor t unwrapped lvl = t level bdim = t bdim You cannot create functorch tensors without having ambient funtorch interpreter stack available level refers things stack torch _functorch pyfunctorch temporarily_restore_interpreter_stack t functorch_stack r = _checked_cast_tensor_t _add_batch_dim ft bdim lvl t is_gradtrackingtensor assert t unwrapped None assert t level None disable_functorch = torch _C _DisableFuncTorch disable_functorch ft = _to_fake_tensor t unwrapped lvl = t level lvl == GRAD_TENSOR_SENTINEL_VALUE r = ft torch _functorch pyfunctorch temporarily_restore_interpreter_stack t functorch_stack r = _checked_cast_tensor_t torch _C _functorch _wrap_for_grad ft lvl is_leaf = t is_leaf t requires_grad safe_is_leaf r r requires_grad = True t requires_grad is_leaf r = _backward_error r t is_functional assert t unwrapped None assert t current_level None ft = meta_tensor t unwrapped shape_env callback NB reuse these exactly we treat functional tensor invisible TODO Actually all probably doesn t work take closer look source symbolic_context r = _checked_cast_tensor_t _wrap_functional_tensor ft t current_level TODO is_leaf requires_grad assert t stride None sizes = t size strides = t stride r = callback lambda torch empty_strided sizes strides dtype=t dtype device= meta device= meta copy_data torch no_grad no_dispatch r real_tensor = torch empty_strided type ignore attr-defined t size t stride dtype=t dtype device=t device assert t data None _safe_copy r real_tensor t data type ignore attr-defined pyrefly ignore bad-return r r = _to_fake_tensor t t is_functional t device type xla lazy assert t unwrapped None assert t is_functorch_wrapped handled above unwrapped = meta_tensor t unwrapped shape_env callback source symbolic_context r = _checked_cast_tensor_t torch _to_functional_tensor unwrapped torch _mirror_autograd_meta_to t autograd_meta_from r type ignore attr-defined t is_view Construct views two steps recursively meta-fy their base then create view s off NB doing directly storage WRONG because won t cause version counters get shared assert t base None base_symbolic_context = None shape_env symbolic_context None torch fx experimental symbolic_shapes StatelessSymbolicContext assert isinstance symbolic_context StatelessSymbolicContext NB This should generally set when input view exception right now fake-ifying grads which work progress symbolic_context view_base_context None base_symbolic_context = symbolic_context view_base_context base = meta_tensor t base shape_env callback torch _dynamo source AttrSource source _base base_symbolic_context is_c_of_r complex_dtype torch dtype real_dtype torch dtype - bool utils is_complex_dtype complex_dtype utils corresponding_real_dtype complex_dtype == real_dtype In some situations MetaConverter may called context where autograd disabled For _is_view assert pass we have setup autograd view metadata anyway Do reenabling ADInplaceOrView key This kind hack old_exclude = torch _C _dispatch_tls_is_dispatch_key_excluded torch _C DispatchKey ADInplaceOrView torch _C _dispatch_tls_set_dispatch_key_excluded torch _C DispatchKey ADInplaceOrView False try base dtype == t dtype pass is_c_of_r base dtype t dtype base = _checked_cast_tensor_t torch view_as_real base is_c_of_r t dtype base dtype base = _checked_cast_tensor_t torch view_as_complex base This guaranteed succeed If fails means there another dtype-converting view function hasn t been handled here base = _checked_cast_tensor_t base view t dtype This very tricky Naively you might expect hold t requires_grad safe_is_leaf t assert t _base requires_grad But s true As you can see following program x = torch zeros y = x view y requires_grad = True z = y view assert z _base x So we may have do two views out base recreate situation t is_leaf Leaf views track view metadata created creating view inside no_grad block torch no_grad r = view_from_base base t As s leaf we can directly assign requires_grad r requires_grad = t requires_grad t base requires_grad == t requires_grad Easy case just run view op torch enable_grad r = view_from_base base t NB We don t actually faithfully replicate autograd connectivity doesn t matter today See following more info https gist github com soulitzer e f b c f fcf c Obscure case Create leaf view give correct requires_grad then do final view NB Can t have non-leaf without requiring grad assert t requires_grad torch no_grad enable_python_dispatcher mid = _checked_cast_tensor_t base view base shape mid requires_grad = t requires_grad torch enable_grad r = view_from_base mid t The CreationMeta influences whether inplace mutation error So we need make sure we properly propagate well assert t creation_meta None torch _C _autograd _set_creation_meta r t creation_meta finally torch _C _dispatch_tls_set_dispatch_key_excluded torch _C DispatchKey ADInplaceOrView old_exclude r fake_device = t device type ignore attr-defined is_leaf = t is_leaf Graph-Break wrapped tensors t is_batchedtensor t is_gradtrackingtensor t is_functorch_wrapped t is_legacy_batchedtensor pyrefly ignore bad-return NotImplemented sizes strides storage_offset = sym_sizes_strides_storage_offset t source symbolic_context If we have subclass desugars into dense tensors perform our callback each inner tensor t is_traceable_wrapper_subclass r = empty_create_subclass t outer_size=sizes outer_stride=strides r = callback lambda torch empty_strided sizes strides dtype=t dtype device= meta copy_data torch no_grad no_dispatch assert t size None assert t stride None assert _is_fake_tensor r r real_tensor = torch empty_strided t size t stride dtype=t dtype device=t device _safe_copy r real_tensor t data assert safe_is_leaf r callback you passed doesn t detach t requires_grad r requires_grad = t requires_grad is_leaf Fake up some autograd history Note we used call clone here mock up some autograd history This bad subclasses Consider case where you have wrapper subclass contiguous its inner tensor noncontiguous clone other ops will have side effect changing metadata inner tensor So instead we now have dedicated fn set autograd history without inadvertently changing other metadata pyrefly ignore bad-argument-type r = _backward_error r s = t storage assert s None s id storage_memo r is_nested r stride == strides r storage_offset == storage_offset You re normal happy install fresh storage into memo set_storage_memo s r untyped_storage copy_data assert _is_fake_tensor r assert r real_tensor None _set_real_storage r untyped_storage r real_tensor untyped_storage You re crazy town somehow you gave us tensor wasn t view had nonzero storage offset nontrivial strides such clone couldn t preserve them already aliases another tensor s storage The most typical way end up here set_ So use set_ bludgeon r_s = meta_storage s callback=callback NB In principle should always work there some subtle difference autograd metadata means we will backprop set_ call even r declared input grad See https github com pytorch pytorch issues reproducer NB The in_kernel_invocation_manager here necessary fake tensor If we run set_ call fake tensor r will improperly report NOT meta tensor cpu tensor then set_ call will fail due device mismatch no_dispatch enough because fake tensor will still claim CPU tensor you ll end up CPU kernel Arguably hack cleaner way solve have FakeStorage concept which would report s CPU device -- no problem now But difficult do because we don t have storage subclasses Relevant test DynamicShapesFunctionTests test_add_dynamic_shapes test dynamo test_dynamic_shapes py maybe_fake_mgr AbstractContextManager None = contextlib nullcontext torch _subclasses fake_tensor in_kernel_invocation_manager maybe_get_fake_mode mb_fake_mode = maybe_get_fake_mode r mb_fake_mode None maybe_fake_mgr = in_kernel_invocation_manager mb_fake_mode torch no_grad maybe_suppress maybe_fake_mgr r set_ r_s storage_offset sizes strides copy_data torch no_grad no_dispatch assert _is_fake_tensor r assert r real_tensor None assert t stride None r real_tensor set_ _get_real_storage r_s t storage_offset t size t stride t grad None torch _dynamo source AttrSource TODO Use valid grad-specific symbolic context instead recycling one t This isn t correct e g t _is_view = t grad _is_view pyrefly ignore unbound-name r grad = meta_tensor t grad shape_env callback AttrSource source grad symbolic_context pyrefly ignore unbound-name torch _C _set_conj r t is_conj pyrefly ignore unbound-name torch _C _set_neg r t is_neg This can skipped necessary performance reasons skip_leaf = t is_gradtrackingtensor t level == GRAD_TENSOR_SENTINEL_VALUE pyrefly ignore unbound-name assert_metadata_eq assert_eq t r skip_symbolic=True skip_leaf=skip_leaf Thanks storage resizing s possible end up tensor advertises real size has storage actually has zero bytes Need reflect generated FakeTensor torch fx experimental symbolic_shapes guard_or_false t storage None guard_or_false t storage size == pyrefly ignore unbound-name r untyped_storage resize_ t is_parameter pyrefly ignore unbound-name r _is_param = True See Note Creating symbolic nested int t nested_int None pyrefly ignore unbound-name assert _is_fake_tensor r pyrefly ignore unbound-name r nested_int_memo = r fake_mode create_symbolic_nested_int nt_tensor_id=t nested_int pyrefly ignore bad-argument-type unbound-name set_tensor_memo t r _checked_get_tensor_memo t __call__ t torch Tensor shape_env Optional ShapeEnv = None callback Optional _MetaTensorCallback _TensorT = None source Optional Source = None symbolic_context Optional SymbolicContext = None Controls whether we should dump tensor metadata structured logs when source None Because we refakify after Dynamo done we don t want dump info again AOTAutograd redundant trace bool = True - _TensorT callback_ _MetaTensorCallback _TensorT callback None callback_ = _identity_callable callback_ = callback TODO zero tensors We appear have eliminated them excluding complex now Filter out cases we don t support TODO This can probably simplified quite bit isinstance t torch Tensor Lazy tensors supported Note XLA implemented top lazy tensor excluded here we have some special handling XLA Dynamo integration t device type == lazy Quantization supported t is_quantized Views out sparse tensors currently supported plain sparse supported htough t _is_view t _base None t _base is_sparse miss += pyrefly ignore bad-return NotImplemented hit += torch overrides is_tensor_like t miss += pyrefly ignore bad-return NotImplemented non-Tensor types don t count hit miss t source None trace = False Describe tensor NB do NOT disable ambient modes we may need query them when figuring out what put here t_desc = describer describe_tensor t trace=trace trace assert source None trace_structured describe_source metadata_fn=lambda describer_id describer id id t_desc id source source name Do meta-fication Here we disable all ambient modes better simulate what would like re-fakeify fresh process contextlib ExitStack exit_stack exit_stack enter_context torch _dispatch python suspend_functionalization st = peek_interpreter_stack st None exit_stack enter_context torch _functorch pyfunctorch temporarily_clear_interpreter_stack r = meta_tensor t_desc shape_env callback_ source symbolic_context type t torch nn Parameter NB Cannot directly use Parameter constructor because would force detach desirable r _is_param = True TODO description later r torch _prims_common utils