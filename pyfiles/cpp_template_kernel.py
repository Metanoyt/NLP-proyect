mypy allow-untyped-defs itertools collections abc Iterable typing Any Callable Optional Union unittest mock patch sympy sympy parsing sympy_parser parse_expr torch torch _inductor utils do_bench_using_profiling torch utils _ordered_set OrderedSet torch utils _sympy symbol SymT config cpp_builder ir lowering L autotune_process CppBenchmarkRequest loop_body LoopBody select_algorithm PartialRender utils sympy_index_symbol sympy_index_symbol_with_prefix virtualized V common REMOVED cpp CppKernel CppKernelProxy KernelGroup ParallelDepth cpp_utils cexpr_index DTYPE_TO_CPP LocalBufferContext parse_expr_with_index_symbols expr isinstance expr sympy Expr expr isinstance expr list tuple parse_expr_with_index_symbols e e expr expr = parse_expr str expr int_symbols = sym sympy_index_symbol sym name sym expr free_symbols expr subs int_symbols wrap_with_tensorbox node - Union ir TensorBox ir ShapeAsConstantBuffer ir TensorBox create node isinstance node ir Buffer ir TensorBox node CppTemplateKernel CppKernel __init__ kernel_name num_threads super __init__ None num_threads kernel_name = kernel_name render_hooks = local_buffers = render template kwargs PartialRender template render kernel=self kwargs render_hooks finalize_all def_kernel inputs dict str ir Buffer outputs dict str ir Buffer aliases Optional dict str str = None function_name str = extra_sizevars Optional list sympy Expr = None placeholder str = DEF_KERNEL - str len function_name == function_name = str kernel_name name inp inputs items inp None args input_buffers inp get_name = name name out outputs items args output_buffers out get_name = name aliases None alias orig aliases items orig args input_buffers args input_buffers alias = args input_buffers orig orig args output_buffers args output_buffers alias = args output_buffers orig unique_sizevars = OrderedSet s input inputs values input None sym itertools chain input get_size input get_stride isinstance sym sympy Expr s sym free_symbols unique_sizevars update s sym extra_sizevars isinstance sym sympy Expr s sym free_symbols unique_sizevars update s output outputs values sym itertools chain output get_size output get_stride isinstance sym sympy Expr s sym free_symbols sizevars = sorted unique_sizevars key=str sizevar sizevars args sizevars sizevar = f k sizevar hook remove all aliases before generate function definition aliases None alias aliases alias args input_buffers raise AssertionError f input_buffers cannot removed alias alias args output_buffers args output_buffers alias = REMOVED cpp_argdefs _ _ = args cpp_argdefs f void function_name join cpp_argdefs assert placeholder render_hooks render_hooks placeholder = hook placeholder call_kernel name str node ir CppTemplateBuffer wrapper = V graph wrapper_code _ call_args arg_types = args cpp_argdefs wrapper generate_kernel_call name call_args triton=False arg_types=arg_types dtype node ir Buffer - str DTYPE_TO_CPP node get_dtype acc_dtype node ir Buffer - str node get_dtype torch float torch bfloat torch half float raise NotImplementedError f Unsupported dtype node get_dtype size node ir Buffer dim int - str cexpr_index rename_indexing node get_size dim stride node ir Buffer dim int - str cexpr_index rename_indexing node get_stride dim index node ir Buffer indices list Any - str indexer = node get_layout as_fixed make_indexer index = indexer parse_expr_with_index_symbols indices index = rename_indexing index outer_name = node get_name inner_name = outer_name outer_name local_buffers args input node get_name f inner_name cexpr_index index slice_nd node ranges list tuple Any Any - ir ReinterpretView Slice given node list ranges start end corresponding its dims The dim sliced corresponding range empty assert len ranges == len node get_size f ranges= node= sliced = wrap_with_tensorbox node dim _range enumerate ranges len _range == continue assert len _range == start end = parse_expr_with_index_symbols _range sliced = L slice_ sliced dim start end clamp=False assert isinstance sliced ir TensorBox assert isinstance sliced data ir ReinterpretView sliced data sliced data select node dim int idx int - ir ReinterpretView We avoid using L select here because we need clamp=False so dim after slicing instead sympy expression symbol - dim_size node = wrap_with_tensorbox node idx = ir View handle_negative_index idx node get_size dim sliced = L squeeze L slice_ node dim idx idx + clamp=False dim assert isinstance sliced data ir ReinterpretView sliced data sliced data view node sizes list Any - ir IRNode node = wrap_with_tensorbox node sizes = parse_expr_with_index_symbols sizes L view node sizes data type ignore arg-type permute node dims node = wrap_with_tensorbox node permuted = L permute node dims data assert isinstance permuted ir ReinterpretView permuted maybe_codegen_profile - str config cpp enable_kernel_profile graph_id = V graph graph_id prefix = graph_ + str graph_id + _ graph_id None handle_str = torch aot_inductor RAIIAtenRecordFunctionHandle f record_ prefix kernel_name _ prefix kernel_name nullptr handle_str unroll_pragma unroll cpp_builder is_gcc f #pragma GCC unroll unroll f #pragma unroll unroll define_buffer name sizes list Any dtype=torch float - str Define kernel local buffer sizes = parse_expr_with_index_symbols sizes buf = ir Buffer name=name layout=ir FixedLayout torch device cpu dtype sizes local_buffers name = buf ctype = f DTYPE_TO_CPP dtype numel = f cexpr_index buf get_numel f auto _ name = std make_unique ctype numel auto name = _ name get define_stack_allocated_buffer name sizes list Any dtype=torch float - str Define stack-allocated buffer sizes = parse_expr_with_index_symbols sizes buf = ir Buffer name=name layout=ir FixedLayout torch device cpu dtype sizes local_buffers name = buf ctype = f DTYPE_TO_CPP dtype numel = f cexpr_index buf get_numel f alignas ctype _ name numel ctype name = _ name reinit_buffer_if_null name Reinit previously defined local buffer null assert name local_buffers buf = local_buffers name ctype = f DTYPE_TO_CPP buf layout dtype numel = f cexpr_index buf get_numel f _ name == nullptr _ name = std make_unique ctype numel name = _ name get release_buffer name Codegen code release ownership local buffer others assert name local_buffers f _ name release store_pointwise_nodes dst ir Buffer nodes list ir IRNode offsets Optional list sympy Expr = None reindexers Optional list Optional Callable list Any list Any = None - str var_sizes = tuple dst get_size var_ranges = sympy_index_symbol_with_prefix SymT INDEX i sz i sz enumerate var_sizes offsets offsets = sympy S Zero len var_sizes reindexers reindexers = None len nodes assert len offsets == len var_sizes output_index = dst get_layout make_indexer var_ranges keys kernel_group = KernelGroup kernel_group args = args cpp_kernel_proxy = CppKernelProxy kernel_group bodies = var_sizes_list = i node enumerate nodes output_name = node get_name i len nodes - dst get_name node = node data isinstance node ir ComputedBuffer node assert isinstance node ir Pointwise node fn args assert len args == assert len args == len var_sizes assert len args == new_args = arg + offset arg offset zip args offsets type ignore arg-type reindexers i None new_args = reindexers i new_args type ignore misc V ops store output_name output_index node make_loader new_args value body = LoopBody fn list var_ranges keys var_ranges list var_ranges keys tuple bodies append body var_sizes_list append var_sizes cpp_kernel_proxy codegen_loop_bodies bodies var_sizes_list max_parallel_depth ParallelDepth parallel_depth= start_depth= This loop parallelized since outermost loop patch object cpp_kernel_proxy loop_nest max_parallel_depth max_parallel_depth kernel_group finalize_kernel cpp_kernel_proxy kernel_group loops_code getvalue store_grouped_gemm_pointwise_nodes dst tuple ir Buffer nodes list ir IRNode offsets list sympy Expr reindexers list Optional Callable list Any list Any output_names list str - str ref_dst = dst var_sizes = tuple ref_dst get_size var_ranges = sympy_index_symbol_with_prefix SymT INDEX i sz i sz enumerate var_sizes assert offsets offsets should set outside assert all len offset == len var_sizes offset offsets output_index = ref_dst get_layout make_indexer var_ranges keys kernel_group = KernelGroup kernel_group args = args cpp_kernel_proxy = CppKernelProxy kernel_group bodies = var_sizes_list = i node enumerate nodes output_name = output_names i node = node data isinstance node ir ComputedBuffer node assert isinstance node ir Pointwise node fn args assert len args == assert len args == len var_sizes assert len args == new_args = arg + offset arg offset zip args offsets i type ignore arg-type reindexers i None new_args = reindexers i new_args type ignore misc V ops store output_name output_index node make_loader new_args value body = LoopBody fn list var_ranges keys var_ranges list var_ranges keys tuple bodies append body var_sizes_list append var_sizes cpp_kernel_proxy codegen_loop_bodies bodies var_sizes_list max_parallel_depth ParallelDepth parallel_depth= start_depth= This loop parallelized since outermost loop patch object cpp_kernel_proxy loop_nest max_parallel_depth max_parallel_depth kernel_group finalize_kernel cpp_kernel_proxy kernel_group loops_code getvalue store_output dst ir Buffer src ir Buffer orig_src Optional ir Buffer = None epilogue_nodes Optional list ir IRNode = None offsets Optional list Any = None reindexers Optional list Optional Callable list Any list Any = None Store ` src ` buffer ` dst ` buffer The size ` src ` ` dst ` should match If ` epilogue_nodes ` provided ` src ` buffer firstly computed epilogues before stored ` dst ` The ` epilogues_nodes ` all pointwise Notes ` src ` ` dst ` buffer could same buffer which case we doing in-place compute stores In case ` epilogue_nodes ` provided we do nothing The ` epilogue_nodes ` exist have computations ` src ` before storing ` dst ` since they come form original Inductor IR they might need adjusted before working ` src ` ` dst ` outlined below ` src ` ` dst ` buffer could sub-slice ranges ` epilogue_nodes ` work In case ` offsets ` could provided adjust indices passed ` epilogue_nodes ` during codegen data ranges also configured according sizes ` src ` ` dst ` b ` dst ` might indexed different way ` epilogue_nodes ` hence ` reindexer ` needed indices ` epilogue_nodes ` match indexing ` dst ` c If ` src ` local we need add local buffer localize ` orig_src ` buffer ` epilogue_nodes ` ` src ` assert isinstance dst ir Buffer ir ReinterpretView assert dst get_size == src get_size f dst= src= offsets offsets = parse_expr_with_index_symbols offsets epilogue_nodes LocalBufferContext args scope assert orig_src None orig_src get_name = src get_name scope add_local_buffer src orig_src epilogue_nodes = scope localize_nodes epilogue_nodes store_pointwise_nodes pyrefly ignore bad-argument-type dst epilogue_nodes type ignore arg-type offsets reindexers dst get_name = src get_name src local copy = L copy dst src data data LocalBufferContext args scope scope add_local_buffer src pyrefly ignore bad-argument-type store_pointwise_nodes dst copy assert dst layout == src layout f dst= src= store_outputs dst tuple ir Buffer src tuple ir IRNode orig_src Optional tuple ir IRNode = None epilogue_nodes Optional list ir IRNode = None offsets Optional list Any = None reindexers Optional list Optional Callable list Any list Any = None multi_output_buffers Optional tuple ir MultiOutput = None assert isinstance dst Iterable assert all _dst get_size == _src get_size _src _dst zip src dst offsets offsets = parse_expr_with_index_symbols offsets gemm_num = len src final_offsets = output_names = epilogue_nodes reindexers reindexers = None len epilogue_nodes LocalBufferContext args scope assert orig_src None localize_epilogue_nodes = all_read_names = epilogue epilogue_nodes all_read_names extend list epilogue get_read_names localize_epilogue_nodes extend scope localize_nodes epilogue_nodes final_offsets extend offsets len localize_epilogue_nodes output_names extend node get_name node localize_epilogue_nodes gemm_idx range gemm_num orig_src gemm_idx get_name = src gemm_idx get_name orig_src gemm_idx get_name all_read_names multi_output_buffers multi_output_buffers gemm_idx get_name all_read_names If any Epilogue nodes use GEMM output let s localize GEMM output global_buffers = orig_src gemm_idx multi_output_buffers multi_output_buffers gemm_idx get_name all_read_names orig_src gemm_idx get_name all_read_names Epilogue might directly read MultiOutput Locallize MultiOutput local Buffer MultiOutput has been stored in-template epilogue otherwise use cse store cache will stored before used global_buffers append multi_output_buffers gemm_idx scope add_local_buffer src gemm_idx global_buffers scope add_local_buffer src gemm_idx localize_epilogue_nodes extend L copy dst gemm_idx src gemm_idx data data reindexers append None output_names append dst gemm_idx get_name final_offsets append sympy S Zero len dst gemm_idx get_size res = store_grouped_gemm_pointwise_nodes dst localize_epilogue_nodes final_offsets reindexers output_names=output_names gemm_idx range gemm_num multi_output_buffers multi_output_buffers gemm_idx get_name all_read_names If MultiOutput used Epilogue let s remove args multi_output_name = multi_output_buffers gemm_idx get_name multi_output_name args output_buffers args output_buffers multi_output_name REMOVED remove_buffer multi_output_name res dst get_name = src get_name copy_list = LocalBufferContext args scope _src _dst zip src dst copy_list extend L copy _dst _src data data scope add_local_buffer _src output_names append _dst get_name final_offsets append sympy S Zero len _dst get_size reindexers = None len copy_list store_grouped_gemm_pointwise_nodes dst nodes=copy_list offsets=final_offsets reindexers=reindexers output_names=output_names assert all _src get_name == _dst get_name _src _dst zip src dst assert all _src get_layout == _dst get_layout _src _dst zip src dst check_bounds expr size lower upper CppTemplateKernel does need codegen related operations CppTemplateCaller ir ChoiceCaller CppTemplateCaller This represents caller CPP template kernels It subclass ir ChoiceCaller Attributes name str The name caller category str The category caller bmreq CppBenchmarkRequest The benchmark request caller template_buffer ir CppTemplateBuffer The template buffer caller __init__ name str category str input_nodes list ir Buffer layout ir Layout make_kernel_render Callable ir CppTemplateBuffer bool Optional list ir IRNode str bmreq CppBenchmarkRequest template CppTemplate type ignore name-defined noqa F info_kwargs Optional dict str Union ir PrimitiveInfoType list ir PrimitiveInfoType = None super __init__ name input_nodes layout description= category = category make_kernel_render = make_kernel_render bmreq = bmreq template = template info_kwargs = info_kwargs precompile - None assert bmreq None bmreq precompile benchmark args out - float assert bmreq None config profile_bandwidth_with_do_bench_using_profiling algo = bmreq make_run_fn args out=out do_bench_using_profiling algo bmreq benchmark args out=out hash_key - str - join category bmreq hash_key info_dict - dict str Union ir PrimitiveInfoType list ir PrimitiveInfoType backend CPP op_type unknown output_node - Union ir TensorBox ir ShapeAsConstantBuffer ir TensorBox create ir CppTemplateBuffer layout=self layout inputs=self input_nodes make_kernel_render=self make_kernel_render template=self template choice=self