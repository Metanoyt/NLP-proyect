Owner s module dynamo torch torch _dynamo test_case torch fx traceback fx_traceback torch utils checkpoint torch _dynamo test_case run_tests torch _dynamo testing AotEagerAndRecordGraphs torch nn attention flex_attention create_block_mask flex_attention torch testing _internal triton_utils requires_cuda_and_triton checkpoint_wrapper fn inner args torch utils checkpoint checkpoint fn args use_reentrant=True inner AnnotateTests torch _dynamo test_case TestCase test_annotations Mod torch nn Module forward x fx_traceback annotate pp_stage fx_traceback annotate fdsp_bucket sin = torch sin x sub = sin - fx_traceback annotate cuda_stream fsdp_bucket mul = sub div = mul div m = Mod backend = AotEagerAndRecordGraphs opt_m = torch compile m backend=backend fullgraph=True x = torch randn requires_grad=True opt_m x sum backward assertEqual len backend fw_graphs assertEqual len backend bw_graphs dynamo_metadata = fx_traceback _get_custom_metadata backend graphs fw_metadata = fx_traceback _get_custom_metadata backend fw_graphs bw_metadata = fx_traceback _get_custom_metadata backend bw_graphs assertExpectedInline str dynamo_metadata \ placeholder l_x_ pp_stage fdsp_bucket call_function sin pp_stage fdsp_bucket call_function sub pp_stage call_function mul pp_stage cuda_stream fsdp_bucket noqa B assertExpectedInline str fw_metadata \ call_function sin pp_stage fdsp_bucket call_function sub pp_stage call_function mul pp_stage cuda_stream fsdp_bucket noqa B assertExpectedInline str bw_metadata \ call_function mul_ pp_stage cuda_stream fsdp_bucket call_function cos pp_stage fdsp_bucket call_function mul_ pp_stage fdsp_bucket noqa B test_activation_checkpointing checkpoint_wrapper gn x torch sin x fn x fx_traceback annotate ac_sin ac = gn x torch sigmoid ac backend = AotEagerAndRecordGraphs opt_fn = torch compile fn backend=backend fullgraph=True x = torch randn requires_grad=True opt_fn x sum backward assertEqual len backend fw_graphs assertEqual len backend bw_graphs dynamo_metadata = fx_traceback _get_custom_metadata backend graphs fw_metadata = fx_traceback _get_custom_metadata backend fw_graphs bw_metadata = fx_traceback _get_custom_metadata backend bw_graphs assertExpectedInline str dynamo_metadata \ placeholder l_x_ ac_sin get_attr wrap_body_ ac_sin placeholder l_x_ ac_sin call_function sin ac_sin output output ac_sin call_function tag_activation_checkpoint ac_sin call_function ac ac_sin noqa B assertExpectedInline str fw_metadata call_function sin ac_sin noqa B assertExpectedInline str bw_metadata \ call_function cos ac_sin call_function mul ac_sin noqa B test_activation_checkpointing_annotation_inside checkpoint_wrapper gn x x = x + fx_traceback annotate stage p = torch sin x p + fn x ac = gn x torch sigmoid ac backend = AotEagerAndRecordGraphs opt_fn = torch compile fn backend=backend fullgraph=True x = torch randn requires_grad=True opt_fn x sum backward assertEqual len backend fw_graphs assertEqual len backend bw_graphs dynamo_metadata = fx_traceback _get_custom_metadata backend graphs fw_metadata = fx_traceback _get_custom_metadata backend fw_graphs bw_metadata = fx_traceback _get_custom_metadata backend bw_graphs assertExpectedInline str dynamo_metadata call_function p stage noqa B assertExpectedInline str fw_metadata call_function sin stage noqa B assertExpectedInline str bw_metadata \ call_function cos stage call_function mul stage noqa B requires_cuda_and_triton test_ac_flex_attention _squared score b h m n score score mask_mod b h q k q = = b = block_mask = create_block_mask mask_mod None None b b gn x torch Tensor fx_traceback annotate compile_inductor flex_attention x x x block_mask=block_mask score_mod=_squared fn x x = torch sin x x = gn x torch cos x x = torch randn b b dtype=torch bfloat device= cuda requires_grad=True backend = AotEagerAndRecordGraphs opt_fn = torch compile fn backend=backend fullgraph=True opt_fn x sum backward assertEqual len backend fw_graphs assertEqual len backend bw_graphs dynamo_metadata = fx_traceback _get_custom_metadata backend graphs fw_metadata = fx_traceback _get_custom_metadata backend fw_graphs bw_metadata = fx_traceback _get_custom_metadata backend bw_graphs assertExpectedInline str dynamo_metadata \ placeholder l_gn_closure_ _cell_contents_kv_indices compile_inductor placeholder l_gn_closure_ _cell_contents_kv_num_blocks compile_inductor placeholder l_gn_closure_ _cell_contents_full_kv_num_blocks compile_inductor placeholder l_gn_closure_ _cell_contents_full_kv_indices compile_inductor placeholder l_gn_closure_ _cell_contents_q_num_blocks compile_inductor placeholder l_gn_closure_ _cell_contents_q_indices compile_inductor placeholder l_gn_closure_ _cell_contents_full_q_num_blocks compile_inductor placeholder l_gn_closure_ _cell_contents_full_q_indices compile_inductor get_attr score_mod_ compile_inductor placeholder child compile_inductor placeholder child_ compile_inductor placeholder child_ compile_inductor placeholder child_ compile_inductor placeholder child_ compile_inductor call_function mul compile_inductor output output compile_inductor get_attr mask_fn_ compile_inductor placeholder child compile_inductor placeholder child_ compile_inductor placeholder child_ compile_inductor placeholder child_ compile_inductor call_function ge compile_inductor output output compile_inductor call_function flex_attention compile_inductor call_function out compile_inductor noqa B assertExpectedInline str fw_metadata \ get_attr sdpa_score compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor call_function mul compile_inductor output output compile_inductor get_attr sdpa_mask compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor call_function ge compile_inductor output output compile_inductor call_function flex_attention compile_inductor call_function getitem compile_inductor call_function getitem_ compile_inductor call_function detach_ compile_inductor call_function detach_ compile_inductor noqa B assertExpectedInline str bw_metadata \ placeholder getitem compile_inductor placeholder detach_ compile_inductor call_function zeros compile_inductor call_function detach compile_inductor call_function detach_ compile_inductor get_attr fw_graph compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor call_function mul compile_inductor output output compile_inductor get_attr joint_graph compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor call_function mul_ compile_inductor call_function mul_ compile_inductor call_function add compile_inductor output output compile_inductor get_attr mask_graph compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor placeholder arg _ compile_inductor call_function ge compile_inductor output output compile_inductor call_function flex_attention_backward compile_inductor call_function getitem_ compile_inductor call_function getitem_ compile_inductor call_function getitem_ compile_inductor noqa B test_as_decorator Mod torch nn Module fx_traceback annotate fdsp_bucket sin x torch sin x forward x fx_traceback annotate pp_stage sin = sin x sub = sin - mul = sub div = mul div m = Mod backend = AotEagerAndRecordGraphs opt_m = torch compile m backend=backend fullgraph=True x = torch randn requires_grad=True m x opt_m x sum backward assertEqual len backend fw_graphs assertEqual len backend bw_graphs dynamo_metadata = fx_traceback _get_custom_metadata backend graphs fw_metadata = fx_traceback _get_custom_metadata backend fw_graphs bw_metadata = fx_traceback _get_custom_metadata backend bw_graphs assertExpectedInline str dynamo_metadata \ placeholder l_x_ pp_stage fdsp_bucket call_function sin pp_stage fdsp_bucket call_function sub pp_stage call_function mul pp_stage noqa B assertExpectedInline str fw_metadata \ call_function sin pp_stage fdsp_bucket call_function sub pp_stage call_function mul pp_stage noqa B assertExpectedInline str bw_metadata \ call_function mul_ pp_stage call_function cos pp_stage fdsp_bucket call_function mul_ pp_stage fdsp_bucket noqa B test_graph_break fn x torch fx traceback annotate pp_stage x = torch sin x torch _dynamo graph_break x = torch cos x x opt_fn = torch compile fn backend= eager x = torch randn requires_grad=True assertEqual fn x opt_fn x __name__ == __main__ run_tests