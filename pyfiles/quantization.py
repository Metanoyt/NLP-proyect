mypy allow-untyped-decorators mypy allow-untyped-defs copy functools itertools math operator typing Any torch torch _dynamo utils counters torch fx experimental symbolic_shapes has_free_symbols torch fx node map_arg config lowering lowerings L require_channels_last pattern_matcher Arg CallFunction filter_nodes KeywordArg ListOf Match stable_topological_sort utils pad_listlike freezing_patterns register_freezing_graph_pattern post_grad register_lowering_pattern aten = torch ops aten prims = torch ops prims quantized_decomposed = torch ops quantized_decomposed quantized = torch ops quantized Only per tensor quant since permute may changes channel idx _PER_TENSOR_QUANTIZE_OPS = quantized_decomposed quantize_per_tensor default quantized_decomposed quantize_per_tensor tensor _VIEW_OPS = aten transpose int aten permute default aten view default aten reshape default The quantization py file primarily incorporates passes related quantization fusion inductor includes Dequant Promotion Conv GEMM weight prepack oneDNN Library Conv GEMM quantization fusion output quant node have Other pointwise operators quantization fusion like qmaxpool d qcat more It also involves int -mixed-fp int -mixed-bf quantization The main difference patterns int -mixed-bf comparing int -mixed-fp There dtype=torch bfloat node inputs activation weight Conv GEMM There dtype=torch float node outputs Conv GEMM before inputs next quant node Refer https github com pytorch pytorch issues detail design int -mixed-bf quantization _get_pattern_output_dtype match Match Get pattern s output dtype node s meta Assume only output node matched pattern pattern_output_nodes = match output_nodes assert len pattern_output_nodes == output_node = pattern_output_nodes assert isinstance output_node torch fx Node output_dtype = output_node meta val dtype assert output_dtype torch int torch uint torch float torch bfloat torch float _e m fn output_dtype _may_generate_pattern_with_dtype_convert pattern dtype=Arg with_dtype_convert=True users= with_dtype_convert CallFunction prims convert_element_type default pattern dtype _users=users pattern _may_generate_pattern_with_reshape pattern reshape_size=Arg with_reshape=True with_reshape CallFunction torch ops aten reshape default pattern reshape_size pattern _generate_linear_t_pattern _dequant_per_channel_pattern dtype assert dtype torch float torch bfloat t_pattern = CallFunction aten permute default _may_generate_pattern_with_dtype_convert _dequant_per_channel_pattern KeywordArg autocast_wgt_dtype dtype == torch bfloat KeywordArg permute_axes t_pattern _unary_fusion_pattern unary_fusion call_fn users is_bf only insert to_dtype is_bf True computation_call = _may_generate_pattern_with_dtype_convert call_fn dtype=KeywordArg to_float with_dtype_convert=is_bf users=users unary_fusion computation_call get_dequantize_per_tensor_activation_pattern is_tensor_overload=False dequantize_per_tensor_activation_pattern = CallFunction quantized_decomposed dequantize_per_tensor tensor is_tensor_overload quantized_decomposed dequantize_per_tensor default KeywordArg x KeywordArg x_scale KeywordArg x_zp KeywordArg x_quant_min KeywordArg x_quant_max KeywordArg x_dq_dtype dequantize_per_tensor_activation_pattern dequantize_per_channel_weight_pattern = CallFunction quantized_decomposed dequantize_per_channel default KeywordArg q_weight KeywordArg w_scale KeywordArg w_zp KeywordArg w_axis KeywordArg w_quant_min KeywordArg w_quant_max KeywordArg w_dtype dequantize_per_channel_to_bf _weight_pattern = _may_generate_pattern_with_dtype_convert dequantize_per_channel_weight_pattern KeywordArg autocast_wgt_dtype dequantize_per_channel_clone_weight_pattern = CallFunction aten clone default dequantize_per_channel_weight_pattern memory_format=KeywordArg memory_format dequantize_per_channel_to_bf _clone_weight_pattern = CallFunction aten clone default dequantize_per_channel_to_bf _weight_pattern memory_format=KeywordArg memory_format get_qconv_pt e_pattern users= CallFunction torch ops onednn qconv_pointwise default KeywordArg x KeywordArg x_scale KeywordArg x_zp KeywordArg packed_weight KeywordArg w_scale KeywordArg w_zp KeywordArg b KeywordArg stride KeywordArg padding KeywordArg dilation KeywordArg groups KeywordArg output_scale KeywordArg output_zero_point KeywordArg output_dtype KeywordArg postop_name KeywordArg postop_args KeywordArg postop_algorithm _users=users get_qconv d_binary_pt e_pattern users= CallFunction torch ops onednn qconv d_pointwise binary KeywordArg x KeywordArg x_scale KeywordArg x_zp KeywordArg packed_weight KeywordArg w_scale KeywordArg w_zp KeywordArg accum KeywordArg b KeywordArg stride KeywordArg padding KeywordArg dilation KeywordArg groups KeywordArg output_scale KeywordArg output_zero_point KeywordArg output_dtype KeywordArg accum_scale KeywordArg accum_zero_point KeywordArg binary_op_name KeywordArg alpha KeywordArg unary_op_name KeywordArg unary_op_args KeywordArg unary_op_algorithm _users=users get_qlinear_pt e_pattern x_scale_zp_are_tensors users= qlinear_op = torch ops onednn qlinear_pointwise tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise default CallFunction qlinear_op KeywordArg x KeywordArg x_scale KeywordArg x_zp KeywordArg packed_weight KeywordArg w_scale KeywordArg w_zp KeywordArg b KeywordArg output_scale KeywordArg output_zero_point KeywordArg output_dtype KeywordArg postop_name KeywordArg postop_args KeywordArg postop_algorithm _users=users get_qlinear_binary_pt e_pattern x_scale_zp_are_tensors users= qlinear_op = torch ops onednn qlinear_pointwise binary_tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise binary CallFunction qlinear_op KeywordArg x KeywordArg x_scale KeywordArg x_zp KeywordArg packed_weight KeywordArg w_scale KeywordArg w_zp KeywordArg x_ KeywordArg b KeywordArg output_scale KeywordArg output_zero_point KeywordArg output_dtype KeywordArg x _scale KeywordArg x _zp KeywordArg binary_op_name KeywordArg alpha KeywordArg unary_op_name KeywordArg unary_op_args KeywordArg unary_op_algorithm _users=users dequantize_accum_pattern = CallFunction quantized_decomposed dequantize_per_tensor default KeywordArg accum KeywordArg accum_scale KeywordArg accum_zp Arg Arg KeywordArg accum_dq_dtype generate_pattern_with_binary binary_post_op computation_call extra_input_pattern dtype_convert=False swap_inputs=False binary_pattern = CallFunction binary_post_op extra_input_pattern computation_call swap_inputs CallFunction binary_post_op computation_call extra_input_pattern _may_generate_pattern_with_dtype_convert binary_pattern KeywordArg convert_dtype_after_inplace_add dtype_convert generate_pattern_with_unary computation_call unary_post_op unary_post_op None CallFunction unary_post_op computation_call computation_call generate_pattern_with_output_quant computation_call with_dtype_convert=False quantized_op_output_pattern_pt e = CallFunction quantized_decomposed quantize_per_tensor default _may_generate_pattern_with_dtype_convert computation_call Arg with_dtype_convert KeywordArg o_inv_scale KeywordArg o_zp KeywordArg o_qmin KeywordArg o_qmax KeywordArg o_dtype quantized_op_output_pattern_pt e _check_node_kwarg_arg_value check_node kwarg_name args_index expected_value kwarg_name check_node kwargs actual_value = check_node kwargs kwarg_name actual_value == expected_value assert len check_node args = args_index + actual_value = check_node args args_index actual_value == expected_value _is_valid_quantized_conv_optimization_pattern fn match output_dtype = _get_pattern_output_dtype match output_dtype torch float torch bfloat Only keep matched pattern same output_dtype qconv_node_after_weight_prepack = filter_nodes match nodes torch ops onednn qconv_pointwise _check_node_kwarg_arg_value qconv_node_after_weight_prepack output_dtype output_dtype True fn _is_valid_qconv_post_op_fusion_pattern has_binary_post_op=False _is_valid_qconv_binary_optimization_pattern has_binary_post_op _is_valid_quantized_conv_optimization_pattern _is_valid_qconv_lowering_pattern fn match len match nodes = False match nodes target torch ops onednn qconv_pointwise default torch ops onednn qconv_pointwise tensor torch ops onednn qconv d_pointwise binary torch ops onednn qconv d_pointwise binary_tensor fn _register_quantized_conv_lowering pattern pass_number computation_op register_lowering_pattern pattern extra_check=_is_valid_qconv_lowering_pattern pass_number=pass_number qconv match Match args kwargs Activation QParams x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp Weight QParams packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp Conv Params b stride padding dilation groups = kwargs b kwargs stride kwargs padding kwargs dilation kwargs groups output_dtype = _get_pattern_output_dtype match assert output_dtype torch int torch uint torch float torch bfloat Output QParams o_inv_scale = kwargs output_scale o_zero_point = kwargs output_zero_point output_dtype = kwargs output_dtype post op postop_name = kwargs postop_name postop_args = kwargs postop_args postop_algorithm = kwargs postop_algorithm computation_args = x x_scale x_zp packed_weight w_scale w_zp b stride padding dilation groups o_inv_scale o_zero_point output_dtype postop_name postop_args postop_algorithm counters inductor qconv_unary_lower_count += counters inductor qconv_unary_lower_nodes += len match nodes L computation_op computation_args qconv _is_valid_quantized_linear_optimization_pattern fn match output_dtype = _get_pattern_output_dtype match output_dtype torch float torch bfloat Only keep matched pattern same output_dtype qlinear_node_after_weight_prepack = filter_nodes match nodes torch ops onednn qlinear_pointwise _check_node_kwarg_arg_value qlinear_node_after_weight_prepack output_dtype output_dtype True fn _is_valid_qlinear_post_op_fusion_pattern has_binary_post_op=False _is_valid_qlinear_binary_optimization_pattern has_binary_post_op _is_valid_quantized_linear_optimization_pattern _is_valid_qlinear_lowering_pattern fn match len match nodes = False match nodes target torch ops onednn qlinear_pointwise default torch ops onednn qlinear_pointwise tensor torch ops onednn qlinear_pointwise binary torch ops onednn qlinear_pointwise binary_tensor fn _register_quantized_linear_unary_lowering pattern pass_number computation_op register_lowering_pattern pattern extra_check=_is_valid_qlinear_lowering_pattern pass_number=pass_number qlinear match Match args kwargs output_dtype = _get_pattern_output_dtype match Activation QParams x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp Weight QParams packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp bias b = kwargs get b Output QParams o_inv_scale = kwargs output_scale o_zero_point = kwargs output_zero_point post op postop_name = kwargs postop_name postop_args = kwargs postop_args postop_algorithm = kwargs postop_algorithm computation_args = x x_scale x_zp packed_weight w_scale w_zp b o_inv_scale o_zero_point output_dtype postop_name postop_args postop_algorithm counters inductor qlinear_unary_lower_count += counters inductor qlinear_unary_lower_nodes += len match nodes L computation_op computation_args qlinear _register_quantized_linear_binary_lowering pattern pass_number computation_op register_lowering_pattern pattern extra_check=_is_valid_qlinear_lowering_pattern pass_number=pass_number qlinear_binary match Match args kwargs output_dtype = _get_pattern_output_dtype match assert output_dtype None Activation QParams x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp x = kwargs x_ x _scale = kwargs x _scale x _zp = kwargs x _zp Weight QParams packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp bias b = kwargs get b Output QParams o_inv_scale = kwargs output_scale o_zero_point = kwargs output_zero_point x realize mkldnn_fusion _can_be_inplace binary_op_name = kwargs binary_op_name alpha = kwargs alpha unary_op_name = kwargs unary_op_name unary_op_args = kwargs unary_op_args unary_op_algorithm = kwargs unary_op_algorithm binary_op_name == sum _can_be_inplace x When we enable GEMM Template output QLinear will reshaped D back D input D This causes _can_be_inplace x False x happens output QLinear scenario Change post op sum binary add case Refer test case test_mkldnn_pattern_matcher py test_qlinear_dequant_promotion_cpu_input_dim_exceeds_ binary_op_name = add computation_args = x x_scale x_zp packed_weight w_scale w_zp x b o_inv_scale o_zero_point output_dtype x _scale x _zp binary_op_name alpha unary_op_name unary_op_args unary_op_algorithm counters inductor qlinear_binary_lower_count += counters inductor qlinear_binary_lower_nodes += len match nodes L computation_op computation_args qlinear_binary _is_valid_qconv_binary_optimization_pattern _is_valid_quantized_op_binary_optimization_pattern torch ops onednn qconv_pointwise _is_valid_qlinear_binary_optimization_pattern _is_valid_quantized_op_binary_optimization_pattern torch ops onednn qlinear_pointwise we don t insert q-dq extra input due accuracy issues extra_input_from_dequant=False _is_valid_quantized_op_binary_optimization_pattern qop extra_input_from_dequant=True Check s valid Binary Pattern qconv d qlinear qop_pointwise should only has one users If extra_input_from_dequant True extra input binary node should come dequant pattern two inputs binary node should have attribute meta should tensors two inputs binary node should have same shape All users extra input pattern should ancestor nodes compute node except binary node connected compute node fn match output_dtype = _get_pattern_output_dtype match compute_node = filter_nodes match nodes qop qop_pointwise should only have one user len compute_node users = False binary_node_inputs = next iter compute_node users args assert len binary_node_inputs == Expects binary node inputs output_dtype torch float torch bfloat extra_input_of_binary_node = None arg binary_node_inputs arg = compute_node extra_input_of_binary_node = arg break assert extra_input_of_binary_node None Extra input binary node comes dequant pattern extra_input_from_dequant isinstance extra_input_of_binary_node torch fx Node extra_input_of_binary_node target = quantized_decomposed dequantize_per_tensor default False two inputs binary node should have attribute meta should tensors hasattr binary_node_inputs meta isinstance binary_node_inputs meta get val None torch Tensor type ignore union-attr hasattr binary_node_inputs meta isinstance binary_node_inputs meta get val None torch Tensor type ignore union-attr False two inputs binary node should have same shape binary_node_inputs meta val size type ignore union-attr = binary_node_inputs meta val size type ignore union-attr False All users extra input pattern should ancestor nodes compute node except binary node connected compute node mkldnn_fusion _get_remaining_users extra_input_of_pattern = match kwargs other other match kwargs match kwargs accum output_dtype torch uint torch int extra_input_from_dequant match kwargs accum_after_dequant len _get_remaining_users extra_input_of_pattern compute_node extra_input_of_pattern == compute_node args False True fn _register_quantized_conv_binary_lowering pattern pass_number computation_op register_lowering_pattern pattern extra_check=_is_valid_qconv_lowering_pattern pass_number=pass_number qconv_binary match Match args kwargs output_dtype = _get_pattern_output_dtype match assert output_dtype None x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp accum = kwargs accum accum_scale = kwargs accum_scale accum_zp = kwargs accum_zero_point packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp b stride padding dilation groups = kwargs b kwargs stride kwargs padding kwargs dilation kwargs groups Output QParams output_scale = kwargs output_scale output_zero_point = kwargs output_zero_point post ops binary_op_name = kwargs binary_op_name alpha = kwargs alpha unary_op_name = kwargs unary_op_name unary_op_args = kwargs unary_op_args unary_op_algorithm = kwargs unary_op_algorithm accum realize mkldnn_fusion _can_be_inplace assert _can_be_inplace accum QConv Binary Inplace Fusion requires accum alias mutation computation_args = x x_scale x_zp packed_weight w_scale w_zp accum b stride padding dilation groups output_scale output_zero_point output_dtype accum_scale accum_zp binary_op_name alpha unary_op_name unary_op_args unary_op_algorithm counters inductor qconv d_binary_lower_count += counters inductor qconv d_binary_lower_nodes += len match nodes L computation_op computation_args qconv_binary _register_quantization_unary_lowering QConv d users qconv_pattern = get_qconv_pt e_pattern users _register_quantized_conv_lowering qconv_pattern pass_number torch ops onednn qconv_pointwise default computation_op QLinear x_scale_zp_are_tensors False True qlinear_pattern = get_qlinear_pt e_pattern x_scale_zp_are_tensors computation_op = torch ops onednn qlinear_pointwise tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise default _register_quantized_linear_unary_lowering qlinear_pattern pass_number computation_op _register_quantization_binary_lowering QConv d users qconv_pattern = get_qconv d_binary_pt e_pattern users _register_quantized_conv_binary_lowering qconv_pattern pass_number torch ops onednn qconv d_pointwise binary computation_op QLinear x_scale_zp_are_tensors False True qlinear_pattern = get_qlinear_binary_pt e_pattern x_scale_zp_are_tensors computation_op = torch ops onednn qlinear_pointwise binary_tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise binary _register_quantized_linear_binary_lowering qlinear_pattern pass_number computation_op _is_valid_quantized_maxpool d_optimization_pattern fn match Only match pattern which max_pool d_with_indices returns value instead indices get_item_node = filter_nodes match nodes operator getitem get_item_node args == fn _register_quantized_maxpool d_lowering pattern computation_op register_lowering_pattern pattern extra_check=_is_valid_quantized_maxpool d_optimization_pattern qmaxpool d match Match args kwargs x = kwargs x kernel_size = kwargs kernel_size stride = kwargs get stride padding = kwargs get padding dilation = kwargs get dilation ceil_mode = kwargs get ceil_mode False padding == padding = dilation == dilation = stride stride = kernel_size kernel_size = pad_listlike kernel_size stride = pad_listlike stride padding = pad_listlike padding dilation = pad_listlike dilation assert len kernel_size == assert len stride == assert len padding == assert len dilation == computation_args = x kernel_size stride padding dilation ceil_mode computation_args _ = require_channels_last computation_op computation_args counters inductor qmaxpool d_matcher_count += counters inductor qmaxpool d_matcher_nodes += len match nodes L computation_op computation_args qmaxpool d _register_quantization_maxpool d Currently default parameters FX Graph generated Dynamo export So user defines nn MaxPool d different assignment default parameter will generate graph different number input nodes hence different pattern matched Refer issue https github com pytorch pytorch issues max_pool d_args_list = KeywordArg stride KeywordArg stride KeywordArg padding KeywordArg stride KeywordArg padding KeywordArg dilation KeywordArg stride KeywordArg padding KeywordArg dilation KeywordArg ceil_mode max_pool d_args max_pool d_args_list dequantize_maxpool d_pattern = CallFunction aten max_pool d_with_indices default get_dequantize_per_tensor_activation_pattern KeywordArg kernel_size max_pool d_args dequantize_lowmem_maxpool d_pattern = CallFunction prims _low_memory_max_pool_with_offsets default get_dequantize_per_tensor_activation_pattern KeywordArg kernel_size max_pool d_args KeywordArg offset_dtype dequantize_maxpool d_get_item_pattern = CallFunction operator getitem dequantize_maxpool d_pattern Arg dequantize_lowmem_maxpool d_get_item_pattern = CallFunction operator getitem dequantize_lowmem_maxpool d_pattern Arg _register_quantized_maxpool d_lowering generate_pattern_with_output_quant dequantize_maxpool d_get_item_pattern quantized max_pool d default _register_quantized_maxpool d_lowering generate_pattern_with_output_quant dequantize_lowmem_maxpool d_get_item_pattern quantized max_pool d default _is_input_output_same_scale_zp check_node fn match Ensure all inputs output has same scale zero point Step Check inputs output zero point Get dequant nodes input dequant_nodes = filter_nodes match nodes quantized_decomposed dequantize_per_tensor default zero_points = node args node dequant_nodes Get quant nodes output quant_nodes = filter_nodes match nodes quantized_decomposed quantize_per_tensor default assert len quant_nodes == expect only add node output quant pattern zero_points append quant_nodes args all zero_point == zero_points zero_point zero_points False Step Check inputs output scale scales = node args node dequant_nodes scales append quant_nodes args all math isclose scale scales rel_tol= e- scale scales type ignore arg-type False True fn _register_quantized_cat_lowering pattern computation_op register_lowering_pattern pattern extra_check=_is_input_output_same_scale_zp aten cat default qcat match Match inputs dim kwargs inputs format x x _dq_dtype x _zp x _scale uint _inputs = input input inputs counters inductor qcat_matcher_count += counters inductor qcat_matcher_nodes += len match nodes L computation_op uint _inputs dim qcat _raw_dequantize_per_tensor_activation_pattern = CallFunction quantized_decomposed dequantize_per_tensor default Arg Arg Arg Arg Arg Arg _register_quantization_cat dequantize_cat_pattern = CallFunction aten cat default ListOf _raw_dequantize_per_tensor_activation_pattern KeywordArg dim _register_quantized_cat_lowering generate_pattern_with_output_quant dequantize_cat_pattern aten cat _register_quantized_reshape_lowering pattern computation_op register_lowering_pattern pattern extra_check=_is_input_output_same_scale_zp aten reshape default qreshape match Match args kwargs qx = kwargs x shape = kwargs shape counters inductor qreshape_matcher_count += counters inductor qreshape_matcher_nodes += len match nodes L computation_op qx shape qreshape _register_quantization_reshape dequantize_reshape_pattern = CallFunction torch ops aten reshape default get_dequantize_per_tensor_activation_pattern KeywordArg shape _register_quantized_reshape_lowering generate_pattern_with_output_quant dequantize_reshape_pattern aten reshape _is_valid_concat_linear_int _woq_optimization_pattern fn match config cpp enable_concat_linear False assert all k match kwargs k x w w w scales all hasattr match kwargs key meta key x w w w scales False x = match kwargs x meta val w = match kwargs w meta val w = match kwargs w meta val w = match kwargs w meta val scales = match kwargs scales meta val len match kwargs scales meta val size False num_scales = match kwargs scales meta val numel w _cols = match kwargs w meta val size w _cols = match kwargs w meta val size w _cols = match kwargs w meta val size For now we only support woq mm kernels x type=bfloat w type=int x dtype == torch bfloat w dtype == torch int w dtype == torch int w dtype == torch int scales dtype == torch bfloat x device type cpu cuda x device == w device w device == w device w device == w device x device == scales device num_scales == w _cols + w _cols + w _cols fn _is_valid_woq_optimization_pattern fn match assert all k match kwargs k x weight scales all hasattr match kwargs key meta key x weight scales False x = match kwargs x meta val weight = match kwargs weight meta val scales = match kwargs scales meta val For now we only support woq mm kernels x type=bfloat w type=int x dtype == torch bfloat weight dtype == torch int scales dtype == torch bfloat x device type cpu cuda x device == weight device x device == scales device fn _register_concat_linear_int _woq_lowering pattern computation_woq computation_reshape register_freezing_graph_pattern pattern extra_check=_is_valid_concat_linear_int _woq_optimization_pattern pass_number= woq_int match Match args kwargs x = kwargs x w = kwargs w w = kwargs w w = kwargs w scales = kwargs scales counters inductor woq_matcher_count += counters inductor woq_matcher_nodes += len match nodes out_features = w meta val size + w meta val size + w meta val size origin_x_size = tuple x meta val size x_shape = - origin_x_size - out_shape = list origin_x_size - + out_features mm_node_of_x = None candidate iter x users keys candidate target aten mm default list candidate _input_nodes target aten cat default mm_node_of_x = candidate break assert mm_node_of_x None unable find mm node _ cat_wgt_node = mm_node_of_x _input_nodes scaling_node = next iter mm_node_of_x users keys user_of_scaling_node = next iter scaling_node users keys Some other pass making some changes entails adding node before s used can only found when lint run stable_topological_sort being run before lint so error being being discovered We call stable_topological_sort here workaround stable_topological_sort match graph match graph inserting_before user_of_scaling_node new_cat_node = match graph call_function aten cat default args= w w w x_reshape_node = match graph call_function computation_reshape args= x x_shape new_woq_node = match graph call_function computation_woq args= x_reshape_node new_cat_node scales new_woq_node meta = copy copy x meta output_reshape_node = match graph call_function computation_reshape args= new_woq_node out_shape scaling_node replace_all_uses_with output_reshape_node match graph erase_node scaling_node match graph erase_node mm_node_of_x match graph erase_node cat_wgt_node match graph lint woq_int _register_woq_lowering pattern computation_woq computation_reshape register_lowering_pattern pattern extra_check=_is_valid_woq_optimization_pattern woq_int match Match args kwargs x = kwargs x weight = kwargs weight scales = kwargs scales counters inductor woq_matcher_count += counters inductor woq_matcher_nodes += len match nodes out_features = weight get_size origin_x_size = x get_size x_shape = - origin_x_size - out_shape = origin_x_size - + out_features func = L computation_reshape x x_shape func = L computation_woq func weight scales L computation_reshape func out_shape woq_int _register_woq_mm_int _pattern F linear x weight dtype=x dtype scales case dispatching mm x reshape _woq_pattern = CallFunction aten mul Tensor CallFunction aten reshape default CallFunction aten mm default CallFunction aten reshape default KeywordArg x Arg CallFunction aten permute default CallFunction prims convert_element_type default KeywordArg weight Arg Arg Arg KeywordArg scales _register_woq_lowering _woq_pattern aten _weight_int pack_mm default aten reshape _register_woq_mm_int _pattern F linear x weight dtype=x dtype scales case dispatching mm w o x reshape _woq_pattern = CallFunction aten mul Tensor CallFunction aten reshape default CallFunction aten mm default KeywordArg x CallFunction aten permute default CallFunction prims convert_element_type default KeywordArg weight Arg Arg Arg KeywordArg scales _register_woq_lowering _woq_pattern aten _weight_int pack_mm default aten reshape _register_woq_mm_int _pattern F linear x weight dtype=x dtype scales case dispatching bmm _woq_pattern = CallFunction aten mul Tensor CallFunction aten bmm default CallFunction aten expand default KeywordArg x Arg CallFunction aten expand default CallFunction aten permute default CallFunction prims convert_element_type default KeywordArg weight Arg Arg Arg KeywordArg scales _register_woq_lowering _woq_pattern aten _weight_int pack_mm default aten reshape _register_woq_mm_int _pattern _woq_pattern = CallFunction aten mul Tensor CallFunction aten mm default KeywordArg x CallFunction prims convert_element_type default CallFunction aten permute default KeywordArg weight Arg Arg KeywordArg scales _register_woq_lowering _woq_pattern aten _weight_int pack_mm default aten reshape _register_int _woq_concat_linear_pattern _create_wgt_node wgt_node_name str CallFunction prims convert_element_type default CallFunction aten permute default KeywordArg wgt_node_name Arg Arg cat_wgt = CallFunction aten cat default _create_wgt_node wgt wgt w w w _woq_pattern = CallFunction aten mul Tensor CallFunction aten mm default KeywordArg x cat_wgt KeywordArg scales _register_concat_linear_int _woq_lowering _woq_pattern aten _weight_int pack_mm default aten reshape _register_quantization_lowerings _register_quantization_unary_lowering _register_quantization_binary_lowering _register_quantization_maxpool d _register_quantization_cat _register_quantization_reshape _register_woq_lowerings _register_woq_mm_int _pattern _register_woq_mm_int _pattern _register_woq_mm_int _pattern _register_woq_mm_int _pattern _is_valid_dequant_promotion_pattern dtype=torch float _inner match assert dtype torch float torch bfloat dequant_pattern_end_node = match output_node dequant_pattern_end_node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor prims convert_element_type default aten reshape default False dequant_pattern_end_node target aten reshape default dequant_node = dequant_pattern_end_node args pattern linear - reshape - dequant dtype == torch float dequant_pattern_end_node args args pattern linear - reshape - to_bf - dequant dequant_node = dequant_pattern_end_node pattern linear - dequant dtype == torch float dequant_pattern_end_node args pattern linear - to_bf - dequant dequant_node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor len list dequant_pattern_end_node users If dequant pattern has more than users then do dequant promoted True False _inner _register_dequant_promotion_pass pattern pass_number dtype=torch float register_freezing_graph_pattern pattern extra_check=_is_valid_dequant_promotion_pattern dtype pass_number=pass_number dequant_promotion match Match args kwargs Dequant_promotion will transform graph quant + - - - &#124; - - - + &#124; dequant &#124; &#124; \ &#124; &#124; node node &#124; + - &#124; - - - &#124; - + quant quant into graph quant + - - - \ - - + &#124; dequant dequant &#124; &#124; &#124; &#124; &#124; &#124; node node &#124; + - &#124; - - - &#124; - + quant quant In graph dequant node shared node node result neither node nor node could form int fusion pattern After transformation graph could hit int fusion pattern dequant-node-quant respectively node node assert dtype torch float torch bfloat clone_to_new_node graph source_node user_node Clone source_node new node Replace user_node s input source_node new_node assert source_node op == call_function clone_to_new_node only support node op call_function graph inserting_before user_node new_node = graph call_function source_node target args=source_node args kwargs=source_node kwargs new_node meta = copy copy source_node meta user_node replace_input_with source_node new_node new_node Find start node end node dequant pattern End node should match output_node Start node should node dequantize_per_tensor dequant_pattern_end_node = match output_node assert dequant_pattern_end_node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor prims convert_element_type default aten reshape default For dequant pattern we should expect see node list OPT aten reshape default OPT prims convert_element_type default to_bf dequantize_per_tensor _find_first_node_in_dequant_pattern _node _node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor For dequant pattern we expect start node dequantize_per_tensor node _node assert len _node args = In dequant pattern each node should have more than arg _find_first_node_in_dequant_pattern _node args dequant_pattern_start_node = _find_first_node_in_dequant_pattern dequant_pattern_end_node assert dequant_pattern_start_node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor Clone dequant pattern each user node graph = match graph user_node_list = list dequant_pattern_end_node users user_node user_node_list _source_node = dequant_pattern_end_node _user_node = user_node while _source_node = dequant_pattern_start_node args _user_node = clone_to_new_node graph _source_node _user_node _source_node = _source_node args type ignore assignment counters inductor dequant_promotion_matcher_count += counters inductor dequant_promotion_matcher_nodes += len match nodes _is_valid_dequant_conv_pattern dtype with_dtype_convert _inner match Here we do some further check ensure It s conv d node dim since we only support lowering conv d now The dequant pattern has only user conv d node If these conditions don t meet we will insert weight prepack node into matched pattern conv_node = match output_node assert conv_node target aten convolution default input_meta_value = conv_node args meta get val weight_meta_value = conv_node args meta get val meta_value input_meta_value weight_meta_value meta_value None meta_value device type = cpu meta_value device type = xpu meta_value dim Only support conv d d now False assert dtype torch float torch bfloat with_dtype_convert dequant_node = conv_node args convert_to_bf = conv_node args dequant_node = convert_to_bf args len list dequant_node users = Ensure dequant pattern only has user since we will delete dequant pattern here False True _inner _register_qconv_weight_prepack_pass pattern pass_number dtype=torch float with_dtype_convert=False register_freezing_graph_pattern pattern extra_check=_is_valid_dequant_conv_pattern dtype with_dtype_convert pass_number=pass_number qconv_weight_prepack match Match args kwargs Match pattern int activation &#124; dequant_per_tensor &#124; Conv d - optional aten clone default - dequant_per_channel - int _weight Insert weight prepack node change pattern int activation &#124; onednn qconv_pointwise - onednn qconv_prepack - int _weight assert dtype torch float torch bfloat conv_node = match output_node assert conv_node target aten convolution default with_dtype_convert dequant_node = conv_node args convert_to_bf = conv_node args dequant_node = convert_to_bf args type ignore union-attr has_clone_to_channel_last_node_in_pattern = conv_node args target aten clone default type ignore union-attr clone_node = conv_node args has_clone_to_channel_last_node_in_pattern None dtype == torch float dequant_per_channel = clone_node args type ignore union-attr has_clone_to_channel_last_node_in_pattern conv_node args weight_to_bf _node = clone_node args type ignore union-attr has_clone_to_channel_last_node_in_pattern conv_node args dequant_per_channel = weight_to_bf _node args type ignore union-attr assert dequant_per_channel target type ignore union-attr quantized_decomposed dequantize_per_channel default Activation QParams qx x_zp x_scale = kwargs x kwargs x_zp kwargs x_scale Weight QParams qw w_scale w_zp = kwargs q_weight kwargs w_scale kwargs w_zp Conv Params bias stride padding dilation groups = kwargs b kwargs stride kwargs padding kwargs dilation kwargs groups x_shape = qx meta get tensor_meta shape has_free_symbols x_shape For dynamic shape case we can t get activation shape ahead runtime x_shape = None graph = match graph graph inserting_before conv_node Insert weight prepack node QConv node packed_weight_inputs = qw w_scale x_scale x_zp stride padding dilation groups x_shape packed_weight_op = torch ops onednn qconv_prepack prepack_weight_node = graph call_function packed_weight_op args=packed_weight_inputs new_args tuple Any = qx x_scale x_zp prepack_weight_node w_scale w_zp bias stride padding dilation groups output_scale output_zero_point dtype output_dtype none attr scalars algorithm new_conv_node = graph call_function torch ops onednn qconv_pointwise default args=new_args conv_node replace_all_uses_with new_conv_node new_conv_node meta update conv_node meta Erase original conv node graph erase_node conv_node Erase dequant pattern with_dtype_convert graph erase_node convert_to_bf type ignore possibly-undefined arg-type graph erase_node dequant_node type ignore arg-type Erase dequant per channel pattern clone_node None graph erase_node clone_node type ignore arg-type dtype == torch bfloat graph erase_node weight_to_bf _node type ignore possibly-undefined arg-type graph erase_node dequant_per_channel type ignore arg-type counters inductor qconv_weight_prepack_matcher_count += counters inductor qconv_weight_prepack_matcher_nodes += len match nodes _generate_dequant_convolution_node_pattern _dequant_per_channel_pattern dtype=torch float with_dtype_convert=False assert dtype torch float torch bfloat dequant_convolution_node_pattern = CallFunction aten convolution default _may_generate_pattern_with_dtype_convert get_dequantize_per_tensor_activation_pattern KeywordArg autocast_act_dtype with_dtype_convert _dequant_per_channel_pattern KeywordArg b KeywordArg stride KeywordArg padding KeywordArg dilation KeywordArg is_transposed KeywordArg out_padding KeywordArg groups dequant_convolution_node_pattern _generate_qconv_weight_prepack_patterns dtype=torch float with_dtype_convert=False assert dtype torch float torch bfloat _generate_dequant_convolution_node_pattern dequantize_per_channel_weight_pattern dtype == torch float dequantize_per_channel_to_bf _weight_pattern dtype with_dtype_convert There another pattern due pass convert_conv_weights_to_channels_last https github com pytorch pytorch blob db f ab f c b d d f e torch _inductor freezing py#L -L Depend some heuristics may may insert channel_last node between convolution dequant_per_channel node _generate_dequant_convolution_node_pattern dequantize_per_channel_clone_weight_pattern dtype == torch float dequantize_per_channel_to_bf _clone_weight_pattern dtype with_dtype_convert _get_linear_node match input_dim_exceeds_two input_contiguous output_reshape_node = None input_dim_exceeds_two input_contiguous output_reshape_node = match output_node assert output_reshape_node target aten reshape default linear_node = output_reshape_node args linear_nodes = filter_nodes match nodes aten bmm default assert len linear_nodes == linear_node = linear_nodes linear_node = match output_node assert linear_node target aten addmm default aten mm default aten bmm default linear_node output_reshape_node _get_linear_dq_node linear_node input_index input_dim_exceeds_two input_contiguous with_dtype_convert act_reshape_node = None activation_to_bf _node = None act_expand_node = None input_dim_exceeds_two input_contiguous act_reshape_node = linear_node args input_index assert act_reshape_node target aten reshape default with_dtype_convert pattern linear - reshape - dequant dequant_node = act_reshape_node args pattern linear - reshape - to_bf - dequant activation_to_bf _node = act_reshape_node args dequant_node = activation_to_bf _node args bmm pattern decomposed linear when input dim exceeds contiguous act_expand_node = linear_node args input_index assert act_expand_node target aten expand default with_dtype_convert dequant_node = act_expand_node args activation_to_bf _node = act_expand_node args dequant_node = activation_to_bf _node args with_dtype_convert pattern linear - dequant dequant_node = linear_node args input_index pattern linear - to_bf - dequant activation_to_bf _node = linear_node args input_index dequant_node = activation_to_bf _node args dequant_node act_reshape_node activation_to_bf _node act_expand_node _is_valid_dequant_linear_pattern dtype input_dim_exceeds_two input_contiguous with_dtype_convert _inner match Check dequant pattern has only user linear_node _ = _get_linear_node match input_dim_exceeds_two input_contiguous input_index = linear_node target aten addmm default assert dtype torch float torch bfloat dequant_node _ _ _ = _get_linear_dq_node linear_node input_index input_dim_exceeds_two input_contiguous with_dtype_convert assert dequant_node target quantized_decomposed dequantize_per_tensor default quantized_decomposed dequantize_per_tensor tensor len list dequant_node users = Ensure dequant pattern only has user since we will delete dequant pattern here False Extra check bmm pattern input_dim_exceeds_two input_contiguous Check act Act expand size should exactly same act size act_expand_size = match kwargs act_expand_size act_node = match kwargs x hasattr act_node meta isinstance act_node meta get val None torch Tensor act_node meta val size == torch Size act_expand_size False Check wgt wgt permute dims should wgt_permute_dims = match kwargs permute_axes wgt_permute_dims = False Check below wgt size items wgt before expand should dim Expand size should dim Expand size should same act size Expand size should same wgt size Expand size should same wgt size qweight_node = match kwargs q_weight wgt_expand_size = match kwargs wgt_expand_size hasattr qweight_node meta isinstance qweight_node meta get val None torch Tensor len qweight_node meta val size == len wgt_expand_size == wgt_expand_size == act_node meta val size wgt_expand_size == qweight_node meta val size wgt_expand_size == qweight_node meta val size False True _inner _register_qlinear_weight_prepack_pass pattern pass_number dtype=torch float input_dim_exceeds_two=False input_contiguous=True with_dtype_convert=False register_freezing_graph_pattern pattern extra_check=_is_valid_dequant_linear_pattern dtype input_dim_exceeds_two input_contiguous with_dtype_convert pass_number=pass_number qlinear_weight_prepack match Match args kwargs Match pattern int activation &#124; dequant_per_tensor &#124; mm addmm - t - dequant_per_channel - int _weight Insert weight prepack node change pattern int activation &#124; onednn qlinear_pointwise - onednn qlinear_prepack - int _weight assert dtype torch float torch bfloat linear_node output_reshape_node = _get_linear_node match input_dim_exceeds_two input_contiguous input_index = linear_node target aten addmm default weight_index = input_index + dequant_node act_reshape_node activation_to_bf _node act_expand_node = _get_linear_dq_node linear_node input_index input_dim_exceeds_two input_contiguous with_dtype_convert input_dim_exceeds_two input_contiguous wgt_expand_node = linear_node args weight_index assert wgt_expand_node target aten expand default t_node = wgt_expand_node args t_node = linear_node args weight_index dtype == torch float dequant_per_channel = t_node args weight_to_bf _node = t_node args dequant_per_channel = weight_to_bf _node args assert dequant_per_channel target quantized_decomposed dequantize_per_channel default Activation QParams qx x_zp x_scale = kwargs x kwargs x_zp kwargs x_scale Weight QParams qw w_scale w_zp = kwargs q_weight kwargs w_scale kwargs w_zp Params bias = kwargs get b x_shape = qx meta get tensor_meta shape has_free_symbols x_shape For dynamic shape case we can t get activation shape ahead runtime x_shape = None graph = match graph graph inserting_before linear_node Insert weight prepack node qlinear node packed_weight_inputs = qw x_shape packed_weight_op = torch ops onednn qlinear_prepack prepack_weight_node = graph call_function packed_weight_op args=packed_weight_inputs new_args tuple Any = qx x_scale x_zp prepack_weight_node w_scale w_zp bias output_scale output_zero_point dtype output_dtype none post op name post op args post op algorithm Node = torch fx node Node isinstance x_scale Node isinstance x_zp Node new_linear_node = graph call_function torch ops onednn qlinear_pointwise tensor args=new_args new_linear_node = graph call_function torch ops onednn qlinear_pointwise default args=new_args input_dim_exceeds_two input_contiguous output_reshape_node replace_all_uses_with new_linear_node new_linear_node meta update output_reshape_node meta bias output_add_node_for_bias = match output_node assert output_add_node_for_bias target aten add Tensor output_add_node_for_bias replace_all_uses_with new_linear_node new_linear_node meta update output_add_node_for_bias meta linear_node replace_all_uses_with new_linear_node new_linear_node meta update linear_node meta linear_node replace_all_uses_with new_linear_node new_linear_node meta update linear_node meta Erase original linear node input_dim_exceeds_two input_contiguous graph erase_node output_reshape_node input_contiguous bias graph erase_node output_add_node_for_bias type ignore possibly-undefined graph erase_node linear_node input_dim_exceeds_two input_contiguous graph erase_node act_reshape_node graph erase_node act_expand_node graph erase_node wgt_expand_node type ignore possibly-undefined with_dtype_convert graph erase_node activation_to_bf _node Erase dequant pattern graph erase_node dequant_node Erase dequant per channel pattern graph erase_node t_node dtype == torch bfloat graph erase_node weight_to_bf _node type ignore possibly-undefined graph erase_node dequant_per_channel counters inductor qlinear_weight_prepack_matcher_count += counters inductor qlinear_weight_prepack_matcher_nodes += len match nodes _generate_dequant_linear_node_pattern _dequant_per_channel_pattern dtype=torch float input_dim_exceeds_two=False is_tensor_overload=False with_dtype_convert=False assert dtype torch float torch bfloat t_pattern = _generate_linear_t_pattern _dequant_per_channel_pattern dtype dequant_linear_bias_pattern = _may_generate_pattern_with_reshape CallFunction aten addmm default KeywordArg b _may_generate_pattern_with_reshape _may_generate_pattern_with_dtype_convert get_dequantize_per_tensor_activation_pattern is_tensor_overload KeywordArg autocast_act_dtype with_dtype_convert KeywordArg act_reshape_size input_dim_exceeds_two t_pattern KeywordArg output_reshape_size input_dim_exceeds_two dequant_linear_no_bias_pattern = _may_generate_pattern_with_reshape CallFunction aten mm default _may_generate_pattern_with_reshape _may_generate_pattern_with_dtype_convert get_dequantize_per_tensor_activation_pattern is_tensor_overload KeywordArg autocast_act_dtype with_dtype_convert KeywordArg act_reshape_size input_dim_exceeds_two t_pattern KeywordArg output_reshape_size input_dim_exceeds_two dequant_linear_bias_pattern dequant_linear_no_bias_pattern _generate_dequant_bmm_node_pattern _dequant_per_channel_pattern dtype=torch float with_bias=False is_tensor_overload=False with_dtype_convert=False When activation linear dim exceed contiguous t_pattern = _generate_linear_t_pattern _dequant_per_channel_pattern dtype assert dtype torch float torch bfloat dequant_bmm_pattern = CallFunction aten bmm default CallFunction aten expand default _may_generate_pattern_with_dtype_convert get_dequantize_per_tensor_activation_pattern is_tensor_overload KeywordArg autocast_act_dtype with_dtype_convert KeywordArg act_expand_size CallFunction aten expand default t_pattern KeywordArg wgt_expand_size _generate_pattern_with_output_add _dequant_bmm_pattern _with_bias _with_bias CallFunction aten add Tensor _dequant_bmm_pattern KeywordArg b _dequant_bmm_pattern _generate_pattern_with_output_add dequant_bmm_pattern with_bias _generate_qlinear_weight_prepack_patterns dtype=torch float input_dim_exceeds_two=False input_contiguous=True with_bias=False is_tensor_overload=False with_dtype_convert=False input_dim_exceeds_two input_contiguous _generate_dequant_bmm_node_pattern dequantize_per_channel_weight_pattern dtype with_bias is_tensor_overload with_dtype_convert _generate_dequant_linear_node_pattern dequantize_per_channel_weight_pattern dtype input_dim_exceeds_two is_tensor_overload with_dtype_convert _generate_linear_dynamic_fp _pattern _dequant_weight_pattern input_dim_exceeds_two=False input_contiguous=True relu_fused=False dtype = torch float t_pattern = _generate_linear_t_pattern _dequant_weight_pattern dtype input_dim_exceeds_two input_contiguous pattern x - expand - bmm - add - relu w - dequant - permute - expand pattern_no_bias = CallFunction aten bmm default CallFunction aten expand default KeywordArg x KeywordArg act_expand_size CallFunction aten expand default t_pattern KeywordArg wgt_expand_size pattern_with_bias = CallFunction aten add Tensor pattern_no_bias KeywordArg b relu_fused pattern_with_bias = CallFunction aten relu default pattern_with_bias pattern_no_bias = CallFunction aten relu default pattern_no_bias pattern_with_bias pattern_no_bias x_pattern_with_reshape = _may_generate_pattern_with_reshape KeywordArg x KeywordArg act_reshape_size input_dim_exceeds_two dequant_linear_bias_pattern = generate_pattern_with_unary _may_generate_pattern_with_reshape CallFunction aten addmm default KeywordArg b x_pattern_with_reshape t_pattern KeywordArg output_reshape_size input_dim_exceeds_two aten relu default relu_fused None dequant_linear_no_bias_pattern = generate_pattern_with_unary _may_generate_pattern_with_reshape CallFunction aten mm default x_pattern_with_reshape t_pattern KeywordArg output_reshape_size input_dim_exceeds_two aten relu default relu_fused None dequant_linear_bias_pattern dequant_linear_no_bias_pattern _register_dequant_promotion dequant_pattern_cases = itertools product torch float torch bfloat True False True False dtype input_dim_exceeds_two is_tensor_overload dequant_pattern_cases dequantization patterns will matched based dtype input dimension size Case int -mixed-fp input dim size Case int -mixed-fp input dim size exceeds Case int -mixed-bf input dim size Case int -mixed-bf input dim size exceeds quant + - - - - &#124; - - - - + &#124; dequant &#124; &#124; &#124; &#124; &#124; OPT to_bf &#124; &#124; &#124; &#124; &#124; OPT reshape &#124; &#124; \ &#124; &#124; node node &#124; + - - &#124; - - - &#124; - - + OPT reshape OPT reshape + - - &#124; - - - &#124; - - + OPT to_fp OPT to_fp + - - &#124; - - - &#124; - - + quant quant _register_dequant_promotion_pass _may_generate_pattern_with_reshape _may_generate_pattern_with_dtype_convert get_dequantize_per_tensor_activation_pattern is_tensor_overload=is_tensor_overload KeywordArg autocast_act_dtype dtype == torch bfloat KeywordArg act_reshape_size with_reshape=input_dim_exceeds_two pass_number= dtype=dtype pass_number= run before weight prepack _register_qconv_weight_prepack dtype with_dtype_convert itertools product torch float torch bfloat True False dtype == torch float with_dtype_convert continue weight_prepack_patterns = _generate_qconv_weight_prepack_patterns dtype with_dtype_convert weight_prepack_pattern weight_prepack_patterns Register pass_number so we can do dequant promotion pass_number _register_qconv_weight_prepack_pass weight_prepack_pattern pass_number= dtype=dtype with_dtype_convert=with_dtype_convert _register_qlinear_weight_prepack Linear related patterns will matched based dtype input dimension size input contiguous Then convert pattern into QLinear node int _fp bf Case int -mixed-fp input dim size Case int -mixed-fp input dim size exceeds contiguous Case int -mixed-bf input dim size Case int -mixed-bf input dim size exceeds contiguous + - - - - &#124; - - - - - - &#124; - - - - - + &#124; dq_per_tensor dq_per_channel &#124; &#124; &#124; &#124; &#124; &#124; OPT to_bf OPT to_bf &#124; &#124; &#124; &#124; &#124; &#124; OPT reshape permute &#124; &#124; \ &#124; &#124; addmm mm &#124; &#124; &#124; &#124; &#124; OPT reshape &#124; Case int -mixed-fp input dim size exceeds contiguous Case int -mixed-bf input dim size exceeds contiguous + - - - - &#124; - - - - - - &#124; - - - - - + &#124; dq_per_tensor dq_per_channel &#124; &#124; &#124; &#124; &#124; &#124; OPT to_bf OPT to_bf &#124; &#124; &#124; &#124; &#124; &#124; expand permute &#124; &#124; \ &#124; &#124; &#124; expand &#124; &#124; &#124; &#124; bmm &#124; &#124; &#124; &#124; &#124; OPT add &#124; linear_weight_prepack_cases = itertools product torch float torch bfloat True False True False True False Step register patterns mm addmm dtype input_dim_exceeds_two is_tensor_overload with_dtype_convert linear_weight_prepack_cases dtype == torch float with_dtype_convert continue weight_prepack_patterns = _generate_qlinear_weight_prepack_patterns dtype input_dim_exceeds_two is_tensor_overload=is_tensor_overload with_dtype_convert=with_dtype_convert weight_prepack_pattern weight_prepack_patterns Register pass_number so we can do dequant promotion pass_number _register_qlinear_weight_prepack_pass weight_prepack_pattern pass_number= dtype=dtype input_dim_exceeds_two=input_dim_exceeds_two with_dtype_convert=with_dtype_convert Step register patterns bmm Linear might decomposed into bmm when input dim exceeds contiguous refer https github com pytorch pytorch blob c df da cd f ec abfdace c torch _decomp decompositions py#L -L case we can convert back qlinear dtype with_bias is_tensor_overload with_dtype_convert itertools product torch float torch bfloat True False True False True False dtype == torch float with_dtype_convert continue bmm_pattern = _generate_qlinear_weight_prepack_patterns dtype=dtype input_dim_exceeds_two=True input_contiguous=False with_bias=with_bias is_tensor_overload=is_tensor_overload with_dtype_convert=with_dtype_convert _register_qlinear_weight_prepack_pass bmm_pattern pass_number= with_bias with_bias there output add so we should try match firstly dtype=dtype input_dim_exceeds_two=True input_contiguous=False with_dtype_convert=with_dtype_convert _register_linear_dynamic_fp _weight_prepack_pass pattern pass_number input_dim_exceeds_two=False input_contiguous=True relu_fused=False _extra_check_fn match Match match kwargs dtype_fp == torch float register_freezing_graph_pattern pattern extra_check=_extra_check_fn pass_number=pass_number linear_dynamic_fp _weight_prepack match Match args kwargs Match pattern fp activation &#124; mm addmm - t - to_fp - to_fp - weight &#124; reshape - relu OR fp activation &#124; expand &#124; bmm - expand - t - to_fp - to_fp - weight &#124; add - relu Insert weight prepack node change pattern fp activation &#124; onednn linear_dynamic_fp - onednn linear_prepack_fp - weight onednn linear_relu_dynamic_fp find params x = kwargs x w = kwargs w bias = kwargs get b find linear node nodes_to_find = aten addmm default aten mm default aten bmm default linear_nodes = node nodes_to_find linear_nodes extend filter_nodes match nodes node assert len linear_nodes == linear_node = linear_nodes assert isinstance linear_node torch fx node Node input_index = linear_node target aten addmm default weight_index = input_index + find relu node relu_node = None relu_fused relu_node = match output_node assert isinstance relu_node torch fx node Node find reshape node expand node add node act_reshape_node output_reshape_node expand_x_node expand_w_node add_bias_node = None None None None None t_node = None input_dim_exceeds_two input_contiguous act_reshape_node = linear_node args input_index t_node = linear_node args weight_index output_reshape_node = next iter linear_node users assert output_reshape_node target aten reshape default expand_x_node = linear_node args input_index expand_w_node = linear_node args weight_index assert isinstance expand_w_node torch fx node Node t_node = expand_w_node args bias add_bias_node = next iter linear_node users assert add_bias_node target aten add Tensor t_node = linear_node args weight_index assert isinstance t_node torch fx node Node w_to_fp _node = t_node args assert isinstance w_to_fp _node torch fx node Node w_to_fp _node target quantized_decomposed convert_element_type no_fuse w_to_fp _node = w_to_fp _node args assert isinstance w_to_fp _node torch fx node Node w_to_fp _node target quantized_decomposed convert_element_type no_fuse x_shape = x meta get tensor_meta shape has_free_symbols x_shape For dynamic shape case we can t get activation shape ahead runtime x_shape = None graph = match graph graph inserting_before linear_node Insert weight prepack node qlinear node packed_weight_inputs = w x_shape packed_weight_op = torch ops onednn linear_prepack_fp prepack_weight_node = graph call_function packed_weight_op args=packed_weight_inputs create new linear node insert graph new_args tuple Any = x prepack_weight_node bias linear_op = torch ops onednn linear_relu_dynamic_fp default relu_fused torch ops onednn linear_dynamic_fp default new_linear_node = graph call_function linear_op args=new_args out_node = match output_node out_node replace_all_uses_with new_linear_node Erase original nodes reverse order new_linear_node meta update out_node meta relu_node None graph erase_node relu_node output_reshape_node None graph erase_node output_reshape_node add_bias_node None graph erase_node add_bias_node graph erase_node linear_node act_reshape_node None assert isinstance act_reshape_node torch fx node Node graph erase_node act_reshape_node expand_x_node None assert isinstance expand_x_node torch fx node Node graph erase_node expand_x_node expand_w_node None assert isinstance expand_w_node torch fx node Node graph erase_node expand_w_node graph erase_node t_node graph erase_node w_to_fp _node graph erase_node w_to_fp _node counters inductor qlinear_weight_prepack_matcher_count += counters inductor qlinear_weight_prepack_matcher_nodes += len match nodes _register_linear_dynamic_fp _weight_prepack to_dtype_op = torch ops quantized_decomposed convert_element_type no_fuse weight_pattern = CallFunction to_dtype_op CallFunction to_dtype_op KeywordArg w KeywordArg dtype_fp KeywordArg dtype_fp cases = itertools product False True input_dim_exceeds_two True False input_contiguous False True relu fused input_dim_exceeds_two input_contiguous relu_fused cases patterns = _generate_linear_dynamic_fp _pattern weight_pattern input_dim_exceeds_two input_contiguous relu_fused pattern patterns _register_linear_dynamic_fp _weight_prepack_pass pattern pass_number= relu_fused input_dim_exceeds_two=input_dim_exceeds_two input_contiguous=input_contiguous relu_fused=relu_fused _register_smooth_quant_int_mm_pattern The pattern no bias reshape - _int_mm - convert_element_type - expand - mul - mul - reshape bias pattern_no_bias - add - reshape - reshape When torch compile ing dynamic=True expand node two tailing reshape nodes exist When torch compile ing dynamic=False they don t exist get_pattern_no_bias expand_a_scale bool reshape_a bool = True CallFunction aten mul Tensor CallFunction aten mul Tensor CallFunction prims convert_element_type default CallFunction aten _int_mm default CallFunction aten reshape default KeywordArg KeywordArg in_shape reshape_a KeywordArg KeywordArg b KeywordArg dtype CallFunction aten expand default KeywordArg x_scale Arg expand_a_scale KeywordArg x_scale KeywordArg w_scale _with_outer_reshape pattern CallFunction aten reshape default pattern KeywordArg out_shape_no_bias torch compile dynamic=False pattern_no_bias_ = _with_outer_reshape get_pattern_no_bias expand_a_scale=False pattern_with_bias_ = CallFunction aten add Tensor pattern_no_bias_ KeywordArg bias torch compile dynamic=True pattern_no_bias_ = _with_outer_reshape get_pattern_no_bias expand_a_scale=True pattern_with_bias_ = CallFunction aten reshape default CallFunction aten reshape default CallFunction aten add Tensor pattern_no_bias_ KeywordArg bias Arg KeywordArg out_shape_with_bias The following patterns torchao int _dynamic_activation_int _weight linear when both activation weights symmetrically quantized In practice though they may also match smooth-quant pattern when D input shape would used Since add currently being used oneDNN post-op unfused we don t need these patterns bias Ideally we should add mul + add post-op support ATen int oneDNN linear op pattern _with_no_outer_or_act_reshape = get_pattern_no_bias expand_a_scale=False reshape_a=False pattern _with_no_outer_or_act_reshape = get_pattern_no_bias expand_a_scale=True reshape_a=False _validate_pattern match Match len match nodes False Make sure weight constant aten_int_mm_node = filter_nodes match nodes aten _int_mm default isinstance aten_int_mm_node args torch fx node Node False aten_int_mm_node args op = get_attr False len match nodes == Check two tailing reshape nodes can fused match nodes args = match nodes args False len match nodes == len match nodes == match nodes target aten add Tensor bias_idx = len match nodes == Check bias shape bias_node = match nodes bias_idx args isinstance bias_node torch fx node Node False len bias_node meta get tensor_meta shape = type ignore union-attr False True pattern_to_pass_number = pattern_no_bias_ pattern_with_bias_ pattern_no_bias_ pattern_with_bias_ pattern _with_no_outer_or_act_reshape pattern _with_no_outer_or_act_reshape pattern pass_number pattern_to_pass_number items register_freezing_graph_pattern pattern extra_check=_validate_pattern pass_number=pass_number _int_mm_weight_prepack match Match args kwargs bias = kwargs get bias x = kwargs weight = kwargs b dtype = kwargs dtype x_scale = kwargs x_scale w_scale = kwargs w_scale x_shape = x meta get tensor_meta shape has_free_symbols x_shape For dynamic shape case we can t get activation shape ahead runtime x_shape = None out_node = match output_node match graph inserting_before out_node transpose_node = match graph call_function aten permute default args= weight contig_node = match graph call_function aten contiguous default args= transpose_node packed_weight_inputs = contig_node x_shape packed_weight_op = torch ops onednn qlinear_prepack prepack_weight_node = match graph call_function packed_weight_op args=packed_weight_inputs dummy_zp = None w_scale = match graph call_function prims convert_element_type default args= w_scale torch float x_scale_shape = x_scale meta get tensor_meta shape x_scale_is_scalar = False has_free_symbols x_scale_shape prod = d x_scale_shape prod = d x_scale_is_scalar = prod == new_args tuple Any x_scale_is_scalar case we can call onednn qlinear directly new_args = x x_scale dummy_zp x_zp prepack_weight_node w_scale dummy_zp w_zp bias output_scale output_zero_point dtype output_dtype none post op name post op args post op algorithm new_linear_node = match graph call_function torch ops onednn qlinear_pointwise tensor args=new_args out_node replace_all_uses_with new_linear_node new_linear_node meta update out_node meta onednn qlinear does support per-channel quantization x so case we have apply x scale add bias ourselves after qlinear in_shape = kwargs get in_shape in_shape None x_reshaped = x x_reshaped = match graph call_function aten reshape default args= x in_shape new_args = x_reshaped x_scale x_zp prepack_weight_node w_scale dummy_zp w_zp None bias output_scale output_zero_point dtype output_dtype none post op name post op args post op algorithm new_linear_node = match graph call_function torch ops onednn qlinear_pointwise args=new_args apply x scale new_out_node = match graph call_function aten mul Tensor args= new_linear_node x_scale Add bias reshape has_outer_reshape = kwargs get out_shape_with_bias None kwargs get out_shape_no_bias None has_outer_reshape out_shape = kwargs get out_shape_with_bias kwargs out_shape_no_bias bias None new_out_node = match graph call_function aten add Tensor args= new_out_node bias has_outer_reshape new_out_node = match graph call_function aten reshape default args= new_out_node out_shape type ignore possibly-undefined has_outer_reshape new_out_node = match graph call_function aten reshape default args= new_out_node out_shape type ignore possibly-undefined out_node replace_all_uses_with new_out_node new_out_node meta update out_node meta node reversed match nodes match graph erase_node node counters inductor qlinear_weight_prepack_matcher_count += counters inductor qlinear_weight_prepack_matcher_nodes += len match nodes PostOpAttr __init__ binary_op_name str = none alpha=None unary_op_name str = none scalars_attr=None algorithm_attr=None - None binary_op_name = binary_op_name alpha = alpha alpha unary_op_name = unary_op_name scalars_attr = scalars_attr scalars_attr algorithm_attr = algorithm_attr algorithm_attr _register_qconv_post_op_fusion_pass pattern pass_number computation_op post_op_attr has_binary_post_op = post_op_attr binary_op_name = none register_freezing_graph_pattern pattern extra_check=_is_valid_qconv_post_op_fusion_pattern has_binary_post_op pass_number=pass_number qconv match Match args kwargs Activation QParams x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp Weight QParams packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp Conv Params b stride padding dilation groups = kwargs b kwargs stride kwargs padding kwargs dilation kwargs groups output_dtype = _get_pattern_output_dtype match assert output_dtype torch int torch uint torch float torch bfloat Output QParams o_inv_scale = kwargs o_inv_scale output_dtype == torch uint output_dtype == torch int o_zero_point = kwargs o_zp output_dtype == torch uint output_dtype == torch int assert kwargs postop_name == none Expected no post op fused weight prepack phase post_op_attr unary_op_name == hardtanh min_value = kwargs get min_value max_value = kwargs get max_value post_op_attr scalars_attr = min_value max_value out_node = match output_node match graph inserting_before out_node has_binary_post_op computation_args tuple Any = x x_scale x_zp packed_weight w_scale w_zp b stride padding dilation groups o_inv_scale o_zero_point output_dtype post_op_attr unary_op_name post_op_attr scalars_attr post_op_attr algorithm_attr accum = kwargs accum output_dtype torch uint torch int kwargs accum_after_dequant accum_scale = kwargs accum_scale output_dtype torch uint torch int accum_zp = kwargs accum_zp output_dtype torch uint torch int computation_args = x x_scale x_zp packed_weight w_scale w_zp accum b stride padding dilation groups o_inv_scale o_zero_point output_dtype accum_scale accum_zp post_op_attr binary_op_name post_op_attr alpha post_op_attr unary_op_name post_op_attr scalars_attr post_op_attr algorithm_attr new_conv_node = match graph call_function computation_op args=computation_args out_node replace_all_uses_with new_conv_node new_conv_node meta update out_node meta node reversed match nodes match graph erase_node node count_key = qconv d_binary_matcher_count has_binary_post_op qconv_unary_matcher_count nodes_key = qconv d_binary_matcher_nodes has_binary_post_op qconv_unary_matcher_nodes counters inductor count_key += counters inductor nodes_key += len match nodes qconv _register_qconv_unary_fusion mkldnn_fusion _hardswish_fusion _hardtanh_fusion _silu_fusion original_pattern_output_dtype torch float torch bfloat Priority match QConv d Unary pattern int output If pattern sub-set pattern we should try match pattern firstly For example pattern qconv_fp - relu pattern qconv_fp - relu - quant is_bf = original_pattern_output_dtype == torch bfloat conv_unary_replace_patterns = PostOpAttr none None none generate_pattern_with_output_quant get_qconv_pt e_pattern PostOpAttr none None relu generate_pattern_with_output_quant generate_pattern_with_unary get_qconv_pt e_pattern aten relu default PostOpAttr none None hardtanh generate_pattern_with_output_quant _unary_fusion_pattern _hardtanh_fusion get_qconv_pt e_pattern is_bf with_dtype_convert=is_bf PostOpAttr none None hardswish generate_pattern_with_output_quant _unary_fusion_pattern _hardswish_fusion get_qconv_pt e_pattern is_bf is_bf with_dtype_convert=is_bf PostOpAttr none None swish generate_pattern_with_output_quant _unary_fusion_pattern _silu_fusion get_qconv_pt e_pattern is_bf is_bf with_dtype_convert=is_bf unary_attr patterns conv_unary_replace_patterns items Register qconv d pattern ExternKernel Lowering _register_qconv_post_op_fusion_pass patterns pass_number torch ops onednn qconv_pointwise default computation_op unary_attr unary_attr Priority match QConv d Unary pattern fp bfloat output conv_unary_replace_float_out_patterns = PostOpAttr none None relu generate_pattern_with_unary get_qconv_pt e_pattern aten relu default PostOpAttr none None hardtanh _may_generate_pattern_with_dtype_convert _unary_fusion_pattern _hardtanh_fusion get_qconv_pt e_pattern is_bf Arg is_bf PostOpAttr none None hardswish _may_generate_pattern_with_dtype_convert _unary_fusion_pattern _hardswish_fusion get_qconv_pt e_pattern is_bf is_bf Arg is_bf PostOpAttr none None swish _may_generate_pattern_with_dtype_convert _unary_fusion_pattern _silu_fusion get_qconv_pt e_pattern is_bf is_bf Arg is_bf unary_attr patterns conv_unary_replace_float_out_patterns items Register qconv d pattern ExternKernel Lowering _register_qconv_post_op_fusion_pass patterns pass_number torch ops onednn qconv_pointwise default computation_op unary_attr unary_attr _register_qconv_binary_fusion int _mixed_bf _with_inplace_add False True Priority match QConv d Binary Binary-Unary pattern int output swap_binary_inputs_list = False True binary_replace_patterns = swap_inputs swap_binary_inputs_list binary_replace_patterns update PostOpAttr sum none generate_pattern_with_output_quant generate_pattern_with_binary aten add Tensor get_qconv_pt e_pattern dequantize_accum_pattern int _mixed_bf _with_inplace_add swap_inputs=swap_inputs PostOpAttr sum relu generate_pattern_with_output_quant generate_pattern_with_unary generate_pattern_with_binary aten add Tensor get_qconv_pt e_pattern dequantize_accum_pattern int _mixed_bf _with_inplace_add swap_inputs=swap_inputs aten relu default binary_unary_attr patterns binary_replace_patterns items _register_qconv_post_op_fusion_pass patterns pass_number torch ops onednn qconv d_pointwise binary computation_op binary_unary_attr binary_unary_attr Priority match QConv d Binary-Unary pattern fp bfloat output binary_replace_float_out_patterns = swap_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr sum relu generate_pattern_with_unary generate_pattern_with_binary aten add Tensor get_qconv_pt e_pattern KeywordArg accum_after_dequant int _mixed_bf _with_inplace_add swap_inputs=swap_inputs aten relu default binary_unary_attr patterns binary_replace_float_out_patterns items int _mixed_bf _with_inplace_add _register_qconv_post_op_fusion_pass patterns pass_number torch ops onednn qconv d_pointwise binary computation_op binary_unary_attr binary_unary_attr _register_qconv_post_op_fusion_pass patterns pass_number torch ops onednn qconv d_pointwise binary computation_op binary_unary_attr binary_unary_attr Priority QConv d Binary pattern fp bfloat output binary_replace_float_out_patterns = swap_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr sum none generate_pattern_with_binary aten add Tensor get_qconv_pt e_pattern KeywordArg accum_after_dequant int _mixed_bf _with_inplace_add swap_inputs=swap_inputs binary_unary_attr patterns binary_replace_float_out_patterns items _register_qconv_post_op_fusion_pass patterns int _mixed_bf _with_inplace_add pass_number torch ops onednn qconv d_pointwise binary computation_op binary_unary_attr binary_unary_attr _register_qlinear_post_op_fusion_pass pattern pass_number computation_op post_op_attr has_binary_post_op = post_op_attr binary_op_name = none register_freezing_graph_pattern pattern extra_check=_is_valid_qlinear_post_op_fusion_pattern has_binary_post_op pass_number=pass_number qlinear_post_op_fusion match Match args kwargs Match pattern qlinear - post op output_dtype = _get_pattern_output_dtype match Activation QParams x x_scale x_zp = kwargs x kwargs x_scale kwargs x_zp Weight QParams packed_weight w_scale w_zp = kwargs packed_weight kwargs w_scale kwargs w_zp bias b = kwargs get b Output QParams o_inv_scale = kwargs o_inv_scale output_dtype torch uint torch int o_zero_point = kwargs o_zp output_dtype torch uint torch int assert kwargs postop_name == none Expected no post op fused weight prepack phase out_node = match output_node match graph inserting_before out_node has_binary_post_op computation_args tuple Any = x x_scale x_zp packed_weight w_scale w_zp b o_inv_scale o_zero_point output_dtype post_op_attr unary_op_name post_op_attr scalars_attr post_op_attr algorithm_attr other = kwargs other other kwargs kwargs accum x _scale = x _zp = computation_args = x x_scale x_zp packed_weight w_scale w_zp other b o_inv_scale o_zero_point output_dtype x _scale x _zp post_op_attr binary_op_name post_op_attr alpha post_op_attr unary_op_name post_op_attr scalars_attr post_op_attr algorithm_attr new_linear_node = match graph call_function computation_op args=computation_args out_node replace_all_uses_with new_linear_node new_linear_node meta update out_node meta node reversed match nodes match graph erase_node node count_key = qlinear_binary_matcher_count has_binary_post_op qlinear_unary_matcher_count nodes_key = qlinear_binary_matcher_nodes has_binary_post_op qlinear_unary_matcher_nodes counters inductor count_key += counters inductor nodes_key += len match nodes _register_qlinear_unary_fusion mkldnn_fusion _gelu_fusion_ _gelu_fusion_erf _gelu_fusion_ _gelu_fusion_tanh original_pattern_output_dtype torch float torch bfloat is_bf = original_pattern_output_dtype == torch bfloat x_scale_zp_are_tensors False True qlinear_pattern = get_qlinear_pt e_pattern x_scale_zp_are_tensors computation_op = torch ops onednn qlinear_pointwise tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise default Priority match QLinear Unary pattern int output linear_unary_replace_patterns = PostOpAttr none None none generate_pattern_with_output_quant qlinear_pattern PostOpAttr none None relu generate_pattern_with_output_quant generate_pattern_with_unary qlinear_pattern aten relu default PostOpAttr none None gelu none generate_pattern_with_output_quant _unary_fusion_pattern _gelu_fusion_erf get_qlinear_pt e_pattern x_scale_zp_are_tensors is_bf is_bf with_dtype_convert=is_bf PostOpAttr none None gelu tanh generate_pattern_with_output_quant _unary_fusion_pattern _gelu_fusion_tanh get_qlinear_pt e_pattern x_scale_zp_are_tensors is_bf is_bf with_dtype_convert=is_bf unary_attr patterns linear_unary_replace_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number computation_op unary_attr unary_attr Priority match QLinear Unary pattern FP BF output linear_unary_replace_float_out_patterns = PostOpAttr none None relu generate_pattern_with_unary qlinear_pattern aten relu default PostOpAttr none None gelu none _may_generate_pattern_with_dtype_convert _unary_fusion_pattern _gelu_fusion_erf get_qlinear_pt e_pattern x_scale_zp_are_tensors is_bf is_bf Arg is_bf PostOpAttr none None gelu tanh _may_generate_pattern_with_dtype_convert _unary_fusion_pattern _gelu_fusion_tanh get_qlinear_pt e_pattern x_scale_zp_are_tensors is_bf is_bf Arg is_bf unary_attr patterns linear_unary_replace_float_out_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number computation_op unary_attr unary_attr _register_qlinear_binary_fusion r Supported linear-binary -unary patterns linear X extra input \ Add &#124; Optional relu &#124; Y int -mixed-fp + --- + --------------- + ----------- + ------------------------------ + --------- + &#124; &#124; Add type &#124; Quant out &#124; Pattern &#124; Post op &#124; + --- + --------------- + ----------- + ------------------------------ + --------- + &#124; &#124; In- out-place &#124; Yes &#124; linear + fp - relu - q &#124; add &#124; + --- + --------------- + ----------- + ------------------------------ + --------- + &#124; &#124; In- out-place &#124; No &#124; linear + fp - relu &#124; sum &#124; + --- + --------------- + ----------- + ------------------------------ + --------- + int -mixed-bf + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; X dtype &#124; Add type &#124; Quant out &#124; Pattern &#124; Post op &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; BF &#124; In- out-place &#124; Yes &#124; linear + bf - relu - q &#124; add &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; BF &#124; In- out-place &#124; No &#124; linear + bf - relu &#124; sum &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; FP &#124; Out-place &#124; Yes &#124; linear + fp - relu - q &#124; add &#124; &#124; &#124; &#124; In-place right &#124; &#124; &#124; &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; FP &#124; Out-place &#124; No &#124; linear + fp - relu &#124; sum &#124; &#124; &#124; &#124; In-place right &#124; &#124; &#124; &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; FP &#124; In-place left &#124; Yes &#124; linear + fp - to_bf - relu - q &#124; add &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + &#124; &#124; FP &#124; In-place left &#124; No &#124; linear + fp - to_bf - relu &#124; add &#124; + --- + ---------- + --------------- + ----------- + ----------------------------------------- + --------- + Note The positions linear extra input can swapped we don t insert q-dq before extra input linear-add recipe But q-dq found extra input we don t match pattern because we cannot match all these patterns passes x_scale_zp_are_tensors False True qlinear_binary_op = torch ops onednn qlinear_pointwise binary_tensor x_scale_zp_are_tensors torch ops onednn qlinear_pointwise binary unary_postop_list = none relu unary_postop_dict = none None relu aten relu default convert_dtype_after_binary_list = False True Priority match QLinear Binary Binary-Unary pattern int output Covers case int -mixed-fp case int -mixed-bf totally patterns identical swap_binary_inputs_list = False True int _mixed_bf _list = False True combinations = itertools product unary_postop_list int _mixed_bf _list swap_binary_inputs_list convert_dtype_after_binary_list qlinear_binary_replace_patterns = unary_op int _mixed_bf swap_inputs cvt_dtype_binary combinations int _mixed_bf cvt_dtype_binary No convert node after binary node dtypes all fp continue qlinear_binary_replace_patterns update PostOpAttr add unary_op generate_pattern_with_output_quant generate_pattern_with_unary generate_pattern_with_binary aten add Tensor get_qlinear_pt e_pattern x_scale_zp_are_tensors KeywordArg other If fp extra input inplace added bf linear output to_bf node inserted after binary dtype_convert=cvt_dtype_binary swap_inputs=swap_inputs unary_postop_dict unary_op binary_unary_attr patterns qlinear_binary_replace_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number qlinear_binary_op computation_op binary_unary_attr Priority match QLinear Binary-Unary pattern fp bfloat output Covers case int -mixed-fp case int -mixed-bf totally patterns identical binary_replace_float_out_patterns = swap_binary_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr sum relu generate_pattern_with_unary generate_pattern_with_binary aten add Tensor get_qlinear_pt e_pattern x_scale_zp_are_tensors KeywordArg accum dtype_convert=False swap_inputs=swap_binary_inputs aten relu default binary_unary_attr patterns binary_replace_float_out_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number qlinear_binary_op computation_op binary_unary_attr Priority match QLinear Binary-Unary pattern fp bfloat output Covers case int -mixed-bf binary_replace_float_out_patterns = swap_binary_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr add relu generate_pattern_with_unary generate_pattern_with_binary aten add Tensor get_qlinear_pt e_pattern x_scale_zp_are_tensors KeywordArg other dtype_convert=True swap_inputs=swap_binary_inputs aten relu default binary_unary_attr patterns binary_replace_float_out_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number qlinear_binary_op computation_op binary_unary_attr Priority QLinear Binary pattern fp bfloat output Covers case int -mixed-fp case int -mixed-bf totally patterns identical binary_replace_float_out_patterns = swap_binary_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr sum none generate_pattern_with_binary aten add Tensor get_qlinear_pt e_pattern x_scale_zp_are_tensors KeywordArg accum dtype_convert=False swap_inputs=swap_binary_inputs binary_unary_attr patterns binary_replace_float_out_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number qlinear_binary_op computation_op binary_unary_attr Priority QLinear Binary pattern fp bfloat output Covers int -mixed-bf binary_replace_float_out_patterns = swap_binary_inputs swap_binary_inputs_list binary_replace_float_out_patterns update PostOpAttr add none generate_pattern_with_binary aten add Tensor get_qlinear_pt e_pattern x_scale_zp_are_tensors KeywordArg other dtype_convert=True swap_inputs=swap_binary_inputs binary_unary_attr patterns binary_replace_float_out_patterns items _register_qlinear_post_op_fusion_pass patterns pass_number qlinear_binary_op computation_op binary_unary_attr functools cache _register_quantization_weight_pack_pass Step Dequant promotion int -mixed-fp bf _register_dequant_promotion Step QConv weight prepack _register_qconv_weight_prepack Step QLinear weight prepack _register_qlinear_weight_prepack _register_linear_dynamic_fp _weight_prepack Step weight prepack SmoothQuant Torchao _register_smooth_quant_int_mm_pattern Step QLinear post op Fusion torch ops mkldnn _is_mkldnn_acl_supported skip fusion ARM _register_qconv_unary_fusion _register_qconv_binary_fusion _register_qlinear_unary_fusion _register_qlinear_binary_fusion _is_valid_concat_linear_woq_int _fusion computation_nodes computation_op = torch ops aten _weight_int pack_mm_for_cpu default act = computation_nodes args wgt = computation_nodes args in_feature_size = wgt meta get val size type ignore union-attr group_size = computation_nodes args len computation_nodes = all node target == computation_op node args == act share same activation node args meta get val size == in_feature_size same feature size node args = wgt gemm_idx == node args op == get_attr wgt all constants node args == group_size same group size gemm_idx node enumerate computation_nodes concat_linear_woq_int gm torch fx GraphModule Concat Linear optimization pass WOQ int This pass fuses original pattern woq_int x w group_size scale_zp woq_int x w group_size scale_zp into single operation concat_res = woq_int x concat_w group_size concat_scale_zp split concat_res split_size_list concat_wgt packed_wgts scale_zps group_size act_dtype Concat wgts scale_zps repack wgt unpacked_wgts = packed_wgt packed_wgts Get unpacked weight list Same https github com pytorch pytorch pull K = packed_wgt size N = packed_wgt size x = torch eye K dtype=act_dtype qscales_and_zeros = torch tensor dtype=act_dtype expand K group_size N contiguous unpacked_wgts append torch ops aten _weight_int pack_mm_for_cpu x packed_wgt group_size qscales_and_zeros t contiguous torch int N K concat_unpacked_wgt = torch cat unpacked_wgts dim= repack_w = torch ops aten _convert_weight_to_int pack_for_cpu concat_unpacked_wgt concat_scale_zp = torch cat scale_zps dim= contiguous repack_w concat_scale_zp graph = gm graph computation_op = torch ops aten _weight_int pack_mm_for_cpu default node graph find_nodes op= call_function target=computation_op node _erased isinstance node meta get val torch Tensor node meta val device type == cpu act = node args users = list act users _is_valid_concat_linear_woq_int _fusion users graph inserting_before node assert all user args op == get_attr user users computation_node_ = users packed_wgts = getattr gm user args target user users group_size = computation_node_ args scale_zps = getattr gm user args target user users out_feature_size_list = packed_wgt size packed_wgt packed_wgts repack_w concat_scale_zp = concat_wgt packed_wgts scale_zps group_size act meta get val dtype repack_w_node_name = computation_node_ args target + _concat concat_scale_zp_node_name = computation_node_ args target + _concat gm register_buffer repack_w_node_name repack_w setattr gm repack_w_node_name repack_w gm register_buffer concat_scale_zp_node_name concat_scale_zp setattr gm concat_scale_zp_node_name concat_scale_zp repack_w_node = graph create_node get_attr repack_w_node_name graph inserting_after repack_w_node concat_scale_zp_node = graph create_node get_attr concat_scale_zp_node_name graph inserting_after concat_scale_zp_node concat_int _gemm_node = graph create_node call_function computation_op act repack_w_node group_size concat_scale_zp_node graph inserting_after concat_int _gemm_node split_node = graph create_node call_function torch ops aten split_with_sizes default concat_int _gemm_node out_feature_size_list split dim graph inserting_after split_node gemm_idx user enumerate users assert user target == computation_op get_item = graph create_node call_function operator getitem split_node gemm_idx graph inserting_after get_item clone_node = graph create_node call_function torch ops aten clone default get_item memory_format torch contiguous_format user replace_all_uses_with clone_node graph erase_node user quant_lift_up graph_module torch fx GraphModule Lift up quant node before view like nodes It can benefit performance Attention like block For example we have pattern DQ DQ LINEAR LINEAR VIEW VIEW PERMUTE PERMUTE TRANSPOSE Q Q DQ DQ Matmul DIV ADD SOFTMAX We want lift up quant nodes matmul before view like nodes output Linear node DQ DQ LINEAR LINEAR Q Q VIEW VIEW PERMUTE PERMUTE TRANSPOSE DQ DQ Matmul DIV ADD SOFTMAX It produces DQ- LINEAR- Q pattern which can fused backend is_view_op node node op == call_function node target _VIEW_OPS node graph_module graph nodes TODO Leslie Here we verify quant node has exactly one input FX node constant scalar value scale zero point For case input quant node has more than one input FX nodes extend implementation lift up all connected nodes before view nodes keep topological order node op == call_function node target _PER_TENSOR_QUANTIZE_OPS len node all_input_nodes == is_view_op node all_input_nodes quant_node = node input_node_of_quant = quant_node args Check nodes along lift up path has only user node Propagate view like node find where insert new quant node could_lift_up = True current_node = quant_node input_node = current_node args while is_view_op input_node len input_node users = could_lift_up = False break current_node = input_node input_node = current_node args Further check input node first view node has only user node could_lift_up len input_node users == counters inductor quant_lift_up_count += Replace dequant s input quant quant s input quant_node replace_all_uses_with input_node_of_quant Insert new quant node graph_module graph inserting_before current_node new_quant_node = graph_module graph node_copy quant_node input_node replace_all_uses_with new_quant_node Update inputs new_quant_node maybe_replace_node n torch fx Node - torch fx Node n == input_node_of_quant input_node n new_args = map_arg new_quant_node args maybe_replace_node new_kwargs = map_arg new_quant_node kwargs maybe_replace_node new_quant_node args = new_args type ignore assignment new_quant_node kwargs = new_kwargs type ignore assignment graph_module graph erase_node quant_node graph_module graph lint graph_module recompile