Copyright c Meta Platforms Inc affiliates Owner s oncall distributed itertools unittest typing cast Optional torch torch nn functional F torch distributed init_device_mesh torch distributed tensor distribute_tensor DTensor Partial Placement Replicate Shard torch distributed tensor debug CommDebugMode torch testing _internal common_cuda PLATFORM_SUPPORTS_FP SM OrLater torch testing _internal common_device_type E M _MAX_POS e m _type torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests TEST_WITH_ROCM torch testing _internal distributed _tensor common_dtensor create_local_tensor_test_class DTensorTestBase skip_unless_torch_gpu with_comms funcol = torch ops c d_functional scale_for_fp t torch Tensor scale_shape tuple int - tuple torch Tensor torch Tensor all d == d scale_shape t = t unsqueeze unsqueeze - t = t unflatten scale_shape - unflatten - scale_shape - scale = t abs amax dim= - float E M _MAX_POS t_fp = t scale None None e m _type t_fp flatten end_dim= flatten start_dim=- scale view scale_shape DistMatrixOpsTest DTensorTestBase with_comms test_addmm device_mesh = build_device_mesh shard_spec = Shard replica_spec = Replicate tensor_to_shard = torch randn mat = distribute_tensor tensor_to_shard device_mesh shard_spec tensor_to_replicate = torch randn mat = distribute_tensor tensor_to_replicate device_mesh replica_spec input_tensor = torch randn input = distribute_tensor input_tensor device_mesh replica_spec dist_res = torch addmm input mat mat local_res = torch addmm input_tensor tensor_to_shard tensor_to_replicate assertEqual dist_res full_tensor local_res with_comms test_addmm_empty_operand device_mesh = build_device_mesh shard_spec = Shard replica_spec = Replicate tensor_to_shard = torch randn mat = distribute_tensor tensor_to_shard device_mesh shard_spec tensor_to_replicate = torch randn mat = distribute_tensor tensor_to_replicate device_mesh replica_spec input_tensor = torch randn inp = distribute_tensor input_tensor device_mesh replica_spec dist_res = torch addmm inp mat mat local_res = torch addmm input_tensor tensor_to_shard tensor_to_replicate assertEqual dist_res full_tensor local_res with_comms test_addmm_auto_redistribute device_mesh = build_device_mesh shard _spec = Shard shard _spec = Shard replica_spec = Replicate tensor_to_shard = torch randn requires_grad=True mat = distribute_tensor tensor_to_shard device_mesh shard _spec tensor_to_shard = torch randn requires_grad=True mat = distribute_tensor tensor_to_shard device_mesh shard _spec input_tensor = torch randn requires_grad=True input = distribute_tensor input_tensor device_mesh replica_spec local_res = torch addmm input_tensor tensor_to_shard tensor_to_shard dist_res = torch addmm input mat mat test addmm output partial assertIsInstance dist_res DTensor assertIsInstance dist_res placements Partial test result same tensor dist_local_res = dist_res full_tensor assertEqual local_res dist_local_res backward checks dist_local_res sum backward local_res sum backward assertIsNotNone mat grad assertEqual mat grad full_tensor tensor_to_shard grad with_comms test_mm device_mesh = build_device_mesh shard _spec = Shard shard _spec = Shard replica_spec = Replicate t = torch randn requires_grad=True t = torch randn requires_grad=True local_res = torch mm t t test_placement_comb placements list Placement placements list Placement - None dt = distribute_tensor t device_mesh placements dt = distribute_tensor t device_mesh placements dist_res DTensor = cast DTensor torch mm dt dt redistribute device_mesh replica_spec assertEqual dist_res to_local local_res backward grad_dist_res = torch ones_like dist_res dist_res backward grad_dist_res assertIsNotNone dt grad placement_specs = shard _spec shard _spec replica_spec shard_specs_comb = list itertools product placement_specs placement_specs spec shard_specs_comb test_placement_comb spec spec with_comms skip_unless_torch_gpu unittest skipIf PLATFORM_SUPPORTS_FP FP only supported H + SM MI + devices test_scaled_mm device_mesh = build_device_mesh shrd = Shard shrd = Shard repl = Replicate part = Partial ws = world_size _scaled_mm requires all dimensions multiples Since we ll shard along n k we need ensure stays true each rank m n k = ws ws t = torch randn m k device=self device_type dtype=torch bfloat t = torch randn n k device=self device_type dtype=torch bfloat output_spec t _spec t _spec scale _shape scale _shape scale _spec scale _spec Tensor-wise scaling Replicated zero-dim scale repl repl repl repl repl Column-parallel two-dim scale shrd repl shrd repl repl Row-parallel one-dim scale part shrd shrd repl repl Row-wise scaling Replicated repl repl repl m n repl repl Column-parallel shrd repl shrd m n repl shrd Row-parallel which actually ends up doing sub-row-wise scaling part shrd shrd m ws n ws shrd shrd full_ref_res = t t t t _fp scale = scale_for_fp t scale _shape t _fp scale = scale_for_fp t scale _shape dist_t _fp = distribute_tensor t _fp device_mesh t _spec dist_t _fp = distribute_tensor t _fp device_mesh t _spec dist_scale = distribute_tensor scale device_mesh scale _spec dist_scale = distribute_tensor scale device_mesh scale _spec CommDebugMode comm_mode dist_res = cast DTensor torch _scaled_mm dist_t _fp dist_t _fp t scale_a=dist_scale scale_b=dist_scale t out_dtype=torch bfloat assertEqual dist_res placements output_spec full_dist_res = dist_res full_tensor Fp matmuls quite inaccurate we need high tolerances assertEqual full_dist_res full_ref_res atol= rtol= e- assertEqual comm_mode get_total_counts with_comms test_matmul device_mesh = build_device_mesh dim = x = torch randn dim A = torch randn dim dim y = torch matmul x A Prepare DTensors dx = distribute_tensor x device_mesh Replicate dA = distribute_tensor A device_mesh Shard Use ` inference_mode ` test DTensor s capability decomposing ` matmul ` op torch inference_mode dy = torch matmul dx dA assertEqual y dy full_tensor with_comms test_t device_mesh = build_device_mesh shard_spec = Shard tensor_to_transpose = torch randn requires_grad=True mat = distribute_tensor tensor_to_transpose device_mesh shard_spec tranposed_mat = mat t assertEqual tranposed_mat size torch Size assertEqual tranposed_mat placements Shard tranposed_mat = tranposed_mat t assertEqual tranposed_mat size torch Size assertEqual tranposed_mat placements shard_spec with_comms test_t_partial device_mesh = build_device_mesh = torch randn b = torch randn c = torch mm b t da = distribute_tensor device_mesh Shard db = distribute_tensor b device_mesh Shard mm da db should Partial tensor transposing should keep Partial dc = torch mm da db t assertTrue isinstance dc placements Partial check local distributed op results match assertEqual c dc redistribute device_mesh Replicate to_local baddbmm introduces nan occasionally CPU https github com pytorch pytorch issues with_comms skip_unless_torch_gpu test_baddbmm device_mesh = build_device_mesh tensor = torch rand device=self device_type requires_grad=True batch_ = torch rand device=self device_type requires_grad=True batch_ = torch rand device=self device_type requires_grad=True test_placement_comb tensor_placements list Placement batch_ _placements list Placement batch_ _placements list Placement beta int alpha int batch_ _grad Optional torch Tensor - None tensor_dt = distribute_tensor tensor device_mesh tensor_placements batch_ _dt = distribute_tensor batch_ device_mesh batch_ _placements batch_ _dt = distribute_tensor batch_ device_mesh batch_ _placements dist_res = cast DTensor torch baddbmm tensor_dt batch_ _dt batch_ _dt beta=beta alpha=alpha redistribute device_mesh Replicate dist_local_res = dist_res to_local assert torch isnan local_result any assert torch isnan dist_local_res any assertEqual dist_local_res detach local_result detach TODO add test backward grad_dist_res = torch ones_like dist_res dist_res backward grad_dist_res assertIsNotNone batch_ _dt grad batch_ _grad_local = batch_ _dt grad redistribute device_mesh Replicate to_local assertEqual batch_ _grad_local batch_ _grad shard _spec = Shard shard _spec = Shard shard _spec = Shard replica_spec = Replicate shard_specs = shard _spec shard _spec shard _spec replica_spec shard_specs_comb = list itertools product shard_specs shard_specs shard_specs If beta input tensor will ignored numeric_params_comb = zero-beta non-zero-beta beta alpha numeric_params_comb local_result = torch baddbmm tensor batch_ batch_ beta=beta alpha=alpha grad_local_res = torch ones_like local_result local_result backward grad_local_res test all combos spec shard_specs_comb test_placement_comb spec spec spec beta alpha batch_ grad with_comms test_bmm device_mesh = build_device_mesh mat = torch rand device=self device_type requires_grad=True mat = torch rand device=self device_type requires_grad=True local_result = torch bmm mat mat grad_local_res = torch ones_like local_result local_result backward grad_local_res test_placement_comb placements list Placement placements list Placement - None mat _dt = distribute_tensor mat device_mesh placements mat _dt = distribute_tensor mat device_mesh placements dist_res = cast DTensor torch bmm mat _dt mat _dt redistribute device_mesh Replicate dist_local_res = dist_res to_local assertEqual dist_local_res local_result test backward TODO figure out replicate shard fail backward generates different grad shape grad_dist_res = torch ones_like dist_res dist_res backward grad_dist_res assertIsNotNone mat _dt grad mat _dt_grad = cast DTensor mat _dt grad mat _grad_local = mat _dt_grad redistribute device_mesh Replicate to_local assertEqual mat _grad_local mat grad shard _spec = Shard shard _spec = Shard shard _spec = Shard replica_spec = Replicate placement_specs = shard _spec shard _spec shard _spec replica_spec shard_specs_comb = list itertools product placement_specs placement_specs tests currently pass spec shard_specs_comb test_placement_comb spec spec with_comms skip_unless_torch_gpu test_scaled_dot_product_attention device_mesh = build_device_mesh comm_mode = CommDebugMode bsz n_heads slen head_dim query = torch rand device=self device_type dtype=torch bfloat requires_grad=True key = torch rand device=self device_type dtype=torch bfloat requires_grad=True value = torch rand device=self device_type dtype=torch bfloat requires_grad=True torch nn attention sdpa_kernel SDPBackend available_backends = dropout_p = TODO Add test cases where is_causal=False attention mask provided Gaps include missing op support aten masked_fill_ Scalar is_causal = True enable_gqa = False params = torch backends cuda SDPAParams query key value None dropout_p is_causal enable_gqa torch backends cuda can_use_flash_attention params debug=False available_backends append SDPBackend FLASH_ATTENTION torch backends cuda can_use_efficient_attention params debug=False available_backends append SDPBackend EFFICIENT_ATTENTION placement_specs = Replicate Shard Shard backend input_placements itertools product available_backends placement_specs dist_query = distribute_tensor query device_mesh input_placements dist_key = distribute_tensor key device_mesh input_placements dist_value = distribute_tensor value device_mesh input_placements sdpa_kernel backends= backend out = F scaled_dot_product_attention query key value dropout_p=dropout_p is_causal=is_causal comm_mode dist_out = F scaled_dot_product_attention dist_query dist_key dist_value dropout_p=dropout_p is_causal=is_causal assertEqual comm_mode get_total_counts assertEqual dist_out placements input_placements assertEqual dist_out full_tensor out out sum backward comm_mode dist_out sum backward assertEqual comm_mode get_total_counts assertEqual dist_query grad placements input_placements assertEqual dist_query grad full_tensor query grad assertEqual dist_key grad placements input_placements assertEqual dist_key grad full_tensor key grad assertEqual dist_value grad placements input_placements assertEqual dist_value grad full_tensor value grad query grad zero_ key grad zero_ value grad zero_ skip_unless_torch_gpu with_comms test_dtensor_mm Test mm DTensor D mesh We need add test here since we only test D mesh test_dtensor_ops py Also we added tests corner case where one D dimension TODO we need test more DTensor ops D mesh especially when mesh dimension D mesh mesh_ = init_device_mesh device_type world_size mesh_ = init_device_mesh device_type world_size mesh_ = init_device_mesh device_type world_size mesh mesh_ mesh_ mesh_ lhs = torch randn rhs = torch randn mm_result = lhs rhs lhs_dtensor = distribute_tensor lhs mesh Shard dim= Replicate rhs_dtensor = distribute_tensor rhs mesh Replicate Shard dim= dtensor_result = lhs_dtensor rhs_dtensor assertEqual dtensor_result full_tensor mm_result atol= e- rtol= e- with_comms skip_unless_torch_gpu test_tensordot_shampoo Create simple test Shampoo s use case device_mesh = build_device_mesh local_a = torch randn local_b = torch randn dims = local_result = torch tensordot local_a local_b dims= dims placements = Replicate Shard Shard placements_tuples = itertools product placements repeat= placement placement placements_tuples dist_a = distribute_tensor local_a device_mesh placement dist_b = distribute_tensor local_b device_mesh placement dist_result = torch tensordot dist_a dist_b dims=dims dist_result_full = dist_result full_tensor assertEqual local_result dist_result_full unittest skipIf TEST_WITH_ROCM ROCm doesn t support CUTLASS unittest skipIf SM OrLater Grouped gemm supported SM with_comms skip_unless_torch_gpu parametrize kwargs D x D case MoE layer inp_shape w _shape w _shape inp_placements Replicate w _placements Shard w _placements Shard expected_comm_counts_fwd expected_comm_counts_bwd expected_out_placements Partial Case would have invalid strides inp mat when sharded inp_shape w _shape w _shape inp_placements Replicate w _placements Shard w _placements Shard expected_comm_counts_fwd expected_comm_counts_bwd expected_out_placements Replicate test_grouped_mm kwargs TODO torch _grouped_mm can take inputs dimension D D x D D More tests need added device_mesh = build_device_mesh comm_mode = CommDebugMode dtype = torch bfloat inp = torch rand kwargs inp_shape device=self device_type dtype=dtype requires_grad=True w = torch rand kwargs w _shape device=self device_type dtype=dtype requires_grad=True w = torch rand kwargs w _shape device=self device_type dtype=dtype requires_grad=True offs = torch tensor device=self device_type dtype=torch int h = torch _grouped_mm inp w offs=offs out = torch _grouped_mm h w offs=offs dist_inp = distribute_tensor inp device_mesh kwargs inp_placements colwise sharded dist_w = distribute_tensor w device_mesh kwargs w _placements rowwise sharded dist_w = distribute_tensor w device_mesh kwargs w _placements dist_offs = distribute_tensor offs device_mesh Replicate comm_mode dist_h = torch _grouped_mm dist_inp dist_w offs=dist_offs dist_out = torch _grouped_mm dist_h dist_w offs=dist_offs assertEqual comm_mode get_total_counts kwargs expected_comm_counts_fwd assertEqual dist_out placements kwargs expected_out_placements assertEqual dist_out full_tensor out out_grad = torch ones_like out out backward out_grad dist_out = dist_out redistribute device_mesh Shard dist_out_grad = distribute_tensor out_grad device_mesh Shard comm_mode dist_out backward dist_out_grad assertEqual comm_mode get_total_counts kwargs expected_comm_counts_bwd assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor kwargs expected_comm_counts_bwd assertEqual dist_inp grad full_tensor inp grad assertEqual dist_w grad full_tensor w grad assertEqual dist_w grad full_tensor w grad instantiate_parametrized_tests DistMatrixOpsTest DistMatrixOpsTestWithLocalTensor = create_local_tensor_test_class DistMatrixOpsTest __name__ == __main__ run_tests