Owner s module onnx io numpy np onnx pytorch_test_common pytorch_test_common skipIfUnsupportedMinOpsetVersion torch torch onnx _constants utils torch onnx _internal torchscript_exporter jit_utils torch onnx _internal torchscript_exporter _globals GLOBALS torch testing _internal common_utils expect_tensor scalar_type shape=None verify actual_type np testing assert_equal actual_type scalarType scalar_type shape None np testing assert_equal actual_type sizes shape shape None np testing assert_equal actual_type varyingSizes shape verify as_graphcontext graph torch Graph - jit_utils GraphContext jit_utils GraphContext graph=graph block=graph block opset=_constants ONNX_TORCHSCRIPT_EXPORTER_MAX_OPSET original_node=None type ignore arg-type params_dict= env= values_in_env=set g_op graph torch Graph op_name str args kwargs as_graphcontext graph op op_name args kwargs TestONNXShapeInference pytorch_test_common ExportTestCase setUp opset_version = _constants ONNX_TORCHSCRIPT_EXPORTER_MAX_OPSET GLOBALS export_onnx_opset_version = opset_version run_test g n type_assertion_funcs isinstance type_assertion_funcs list type_assertion_funcs = type_assertion_funcs torch _C _jit_pass_onnx_graph_shape_type_inference g opset_version out type_assertion_func zip n outputs type_assertion_funcs type_assertion_func out type create_empty_graph g = torch _C Graph kick off initialization ConstantMap torch _C _jit_pass_onnx_graph_shape_type_inference g opset_version g insert_tensor_constant g tensor g_op g Constant value_t=tensor test_cast Test cast input unknown scalar type g = create_empty_graph input = g addInput cast_out = g_op g Cast input to_i= run_test g cast_out node expect_tensor Float test_constant_of_shape Test ConstantOfShape input onnx Shape node g = create_empty_graph constant = insert_tensor_constant g torch ones shape = g_op g Shape constant constant_of_shape = g_op g ConstantOfShape shape value_t=torch tensor run_test g constant_of_shape node expect_tensor Float shape= test_constant_of_shape_static Test ConstantOfShape input prim ListConstruct static tensor rank = g = create_empty_graph constants = insert_tensor_constant g torch tensor i + i range rank shape = g_op g prim ListConstruct constants shape setType torch _C ListType ofInts constant_of_shape = g_op g ConstantOfShape shape value_t=torch tensor run_test g constant_of_shape node expect_tensor Float shape= test_constant_of_shape_dynamic Test ConstantOfShape input prim ListConstruct dynamic tensor rank = g = create_empty_graph inputs = g addInput i range rank shape = g_op g prim ListConstruct inputs shape setType torch _C ListType ofInts constant_of_shape = g_op g ConstantOfShape shape value_t=torch tensor run_test g constant_of_shape node expect_tensor Float shape= None None None None test_gather_dynamic_index g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes None indices = g addInput indices setType indices type with_dtype torch int with_sizes None output = g_op g Gather input indices axis_i= run_test g output node expect_tensor Float shape= None None test_gather_scalar_index g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes None indices = insert_tensor_constant g torch tensor output = g_op g Gather input indices axis_i= run_test g output node expect_tensor Float shape= None test_reshape g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch tensor - shape = g_op g Reshape constant constant_ run_test g shape node expect_tensor Float shape= g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch tensor - shape = g_op g Reshape constant constant_ run_test g shape node expect_tensor Float shape= g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch tensor - shape = g_op g Reshape constant constant_ run_test g shape node expect_tensor Float shape= test_reshape_symbolic g = create_empty_graph input = g addInput input setType input type with_sizes None None constant = insert_tensor_constant g torch tensor - output = g_op g Reshape input constant run_test g output node expect_tensor None shape= None None skipIfUnsupportedMinOpsetVersion test_reshape_allowzero g = create_empty_graph input = g addInput input setType input type with_sizes constant = insert_tensor_constant g torch tensor output = g_op g Reshape input constant allowzero_i= run_test g output node expect_tensor None shape= test_slice g = create_empty_graph input = g addInput input setType input type with_sizes None None start_input = g addInput start_input setType start_input type with_sizes None end = insert_tensor_constant g torch tensor axis = insert_tensor_constant g torch tensor step = insert_tensor_constant g torch tensor slice = g_op g Slice input start_input end axis step run_test g slice node expect_tensor None shape= None None test_slice_with_dynamic_start_index g = create_empty_graph input = insert_tensor_constant g torch ones start_input = g addInput start_input setType start_input type with_sizes end = insert_tensor_constant g torch tensor axis = insert_tensor_constant g torch tensor - slice = g_op g Slice input start_input end axis run_test g slice node expect_tensor None shape= None None test_broadcast_matmul g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch ones shape = g_op g MatMul constant constant_ run_test g shape node expect_tensor Float shape= test when first input rank g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch ones shape = g_op g MatMul constant constant_ run_test g shape node expect_tensor Float shape= test when second input rank g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch ones shape = g_op g MatMul constant constant_ run_test g shape node expect_tensor Float shape= test when both inputs rank g = create_empty_graph constant = insert_tensor_constant g torch ones constant_ = insert_tensor_constant g torch ones shape = g_op g MatMul constant constant_ run_test g shape node expect_tensor Float shape= test_expand g = create_empty_graph input = g addInput constant = insert_tensor_constant g torch ones input setType constant type with_sizes None None shape = g_op g Shape input expand = g_op g Expand constant shape run_test g expand node expect_tensor Float shape= None None test_pad g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes constant = insert_tensor_constant g torch ones dtype=torch long none = g_op g prim Constant setType torch NoneType get pad = g_op g Pad input constant none mode_s= constant run_test g pad node expect_tensor Float shape= test_pad_with_dynamic_input_shape g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes None None constant = insert_tensor_constant g torch ones dtype=torch long none = g_op g prim Constant setType torch NoneType get pad = g_op g Pad input constant none mode_s= constant run_test g pad node expect_tensor Float shape= None None test_pad_with_dynamic_pad_size g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes pad_size = g addInput pad_size setType pad_size type with_dtype torch long with_sizes none = g_op g prim Constant setType torch NoneType get pad = g_op g Pad input pad_size none mode_s= constant run_test g pad node expect_tensor Float shape= None None None test_resize g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes none = g_op g prim Constant setType torch NoneType get scales = insert_tensor_constant g torch tensor dtype=torch float resize = g_op g Resize input none scales coordinate_transformation_mode_s= align_corners cubic_coeff_a_f=- mode_s= linear nearest_mode_s= floor run_test g resize node expect_tensor Float shape= test_resize_after_concat g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes none = g_op g prim Constant setType torch NoneType get scale_ = insert_tensor_constant g torch tensor dtype=torch float scale_ = insert_tensor_constant g torch tensor dtype=torch float ` scales ` values should statically known due constant folding shape inference scales = g_op g Concat scale_ scale_ axis_i= resize = g_op g Resize input none scales coordinate_transformation_mode_s= align_corners cubic_coeff_a_f=- mode_s= linear nearest_mode_s= floor run_test g resize node expect_tensor Float shape= test_reduce_prod_with_axes g = create_empty_graph input = g addInput input setType input type with_dtype torch long with_sizes reduce_prod = g_op g ReduceProd input axes_i= run_test g reduce_prod node expect_tensor Long shape= test_reduce_prod_without_axes g = create_empty_graph input = g addInput input setType input type with_dtype torch long with_sizes reduce_prod = g_op g ReduceProd input run_test g reduce_prod node expect_tensor Long shape= test_proceeding_nodes_use_prim_pack_padded_output_dtype_correctly g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes length = g addInput length setType length type with_dtype torch long with_sizes padded batch_size = g_op g prim PackPadded input length outputs= ` prim PackPadded ` only occurs tracing mode Hence its outputs inherits shape data type traced graph padded setType padded type with_dtype torch float with_sizes None None batch_size setType batch_size type with_dtype torch long with_sizes None ` Gather ` should use data type ` batch_size ` data type its output gather_idx = insert_tensor_constant g torch tensor dtype=torch long gather = g_op g Gather batch_size gather_idx axis_i= run_test g gather node expect_tensor Long shape= None test_squeeze_after_dynamic_if torch onnx symbolic_opset squeeze squeeze g = create_empty_graph input = g addInput input setType input type with_dtype torch float with_sizes None Type intentionally bool test added Cast node doesn t stop shape inference cond = g addInput cond setType input type with_dtype torch int with_sizes _ if_context else_context new_node = jit_utils add_op_with_blocks as_graphcontext g If cond n_blocks= block _output = if_context op Add input input block _output = else_context op Identity input utils _add_output_to_block if_context block block _output utils _add_output_to_block else_context block block _output if_output = torch _C _jit_pass_fixup_onnx_controlflow_node new_node _constants ONNX_TORCHSCRIPT_EXPORTER_MAX_OPSET torch _C _jit_pass_onnx_node_shape_type_inference new_node _constants ONNX_TORCHSCRIPT_EXPORTER_MAX_OPSET Exporter will add If instead raw Squeeze does know dimension squeezing has size squeezed = squeeze as_graphcontext g if_output dim= assert squeezed node kind == onnx Squeeze run_test g squeezed node expect_tensor Float shape= None TestONNXCustomOpShapeInference pytorch_test_common ExportTestCase setUp super setUp opset_version = _constants ONNX_TORCHSCRIPT_EXPORTER_MAX_OPSET test_setType_maintains_output_shape_for_single_custom_op addCleanup torch onnx unregister_custom_op_symbolic linalg_inv CustomInverse torch nn Module forward x torch inverse x + x linalg_inv_settype g g op com microsoft Inverse setType type torch onnx register_custom_op_symbolic linalg_inv linalg_inv_settype model = CustomInverse x = torch randn f = io BytesIO torch onnx export model x f opset_version=self opset_version custom_opsets= com microsoft dynamo=False model_proto = onnx load io BytesIO f getvalue model_value_info = model_proto graph value_info assertIsNotNone model_value_info assert model_value_info dims = model_value_info type tensor_type shape dim i range len dims If node output has shape info should have dim_value Otherwise has dim_params dynamic shape assertTrue dims i HasField dim_value dim rank zip dims x size assertEqual dim dim_value rank test_no_setType_for_single_custom_op addCleanup torch onnx unregister_custom_op_symbolic linalg_inv CustomInverse torch nn Module forward x torch inverse x + x linalg_inv_no_settype g g op com microsoft Inverse torch onnx register_custom_op_symbolic linalg_inv linalg_inv_no_settype model = CustomInverse x = torch randn f = io BytesIO torch onnx export model x f opset_version=self opset_version custom_opsets= com microsoft dynamo=False model_proto = onnx load io BytesIO f getvalue model_value_info = model_proto graph value_info assertIsNotNone model_value_info assert model_value_info dims = model_value_info type tensor_type shape dim i range len dims If node output has shape info should have dim_value Otherwise has dim_params dynamic shape assertTrue dims i HasField dim_param test_setType_maintains_output_shape_for_single_custom_op_with_dynamic_axes addCleanup torch onnx unregister_custom_op_symbolic linalg_inv CustomInverse torch nn Module forward x torch inverse x + x linalg_inv_settype g g op com microsoft Inverse setType type with_dtype torch float with_sizes None torch onnx register_custom_op_symbolic linalg_inv linalg_inv_settype model = CustomInverse x = torch randn f = io BytesIO torch onnx export model x f opset_version=self opset_version custom_opsets= com microsoft input_names= x dynamic_axes= x batch dynamo=False model_proto = onnx load io BytesIO f getvalue model_value_info = model_proto graph value_info assertIsNotNone model_value_info assert model_value_info dims = model_value_info type tensor_type shape dim The first axe should dynamic we defined when exporting assertTrue dims HasField dim_param i range len dims If node output has shape info should have dim_value Otherwise has dim_params dynamic shape assertTrue dims i HasField dim_value assertEqual dims i dim_value x size i test_setType_maintains_output_shape_for_single_custom_op_with_onnx_ops addCleanup torch onnx unregister_custom_op_symbolic linalg_inv CustomInverse torch nn Module forward x y z x = torch inverse x x + y + z linalg_inv_settype g g op com microsoft Inverse setType type with_dtype torch float with_sizes torch onnx register_custom_op_symbolic linalg_inv linalg_inv_settype model = CustomInverse x = torch randn y = torch randn z = torch randn f = io BytesIO torch onnx export model x y z f opset_version=self opset_version custom_opsets= com microsoft dynamo=False model_proto = onnx load io BytesIO f getvalue To validate shape inverse Op we need find inverse output name then use identify its value_info shape output_name = node model_proto graph node node op_type == Inverse output_name = node output break assert output_name model_value_info = model_proto graph value_info assertIsNotNone model_value_info assert model_value_info value_info model_value_info assert value_info name value_info name == output_name dims = value_info type tensor_type shape dim i range len dims If node output has shape info should have dim_value Otherwise has dim_params dynamic shape assertTrue dims i HasField dim_value dim rank zip dims x size assertEqual dim dim_value rank __name__ == __main__ common_utils run_tests