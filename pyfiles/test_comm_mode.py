Owner s oncall distributed torch torch distributed dist torch distributed _functional_collectives funcol torch nn nn torch distributed tensor DeviceMesh DTensor Shard torch distributed tensor debug CommDebugMode torch testing _internal common_distributed requires_nccl torch testing _internal common_utils run_tests TestCase torch testing _internal distributed _tensor common_dtensor MLPModule torch testing _internal distributed fake_pg FakeStore c d_functional = torch ops c d_functional c d_ops = torch ops c d TestCommMode TestCase tearDown super tearDown dist destroy_process_group setUp super setUp world_size = store = FakeStore dist init_process_group backend= fake rank= world_size=self world_size store=store device_type = cuda torch cuda is_available cpu world_pg = dist distributed_c d _get_default_group checksAssert comm_mode key expected_value expected_total_value comm_counts = comm_mode get_comm_counts assertEqual comm_mode get_total_counts expected_total_value assertEqual comm_counts key expected_value test_comm_mode world_pg = world_pg WrapperModel nn Module __init__ device super __init__ model = MLPModule device=device forward x x = funcol all_gather_tensor x world_pg x = funcol reduce_scatter_tensor x sum world_pg out = model x funcol all_reduce out sum world_pg model = WrapperModel device_type comm_mode = CommDebugMode comm_mode model torch randn device=self device_type comm_counts = comm_mode get_comm_counts assertEqual comm_mode get_total_counts assertEqual comm_counts c d_functional all_reduce assertEqual comm_counts c d_functional all_gather_into_tensor assertEqual comm_counts c d_functional reduce_scatter_tensor test_comm_mode_coalesced world_pg = world_pg WrapperModelCoalesced nn Module __init__ device super __init__ model = MLPModule device=device forward x x = funcol all_gather_tensor x world_pg x = funcol reduce_scatter_tensor x sum world_pg out = model x funcol all_reduce_coalesced out sum world_pg model = WrapperModelCoalesced device_type comm_mode = CommDebugMode comm_mode model torch randn device=self device_type comm_counts = comm_mode get_comm_counts assertEqual comm_mode get_total_counts assertEqual comm_counts c d_functional all_reduce_coalesced assertEqual comm_counts c d_functional all_gather_into_tensor assertEqual comm_counts c d_functional reduce_scatter_tensor test_comm_mode_with_dtensor mesh = DeviceMesh device_type list range world_size f x y torch mm x y comm_mode = CommDebugMode x = torch randn requires_grad=True y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard run_check=False y_dtensor = DTensor from_local y mesh Shard run_check=False comm_mode f x_dtensor y_dtensor comm_counts = comm_mode get_comm_counts assertEqual comm_mode get_total_counts assertEqual comm_counts c d_functional all_reduce assertEqual comm_counts c d_functional all_gather_into_tensor assertEqual comm_counts c d_functional reduce_scatter_tensor requires_nccl test_comm_mode_with_c d torch cuda is_available inp = torch rand cuda all_gather_out = inp new_empty world_size comm_mode = CommDebugMode tests c d all_reduce tracing comm_mode dist all_reduce inp checksAssert comm_mode c d_ops allreduce_ tests c d all_gather_into_tensor tracing comm_mode dist all_gather_into_tensor all_gather_out inp checksAssert comm_mode c d_ops _allgather_base_ tests c d reduce_scatter tracing comm_mode dist reduce_scatter_tensor inp all_gather_out checksAssert comm_mode c d_ops _reduce_scatter_base_ tests c d broadcast tracing comm_mode dist broadcast inp checksAssert comm_mode c d_ops broadcast_ tests c d gather tracing comm_mode dist gather inp None checksAssert comm_mode c d_ops gather_ tests c d reduce tracing comm_mode dist reduce inp checksAssert comm_mode c d_ops reduce_ tests c d scatter tracing comm_mode dist scatter inp None checksAssert comm_mode c d_ops scatter_ tests c d all_gather tracing output_list = comm_mode dist all_gather output_list inp None checksAssert comm_mode c d_ops allgather_ tests c d allgather_coalesced_ tracing output_list = comm_mode dist all_gather_coalesced output_list inp None checksAssert comm_mode c d_ops allgather_coalesced_ tests c d allgather_into_tensor_coalesced_ tracing comm_mode dist _coalescing_manager dist all_gather_into_tensor all_gather_out inp checksAssert comm_mode c d_ops allgather_into_tensor_coalesced_ tests c d allreduce_coalesced comm_mode dist all_reduce_coalesced inp checksAssert comm_mode c d_ops allreduce_coalesced_ tests c d reduce_scatter_ comm_mode dist reduce_scatter all_gather_out inp checksAssert comm_mode c d_ops reduce_scatter_ tests c d reduce_scatter_tensor_coalesced comm_mode dist _coalescing_manager dist reduce_scatter_tensor all_gather_out inp checksAssert comm_mode c d_ops reduce_scatter_tensor_coalesced_ tests c d alltoall_ comm_mode dist all_to_all inp inp checksAssert comm_mode c d_ops alltoall_ tests c d alltoall_base_ comm_mode dist all_to_all_single inp inp checksAssert comm_mode c d_ops alltoall_base_ __name__ == __main__ run_tests