csv os re sys This script takes logs produced benchmark scripts e g torchbench py parses into CSV file summarizes what failing why It kept separate benchmark script emitting more structured output often more convenient iterate quickly log files offline instead having make change benchmark script then do full sweep see updates This script very well written feel free rewrite necessary assert len sys argv == full_log = open sys argv read If log contains gist URL extract so we can include CSV gist_url = m = re search r https gist github com a-f - + full_log m None gist_url = m group Split log into entry per benchmark entries = re split r cuda train &#124; eval + ^ + &#124; WARNING root ^ + failed load full_log Entries schema example ` hf_Bert None PASS\nTIMING entire_frame_compile backend_compile e- \nDynamo produced graph s covering ops\n ` chunker seq size seq pos pos + size pos range len seq size c = i = out = csv DictWriter sys stdout bench name result component context explain frame_time backend_time graph_count op_count graph_breaks unique_graph_breaks dialect= excel out writeheader out writerow explain gist_url Sometimes backtraces will third party code which results very long file names Delete absolute path case normalize_file f site-packages f f split site-packages os path relpath f Assume we run torchbench huggingface timm_models order output doesn t say which suite benchmark part TODO make more robust bench = torchbench = + number matches entries split regex name name log chunker entries name None name = name name startswith Albert bench = huggingface name startswith adv_inc bench = timm_models Payload will go into csv r = UNKNOWN explain = component = context = PASS log r = PASS TIMEOUT log r = FAIL TIMEOUT Accuracy failed log r = FAIL ACCURACY Attempt extract out useful information traceback log = log split The above exception direct cause following exception split = log split Traceback most recent call last maxsplit= len split == log = split log = log split Original traceback m = re search r File ^ + line - + +\n + + \n A-Za-z + Error &#124; Exception &#124; NotImplementedError log m None r = FAIL component = f normalize_file m group m group context = m group explain = f m group m = re search r File ^ + line - + +\n + + \nAssertionError log m None r = FAIL component = f normalize_file m group m group context = m group explain = AssertionError Sometimes benchmark will say FAIL without any useful info See https github com pytorch torchdynamo issues FAIL log r = FAIL r == UNKNOWN c += backend_time = None frame_time = None TIMING log result = re search TIMING \n log group split_str = result split backend_compile len split_str == backend_time = float split_str frame_time = float split_str split entire_frame_compile STATS log result = re search STATS \n log group call_ op count &#124; FakeTensor __torch_dispatch__ &#124; ProxyTorchDispatchMode __torch_dispatch__ split_all = result split &#124; TODO rewrite work arbitrarily many stats graph_count = None op_count = None graph_breaks = None unique_graph_breaks = None m = re search r Dynamo produced \d+ graphs covering \d+ ops \d+ graph breaks \ \d+ unique\ log graph_count = m group op_count = m group graph_breaks = m group unique_graph_breaks = m group If context string too long don t put CSV This hack try make more likely Google Sheets will offer split columns len context context = Temporary file names meaningless report s generated code case tmp component component = generated code context = out writerow bench bench name name result r component component context context explain explain frame_time frame_time backend_time backend_time graph_count graph_count op_count op_count graph_breaks graph_breaks unique_graph_breaks unique_graph_breaks i += noqa SIM c print f failed classify c entries file=sys stderr