math os sys collections OrderedDict dataclasses astuple dataclass typing Any NamedTuple Optional typing_extensions Self torch torch nan nn UntypedStorage torch _guards active_fake_mode torch _subclasses fake_tensor FakeTensorMode torch distributed _tools common_utils get_untyped_storages torch distributed _tools mod_tracker ModTracker torch distributed _tools runtime_estimator RuntimeEstimator torch testing _internal composite_compliance is_inplace is_inplace_view_fn is_view_fn torch utils _python_dispatch TorchDispatchMode torch utils _pytree tree_flatten torch utils checkpoint SAC_IGNORED_OPS __all__ = SACEstimator SACStats MSPS SACTradeOffStats SACGreedyOrderMeta aten = torch ops aten _ADDITIONAL_IGNORED_OPS = aten lift_fresh default type ignore attr-defined torch ops profiler _record_function_exit _RecordFunction type ignore attr-defined aten clone default type ignore attr-defined seems needed torch compile OPS_TO_ALWAYS_SKIP = SAC_IGNORED_OPS &#124; _ADDITIONAL_IGNORED_OPS This value hard-coded here https github com pytorch pytorch blob fba d f ff ab e ad fd c cuda CUDACachingAllocator cpp#L _PYTORCH_MIN_ALLOCATE = int os environ get PYTORCH_NO_CUDA_MEMORY_CACHING == _display_stats_tabular headers list str table_data list list Any - None try tabulate tabulate except ImportError err raise ImportError Please install tabulate err Use tabulate print table print tabulate table_data headers=headers tablefmt= rst Based https github com facebookresearch xformers blob main xformers checkpoint py#L dataclass _SACMetadata Stores metadata single operator SAC Attributes func Any The operator function time_taken float The time taken operator memory_used float The memory used operator curr_idx int The current operator index output_ids Tuple int The storage IDs operator s outputs inplace_info Tuple int Tuple parent operator in-place operator is_view_like bool Whether operator view-like is_rand_op bool Whether operator random operator func Any time_taken float memory_used float curr_idx int output_ids tuple int inplace_info tuple int is_view_like bool is_rand_op bool dataclass _SACModMetadata Stores metadata module SAC Attributes start_idx int The starting index module s operators force_store_random bool Whether force store random operators module sac_metadata List _SACMetadata List metadata each operator module start_idx int force_store_random bool sac_metadata list _SACMetadata dataclass SACStats A storing Activation Checkpointing statistics corresponding module Attributes func_names List str List operator names runtimes List float List operator runtimes millliseconds memory List int List operator memory usage bytes view_like_ops List int Indices view-like operators rand_ops List int Indices random operators saved_autograd_ops List int Indices operator results saved autograd engine inplace_ops List Tuple int int Tuple indices op its first parent Inplace operators force_store_random bool Whether force store random operator results func_names list str runtimes list float memory list int view_like_ops list int rand_ops list int saved_autograd_ops list int inplace_ops list tuple int int force_store_random bool MSPS NamedTuple Represents Memory Runtime Statistics operator operator group Attributes func_names set str Set operator operator group names op_idx int Operator index group head index case operator groups memory int Memory usage bytes runtime float Runtime milliseconds msps float Memory per second calculated memory runtime func_names set str op_idx int memory int runtime float msps float dataclass SACTradeOffStats Stores statistics activation-checkpointing trade-off Attributes n_segments int Number piecewise linear segments fitted trade-off curve slopes List float Slopes pieces linear segments fitted trade-off curve intercepts List float Intercepts pieces linear segments fitted trade-off curve fit_breaks List float Breakpoints pieces linear segments fitted trade-off curve tradeoff_curve OrderedDict float float Trade-off curve data memory discarded vs recomputation time sac_memory int Total memory operations available activation checkpointing bytes sac_runtime float Total runtime operations available activation checkpointing milliseconds n_segments int slopes list float intercepts list float fit_breaks list float tradeoff_curve OrderedDict float float sac_memory int sac_runtime float dataclass SACGreedyOrderMeta Stores metadata Greedy-order SAC Attributes recomputed_ops set int Set operator indices recomputed stored_ops set int Set operator indices stored inplace_op_groups dict int set int Dictionary inplace operator groups group-head operators random_ops_group dict int set int Dictionary random op group head random ops msps_meta list MSPS List Memory Runtime Statistics operators recomputed_ops set int stored_ops set int inplace_op_groups dict int set int random_ops_group dict int set int msps_meta list MSPS SACEstimator TorchDispatchMode Estimates memory recomputation time trade-offs applying Selective Activation Checkpointing SAC This provides ` ` TorchDispatchMode ` ` based context manager can used estimate memory runtime trade-offs functions ` ` torch nn Module ` ` s Selective Activation Checkpointing SAC It provides detailed statistics metadata information operators each module provides greedy order selecting operators recomputed checkpointed It also constructs per-module trade-off graph discarded memory vs recomputation time obtained greedy order Using ` ` RuntimeEstimator ` ` under hood supports two estimation modes ` operator-level-benchmark ` ` operator-level-cost-model ` roofline model Attributes sac_mod_stats Dict str SACStats Dictionary module FQN fully qualified name ` ` SACStats ` ` sac_mod_tradeoff_stats Dict str SACTradeOffStats Dictionary module FQN ` ` SACTradeOffStats ` ` sac_mod_greedy_order_meta Dict str SACGreedyOrderMeta Dictionary module FQN ` ` SACGreedyOrderMeta ` ` Note This designed used under ` ` FakeTensorMode ` ` Currently only supports estimation compute time memory usage does consider communication Example usage code-block python sac_estimator = SACEstimator FakeTensorMode module = inp = sac_estimator operator-level-cost-model output = module inp sac_estimator display_modulewise_sac_stats depth= print_tabular=True __init__ - None sac_mod_stats dict str SACStats = sac_mod_tradeoff_stats dict str SACTradeOffStats = sac_mod_greedy_order_meta dict str SACGreedyOrderMeta = _mod_tracker = ModTracker _sac_metadata list _SACMetadata = _sac_mod_metadata dict str _SACModMetadata = _leaf_modules set str = set _saved_tensor_hook_ctx = torch autograd graph saved_tensors_hooks _pack_hook lambda x x _saved_tensor_ids set int = set _estimate_runtime = RuntimeEstimator _roofline_estimate _pack_hook x torch Tensor - torch Tensor Hook function track underlying storage IDs tensors Updates _saved_tensor_ids set IDs tensor s storages Used conjunction torch autograd graph saved_tensors_hooks untyped_storages = get_untyped_storages x storage_ids = hash st st untyped_storages _saved_tensor_ids update storage_ids x _pre_fw_hook mod nn Module inputs Any - None Pre-forward hook function prepare module metadata Tracks module FQN force store random flag ` ` SACModMetadata ` ` Initializes metadata non-leaf modules marks leaf modules mod_fqn = _mod_tracker get_known_fqn mod assert mod_fqn None num_children = sum _ mod children num_children force_store_random = _get_force_store_random inputs _sac_mod_metadata mod_fqn = _SACModMetadata start_idx=len _sac_metadata force_store_random=force_store_random sac_metadata= _leaf_modules add mod_fqn _post_fw_hook mod nn Module inputs Any outputs Any - None Retrieves module s FQN checks s leaf module If leaf module computes - ` ` SACStats ` ` using module s metadata force store random flag - ` ` SACGreedyOrderMeta ` ` using computed SAC statistics mod_fqn = _mod_tracker get_known_fqn mod assert mod_fqn None mod_fqn _leaf_modules sac_mod_stats mod_fqn = _get_sac_stats data=self _sac_mod_metadata mod_fqn sac_metadata force_store_random=self _sac_mod_metadata mod_fqn force_store_random sac_mod_greedy_order_meta mod_fqn = _get_greedy_order_meta sac_mod_stats mod_fqn _get_force_store_random inputs Any - bool flat_inputs _ = tree_flatten inputs all isinstance x torch Tensor x flat_inputs _get_sac_stats data list _SACMetadata force_store_random bool - SACStats Ignore operations should skipped SAC such aten detach default because autograd inserts those during backward breaks fwd-bwd alignment filtered_data = x x data x func OPS_TO_ALWAYS_SKIP ops runtimes_ memory_ new_ids output_ids inplace_ops_ view_like_ops_ rand_ops_ = zip astuple x x filtered_data strict=True Extract metadata information runtimes = list runtimes_ memory = list memory_ func_names = op _overloadpacket __name__ op ops view_like_ops = i i x enumerate view_like_ops_ x rand_ops = i i x enumerate rand_ops_ x saved_autograd_ops = i i out_ids enumerate output_ids set out_ids issubset _saved_tensor_ids Remap inplace indices we have removed OPS_TO_ALWAYS_SKIP FIXME sanketpurandare Fix changing parent inplace-op itself original parent OPS_TO_ALWAYS_SKIP try inplace_ops = tuple map new_ids index x x inplace_ops_ x except ValueError err raise ValueError f The remapping inplace ops failed since one inplace op parents f must have been present OPS_TO_ALWAYS_SKIP err The last operation always stored output checkpoint block so we can avoid recomputing We set memory zero instead adding new constraint because we want both endpoints memory_budget valid FIXME sanketpurandare heuristic finding last non-view non-inplace op might always correct which would yield suboptimal policies last_op = len ops - skip_ops_ = set view_like_ops &#124; set x x inplace_ops reversed_skip_ops = sorted skip_ops_ reverse=True op reversed_skip_ops op == last_op last_op -= memory last_op = Create single ` ` SACStats ` ` object entire block ` ` _SACMetadata ` ` SACStats func_names=func_names runtimes=runtimes memory=memory view_like_ops=view_like_ops rand_ops=rand_ops saved_autograd_ops=saved_autograd_ops inplace_ops=inplace_ops type ignore arg-type force_store_random=force_store_random _get_inplace_metadata func Any out_storages set UntypedStorage - tuple int tuple int dict str tuple int Get current index metadata obtained so far curr_idx = len _sac_metadata Get set active modules leaf active_mod_fqns set str = par par _mod_tracker parents par _leaf_modules Output ids identifies storage objects corresponding tensors output_ids = tuple hash st st out_storages If function inplace is_inplace func curr_idx output_ids dict fromkeys active_mod_fqns op_idx = curr_idx Initialize parent op ids inplace op each active modules mod_op_parent_idxs dict str int = dict fromkeys active_mod_fqns - i d enumerate _sac_metadata Find first occurrence tensor corresponding each module shares same storage current tensor past_output_ids = d output_ids set output_ids issubset set past_output_ids mod_fqn op_parent_idx mod_op_parent_idxs items op_parent_idx == - acm_stats = _sac_mod_metadata get mod_fqn None i = acm_stats start_idx mod_op_parent_idxs mod_fqn = i assert mod_fqn == Global mod_op_parent_idxs mod_fqn = i If no parent tensor found then s probably inplace op arguments so one can just store current-op idx parent idx mod_fqn op_parent_idx mod_op_parent_idxs items op_parent_idx mod_op_parent_idxs mod_fqn = op_idx mod_inplace_info = mod_fqn op_idx mod_op_parent_idxs mod_fqn mod_fqn active_mod_fqns curr_idx output_ids mod_inplace_info type ignore return-value __torch_dispatch__ type ignore no-untyped-def func types args= kwargs=None Get runtime estimate out op_time = _estimate_runtime func args kwargs flat_outs _ = tree_flatten out out_storages_cuda set UntypedStorage = set out_storages_cpu set UntypedStorage = set cuda_devices set torch device = set o flat_outs isinstance o torch Tensor o device type == cuda out_storages_cuda update get_untyped_storages o cuda_devices add o device out_storages_cpu update get_untyped_storages o Check there s more than CUDA device assert len cuda_devices = f func __name__ s output has more than CUDA devices cuda_devices Get memory consumed output nbytes_cuda = sum math ceil st nbytes _PYTORCH_MIN_ALLOCATE _PYTORCH_MIN_ALLOCATE st out_storages_cuda nbytes_cpu = sum st nbytes st out_storages_cpu nbytes = nbytes_cuda + nbytes_cpu Get current operator index output storage identifiers inplace metadata out_storages = out_storages_cuda &#124; out_storages_cpu curr_idx output_ids mod_inplace_info = _get_inplace_metadata func out_storages Determine function in-place random-op view-like is_view_like = is_view_fn func is_inplace_view_fn func is_rand_op = torch Tag nondeterministic_seeded func tags is_view_like nbytes = sdpa has non-deterministic seed might deterministic no dropout applied func overloadpacket __name__ == _scaled_dot_product_flash_attention pyrefly ignore missing-attribute is_rand_op = kwargs get dropout_p = Create metadata information per active non-leaf module mod_fqn _mod_tracker parents mod_fqn _leaf_modules continue acm = _SACMetadata func=func time_taken=op_time memory_used=nbytes curr_idx=curr_idx output_ids=output_ids inplace_info=mod_inplace_info mod_fqn is_view_like=is_view_like is_rand_op=is_rand_op acm_stats = _sac_mod_metadata get mod_fqn None acm_stats sac_metadata append acm assert mod_fqn == Global f Module mod_fqn found AC Mod Stats _sac_metadata append acm out _get_greedy_order_meta sac_stats SACStats - SACGreedyOrderMeta An inplace-op group set inplace-ops operate same underlying tensor storage inplace_op_groups A dictionary top-most parent inplace-ops inplace-ops group The top-most op can itself inplace-op can non-inplace op inplace_op_to_group_head A dictionary maps all inplace-ops their respective group heads inplace_op_groups dict int set int = inplace_op_to_group_head dict int int = dict sac_stats inplace_ops Initialize inplace_op_groups using inplace_op_to_group_head op_idx group_head_idx inplace_op_to_group_head items op_group = inplace_op_groups setdefault group_head_idx group_head_idx op_group add op_idx Like inplace ops all random ops function module should all either recomputed saved group This because they affect ranom seed generator If force_store_random set True all random ops will stored default For easy manageability we store top-most random op leader random_ops_group random_ops_group dict int set int = random_group_head_idx = min sac_stats rand_ops default=- has_rand_ops = bool sac_stats rand_ops has_rand_ops random_ops_group random_group_head_idx = set sac_stats rand_ops Random ops stored force_store_random set View-like ops recomputed default For inplace_op_groups If head group inplace op then we have store entire group b If any op group random force_store_random set then entire group will stored c If none ops group random head group in-place op then group can considered recomputation its entirety stored_ops set int = set recomputed_ops set int = set Case has_rand_ops sac_stats force_store_random stored_ops add random_group_head_idx Case recomputed_ops update set sac_stats view_like_ops group_head_idx op_group inplace_op_groups items Case group_head_idx inplace_op_to_group_head stored_ops add group_head_idx Case b sac_stats force_store_random len op_group set sac_stats rand_ops stored_ops add group_head_idx The potential recompute candidates populated recompute_candidates set int = set The random group head stored has_rand_ops random_group_head_idx stored_ops recompute_candidates add random_group_head_idx The in-place op group heads stored recompute_candidates update set inplace_op_groups keys - stored_ops The non-inplace non-random ops neither stored nor recomputed default recompute_candidates update set range len sac_stats memory - recomputed_ops - stored_ops - set inplace_op_to_group_head keys - set sac_stats rand_ops We define msps recomp candidate ratio memory runtime aka memory savings per second msps_meta list MSPS = cand_idx recompute_candidates op_indices = cand_idx cand_idx inplace_op_groups op_indices update inplace_op_groups cand_idx has_rand_ops cand_idx == random_group_head_idx op_indices update sac_stats rand_ops mem = sum sac_stats memory op_idx op_idx op_indices runtime = sum sac_stats runtimes op_idx op_idx op_indices func_names = sac_stats func_names op_idx op_idx op_indices msps = mem runtime runtime sys float_info max msps_meta append MSPS func_names cand_idx mem runtime msps We choose candidates recomputed based increasing msps msps_meta sort key=lambda x x msps reverse=True SACGreedyOrderMeta recomputed_ops stored_ops inplace_op_groups random_ops_group msps_meta _get_sac_tradeoff_pwlf_stats sac_stats SACStats greedy_order_meta SACGreedyOrderMeta n_segments int = save_tradeoff_graph bool = False filename str = ac_tradeoff - SACTradeOffStats try numpy np type ignore import-not-found pwlf type ignore import-untyped import-not-found except ImportError err raise ImportError Please install pwlf numpy package err stored_ops recomputed_ops inplace_op_groups random_ops_group msps_meta = greedy_order_meta stored_ops greedy_order_meta recomputed_ops greedy_order_meta inplace_op_groups greedy_order_meta random_ops_group greedy_order_meta msps_meta Initialize discarded memory recomputation runtime sum already chosen recomputed_ops recomp_indices set int = set r_idx recomputed_ops recomp_indices add r_idx r_idx inplace_op_groups recomp_indices update inplace_op_groups r_idx r_idx random_ops_group recomp_indices update random_ops_group r_idx discarded_mem = sum sac_stats memory op_idx op_idx recomp_indices recomp_runtime = sum sac_stats runtimes op_idx op_idx recomp_indices Initialize max recomputation time total recomputation memory sac_runtime = sum sac_stats runtimes sac_memory = sum sac_stats memory Tradeoff curve stores KV pair discarded memory total memory recomputation time total runtime incurred delta = e- tradeoff_curve = OrderedDict Initialize trade-off curve stats already chosen recomputed_ops tradeoff_curve discarded_mem sac_memory + delta = recomp_runtime sac_runtime Update trade-off curve memory runtime stats SAC candidates greedy order their ` ` MSPS ` ` cand msps_meta discarded_mem += cand memory recomp_runtime += cand runtime tradeoff_curve discarded_mem sac_memory + delta = recomp_runtime sac_runtime Finally we add memory recomputation time always stored ops stored_indices set int = set s_idx stored_ops stored_indices add s_idx s_idx inplace_op_groups stored_indices update inplace_op_groups s_idx s_idx random_ops_group stored_indices update random_ops_group s_idx discarded_mem += sum sac_stats memory op_idx op_idx stored_indices recomp_runtime += sum sac_stats runtimes op_idx op_idx stored_indices tradeoff_curve discarded_mem sac_memory + delta = recomp_runtime sac_runtime x_ = list tradeoff_curve keys y_ = list tradeoff_curve values We shift y values left x values right upperbound trade-off function TODO Write better explanation why needs done x = x_ len x_ - y = y_ tradeoff_pwlf = pwlf PiecewiseLinFit x y Fit piecewise linear function specified number segments trade-off curve n_segments = max min len x - n_segments tradeoff_pwlf fit n_segments=n_segments save prediction graph save_prediction_graph pwlf_ pwlf PiecewiseLinFit x list float y list float filename str - None try matplotlib pyplot plt type ignore import-not-found numpy np type ignore import-not-found except ImportError err raise ImportError Install matplotlib numpy using pip pip install matplotlib numpy err predict determined points xHat = np linspace min x max x num= yHat = pwlf_ predict xHat plot results plt figure plt plot x y o label= Shifted plt plot xHat yHat - label= Predicted plt plot x_ y_ x label= Original plt ylabel Recomp time Total recomp time plt xlabel Memory discarded Total memory plt legend plt title f filename plt suptitle f Total Memory = sac_memory B Total Runtime = sac_runtime f ms fontsize= folder_name = tradeoff_graphs os path exists folder_name os makedirs folder_name Save plots folder plt savefig os path join folder_name f filename png save_tradeoff_graph save_prediction_graph tradeoff_pwlf x y filename Obtain slopes intercepts breakpoints fitted piecewise linear functions slopes = tradeoff_pwlf calc_slopes tolist assert isinstance tradeoff_pwlf intercepts np ndarray isinstance tradeoff_pwlf fit_breaks np ndarray intercepts = tradeoff_pwlf intercepts tolist fit_breaks = tradeoff_pwlf fit_breaks tolist SACTradeOffStats n_segments=n_segments slopes=slopes intercepts=intercepts type ignore arg-type fit_breaks=fit_breaks type ignore arg-type tradeoff_curve=tradeoff_curve sac_memory=sac_memory sac_runtime=sac_runtime display_sac_stats sac_stats SACStats print_tabular bool = False - None Displays SAC statistics Args sac_stats SACStats The SAC statistics display print_tabular bool optional Whether print statistics tabular format Defaults False Prints Total Memory The total memory usage bytes Total Runtime The total runtime milliseconds Store Random A flag indicating whether force store random operator results Followed table following columns Op Idx The operator index Op Name The operator name Runtimes ms The operator runtime milliseconds Memory B The operator memory usage bytes View-like A flag indicating whether operator view-like Random A flag indicating whether operator random Saved Autograd A flag indicating whether operator s result saved autograd engine In-place The index operator s first parent None in-place If print_tabular True table printed tabular format Otherwise table printed plain text format print f Total Memory sum sac_stats memory B Total Runtime sum sac_stats runtimes ms f Store Random sac_stats force_store_random table_data = op_parent = dict sac_stats inplace_ops i fn_name enumerate sac_stats func_names row = str i fn_name f sac_stats runtimes i f str sac_stats memory i str i sac_stats view_like_ops str i sac_stats rand_ops str i sac_stats saved_autograd_ops str op_parent get i table_data append row Define headers headers = Op Idx Op Name Runtimes ms Memory B View-like Random Saved Autograd In-place print_tabular _display_stats_tabular headers table_data max_widths = _ range len headers table_data insert headers row table_data i elem enumerate row max_widths i = max max_widths i len elem row table_data print \t join f elem max_widths i i elem enumerate row display_sac_tradeoff_stats greedy_order_meta SACGreedyOrderMeta sac_stats SACStats print_tabular bool = False - None Displays SAC trade-off statistics Args greedy_order_meta SACGreedyOrderMeta The SAC greedy order metadata sac_stats SACStats The SAC statistics print_tabular bool optional Whether print statistics tabular format Defaults False Prints A table following columns Op Id s The operator index es Op Name s The operator name s Discarded Mem The percentage discarded memory Discarded Mem B The discarded memory bytes Recomp time The percentage recomputed time Recomp time ms The recomputed time milliseconds MSPS The memory per second Always Stored A flag indicating whether operator always stored Always Recomputed A flag indicating whether operator always recomputed If print_tabular True table printed tabular format Otherwise table printed plain text format table_data = total_memory total_runtime = sum sac_stats memory sum sac_stats runtimes discarded_mem int = recomp_runtime float = append_row op_indices set int func_names set str msps Optional float = None stored Optional bool = False recomputed Optional bool = False - None row = str op_indices str func_names f discarded_mem total_memory f str discarded_mem f recomp_runtime total_runtime f str recomp_runtime f msps e msps None str nan str stored str recomputed table_data append row stored_ops recomputed_ops inplace_op_groups random_ops_group msps_meta = greedy_order_meta stored_ops greedy_order_meta recomputed_ops greedy_order_meta inplace_op_groups greedy_order_meta random_ops_group greedy_order_meta msps_meta op_idx recomputed_ops op_indices set int = op_idx op_idx inplace_op_groups op_indices update inplace_op_groups op_idx op_idx random_ops_group op_indices update random_ops_group op_idx discarded_mem += sum sac_stats memory i i op_indices recomp_runtime += sum sac_stats runtimes i i op_indices func_names = sac_stats func_names i i op_indices append_row op_indices func_names recomputed=True cand msps_meta discarded_mem += cand memory recomp_runtime += cand runtime op_indices = cand op_idx cand op_idx inplace_op_groups op_indices update inplace_op_groups cand op_idx cand op_idx random_ops_group op_indices update random_ops_group cand op_idx append_row op_indices cand func_names msps=cand msps op_idx stored_ops op_indices = op_idx op_idx inplace_op_groups op_indices update inplace_op_groups op_idx op_idx random_ops_group op_indices update random_ops_group op_idx discarded_mem += sum sac_stats memory i i op_indices recomp_runtime += sum sac_stats runtimes i i op_indices func_names = sac_stats func_names i i op_indices append_row op_indices func_names stored=True headers = Op Id s Op Name s Discarded Mem Discarded Mem B Recomp time Recomp time ms MSPS Always Stored Always Recomputed print_tabular _display_stats_tabular headers table_data max_widths = _ range len headers table_data insert headers row table_data i elem enumerate row max_widths i = max max_widths i len elem row table_data print \t join f elem max_widths i i elem enumerate row pwlf_sac_tradeoff_curve n_segments int = save_tradeoff_graphs bool = False - None Fits piecewise linear function specified sumber segments SAC trade-off curve discarded memory vs recomputation time Args n_segments int optional The number segments used fitting piecewise linear function trade-off curve Defaults save_tradeoff_graphs bool optional Whether save trade-off graphs file Defaults False If save_tradeoff_graphs True trade-off graphs saved file using module FQN filename mod_fqn sac_stats sac_mod_stats items sac_mod_tradeoff_stats mod_fqn = _get_sac_tradeoff_pwlf_stats sac_stats=sac_stats greedy_order_meta=self sac_mod_greedy_order_meta mod_fqn n_segments=n_segments save_tradeoff_graph=save_tradeoff_graphs filename=mod_fqn display_modulewise_sac_stats depth int = print_tabular bool = False - None Displays SAC trade-off statistics each module Args depth int optional The maximum depth modules display Defaults print_tabular bool optional Whether print statistics tabular format Defaults False Prints For each module depth less than equal specified depth The SAC statistics module using display_sac_stats The SAC trade-off statistics module using display_sac_tradeoff_stats If print_tabular True statistics printed tabular format Otherwise statistics printed plain text format mod_fqn sac_stats sac_mod_stats items mod_depth = mod_fqn count + mod_depth depth continue print f Module mod_fqn display_sac_stats sac_stats print_tabular print f AC Trade-off Module mod_fqn MSPS = Memory Runtime display_sac_tradeoff_stats sac_mod_greedy_order_meta mod_fqn sac_stats print_tabular __call__ estimate_mode_type str - Self Sets estimate mode type Currently supported modes - operator-level-benchmark Estimates runtime using operator benchmarking - operator-level-cost-model Estimates runtime using roofline cost model Args estimate_mode_type str The type estimate mode use Returns SACEstimator The SAC estimator instance Raises NotImplementedError If estimate mode type supported estimate_mode_type == operator-level-benchmark _estimate_runtime = RuntimeEstimator _benchmark_estimate estimate_mode_type == operator-level-cost-model _estimate_runtime = RuntimeEstimator _roofline_estimate raise NotImplementedError f estimate_mode_type estimate_mode_type supported __enter__ - Self type ignore no-untyped-def fake_mode = active_fake_mode assert isinstance fake_mode FakeTensorMode SAC Estimator should called FakeTensorMode RuntimeEstimator fake_mode = fake_mode _mod_tracker register_user_hooks pre_fw_hook=self _pre_fw_hook post_fw_hook=self _post_fw_hook _mod_tracker __enter__ _saved_tensor_hook_ctx __enter__ super __enter__ __exit__ args Any - None type ignore no-untyped-def _saved_tensor_hook_ctx __exit__ _mod_tracker __exit__ args super __exit__ args