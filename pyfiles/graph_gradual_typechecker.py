mypy allow-untyped-defs itertools operator collections abc Callable functools reduce typing TypeVar typing_extensions ParamSpec sympy torch torch fx experimental refinement_types Equality torch fx experimental unification Var type ignore attr-defined torch fx node Node Target torch fx tensor_type Dyn is_consistent is_more_precise TensorType torch nn modules batchnorm BatchNorm d torch nn modules conv Conv d _T = TypeVar _T _P = ParamSpec _P _INFERENCE_RULES dict Target Callable = _REFINEMENT_RULES dict Target Callable = _RULES dict Target Callable = __all__ = GraphTypeChecker Refine adaptiveavgpool d_check adaptiveavgpool d_inference_rule add_inference_rule all_eq bn d_inference_rule broadcast_types calculate_out_dimension conv d_inference_rule conv_refinement_rule conv_rule element_wise_eq expand_to_tensor_dim first_two_eq flatten_check flatten_inference_rule flatten_refinement_rule get_attr_inference_rule get_greatest_upper_bound get_parameter linear_check linear_inference_rule linear_refinement_rule maxpool d_check maxpool d_inference_rule register_algebraic_expressions_inference_rule register_inference_rule register_refinement_rule relu_inference_rule reshape_inference_rule transpose_inference_rule expand_to_tensor_dim t n Expand type desired tensor dimension possible Raise error otherwise - t given type - n number dimensions expand t == Dyn dims = Dyn n TensorType tuple dims isinstance t TensorType len t __args__ = n raise TypeError f Cannot extend tensor Tensor t has rank len t __args__ It should have rank n t raise TypeError f Cannot match type t broadcast_types t t Applies broadcasting both given types such they become consistent each other returns two new resulting types either type Dyn do nothing since types already consistent t == Dyn t == Dyn isinstance t Var isinstance t Var t t isinstance t TensorType isinstance t TensorType s = len t __args__ s = len t __args__ new_t = list t __args__ new_t = list t __args__ We make types same length which first requirement consistency s s _ range s - s new_t insert s s _ range s - s new_t insert we replace occurrences each tensor corresponding type other tensor i x y enumerate zip new_t new_t x == new_t i = y y == new_t i = x point our tensors should consistent we can apply element-wise operation find right dimension output operation t t = TensorType tuple new_t TensorType tuple new_t t t raise TypeError f Cannot broadcast types t t register_inference_rule call_target Target - Callable Callable _P _T Callable _P _T register fn Callable _P _T - Callable _P _T call_target _INFERENCE_RULES raise RuntimeError f Inference rule already registered call_target _INFERENCE_RULES call_target = fn fn register register_refinement_rule call_target Target - Callable Callable _P _T Callable _P _T register fn Callable _P _T - Callable _P _T call_target _REFINEMENT_RULES raise RuntimeError f Refinement rule already registered call_target _REFINEMENT_RULES call_target = fn fn register register_algebraic_expressions_inference_rule call_target Target - Callable Callable _P _T Callable _P _T register fn Callable _P _T - Callable _P _T call_target _RULES raise RuntimeError f Rule already registered call_target _RULES call_target = fn fn register register_inference_rule torch add register_inference_rule operator add add_inference_rule n Node Apply addition inference rule This includes - scalar addition - broadcasting semantics Note we always least precise type between operands after applying broadcasting final type operation Note we do modify operand types themselves after applying broadcasting them We only use them calculate final type assert isinstance n args Node assert isinstance n args Node t = n args type t = n args type handle scalar addition t int isinstance t TensorType n type = t n type handle scalar addition t int isinstance t TensorType n type = t n type we bring new types point where we can check consistency any inconsistency would have been caused broadcasting point new_t new_t = broadcast_types t t new_t = t new_t = t n meta broadcast = True n meta str n args = new_t n meta str n args = new_t n meta broadcast = False new_t = t n meta broadcast new_t new_t = t n meta broadcast new_t we check consistency between new types is_consistent new_t new_t we less precise type because broadcasting may have happened operands shape Dyn we have assign node Dyn is_more_precise new_t new_t n type = new_t n type = new_t n type raise TypeError f Cannot add arguments n args n args type n args n args type node n f Types should match register_inference_rule getattr get_attr_inference_rule n Node traced The current getattr rule only handles shape attribute Can extended other attributes The most representitive type we have Dyn system can extended more types such type represent shapes attr_name = n args attr_name == shape n type = Dyn raise TypeError Not yet implemented TODO We leave like till we add type represent tensor sizes n type register_inference_rule torch transpose transpose_inference_rule n Node We check dimensions transpose operations within range tensor type node n target torch transpose assert isinstance n args Node t = n args type assert isinstance n args int assert isinstance n args int dim dim = n args n args t == Dyn n type = Dyn n type isinstance t TensorType = dim len t __args__ = dim len t __args__ new_type = list t __args__ new_type dim new_type dim = new_type dim new_type dim final = TensorType new_type n type = get_greatest_upper_bound n type final n type raise TypeError f Cannot transpose dim dim type t node n raise TypeError f Cannot transpose dim dim type t node n register_inference_rule torch reshape reshape_inference_rule n Node Without dynamism rule checks product elements argument tensor type equal product elements required shape We gradualize rule adding case handle fully dynamic input well input where some tensor dimensions unknown In case we check divisibility assert isinstance n args Node t = n args type assert isinstance n args list t = n args t _type = TensorType Dyn elem == - elem elem t we do know original tensor dimension we required dimension t == Dyn n type = t _type t _type any dimensions unknown we check divisibility isinstance t TensorType assert isinstance t TensorType = e e = Dyn e t __args__ p = reduce operator mul p = reduce operator mul t p p == p p == n type = t _type t _type raise TypeError f Cannot reshape node n t t _type raise TypeError f Cannot reshape node n t t _type register_inference_rule BatchNorm d bn d_inference_rule n Node module_instance Given BatchNorm D instance node check following conditions - input type can expanded size tensor t = x_ x_ x_ x_ - current node type can expanded size tensor t = x_ x_ x_ x_ - t consistent t - x_ consistent module s num_features - x_ consistent module s num_features output type more precise type t t assert isinstance n args Node n args type = expand_to_tensor_dim n args type arg_type = n args type n type = expand_to_tensor_dim n type we check conditions incoming argument any existing annotation we also check consistency between both annotations is_consistent arg_type __args__ module_instance num_features is_consistent n type __args__ module_instance num_features is_consistent arg_type n type we choose more precise type node type so incoming argument has more type information we set node s type argument type n type = get_greatest_upper_bound arg_type n type n type raise TypeError f Cannot apply module_instance input type arg_type existing type n type n calculate_out_dimension d_in module_instance index For calculating h_in w_out according conv D documentation padding = module_instance padding module_instance padding isinstance module_instance padding int module_instance padding kernel_size = module_instance kernel_size module_instance kernel_size isinstance module_instance kernel_size int module_instance kernel_size stride = module_instance stride module_instance stride isinstance module_instance stride int module_instance stride dilation = module_instance dilation module_instance dilation isinstance module_instance dilation int module_instance dilation DIMENSION_TYPES = int sympy Symbol d_in == Dyn Dyn isinstance d_in DIMENSION_TYPES n = d_in + padding index - dilation index kernel_size index - - n stride + raise TypeError f d_in module_instance must number Dyn Received type d_in get_greatest_upper_bound type type Get most precise type s consistent given types type == Dyn type type == Dyn type isinstance type TensorType isinstance type TensorType is_consistent type type raise TypeError f Inconsistent types type type gub = t is_more_precise t t t t t zip type __args__ type __args__ TensorType tuple gub register_inference_rule Conv d conv d_inference_rule n Node module_instance Given Conv D instance node check following conditions - input type can expanded size tensor t = x_ x_ H W - current node type can expanded size tensor t = x_ x_ x_ x_ - x_ consistent module s in_channels - let o = x_ out_channels H_out W_out then output greatest upper bound o existing node type t assert isinstance n args Node n args type = expand_to_tensor_dim n args type arg_type = n args type curr_node_type = expand_to_tensor_dim n type is_consistent arg_type __args__ module_instance in_channels w_in = arg_type __args__ h_in = arg_type __args__ h_out = calculate_out_dimension h_in module_instance w_out = calculate_out_dimension w_in module_instance new_type = TensorType arg_type __args__ module_instance out_channels h_out w_out gub = get_greatest_upper_bound new_type curr_node_type n type = gub n type raise TypeError f Cannot apply module_instance input type arg_type existing type n type n register_inference_rule torch nn ReLU relu_inference_rule n Node module_instance Input output shapes should equal assert isinstance n args Node n args type == Dyn isinstance n type TensorType n args type = expand_to_tensor_dim n args type len n type __args__ isinstance n args type TensorType n type = get_greatest_upper_bound n args type n type n type maxpool d_check typ module_instance Applies maxpool d shape information input affects last two dimensions new_type_list = list typ __args__ len new_type_list == len new_type_list == w_in = new_type_list - h_in = new_type_list - h_out = calculate_out_dimension h_in module_instance w_out = calculate_out_dimension w_in module_instance new_type_list - = w_out new_type_list - = h_out TensorType tuple new_type_list raise TypeError f Wrong size typ module_instance register_inference_rule torch nn MaxPool d maxpool d_inference_rule n Node module_instance Given MaxPool D instance node check following conditions - Input size matches size - Current node type consistent output type we will calculate - Input size matches output size last two dimensions output w_out h_out The remaining dimensions same input - Our final result greatest upper bound output we calculate current node type assert isinstance n args Node n args type == Dyn isinstance n type TensorType n args type = expand_to_tensor_dim n args type len n type __args__ isinstance n args type TensorType output = maxpool d_check n args type module_instance n type = get_greatest_upper_bound output n type n type linear_check tensor_type module_instance Checks input tensor type satisfies conditions linear operation returns output type based out features given module_instance len tensor_type __args__ = is_consistent module_instance in_features tensor_type __args__ - new_type_args = list tensor_type __args__ new_type_args - = module_instance out_features TensorType tuple new_type_args raise TypeError f Inconsistent module_instance in_features tensor_type __args__ - module_instance raise TypeError f Type tensor_type must have rank more register_inference_rule torch nn Linear linear_inference_rule n Node module_instance Applies shape information input then gets greatest upper bound resulting type existing type assert isinstance n args Node n args type == Dyn isinstance n type TensorType n args type = expand_to_tensor_dim n args type len n type __args__ isinstance n args type TensorType output_type = linear_check n args type module_instance n type = get_greatest_upper_bound output_type n type n type adaptiveavgpool d_check tensor_type module_instance output_size = module_instance output_size isinstance output_size int output_size = output_size output_size isinstance output_size tuple output_size = list output_size output_size None output_size = output_size output_size None output_size = output_size new_type_list = list tensor_type __args__ len tensor_type __args__ == len tensor_type __args__ == new_type_list - = output_size new_type_list - = output_size TensorType tuple new_type_list raise TypeError f Tensor ranks must Got tensor_type register_inference_rule torch nn AdaptiveAvgPool d adaptiveavgpool d_inference_rule n Node module_instance The input output sizes should same except last two dimensions taken input which represent width height assert isinstance n args Node n args type == Dyn isinstance n type TensorType n args type = expand_to_tensor_dim n args type len n type __args__ isinstance n args type TensorType output_type = adaptiveavgpool d_check n args type module_instance n type = get_greatest_upper_bound n type output_type n type flatten_check tensor_type start_dim end_dim l = len tensor_type __args__ start_dim = l start_dim == - abs start_dim end_dim = l + end_dim + end_dim end_dim + = start_dim = l - = end_dim = l start_dim end_dim my_args = list tensor_type __args__ lhs = my_args start_dim rhs = my_args end_dim mid = my_args start_dim end_dim Dyn mid mid = Dyn mid = reduce operator mul my_args start_dim end_dim new_type_list = lhs + mid + rhs TensorType tuple new_type_list raise TypeError f Incompatible dimensions start_dim end_dim - type tensor_type register_inference_rule torch flatten flatten_inference_rule n Node Applies flatten shape information input then gets greatest upper bound resulting type existing type assert isinstance n args Node set default start end dims start_dim = end_dim = - len n args assert isinstance n args int start_dim = n args len n args assert isinstance n args int end_dim = n args n args type == Dyn isinstance n type TensorType n args type = expand_to_tensor_dim n args type len n type __args__ isinstance n args type TensorType output_type = flatten_check n args type start_dim end_dim n type = get_greatest_upper_bound output_type n type n type GraphTypeChecker __init__ env traced env = env traced = traced type_check A gradual type checker graphs Effect every node s field type will populated type after type-checking done graph = traced graph type check every node gradual type rules any node does type check false n graph nodes type_check_node n True type_check_node n Node Type check given fx node Current operations - Reshape - Transpose - Add - Relu - conv d - batchnorm d - flatten - maxpool d - adaptiveavgpool d - linear n type None n type = Dyn n op == placeholder n type n op == get_attr t = get_parameter traced n target type ignore arg-type isinstance t data torch Tensor n type = TensorType t data shape n type n op == call_function n target getattr assert getattr _INFERENCE_RULES _INFERENCE_RULES n target n traced n target _INFERENCE_RULES _INFERENCE_RULES n target n raise RuntimeError f No inference rule registered target n target n op == call_module module_instance = traced get_submodule n target type module_instance _INFERENCE_RULES _INFERENCE_RULES type module_instance n module_instance raise RuntimeError f No inference rule registered type module_instance n op == output get_node_type type n type = torch fx node map_arg n args get_node_type n type raise NotImplementedError f Method n op yet implemented register_refinement_rule Conv d conv_refinement_rule n Node The equality constraints between first dimension input output res = assert isinstance n args Node arg_type = n args type isinstance arg_type TensorType isinstance n type TensorType res = Equality arg_type __args__ n type __args__ res register_refinement_rule torch nn Linear linear_refinement_rule n Node The equality constraints between first dimension input output res = assert isinstance n args Node arg_type = n args type isinstance arg_type TensorType isinstance n type TensorType res = Equality arg_type __args__ n type __args__ res register_refinement_rule BatchNorm d register_refinement_rule torch nn ReLU all_eq n Node For operations where input shape equal output shape res = assert isinstance n args Node arg_type = n args type isinstance arg_type TensorType isinstance n type TensorType args = arg_type __args__ args = n type __args__ res = Equality args i args i i range len args res register_refinement_rule torch nn AdaptiveAvgPool d register_refinement_rule torch nn MaxPool d first_two_eq n Node For operations where first two dimensions input output shape equal res = assert isinstance n args Node arg_type = n args type isinstance arg_type TensorType isinstance n type TensorType args = arg_type __args__ args = n type __args__ res = Equality args args Equality args args res register_refinement_rule torch add register_refinement_rule operator add element_wise_eq n Node For element-wise operations handles broadcasting Note after applying broadcasting arguments we able determine certain dimensions have been broadcast they symbolicallu equal case we can establish equality between those dimensions corresponding output dimensions Note takes two iterations result One iteration establish equality between certain dimensions operands requiring whole solver including unification another iteration establish equality between operands resulting type requiring another round constraint generation unificaiton res = isinstance n args Node isinstance n args Node arg_type = n args type arg_type = n args type isinstance arg_type TensorType isinstance arg_type TensorType isinstance n type TensorType args args = broadcast_types arg_type arg_type point we know args args same size = args __args__ = args __args__ = n type __args__ we would here second iteration where we establish equality between operand type dimensions resulting type dimensions r = x y z zip x == y r append Equality x z res = r res register_refinement_rule torch flatten flatten_refinement_rule n Node Generates equality constraints between dimensions input output will involved flatten operation assert isinstance n args Node eq_const = start_dim = end_dim = - len n args assert isinstance n args int start_dim = n args len n args assert isinstance n args int end_dim = n args isinstance n type TensorType isinstance n args type TensorType l = len n type __args__ arg_type = n args type start_dim = l start_dim == - start_dim end_dim = l + end_dim + end_dim end_dim + t t zip n type __args__ start_dim arg_type __args__ start_dim eq_const append Equality t t t t zip n type __args__ end_dim arg_type __args__ end_dim eq_const append Equality t t eq_const register_algebraic_expressions_inference_rule Conv d conv_rule n Node module_instance Represents output terms algrbraic expression w r t input when possible assert isinstance n args Node arg_type = n args type isinstance arg_type TensorType isinstance n type TensorType w_in = arg_type __args__ h_in = arg_type __args__ h_out = calculate_out_dimension h_in module_instance w_out = calculate_out_dimension w_in module_instance new_type = TensorType n type __args__ n type __args__ h_out w_out n type = new_type new_type Refine Symbolic shape inference Generates constraints over type variables Currently all constraints equality constraints __init__ traced constraints = traced = traced symbol_iter = itertools count start= step= refine Generates constraints every node graph based operation graph = traced graph n graph nodes refine_node n True symbolic_relations Infers algebraic relations graph = traced graph n graph nodes infer_symbolic_relations n True replace_dyn_with_fresh_var typ Replace all unknown types fresh type variables typ == Dyn new_symbol = Var next symbol_iter new_symbol isinstance typ TensorType new_args = replace_dyn_with_fresh_var typ __args__ TensorType tuple new_args isinstance typ list replace_dyn_with_fresh_var t t typ isinstance typ tuple replace_dyn_with_fresh_var t t typ typ convert_to_sympy_symbols typ Replace all unknown types fresh type variables isinstance typ Var sympy symbols str typ isinstance typ TensorType new_args = convert_to_sympy_symbols typ __args__ TensorType tuple new_args isinstance typ list convert_to_sympy_symbols t t typ isinstance typ tuple convert_to_sympy_symbols t t typ typ refine_node n Node Returns list equality constraints call_module call_function nodes Models relation between input output dimensions using constraints case they both tensors All operations used resnet defined n type None n type = Dyn n type = replace_dyn_with_fresh_var n type n op == call_function n target _REFINEMENT_RULES constraints += _REFINEMENT_RULES n target n n op == call_module module_instance = traced get_submodule n target type module_instance _REFINEMENT_RULES constraints += _REFINEMENT_RULES type module_instance n n op == output get_node_type type n type = torch fx node map_arg n args get_node_type n type infer_symbolic_relations n Node n type = convert_to_sympy_symbols n type n op == call_function n target _RULES _RULES n target n n op == call_module module_instance = traced get_submodule n target type module_instance _RULES _RULES type module_instance n module_instance n op == output get_node_type type n type = torch fx node map_arg n args get_node_type n type get_parameter traced target str Returns parameter given ` ` target ` ` exists otherwise throws error See docstring ` ` get_submodule ` ` more detailed explanation method s functionality well how correctly specify ` ` target ` ` Args target The fully-qualified string name Parameter look See ` ` get_submodule ` ` how specify fully-qualified string Returns torch nn Parameter The Parameter referenced ` ` target ` ` Raises AttributeError If target string references invalid path resolves something ` ` nn Parameter ` ` module_path _ param_name = target rpartition mod torch nn Module = traced get_submodule module_path hasattr mod param_name raise AttributeError mod _get_name + has no attribute ` + param_name + ` param torch nn Parameter = getattr mod param_name param