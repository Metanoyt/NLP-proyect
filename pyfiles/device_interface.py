Device abstraction layer TorchDynamo Inductor backends This module provides unified interface different hardware backends CUDA XPU CPU MPS MTIA through common device interface Key components include - DeviceInterface Base defining common API all device types - Device-specific implementations CudaInterface XpuInterface CpuInterface MpsInterface MtiaInterface - Device registration system managing available backends - Worker APIs multi-processing scenarios - Stream event management across different devices - Device property caching worker processes The abstraction layer enables device-agnostic code TorchDynamo while allowing specialized implementations each hardware backend s unique features inspect time collections namedtuple collections abc Callable Iterable dataclasses dataclass typing Any Literal Optional Union torch get_cuda_stream Optional Callable int int torch cuda _is_compiled torch _C _cuda_getCurrentRawStream get_cuda_stream get_cuda_stream = None Recording device properties main process used worker process caching_worker_device_properties dict str Any = caching_worker_current_devices dict str int = DeviceInterface This simple device runtime interface Inductor It enables custom backends integrated Inductor device-agnostic semantic device __new__ cls device torch types Device - Any raise NotImplementedError Event __new__ cls args Any kwargs Any - Any raise NotImplementedError Event should inherited torch Event otherwise couldn t captured dynamo Stream __new__ cls args Any kwargs Any - Any raise NotImplementedError Stream should inherited torch Stream otherwise couldn t captured dynamo Worker Worker API query device properties will work multi processing workers cannot use GPU APIs due processing fork initialization time issues Properties recorded main process before we fork workers staticmethod set_device device int - None raise NotImplementedError staticmethod current_device - int raise NotImplementedError staticmethod get_device_properties device torch types Device = None - Any raise NotImplementedError staticmethod current_device - int raise NotImplementedError staticmethod set_device device torch types Device - None raise NotImplementedError staticmethod maybe_exchange_device device int - int raise NotImplementedError staticmethod exchange_device device int - int raise NotImplementedError staticmethod device_count - int raise NotImplementedError staticmethod is_available - bool raise NotImplementedError staticmethod stream stream torch Stream - Any raise NotImplementedError staticmethod current_stream - torch Stream raise NotImplementedError staticmethod set_stream stream torch Stream - None raise NotImplementedError staticmethod _set_stream_by_id stream_id int device_index int device_type int - None raise NotImplementedError staticmethod get_raw_stream device_idx int - int raise NotImplementedError staticmethod synchronize device torch types Device = None - None raise NotImplementedError classmethod get_device_properties cls device torch types Device = None - Any cls Worker get_device_properties device staticmethod get_compute_capability device torch types Device = None - Any raise NotImplementedError staticmethod is_bf _supported including_emulation bool = False - bool raise NotImplementedError classmethod is_dtype_supported cls dtype torch dtype including_emulation bool = False - bool dtype = torch bfloat cls is_bf _supported including_emulation staticmethod memory_allocated device torch types Device = None - int raise NotImplementedError staticmethod is_triton_capable device torch types Device = None - bool Returns True device has Triton support False otherwise even appropriate Triton backend available False classmethod raise_if_triton_unavailable cls device torch types Device = None - None Raises ` RuntimeError ` appropriate human-readable instructions resolve issue Triton available given device default device ` device ` ` None ` The caller should ensure presence triton package before calling method cls is_triton_capable raise RuntimeError This device capable supporting Triton DeviceGuard This provides context manager device switching This stripped down version torch device_name device The context manager changes current device given device index entering context restores original device exiting The device switched using provided device interface __init__ device_interface type DeviceInterface index Optional int - None device_interface = device_interface idx = index prev_idx = - __enter__ - None idx None prev_idx = device_interface exchange_device idx __exit__ type Any value Any traceback Any - Literal False idx None idx = device_interface maybe_exchange_device prev_idx False CudaInterface DeviceInterface device = torch cuda device type ignore assignment register Event Stream into backend interface make sure Event Stream implemented inherited torch Event torch Stream Event = torch cuda Event type ignore assignment Stream = torch cuda Stream type ignore assignment pyrefly ignore bad-override Worker staticmethod set_device device int - None caching_worker_current_devices cuda = device staticmethod current_device - int cuda caching_worker_current_devices caching_worker_current_devices cuda torch cuda current_device staticmethod get_device_properties device torch types Device = None - Any device None isinstance device str device = torch device device assert device type == cuda isinstance device torch device device = device index device None device = CudaInterface Worker current_device cuda caching_worker_device_properties device_prop = torch cuda get_device_properties i i range torch cuda device_count caching_worker_device_properties cuda = device_prop caching_worker_device_properties cuda device current_device = staticmethod torch cuda current_device set_device = staticmethod torch cuda set_device device_count = staticmethod torch cuda device_count stream = staticmethod torch cuda stream type ignore assignment pyrefly ignore bad-override current_stream = staticmethod torch cuda current_stream set_stream = staticmethod torch cuda set_stream type ignore assignment _set_stream_by_id = staticmethod torch cuda _set_stream_by_id type ignore assignment synchronize = staticmethod torch cuda synchronize get_device_properties = staticmethod torch cuda get_device_properties type ignore assignment get_raw_stream = staticmethod get_cuda_stream type ignore assignment arg-type exchange_device = staticmethod torch cuda _exchange_device type ignore arg-type has-type maybe_exchange_device = staticmethod torch cuda _maybe_exchange_device type ignore arg-type has-type memory_allocated = staticmethod torch cuda memory_allocated is_bf _supported = staticmethod torch cuda is_bf _supported type ignore arg-type Can mock patched patch decorator staticmethod is_available - bool torch cuda is_available staticmethod get_compute_capability device torch types Device = None - Union int str torch version hip None major min = torch cuda get_device_capability device major + min torch cuda get_device_properties device gcnArchName split staticmethod is_triton_capable device torch types Device = None - bool torch version hip None torch cuda get_device_properties device major = staticmethod raise_if_triton_unavailable device torch types Device = None - None torch _inductor exc GPUTooOldForTriton CudaInterface is_triton_capable device device_props = torch cuda get_device_properties device raise GPUTooOldForTriton device_props inspect currentframe triton backends torch version hip None amd triton backends backends raise RuntimeError triton built amd backend nvidia triton backends backends raise RuntimeError triton built nvidia backend get_mtia_stream Optional Callable int int torch mtia _is_compiled torch _C _mtia_getCurrentRawStream get_mtia_stream get_mtia_stream = None MtiaInterface DeviceInterface device = torch mtia device type ignore assignment Event = torch mtia Event type ignore assignment Stream = torch mtia Stream type ignore assignment pyrefly ignore bad-override Worker staticmethod set_device device int - None caching_worker_current_devices mtia = device staticmethod current_device - int mtia caching_worker_current_devices caching_worker_current_devices mtia torch mtia current_device staticmethod get_device_properties device torch types Device = None - Any device None isinstance device str device = torch device device assert device type == mtia isinstance device torch device device = device index device None device = MtiaInterface Worker current_device mtia caching_worker_device_properties device_prop = torch mtia get_device_properties i i range torch mtia device_count caching_worker_device_properties mtia = device_prop caching_worker_device_properties mtia device current_device = staticmethod torch mtia current_device set_device = staticmethod torch mtia set_device type ignore assignment device_count = staticmethod torch mtia device_count stream = staticmethod torch mtia stream type ignore assignment pyrefly ignore bad-override current_stream = staticmethod torch mtia current_stream set_stream = staticmethod torch mtia set_stream type ignore assignment _set_stream_by_id = staticmethod torch mtia _set_stream_by_id type ignore assignment synchronize = staticmethod torch mtia synchronize get_device_properties = staticmethod torch mtia get_device_properties type ignore assignment get_raw_stream = staticmethod get_mtia_stream type ignore assignment arg-type exchange_device = staticmethod torch mtia _exchange_device type ignore arg-type has-type maybe_exchange_device = staticmethod torch mtia _maybe_exchange_device type ignore arg-type has-type memory_allocated = staticmethod torch mtia memory_allocated type ignore assignment is_bf _supported = staticmethod torch mtia is_bf _supported type ignore arg-type Can mock patched patch decorator staticmethod is_available - bool ret = torch mtia is_available ret staticmethod get_compute_capability device torch types Device = None - Any cc = torch mtia get_device_capability device cc staticmethod is_triton_capable device torch types Device = None - bool True staticmethod raise_if_triton_unavailable evice torch types Device = None - None triton backends mtia triton backends backends raise RuntimeError triton built mtia backend get_xpu_stream Optional Callable int int torch xpu _is_compiled torch _C _xpu_getCurrentRawStream get_xpu_stream get_xpu_stream = None XpuInterface DeviceInterface device = torch xpu device type ignore assignment Event = torch xpu Event type ignore assignment Stream = torch xpu Stream type ignore assignment pyrefly ignore bad-override Worker staticmethod set_device device int - None caching_worker_current_devices xpu = device staticmethod current_device - int xpu caching_worker_current_devices caching_worker_current_devices xpu torch xpu current_device staticmethod get_device_properties device torch types Device = None - Any device None isinstance device str device = torch device device assert device type == xpu isinstance device torch device device = device index device None device = XpuInterface Worker current_device xpu caching_worker_device_properties device_prop = torch xpu get_device_properties i i range torch xpu device_count caching_worker_device_properties xpu = device_prop caching_worker_device_properties xpu device current_device = staticmethod torch xpu current_device set_device = staticmethod torch xpu set_device device_count = staticmethod torch xpu device_count type ignore has-type stream = staticmethod torch xpu stream type ignore assignment pyrefly ignore bad-override current_stream = staticmethod torch xpu current_stream set_stream = staticmethod torch xpu set_stream type ignore assignment _set_stream_by_id = staticmethod torch xpu _set_stream_by_id type ignore assignment synchronize = staticmethod torch xpu synchronize get_device_properties = staticmethod torch xpu get_device_properties type ignore assignment get_raw_stream = staticmethod get_xpu_stream type ignore assignment arg-type exchange_device = staticmethod torch xpu _exchange_device type ignore arg-type has-type maybe_exchange_device = staticmethod torch xpu _maybe_exchange_device type ignore arg-type has-type memory_allocated = staticmethod torch xpu memory_allocated Can mock patched patch decorator staticmethod is_available - bool torch xpu is_available staticmethod get_compute_capability device torch types Device = None - Any cc = torch xpu get_device_capability device cc staticmethod is_bf _supported including_emulation bool = False - bool torch xpu is_bf _supported staticmethod is_triton_capable device torch types Device = None - bool True staticmethod raise_if_triton_unavailable device torch types Device = None - None triton backends intel triton backends backends raise RuntimeError triton built intel backend dataclass CpuDeviceProperties multi_processor_count int CpuInterface DeviceInterface pyrefly ignore bad-override Event torch Event __init__ enable_timing bool = True - None time = elapsed_time end_event Any - float end_event time - time record stream Any = None - None time = time perf_counter pyrefly ignore bad-override Worker staticmethod get_device_properties device torch types Device = None - CpuDeviceProperties multiprocessing cpu_count = multiprocessing cpu_count CpuDeviceProperties cpu_count staticmethod is_available - bool True staticmethod is_bf _supported including_emulation bool = False - bool True staticmethod get_compute_capability device torch types Device = None - str staticmethod get_raw_stream device_idx Any - int staticmethod current_device - int staticmethod synchronize device torch types Device = None - None pass staticmethod is_triton_capable device torch types Device = None - bool True staticmethod raise_if_triton_unavailable device torch types Device = None - None triton backends cpu triton backends backends raise RuntimeError triton built cpu backend MpsInterface DeviceInterface staticmethod is_bf _supported including_emulation bool = False - bool torch backends mps is_macos_or_newer classmethod is_dtype_supported cls dtype torch dtype including_emulation bool = False - bool dtype torch float torch complex False dtype = torch bfloat cls is_bf _supported including_emulation staticmethod is_available - bool torch backends mps is_available staticmethod current_device - int staticmethod get_compute_capability device torch types Device = None - str staticmethod synchronize device torch types Device = None - None torch mps synchronize pyrefly ignore bad-override Worker staticmethod get_device_properties device torch types Device = None - Any namedtuple MPSProperties multi_processor_count torch backends mps get_core_count type ignore arg-type staticmethod current_device - int device_interfaces dict str type DeviceInterface = _device_initialized = False register_interface_for_device device Union str torch device device_interface type DeviceInterface - None isinstance device torch device device = device type device_interfaces device = device_interface get_interface_for_device device Union str torch device - type DeviceInterface isinstance device torch device device = device type _device_initialized init_device_reg device device_interfaces device_interfaces device raise NotImplementedError f No interface device device get_registered_device_interfaces - Iterable tuple str type DeviceInterface _device_initialized init_device_reg device_interfaces items init_device_reg - None global _device_initialized register_interface_for_device cuda CudaInterface i range torch cuda device_count register_interface_for_device f cuda i CudaInterface register_interface_for_device xpu XpuInterface i range torch xpu device_count register_interface_for_device f xpu i XpuInterface register_interface_for_device mtia MtiaInterface i range torch mtia device_count register_interface_for_device f mtia i MtiaInterface register_interface_for_device cpu CpuInterface register_interface_for_device mps MpsInterface _device_initialized = True