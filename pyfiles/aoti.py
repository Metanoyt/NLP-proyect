Utilities debugging reproducing issues Ahead Time Inductor AOTI compilation This file provides tools utilities - Generating minimal reproducible test cases minification - Handling exported programs graph modules - Creating debug repros AOTI compilation issues - Supporting both accuracy testing error reproduction - Managing configuration environment repro cases The main components include - Minification tools reduce test cases while preserving errors - Repro generation utilities exported programs - Error handling specific AOTI compilation - Command-line interface running managing repros argparse functools io logging os re shutil sys textwrap collections abc Sequence importlib import_module typing Any IO Optional Union torch torch _dynamo debug_utils _cuda_system_info_comment BuckTargetWriter extra_imports generate_config_string generate_env_vars_string helper_for_dump_minify InputReader minifier_dir NNModuleToString NopInputReader torch export ExportedProgram torch hub tqdm log = logging getLogger __name__ inductor_config = import_module torch _inductor config use_buck = inductor_config is_fbcode AOTIMinifierError Exception __init__ original_exception Union str Exception - None additional_message = This error caused bug AOTI minifier please report bug PyTorch full_message = f additional_message str original_exception super __init__ full_message original_exception = original_exception dump_to_minify exported_program ExportedProgram compiler_name str command str = minify options Optional dict str Any = None - None If command minify Dump exported_program ` debug_dir minifier minifier_launcher py ` minify command If command run Dump exported_program ` cwd repro py ` run command assert command minify run subdir = os path join minifier_dir checkpoints os path exists subdir os makedirs subdir exist_ok=True command == minify out = io StringIO save_graph_repro_ep out compiler_name exported_program=exported_program save_dir=subdir command= minify config_patches=options helper_for_dump_minify out getvalue curdir = os getcwd file_name = os path join curdir repro py try open file_name w fd save_graph_repro_ep fd compiler_name exported_program=exported_program config_patches=options save_dir=subdir command= run module_in_comment=True log warning Writing repro file s file_name use_buck BuckTargetWriter file_name write except OSError log warning No write permissions s file_name get_module_string gm torch fx GraphModule - str _convert_to_comment s_ str - str s = s_ split \n len s == + s_ first = s pop i range len s line = s i line strip = s i = + line s i = s = \n join s s = first + \n + s s module_string = NNModuleToString convert gm _convert_to_comment module_string save_graph_repro_ep fd IO Any compiler_name str exported_program Optional ExportedProgram = None gm Optional torch nn Module = None args Optional tuple Any = None config_patches Optional dict str str = None stable_output bool = False save_dir Optional str = None command str = run accuracy Optional Union str bool = None check_str Optional str = None module_in_comment bool = False strict bool = False - None Save graph reproducing error Either exported_program gm will saved depending which one defined Only one exported_program gm should defined exported_program None gm None raise AOTIMinifierError One exported_program gm must defined exported_program None gm None raise AOTIMinifierError Only one exported_program gm can defined gm None args None raise AOTIMinifierError If gm defined args should also defined exported_program None assert gm None assert args None exported_program = torch export export gm args strict=strict gm None gm = exported_program module check_guards=False save graph preview using gm module_string = get_module_string gm type ignore arg-type fd write module_string save graph repro using exported_program fd write generate_compiler_repro_exported_program exported_program options=config_patches stable_output=stable_output save_dir=save_dir accuracy None accuracy = _accuracy compiler_name fd write __name__ == __main__ \n fd write torch _dynamo repro aoti run_repro\n fd write f torch no_grad \n f run_repro exported_program config_patches=config_patches accuracy= accuracy r command= command r f save_dir= save_dir r check_str= check_str r \n dump_compiler_graph_state gm torch fx GraphModule args Sequence Any compiler_name str config_patches Optional dict str str = None accuracy Optional Union str bool = None strict bool = False - None subdir = os path join minifier_dir checkpoints os path exists subdir os makedirs subdir exist_ok=True file_name = os path join subdir f len gm graph nodes py log warning Writing checkpoint s nodes s len gm graph nodes file_name open file_name w fd save_graph_repro_ep fd compiler_name gm=gm args=tuple args config_patches=config_patches save_dir=subdir accuracy=accuracy module_in_comment=True strict=strict curdir = os getcwd repro_path = os path join curdir repro py try shutil copyfile file_name repro_path log warning Copying repro file convenience s repro_path use_buck BuckTargetWriter file_name write except OSError log warning No write permissions s repro_path ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ DUMP REPROS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ generate_compiler_repro_exported_program exported_program ExportedProgram options Optional dict str str = None stable_output bool = False save_dir Optional str = None - str model_str = textwrap dedent f generate_env_vars_string stable_output=stable_output torch torch _inductor inductor_prims generate_config_string stable_output=stable_output isolate_fails_code_str = None extra_imports stable_output model_str += f torch version torch version __version__ \n hasattr torch version cuda model_str += f torch cuda version torch version cuda \n hasattr torch version git_version model_str += f torch git version torch version git_version \n\n\n model_str += _cuda_system_info_comment save_dir ep_path = os path join save_dir exported_program pt ep_path = exported_program pt torch export save exported_program ep_path model_str += f exported_program = torch export load ep_path \n model_str += print exported_program graph \n model_str += f config_patches= options \n model_str repro_load_args load_args Any save_dir Optional str - tuple Any hasattr load_args _version log warning load_args does have _version attribute please file bug PyTorch describe how you generate repro script load_args _version log warning load_args version s version PyTorch only supports version We will try run anyway there may incompatibility so try upgrading your version PyTorch load_args _version nop_reader = NopInputReader load_args nop_reader tqdm desc= Loading inputs total=nop_reader total pbar input_reader = InputReader save_dir=save_dir pbar=pbar load_args input_reader args = input_reader args tuple args repro_common options Any exported_program ExportedProgram - tuple torch fx GraphModule Any Any pyrefly ignore bad-assignment torch _inductor config generate_intermediate_hooks = True mod = exported_program module check_guards=False args kwargs = exported_program example_inputs mod args kwargs type ignore return-value repro_get_args options Any exported_program ExportedProgram config_patches Optional dict str Any - tuple torch fx GraphModule Any Any mod args kwargs = repro_common options exported_program mod args kwargs repro_run options Any exported_program ExportedProgram config_patches Optional dict str Any - None torch _inductor _aoti_compile_and_package_inner gm args kwargs = repro_common options exported_program torch cuda synchronize _aoti_compile_and_package_inner gm args kwargs load_and_run=True check_accuracy=options accuracy inductor_configs=config_patches need_sync = False arg args isinstance arg torch Tensor arg is_cuda need_sync = True break need_sync synchronize ensure segfaults surfaced export_for_aoti_minifier gm torch nn Module tuple_inputs tuple Any strict bool = False skip_export_error bool = True - Optional torch nn Module Some graphs cannot used AOTI export illegal graphs these should considered graphs don t fail minifier so minifier keeps searching In these case we None Otherwise we exported graph module This won t affect minifier result because minifier only responsible catching errors AOTI export Please add list illegal graphs you change implementation here - graph output allowed export If skip_export_error=True then errors export will raised minifier will keep exploring ignore graph torch _dynamo exc UserError UserErrorType try ep = torch export export gm tuple_inputs strict=strict gm = ep module check_guards=False gm except Exception e skip_export_error None isinstance e UserError e error_type == UserErrorType INVALID_OUTPUT graph output allowed export when strict=True None isinstance e RuntimeError graph output allowed export when strict=False pattern = r Found output which known type\ re search pattern str e None None raise AOTIMinifierError e e we should never reach here None repro_minify options Any exported_program ExportedProgram config_patches Optional dict str Any - None functorch compile minifier torch _inductor _aoti_compile_and_package_inner torch _inductor compile_fx _aoti_flatten_inputs mod args kwargs = repro_common options exported_program update serialized_in_spec serialized_out_spec flat_example_inputs inductor_configs = _aoti_flatten_inputs mod args kwargs options=config_patches compiler_name = aot_inductor assert options minifier_export_mode dynamo python strict = options minifier_export_mode == dynamo skip_export_error = options skip_export_error torch cuda synchronize need_sync = False arg args isinstance arg torch Tensor arg is_cuda need_sync = True break module_fails gm torch fx GraphModule flat_example_inputs list Any check_str Optional str = None - bool Need export first so in_spec out_spec populated tuple_inputs = tuple flat_example_inputs pyrefly ignore bad-assignment gm = export_for_aoti_minifier gm tuple_inputs strict=strict skip_export_error=skip_export_error Some graphs cannot used AOTI export illegal graphs these should considered graphs don t fail minifier so minifier keeps searching gm None False assert isinstance gm torch fx GraphModule try _aoti_compile_and_package_inner gm tuple_inputs load_and_run=True check_accuracy=options accuracy inductor_configs=inductor_configs need_sync synchronize ensure segfaults surfaced False except Exception e check_str None check_str repr e False True minifier mod flat_example_inputs module_fails=functools partial module_fails check_str=options check_str dump_state=functools partial dump_compiler_graph_state compiler_name=compiler_name config_patches=config_patches accuracy=options accuracy strict=strict save_dir=options save_dir offload_to_disk=options offload_to_disk skip_offload=options skip_saving_eager_intermediates skip_sanity=options skip_sanity max_granularity=options max_granularity run_repro exported_program ExportedProgram config_patches Optional dict str str = None command str = run accuracy Union bool str = save_dir Optional str = None tracing_mode Optional str = None check_str Optional str = None minifier_export_mode str = python skip_export_error bool = True more_kwargs Any - Any k more_kwargs log warning Unrecognized kwarg s perhaps repro made newer version PyTorch k accuracy True accuracy = accuracy accuracy False accuracy = parser = argparse ArgumentParser description=f \ An AOTI repro script typically triggering bug PyTorch AOTInductor When run no arguments script defaults running command Extra flags may available find out more try command -- help There also alternate subcommands available see below default settings script accuracy= tracing_mode= save_dir= check_str= formatter_class=argparse RawTextHelpFormatter common_flags parser argparse ArgumentParser - None accuracy_group = parser add_mutually_exclusive_group accuracy_group add_argument -- no-accuracy dest= accuracy action= store_const const= default=accuracy help= do test accuracy just run module see errors accuracy_group add_argument -- accuracy action= store_const const= accuracy default=accuracy help= \ test RMSE between compiled module fp reference greater than eager fp reference This usually more reliable than standard allclose test we expect numeric differences compiling often improving accuracy over eager RMSE test allows compiled module diverge greatly eager long divergence moves closer true mathematical value network Caveats double precision can still suffer rounding error so perfect reference see example Herbie Automatically Improving Floating Point Accuracy approaches detect necessary working precision compute arbitrary precision floating point unfortunately practical tensor computation there enough samples output being compared we may get unlucky have unlucky greater RMSE than eager could overcome applying more rigorous statistical test some p-value which we leave future work accuracy_group add_argument -- strict-accuracy dest= accuracy action= store_const const= strict_accuracy default=accuracy help= \ default when doing accuracy minification we will reject reductions which change divergence floating point divergence integral boolean divergence This because some operations like ReLU involve temporarily sharp boundaries smooth out again afterwards without requiring divergence floating point minifier will often fixate divergent boolean tensor even though true source divergence However rejecting these reductions makes more difficult minifier make process Using option will let minifier progress ALL divergences -- you just might end up useful repro end parser add_argument -- save-dir type=str default=save_dir metavar= DIR help= directory where saved inputs live parser add_argument -- no-save-dir dest= save_dir action= store_const const=None help= don t use any directory saved inputs subparsers = parser add_subparsers dest= command metavar= run minify required=True parser_run = subparsers add_parser run help= just run repro common_flags parser_run parser_minify = subparsers add_parser minify help= run minifier repro common_flags parser_minify parser_get_args = subparsers add_parser get_args help= get args common_flags parser_get_args parser_minify add_argument -- skip-saving-eager-intermediates action= store_true help= skip saving eager intermediates -- minify parser_minify add_argument -- offload-to-disk action= store_true help= during minification offload delta debugging intermediates disk Use you re OOMing parser_minify add_argument -- skip-sanity action= store_true help= skip sanity check beginning minification original graph parser_minify add_argument -- max-granularity type=int default=None help= start granularity work down must power parser_minify add_argument -- check-str type=str default=check_str help= require minified program fail error containing string parser_minify add_argument -- minifier-export-mode type=str default=minifier_export_mode help= The export mode used minifier either dynamo python ` dynamo ` corresponds strict=True ` python ` corresponds strict=False parser_minify add_argument -- skip-export-error type=bool default=skip_export_error help= Skip intermediate graphs cannot exported Run repro context minification inverting exit code meaning parser_minifier_query = subparsers add_parser minifier-query common_flags parser_minifier_query parser_minifier_query add_argument -- check-str type=str default=check_str help= require minified program fail error containing string args = None len sys argv = args = command sys argv options = parser parse_args args COMMAND_FNS = minify repro_minify run repro_run get_args repro_get_args COMMAND_FNS options command options exported_program config_patches=config_patches