mypy allow-untyped-defs Copyright c Meta Platforms Inc affiliates collections abc Callable functools partial typing Any TYPE_CHECKING torch binary _apply_native_binary NATIVE_BINARY_FNS NATIVE_INPLACE_BINARY_FNS core _get_data _masks_match _maybe_get_mask is_masked_tensor MaskedTensor passthrough _apply_pass_through_fn PASSTHROUGH_FNS reductions _apply_reduction NATIVE_REDUCE_FNS TENSOR_REDUCE_FNS TORCH_REDUCE_FNS unary _apply_native_unary NATIVE_INPLACE_UNARY_FNS NATIVE_UNARY_FNS TYPE_CHECKING torch _ops OpOverload __all__ = type ignore var-annotated _check_args_kwargs_length args kwargs error_prefix len_args=None len_kwargs=None len_args None len_args = len args raise ValueError f error_prefix len args must len_args got len args len_kwargs None len_kwargs = len kwargs raise ValueError f error_prefix len kwargs must len_kwargs got len kwargs _MaskedContiguous torch autograd Function staticmethod pyrefly ignore bad-override forward ctx input is_masked_tensor input raise ValueError MaskedContiguous forward input must MaskedTensor input is_contiguous input data = input get_data mask = input get_mask MaskedTensor data contiguous mask contiguous staticmethod pyrefly ignore bad-override backward ctx grad_output grad_output _MaskedToDense torch autograd Function staticmethod pyrefly ignore bad-override forward ctx input is_masked_tensor input raise ValueError MaskedToDense forward input must MaskedTensor input layout == torch strided input ctx layout = input layout data = input get_data mask = input get_mask MaskedTensor data to_dense mask to_dense staticmethod pyrefly ignore bad-override backward ctx grad_output layout = ctx layout layout == torch sparse_coo grad_output to_sparse_coo layout == torch sparse_csr grad_output to_sparse_csr layout == torch strided grad_output to_dense raise ValueError to_dense Unsupported input layout layout _MaskedToSparse torch autograd Function staticmethod pyrefly ignore bad-override forward ctx input is_masked_tensor input raise ValueError MaskedToSparse forward input must MaskedTensor Following convention sparse tensors to_sparse always means we convert sparse_coo input layout == torch sparse_coo input data = input get_data mask = input get_mask sparse_mask = mask to_sparse_coo coalesce sparse_data = data sparse_mask sparse_mask MaskedTensor sparse_data sparse_mask staticmethod pyrefly ignore bad-override backward ctx grad_output grad_output to_dense _MaskedToSparseCsr torch autograd Function staticmethod pyrefly ignore bad-override forward ctx input is_masked_tensor input raise ValueError MaskedToSparseCsr forward input must MaskedTensor input _masked_data ndim = raise ValueError f Only D tensors can converted SparseCsr layout got shape input _masked_data size input layout == torch sparse_csr input data = input get_data mask = input get_mask sparse_mask = mask to_sparse_csr sparse_data = data sparse_mask sparse_mask MaskedTensor sparse_data sparse_mask staticmethod pyrefly ignore bad-override backward ctx grad_output grad_output to_dense _MaskedWhere torch autograd Function staticmethod pyrefly ignore bad-override forward ctx cond other ctx mark_non_differentiable cond ctx save_for_backward cond torch ops aten where cond other staticmethod pyrefly ignore bad-override backward ctx grad_output cond = ctx saved_tensors masked_out_like mt MaskedTensor mt get_data torch zeros_like mt get_mask bool None torch ops aten where cond grad_output masked_out_like grad_output torch ops aten where cond masked_out_like grad_output grad_output _MASKEDTENSOR_FUNCTION_TABLE = _function_fn_apply_map = tuple NATIVE_REDUCE_FNS tuple TORCH_REDUCE_FNS tuple TENSOR_REDUCE_FNS _apply_reduction fn_map_list apply_fn _function_fn_apply_map items fn_map fn_map_list fn fn_map _MASKEDTENSOR_FUNCTION_TABLE fn = partial apply_fn fn register_function_func ops Used registering new __torch_function__ function MaskedTensor Called via _MASKEDTENSOR_FUNCTION_TABLE func args kwargs The code register new function looks like register_function_func list_of_ops foo func args kwargs implementation wrapper func op ops _MASKEDTENSOR_FUNCTION_TABLE op = partial func op wrapper register_function_func NATIVE_REDUCE_FNS + TORCH_REDUCE_FNS + TENSOR_REDUCE_FNS _general_function_reductions func args kwargs _apply_reduction func args kwargs register_function_func torch Tensor where torch where _function_where func args kwargs _check_args_kwargs_length args kwargs __torch_function__ torch where len_args= len_kwargs= _MaskedWhere apply args register_function_func torch Tensor contiguous _function_contiguous func args kwargs _MaskedContiguous apply args register_function_func torch Tensor to_dense _function_to_dense func args kwargs _MaskedToDense apply args register_function_func torch Tensor to_sparse _function_to_sparse func args kwargs _MaskedToSparse apply args register_function_func torch Tensor to_sparse_csr _function_to_sparse_csr func args kwargs _MaskedToSparseCsr apply args _MASKEDTENSOR_DISPATCH_TABLE dict OpOverload Callable Any = register_dispatch_func aten_ops Used registering new __torch_dispatch__ function MaskedTensor Called via _MASKEDTENSOR_DISPATCH_TABLE func args kwargs The code register new function looks like register_dispatch_func list_of_ops foo func args kwargs implementation wrapper func aten_op aten_ops _MASKEDTENSOR_DISPATCH_TABLE aten_op = partial func aten_op wrapper register_dispatch_func NATIVE_REDUCE_FNS + TORCH_REDUCE_FNS + TENSOR_REDUCE_FNS _general_reduction func args kwargs _apply_reduction func args kwargs register_dispatch_func PASSTHROUGH_FNS _general_passthrough func args kwargs _apply_pass_through_fn func args kwargs register_dispatch_func NATIVE_UNARY_FNS + NATIVE_INPLACE_UNARY_FNS _general_unary func args kwargs _apply_native_unary func args kwargs register_dispatch_func NATIVE_BINARY_FNS + NATIVE_INPLACE_BINARY_FNS _general_binary func args kwargs _apply_native_binary func args kwargs register_dispatch_func torch ops aten stride stride func args kwargs None register_dispatch_func torch ops aten sym_stride sym_stride func args kwargs None register_dispatch_func torch ops prim layout layout func args kwargs _get_data args layout register_dispatch_func torch ops aten is_contiguous torch ops aten sym_is_contiguous is_contiguous func args kwargs data = _get_data args data is_sparse raise ValueError MaskedTensors sparse data do have is_contiguous func data args kwargs register_dispatch_func torch ops aten is_strides_like_format is_strides_like_format func args kwargs data = _get_data args data is_sparse raise ValueError MaskedTensors sparse data do have is_strides_like_format func data args kwargs register_dispatch_func torch ops aten is_non_overlapping_and_dense is_non_overlapping_and_dense func args kwargs data = _get_data args data is_sparse raise ValueError MaskedTensors sparse data do have is_non_overlapping_and_dense func data args kwargs register_dispatch_func torch ops aten contiguous contiguous func args kwargs _get_data args is_sparse raise ValueError MaskedTensors sparse data do have contiguous _MaskedContiguous apply args register_dispatch_func torch ops aten new_empty_strided new_empty_strided func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= data = _get_data args mask = _maybe_get_mask args tuple args = tuple data size raise ValueError f __torch_dispatch__ func args expected same data size tuple args = tuple data stride raise ValueError f __torch_dispatch__ func args expected same data stride MaskedTensor func data args args kwargs mask register_dispatch_func torch ops aten _local_scalar_dense _local_scalar_dense func args kwargs _maybe_get_mask args raise ValueError f __torch_dispatch__ func expected mask tensor torch ops aten _local_scalar_dense _get_data args register_dispatch_func torch ops aten detach torch ops aten clone _apply_fn_on_data func args kwargs MaskedTensor func _get_data args _maybe_get_mask args register_dispatch_func torch ops aten _to_copy _to_copy func args kwargs new_data = func _get_data args args kwargs cloned_kwargs = kwargs copy cloned_kwargs dtype = torch bool new_mask = func _maybe_get_mask args args cloned_kwargs MaskedTensor new_data new_mask register_dispatch_func torch ops aten _softmax _softmax func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= data = _get_data args mask = _maybe_get_mask args result_data = torch ops aten _masked_softmax data ~mask args MaskedTensor result_data mask register_dispatch_func torch ops aten ones_like ones_like func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= result_data = func _get_data args kwargs MaskedTensor result_data _maybe_get_mask args register_dispatch_func torch ops aten _softmax_backward_data _softmax_backward_data func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= grad output dim _input_dtype = args is_masked_tensor grad is_masked_tensor output _masks_match grad output raise ValueError f __torch_dispatch__ func expected masks grad output match grad_data = _get_data grad new_grad_data = torch ops aten _masked_softmax_backward grad_data _get_data output ~_maybe_get_mask grad dim grad_data ndim res = MaskedTensor new_grad_data _maybe_get_mask grad res raise ValueError f __torch_dispatch__ func grad output must both MaskedTensors register_dispatch_func torch ops aten copy_ copy_ func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= _masks_match _maybe_get_mask args _maybe_get_mask args raise ValueError args mask args mask must match do func _get_data args _get_data args args register_dispatch_func torch ops aten where where func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= torch is_tensor args raise ValueError f __torch_dispatch__ func expected args tensor mx = args my = args is_masked_tensor mx mx = MaskedTensor mx torch ones_like mx dtype=torch bool is_masked_tensor my my = MaskedTensor my torch ones_like my dtype=torch bool new_data = func args mx get_data my get_data new_mask = func args mx get_mask my get_mask MaskedTensor new_data new_mask register_dispatch_func torch ops aten _to_sparse _to_sparse func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= torch is_tensor args raise TypeError f __torch_dispatch__ func expected args tensor mt = args is_masked_tensor mt mt = MaskedTensor mt torch ones_like mt dtype=torch bool mt is_sparse_coo mt new_mask = func _maybe_get_mask args coalesce new_data = _get_data args sparse_mask new_mask MaskedTensor new_data new_mask register_dispatch_func torch ops aten _to_sparse_csr _to_sparse_csr func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= torch is_tensor args raise ValueError f __torch_dispatch__ func expected args tensor mt = args is_masked_tensor mt mt = MaskedTensor mt torch ones_like mt bool mt is_sparse_csr mt new_mask = func _maybe_get_mask args new_data = _get_data args sparse_mask new_mask MaskedTensor new_data new_mask register_dispatch_func torch ops aten _to_dense _to_dense func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= torch is_tensor args raise ValueError f __torch_dispatch__ func expected args tensor mt = args is_masked_tensor mt mt = MaskedTensor mt torch ones_like mt bool new_data = func _get_data args new_mask = func _maybe_get_mask args MaskedTensor new_data new_mask register_dispatch_func torch ops aten _indices _indices func args kwargs Assumes data sparse _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= data = _get_data args indices MaskedTensor data torch ones_like data bool register_dispatch_func torch ops aten _values _values func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= data = _get_data args values MaskedTensor data torch ones_like data bool register_dispatch_func torch ops aten _sparse_coo_tensor_with_dims_and_tensors _sparse_coo_tensor_with_dims_and_tensors func args kwargs new_args = list args is_masked_tensor args - new_args - = args - get_data is_masked_tensor args - new_args - = args - get_data new_data = func new_args kwargs new_args - = torch ones_like new_args - new_mask = func new_args kwargs bool MaskedTensor new_data new_mask register_dispatch_func torch ops aten is_same_size is_same_size func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= _get_data args is_same_size _get_data args register_dispatch_func torch ops aten _is_any_true _is_any_true func args kwargs _check_args_kwargs_length args kwargs f __torch_dispatch__ func len_args= len_kwargs= data = _get_data args mask = _maybe_get_mask args mask None raise ValueError f __torch_dispatch__ func expected args MaskedTensor data dtype = torch bool raise ValueError f __torch_dispatch__ func expected boolean tensor data is_sparse raise ValueError f MaskedTensors sparse data do have func MaskedTensor func data mask torch tensor True