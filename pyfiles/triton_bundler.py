copy dataclasses logging os shutil uuid pathlib Path typing Optional torch _dynamo utils counters dynamo_timed set_feature_use torch _utils_internal justknobs_check torch utils _filelock FileLock runtime runtime_utils triton_cache_dir utils _IS_WINDOWS GPU_KERNEL_BIN_EXTS log = logging getLogger __name__ dataclasses dataclass frozen=True TritonBundleEntry When we have compiled triton kernel we take note kernel its triton generated hash its device where kernel located This minimum information we can use later retrieve kernel file system kernel_hash str device int directory str dataclasses dataclass frozen=True TritonKernelArtifact Artifact individual kernel converted bytes Bytes could cubin json ttir ttgir filename str payload bytes = dataclasses field repr=False Do display binary dataclasses dataclass frozen=True StaticallyLaunchedAutotuner Represents statically compiled CachingAutotuner object we can save directly cache A CachingAutotuner made up list StaticTritonCompileResults each which uses cubin TritonKernelArtifact Statically saved here have their cubin files saved corresponding TritonBundleEntry cache_key str kernel_name str kernel CachingAutotuner type ignore name-defined noqa F dataclasses dataclass frozen=True TritonKernelArtifacts Collection artifacts particular kernel kernel_hash str device int artifacts list TritonKernelArtifact dataclasses dataclass frozen=True TritonBundlerMetadata Metadata used instrumentation cached_kernel_names list str statically_launched_kernel_names list str dataclasses dataclass frozen=True TritonBundle Serializable bundle save into FXGraphCache kernel_artifacts list TritonKernelArtifacts static_autotuners list StaticallyLaunchedAutotuner TritonBundler Lightweight Triton Kernel bundler notes each time we compile triton kernel When collect called converts all previously noted kernels their artifacts into structured bytes blob later when write called writes structured blob back file system Intended Life cycle - TritonBundler begin_compile called when we start compiling Inductor - TritonBundler put called each time Triton Kernel compiled - TritonBundler collect called when cache entry being generated - TritonBundler end_compile called indicate bundling completed collect will execute function well - TritonBundler read_and_emit called when cache entry read _entries Optional list TritonBundleEntry = None _static_autotuners Optional list StaticallyLaunchedAutotuner = None __grp__kernel_name json contains metadata source code paths we use sentinel value search replace _REPLACE_BYTES bytes = b REPLACE staticmethod is_enabled - bool torch _inductor config config force_disable_caches False b = config bundle_triton_into_fx_graph_cache None b config is_fbcode False justknobs_check pytorch remote_cache bundle_triton_into_fx_graph_cache_v classmethod begin_compile cls - None Initializes TritonBundler The current TritonBundler bundle finalized TritonBundler collect TritonBundler is_enabled log debug TritonBundler begin_compile called assert cls _entries None cls _entries = cls _static_autotuners = classmethod end_compile cls - None Finalizes TritonBundler If collect yet called discards current bundle log debug TritonBundler end_compile called cls _entries = None cls _static_autotuners = None classmethod put cls kernel_hash str device int - None Lazily observes we have seen Triton kernel compilation Remembers when collect later called entries = cls _entries None entries append TritonBundleEntry kernel_hash device triton_cache_dir device classmethod put_static_autotuner cls key str kernel CachingAutotuner - None type ignore name-defined noqa F torch _inductor config assert config use_static_cuda_launcher entries = cls _static_autotuners None Clear bunch unpicklable values make copy save FXGraphCache old_values = kernel prepare_for_pickle new_kernel = copy deepcopy kernel new_kernel prepare_for_caching new_kernel _reload_kernel = None entries append StaticallyLaunchedAutotuner key new_kernel inductor_meta get kernel_name unknown_kernel new_kernel Put values back since we need use now kernel restore_after_unpickle old_values classmethod collect_static_autotuners cls - tuple list StaticallyLaunchedAutotuner list str cls _static_autotuners log info Saving d statically launchable CachingAutotuners len cls _static_autotuners static_autotuner_names = i kernel_name i cls _static_autotuners counters inductor triton_bundler_save_static_autotuner += cls _static_autotuners static_autotuner_names classmethod load_autotuners cls static_autotuners Optional list StaticallyLaunchedAutotuner - list str Load statically launchable CachingAutotuners into async_compile CompiledTritonKernels cache static_autotuners torch _inductor async_compile CompiledTritonKernels torch _inductor codecache StaticAutotunerFuture log info Loading d statically launchable autotuners len static_autotuners kernel_names = dynamo_timed TritonBundler load_cached_static_autotuners result static_autotuners try Make sure cubin path exists valid compile_result result kernel compile_results compile_result reload_cubin_path except RuntimeError log warning Failed reload cubin file statically launchable autotuner s result kernel_name exc_info=True continue We make future instead returning kernel here so kernels statically launchable i e cache miss can launch worker without waiting blocking step StaticAutotunerFuture result CompiledTritonKernels _cache result cache_key = StaticAutotunerFuture result kernel counters inductor triton_bundler_load_static_autotuner += kernel_names append result kernel_name kernel_names classmethod collect cls - tuple TritonBundle Optional TritonBundlerMetadata This main function called when cache write happens This function converts all previously remembered kernels into bundled format so can written into cache entry This function also finalizes current bundle torch _inductor config TritonBundler is_enabled cls end_compile set_feature_use triton_bundling False TritonBundle None set_feature_use triton_bundling True dynamo_timed key= TritonBundler collect log_pt _compile_event=True entries = cls _entries entries None result list TritonKernelArtifacts = kernel_names list str = entry entries artifacts list TritonKernelArtifact = path = os path join entry directory entry kernel_hash os path exists path continue filename os listdir path filepath = os path join path filename try assert os path isfile filepath open filepath rb file payload = file read filepath endswith json Make sure there s no sentinel value TritonBundler _REPLACE_BYTES payload log warning Bundle contains illegal s payload s TritonBundler _REPLACE_BYTES payload raise AssertionError Bundle contains illegal bytes Remove path payload payload = payload replace str encode path TritonBundler _REPLACE_BYTES artifacts append TritonKernelArtifact filename payload counters inductor triton_bundler_save_kernel += except Exception log debug failed collect triton kernel exc_info=True extension = os path splitext filename extension GPU_KERNEL_BIN_EXTS values Each kernel has bunch files like cubin cuda spv xpu json ttir Just append one them without extension kernel_names append Path filename stem artifacts result append TritonKernelArtifacts entry kernel_hash entry device artifacts config use_static_cuda_launcher static_autotuners static_kernel_names = cls collect_static_autotuners static_autotuners = static_kernel_names = cls end_compile TritonBundle result static_autotuners TritonBundlerMetadata kernel_names static_kernel_names TritonBundle None staticmethod read_and_emit bundle TritonBundle - Optional TritonBundlerMetadata This main function called when cache read happens This function converts bundled format back into individual files writes them filesystem NOTE When we writing filesystem we assume exclusive access target directory This means target folder already exists non-empty we bail out Exclusive access means no other process should writing reading target directory torch _inductor config TritonBundler is_enabled None dynamo_timed key= TritonBundler read_and_emit log_pt _compile_event=True kernel_names list str = artifacts bundle kernel_artifacts basedir = triton_cache_dir artifacts device directory = os path join basedir artifacts kernel_hash os path exists directory len os listdir directory = If directory already exists we bail out leave local disk take care caching log debug Bailing out TritonBundler read_and_emit s non empty directory continue Path basedir mkdir parents=True exist_ok=True Random ID avoid any collisions rnd_id = str uuid uuid tmp_dir = os path join basedir f tmp rnd_id os makedirs tmp_dir artifact artifacts artifacts filepath = os path join tmp_dir artifact filename open filepath wb file payload = artifact payload artifact filename endswith json payload = payload replace TritonBundler _REPLACE_BYTES str encode directory file write payload counters inductor triton_bundler_read_and_emit_kernel += extension = os path splitext artifact filename extension GPU_KERNEL_BIN_EXTS values Each kernel has bunch files like cubin cuda spv xpu json ttir Just append one them without extension kernel_names append Path artifact filename stem _IS_WINDOWS FileLock directory + lock os path exists directory shutil rmtree directory os replace tmp_dir directory Atomic POSIX systems try os replace tmp_dir directory except OSError log warning Directory s empty - skipping tmp_dir config use_static_cuda_launcher static_kernel_names = TritonBundler load_autotuners bundle static_autotuners static_kernel_names = TritonBundlerMetadata kernel_names static_kernel_names