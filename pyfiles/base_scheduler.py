mypy allow-untyped-defs warnings weakref functools wraps torch ao pruning sparsifier base_sparsifier BaseSparsifier __all__ = BaseScheduler BaseScheduler __init__ sparsifier last_epoch=- verbose=False Attach sparsifier isinstance sparsifier BaseSparsifier raise TypeError f type sparsifier __name__ instance torch ao pruning BaseSparsifier sparsifier = sparsifier Initialize epoch base sparsity levels base_sl = group sparsity_level group sparsifier groups last_epoch = last_epoch Following https github com pytorch pytorch issues We would like ensure ` scheduler step ` called after ` sparsifier step ` with_counter method getattr method _with_counter False ` sparsifier step ` has already been replaced method Keep weak reference sparsifier instance prevent cyclic references instance_ref = weakref ref method __self__ Get unbound method same purpose func = method __func__ cls = instance_ref __class__ del method wraps func wrapper args kwargs instance = instance_ref instance _step_count += type ignore union-attr wrapped = func __get__ instance cls wrapped args kwargs Note returned function here no longer bound method so attributes like ` __func__ ` ` __self__ ` no longer exist wrapper _with_counter = True type ignore attr-defined wrapper sparsifier step = with_counter sparsifier step type ignore assignment sparsifier _step_count = type ignore attr-defined _step_count int = verbose = verbose Housekeeping _get_sl_called_within_step bool = False step state_dict Returns state scheduler ` dict ` It contains entry every variable __dict__ which sparsifier key value key value __dict__ items key = sparsifier load_state_dict state_dict Loads schedulers state Args state_dict dict scheduler state Should object returned call meth ` state_dict ` __dict__ update state_dict get_last_sl Return last computed sparsity level current scheduler _last_sl get_sl Compute sparsity level using chainable form scheduler Note This method intended called directly only used step method Use get_last_sl instead _get_sl_called_within_step warnings warn To get last sparsity level computed scheduler please use ` get_last_sl ` stacklevel= raise NotImplementedError print_sl is_verbose group sl epoch=None Display current sparsity level is_verbose epoch None print f Adjusting sparsity level group group sl e print f Epoch epoch d adjusting sparsity level group group sl e __repr__ format_string = __class__ __name__ + format_string += \n format_string += f Sparsifier sparsifier \n format_string += f base_sl base_sl \n format_string += format_string step epoch=None Raise warning trying call scheduler step before sparsifier https github com pytorch pytorch issues _step_count == hasattr sparsifier step _with_counter warnings warn Seems like ` sparsifier step ` has been overridden after sparsity scheduler initialization Please make sure call ` sparsifier step ` before ` scheduler step ` UserWarning stacklevel= Just check there two first scheduler step calls before sparsifier step sparsifier _step_count type ignore attr-defined warnings warn Detected call ` scheduler step ` before ` sparsifier step ` You have make sure you run sparsifier step BEFORE any calls scheduler step UserWarning stacklevel= _step_count += _enable_get_sl_call __init__ o o = o __enter__ o _get_sl_called_within_step = True __exit__ type value traceback o _get_sl_called_within_step = False _enable_get_sl_call last_epoch += values = get_sl i data enumerate zip sparsifier groups values param_group sl = data param_group sparsity_level = sl print_sl verbose i sl epoch _last_sl = group sparsity_level group sparsifier groups sparsifier enable_mask_update = True _make_sure_a_list var r Utility extends same length groups ensuring list n = len sparsifier groups isinstance var list tuple var n len var = n raise ValueError f Expected variable length n got len var list var We want result list tuple