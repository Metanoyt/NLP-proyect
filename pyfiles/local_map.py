Copyright c Facebook Inc its affiliates All rights reserved This source code licensed under BSD license found LICENSE file root directory source tree NOTE file may removed once we move dynamo frontend contextlib functools collections abc Callable Generator contextlib contextmanager typing Any Optional Sequence TypeAlias torch torch utils _pytree pytree torch _C DispatchKey torch _higher_order_ops utils clone_outputs_aliasing_inputs redirect_to_mode save_tensors_and_symints_for_backward saved_tensors_and_symints torch _ops HigherOrderOperator torch _subclasses fake_tensor FakeTensor FakeTensorMode torch _subclasses functional_tensor FunctionalTensor torch fx GraphModule torch fx experimental proxy_tensor ProxyTorchDispatchMode track_tensor_tree torch utils checkpoint _CachedTorchDispatchMode _CachingTorchDispatchMode Proxy HOP instead inlining into And trace local shapes AP _DEFER_INLINING = False GraphArg TypeAlias = tuple torch Tensor int torch SymInt None contextmanager defer_inlining - Generator None None None global _DEFER_INLINING prior = _DEFER_INLINING try _DEFER_INLINING = True yield finally _DEFER_INLINING = prior Used unwrap tensors classes like FunctionalTensor Parameter _new_tensor t Any new_shape Optional Sequence int = None new_stride Optional Sequence int = None - Any isinstance t torch Tensor assert type t FunctionalTensor FakeTensor torch Tensor f No subclasses support now found type t torch empty_strided t size new_shape None new_shape t stride new_stride None new_stride device=t device dtype=t dtype requires_grad=t requires_grad t Autoparallel specific we want treat plain tensors DTensors _redistribute args Any all_placements tuple Any mesh Any shape_stride_fn Callable torch Tensor Any Any tuple list int list int - GraphArg torch _dispatch python suspend_functionalization torch _guards detect_fake_mode torch _subclasses functional_tensor disable_functional_mode torch fx experimental proxy_tensor disable_proxy_modes_tracing suspend_functionalization disable_functional_mode disable_proxy_modes_tracing fake_mode = detect_fake_mode args assert fake_mode None defer_inlining only supported FakeTensors fake_mode new_args = list pytree tree_map _new_tensor args i tensor placements enumerate zip new_args all_placements tensor None Sometimes gradients can None continue new_shape new_stride = shape_stride_fn tensor mesh placements new_args i = _new_tensor tensor new_shape=new_shape new_stride=new_stride new_args = tuple new_args assert all isinstance t FakeTensor int torch SymInt type None t new_args f Unexpected element args= new_args redistribute_fw_inputs global_args Any all_placements Any mesh Any _ Optional int = None - GraphArg assert len global_args == len all_placements _redistribute global_args all_placements mesh torch distributed tensor _utils compute_local_tensor_info redistribute_fw_outputs local_outs Any all_placements Any mesh Any num_activations int - GraphArg assert len local_outs == len all_placements + num_activations num_fw_outs = len local_outs - num_activations assert num_fw_outs outs activations = local_outs num_fw_outs local_outs num_fw_outs _redistribute outs all_placements mesh torch distributed tensor _utils compute_global_tensor_info activations redistribute_bw_inputs global_args Any all_placements Any mesh Any num_activations int - GraphArg assert len global_args == len all_placements + num_activations activations inputs = global_args num_activations global_args num_activations assert len inputs local_inputs = _redistribute inputs all_placements mesh torch distributed tensor _utils compute_local_tensor_info activations local_inputs redistribute_bw_outputs local_outs Any all_placements Any mesh Any _ Optional int = None - GraphArg assert len local_outs == len all_placements _redistribute local_outs all_placements mesh torch distributed tensor _utils compute_global_tensor_info LocalMapHOP HigherOrderOperator __init__ - None super __init__ local_map_hop __call__ gm GraphModule args Any kwargs Any - Any super __call__ gm args kwargs local_map_hop = LocalMapHOP Registers dispatches SAC redirect_to_mode local_map_hop _CachingTorchDispatchMode redirect_to_mode local_map_hop _CachedTorchDispatchMode create_hop_fw_bw fw_gm GraphModule _args Any - tuple GraphModule GraphModule int int set int Traces joint applies passes partitions Keeping these imports here Avoid circular dependencies once we upstream dynamo frontend torch _dispatch python suspend_functionalization torch _functorch aot_autograd AOTConfig create_joint torch _guards detect_fake_mode torch _subclasses fake_tensor FakeTensor FakeTensorMode torch _subclasses functional_tensor disable_functional_mode torch fx experimental proxy_tensor disable_proxy_modes_tracing make_fx local_map_kwargs = fw_gm meta local_map_kwargs type ignore attr-defined assert in_placements local_map_kwargs assert out_placements local_map_kwargs assert device_mesh local_map_kwargs assert len local_map_kwargs in_placements == len _args dummy_aot_config = AOTConfig fw_compiler=None type ignore arg-type bw_compiler=None type ignore arg-type partition_fn=None type ignore arg-type decompositions= num_params_buffers= aot_id= keep_inference_input_mutations=False suspend_functionalization disable_functional_mode disable_proxy_modes_tracing If someone runs hop under default compiler backend eager Then path will run actual user inputs We convert them fake tensors order perform any actual compute fake_mode = detect_fake_mode _args fake_mode None fake_mode = FakeTensorMode allow_non_fake_inputs=True fake_mode fw_inputs = redistribute_fw_inputs _args local_map_kwargs in_placements local_map_kwargs device_mesh assert len fw_inputs == len local_map_kwargs in_placements assert all isinstance t FakeTensor int torch SymInt t fw_inputs f Unexpected element fw_inputs= ctx = fake_mode shape_env ignore_fresh_unbacked_symbols fake_mode shape_env None contextlib nullcontext ctx fw_outs = fw_gm fw_inputs example_grads = pytree tree_map _new_tensor fw_outs isinstance example_grads list tuple example_grads = example_grads num_fw_inputs = len fw_inputs num_fw_outputs = len example_grads joint_f primals_and_tangents list torch Tensor - Any primals = primals_and_tangents num_fw_inputs tangents = primals_and_tangents num_fw_inputs prepare_fw_with_masks fw_gm torch fx GraphModule - Callable Any fw_with_masks args Any - tuple tuple Any list bool The Interpreter here required propagate metadata dynamo graph body local_map graph body This required fx_traceback annotate work fw_out = torch fx Interpreter fw_gm run args assert isinstance fw_out tuple Dynamo traced submodule should tuple fw_out bool isinstance ret torch Tensor ret requires_grad ret fw_out fw_with_masks fw_outs grads = create_joint prepare_fw_with_masks fw_gm aot_config=dummy_aot_config primals tangents torch fx experimental symbolic_shapes has_free_unbacked_symbols assert has_free_unbacked_symbols fw_outs grads Unbacked symints leaking outside joint graph yet supported maybe_clone = clone_outputs_aliasing_inputs primals_and_tangents put grads first work existing hop utils pytree tree_map maybe_clone grads fw_outs filtered_grads_idx = set i example_grad enumerate example_grads Filter out grads None do require_grad The AOTAutograd utils we rely force assumption We must also filter runtime tangents too example_grad None isinstance example_grad torch Tensor example_grad requires_grad filtered_grads_idx add i primals_and_tangents = fw_inputs example_grads i i filtered_grads_idx joint_hop_gm = make_fx joint_f primals_and_tangents torch _functorch _aot_autograd graph_capture copy_fwd_metadata_to_bw_nodes copy_fwd_metadata_to_bw_nodes joint_hop_gm torch _functorch _aot_autograd graph_compile prepare_for_partitioner torch _inductor compile_fx partition_fn Match partitioner convention prepped_joint_hop_gm = prepare_for_partitioner joint_hop_gm num_fw_inputs num_fw_outputs disable_proxy_modes_tracing Also runs joint passes new_fw_gm new_bw_gm = partition_fn prepped_joint_hop_gm num_fwd_outputs=num_fw_outputs static_lifetime_input_indices= Propagate meta onto fw bw graphs later will set proxied nodes new_fw_gm meta local_map_kwargs = local_map_kwargs new_bw_gm meta local_map_kwargs = local_map_kwargs Okay because Autoparallel assumes same sharding between param grads new_bw_gm meta local_map_kwargs in_placements = tuple local_map_kwargs out_placements i i filtered_grads_idx new_bw_gm meta local_map_kwargs out_placements = local_map_kwargs in_placements Validate Forward fw_kwargs = new_fw_gm meta local_map_kwargs expected_fw_inputs = len fw_kwargs in_placements expected_fw_outputs = len fw_kwargs out_placements actual_fw_inputs = len new_fw_gm graph find_nodes op= placeholder actual_fw_outputs = num_fw_outputs assert expected_fw_inputs == actual_fw_inputs assert expected_fw_outputs == actual_fw_outputs Validate Activations assert len new_fw_gm graph find_nodes op= output == num_activations = len new_fw_gm graph find_nodes op= output args - num_fw_outputs tensors first then symints assert num_activations = Validate Backward bw_kwargs = new_bw_gm meta local_map_kwargs expected_bw_inputs = len bw_kwargs in_placements expected_bw_outputs = len bw_kwargs out_placements actual_bw_inputs = len new_bw_gm graph find_nodes op= placeholder - num_activations assert actual_bw_inputs assert expected_fw_inputs + expected_bw_inputs == len primals_and_tangents assert actual_fw_inputs + actual_bw_inputs == len primals_and_tangents assert len new_bw_gm graph find_nodes op= output == actual_bw_outputs = len new_bw_gm graph find_nodes op= output args assert expected_bw_inputs == actual_bw_inputs assert expected_bw_outputs == actual_bw_outputs new_fw_gm meta num_activations = num_activations new_fw_gm meta is_backward = False new_bw_gm meta num_activations = num_activations new_bw_gm meta is_backward = True new_fw_gm new_bw_gm num_fw_inputs num_fw_outputs filtered_grads_idx LocalMapAutogradOp torch autograd Function staticmethod pyrefly ignore bad-override forward ctx Any fw_gm GraphModule bw_gm GraphModule num_fw_ins int num_fw_outs int filtered_grads_idx set int args Any kwargs Any - tuple Optional torch Tensor torch _functorch _aot_autograd schemas MemoryFormatMeta ctx bw_gm = bw_gm ctx num_fw_ins = num_fw_ins ctx filtered_grads_idx = filtered_grads_idx torch _C _AutoDispatchBelowAutograd fw_outs_with_saved_activations = local_map_hop fw_gm args kwargs fw_outs = fw_outs_with_saved_activations num_fw_outs saved_activations = fw_outs_with_saved_activations num_fw_outs save_tensors_and_symints_for_backward ctx saved_activations ctx expected_tangent_metadata = i MemoryFormatMeta from_tensor fw_outs i i filtered_grads_idx fw_outs staticmethod backward ctx Any _grads tuple torch Tensor - tuple Optional torch Tensor torch _functorch _aot_autograd runtime_wrappers coerce_to_expected_memory_format assert ctx pos == sorted ctx pos Interleaving saved tensor activations symints expected min-cut partitioner ctx pos = list reversed ctx pos make saved_tensors_and_symints symints first saved_activations = saved_tensors_and_symints ctx torch _C _AutoDispatchBelowAutograd Filter out grads None do require_grad The AOTAutograd utils we rely force assumption grads = _grads i i ctx filtered_grads_idx assert len grads == len ctx expected_tangent_metadata f len grads = vs len ctx expected_tangent_metadata i meta ctx expected_tangent_metadata items pyrefly ignore bad-argument-type grads i = coerce_to_expected_memory_format grads i meta grad_ins = local_map_hop ctx bw_gm saved_activations grads len grad_ins = ctx num_fw_ins raise RuntimeError f Expected ctx num_fw_ins grad_ins got len grad_ins None None None None None grad_ins local_map_hop py_impl torch _C DispatchKey Autograd autograd_key fw_gm GraphModule args Any kwargs Any - Any local_map_kwargs = fw_gm meta local_map_kwargs type ignore attr-defined assert local_map_kwargs get in_grad_placements None None local_map in_grad_placements yet supported _DEFER_INLINING fw_gm bw_gm num_fw_ins num_fw_outs filtered_grads_idx = create_hop_fw_bw fw_gm args LocalMapAutogradOp apply fw_gm bw_gm num_fw_ins num_fw_outs filtered_grads_idx args kwargs TODO get rid when we can install subgraph torch fx Interpreter fw_gm run args kwargs local_map_hop py_functionalize_impl functional_mode_key ctx Any gm GraphModule args Any kwargs Any - tuple torch Tensor assert kwargs unwrapped_inputs = ctx unwrap_tensors args ctx redispatch_to_next out = local_map_hop gm unwrapped_inputs ctx wrap_tensors out local_map_hop py_impl FakeTensorMode fake_mode_key mode FakeTensorMode gm GraphModule args Any kwargs Any - GraphArg mode _DEFER_INLINING gm args kwargs otherwise we need convert local shapes AP is_backward = gm meta is_backward redistribute_inputs = redistribute_bw_inputs is_backward redistribute_fw_inputs local_args = redistribute_inputs args gm meta local_map_kwargs in_placements gm meta local_map_kwargs device_mesh gm meta num_activations local_outs = gm local_args redistribute_outputs = redistribute_bw_outputs is_backward redistribute_fw_outputs global_outs = redistribute_outputs local_outs gm meta local_map_kwargs out_placements gm meta local_map_kwargs device_mesh gm meta num_activations global_outs proxy_mode_key_common call_hop Callable Any proxy_mode ProxyTorchDispatchMode gm GraphModule args Any kwargs Any - tuple torch Tensor assert proxy_mode None Mode should always enabled python fallback key assert len kwargs == example_out = call_hop args kwargs proxy_args = pytree tree_map proxy_mode tracer unwrap_proxy args type ignore union-attr out_proxy = proxy_mode tracer create_proxy call_function call_hop proxy_args extract local_map args post-dispatch operates GraphModules assert gm meta local_map_kwargs local_map_kwargs = gm meta local_map_kwargs propagate local_map args call_function node out_proxy node meta local_map_kwargs = local_map_kwargs track_tensor_tree example_out out_proxy constant=None tracer=proxy_mode tracer local_map_hop py_impl ProxyTorchDispatchMode proxy_mode_key proxy_mode ProxyTorchDispatchMode gm GraphModule args Any kwargs Any - tuple torch Tensor TODO get rid when we can install subgraph call_local_map _args Any _kwargs Any - Any functools partial local_map_hop gm _args _kwargs proxy_mode_key_common call_local_map proxy_mode gm args kwargs Running HOP eager real tensors local_map_hop py_impl DispatchKey CompositeExplicitAutograd real_impl gm GraphModule args Any kwargs Any - tuple torch Tensor gm args kwargs