Owner s module dynamo contextlib importlib util os re tempfile torch _dynamo config torch _dynamo test_case torch _inductor mock_cache mock_cache torch compiler config torch nested torch _dynamo testing CompileCounter torch _inductor cpp_builder normalize_path_separator torch _inductor utils clear_caches fresh_cache torch testing _internal common_utils IS_WINDOWS PgoTest torch _dynamo test_case TestCase setUp super setUp _test_stack = contextlib ExitStack _test_stack enter_context torch compiler config patch job_id=self id _test_stack enter_context torch _dynamo config patch automatic_dynamic_local_pgo=True os environ get INDUCTOR_TEST_DISABLE_FRESH_CACHE = _test_stack enter_context fresh_cache mock_cache PatchCaches setUp tearDown super tearDown torch _dynamo reset _test_stack close mock_cache PatchCaches tearDown reset torch _dynamo reset clear_caches test_basic cnts = CompileCounter torch compile backend=cnts fullgraph=True f x x f torch randn f torch randn assertEqual cnts frame_count reset cnts clear f torch randn f torch randn assertEqual cnts frame_count torch _dynamo config patch force_parameter_static_shapes=False force_nn_module_property_static_shapes=False test_whitelist_suggestion torch _dynamo pgo _collect_dynamic_sources _collect_missing_sources get_code_state render_code_state cnts = CompileCounter torch compile backend=cnts fullgraph=True Foo torch nn Module __init__ super __init__ lin = torch nn Linear attr = torch randn forward x y lin x + attr + y sources = L x L _modules lin _parameters weight L _modules lin _parameters bias L attr L y check_whitelist sources_ state = render_code_state get_code_state whitelist = re search r TORCH_COMPILE_DYNAMIC_SOURCES= state group src sources_ assertTrue src whitelist check_num_missing_whitelist expected frame_state = next iter get_code_state values all_dynamic_sources = _collect_dynamic_sources frame_state missing_whitelist = _collect_missing_sources all_dynamic_sources assertEqual len missing_whitelist expected check growing whitelist f = Foo f torch randn torch randn only x f torch randn torch randn check_whitelist sources x lin weight f lin = torch nn Linear f torch randn torch randn check_whitelist sources x y lin weight lin bias attr f lin = torch nn Linear f attr = torch randn f torch randn torch randn check_whitelist sources check_num_missing_whitelist now use suggested whitelist reset cnts clear code_state = get_code_state state = render_code_state code_state whitelist = re search r TORCH_COMPILE_DYNAMIC_SOURCES= state group torch compiler config patch dynamic_sources=whitelist f = Foo f torch randn torch randn f torch randn torch randn f lin = torch nn Linear f attr = torch randn f torch randn torch randn assertEqual cnts frame_count check_num_missing_whitelist test_no_empty_graph_allowlist torch _dynamo disable g x x + x torch compile backend= eager f x g x reset f torch randn f torch randn assertEqual torch _dynamo pgo _LOGGED_DYNAMIC_ALLOWLIST False torch compile backend= eager f x g x + + reset f torch randn f torch randn assertEqual torch _dynamo pgo _LOGGED_DYNAMIC_ALLOWLIST True test_pgo_dynamic_false torch compile backend= eager dynamic=False Foo torch nn Module forward x y x += y += torch _dynamo graph_break x -= y = x y reset f = Foo f torch randn torch randn f torch randn torch randn check PGO code state overwritten static value both before after graph break code_state torch _dynamo pgo get_code_state values assertEqual code_state automatic_dynamic L x size assertEqual code_state automatic_dynamic L y size test_whitelist_ints_floats torch compile backend= eager fullgraph=True Bar torch nn Module __init__ c d super __init__ c = c d = d forward x y z d == x += c == x + y + torch tensor z f = Bar f f d = f state = torch _dynamo pgo render_code_state torch _dynamo pgo get_code_state whitelist = re search r TORCH_COMPILE_DYNAMIC_SOURCES= state group assertTrue L x whitelist assertTrue L y whitelist assertTrue ___as_tensor L y whitelist ephemeral FloatTensor source assertTrue L z whitelist static float assertTrue L c whitelist static float property assertTrue L d whitelist dynamic int property test_pgo_dynamic_params cnts = CompileCounter torch compile backend=cnts fullgraph=True Foo torch nn Module __init__ super __init__ lin = None forward x lin x f = Foo run reset cnts clear f lin = torch nn Linear f torch randn f torch randn f lin = torch nn Linear f torch randn recompile each run run assertEqual cnts frame_count parameter static shapes forced static so we recompile once torch _dynamo config patch force_parameter_static_shapes=False force_nn_module_property_static_shapes=False run assertEqual cnts frame_count because flags flipped params included PGO run assertEqual cnts frame_count test_njt cnts = CompileCounter NB PGO doesn t do anything here point catch pickle problem nested int torch compile backend=cnts fullgraph=True f x x x = torch nested nested_tensor_from_jagged torch randn torch tensor torch tensor y = torch nested nested_tensor_from_jagged torch randn torch tensor torch tensor f x f y assertEqual cnts frame_count reset cnts clear = torch nested nested_tensor_from_jagged torch randn torch tensor torch tensor b = torch nested nested_tensor_from_jagged torch randn torch tensor torch tensor f f b assertEqual cnts frame_count test_distinct_compile_id cnts = CompileCounter torch compile backend=cnts fullgraph=True f x x torch compiler config patch job_id= foo f torch randn f torch randn assertEqual cnts frame_count reset cnts clear torch compiler config patch job_id= bar f torch randn f torch randn assertEqual cnts frame_count torch _dynamo reset clear_caches cnts clear torch compiler config patch job_id= foo f torch randn f torch randn assertEqual cnts frame_count TODO test local need ensure local filesystem gets cleared out torch _dynamo config patch automatic_dynamic_remote_pgo=True automatic_dynamic_local_pgo=False test_remote_basic cnts = CompileCounter torch compile backend=cnts fullgraph=True f x x mock_cache PatchCaches f torch randn f torch randn assertEqual cnts frame_count assertEqual mock_cache global_stats dynamo_pgo mock_cache Stats reset cnts clear f torch randn f torch randn assertEqual cnts frame_count assertEqual mock_cache global_stats dynamo_pgo mock_cache Stats reset cnts clear torch compiler config patch cache_key_tag test f torch randn f torch randn assertEqual cnts frame_count assertEqual mock_cache global_stats dynamo_pgo mock_cache Stats Test same file appears two different paths two different compilations PGO still works test_different_file_paths_local_pgo content = torch run cnt torch compile backend=cnt fullgraph=True func x x func torch rand func torch rand func torch rand temp_dir = tempfile TemporaryDirectory temp_dir = tempfile TemporaryDirectory We need normalize_path_separator Windows file path path = normalize_path_separator os path join temp_dir name example py path = normalize_path_separator os path join temp_dir name example py cnts = CompileCounter assert path = path write_load_and_run path open path w file file write content spec = importlib util spec_from_file_location example path assert spec None module = importlib util module_from_spec spec assert spec loader None spec loader exec_module module module run cnts write_load_and_run path assertEqual cnts frame_count state = torch _dynamo pgo render_code_state torch _dynamo pgo get_code_state Windows can t create unification temp path hash C Users Xuhan AppData Local Temp tmpx hfkuqa example py Skip hash check assertTrue hash IS_WINDOWS hash fe state assertTrue example py func state assertTrue L x tensor size= stride= state We should compile only once due PGO cnts clear write_load_and_run path assertEqual cnts frame_count torch _dynamo config patch automatic_dynamic_remote_pgo=True automatic_dynamic_local_pgo=False test_sticky_pgo_read_write cnts = CompileCounter torch compile backend=cnts fullgraph=True f x y x y t x y torch randn x y mock_cache PatchCaches we pretend disable default remote cache keying different job ids per run torch compiler config patch job_id= f t t f t t assertEqual cnts frame_count first test we re reading local default remote cache we should recompile when x wobbles reset cnts clear torch compiler config patch job_id= b pgo_extra_write_key= sticky_ f t t f t t assertEqual cnts frame_count now extra sticky_ key we start dynamic x no recompiles reset cnts clear torch compiler config patch job_id= c pgo_extra_read_key= sticky_ f t t f t t assertEqual cnts frame_count last test wobble y write sticky_ key reset cnts clear torch compiler config patch job_id= d pgo_extra_write_key= sticky_ f t t f t t f t t assertEqual cnts frame_count start using default remote PGO create run wobbles y reset cnts clear f t t f t t f t t both default remote present we ignore extra remote reset cnts clear torch compiler config patch pgo_extra_read_key= sticky_ f t t f t t assertEqual cnts frame_count f t t assertEqual cnts frame_count __name__ == __main__ torch _dynamo test_case run_tests run_tests