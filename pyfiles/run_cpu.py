mypy allow-untyped-defs This script launching PyTorch inference Intel R Xeon R Scalable Processors optimal configurations Single instance inference multi-instance inference enabled Note term instance here doesn t refer cloud instance This script executed single process It invokes multiple instances which formed multiple threads each instance kind group threads context Illustrated below + ----------------------------- + ---------------------- + ------- + &#124; process &#124; thread &#124; core &#124; +=============================+======================+=======+ &#124; torch backends xeon run_cpu &#124; instance thread &#124; &#124; &#124; &#124; thread &#124; &#124; &#124; + ---------------------- + ------- + &#124; &#124; instance thread &#124; &#124; &#124; &#124; thread &#124; &#124; &#124; + ---------------------- + ------- + &#124; &#124; &#124; &#124; &#124; + ---------------------- + ------- + &#124; &#124; instance N thread &#124; M &#124; &#124; &#124; thread &#124; M+ &#124; + ----------------------------- + ---------------------- + ------- + To get peak performance Intel R Xeon R Scalable Processors script optimizes configuration thread memory management For thread management script configures thread affinity preload Intel OMP library For memory management configures NUMA binding preload optimized memory allocation library e g tcmalloc jemalloc Environment variables will set script + ------------------ + ------------------------------------------------------------------------------------------------- + &#124; Environ Variable &#124; Value &#124; +==================+=================================================================================================+ &#124; LD_PRELOAD &#124; Depending knobs you set lib libiomp so lib libjemalloc so lib libtcmalloc so might &#124; &#124; &#124; appended LD_PRELOAD &#124; + ------------------ + ------------------------------------------------------------------------------------------------- + &#124; KMP_AFFINITY &#124; If libiomp so preloaded KMP_AFFINITY could set granularity=fine compact &#124; + ------------------ + ------------------------------------------------------------------------------------------------- + &#124; KMP_BLOCKTIME &#124; If libiomp so preloaded KMP_BLOCKTIME set &#124; + ------------------ + ------------------------------------------------------------------------------------------------- + &#124; OMP_NUM_THREADS &#124; value ncores_per_instance &#124; + ------------------ + ------------------------------------------------------------------------------------------------- + &#124; MALLOC_CONF &#124; If libjemalloc so preloaded MALLOC_CONF will set &#124; &#124; &#124; oversize_threshold background_thread true metadata_thp auto &#124; + ------------------ + ------------------------------------------------------------------------------------------------- + Note This script respects environment variables set preliminarily I e If you set environment variables mentioned above before running script script will overwrite values script How use module ~~~~~~~~~~~~~~~~~~~~~~~ Single instance inference ------------------------- Run single-instance inference single node all CPU nodes python -m torch backends xeon run_cpu -- throughput-mode script py args Run single-instance inference single CPU node python -m torch backends xeon run_cpu -- node-id script py args Multi-instance inference ------------------------ Multi-instance By default tool runs one process per node If you want set instance numbers core per instance -- ninstances -- ncores-per-instance should set python -m torch backends xeon run_cpu -- python_script args eg Intel R Xeon R Scalable Processor instance cores per instance python -m torch backends xeon run_cpu -- ninstances -- ncores-per-instance python_script args Run single-instance inference among multiple instances By default runs all ninstances If you want independently run single instance among ninstances specify rank eg run th instance Intel R Xeon R Scalable Processor instance i e numactl -C - python -m torch backends xeon run_cpu -- ninstances -- rank python_script args eg run st instance Intel R Xeon R Scalable Processor instance i e numactl -C - python -m torch backends xeon run_cpu -- ninstances -- rank python_script args eg run th instance Intel R Xeon R Scalable Processor instance cores per instance first four cores i e numactl -C - python -m torch backends xeon run_cpu -- core-list -- ninstances -- ncores-per-instance -- rank python_script args To look up what optional arguments module offers python -m torch backends xeon run_cpu -- help Memory allocator ---------------- -- enable-tcmalloc -- enable-jemalloc can used enable different memory allocator glob logging os platform re subprocess sys argparse ArgumentParser RawTextHelpFormatter REMAINDER os path expanduser torch distributed elastic multiprocessing DefaultLogsSpecs _DefaultLogsSpecs start_processes Std format_str = asctime s - name s - levelname s - message s logging basicConfig level=logging INFO format=format_str logger = logging getLogger __name__ _CPUinfo Get CPU information such cores list NUMA information __init__ test_input= cpuinfo = platform system Windows Darwin raise RuntimeError f platform system supported platform system == Linux Sample output ` lscpu -- parse=CPU Core Socket Node ` The following parsable format which can fed other programs Each different item every column has unique ID starting zero CPU Core Socket Node test_input == lscpu_cmd = lscpu -- parse=CPU Core Socket Node lscpu_info = subprocess check_output lscpu_cmd universal_newlines=True split \n lscpu_info = test_input split \n Get information about cpu core socket node line lscpu_info pattern = r ^ \d + \d + \d + \d regex_out = re search pattern line regex_out cpuinfo append regex_out group strip split physical cores = core column lscpu output logical cores = cPU column lscpu output node_nums = int max line line cpuinfo + node_physical_cores list list int = node_id index node_logical_cores list list int = node_id index physical_core_node_map = physical core numa node id logical_core_node_map = logical core numa node id node_id range node_nums cur_node_physical_core = cur_node_logical_core = cpuinfo cpuinfo nid = cpuinfo cpuinfo = node_id == int nid int cpuinfo cur_node_physical_core cur_node_physical_core append int cpuinfo physical_core_node_map int cpuinfo = int node_id cur_node_logical_core append int cpuinfo logical_core_node_map int cpuinfo = int node_id node_physical_cores append cur_node_physical_core node_logical_cores append cur_node_logical_core _physical_core_nums len node_physical_cores len node_physical_cores _logical_core_nums len node_logical_cores len node_logical_cores get_node_physical_cores node_id node_id node_id node_nums - raise ValueError f Invalid node id node_id Valid node ids list range len node_physical_cores node_physical_cores node_id get_node_logical_cores node_id node_id node_id node_nums - raise ValueError f Invalid node id node_id Valid node ids list range len node_physical_cores node_logical_cores node_id get_all_physical_cores all_cores = cores node_physical_cores all_cores extend cores all_cores get_all_logical_cores all_cores = cores node_logical_cores all_cores extend cores all_cores numa_aware_check core_list Check whether all cores core_list same NUMA node Cross NUMA will reduce performance We strongly advice use cores different nodes cores_numa_map = logical_core_node_map numa_ids = core core_list numa_id = cores_numa_map core numa_id numa_ids numa_ids append numa_id len numa_ids logger warning Numa Aware cores s different NUMA nodes s To avoid \ behavior please use -- ncores-per-instance knob make sure number cores divisible -- ncores-per-\ instance Alternatively please use -- skip-cross-node-cores knob str core_list str numa_ids len numa_ids == raise RuntimeError invalid number NUMA nodes please make sure numa_ids = numa_ids _Launcher r Class launcher msg_lib_notfound = f Unable find library file lib so $ CONDA_PREFIX lib $ VIRTUAL_ENV lib \ local lib usr local lib usr local lib usr lib usr lib \ expanduser ~ local lib so LD_PRELOAD environment variable will set __init__ - None cpuinfo = _CPUinfo add_lib_preload lib_type Enable TCMalloc JeMalloc intel OpenMP library_paths = CONDA_PREFIX os environ library_paths append f os environ CONDA_PREFIX lib VIRTUAL_ENV os environ library_paths append f os environ VIRTUAL_ENV lib library_paths += f expanduser ~ local lib usr local lib usr local lib usr lib usr lib lib_find = False lib_set = False item os getenv LD_PRELOAD split item endswith f lib lib_type so lib_set = True break lib_set lib_path library_paths library_file = os path join lib_path f lib lib_type so matches = glob glob library_file len matches ld_preloads = f matches os getenv LD_PRELOAD os environ LD_PRELOAD = os pathsep join p strip os pathsep p ld_preloads p lib_find = True break lib_set lib_find is_numactl_available numactl_available = False try cmd = numactl -C -m hostname r = subprocess run cmd env=os environ stdout=subprocess DEVNULL stderr=subprocess DEVNULL check=False r returncode == numactl_available = True except Exception pass numactl_available set_memory_allocator enable_tcmalloc=True enable_jemalloc=False use_default_allocator=False Enable TCMalloc JeMalloc LD_PRELOAD set configuration JeMalloc By default PTMalloc will used PyTorch TCMalloc JeMalloc can get better memory reuse reduce page fault improve performance enable_tcmalloc enable_jemalloc raise RuntimeError Unable enable TCMalloc JEMalloc same time enable_tcmalloc find_tc = add_lib_preload lib_type= tcmalloc find_tc msg = f msg_lib_notfound you can use conda install -c conda-forge gperftools install logger warning msg format TCmalloc tcmalloc noqa G logger info Use TCMalloc memory allocator enable_jemalloc find_je = add_lib_preload lib_type= jemalloc find_je msg = f msg_lib_notfound you can use conda install -c conda-forge jemalloc install logger warning msg format Jemalloc jemalloc noqa G logger info Use JeMalloc memory allocator set_env MALLOC_CONF oversize_threshold background_thread true metadata_thp auto use_default_allocator pass find_tc = add_lib_preload lib_type= tcmalloc find_tc logger info Use TCMalloc memory allocator find_je = add_lib_preload lib_type= jemalloc find_je logger info Use JeMalloc memory allocator logger warning Neither TCMalloc nor JeMalloc found $ CONDA_PREFIX lib $ VIRTUAL_ENV lib local lib usr local lib usr local lib usr lib usr lib s local lib so LD_PRELOAD environment variable will set This may drop performance expanduser ~ log_env_var env_var_name= env_var_name os environ logger info s= s env_var_name os environ env_var_name set_env env_name env_value env_value logger warning s None env_name env_name os environ os environ env_name = env_value os environ env_name = env_value logger warning Overriding value one set environment variable s \ Value applied s Value ignored s env_name os environ env_name env_value log_env_var env_name set_kmp_affinity used control whether set KMP_AFFINITY In scenario use all cores all nodes including logical cores setting KMP_AFFINITY disables logical cores In case KMP_AFFINITY should set set_multi_thread_and_allocator ncores_per_instance disable_iomp=False set_kmp_affinity=True enable_tcmalloc=True enable_jemalloc=False use_default_allocator=False Set multi-thread configuration enable Intel openMP TCMalloc JeMalloc By default GNU openMP PTMalloc used PyTorch Intel openMP TCMalloc JeMalloc better alternatives get performance benefit set_memory_allocator enable_tcmalloc enable_jemalloc use_default_allocator set_env OMP_NUM_THREADS str ncores_per_instance disable_iomp find_iomp = add_lib_preload lib_type= iomp find_iomp msg = f msg_lib_notfound you can use conda install mkl install logger warning msg format iomp iomp noqa G logger info Using Intel OpenMP set_kmp_affinity set_env KMP_AFFINITY granularity=fine compact set_env KMP_BLOCKTIME log_env_var LD_PRELOAD r Launcher single instance multi-instance launch args cores = set_kmp_affinity = True enable_taskset = False args core_list user specify what cores will used params cores = int x x args core_list split args ncores_per_instance == - raise RuntimeError please specify -- ncores-per-instance you have pass -- core-list params args ninstances args ncores_per_instance args ninstances len cores logger warning only first s cores will used \ you specify s cores core_list args ncores_per_instance args ninstances len cores args ninstances = len cores args ncores_per_instance args use_logical_core args node_id = - cores = cpuinfo get_node_logical_cores args node_id cores = cpuinfo get_all_logical_cores When using all cores all nodes including logical cores setting KMP_AFFINITY disables logical cores Thus KMP_AFFINITY should set set_kmp_affinity = False args node_id = - cores = cpuinfo get_node_physical_cores args node_id cores = cpuinfo get_all_physical_cores args multi_instance args ninstances == - args ncores_per_instance == - args ninstances = args ncores_per_instance = len cores args multi_instance args ninstances == - args ncores_per_instance == - args throughput_mode = True args ncores_per_instance == - args ninstances = - args ninstances len cores raise RuntimeError f there len cores total cores you specify args ninstances ninstances \ please make sure ninstances = total_cores args ncores_per_instance = len cores args ninstances args ncores_per_instance = - args ninstances == - args skip_cross_node_cores args ninstances = len cores args ncores_per_instance ncore_per_node = len cpuinfo node_physical_cores num_leftover_cores = ncore_per_node args ncores_per_instance args ncores_per_instance ncore_per_node too many ncores_per_instance skip cross-node cores logger warning there s core s per socket you specify s ncores_per_instance \ skip_cross_node_cores Please make sure -- ncores-per-instance core s per \ socket ncore_per_node args ncores_per_instance sys exit - num_leftover_cores == aren t any cross-node cores logger info -- skip-cross-node-cores set there no cross-node cores args ninstances = len cores args ncores_per_instance skip cross-node cores args ninstances = - logger warning -- skip-cross-node-cores exclusive -- ninstances -- ninstances \ won t take effect even set explicitly i = leftover_cores = set while ncore_per_node i = len cores leftover_cores update cores ncore_per_node i - num_leftover_cores ncore_per_node i i += cores = list set cores - leftover_cores assert len cores args ncores_per_instance == args ninstances = len cores args ncores_per_instance args ninstances args ncores_per_instance len cores raise RuntimeError Please make sure ninstances ncores_per_instance = total_cores args latency_mode logger warning -- latency-mode exclusive -- ninstances -- ncores-per-instance -- node-id \ -- use-logical-core They won t take effect even they set explicitly args ncores_per_instance = cores = cpuinfo get_all_physical_cores args ninstances = len cores args ncores_per_instance args throughput_mode logger warning -- throughput-mode exclusive -- ninstances -- ncores-per-instance -- node-id \ -- use-logical-core They won t take effect even they set explicitly args ninstances = cpuinfo node_nums cores = cpuinfo get_all_physical_cores args ncores_per_instance = len cores args ninstances args ninstances args rank = - logger info assigning s cores instance s args ncores_per_instance args rank args disable_numactl numactl_available = is_numactl_available numactl_available args disable_taskset logger warning Core binding numactl available Disabling numactl using taskset instead \ This may affect performance multi-socket system please use numactl memory binding needed args disable_numactl = True enable_taskset = True logger warning Core binding numactl available -- disable_taskset set \ Please unset -- disable_taskset use taskset instead numactl sys exit - args disable_taskset enable_taskset = True set_multi_thread_and_allocator args ncores_per_instance args disable_iomp set_kmp_affinity args enable_tcmalloc args enable_jemalloc args use_default_allocator entrypoint = launch_args = launch_envs dict int dict = launch_tee = check whether launched torchrun -- nproc-per-node num workers local_size = int os environ get LOCAL_WORLD_SIZE local_rank = int os environ get LOCAL_RANK i range args ninstances cmd = cur_process_cores = args disable_numactl enable_taskset args disable_numactl cmd = numactl enable_taskset cmd = taskset cores = sorted cores args rank == - sequentially assign ncores_per_instance ninstances core_list = cores i args ncores_per_instance i + args ncores_per_instance assign ncores_per_instance rank core_list = cores args rank args ncores_per_instance args rank + args ncores_per_instance core_ranges list dict = local_size total_num_cores = len core_list cores_per_rank = total_num_cores local_size assert cores_per_rank = At least one core needs assigned each rank core_list = core_list cores_per_rank local_rank cores_per_rank local_rank + core core_list len core_ranges == range_elem = start core end core core_ranges append range_elem core - core_ranges - end == core_ranges - end = core range_elem = start core end core core_ranges append range_elem r core_ranges cur_process_cores = f cur_process_cores r start - r end cur_process_cores = cur_process_cores - args disable_numactl numa_params = f -C cur_process_cores numa_ids = join str numa_id numa_id cpuinfo numa_aware_check core_list numa_params += f -m numa_ids cmd extend numa_params split enable_taskset taskset_params = f -c cur_process_cores cmd extend taskset_params split with_python = args no_python with_python cmd append sys executable cmd append -u args module cmd append -m cmd append args program cmd extend args program_args cmd_s = join cmd logger info cmd_s entrypoint == entrypoint = cmd del cmd launch_args i = tuple cmd launch_envs i = launch_tee i = Std ALL args rank = - launches single instance rank only break ctx = start_processes name=args log_file_prefix entrypoint=entrypoint args=launch_args envs=launch_envs logs_specs=_DefaultLogsSpecs log_dir=args log_path tee=launch_tee ctx wait _add_memory_allocator_params parser group = parser add_argument_group Memory Allocator Parameters allocator control group add_argument -- enable-tcmalloc -- enable_tcmalloc action= store_true default=False help= Enable tcmalloc allocator group add_argument -- enable-jemalloc -- enable_jemalloc action= store_true default=False help= Enable jemalloc allocator group add_argument -- use-default-allocator -- use_default_allocator action= store_true default=False help= Use default memory allocator _add_multi_instance_params parser group = parser add_argument_group Multi-instance Parameters multi-instance control group add_argument -- ncores-per-instance -- ncores_per_instance metavar= \b default=- type=int help= Cores per instance group add_argument -- ninstances metavar= \b default=- type=int help= For multi-instance you should give cores number you used per instance group add_argument -- skip-cross-node-cores -- skip_cross_node_cores action= store_true default=False help= If specified -- ncores-per-instance skips cross-node cores group add_argument -- rank metavar= \b default= - type=int help= Specify instance index assign ncores_per_instance rank \ otherwise ncores_per_instance will assigned sequentially ninstances Please refer \ https github com intel intel-extension-for-pytorch blob master docs tutorials performance_tuning launch_script md group add_argument -- latency-mode -- latency_mode action= store_true default=False help= By default core per instance use all physical cores group add_argument -- throughput-mode -- throughput_mode action= store_true default=False help= By default one instance per node use all physical cores group add_argument -- node-id -- node_id metavar= \b default=- type=int help= node id multi-instance default all nodes will used group add_argument -- use-logical-core -- use_logical_core action= store_true default=False help= Whether only use physical cores group add_argument -- disable-numactl -- disable_numactl action= store_true default=False help= Disable numactl group add_argument -- disable-taskset -- disable_taskset action= store_true default=False help= Disable taskset group add_argument -- core-list -- core_list metavar= \b default=None type=str help= Specify core list core_id core_id otherwise all cores will used group add_argument -- log-path -- log_path metavar= \b default= type=str help= The log file directory Default path which means disable logging files group add_argument -- log-file-prefix -- log_file_prefix metavar= \b default= run type=str help= log file prefix _add_kmp_iomp_params parser group = parser add_argument_group IOMP Parameters group add_argument -- disable-iomp -- disable_iomp action= store_true default=False help= By default we use Intel OpenMP libiomp so will add LD_PRELOAD create_args parser=None Parse command line options retval ArgumentParser pyrefly ignore missing-attribute parser add_argument -- multi-instance -- multi_instance action= store_true default=False help= Enable multi-instance default one instance per node pyrefly ignore missing-attribute parser add_argument -m -- module default=False action= store_true help= Changes each process interpret launch script python module executing same behavior python -m pyrefly ignore missing-attribute parser add_argument -- no-python -- no_python default=False action= store_true help= Do prepend -- program script python - just exec directly Useful when script Python script _add_memory_allocator_params parser _add_kmp_iomp_params parser _add_multi_instance_params parser positional pyrefly ignore missing-attribute parser add_argument program type=str help= The full path program script launched followed all arguments script rest training program pyrefly ignore missing-attribute parser add_argument program_args nargs=REMAINDER main args env_before = set os environ keys platform system Windows Darwin raise RuntimeError f platform system supported args log_path os makedirs args log_path exist_ok=True args log_path = os devnull args latency_mode args throughput_mode raise RuntimeError Either args latency_mode args throughput_mode should set args no_python args program endswith py raise RuntimeError For non Python script you should use -- no-python parameter Verify LD_PRELOAD LD_PRELOAD os environ lst_valid = tmp_ldpreload = os environ LD_PRELOAD item tmp_ldpreload split matches = glob glob item len matches lst_valid append item logger warning s doesn t exist Removing LD_PRELOAD item len lst_valid os environ LD_PRELOAD = join lst_valid os environ LD_PRELOAD = launcher = _Launcher launcher launch args x sorted set os environ keys - env_before logger debug s= s x os environ x __name__ == __main__ parser = ArgumentParser description= This script launching PyTorch inference Intel R Xeon R Scalable Processors optimal configurations Single instance inference multi-instance inference enable To get peak performance Intel R Xeon R Scalable Processors script optimizes configuration thread memory management For thread management script configures thread affinity preload Intel OMP library For memory management configures NUMA binding preload optimized memory allocation library e g tcmalloc jemalloc \n################################# Basic usage ############################# \n \n single instance\n \n python -m torch backends xeon run_cpu python_script args \n \n multi-instance \n \n python -m torch backends xeon run_cpu -- ninstances xxx -- ncores-per-instance xx python_script args\n \n############################################################################# \n formatter_class=RawTextHelpFormatter create_args parser args = parser parse_args main args