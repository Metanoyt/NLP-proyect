Owner s oncall jit io os sys torch Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir torch testing _internal common_utils raise_on_run_directly suppress_warnings torch testing _internal jit_utils JitTestCase TestTypeSharing JitTestCase assertSameType m m isinstance m torch jit ScriptModule m = torch jit script m isinstance m torch jit ScriptModule m = torch jit script m assertEqual m _c _type m _c _type assertDifferentType m m isinstance m torch jit ScriptModule m = torch jit script m isinstance m torch jit ScriptModule m = torch jit script m assertNotEqual m _c _type m _c _type test_basic M torch nn Module __init__ b c super __init__ = b = b c = c forward x x = torch rand b = torch rand c = torch rand m = M b c m = M b c assertSameType m m test_diff_attr_values Types should shared even attribute values differ M torch nn Module __init__ b c super __init__ = b = b c = c forward x x = torch rand b = torch rand c = torch rand m = M b c m = M b c assertSameType m m test_constants Types should shared identical constant values different different constant values M torch nn Module __constants__ = const __init__ attr const super __init__ attr = attr const = const forward const attr = torch rand m = M attr m = M attr assertSameType m m different constant value m = M attr assertDifferentType m m test_linear Simple example real nn Module = torch nn Linear b = torch nn Linear c = torch nn Linear = torch jit script b = torch jit script b c = torch jit script c assertSameType b assertDifferentType c test_submodules If submodules differ types should differ M torch nn Module __init__ out out super __init__ submod = torch nn Linear out submod = torch nn Linear out forward x x = submod x x = submod x x = M b = M assertSameType b assertSameType submod b submod c = M assertDifferentType c assertSameType b submod c submod assertDifferentType submod b submod test_param_vs_attribute The same module ` foo ` parameter vs attribute shouldn t share types M torch nn Module __init__ foo super __init__ foo = foo forward x x + foo as_param = torch nn Parameter torch ones as_attr = torch ones param_mod = M as_param attr_mod = M as_attr assertDifferentType attr_mod param_mod test_same_but_different_classes Even everything about module same different originating classes should prevent type sharing A torch nn Module __constants__ = const __init__ out out super __init__ submod = torch nn Linear out submod = torch nn Linear out const = forward x x = submod x x = submod x x const B torch nn Module __constants__ = const __init__ out out super __init__ submod = torch nn Linear out submod = torch nn Linear out const = forward x x = submod x x = submod x x const = A b = B assertDifferentType b test_mutate_attr_value Mutating value attribute should change type sharing M torch nn Module __init__ out out super __init__ submod = torch nn Linear out submod = torch nn Linear out foo = torch ones forward x x = submod x x = submod x x + foo = M b = M foo = torch ones b foo = torch rand assertSameType b test_assign_python_attr Assigning new python-only attribute should change type sharing M torch nn Module __init__ out out super __init__ submod = torch nn Linear out submod = torch nn Linear out foo = torch ones forward x x = submod x x = submod x x + foo explicitly call script freeze type = torch jit script M b = torch jit script M new_attr = foo bar baz assertSameType b we assign attributes before calling script types should different since ` new_attr ` should turned into Script attribute = M b = M new_attr = foo bar baz assertDifferentType b test_failed_attribute_compilation Attributes whose type cannot inferred should fail cleanly nice hints M torch nn Module __init__ - None super __init__ assign type we know can t converted TorchScript foo = object forward try use forward foo m = M assertRaisesRegexWithHighlight RuntimeError failed convert Python type foo torch jit script m test_script_function_attribute_different Different functions passed should lead different types torch jit script fn x x + x torch jit script fn x x - x M torch nn Module __init__ fn super __init__ fn = fn forward x fn x fn _mod = M fn fn _mod = M fn assertDifferentType fn _mod fn _mod test_builtin_function_same Caller torch nn Module __init__ fn super __init__ fn = fn forward input fn input input c = Caller torch add c = Caller torch add assertSameType c c test_builtin_function_different Caller torch nn Module __init__ fn super __init__ fn = fn forward input fn input input c = Caller torch add c = Caller torch sub assertDifferentType c c test_script_function_attribute_same Same functions passed should lead same types torch jit script fn x x + x M torch nn Module __init__ fn super __init__ fn = fn forward x fn x fn _mod = M fn fn _mod = M fn assertSameType fn _mod fn _mod test_python_function_attribute_different Different functions passed should lead different types fn x x + x fn x x - x M torch nn Module __init__ fn super __init__ fn = fn forward x fn x fn _mod = M fn fn _mod = M fn assertDifferentType fn _mod fn _mod test_python_function_attribute_same Same functions passed should lead same types fn x x + x M torch nn Module __init__ fn super __init__ fn = fn forward x fn x fn _mod = M fn fn _mod = M fn assertSameType fn _mod fn _mod suppress_warnings test_tracing_gives_different_types Since we can t guarantee methods same between different trace runs tracing must always generate unique type M torch nn Module forward x y x sum y sum x y = torch jit trace M torch zeros torch ones b = torch jit trace M torch ones torch zeros assertDifferentType b test_ignored_fns M torch nn Module __init__ foo super __init__ foo = foo torch jit ignore ignored foo forward ignored = torch jit script M torch ones b = torch jit script M torch ones assertSameType b assertNotEqual b suppress_warnings test_script_module_containing_traced_module Traced torch nn Module forward x x sum x x + x M torch nn Module __init__ input super __init__ traced = torch jit trace Traced input forward x traced x = M torch ones b = M torch zeros assertDifferentType b test_loaded_modules_work AB torch nn Module __init__ - None super __init__ = b = forward + b A torch nn Module __init__ - None super __init__ = forward Wrapper torch nn Module __init__ sub super __init__ sub = sub forward sub package x buffer = io BytesIO torch jit save torch jit script x buffer buffer seek torch jit script Wrapper torch jit load buffer = package AB b = package A b test_module_dict_same_type_different_name We should able differentiate between two ModuleDict instances have different keys same value types A torch nn Module forward x x Foo torch nn Module __init__ s super __init__ dict = torch nn ModuleDict s forward x x = Foo foo A b = Foo bar A c = Foo bar A assertDifferentType b assertSameType b c test_type_sharing_define_in_init Tests types between instances ScriptModule subclass defines methods its __init__ shared A torch jit ScriptModule __init__ val super __init__ define f forward - int val one = A two = A assertEqual one assertEqual two test_type_sharing_disabled Test type sharing can disabled A torch nn Module __init__ sub super __init__ sub = sub forward x x B torch nn Module forward x x top = A A B top = A A B top _s = torch jit _recursive create_script_module top torch jit _recursive infer_methods_to_compile share_types=False top _s = torch jit _recursive create_script_module top torch jit _recursive infer_methods_to_compile share_types=False assertDifferentType top _s top _s assertDifferentType top _s top _s sub assertDifferentType top _s top _s sub assertDifferentType top _s top _s sub assertDifferentType top _s top _s sub test_type_shared_ignored_attributes Test types shared exclusion their ignored attributes makes them equal A torch nn Module __jit_ignored_attributes__ = __init__ b super __init__ = b = b forward x x a_with_linear = A torch nn Linear a_with_string = A string Both should have same type because attribute differs type ignored common attribute has same type assertSameType a_with_linear a_with_string test_type_not_shared_ignored_attributes Test types shared exclusion their ignored attributes makes them equal A torch nn Module __jit_ignored_attributes__ = __init__ b c super __init__ = b = b c = c forward x x mod = A torch nn Linear string s = torch jit script mod A __jit_ignored_attributes__ = b s = torch jit script mod The types s s should differ Although they instances A __jit_ignored_attributes__ modified before scripting s so set ignored attributes different between s s assertDifferentType s s __name__ == __main__ raise_on_run_directly test test_jit py