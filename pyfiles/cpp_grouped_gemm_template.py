contextlib logging typing Any Callable cast Optional TypeVar unittest mock patch torch torch utils torch utils _ordered_set OrderedSet _dynamo utils counters config ir kernel mm_common mm_args select_algorithm ChoiceCaller DataProcessorTemplateWrapper utils parallel_num_threads virtualized V cpp get_export_declaration cpp_gemm_template CppGemmTemplate expand_bias gen_ d_view_of_epilogue_buf prune_tensors transpose_w cpp_micro_gemm CppMicroGemmAMX create_micro_gemm cpp_template_kernel CppTemplateKernel cpp_utils create_epilogue_with_attr DTYPE_TO_CPP GemmBlocking get_gemm_template_output_and_compute_dtype log = logging getLogger __name__ GEMM_TEMPLATE = r template header getvalue micro_gemm codegen_define kernel extern C export_declaration kernel def_kernel inputs=kernel_args outputs=Y_list aliases=aliases kernel maybe_codegen_profile template codegen_blocks num_threads N K micro_gemm is_dynamic_M kernel GemmOuts config L _cache_size L _cache_size X_list W_list - num_threads #pragma omp parallel num_threads num_threads template codegen_multi_threads_params &#124; indent false - template codegen_single_thread_params is_dynamic_M &#124; indent false - endif micro_gemm codegen_init kernel - set acc_buf_name_list= - set acc_buf_name_prefix = local_acc_buf_ - gemm_idx range gemm_grouped_num - set acc_buf_name = acc_buf_name_prefix + gemm_idx &#124; string kernel define_buffer acc_buf_name Mc_blocks Mr Nc_blocks Nr acc_buf_dtype - set acc_buf_name_list=acc_buf_name_list append acc_buf_name - endfor int _t mc_block_id = mc_block_id num_Mc_blocks_per_thread mc_block_id++ template codegen_m_loop_params &#124; indent false int _t nc = n_block_start nc n_block_end nc += Nc_blocks template codegen_n_loop_params &#124; indent false - set acc_list= - gemm_idx range gemm_grouped_num - set acc_list = acc_list append kernel local_buffers acc_buf_name_list gemm_idx kernel reinit_buffer_if_null acc_buf_name_list gemm_idx - endfor int _t kc = k_block_start kc k_block_end kc += Kc_blocks int _t k_start = kc Kr int _t k_end = std min std min kc + Kc_blocks k_block_end Kr K - set tile_X_list= - gemm_idx range gemm_grouped_num - set tile_X_list = tile_X_list append kernel slice_nd X_list gemm_idx m_start m_end k_start k_end - endfor int _t nci = nc nci nc_block_end nci++ - set tile_W_ d_list= - set tile_W_list= - set acc_slice_list= - gemm_idx range gemm_grouped_num - set acc_slice_list = acc_slice_list append kernel slice_nd acc_list gemm_idx m_end - m_start nci - nc Nr nci - nc + Nr - set tile_W_ d_list = tile_W_ d_list append kernel slice_nd W_list gemm_idx nci nci + k_start k_end - endfor - gemm_idx range gemm_grouped_num - set tile_W_list = tile_W_list append kernel view tile_W_ d_list gemm_idx k_end - k_start micro_gemm register_blocking block_n - endfor kc == k_block_start - gemm_idx range gemm_grouped_num micro_gemm codegen_call kernel tile_X_list gemm_idx tile_W_list gemm_idx acc_slice_list gemm_idx accum=False &#124; indent false - endfor - gemm_idx range gemm_grouped_num micro_gemm codegen_call kernel tile_X_list gemm_idx tile_W_list gemm_idx acc_slice_list gemm_idx accum=True &#124; indent false - endfor - set tile_acc_list = - set tile_Y_list = - gemm_idx range gemm_grouped_num - set tile_acc_list = tile_acc_list append kernel slice_nd acc_list gemm_idx m_end - m_start n_end - n_start - set tile_Y_list = tile_Y_list append kernel slice_nd Y_ d_list gemm_idx m_start m_end n_start n_end - endfor kernel store_outputs tile_Y_list tile_acc_list GemmOuts epilogue_nodes offsets= m_start n_start reindexers=reindexers multi_output_buffers=multi_output_buffers &#124; indent false micro_gemm codegen_finalize kernel get_deduplicated_act act_mapping dict int ir IRNode - list ir IRNode act_deduplicated = act_deduplicated_name OrderedSet str = OrderedSet act_idx range len act_mapping values act = act_mapping act_idx act get_name act_deduplicated_name act_deduplicated append act act_deduplicated_name add act get_name act_deduplicated CppGroupedGemmTemplate CppGemmTemplate __init__ input_nodes list ir IRNode layout ir Layout num_threads int register_blocking GemmBlocking beta int = alpha int = has_bias bool = False epilogue_creator Optional Callable ir Buffer ir Pointwise = None act_mapping Optional dict int ir IRNode = None gemm_grouped_num int = - None Template Group GEMMs Each GEMM has same dimensions m n k same leading dimensions lda ldb ldc their A B C matrices Each GEMM has distinct shared activations has distinct weight has unique bias no bias has distinct epilogues In current implementation outputs all GEMMs accumulated using pointwise epilogues This behavior can extended future needed super __init__ input_nodes layout num_threads register_blocking beta alpha has_bias epilogue_creator act_mapping = act_mapping gemm_grouped_num = gemm_grouped_num pyrefly ignore bad-override output_node list ir Buffer = ir Buffer name= buf_out + str idx layout=layout idx range gemm_grouped_num classmethod pyrefly ignore bad-override add_choices cls choices list ChoiceCaller layout ir Layout input_nodes list ir IRNode beta int = alpha int = has_bias tuple bool = False False trans_w bool = False input_indices Optional list int = None epilogue_creator Optional Callable ir Buffer ir Pointwise = None act_mapping Optional dict int ir IRNode = None gemm idx its act buf - DataProcessorTemplateWrapper Input nodes order x optional x w w optional b optional b gemm_grouped_num = len has_bias assert act_mapping act_deduplicated = get_deduplicated_act act_mapping wgt_start_idx = len act_deduplicated bias_start_idx = wgt_start_idx + gemm_grouped_num input_indices = list range len input_nodes _T = TypeVar _T ir IRNode torch Tensor _U = TypeVar _U ir Layout torch Tensor reorder_and_filter inputs list _T layout_or_out _U - tuple list _T _U assert input_indices None input_indices must set inputs idx idx input_indices layout_or_out new_inputs new_layout = reorder_and_filter input_nodes layout maybe_to_dense inputs list _T layout_or_out _U - tuple list _T _U new_inputs = list inputs idx range wgt_start_idx wgt_start_idx + gemm_grouped_num isinstance inputs idx torch Tensor W = inputs idx assert isinstance W torch Tensor W must torch Tensor pyrefly ignore unsupported-operation new_inputs idx = W to_dense W is_mkldnn W new_inputs layout_or_out normalize_shapes inputs list _T layout_or_out _U - tuple list _T _U new_inputs list _T = list inputs trans_w new_inputs layout_or_out X = new_inputs wgt_idx range wgt_start_idx wgt_start_idx + gemm_grouped_num new_input = new_inputs wgt_idx new_inputs wgt_idx = transpose_w new_input trans_w bias_idx range bias_start_idx len new_inputs pyrefly ignore bad-argument-type new_bias = expand_bias new_inputs bias_idx X assert new_bias None pyrefly ignore unsupported-operation new_inputs bias_idx = new_bias new_inputs layout_or_out num_threads = parallel_num_threads new_inputs _ = normalize_shapes maybe_to_dense new_inputs new_layout m n k _ = mm_args new_inputs new_inputs wgt_start_idx output_dtype compute_dtype = get_gemm_template_output_and_compute_dtype new_inputs get_dtype micro_gemm = create_micro_gemm micro_gemm m n k input_dtype=new_inputs get_dtype input _dtype=new_inputs wgt_start_idx get_dtype output_dtype=output_dtype compute_dtype=compute_dtype alpha=alpha num_threads=num_threads assert micro_gemm None _ block_n _ = micro_gemm register_blocking new_size padded_n = cls get_padded_size n block_n k should_block_weight=True padding = padded_n - n pack_weight inputs list _T layout_or_out _U - tuple list _T _U new_W_list = new_inputs = list inputs W_list = new_inputs wgt_start_idx wgt_start_idx + gemm_grouped_num W W_list blocked_w = cls block_weight W new_size padding new_W_list append cls pack_vnni_weight blocked_w micro_gemm new_size new_inputs wgt_start_idx wgt_start_idx + gemm_grouped_num = new_W_list new_inputs layout_or_out preprocessor inputs list _T layout _U - tuple list _T _U pack_weight normalize_shapes maybe_to_dense reorder_and_filter inputs layout postprocessor output _T - _T isinstance output ir TensorBox template_buffer = ir InputsKernel unwrap_storage_for_input output assert isinstance template_buffer ir CppTemplateBuffer new_input_nodes _ = reorder_and_filter input_nodes layout W_nodes = new_input_nodes wgt_start_idx wgt_start_idx + gemm_grouped_num W_tensor = W_node W_nodes assert W_node get_name V graph constants pyrefly ignore bad-argument-type W_tensor append V graph constants W_node get_name new_input_nodes wgt_start_idx wgt_start_idx + gemm_grouped_num = W_tensor type ignore assignment new_input_nodes _ = pack_weight normalize_shapes maybe_to_dense new_input_nodes layout Prune unused tensors prune_tensors input_nodes new_input_nodes idx range wgt_start_idx wgt_start_idx + gemm_grouped_num W_packed = new_input_nodes idx assert isinstance W_packed torch Tensor W_packed_constant = V graph add_tensor_constant W_packed template_buffer inputs idx = ir InputsKernel unwrap_storage_for_input W_packed_constant pyrefly ignore bad-return output template = DataProcessorTemplateWrapper CppGroupedGemmTemplate preprocessor postprocessor input_nodes=input_nodes layout=layout num_threads=num_threads register_blocking=micro_gemm register_blocking beta=beta alpha=alpha has_bias=has_bias epilogue_creator=epilogue_creator act_mapping=act_mapping gemm_grouped_num=gemm_grouped_num template maybe_append_choice choices template render type ignore override no-untyped-def kernel CppTemplateKernel template_buffer_node Optional ir CppTemplateBuffer = None flag_template_buffer_has_other_users Optional bool = None epilogue_nodes Optional list ir IRNode = None kwargs - str assert act_mapping act_deduplicated = get_deduplicated_act act_mapping wgt_start_idx = len act_deduplicated bias_start_idx = wgt_start_idx + gemm_grouped_num X_list = list act_mapping values W_list = input_nodes wgt_start_idx wgt_start_idx + gemm_grouped_num inp_list = cur_idx = bias_start_idx inp_idx range gemm_grouped_num inp = None pyrefly ignore index-error has_bias inp_idx inp = input_nodes cur_idx cur_idx += inp_list append inp Y_list = output_node multi_output_buffers = None template_buffer_node None W_list = template_buffer_node inputs wgt_start_idx wgt_start_idx + gemm_grouped_num assert isinstance template_buffer_node outputs list Y_list = template_buffer_node outputs counters inductor cpp_grouped_gemm_template += multi_output_buffers = template_buffer_node outputs template_buffer = Y_list fake_buffers list ir Buffer = Y_ d_list = Y_list output_dtype compute_dtype = get_gemm_template_output_and_compute_dtype X_list get_dtype micro_gemm = create_micro_gemm f kernel kernel_name _micro_gemm m n k input_dtype=X_list get_dtype pyrefly ignore missing-attribute input _dtype=W_list get_dtype output_dtype=output_dtype compute_dtype=compute_dtype alpha=self alpha num_threads=self num_threads assert micro_gemm None assert register_blocking == micro_gemm register_blocking log_blockings isinstance micro_gemm CppMicroGemmAMX counters inductor cpp_micro_gemm_amx_counter += L _cache_size = torch _C _cpu _L d_cache_size per core cache size Bytes assert L _cache_size f Expect L _cache_size got L _cache_size L _cache_size = torch _C _cpu _L _cache_size per core cache size Bytes assert L _cache_size f Expect L _cache_size got L _cache_size epilogues list ir IRNode = reindexers list Optional Callable list Any list Any = gemm_output_buffers list ir Buffer = out_buf_idx range gemm_grouped_num gemm_output_name = f template_buffer get_name _GemmOut + str out_buf_idx gemm_output_buffers append ir Buffer name=gemm_output_name layout=template_buffer layout assert epilogue_creator epilogue_creator supported yet Grouped GEMM Template kernel_args dict str Optional ir IRNode = x_idx range wgt_start_idx kernel_args X + str x_idx = act_deduplicated x_idx w_idx range gemm_grouped_num pyrefly ignore unsupported-operation kernel_args W + str w_idx = W_list w_idx inp_idx range gemm_grouped_num kernel_args inp + str inp_idx = inp_list inp_idx _bias_add_epilogue buf ir IRNode inp ir IRNode - ir Pointwise create_epilogue_with_attr buf bias_add other=inp beta=self beta dtype=self layout dtype gemm_idx inp enumerate inp_list inp buffer_name = Y_list gemm_idx get_name epilogues append ir ComputedBuffer name=buffer_name layout=template_buffer layout data=_bias_add_epilogue gemm_output_buffers gemm_idx inp reindexers append None epilogue_nodes epilogues extend epilogue_nodes epilogue_node epilogue_nodes Y = cast ir Buffer epilogue_node _ reindexers = gen_ d_view_of_epilogue_buf Y template_buffer epilogue_node reindexers default_reindexers= None options = dict N=self n K=self k PADDED_N=self padded_n aliases= beta=self beta alpha=self alpha num_threads=self num_threads micro_gemm=micro_gemm is_dynamic_M=self is_dynamic_M template=self kernel=kernel export_declaration=get_export_declaration acc_buf_dtype=torch float DTYPE_TO_CPP=DTYPE_TO_CPP L _cache_size=L _cache_size L _cache_size=L _cache_size config=config epilogue_nodes=epilogues GemmOuts=gemm_output_buffers reindexers=reindexers kernel_args=kernel_args X_list=X_list W_list=W_list gemm_grouped_num=self gemm_grouped_num Y_list= Y + str idx Y idx Y enumerate Y_list Y_ d_list=Y_ d_list multi_output_buffers=multi_output_buffers contextlib ExitStack stack stack enter_context patch object V graph get_dtype _fake_get_dtype fake_buffers _template_from_string GEMM_TEMPLATE render options