Owner s oncall distributed contextlib torch torch distributed dist torch _subclasses fake_tensor FakeTensorMode torch distributed tensor DeviceMesh DTensor Partial Replicate Shard torch distributed tensor _dtensor_spec ShardOrderEntry torch testing _internal common_utils instantiate_parametrized_tests parametrize requires_cuda run_tests TestCase torch testing _internal distributed fake_pg FakeStore torch utils _debug_mode _OpCall _RedistributeCall DebugMode torch utils _python_dispatch TorchDispatchMode requires_cuda TestDTensorDebugMode TestCase tearDown super tearDown dist destroy_process_group setUp super setUp world_size = store = FakeStore dist init_process_group backend= fake rank= world_size=self world_size store=store device_type = cuda test_debug_mode_mm mesh = DeviceMesh device_type list range world_size x = torch randn requires_grad=False y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard run_check=False y_dtensor = DTensor from_local y mesh Shard run_check=False DebugMode record_torchfunction=True debug_mode torch mm x_dtensor y_dtensor sum assertExpectedInline debug_mode debug_string \ torch mm dt f &#124; S dt f &#124; S aten mm dt f &#124; S dt f &#124; S redistribute_input S - R redistribute_input t f trace S - R _c d_functional all_gather_into_tensor t f _c d_functional wait_tensor t f aten mm t f t f method sum torch _C TensorBase objects dt f &#124; S aten sum dt f &#124; S aten sum t f assertTrue isinstance debug_mode operators _OpCall assertTrue isinstance debug_mode operators _RedistributeCall assertEqual next iter debug_mode operators torch ops aten mm default check stringification assertTrue hasattr debug_mode operators args_str assertFalse hasattr debug_mode operators args check recording hook mm x y x y sum eager_out = mm x_dtensor y_dtensor check recording hook compiled variant DebugMode debug_mode DebugMode record_outputs DebugMode log_tensor_hashes compiled_out = torch compile mm backend= aot_eager x_dtensor y_dtensor check numerical equivalence assertTrue torch equal eager_out compiled_out sum_op = next iter op op debug_mode operators isinstance op _OpCall str op op == aten sum default assertTrue torch equal sum_op record output eager_out to_local assertTrue aten sum t f hash debug_mode debug_string test_debug_string_inside_context mesh = DeviceMesh device_type list range world_size x = torch randn requires_grad=False y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard run_check=False y_dtensor = DTensor from_local y mesh Shard run_check=False DebugMode debug_mode torch mm x_dtensor y_dtensor sum s = debug_mode debug_string s = debug_mode debug_string assertEqual s s test_debug_mode_backward mesh = DeviceMesh device_type list range world_size x = torch randn requires_grad=True y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard run_check=False y_dtensor = DTensor from_local y mesh Shard run_check=False DebugMode record_torchfunction=True record_stack_trace=True debug_mode z = x_dtensor + y_dtensor z sum backward assertExpectedInline debug_mode debug_string \ method add torch _C TensorBase objects dt f &#124; S dt f &#124; S aten add Tensor dt f &#124; S dt f &#124; S redistribute_input S - S redistribute_input t f trace S - S _dtensor shard_dim_alltoall t f aten add Tensor t f t f method sum torch _C TensorBase objects dt f &#124; S aten sum dt f &#124; S aten sum t f torch _tensor backward dt f &#124; P gradient=None retain_graph=None create_graph=False inputs=None aten ones_like dt f &#124; P pin_memory=False memory_format=torch preserve_format aten ones_like t f pin_memory=False memory_format=torch preserve_format aten expand dt f &#124; R aten expand t f redistribute_input t f trace R- S aten split Tensor t f aten clone t f aten _to_copy t f dtype=torch float layout=torch strided device=cpu redistribute_input t f trace R- S aten detach t f aten split Tensor t f aten clone t f aten _to_copy t f dtype=torch float layout=torch strided device=cpu aten detach t f check stack trace assertTrue z sum backward debug_mode operators - stack_trace test_debug_mode_densor_redistribution_trace mesh = DeviceMesh device_type torch arange world_size view x = torch randn requires_grad=True y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard Shard run_check=False y_dtensor = DTensor from_local y mesh Shard Shard run_check=False x_dtensor _spec shard_order = ShardOrderEntry tensor_dim= mesh_dims= y_dtensor _spec shard_order = ShardOrderEntry tensor_dim= mesh_dims= DebugMode record_torchfunction=False debug_mode torch mm x_dtensor y_dtensor sum assertExpectedInline debug_mode debug_string \ aten mm dt f &#124; S S dt f &#124; S S redistribute_input S S - S R redistribute_input t f trace S S - S R _c d_functional all_gather_into_tensor t f _c d_functional wait_tensor t f redistribute_input S S - RS redistribute_input t f trace S S - S R- RR- RS _c d_functional all_gather_into_tensor t f _c d_functional wait_tensor t f aten chunk t f aten cat t f t f _c d_functional all_gather_into_tensor t f _c d_functional wait_tensor t f aten chunk t f aten cat t f t f t f t f aten chunk t f aten clone t f aten mm t f t f aten sum dt f &#124; S S aten sum t f test_debug_mode_einsum mesh = DeviceMesh device_type torch arange world_size view Create test tensors = torch randn b = torch randn a_dt = DTensor from_local mesh Partial Replicate run_check=False b_dt = DTensor from_local b mesh Replicate Partial run_check=False Capture operator decomposition DebugMode record_torchfunction=True debug_mode torch einsum bld dnh- blnh a_dt b_dt assertExpectedInline debug_mode debug_string \ torch functional einsum bld dnh- blnh dt f &#124; PR dt f &#124; RP aten unsqueeze dt f &#124; PR aten unsqueeze t f aten unsqueeze dt f &#124; PR aten unsqueeze t f aten permute dt f &#124; PR aten permute t f aten unsqueeze dt f &#124; RP aten unsqueeze t f aten unsqueeze dt f &#124; RP aten unsqueeze t f aten permute dt f &#124; RP aten permute t f aten permute dt f &#124; PR aten permute t f aten view dt f &#124; PR aten view t f aten permute dt f &#124; RP aten permute t f aten view dt f &#124; RP aten view t f aten bmm dt f &#124; PR dt f &#124; RP redistribute_input PR - S S redistribute_input t f trace PR- S R- S S aten chunk t f aten cat t f t f t f t f _c d_functional reduce_scatter_tensor t f sum _c d_functional wait_tensor t f aten chunk t f aten clone t f redistribute_input RP - S S redistribute_input t f trace RP- S P- S S aten chunk t f aten clone t f aten chunk t f aten cat t f t f _c d_functional reduce_scatter_tensor t f sum _c d_functional wait_tensor t f aten bmm t f t f aten view dt f &#124; PP aten view t f aten permute dt f &#124; PP aten permute t f aten view dt f &#124; PP aten view t f test_real_tensor x = torch randn linear = torch nn Linear DebugMode record_torchfunction=True debug_mode linear x sum assertExpectedInline debug_mode debug_string \ torch _C _nn linear t f t f t f aten view t f aten t t f aten addmm t f t f t f aten view t f method sum torch _C TensorBase objects t f aten sum t f test_fake_tensor FakeTensorMode x = torch randn y = torch randn DebugMode record_torchfunction=True record_faketensor=True debug_mode torch matmul y x assertExpectedInline debug_mode debug_string \ torch matmul ft f ft f aten view ft f aten mm ft f ft f aten _unsafe_view ft f test_tensor_attributes x = torch randn x = x x = x y = torch randn y = y DebugMode record_torchfunction=True record_faketensor=True record_tensor_attributes= store_original_args=True debug_mode torch matmul y x assertExpectedInline debug_mode debug_string \ torch matmul t f =y t f =x =x aten view t f =y aten mm t f t f =x =x aten _unsafe_view t f assertTrue hasattr debug_mode operators args assertEqual id debug_mode operators args id y parametrize has_inner_mode True False parametrize has_outer_mode True False test_nested_debug_mode has_inner_mode has_outer_mode DummyTorchDispatchMode TorchDispatchMode __torch_dispatch__ func types args= kwargs=None func args kwargs DummyTorchDispatchMode TorchDispatchMode __torch_dispatch__ func types args= kwargs=None func args kwargs mesh = DeviceMesh device_type list range world_size x = torch randn requires_grad=True y = torch randn requires_grad=True x_dtensor = DTensor from_local x mesh Shard run_check=False y_dtensor = DTensor from_local y mesh Shard run_check=False inner_mode = DummyTorchDispatchMode has_inner_mode contextlib nullcontext outer_mode = DummyTorchDispatchMode has_outer_mode contextlib nullcontext outer_mode DebugMode debug_mode inner_mode torch mm x_dtensor y_dtensor assertTrue redistribute_input S - R debug_mode debug_string test_debug_mode_higher_order_cond Test DebugMode higher order operation x = torch randn requires_grad=True DebugMode record_torchfunction=True debug_mode rewrite torch conda torch ops higher_order cond avoid compilation torch ops higher_order cond torch tensor True lambda x x + lambda x x - x Verify cond operations captured debug mode assertIn torch ops higher_order cond debug_mode debug_string test_compile torch compile f x x sin cos x = torch randn DebugMode debug_mode f x assertEqual len debug_mode debug_string test_nn_module Foo torch nn Module __init__ super __init__ l = torch nn Linear l = torch nn Linear forward x l l x Bar torch nn Module __init__ super __init__ abc = Foo xyz = torch nn Linear forward x xyz abc x mod = Bar inp = torch randn DebugMode record_nn_module=True debug_mode _ = mod inp assertExpectedInline debug_mode debug_string \ nn Mod Bar nn Mod Bar abc nn Mod Bar abc l aten t t f aten addmm t f t f t f nn Mod Bar abc l aten t t f aten addmm t f t f t f nn Mod Bar xyz aten t t f aten addmm t f t f t f instantiate_parametrized_tests TestDTensorDebugMode __name__ == __main__ run_tests