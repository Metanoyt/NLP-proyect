Copyright c Meta Platforms Inc affiliates implement matrix related ops distributed tensor torch torch distributed tensor _dtensor_spec DTensorSpec TensorMeta torch distributed tensor _op_schema OpSchema OutputSharding torch distributed tensor _ops utils register_prop_rule aten = torch ops aten register_prop_rule aten convolution default convolution_rules op_schema OpSchema - OutputSharding input_spec weight_spec bias_spec stride padding dilation _transposed _output_padding _groups = op_schema args_schema assert isinstance input_spec DTensorSpec assert isinstance weight_spec DTensorSpec assert isinstance bias_spec DTensorSpec assert input_spec tensor_meta None assert weight_spec tensor_meta None in_shape = input_spec tensor_meta shape weight_shape = weight_spec tensor_meta shape assert isinstance stride list assert isinstance padding list assert isinstance dilation list assert isinstance weight_shape torch Size out_conv_shape = d + padding i - dilation i weight_shape i + - - stride i + i d enumerate in_shape output_shape = in_shape weight_shape + out_conv_shape output_stride = i range len output_shape output_stride insert output_stride output_shape -i output_dim_map = input_spec dim_map pending_sums = input_spec sums tensor_meta = TensorMeta torch Size output_shape tuple output_stride input_spec tensor_meta dtype OutputSharding DTensorSpec from_dim_map input_spec mesh output_dim_map pending_sums tensor_meta=tensor_meta register_prop_rule aten convolution_backward default convolution_backward_rules op_schema OpSchema - OutputSharding input_spec = op_schema args_schema grad_output_spec input_spec weight_spec bias_shape_opt _stride _padding _dilation _transposed _output_padding _groups _output_mask = op_schema args_schema assert isinstance grad_output_spec DTensorSpec assert isinstance input_spec DTensorSpec assert isinstance weight_spec DTensorSpec assert isinstance bias_shape_opt list assert input_spec tensor_meta None weight_tensor_meta = weight_spec tensor_meta bias_tensor_meta = TensorMeta torch Size bias_shape_opt input_spec tensor_meta dtype grad_input_spec = input_spec grad_weight_spec = DTensorSpec from_dim_map input_spec mesh - - - - tensor_meta=weight_tensor_meta grad_bias_spec = DTensorSpec from_dim_map input_spec mesh - tensor_meta=bias_tensor_meta TODO actually output_mask respected here we should set corresponding spec ` None ` output_mask ` False ` certain output Tensor This also applies conv handler torch distributed tensor _tp_conv py OutputSharding grad_input_spec grad_weight_spec grad_bias_spec