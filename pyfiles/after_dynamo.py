Utilities reproducing debugging issues Dynamo after graph capture This file provides tools infrastructure debugging problems occur after Dynamo has captured graph before during backend compilation Key components include - Minification tools reduce large graphs minimal failing examples - Accuracy testing validate compiled graph outputs match eager mode - Repro generation create standalone reproduction scripts - Debug backends capturing analyzing failures - Utilities saving loading graph states inputs The tools here focus specifically post-graph-capture stage making them useful debugging backend compilation issues AOTAutograd problems accuracy discrepancies between compiled eager execution argparse copy functools logging os shutil sys textwrap collections abc Callable Sequence importlib import_module typing Any Optional Union torch torch fx fx torch _dynamo debug_utils AccuracyError backend_accuracy_fails BUCK_CMD_PREFIX BuckTargetWriter extra_imports generate_config_string generate_env_vars_string helper_for_dump_minify InputReader InputWriter minifier_dir NNModuleToString NopInputReader run_fwd_maybe_bwd same_two_models torch fx experimental symbolic_shapes fx_placeholder_targets torch hub tqdm config backends registry CompilerFn lookup_backend register_debug_backend debug_utils clone_inputs_retaining_gradness log = logging getLogger __name__ inductor_config = import_module torch _inductor config use_buck = inductor_config is_fbcode ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MAIN ENTRY POINT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ _accuracy_fails gm torch fx GraphModule example_inputs Sequence Any compiler_fn Callable torch fx GraphModule list Any torch fx GraphModule - bool backend_accuracy_fails gm example_inputs compiler_fn only_fwd=config repro_forward_only ignore_non_fp=config repro_ignore_non_fp WrapBackendDebug __init__ unconfigured_compiler_fn CompilerFn compiler_name Optional str - None functools wraps unconfigured_compiler_fn _torchdynamo_orig_backend = unconfigured_compiler_fn _compiler_name = compiler_name hasattr unconfigured_compiler_fn __name__ __name__ = unconfigured_compiler_fn __name__ hasattr unconfigured_compiler_fn compiler_name __name__ = unconfigured_compiler_fn compiler_name type ignore attr-defined hasattr unconfigured_compiler_fn get_compiler_config get_compiler_config = unconfigured_compiler_fn get_compiler_config type ignore attr-defined __call__ gm torch fx GraphModule example_inputs list Any kwargs Any - torch fx GraphModule compiler_fn = functools partial _torchdynamo_orig_backend kwargs assert config repro_after dynamo aot None config repro_after == dynamo add_paths exc Exception - None exc minifier_path = os path join minifier_dir minifier_launcher py type ignore attr-defined use_buck exc buck_command = join type ignore attr-defined BUCK_CMD_PREFIX + BuckTargetWriter exc minifier_path cmd_line_path type ignore attr-defined config repro_level == dump_to_minify_after_dynamo gm example_inputs _compiler_name Check either accuracy level other type failures config repro_level == Check Accuracy compiled_gm = compiler_fn copy deepcopy gm example_inputs _accuracy_fails gm example_inputs compiler_fn type ignore arg-type log warning Accuracy failed TorchDynamo produced graph Creating script minify error dump_to_minify_after_dynamo fx GraphModule gm copy deepcopy gm graph example_inputs _compiler_name exc = AccuracyError Bad accuracy detected add_paths exc raise exc try compiled_gm = compiler_fn copy deepcopy gm example_inputs run_fwd_maybe_bwd compiled_gm example_inputs type ignore arg-type except Exception exc log warning Compiled Fx GraphModule failed Creating script minify error config repro_level == dump_state_fn = functools partial dump_backend_state compiler_name=self _compiler_name dump_state_fn fx GraphModule gm copy deepcopy gm graph example_inputs config repro_level == dump_to_minify_after_dynamo fx GraphModule gm copy deepcopy gm graph example_inputs _compiler_name add_paths exc raise compiled_gm = compiler_fn gm example_inputs compiled_gm type ignore return-value wrap_backend_debug unconfigured_compiler_fn CompilerFn compiler_name Optional str - WrapBackendDebug A minifier decorator wraps TorchDynamo produced Fx graph modules As opposed wrap_compiler_debug wrapper intercepts TorchDynamo produced Fx Graph Module This makes backend-agnostic some level e g useful minifying issues related Aot Autograd tracing If error found we minify save minified repro repro tar gz WrapBackendDebug unconfigured_compiler_fn compiler_name ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REPRO DUMPERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ generate_dynamo_fx_repro_string gm torch fx GraphModule args Sequence Any compiler_name Optional str check_accuracy bool = False stable_output bool = False save_dir Optional str = None command str = run - str Generate repro string backend-agnostic minified version model_str = NNModuleToString convert gm TODO Figure out why torch compile d hash isn t work codepath writer = InputWriter save_dir stable_hash=True placeholder arg zip fx_placeholder_targets gm args isinstance arg int torch SymInt writer symint placeholder arg isinstance arg torch Tensor TODO improve these names FQN writer tensor placeholder arg raise TypeError f arg neither SymInt int nor torch Tensor arg load_args = \n join writer lines textwrap dedent f generate_env_vars_string stable_output=stable_output math inf torch torch tensor device torch fx fx torch _dynamo torch _dynamo testing rand_strided torch _dynamo debug_utils run_fwd_maybe_bwd generate_config_string stable_output=stable_output extra_imports model_str mod = Repro load_args __name__ == __main__ torch _dynamo repro after_dynamo run_repro run_repro mod load_args accuracy= check_accuracy r command= command r save_dir= save_dir r autocast= torch is_autocast_enabled r backend= compiler_name r dump_backend_repro_as_file gm torch fx GraphModule args Sequence Any compiler_name Optional str check_accuracy bool = False - None Saves repro repro py file curdir = os getcwd subdir = os path join os getcwd checkpoints os path exists subdir os makedirs subdir exist_ok=True file_name = os path join subdir f minified_ len gm graph nodes _nodes py log warning Writing checkpoint s nodes s len gm graph nodes file_name open file_name w fd fd write generate_dynamo_fx_repro_string gm args compiler_name check_accuracy save_dir=subdir latest_repro = os path join curdir repro py log warning Copying s s convenience file_name latest_repro use_buck BuckTargetWriter latest_repro write shutil copyfile file_name latest_repro dump_backend_state gm torch fx GraphModule args Sequence Any compiler_name Optional str check_accuracy bool = False - None Dumps dynamo graph repro issue It tries convert Fx GraphModule string If we can writes repro py file If we can t convert Fx GraphModule string we use to_folder save module save tar file assert NNModuleToString can_convert_to_string gm dump_backend_repro_as_file gm args compiler_name check_accuracy dump_backend_repro_as_tarfile gm args compiler_name ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MINIFIER DUMPER ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ dump_to_minify_after_dynamo gm torch fx GraphModule args Sequence Any compiler_name Optional str - None TODO factor out subdir = os path join minifier_dir checkpoints os path exists subdir os makedirs subdir exist_ok=True helper_for_dump_minify generate_dynamo_fx_repro_string gm args compiler_name check_accuracy=config repro_level == save_dir=subdir command= minify ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MINIFIER BACKENDS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ register_debug_backend type ignore arg-type dynamo_minifier_backend gm fx GraphModule example_inputs Sequence Any compiler_name Optional str - fx GraphModule functorch compile minifier compiler_fn = lookup_backend compiler_name type ignore arg-type TODO It s inconsistent pass SymInt inputs REAL tensors We should pass ints look GraphModule placeholders resolve them SymInt necessary example_inputs = i node hint isinstance i torch SymInt i i example_inputs try compiled_gm = compiler_fn gm example_inputs run_fwd_maybe_bwd compiled_gm example_inputs type ignore arg-type raise ValueError No issue detected except Exception exc orig_failure = str exc log warning Compiled Fx GraphModule failed Creating script minify error dump_state_fn = functools partial dump_backend_state compiler_name=compiler_name dump_state_fn fx GraphModule gm copy deepcopy gm graph example_inputs fails_fn = functools partial backend_fails compiler_fn=compiler_fn orig_failure=orig_failure minifier gm example_inputs module_fails=fails_fn dump_state=dump_state_fn gm register_debug_backend type ignore arg-type dynamo_accuracy_minifier_backend gm fx GraphModule example_inputs Sequence Any compiler_name Optional str - fx GraphModule functorch compile minifier compiler_fn = lookup_backend compiler_name type ignore arg-type Set eval mode remove randomness gm eval Check Accuracy _accuracy_fails gm example_inputs compiler_fn type ignore arg-type log warning Accuracy failed TorchDynamo produced graph dump_state_fn = functools partial dump_backend_state compiler_name=compiler_name check_accuracy=True fails_fn = functools partial _accuracy_fails compiler_fn=compiler_fn type ignore arg-type dump_state_fn fx GraphModule gm copy deepcopy gm graph example_inputs minifier gm example_inputs module_fails=fails_fn dump_state=dump_state_fn log error Input graph does fail accuracy testing gm backend_fails gm fx GraphModule example_inputs Sequence Any compiler_fn CompilerFn orig_failure Sequence Any - bool Minifier uses function identify minified graph module fails same error One caveat minifier can potentially go into wrong direction when resulting graph module fails different reason To avoid we save string original exception check similarity between new old exception They can somewhat different some cases when exception string depends failing node information So we have loose similarity metric guide minifier path difflib SequenceMatcher try Run original gm check eager validity run_fwd_maybe_bwd gm clone_inputs_retaining_gradness example_inputs compiled_gm = compiler_fn gm example_inputs type ignore arg-type run_fwd_maybe_bwd compiled_gm clone_inputs_retaining_gradness example_inputs type ignore arg-type except Exception e new_failure = str e SequenceMatcher None orig_failure new_failure ratio True False ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REPRO MAIN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ run_load_args options Any mod torch nn Module load_args Any - list Any hasattr load_args _version log warning load_args does have _version attribute please file bug PyTorch describe how you generate repro script load_args _version log warning load_args version s version PyTorch only supports version We will try run anyway there may incompatibility so try upgrading your version PyTorch load_args _version nop_reader = NopInputReader load_args nop_reader tqdm desc= Loading inputs total=nop_reader total pbar input_reader = InputReader save_dir=options save_dir pbar=pbar load_args input_reader args = input_reader args args repro_minify options Any mod torch nn Module load_args Any - None args = run_load_args options mod load_args Setup debug minifier compiler options accuracy compiler_fn = lookup_backend dynamo_minifier_backend compiler_fn = lookup_backend dynamo_accuracy_minifier_backend options backend None raise RuntimeError Compiler name None - likely means custom compiler called torchdynamo Please remove error your custom compiler function replace backend=None line run_repro backend= my_imported_custom_function dynamo_minifier_backend = functools partial compiler_fn compiler_name=options backend type ignore call-arg opt_mod = torch _dynamo optimize dynamo_minifier_backend mod torch amp autocast cuda enabled=options autocast opt_mod args repro_run options Any mod torch nn Module load_args Any - None opt_mod = torch _dynamo optimize options backend mod options accuracy = mod eval opt_mod eval type ignore union-attr torch amp autocast cuda enabled=options autocast TODO disable clone args = run_load_args options mod load_args assert same_two_models mod mod args Eager itself failed type ignore arg-type same_two_models mod type ignore arg-type opt_mod type ignore arg-type args only_fwd=config repro_forward_only ignore_non_fp=config repro_ignore_non_fp raise AccuracyError Dynamo failed torch amp autocast cuda enabled=options autocast args = run_load_args options mod load_args run_fwd_maybe_bwd mod args only_fwd=options only_fwd disable_clone=True type ignore arg-type del args args = run_load_args options mod load_args run_fwd_maybe_bwd opt_mod type ignore arg-type args only_fwd=options only_fwd disable_clone=True type ignore arg-type run_repro mod torch nn Module load_args Any command str = run accuracy Union bool str = save_dir Optional str = None autocast bool = False backend str = inductor kwargs Any - None k kwargs log warning Unrecognized kwarg s perhaps repro made newer version PyTorch k accuracy True accuracy = accuracy accuracy False accuracy = parser = argparse ArgumentParser description=f \ An after_dynamo repro script typically triggering bug Dynamo AOTAutograd When run no arguments script defaults running command Extra flags may available find out more try command -- help There also alternate subcommands available see below default settings script accuracy= save_dir= formatter_class=argparse RawTextHelpFormatter common_flags parser argparse ArgumentParser - None accuracy_group = parser add_mutually_exclusive_group accuracy_group add_argument -- no-accuracy dest= accuracy action= store_const const= default=accuracy help= do test accuracy just run module see errors accuracy_group add_argument -- accuracy action= store_const const= accuracy default=accuracy help= test accuracy parser add_argument -- save-dir type=str default=save_dir metavar= DIR help= directory where saved inputs live parser add_argument -- no-save-dir dest= save_dir action= store_const const=None help= don t use any directory saved inputs parser add_argument -- no-isolate dest= isolate action= store_false default=False help= no isolate doesn t do anything after_dynamo parser add_argument -- autocast default=autocast action= store_true help= use torch cuda amp autocast parser add_argument -- no-autocast dest= autocast action= store_false help= don t use torch cuda amp autocast parser add_argument -- backend type=str default=backend metavar= BACKEND help= torch compile backend use subparsers = parser add_subparsers dest= command metavar= run minify required=True parser_run = subparsers add_parser run help= just run repro common_flags parser_run parser_run add_argument -- only-fwd action= store_true help= don t run backwards compilation testing parser_minify = subparsers add_parser minify help= run minifier repro common_flags parser_minify args = None len sys argv = args = command sys argv options = parser parse_args args COMMAND_FNS = minify repro_minify run repro_run COMMAND_FNS options command options mod load_args