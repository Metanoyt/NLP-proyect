operator_benchmark op_bench torch torch ao nn quantized nnq torch ao quantization tq torch nn nn Microbenchmarks general quantization operations mode used show direction benchmark Q benchmark quantization dequantization quantize_configs_short_dict = attr_names C M N dtype mode attrs torch quint Q torch quint D tags short quantize_configs_long_dict = C reused per-channel avoid single channel test M N dtype torch quint torch qint torch qint mode D Q tags long quantize_per_tensor_configs_short = op_bench config_list quantize_configs_short_dict quantize_per_tensor_configs_long = op_bench cross_product_configs quantize_configs_long_dict QuantizePerTensorBenchmark op_bench TorchBenchmarkBase r Benchmarks both quantization dequantization init C M N dtype mode assert mode Q D input = torch rand C M N dtype = dtype op = nnq Quantize scale= zero_point= dtype=dtype set_module_name QuantizePerTensor mode == D input = op input op = nnq DeQuantize set_module_name DequantizePerTensor inputs = input input forward input op input op_bench generate_pt_test quantize_per_tensor_configs_short + quantize_per_tensor_configs_long QuantizePerTensorBenchmark === Per Channel quantization === quantize_per_channel_configs_short = op_bench config_list cross_product_configs= axis quantize_configs_short_dict quantize_per_channel_configs_long = op_bench cross_product_configs axis= quantize_configs_long_dict QuantizePerChannelBenchmark op_bench TorchBenchmarkBase r Benchmarks both quantization dequantization init C M N dtype axis mode assert mode Q D input = torch rand C M N op = torch quantize_per_channel channel_len = C M N axis kwargs = scales torch tensor channel_len zero_points torch tensor channel_len dtype dtype axis axis set_module_name QuantizePerChannel mode == D input = op input kwargs dequant input scales zero_points axis int dtype int input dequantize op = dequant set_module_name DequantizePerChannel inputs = input input scales torch tensor channel_len zero_points torch tensor channel_len axis axis dtype dtype forward input scales zero_points axis int dtype int op input scales=scales zero_points=zero_points axis=axis dtype=dtype op_bench generate_pt_test quantize_per_channel_configs_short + quantize_per_channel_configs_long QuantizePerChannelBenchmark === Fake Quantization === Generated benchmarks names start learnable_kernel original_kernel ex original_kernel_nbits _cpu_N _C _H _W _zero_point_dtypetorch int _bwdall fake_quantize_configs_short_dict = attr_names N C H W zero_point_dtype attrs torch int tags short fake_quantize_configs_long_dict = N C H W zero_point_dtype torch int tags long fake_quantize_configs_short = op_bench config_list cross_product_configs= device cpu cuda fake_quantize_configs_short_dict fake_quantize_configs_long = op_bench cross_product_configs device= cpu cuda fake_quantize_configs_long_dict FakeQuantizeBenchmark op_bench TorchBenchmarkBase r Benchmarks fake quantization default parameters init N C H W zero_point_dtype device inputs = input torch rand N C H W device op = tq FakeQuantize device set_module_name FakeQuantize forward input op input op_bench generate_pt_test fake_quantize_configs_short + fake_quantize_configs_long FakeQuantizeBenchmark op_type used describe type operator used benchmarking learnable_kernel represents c++ kernel can backpropagate scale zero point original_kernel represents original fake quantize c++ kernel fakeQuantizePerTensorLearnableKernel input scale zero_point quant_min int quant_max int torch _fake_quantize_learnable_per_tensor_affine input scale zero_point quant_min quant_max fakeQuantizePerTensorOriginalKernel input scale zero_point quant_min int quant_max int torch fake_quantize_per_tensor_affine input quant_min quant_max fake_quantize_per_tensor_ops = op_bench op_list attrs= learnable_kernel_tensor fakeQuantizePerTensorLearnableKernel original_kernel_tensor fakeQuantizePerTensorOriginalKernel attr_names= op_name op_func fake_quantize_operator_configs_short = op_bench config_list cross_product_configs= nbits device cpu cuda fake_quantize_configs_short_dict fake_quantize_operator_configs_long = op_bench cross_product_configs nbits= device= cpu cuda fake_quantize_configs_long_dict TODO future PR Combine config floating point zero_point other configs once fully supported all fakeQuant operators devices https github com pytorch pytorch issues fake_quantize_configs_long_dict_float_zero_point = fake_quantize_configs_long_dict copy fake_quantize_configs_long_dict_float_zero_point zero_point_dtype = torch float torch half fake_quantize_operator_configs_long_float_zero_point = op_bench cross_product_configs nbits= device= cpu cuda fake_quantize_configs_long_dict_float_zero_point FakeQuantizePerTensorBaseOpBenchmark op_bench TorchBenchmarkBase r Benchmarks different fake quantize per tensor operators init N C H W zero_point_dtype nbits device op_func quant_min = quant_max = nbits - quant_range = nbits input = nn Parameter torch rand N C H W dtype=torch float device=device requires_grad=self auto_set scale = nn Parameter torch tensor device requires_grad=self auto_set op_func __name__ == fakeQuantizePerChannelOriginalKernel zero_point = nn Parameter torch tensor device zero_point_dtype requires_grad=self auto_set zero_point = nn Parameter torch tensor device requires_grad=self auto_set inputs = input input scale scale zero_point zero_point quant_min quant_min quant_max quant_max op_func = op_func forward input scale zero_point quant_min int quant_max int op_func input scale zero_point quant_min quant_max op_bench generate_pt_tests_from_op_list fake_quantize_per_tensor_ops fake_quantize_operator_configs_short + fake_quantize_operator_configs_long FakeQuantizePerTensorBaseOpBenchmark op_bench generate_pt_gradient_tests_from_op_list fake_quantize_per_tensor_ops fake_quantize_operator_configs_short + fake_quantize_operator_configs_long FakeQuantizePerTensorBaseOpBenchmark fakeQuantizePerChannelLearnableKernel input scale zero_point axis int quant_min int quant_max int torch _fake_quantize_learnable_per_channel_affine input scale zero_point axis quant_min quant_max fakeQuantizePerChannelOriginalKernel input scale zero_point axis int quant_min int quant_max int torch fake_quantize_per_channel_affine input scale zero_point axis quant_min quant_max fake_quantize_per_channel_ops = op_bench op_list attrs= learnable_kernel_channel fakeQuantizePerChannelLearnableKernel original_kernel_channel fakeQuantizePerChannelOriginalKernel attr_names= op_name op_func fake_quantize_per_channel_float_zero_point_ops = op_bench op_list attrs= original_kernel fakeQuantizePerChannelOriginalKernel attr_names= op_name op_func FakeQuantizePerChannelOpBenchmark op_bench TorchBenchmarkBase r Benchmarks different fake quantize per channel operators init N C H W zero_point_dtype nbits device op_func quant_min = quant_max = nbits - quant_range = nbits Axis chosen respect number channels C axis = input = nn Parameter torch rand N C H W dtype=torch float device=device requires_grad=self auto_set op_func __name__ == fakeQuantizePerChannelOriginalKernel scale = torch ones C device=device dtype=torch float requires_grad=False zero_point = torch zeros C device=device dtype=zero_point_dtype requires_grad=False scale = nn Parameter torch ones C device=device dtype=torch float requires_grad=self auto_set zero_point = nn Parameter torch zeros C device=device dtype=torch float requires_grad=self auto_set inputs = input input scale scale zero_point zero_point axis axis quant_min quant_min quant_max quant_max op_func = op_func forward input scale zero_point axis int quant_min int quant_max int op_func input scale zero_point axis quant_min quant_max op_bench generate_pt_tests_from_op_list fake_quantize_per_channel_ops fake_quantize_operator_configs_short + fake_quantize_operator_configs_long FakeQuantizePerChannelOpBenchmark op_bench generate_pt_tests_from_op_list fake_quantize_per_channel_float_zero_point_ops fake_quantize_operator_configs_long_float_zero_point FakeQuantizePerChannelOpBenchmark op_bench generate_pt_gradient_tests_from_op_list fake_quantize_per_channel_ops fake_quantize_operator_configs_short + fake_quantize_operator_configs_long FakeQuantizePerChannelOpBenchmark __name__ == __main__ op_bench benchmark_runner main