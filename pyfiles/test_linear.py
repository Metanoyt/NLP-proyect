Owner s oncall quantization torch torch ao quantization experimental linear LinearAPoT torch nn modules linear Linear unittest TestNonUniformObserver unittest TestCase Test linear_APoT_fn comparing uniform linear d tensors size k= test_linear_APoT_k weight fp tensor weight = torch rand activation fp tensor ~ integer values activation = torch randint low= high= size= dtype=torch float calculate result calling linear forward method apot_linear = LinearAPoT weight apot_linear_result = apot_linear activation calculate expected results fp_linear = Linear bias=False set weight fp linear apot_quantized_weight_float = apot_linear weight type torch FloatTensor fp_linear_weight = torch nn parameter Parameter data=apot_quantized_weight_float fp_linear weight = fp_linear_weight fp_linear_result = fp_linear activation data assertTrue torch equal apot_linear_result fp_linear_result Test linear_APoT_fn comparing uniform linear d tensors size k= test_linear_APoT_k weight fp tensor weight = torch rand activation fp tensor ~ integer values note transpose activation matrix will have dimension activation = torch randint low= high= size= dtype=torch float calculate result calling linear forward method apot_linear = LinearAPoT weight apot_linear_result = apot_linear activation calculate expected results fp_linear = Linear bias=False set weight fp linear apot_quantized_weight_float = apot_linear weight type torch FloatTensor fp_linear_weight = torch nn parameter Parameter data=apot_quantized_weight_float fp_linear weight = fp_linear_weight fp_linear_result = fp_linear activation data assertTrue torch equal apot_linear_result fp_linear_result __name__ == __main__ unittest main