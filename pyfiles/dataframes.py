mypy allow-untyped-defs typing Any Optional torch utils data datapipes _decorator functional_datapipe torch utils data datapipes dataframe structures DataChunkDF torch utils data datapipes datapipe DFIterDataPipe IterDataPipe TODO VitalyFedyunin Add error when two different traces get combined __all__ = Capture CaptureA CaptureAdd CaptureCall CaptureControl CaptureDataFrame CaptureDataFrameWithDataPipeOps CaptureF CaptureGetAttr CaptureGetItem CaptureInitial CaptureLikeMock CaptureMul CaptureSetItem CaptureSub CaptureVariable CaptureVariableAssign DataFrameTracer DataFrameTracedOps disable_capture get_val disable_capture CaptureControl disabled = True CaptureControl disabled = False DataFrameTracedOps DFIterDataPipe __init__ source_datapipe output_var source_datapipe = source_datapipe output_var = output_var __iter__ item source_datapipe yield output_var apply_ops item TODO VitalyFedyunin Extract list DFIterDataPipe registered functions DATAPIPES_OPS = _dataframes_as_tuples groupby _dataframes_filter map to_datapipe shuffle concat batch _dataframes_per_row _dataframes_concat _dataframes_shuffle UNIMPLEMENTED_ATTR = __deepcopy__ __setstate__ is_shardable apply_sharding Capture TODO All operations shared across entire InitialCapture need figure out what we join two captures __init__ schema_df=None ctx = operations variables schema_df schema_df __str__ _ops_str _ops_str res = pyrefly ignore not-iterable op ctx operations len res res += \n res += str op res __getstate__ TODO VitalyFedyunin Currently can t pickle why ctx schema_df = None pyrefly ignore not-iterable var ctx variables var calculated_value = None state = item __dict__ state item = getattr item state __setstate__ state k v state items setattr k v __getattr__ attrname attrname == kwarg attrname == kwargs raise RuntimeError no kwargs attrname == __deepcopy__ raise AttributeError result = CaptureGetAttr attrname ctx=self ctx result __getitem__ key CaptureGetItem key ctx=self ctx __setitem__ key value pyrefly ignore missing-attribute ctx operations append CaptureSetItem key value ctx=self ctx __add__ add_val res = CaptureAdd add_val ctx=self ctx var = CaptureVariable res ctx=self ctx pyrefly ignore missing-attribute ctx operations append CaptureVariableAssign variable=var value=res ctx=self ctx var __sub__ add_val res = CaptureSub add_val ctx=self ctx var = CaptureVariable res ctx=self ctx pyrefly ignore missing-attribute ctx operations append CaptureVariableAssign variable=var value=res ctx=self ctx var __mul__ add_val res = CaptureMul add_val ctx=self ctx var = CaptureVariable res ctx=self ctx t = CaptureVariableAssign variable=var value=res ctx=self ctx pyrefly ignore missing-attribute ctx operations append t var _is_context_empty pyrefly ignore bad-argument-type len ctx operations == len ctx variables == apply_ops_ dataframe TODO VitalyFedyunin Make calculation thread safe currently updates pointer pyrefly ignore unsupported-operation ctx variables calculated_value = dataframe pyrefly ignore not-iterable op ctx operations op execute property columns apply_ops_ ctx schema_df value = execute value columns TODO VitalyFedyunin Add tests TODO VitalyFedyunin Need join context one them empty because we used capture __call__ args kwargs TODO Check args kwargs have more than one different context _is_context_empty TODO Allow CaptureA take context mock arg args isinstance arg Capture arg _is_context_empty ctx = arg ctx break _is_context_empty k v kwargs items isinstance k Capture k _is_context_empty ctx = k ctx break isinstance v Capture v _is_context_empty ctx = v ctx break res = CaptureCall ctx=self ctx args=args kwargs=kwargs var = CaptureVariable None ctx=self ctx t = CaptureVariableAssign ctx=self ctx variable=var value=res pyrefly ignore missing-attribute ctx operations append t var CaptureF Capture __init__ ctx=None kwargs ctx None ctx = operations variables ctx = ctx kwargs = kwargs CaptureA CaptureF __str__ f kwargs name execute value = kwargs real_attribute value CaptureLikeMock __init__ name unittest mock mock TODO VitalyFedyunin Do use private function here copy own implementation instead get_target attribute = mock _get_target name type ignore attr-defined get_target = get_target attribute = attribute name = name __enter__ save = getattr get_target attribute capt = CaptureA name=self name real_attribute=self save setattr get_target attribute capt __exit__ exc_info setattr get_target attribute save CaptureCall Capture __init__ callable ctx=None kwargs ctx None ctx = operations variables ctx = ctx kwargs = kwargs callable = callable __str__ callable args kwargs format callable=self callable kwargs execute TODO VitalyFedyunin execute kwargs maybe nested structures executed_args = arg kwargs args isinstance arg Capture executed_args append arg execute executed_args append arg left = get_val callable left executed_args kwargs kwargs CaptureVariableAssign CaptureF __str__ variable = kwargs variable value = kwargs value f variable = value execute kwargs variable calculated_value = kwargs value execute CaptureVariable Capture TODO VitalyFedyunin This should atomic thread safe names_idx = __init__ value ctx CaptureControl disabled raise RuntimeError Attempting create capture variable capture off ctx = ctx value = value name = f var_ CaptureVariable names_idx CaptureVariable names_idx += ctx variables append __str__ name execute calculated_value apply_ops dataframe TODO VitalyFedyunin Make calculation thread safe currently updates pointer pyrefly ignore unsupported-operation ctx variables calculated_value = dataframe pyrefly ignore not-iterable op ctx operations op execute calculated_value CaptureGetItem Capture __init__ left key ctx ctx = ctx left = left key = key __str__ f left get_val key execute left = left execute left key CaptureSetItem Capture __init__ left key value ctx ctx = ctx left = left key = key value = value __str__ f left get_val key = value execute left = left execute value = value execute left key = value CaptureAdd Capture __init__ left right ctx ctx = ctx left = left right = right __str__ f left + right execute get_val left + get_val right CaptureMul Capture __init__ left right ctx ctx = ctx left = left right = right __str__ f left right execute get_val left get_val right CaptureSub Capture __init__ left right ctx ctx = ctx left = left right = right __str__ f left - right execute get_val left - get_val right CaptureGetAttr Capture __init__ src name ctx ctx = ctx src = src name = name __str__ f src name execute val = get_val src getattr val name get_val capture isinstance capture Capture capture execute isinstance capture str f capture capture CaptureInitial CaptureVariable __init__ schema_df=None pyrefly ignore bad-assignment new_ctx dict str list Any = operations variables schema_df schema_df super __init__ None new_ctx name = f input_ name CaptureDataFrame CaptureInitial pass CaptureDataFrameWithDataPipeOps CaptureDataFrame as_datapipe pyrefly ignore unsupported-operation DataFrameTracedOps ctx variables source_datapipe raw_iterator as_datapipe __iter__ __iter__ iter _dataframes_as_tuples batch batch_size= drop_last bool = False wrapper_class=DataChunkDF dp = _dataframes_per_row _dataframes_concat batch_size dp = dp as_datapipe batch drop_last=drop_last wrapper_class=wrapper_class dp _dp_contains_dataframe = True dp groupby group_key_fn buffer_size= group_size=None guaranteed_group_size=None drop_remaining=False dp = _dataframes_per_row dp = dp as_datapipe groupby group_key_fn buffer_size=buffer_size group_size=group_size guaranteed_group_size=guaranteed_group_size drop_remaining=drop_remaining dp shuffle args kwargs _dataframes_shuffle args kwargs filter args kwargs _dataframes_filter args kwargs collate args kwargs raise RuntimeError Can t collate unbatched DataFrames stream __getattr__ attrname attrname UNIMPLEMENTED_ATTR raise AttributeError Attempting get attrname attrname DATAPIPES_OPS as_datapipe __getattr__ attrname super __getattr__ attrname functional_datapipe trace_as_dataframe DataFrameTracer CaptureDataFrameWithDataPipeOps IterDataPipe type ignore misc source_datapipe Optional Any = None TODO VitalyFedyunin Must implement all special functions datapipes set_shuffle_settings args kwargs pass is_shardable False __init__ source_datapipe schema_df=None source_datapipe = source_datapipe schema_df None schema_df = next iter source_datapipe super __init__ schema_df=schema_df