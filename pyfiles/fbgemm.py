torch _common_operator_config_utils _get_binary_op_configs _get_bn_configs _get_cat_config _get_conv_configs _get_default_op_configs _get_embedding_op_configs _get_fixed_qparams_op_configs _get_linear_configs _get_rnn_op_configs _get_share_qparams_op_configs _get_tensor_info_op_configs backend_config BackendConfig DTypeConfig __all__ = get_fbgemm_backend_config =================== &#124; DTYPE CONFIGS &#124; =================== TODO For now these DTypeConfigs identical ones defined native py In future once we support specifying quant_min quant_max scale_min scale_max these will diverge In particular FBGEMM we will restrict activation quantized values within fbgemm_weighted_op_quint _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch quint weight_dtype=torch qint bias_dtype=torch float fbgemm_default_op_quint _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch quint fbgemm_default_op_fp _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch float bias_dtype=torch float fbgemm_default_dynamic_int _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch float weight_dtype=torch qint bias_dtype=torch float is_dynamic=True fbgemm_default_dynamic_float _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch float bias_dtype=torch float is_dynamic=True fbgemm_weight_only_quint _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch quint fbgemm_weight_only_quint x _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch quint x ===================== &#124; BACKEND CONFIGS &#124; ===================== get_fbgemm_backend_config - BackendConfig Return ` BackendConfig ` PyTorch s native FBGEMM backend conv_dtype_configs = fbgemm_weighted_op_quint _dtype_config linear_dtype_configs = fbgemm_weighted_op_quint _dtype_config fbgemm_default_dynamic_int _dtype_config fbgemm_default_dynamic_float _dtype_config binary_op_dtype_configs = fbgemm_default_op_quint _dtype_config default_op_dtype_configs = fbgemm_default_op_quint _dtype_config fixed_qparams_op_dtype_configs = fbgemm_default_op_quint _dtype_config share_qparams_op_dtype_configs = fbgemm_default_op_quint _dtype_config tensor_info_op_dtype_configs = fbgemm_default_op_quint _dtype_config rnn_op_dtype_configs = fbgemm_default_dynamic_int _dtype_config fbgemm_default_dynamic_float _dtype_config embedding_op_dtype_configs = fbgemm_weight_only_quint _dtype_config fbgemm_weight_only_quint x _dtype_config BackendConfig fbgemm set_backend_pattern_configs _get_conv_configs conv_dtype_configs set_backend_pattern_configs _get_linear_configs linear_dtype_configs set_backend_pattern_configs _get_binary_op_configs binary_op_dtype_configs set_backend_pattern_config _get_cat_config default_op_dtype_configs set_backend_pattern_configs _get_default_op_configs default_op_dtype_configs set_backend_pattern_configs _get_fixed_qparams_op_configs fixed_qparams_op_dtype_configs set_backend_pattern_configs _get_share_qparams_op_configs share_qparams_op_dtype_configs set_backend_pattern_configs _get_tensor_info_op_configs tensor_info_op_dtype_configs set_backend_pattern_configs _get_bn_configs default_op_dtype_configs set_backend_pattern_configs _get_rnn_op_configs rnn_op_dtype_configs set_backend_pattern_configs _get_embedding_op_configs embedding_op_dtype_configs