mypy ignore-errors contextlib functools inspect torch bf _is_not_fp torch backends mkldnn is_available False torch ops mkldnn _is_mkldnn_bf _supported False True tf _is_not_fp torch backends mkldnn is_available False torch _C _cpu _is_amx_fp _supported False True contextlib contextmanager reduced_f _off old_matmul_precision = torch backends mkldnn matmul fp _precision old_conv_precision = torch backends mkldnn conv fp _precision try torch backends mkldnn matmul fp _precision = ieee torch backends mkldnn conv fp _precision = ieee yield finally torch backends mkldnn matmul fp _precision = old_matmul_precision torch backends mkldnn conv fp _precision = old_conv_precision contextlib contextmanager bf _on bf _precision= e- old_matmul_precision = torch backends mkldnn matmul fp _precision old_conv_precision = torch backends mkldnn conv fp _precision old_precision = precision try torch backends mkldnn matmul fp _precision = bf torch backends mkldnn conv fp _precision = bf precision = bf _precision yield finally torch backends mkldnn matmul fp _precision = old_matmul_precision torch backends mkldnn conv fp _precision = old_conv_precision precision = old_precision contextlib contextmanager tf _on tf _precision= e- old_matmul_precision = torch backends mkldnn matmul fp _precision old_conv_precision = torch backends mkldnn conv fp _precision old_precision = precision try torch backends mkldnn matmul fp _precision = tf torch backends mkldnn conv fp _precision = tf precision = tf _precision yield finally torch backends mkldnn matmul fp _precision = old_matmul_precision torch backends mkldnn conv fp _precision = old_conv_precision precision = old_precision This wrapper wraps test run test three times one reduced_f OFF others reduced_f ON including bf ON tf ON When running reduced_f ON will use reduced precision bf tf specified argument reduced_f _on_and_off bf _precision= e- tf _precision= e- with_reduced_f _disabled function_call reduced_f _off function_call with_bf _enabled function_call bf _on bf _precision function_call with_tf _enabled function_call tf _on tf _precision function_call wrapper f params = inspect signature f parameters arg_names = tuple params keys functools wraps f wrapped args kwargs kwargs update zip arg_names args strict=False cond = True device kwargs cond = cond torch device kwargs device type == cpu dtype kwargs cond = cond kwargs dtype == torch float bf _cond = cond bf _is_not_fp tf _cond = cond tf _is_not_fp bf _cond tf _cond with_reduced_f _disabled kwargs lambda f kwargs bf _cond with_bf _enabled kwargs lambda f kwargs tf _cond with_tf _enabled kwargs lambda f kwargs f kwargs wrapped wrapper