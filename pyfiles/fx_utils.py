mypy allow-untyped-defs contextlib operator collections defaultdict typing Any Callable Optional sympy torch torch fx torch _dispatch python enable_python_dispatcher torch _subclasses fake_tensor FakeTensorMode torch fx experimental symbolic_shapes compute_unbacked_bindings rebind_unbacked statically_known_true sym_eq torch utils _pytree pytree torch utils _ordered_set OrderedSet torch utils _pytree tree_map torch utils flop_counter flop_registry virtualized V Check pattern nn module F function torch Tensor method matched Works length patterns module function method matches_module_function_pattern pattern tuple type torch nn modules Module Callable Any node torch fx node Node modules dict str torch nn modules Module - bool len node args == False isinstance node args torch fx Node isinstance node torch fx Node False first node call_module node args op = call_module False isinstance node args target str False node args target modules False type modules node args target pattern False second node call_function call_method node op = call_function node op = call_method False node target = pattern False make sure node args output only used current node len node args users False True FakeTensorUpdater The main idea here s difficult maintain accurate fake tensors our primary form metadata each node our graph we transform The most reliable way obtain information rerunning faketensor propagation However general faketensor propagation fairly expensive So instead we d like only rerun faketensor propagation nodes have changed In order detect which nodes have changed we first hash its node target argument lists which immutable FX Then whenever we call incremental_update we check which FX nodes have new hash recompute faketensor metadata node Then we continue recursively compute faketensors all users until fake tensors stop changing __init__ graph torch fx Graph - None processed_hashes = OrderedSet Any graph = graph node graph nodes processed_hashes add hash_node node hash_node node torch fx Node todo chilli Not great hash function node node target id node args id node kwargs incremental_update Update FakeTensors graph We will try do minimum amount work existing_storages defaultdict Optional int int = defaultdict int node graph nodes existing_storages get_node_storage node += is_intlist_same new old statically_known_true sym_eq new old is_fake_tensor_same new old node type new type old False isinstance new list tuple len new = len old False all is_fake_tensor_same new_i old_i node=node new_i old_i zip new old new None old None isinstance new torch Tensor assert isinstance new torch SymInt torch SymBool torch SymFloat f Unknown type type new graph new node shape_env _maybe_evaluate_static sympy Eq new node expr old node expr == sympy true is_intlist_same new shape old shape new layout = old layout False new layout == torch strided is_intlist_same new stride old stride statically_known_true new storage_offset == old storage_offset False new device = old device False get_storage new == get_storage old True any_user_may_alias node isinstance node meta val torch Tensor analysis too complicated lists can support future True user node users isinstance user target torch _ops OpOverload torch _ops HigherOrderOperator user target torch _inductor fx_passes reinplace _generalized_scatter True isinstance user target torch _ops HigherOrderOperator HOPs survive until inductor all non-aliasing HOPs We will likely never support HOPs aliasing continue Strategy do FakeTensor prop see storage aliases If Inductor ever gets tighter invariants OpOverloads we ban things like torch ops aten reshape calls graph Then could just fast schema lookup is_valid args kwargs = get_fake_args_kwargs user is_valid True V fake_mode enable_python_dispatcher contextlib ExitStack stack Ignore unbacked symbols they exist we re making FakeTensor then throwing away shape_env = V fake_mode shape_env shape_env None stack enter_context shape_env ignore_fresh_unbacked_symbols new_fake_tensor = user target args kwargs isinstance new_fake_tensor torch Tensor analysis too complicated lists can support future True get_storage new_fake_tensor == get_storage node meta val True False This case where returns completely fresh storage s used nowhere If FakeTensor s storage fresh none node s users can alias then we don t need update node existing_storages get_storage old == get_storage new existing_storages any_user_may_alias node True False should_process_node node node target nodes returning true function called under fake mode does work inductor lowerings We check node target aten operator operator getitem which used when returning multiple tensors op node op == call_function isinstance node target torch _ops OpOverload node target operator getitem node target torch _inductor fx_passes reinplace _generalized_scatter to_process = OrderedSet int node graph nodes NB Be very careful about skipping nodes via continues here ask careful review when changing code The consequence incorrect FakeTensor metadata difficult-to-debug silent incorrectness hash_node node processed_hashes id node to_process continue should_process_node node continue is_valid args kwargs = get_fake_args_kwargs node is_valid continue V fake_mode enable_python_dispatcher new_fake_tensor = node target args kwargs val node meta is_fake_tensor_same new_fake_tensor node meta val node=node continue rebind_unbacked V fake_mode shape_env node new_fake_tensor node meta val = new_fake_tensor shape_env = V fake_mode shape_env symbol_to_path = compute_unbacked_bindings shape_env new_fake_tensor Refresh bindings new symbols node meta unbacked_bindings = symbol_to_path existing_storages get_node_storage node += to_process update id user user node users processed_hashes add hash_node node get_storage t torch Tensor - int t untyped_storage _cdata get_node_storage node torch fx Node - Optional int val node meta None isinstance node meta val torch Tensor None torch _C _has_storage node meta val None get_storage node meta val get_fake x isinstance x torch fx Node val x meta x x meta val x get_fake_args_kwargs x torch fx Node - tuple bool tuple Any dict str Any First value returns boolean any input nodes don t have faketensor args kwargs = tree_map get_fake x args x kwargs any isinstance torch fx Node pytree arg_tree_leaves args kwargs False args kwargs True args kwargs is_node_realized node torch fx Node - bool Returns true node always realized when lowered inductor IR NOTE This may some false negatives e g doesn t handle buffers realized heuristically during lowering buffers realized indirectly through view ops torch _inductor lowering fallbacks needs_realized_inputs is_buffer node torch fx Node - bool node op == call_function node target operator getitem For nodes multiple outputs we get fx graph foo = torch ops aten foo getitem = foo getitem_ = foo where we need check foo fallback kernel is_buffer node args type ignore arg-type node op placeholder output node target fallbacks is_buffer node True realizes_inputs node torch fx Node - bool node op == output node target needs_realized_inputs any realizes_inputs user user node users True Otherwise assume node isn t realized False count_flops_fx node torch fx Node - Optional int countable_fx node isinstance node target str None FakeTensorMode allow_non_fake_inputs=True success args kwargs = get_fake_args_kwargs node success torch utils flop_counter FlopCounterMode display=False flop_counter_mode node target args kwargs counted_flops = flop_counter_mode get_total_flops counted_flops None countable_fx node torch fx Node - bool Whether we can count flops FX node assert isinstance node torch fx Node hasattr node target False target = node target hasattr target overloadpacket target flop_registry packet = target overloadpacket packet flop_registry