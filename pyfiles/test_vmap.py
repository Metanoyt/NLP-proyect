Owner s module functorch Copyright c Facebook Inc its affiliates All rights reserved This source code licensed under BSD-style license found LICENSE file root directory source tree contextlib functools itertools os random types unittest warnings collections namedtuple OrderedDict unittest case skipIf common_utils check_vmap_fallback compute_quantities_for_vmap_test decorate DisableVmapFallback generate_vmap_inputs get_fallback_and_vmap_exhaustive is_batch_norm_training is_valid_inplace_sample_input opsToleranceOverride skip skipOps tol xfail xfailIf functorch_additional_op_db additional_op_db functorch torch torch nn functional F functorch grad grad_and_value jacfwd jvp vjp vmap functorch experimental chunk_vmap torch Tensor torch _C _functorch reshape_dim_into reshape_dim_outof torch _functorch make_functional functional_init_with_buffers torch _functorch vmap restore_vmap torch nn attention sdpa_kernel SDPBackend torch testing _internal autograd_function_db autograd_function_db torch testing _internal common_cuda PLATFORM_SUPPORTS_CUDNN_ATTENTION PLATFORM_SUPPORTS_FLASH_ATTENTION PLATFORM_SUPPORTS_MEM_EFF_ATTENTION tf _on_and_off with_tf _off torch testing _internal common_device_type instantiate_device_type_tests onlyCUDA OpDTypes ops tol toleranceOverride torch testing _internal common_methods_invocations op_db torch testing _internal common_utils instantiate_parametrized_tests IS_WINDOWS markDynamoStrictTest parametrize run_tests skipIfTorchDynamo subtest TEST_WITH_TORCHDYNAMO TestCase unMarkDynamoStrictTest xfailIfTorchDynamo torch testing _internal custom_op_db custom_op_db torch utils _pytree pytree get_platform_specific_sdpa ret = SDPBackend MATH PLATFORM_SUPPORTS_FLASH_ATTENTION ret append SDPBackend FLASH_ATTENTION PLATFORM_SUPPORTS_MEM_EFF_ATTENTION ret append SDPBackend EFFICIENT_ATTENTION PLATFORM_SUPPORTS_CUDNN_ATTENTION ret append SDPBackend CUDNN_ATTENTION ret PLATFORM_SPECIFIC_SDPA = get_platform_specific_sdpa FALLBACK_REGEX = There performance drop EnableVmapFallbackWarnings __enter__ prev_state = torch _C _debug_only_are_vmap_fallback_warnings_enabled torch _C _debug_only_display_vmap_fallback_warnings True __exit__ ignored torch _C _debug_only_display_vmap_fallback_warnings prev_state markDynamoStrictTest TestVmapAPI TestCase test_non_tensor_output_raises assertRaisesRegex ValueError got type float vmap lambda x torch ones multiple_outputs x x assertRaisesRegex ValueError got type int vmap multiple_outputs torch ones test_different_map_dim_size_raises x = torch randn y = torch randn expected_msg = Expected all tensors have same size mapped dimension assertRaisesRegex ValueError expected_msg vmap torch mul x y assertRaisesRegex ValueError expected_msg vmap lambda z z + z in_dims= x y assertRaisesRegex ValueError expected_msg vmap lambda z z x + z y in_dims= x y x x y y test_func_with_no_inputs expected_msg = got no inputs foo torch randn bar x torch randn assertRaisesRegex ValueError expected_msg vmap foo assertRaisesRegex ValueError expected_msg vmap bar test_func_with_no_tensors foo x torch randn assertRaisesRegex ValueError least one Tensor vmap foo None test_constant_function output = vmap lambda x torch tensor torch ones assertEqual output torch tensor test_single_input x = torch randn square x x x output = vmap square x assertEqual output x x test_multiple_inputs x = torch randn y = torch randn output = vmap torch mul x y assertEqual output x y test_multiple_outputs foo x x x x x x x = torch randn outputs = vmap foo x assertEqual outputs x x assertEqual outputs x x x test_multiple_outputs This same thing returns_tuple_of_tensors x x x returns_tuple_of_tensors x x x returns_list_of_two_tensors x x x returns_list_of_one_tensor x x x = torch randn should throw vmap returns_tuple_of_tensors x vmap returns_list_of_two_tensors x vmap returns_list_of_one_tensor x test_nested_with_same_map_dim x = torch randn y = torch randn output = vmap vmap torch mul x y assertEqual output x y output = vmap vmap vmap torch mul x y assertEqual output x y test_nested_with_diag_embed diag_embed requires special testing because registered conditional functionalization x = torch randn output = vmap vmap torch diag_embed x assertEqual output torch diag_embed x test_nested_with_different_map_dim x = torch randn y = torch randn output = vmap lambda x vmap lambda y x y y x assertEqual output shape assertEqual output x view y z = torch randn output = vmap lambda x vmap lambda y vmap lambda z x y z z y x assertEqual output shape assertEqual output x view y view z test_noop_in_inner_vmap x = torch randn y = torch randn output = vmap lambda x vmap lambda y x y x assertEqual output x view expand test_checkpoint A = torch randn dtype=torch float requires_grad=True get_grad checkpoint A grad = None get_loss A ortho_A _ = torch func vmap torch linalg qr A torch sum ortho_A checkpoint loss = torch utils checkpoint checkpoint get_loss A use_reentrant=False loss = get_loss A loss backward A grad expected = get_grad checkpoint=False result = get_grad checkpoint=True assertEqual result expected test_unsupported_op_err_msg Unsupported view op tensor = torch randn msg = r Batching rule implemented aten + r fallback path doesn t work out= view ops TODO find view op assertRaisesRegex RuntimeError msg vmap torch ravel tensor out_op x y torch abs x out=y assertRaisesRegex RuntimeError msg vmap out_op tensor tensor Don t support non-tensor returns This limitation vmap functions don t tensors must special cased assertRaisesRegex RuntimeError Batching rule implemented vmap torch equal tensor tensor test_nonzero_out_dims Basic test tensor = torch randn result = vmap lambda x x out_dims= tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr Test batch dimension gets permuted dim tensor = torch randn result = vmap lambda x x out_dims= tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr negative out_dim tensor = torch randn result = vmap lambda x x out_dims=- tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr check out_dims works ALL outputs tensor = torch randn other = torch randn result = vmap lambda x y x y out_dims= tensor other assertEqual result tensor permute other permute use out_dims maximum vmap-able tensor dims dims ndims = shape = + ndims - expected_shape = + ndims - tensor = torch randn shape result = vmap lambda x x out_dims= tensor assertEqual result shape expected_shape test something identity function foo x y x x y x y y x = torch randn y = torch randn result = vmap foo out_dims= x y assertEqual result x permute x y permute x y y permute test_multiple_out_dims foo x x x bar x y x x x x y x = torch randn y = torch randn result = vmap foo out_dims= x assertEqual result x x permute result = vmap bar out_dims= - x y expected = x permute x x permute x y permute assertEqual result expected test_nested_out_dims y = torch randn Inner vmap has non-zero out_dim result = vmap lambda y vmap lambda x x out_dims= y y assertEqual result shape assertEqual result y permute all vmaps have non-zero out_dim result = vmap lambda y vmap lambda x x out_dims= y out_dims= y assertEqual result shape assertEqual result y permute throwing some negative out_dims result = vmap lambda y vmap lambda x x out_dims=- y out_dims=- y assertEqual result shape assertEqual result y permute testing fn isn t identity x = torch randn y = torch randn result = vmap lambda y vmap lambda x x y out_dims= x out_dims=- y assertEqual result shape assertEqual result y view x permute test_out_dims_edge_case foo x x Test we accept out_dims= function one output tensor = torch randn expected = vmap foo out_dims= tensor result = vmap foo out_dims= tensor assertEqual result expected test_out_dims_none_tuple foo x x hello world tensor = torch randn result = vmap foo out_dims= None tensor assertEqual result hello world assertEqual result tensor foo x x add_ None hello world result = vmap foo out_dims= None None tensor assertEqual result None hello world test_out_dims_none foo x x tensor = torch randn assertRaisesRegex ValueError can BatchedTensor when out_dim None vmap foo out_dims=None tensor foo x x add_ hello world result = vmap foo out_dims=None tensor assertEqual result hello world test_out_dims_normal_tensor foo x torch arange tensor = torch randn result = vmap foo tensor assertEqual result shape result = vmap foo out_dims=None tensor assertEqual result torch arange test_pytree_returns x = torch randn f x y = x sin y y y y y y y y y y y y = vmap f x assertEqual y x sin assertEqual y y assertEqual y y assertEqual y y assertEqual y y assertEqual y y test_pytree_odict_returns x = torch randn f t y = t sin OrderedDict sin y cos t cos out = vmap f x assert isinstance out OrderedDict expected = f x assertEqual out sin expected sin assertEqual out cos expected cos test_pytree_returns_outdims x = torch randn f x y = x sin y y y y y y = vmap f out_dims= x assertEqual y x sin assertEqual y x sin assertEqual y x sin t test_pytree_returns_broadcast_simple x = torch randn f x y = x sin y y y y y y = vmap f out_dims= x assertEqual y x sin t assertEqual y y assertEqual y y test_pytree_returns_broadcast_nested x = torch randn f x y = x sin y y y y y y = vmap f out_dims= x assertEqual y x sin assertEqual y y t assertEqual y y t test_out_dims_must_be_int_or_collection_of_int_err_msg msg = must int None python collection ints tensor = torch randn assertRaisesRegex ValueError msg vmap lambda x x out_dims= lol tensor assertRaisesRegex ValueError msg vmap lambda x x out_dims= lol tensor test_out_dims_and_num_outputs_mismatch_err_msg msg = compatible x = torch randn Too many out_dims assertRaisesRegex ValueError msg vmap lambda x x out_dims= x assertRaisesRegex ValueError msg vmap lambda x x x x out_dims= x Too few out_dims assertRaisesRegex ValueError msg vmap lambda x x x out_dims= x assertRaisesRegex ValueError msg vmap lambda x x x x out_dims= x test_out_dim_out_of_bounds_err_msg TODO rzou This error message isn t great It comes straight maybe_wrap_dim Consider doing try-catch- add some context error message future C++ msg = Dimension out range x = torch randn assertRaisesRegex IndexError msg vmap lambda x x out_dims= x assertRaisesRegex IndexError msg vmap lambda x x out_dims=- x test_non_zero_in_dims tensor = torch randn Implicit out_dims = vmap will move batch dim front output = vmap lambda x x tensor assertEqual output tensor permute assertEqual output data_ptr tensor data_ptr x = torch randn y = torch randn output = vmap torch mul x y assertEqual output x y t output = vmap torch mul x y assertEqual output x t y test_none_in_dims x = torch randn y = torch randn None in_dim Tensor means we don t map over output = vmap torch mul None x y assertEqual output shape assertEqual output x view y None in_dim non-tensor arguments output = vmap torch mul None x assertEqual output x test_nested_non_default_in_dims x = torch rand y = torch rand result = vmap vmap vmap torch mul x y assertEqual result x permute y permute test_nested_negative_in_dims x = torch randn y = torch randn output = vmap torch mul - - x y assertEqual output shape assertEqual output x y permute test_non_default_in_dims_out_dims x = torch randn Same in_dim out_dim vmap over identity result = vmap lambda x x in_dims= out_dims= x assertEqual result x assertEqual result data_ptr x data_ptr Different in_dim out_dim vmap over identity result = vmap lambda x x in_dims= out_dims= x assertEqual result shape assertEqual result x transpose assertEqual result data_ptr x data_ptr foo x x Same in_dim out_dim vmap over operation result = vmap foo in_dims= out_dims= x assertEqual result x Different in_dim out_dim vmap over operation result = vmap foo in_dims= out_dims= x assertEqual result shape assertEqual result x transpose Basic nested test result = vmap vmap foo x assertEqual result x test_item_throws f x x item assertRaisesRegex RuntimeError r item\ \ Tensor vmap f torch randn test_data_dependent_control_flow_throws f x x x assertRaisesRegex RuntimeError r data-dependent control flow vmap f torch randn test_accepts_nested_inputs x = torch randn y = torch randn Single layer nesting out = vmap lambda z z + z x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z x + z y x x y y assertEqual out x + y out = vmap lambda z z x + z y in_dims= x x y y assertEqual out x + y out = vmap lambda z z x + z y in_dims= x y x x y y assertEqual out x + y Multiple layers nesting out_fn = vmap lambda z z x + z x + z y + z y out = out_fn x x x y y y assertEqual out x + x + y + y test_in_dims_wrong_type_err_msg x = torch randn y = torch randn msg = r expected ` in_dims ` int \ potentially nested\ tuple assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap torch mul set x y assertRaisesRegex ValueError msg vmap torch mul lol x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y The following should throw vmap torch mul x y test_not_enough_in_dims_err_msg x = torch randn y = torch randn msg = r in_dims compatible structure ` inputs ` assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y The following should throw vmap torch mul x y test_integer_in_dim_but_not_tensor_input_err_msg noqa F foo xy xy xy bar x yz x yz yz x = torch randn following errors jax will always errors msg = Got in_dim= input input type assertRaisesRegex ValueError msg vmap torch sum x assertRaisesRegex ValueError msg vmap torch sum x assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x The following should throw vmap torch sum None x test_in_dim_not_in_tensor_err_msg foo x x x x = torch randn y = torch randn msg = r Got in_dim=- \w some input input Tensor dimensionality \w assertRaisesRegex ValueError msg vmap foo torch randn assertRaisesRegex ValueError msg vmap foo in_dims= torch randn assertRaisesRegex ValueError msg vmap foo in_dims= - x assertRaisesRegex ValueError msg vmap foo in_dims= y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y following should throw vmap foo in_dims= torch randn vmap foo in_dims= torch randn test_fallback_does_not_warn_by_default op = torch _test_functorch_fallback x = torch randn y = torch randn warnings catch_warnings record=True wa torch vmap op x y The single warning here vmap experimental warning warning vmap fallback path assertEqual len wa skipIfTorchDynamo Flaky test unittest expectedFailure test_fallback_warns_when_warnings_are_enabled NB One day we will implement batching rule torch atan If when we do test should replaced test fallback path another operator avoid bitrot op = torch _test_functorch_fallback x = torch randn y = torch randn warnings catch_warnings record=True wa EnableVmapFallbackWarnings torch vmap op x y assertEqual len wa assertRegex str wa - message FALLBACK_REGEX _assert_uses_vmap_fallback vmap_args inputs warnings catch_warnings record=True wa EnableVmapFallbackWarnings result = vmap vmap_args inputs assertEqual len wa assertRegex str wa - message FALLBACK_REGEX test_fallback_zero_dim op = torch _test_functorch_fallback x = torch randn y = torch randn _assert_uses_vmap_fallback op x y B B = x = torch randn B y = torch randn msg = The fallback path does support vmap over dims size assertRaisesRegex RuntimeError msg vmap op None x y assertRaisesRegex RuntimeError msg vmap op None y x assertRaisesRegex RuntimeError msg vmap op x x x = torch randn B B y = torch randn B assertRaisesRegex RuntimeError msg vmap op None x y assertRaisesRegex RuntimeError msg vmap op None y x assertRaisesRegex RuntimeError msg vmap op x x test_fallback_warning We use dummy function _test_functorch_fallback defined prim_native_functions cpp op = torch _test_functorch_fallback x = torch randn y = torch randn _assert_uses_vmap_fallback op x y x = torch randn y = torch randn result = vmap op x y assertEqual result op x permute y nested vmap x = torch randn y = torch randn result = vmap vmap op x y assertEqual result op x permute y big batch size total x = torch randn y = torch randn result = vmap vmap vmap op x y assertEqual result op x y view TODO No clue what wrong here unittest skip test_fallback_masked_fill NB One day we will implement batching rule masked_fill If when we do test should replaced test fallback path another operator avoid bitrot run_test batch_size B = batch_size x = torch randn B dim = index = torch tensor values = torch randn B _assert_uses_vmap_fallback torch index_add None None x dim index values result = vmap torch index_add None None x dim index values expected = torch index_add x dim + index values view B assertEqual result expected run_test batch_size= run_test batch_size= test_fallback_multiple_returns NB One day we will implement batching rule torch var_mean If when we do test should replaced test fallback path another operator avoid bitrot B B B = tensor = torch randn B _assert_uses_vmap_fallback torch var_mean tensor fallback correctness torch var_mean result = vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected nested vmap tensor = torch randn B B result = vmap vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected big batch size nested vmap tensor = torch randn B B B result = vmap vmap vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected test_inplace_fallback_unary Test in-place fallback in-place method takes no additional Tensor arguments This simplest case fallback NB One day we will implement batching rule acos_ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor acos_ B B B = x = torch randn B _assert_uses_vmap_fallback op x Single vmap x_orig = torch rand B x = x_orig clone result = vmap op x assertTrue result x assertEqual result x_orig acos Single vmap + different out_dim produces view x_orig = torch rand B x = x_orig clone result = vmap op out_dims= x assertTrue result _base x assertEqual result x_orig t acos Nested vmap x_orig = torch randn B B x = x_orig clone result = vmap vmap op x assertTrue result x assertEqual result x_orig acos Nested vmap large batch size x_orig = torch randn B B B x = x_orig clone result = vmap vmap vmap op x assertTrue result x assertEqual result x_orig acos test_inplace_fallback_nary_same_levels NB One day we will implement batching rule atan _ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor atan _ outplace_op = torch atan x = torch randn y = torch randn _assert_uses_vmap_fallback op x y Single vmap B = x_orig = torch randn B x = x_orig clone y = torch randn B vmap op x y assertEqual x outplace_op x_orig y movedim Nested vmap B B = x_orig = torch randn B B x = x_orig clone y = torch randn B B vmap vmap op x y assertEqual x outplace_op x_orig y movedim big batch size total B B B = x_orig = torch randn B B B x = x_orig clone y = torch randn B B B vmap vmap vmap op x y assertEqual x outplace_op x_orig y view B B B Fallback isInplaceVmapCompatible check broken unittest expectedFailure test_inplace_fallback_nary_different_levels NB One day we will implement batching rule atan _ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor atan _ outplace_op = torch atan B B = x = torch rand B y = torch rand _assert_uses_vmap_fallback op None x y op left right All levels right found left x_orig = torch rand B x = x_orig clone y = torch rand vmap op in_dims= None x y assertEqual x outplace_op x_orig y x_orig = torch rand B B x = x_orig clone y = torch rand B vmap vmap op in_dims= None x y assertEqual x outplace_op x_orig y view B op left right Some levels right found left msg = r vmap aten atan _\ \ extra_args\ possible x = torch rand y = torch rand B assertRaisesRegex RuntimeError msg vmap op in_dims= None x y x = torch rand B y = torch rand B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None in_dims= None x y x = torch rand B y = torch rand B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None in_dims= None x y x = torch rand B y = torch rand B B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None x y test_backward_unsupported_interaction x = torch randn requires_grad=True y = torch randn grad = torch randn_like x err_msg = r backward\ \ called inside functorch transform backward_on_vmapped_tensor x x sum backward FIXME skipTest error element tensors does require grad does have grad_fn assertRaisesRegex RuntimeError err_msg vmap backward_on_vmapped_tensor x backward_with_vmapped_grad x grad x backward grad assertRaisesRegex RuntimeError err_msg vmap backward_with_vmapped_grad x grad completely_unrelated_backward y x sum backward y assertRaisesRegex RuntimeError err_msg vmap completely_unrelated_backward y unittest expectedFailure test_grad_unsupported_interaction input_tensor = torch randn requires_grad=True err_msg = autograd grad called inside torch vmap captured = torch randn requires_grad=True output_to_grad_is_vmapped input_tensor output = captured input_tensor sum torch autograd grad output captured assertRaisesRegex RuntimeError err_msg vmap output_to_grad_is_vmapped input_tensor output = input_tensor sum input_to_grad_is_vmapped input_tensor torch autograd grad output input_tensor assertRaisesRegex RuntimeError err_msg vmap input_to_grad_is_vmapped input_tensor test_batched_gradient_basic N = x = torch randn N requires_grad=True y = torch randn N vjp_mul v torch autograd grad x y x grad_outputs= v batched_v = torch eye N jacobian = vmap vjp_mul batched_v assertEqual jacobian torch diagflat y test_functools_partial x = torch randn y = torch randn result = vmap functools partial torch mul x y assertEqual result x y test_nn_module tensor = torch randn model = torch nn Linear bias=False result = vmap model tensor assertEqual result model tensor test_fallback_with_undefined_grad B = x = torch randn requires_grad=True weight = torch randn v = torch randn B get_vjp v result = torch nn functional conv d x weight grad_x = torch autograd grad result x v grad_x Runs vmap get_vjp v which should error out The backward formula convolution returns undefined Tensor grad_bias because original bias does exist In future we ll probably add batching rule convolution backward When happens we should modify test use different op create use dummy operator avoid bitrot _assert_uses_vmap_fallback get_vjp v test_reshape_dim_into x = torch randn y = reshape_dim_into x assertEqual y x reshape y = reshape_dim_into x assertEqual y x movedim reshape y = reshape_dim_into x assertEqual y x movedim reshape y = reshape_dim_into x assertEqual y x movedim reshape y = reshape_dim_into - x assertEqual y x movedim reshape y = reshape_dim_into - x assertEqual y x movedim reshape y = reshape_dim_into - - x assertEqual y x movedim reshape test_reshape_dim_outof x = torch randn permute y = reshape_dim_outof x assertEqual y x reshape y = reshape_dim_outof x assertEqual y x reshape y = reshape_dim_outof x assertEqual y x reshape y = reshape_dim_outof - x assertEqual y x reshape Case ` ` sized dim x = torch randn y = reshape_dim_outof - x assertEqual y shape torch Size test_batch_rule_does_not_need_to_handle_no_batched_input f x y res = torch dot y torch ones x + res x = torch randn y = torch randn out = vmap vmap f in_dims= None in_dims= None x y expected = torch mv y torch ones view + x assertEqual out expected test_decomposition_under_python_dispatcher This test will raise error vmap fallback gets invoked Here we test decomps registered FuncTorchBatchedDecomposition respected Python Dispatcher t = torch ones DisableVmapFallback torch _dispatch python enable_python_dispatcher o = torch vmap torch square t assertEqual o torch square t _test_vmap_autocast device torch device device type == cpu amp_dtype = torch bfloat amp_dtype = torch float a_float = torch rand device=device b_float = torch rand device=device c_float = torch rand device=device d_float = torch rand device=device Case autocast inside vmapped function func x y z w torch autocast dtype=amp_dtype device_type=device e_float = torch matmul x y assert e_float dtype == amp_dtype e_float dtype f_float = torch matmul z e_float assert f_float dtype == amp_dtype f_float dtype torch matmul w f_float float expected = func a_float b_float c_float d_float out = vmap func a_float b_float c_float d_float assert expected allclose out Case autocast decorator inside vmapped function torch autocast dtype=amp_dtype device_type=device func x y z w e_float = torch matmul x y assert e_float dtype == amp_dtype e_float dtype f_float = torch matmul z e_float assert f_float dtype == amp_dtype f_float dtype torch matmul w f_float expected = func a_float b_float c_float d_float out = vmap func a_float b_float c_float d_float assert expected allclose out Case autocast outside vmapped function func x y z w e_float = torch matmul x y assert e_float dtype == amp_dtype e_float dtype f_float = torch matmul z e_float assert f_float dtype == amp_dtype f_float dtype torch matmul w f_float torch autocast dtype=amp_dtype device_type=device expected = func a_float b_float c_float d_float out = vmap func a_float b_float c_float d_float assert expected allclose out unittest skip Somehow vmap autocast do work CPU test_vmap_autocast_cpu _test_vmap_autocast cpu skipIf torch cuda is_available CUDA unavailable test_vmap_autocast_cuda _test_vmap_autocast cuda test_restore_vmap_pytree_input_output f x y output = x + x output = y output b output B = x = torch randn B x = torch randn B y = torch randn B out out_dims = restore_vmap f B error x x y expected = vmap f in_dims= out_dims= b x x y assertEqual out expected assertEqual out_dims b test_restore_vmap_no_vmapped_inputs f x y z x y z z B = Mix tensor non-tensor inputs x = torch randn y = torch randn z = out out_dims = restore_vmap f None None None B error x y z assertEqual out f x y z assertEqual out_dims None None None test_restore_vmap_unexpanded_outputs f x y Mix tensor non-tensor outputs y y sum None B = x = torch randn B y = torch randn out out_dims = restore_vmap f None B error x y assertEqual out f None y assertEqual out_dims None None None test_data_attribute foo x y = x data noqa F x assertRaisesRegex RuntimeError accessing ` data ` under vmap transform torch func vmap foo torch randn foo x x data = torch ones x assertRaisesRegex RuntimeError mutating directly ` data ` under vmap torch func vmap foo torch randn slice_inputs inputs bdims i result = inp bdim zip inputs bdims bdim None result append inp result append inp select bdim i tuple result reference_vmap op inputs in_dims= out_dims= return_nt=False isinstance in_dims int in_dims = in_dims len inputs bdim_sizes = inp size dim inp dim zip inputs in_dims dim None assert all bdim_size == bdim_sizes bdim_size bdim_sizes bdim_size = bdim_sizes results = tuple op slice_inputs inputs in_dims i i range bdim_size assert len results op_has_single_return = isinstance results tuple op_has_single_return assert all isinstance result torch Tensor result results isinstance out_dims int out_dims = out_dims return_nt torch nested nested_tensor list results torch stack results dim=out_dims assert all isinstance result tuple result results num_returns = len results assert all len result == num_returns result results isinstance out_dims int out_dims = out_dims num_returns return_nt tuple torch nested nested_tensor list result_shards result_shards zip results tuple torch stack result_shards out_dim result_shards out_dim zip zip results out_dims TensorFactory staticmethod rand size device= cpu dtype=torch float torch rand size device=device dtype=dtype staticmethod randn size device= cpu dtype=torch float torch randn size device=device dtype=dtype staticmethod randp size device= cpu dtype=torch float torch rand size device=device dtype=dtype + Tests vmap op in_dims out_dims inputs comparing output slow sequential map+stack fallback check_view Test first returned output view first input check_propagates_grad Test operation propagates gradients _vmap_test op inputs in_dims= out_dims= check_view=False check_propagates_grad=True result = vmap op in_dims out_dims inputs are_nested = t is_nested t pytree tree_leaves result reference_result = reference_vmap op inputs in_dims out_dims return_nt=any are_nested assertEqual result reference_result op_has_single_return = isinstance result tuple check_view result_as_tuple = result op_has_single_return result output result_as_tuple input _base = inputs inputs _base None inputs _base assertTrue output _base input _base msg= result view first input check_propagates_grad Assuming input floating-point tensor Check vmap operation propagates requires_grad flag zeroth output Some vmap operators implemented way assumes they composite respect autograd If operator ever changed composite respect autograd then following check should fail inputs_clone = list inputs inputs_clone = inputs clone requires_grad_ result = vmap op in_dims out_dims inputs_clone result_as_tuple = result op_has_single_return result assertTrue result requires_grad should_allow_vmap_fallback_usage fn getattr fn _allow_vmap_fallback_usage False allowVmapFallbackUsage fn fn _allow_vmap_fallback_usage = True fn All tests TestVmapBase check slow vmap fallback never invoked This so we can incrementally add batching rules operators replace slow vmap fallback path said operators To skip check please use allowVmapFallbackUsage decorator NB Don t add tests TestVmapBase directly unless you want them run every subclass TestVmapBase Add them e g TestVmapOperators NB TestVmapBase nested This prevents test runners picking up running Namespace TestVmapBase TestCase __init__ method_name= runTest super __init__ method_name test_method = getattr method_name None test_method None should_allow_vmap_fallback_usage test_method setattr method_name _wrap_method_with_vmap_fallback_check test_method _wrap_method_with_vmap_fallback_check method msg = Expected test invoke vmap fallback path i e all operators being tested test should have batching rules implemented If you intentionally testing something do fallback path use allowVmapFallbackUsage Otherwise please make sure batching rules implemented operator s being tested functools wraps method wrapper args kwargs warnings catch_warnings record=True warnings simplefilter always EnableVmapFallbackWarnings method args kwargs captured_warning wa assertNotRegex str captured_warning message FALLBACK_REGEX msg types MethodType wrapper allowVmapFallbackUsage test_vmap_fallback_check_ok One day we ll implement batching rule torch var_mean When happens please change example use operator doesn t have batching rule implemented op_using_fallback = torch var_mean vmap op_using_fallback torch rand unittest expectedFailure test_vmap_fallback_check _wrap_method_with_vmap_fallback_check no_fallback pass One day we ll implement batching rule torch var_mean When happens please change example use operator doesn t have batching rule implemented op_using_fallback = torch var_mean _wrap_method_with_vmap_fallback_check uses_fallback vmap op_using_fallback torch rand no_fallback assertRaises AssertionError uses_fallback _make_case op input_getter=TensorFactory randn op input_getter markDynamoStrictTest TestVmapOperators Namespace TestVmapBase _vmap_test args kwargs _vmap_test args kwargs _vmap_view_test args kwargs _vmap_test args kwargs check_view=True _test_unary op getter device args kwargs test = functools partial _vmap_test args kwargs B B = Single vmap various in_dims out_dims test op getter B device test op getter B device in_dims= test op getter B device in_dims= out_dims= Doubly nested vmap test vmap op getter B B device test vmap op getter B B device in_dims= test vmap op in_dims= getter B B device in_dims= out_dims= parametrize case torch abs TensorFactory randn torch acos TensorFactory rand torch asin TensorFactory rand torch atan TensorFactory rand torch ceil TensorFactory randn torch cos TensorFactory rand torch cosh TensorFactory rand torch digamma TensorFactory rand torch exp TensorFactory randn torch expm TensorFactory randn torch floor TensorFactory randn torch frac TensorFactory randn torch lgamma TensorFactory rand torch log TensorFactory randp torch log TensorFactory randp torch log p TensorFactory randp torch log TensorFactory randp torch neg TensorFactory randn torch reciprocal TensorFactory randp torch relu TensorFactory randn torch round TensorFactory randn torch rsqrt TensorFactory randp torch sigmoid TensorFactory randn torch sign TensorFactory randn torch sin TensorFactory rand torch sinh TensorFactory rand torch sqrt TensorFactory rand torch tan TensorFactory rand torch tanh TensorFactory rand torch trunc TensorFactory randn name_fn=lambda x x __name__ test_unary_pointwise case op getter = case _test_unary op getter cpu test in-place method = getattr Tensor f op __name__ + _ _test_unary method getter cpu check_propagates_grad=False test_clone Some basic tests _test_unary lambda x x clone TensorFactory randn cpu _test_unary lambda x x clone memory_format=torch preserve_format TensorFactory randn cpu _test_unary lambda x x clone memory_format=torch contiguous_format TensorFactory randn cpu Test per-examples contiguous when using torch contiguous_format clone_contiguous x x clone memory_format=torch contiguous_format B B = x = torch randn B y = vmap clone_contiguous in_dims= out_dims= x assertTrue y movedim is_contiguous assertTrue y is_contiguous x = torch randn B B y = vmap vmap clone_contiguous in_dims= in_dims= x assertTrue y is_contiguous assertTrue y is_contiguous msg = r only supported memory_format torch preserve_format torch contiguous_format assertRaisesRegex RuntimeError msg vmap lambda x x clone memory_format=torch channels_last torch randn B assertRaisesRegex RuntimeError msg vmap lambda x x clone memory_format=torch channels_last_ d torch randn B test_weird_matmul_case Check doesn t crash https github com pytorch functorch issues x = torch randn y = torch randn vmap vmap torch matmul in_dims= None x y parametrize case torch clamp_min_ TensorFactory randn torch clamp_max_ TensorFactory randn name_fn=lambda x x __name__ test_clamp_inplace_variant case test = _vmap_test get_number getter getter item op getter = case device = cpu B B = Single vmap op Tensor Tensor test op getter B device getter B device check_propagates_grad=False test op getter B device getter B device check_propagates_grad=False test op getter B device getter B device in_dims= check_propagates_grad=False test op getter B device getter B device in_dims= out_dims= check_propagates_grad=False test op getter B device getter device in_dims= None check_propagates_grad=False test op getter B device getter B device in_dims= check_propagates_grad=False Nested vmap op Tensor Tensor test vmap op getter B B device getter B B device check_propagates_grad=False Python number overload op Tensor Number number = get_number getter _test_unary lambda t op t number getter device check_propagates_grad=False parametrize case subtest _make_case torch clamp_min name= clamp_min subtest _make_case torch clamp_max name= clamp_max test_clamp_variant case test = _vmap_test get_number getter getter item op getter = case device = cpu B B = Single vmap op Tensor Tensor test op getter B device getter B device test op getter B device getter B device test op getter B device getter B device in_dims= test op getter B device getter B device in_dims= out_dims= test op getter B device getter device in_dims= None test op getter device getter B device in_dims= None Nested vmap op Tensor Tensor test vmap op getter B B device getter B B device test vmap op in_dims= None getter B device getter B device in_dims= None Python number overload op Tensor Number number = get_number getter _test_unary lambda t op t number getter device test_copy_ x = torch randn y = torch randn vmap Tensor copy_ x y assertEqual x y x = torch randn y = torch randn vmap Tensor copy_ in_dims= None y x assertEqual y x expand t x = torch randn y = torch randn assertRaisesRegex RuntimeError inplace vmap Tensor copy_ in_dims= None x y test_silu_backward test = _vmap_test device = cpu getter = TensorFactory randp B = op = torch ops aten silu_backward Single vmap op Tensor Tensor test op getter B device getter B device test op getter device getter B device in_dims= None test op getter B device getter device in_dims= None parametrize case subtest _make_case torch add name= add subtest _make_case lambda x y x + y name= add_dunder subtest _make_case torch sub name= sub subtest _make_case lambda x y x - y name= sub_dunder subtest _make_case torch mul name= mul subtest _make_case lambda x y x y name= mul_dunder subtest _make_case torch div input_getter=TensorFactory randp name= div subtest _make_case lambda x y x y input_getter=TensorFactory randp name= div_dunder subtest _make_case torch pow input_getter=TensorFactory randp name= pow subtest _make_case lambda x y x y input_getter=TensorFactory randp name= pow_dunder test_arithmetic case test = _vmap_test get_number getter getter item op getter = case device = cpu B B = Single vmap op Tensor Tensor test op getter B device getter B device test op getter B device getter B device test op getter B device getter B device in_dims= test op getter B device getter B device in_dims= out_dims= test op getter B device getter device in_dims= None test op getter device getter B device in_dims= None Nested vmap op Tensor Tensor test vmap op getter B B device getter B B device test vmap op in_dims= None getter B device getter B device in_dims= None Python number overload op Tensor Number vice-versa number = get_number getter _test_unary lambda t op t number getter device number = get_number getter _test_unary lambda t op number t getter device Type promotion op Logical Scalar Tensor Logical Scalar Tensor test op getter B device getter B device dtype=torch double test op getter B device dtype=torch double getter B device test op getter B device getter B device Type promotion op Tensor Logical Scalar Tensor vice-versa test op getter B device getter B device torch double test op getter B device torch double getter B device torch cuda is_available TODO rzou fix following Test cross-device scalars number = get_number getter _test_unary lambda t op t number getter device= cuda _test_unary lambda t op number t getter device= cuda _test_unary lambda t op t torch tensor number getter device= cuda test_as_strided _test sizes strides offset tensor lambd bdim dim test result = vmap lambda t t as_strided sizes strides offset tensor expected = vmap lambd tensor assertTrue result _base expected _base assertEqual result expected bdim dim - test tensor = tensor movedim - result = vmap lambda t t as_strided sizes strides offset - tensor expected = vmap lambd - tensor assertTrue result _base expected _base assertEqual result expected single vmap test B = Each Tensor has shape B expressions below just get tensors different strides have shape B tensors = contiguous torch randn B non-contiguous torch randn B transpose torch randn B movedim - transpose non-zero storage offset torch randn B torch randn B movedim non-contiguous strides zero storage offset torch randn B torch randn B movedim non-contiguous strides non-zero storage offset torch randn B torch randn B movedim - x tensors S S = x stride offset = x storage_offset Broadcast _test S S offset x lambda x x expand transpose _test S S offset x lambda x x transpose select _test S offset + S x lambda x x diagonal _test S + S offset x lambda x x diagonal strided slice _test S offset x lambda x x Nested vmap test B = x = torch randn B B S S = x stride result = vmap vmap lambda t t as_strided S S in_dims= x expected = vmap vmap lambda t t expand in_dims= x assertTrue result _base expected _base assertEqual result expected Check mal-formatted size strides doesn t crash assertRaisesRegex RuntimeError size stride must have same length x = torch randn B transpose vmap lambda x x as_strided x All Sanity check b c cases check xs i as_strided sizes strides offset + xs i offset - xs offset doesn t index memory out bounds xs i This condition important correctness as_strided batching rule see NOTE When will as_strided_batching_rule fail Sanity check The maximum indexable location xs i as_strided sizes strides offset + xs i offset - xs offset less than equal maximum indexable location xs i msg = This supported inside vmap assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x assertRaisesRegex RuntimeError msg x = torch randn B B vmap vmap lambda x x as_strided x Sanity check b The min indexable location xs i as_strided sizes strides offset + xs i offset - xs offset greater than equal min indexable location xs i assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided B - x Sanity check c xs i zero-dim tensor xs i as_strided sizes strides offset + xs i offset - xs offset assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x test_nll_loss test = _vmap_test op = F nll_loss B = y = torch randn B t = torch randint B test op y t test functools partial op reduction= sum y t test functools partial op reduction= none y t y = torch randn B t = torch randint test op y t in_dims= None test functools partial op reduction= sum y t in_dims= None test functools partial op reduction= none y t in_dims= None test_adaptive_avg_pool d test = _vmap_test op = functools partial F adaptive_avg_pool d output_size= x = torch randn test op x test op x in_dims= test op x in_dims= test_bmm op = torch bmm test = _vmap_test B B = shape mismatch msg = assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_cat test = _vmap_test B B = Quick hack b c vmap can t accept list tensors argument get_op dim op tensors torch cat tensors dim=dim op test get_op torch rand B torch rand B test get_op torch rand B torch rand B test get_op torch rand torch rand B in_dims= None test get_op torch rand torch rand B torch rand in_dims= None None test get_op torch rand B torch rand B test get_op torch rand B torch rand in_dims= None test get_op torch rand torch rand B torch rand B in_dims= None test get_op torch rand torch rand B in_dims= None test get_op torch rand torch rand B in_dims= None test get_op - torch rand torch rand B in_dims= None test vmap get_op in_dims= None torch rand B torch rand B in_dims= None test vmap get_op in_dims= torch rand B torch rand B B in_dims= None test_unsafe_view Unsafe view isn t exposed so we get via vmap grad matmul test = functools partial _vmap_test check_propagates_grad=False B = x = torch randn B y = torch randn B baz x y x y sum test functorch grad baz x y test_conj op = torch conj run_test dtype get shape torch randn shape dtype=dtype B B = test = _vmap_test Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= correctness tests run_test torch float run_test torch cfloat check torch conj non-complex tensor returns same tensor real_tensor = torch randn result = vmap op real_tensor assertEqual result data_ptr real_tensor data_ptr test_contiguous op = Tensor contiguous _test_unary op TensorFactory randn cpu check contiguous returns original tensor per-examples already contiguous B = x = torch randn B x = x movedim result = vmap Tensor contiguous in_dims= out_dims= x assertTrue result x msg = NYI querying is_contiguous inside vmap memory_format tensor = torch randn B assertRaisesRegex RuntimeError msg vmap functools partial op memory_format=torch channels_last tensor assertRaisesRegex RuntimeError msg vmap functools partial op memory_format=torch channels_last_ d tensor test_stride B = x = torch randn B foo x assert x stride == x vmap foo x x = torch randn B movedim bar x assert x stride == B x vmap bar x test_chunk test = _vmap_view_test op = torch chunk B B B = tests torch split split_size int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_clamp clamp_cases = lambda t t clamp min=- TensorFactory randn lambda t t clamp max= TensorFactory randn lambda t t clamp min=- max= TensorFactory randn lambda t t clamp_min min=- TensorFactory randn lambda t t clamp_max max= TensorFactory randn op getter clamp_cases _test_unary op getter cpu test_comparison_ops test = functools partial _vmap_test check_propagates_grad=False getter = TensorFactory randn B B = ops = torch eq lambda x y x == y torch gt lambda x y x y torch ge lambda x y x = y torch le lambda x y x = y torch lt lambda x y x y torch ne lambda x y x = y op ops Single vmap op Tensor Tensor test op getter B getter B test op getter B getter B test op getter B getter B in_dims= test op getter B getter B in_dims= out_dims= test op getter B getter in_dims= None test op getter getter B in_dims= None Nested vmap op Tensor Tensor test vmap op getter B B getter B B test vmap op in_dims= None getter B getter B in_dims= None test number inputs number = getter item _test_unary lambda t op t number getter cpu check_propagates_grad=False test_cross_batch_size_three Let s test corner case when batch_size cross dim argument specified According cross API dim will assigned first dim value In test we ensure found dim batch dim op = torch cross test = _vmap_test B = B = test op torch rand B torch rand B test vmap op in_dims= None torch rand B B torch rand B B in_dims= None test_diagonal tensor = torch randn test = _vmap_view_test op = torch diagonal test op tensor in_dims= None None None test op tensor - in_dims= None None None test op tensor in_dims= None None None test op tensor - - in_dims= None None None out_dims= test vmap lambda t op t - tensor in_dims= out_dims= test vmap vmap lambda t op t in_dims= in_dims= tensor in_dims= out_dims= test_dot op = torch dot test = _vmap_test B B = shape mismatch msg = assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_expand_as op = torch Tensor expand_as test = _vmap_view_test B B B = test op torch rand B torch rand B test op torch rand B torch rand in_dims= None test op torch rand torch rand B in_dims= None test vmap op torch rand B B torch rand B B test vmap op torch rand B B torch rand B B in_dims= test vmap op torch rand B B torch rand B in_dims= None test vmap vmap op torch rand B B B torch rand B B B test_fill_and_zero_inplace test = functools partial _vmap_test check_propagates_grad=False B B = ops = lambda t t fill_ lambda t t fill_ torch tensor lambda t t zero_ op ops Single vmap various in_dims out_dims test op TensorFactory randn B test op TensorFactory randn B in_dims= test op TensorFactory randn B in_dims= out_dims= Doubly nested vmap test vmap op TensorFactory randn B B test vmap op TensorFactory randn B B in_dims= test vmap op in_dims= TensorFactory randn B B in_dims= out_dims= test when value batched tensor fill_ operator B B = test Tensor fill_ TensorFactory randn B B TensorFactory randn B assertRaisesRegex RuntimeError Runtime Error thrown when tensor being written isn t being vmapped over vmap Tensor fill_ None TensorFactory randn B B TensorFactory randn B _test_complex_views op dtypes test = _vmap_view_test run_test op dtype get shape torch randn shape dtype=dtype B B = Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= dtype dtypes run_test op dtype test_real _test_complex_views torch real dtypes= torch cfloat torch cdouble test_imag _test_complex_views torch imag dtypes= torch cfloat torch cdouble test_view_as_real _test_complex_views torch view_as_real dtypes= torch cfloat torch cdouble test_view_as_complex run_test dtype get shape torch randn shape dtype=dtype op = torch view_as_complex test = _vmap_view_test B B = Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= Interesting case Batch dim directly before dim size test op get B in_dims= test vmap op in_dims= get B B in_dims= Interesting case Batch dim end tensor success cases view_as_complex requires dim size have stride order view function property test op get B transpose in_dims= test vmap op in_dims= get B B movedim test vmap op in_dims= get B B movedim Interesting case Batch dim end tensor failure cases msg = Tensor must have last dimension stride assertRaisesRegex RuntimeError msg vmap op in_dims= get B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= in_dims= get B B Invalid input no dimension size msg = Input tensor must have one more dimensions assertRaisesRegex RuntimeError msg vmap op get B assertRaisesRegex RuntimeError msg vmap vmap op get B B Invalid input Batch dim has size logical last dim does have size msg = Tensor must have last dimension size assertRaisesRegex RuntimeError msg vmap op in_dims= get dtype torch float torch double run_test dtype test_is_complex ctensor = torch randn dtype=torch cfloat tensor = torch randn foo x x is_complex torch tensor torch tensor assertEqual vmap foo ctensor torch tensor assertEqual vmap foo tensor torch tensor test_is_floating_point float_tensor = torch tensor long_tensor = torch tensor foo x x is_floating_point torch tensor torch tensor assertEqual vmap foo float_tensor torch tensor assertEqual vmap foo long_tensor torch tensor unittest skipIf IS_WINDOWS reason= Windows yet supported torch compile test_is_contiguous foo x x is_contiguous torch tensor torch tensor B B = Single batch dim contig = torch randn B assertEqual vmap foo contig torch ones B noncontig = torch randn B assertEqual vmap foo in_dims= noncontig torch zeros B noncontig = torch randn B movedim assertEqual vmap foo noncontig torch zeros B noncontig = torch randn B assertEqual vmap foo in_dims= noncontig torch zeros B Multiple batch dims contig = torch randn B B assertEqual vmap vmap foo contig torch ones B B contig = torch randn B B assertEqual vmap vmap foo in_dims= contig torch ones B B contig = torch randn B B movedim assertEqual vmap vmap foo contig torch ones B B noncontig = torch randn B B assertEqual vmap vmap foo in_dims= noncontig torch zeros B B is_contiguous empty tensor True bar x assert x is_contiguous x vmap bar torch randn B vmap bar in_dims= torch randn B vmap bar torch randn B transpose - - is_contiguous other memory formats baz x memory_format x is_contiguous memory_format=memory_format x msg = NYI querying is_contiguous inside vmap memory_format tensor = torch randn B assertRaisesRegex RuntimeError msg vmap functools partial baz memory_format=torch channels_last tensor assertRaisesRegex RuntimeError msg vmap functools partial baz memory_format=torch channels_last_ d tensor mf torch channels_last torch channels_last_ d torch compile backend= eager fullgraph=True f x x is_contiguous memory_format=mf x sin x cos assertRaisesRegex RuntimeError msg vmap f torch randn test_unsqueeze op = torch unsqueeze test = _vmap_view_test B B = unsqueeze dim test op torch rand B in_dims= None test op torch rand B in_dims= None unsqueeze last dim positive test op torch rand B in_dims= None test op torch rand B in_dims= None unsqueeze last dim negative test op torch rand B - in_dims= None test op torch rand B - in_dims= None nested vmaps unsqueeze_ x torch unsqueeze x unsqueeze_last x torch unsqueeze x - bdims canonical order test vmap unsqueeze_ torch rand B B test vmap unsqueeze_last torch rand B B wild bdims test vmap unsqueeze_ torch rand B B in_dims= test vmap unsqueeze_ in_dims= torch rand B B in_dims= test vmap unsqueeze_last torch rand B B in_dims= test vmap unsqueeze_last in_dims= torch rand B B in_dims= test_movedim op = torch movedim test = _vmap_view_test B B B = movedim tensor int int variant test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap op in_dims= None None in_dims= None None torch rand B B B in_dims= None None movedim tensor intlist intlist variant test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap op in_dims= None None in_dims= None None torch rand B B B in_dims= None None test_mm op = torch mm test = _vmap_test B B = shape mismatch msg = Shape mismatch assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_mv op = torch mv test = _vmap_test B B = shape mismatch msg = assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_narrow op = torch narrow test = _vmap_view_test B B B = test op torch rand B - in_dims= None None None test op torch rand B in_dims= None None None test vmap op in_dims= None None None torch rand B B in_dims= None None None test vmap vmap op in_dims= None None None in_dims= None None None torch rand B B B - in_dims= None None None test_new_empty Empty non-deterministic so we just check shape output tensor what we expect vmap fallback isn t used op = Tensor new_empty B B = result = vmap lambda x op x torch randn B assertEqual result shape B result = vmap lambda x op x torch randn B assertEqual result shape B result = vmap vmap lambda x op x torch randn B B assertEqual result shape B B test_new_empty_strided Empty non-deterministic so we just check size shape output what we expect vmap fallback isn t used B B = _test_single_vmap size stride B x = torch randn B result = vmap lambda x x new_empty_strided size stride x S = torch empty_strided size stride storage size assertEqual result shape B + size assertEqual result stride S + stride _test_double_vmap size stride B B x = torch randn B B result = vmap vmap lambda x x new_empty_strided size stride x S = torch empty_strided size stride storage size assertEqual result shape B B + size assertEqual result stride B S S + stride x = torch randn B B result = vmap vmap lambda x x new_empty_strided size stride in_dims= x S = x new_empty_strided size stride storage size assertEqual result shape B B + size assertEqual result stride B S S + stride contiguous case _test_single_vmap B _test_double_vmap B B expanded _test_single_vmap B _test_double_vmap B B some these cases pretty strange just verifying empty_strided allows them then BatchedTensor new_empty_strided can well shape strides _test_single_vmap shape strides B _test_double_vmap shape strides B B test_new_zeros op = Tensor new_zeros test = functools partial _vmap_test check_propagates_grad=False B B = test lambda x op x torch rand B test lambda x op x torch rand B test vmap lambda x op x torch rand B B test_select op = torch select test = _vmap_view_test B B B = test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap lambda t op t torch rand B B in_dims= test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_roll_no_dims op = torch roll test = _vmap_test B B B = test op torch rand B in_dims= None test op torch rand B in_dims= None test vmap lambda t op t torch rand B B in_dims= test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_stack test = _vmap_test B B = Quick hack b c vmap can t accept list tensors argument get_op dim op tensors torch stack tensors dim=dim op test get_op torch rand B torch rand B test get_op torch rand torch rand B in_dims= None test get_op torch rand torch rand B in_dims= None test get_op - torch rand torch rand B in_dims= None test vmap get_op in_dims= None torch rand B torch rand B in_dims= None test vmap get_op in_dims= torch rand B torch rand B B in_dims= None test_slice test = _vmap_view_test B B B = test lambda t t torch rand B test lambda t t torch rand B in_dims= test vmap lambda t t in_dims= torch rand B B in_dims= test vmap vmap lambda t t in_dims= in_dims= torch rand B B B in_dims= xfailIfTorchDynamo test_squeeze verify_behavior op min_ndim= test = _vmap_view_test B B = These tests cannot used operator requires more than dimension after batching min_ndim = test op torch rand B test op torch rand B test vmap op torch rand B B test vmap op torch rand B B in_dims= test op torch rand B test op torch rand B in_dims= test op torch rand B test op torch rand B test vmap op torch rand B B test vmap op torch rand B B in_dims= verify_behavior torch squeeze verify_behavior lambda x torch squeeze x dim= min_ndim= verify_behavior lambda x torch squeeze x dim= min_ndim= verify_behavior lambda x torch squeeze x dim=- min_ndim= verify_behavior lambda x torch squeeze x dim=- min_ndim= msg = try torch squeeze torch rand dim= except IndexError err msg = str err assertRaises RuntimeError msg=msg vmap lambda x torch squeeze x dim= torch rand _test_mean_sum_dim op test = _vmap_test B B = Single vmap various in_dims out_dims test lambda x op x torch randn B test lambda x op x - torch randn B test lambda x op x torch randn B test lambda x op x - torch randn B in_dims= test lambda x op x torch randn B in_dims= out_dims= Doubly nested vmap test vmap lambda x op x torch randn B B test vmap lambda x op x - torch randn B B test vmap lambda x op x - torch randn B B in_dims= test vmap lambda x op x in_dims= torch randn B B in_dims= out_dims= test_sum_dim _test_mean_sum_dim torch sum test_mean_dim _test_mean_sum_dim torch mean test_argmax_dim test f args loop_out batched_out get_fallback_and_vmap_exhaustive f args assertEqual loop_out batched_out B = test lambda x torch argmax x torch randn B test lambda x torch argmax x torch randn B test lambda x torch argmax x torch randn B test lambda x torch argmax x - torch randn B test lambda x torch argmax x torch randn B _test_sum_mean op test = _vmap_test B B = Single vmap various in_dims out_dims test op torch randn B test op torch randn B test op torch randn B in_dims= test op torch randn B in_dims= Doubly nested vmap test vmap op torch randn B B test vmap op torch randn B B test vmap op torch randn B B in_dims= test_sum _test_sum_mean torch sum test_mean _test_sum_mean torch mean test_repeat test = _vmap_test B = op = Tensor repeat test lambda x op x torch rand B test lambda x op x torch rand B in_dims= skipIfTorchDynamo test_slogdet test = functools partial _vmap_test check_propagates_grad=False B = op = torch linalg slogdet test op torch rand B test op torch rand B test op torch rand B test op torch rand B in_dims= test_reshape test = _vmap_test B B B = op = torch reshape test op torch rand B in_dims= None check_view=True test op torch rand B in_dims= None check_view=False test vmap lambda t t reshape - torch rand B B check_view=True test vmap vmap lambda t t reshape - in_dims= in_dims= torch rand B B B in_dims= check_view=False test_reshape_as test = _vmap_test B B B = op = torch Tensor reshape_as test op torch rand B torch rand B check_view=True test op torch rand torch rand B in_dims= None check_view=True test op torch rand B torch rand in_dims= None check_view=True test op torch rand B torch rand in_dims= None check_view=False test vmap op torch rand B B torch randn B B check_view=True test vmap vmap op in_dims= None in_dims= None torch rand B B B torch rand B in_dims= check_view=False test_result_type scalar_tensor_with_dtype op wrapped args kwargs dtype = op args kwargs torch ones dtype=dtype wrapped test = _vmap_test op = scalar_tensor_with_dtype torch result_type B = test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch tensor torch randn B check_propagates_grad=False test lambda x op x torch tensor dtype=torch double torch randn B check_propagates_grad=False test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch tensor torch randn B check_propagates_grad=False test lambda x op x torch tensor dtype=torch double torch randn B check_propagates_grad=False test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False test_tensor_split test = _vmap_view_test op = torch tensor_split B B B = tests torch tensor_split indices_or_sections int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= tests torch tensor_split indices_or_sections List int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= skipIfTorchDynamo really slow test_split test = _vmap_view_test op = torch split B B B = tests torch split split_size int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= tests torch split split_size List int dim test op torch rand B - in_dims= None None test op torch rand B + in_dims= None None test vmap op in_dims= None None torch rand B B + in_dims= None None test vmap vmap lambda t op t + in_dims= torch rand B B B in_dims= test_trace op = torch trace test = _vmap_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_transpose op = torch transpose test = _vmap_view_test B B B = test lambda x op x torch rand B test lambda x op x - - torch rand B test lambda x op x torch rand B test lambda x op x torch rand B in_dims= test vmap lambda x op x torch rand B B in_dims= test vmap vmap lambda x op x in_dims= torch rand B B B in_dims= Special case scalar tensor dim dim itertools product - - x = torch rand B result = vmap lambda x op x dim dim x assertTrue result x test_t op = torch t test = _vmap_view_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_T_numpy op t t T test = _vmap_view_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_to test = _vmap_test B B = test lambda t t cpu torch rand B test lambda t t torch double torch rand B test lambda t o t o torch rand B torch randn B dtype=torch float test lambda t o t o torch rand B torch randn B dtype=torch float in_dims= None test vmap lambda t t torch double torch rand B B also test some casting methods test lambda t t double torch rand B test lambda t t float torch rand B test lambda t t int torch rand B check_propagates_grad=False test lambda t t long torch rand B check_propagates_grad=False test_unfold op = torch Tensor unfold test = _vmap_view_test B B B = test op torch rand B in_dims= None None None test op torch rand B in_dims= None None None test vmap op in_dims= None None None torch rand B B in_dims= None None None test vmap vmap op in_dims= None None None in_dims= None None None torch rand B B B - in_dims= None None None test_unbind test = _vmap_view_test op = torch unbind B B B = test op torch rand B - in_dims= None test op torch rand B test op torch rand B in_dims= None test vmap op in_dims= None torch rand B B in_dims= None test vmap vmap lambda t op t dim= in_dims= torch rand B B B in_dims= test_view test = _vmap_view_test B B B = op = torch Tensor view We should error out view would produce incorrect result assertRaises RuntimeError vmap op in_dims= None torch rand B test op torch rand B in_dims= None test op torch rand B in_dims= None test vmap lambda t t view - torch rand B B test vmap vmap lambda t t reshape - in_dims= torch rand B B B in_dims= test_view_as test = _vmap_view_test B B B = op = torch Tensor view_as We should error out view would produce incorrect result assertRaises RuntimeError vmap op in_dims= torch rand B torch rand B test op torch rand B torch rand B test op torch rand torch rand B in_dims= None test op torch rand B torch rand in_dims= None test op torch rand B torch rand in_dims= None test vmap op torch rand B B torch randn B B test vmap vmap op in_dims= None in_dims= None torch rand B B B torch rand B in_dims= test_conv d conv_setups = torch nn Conv d torch conv d torch nn Conv d torch conv d torch nn Conv d torch conv d torch nn ConvTranspose d torch conv_transpose d conv_mod conv_fn inp_shape conv_setups mod = conv_mod kernel_size= arg_values = torch randn inp_shape mod weight mod bias kwarg_values = loop_out batched_out get_fallback_and_vmap_exhaustive conv_fn arg_values kwarg_values assertEqual loop_out batched_out arg_values = torch randn inp_shape mod weight None loop_out batched_out get_fallback_and_vmap_exhaustive conv_fn arg_values kwarg_values assertEqual loop_out batched_out mod = conv_mod kernel_size= groups= stride= padding= dilation= arg_values = torch randn inp_shape mod weight mod bias kwarg_values = dict groups= stride= padding= dilation= loop_out batched_out get_fallback_and_vmap_exhaustive conv_fn arg_values kwarg_values assertEqual loop_out batched_out arg_values = torch randn inp_shape mod weight None loop_out batched_out get_fallback_and_vmap_exhaustive conv_fn arg_values kwarg_values assertEqual loop_out batched_out test_one_hot sample_inputs = torch randint torch randint args sample_inputs loop_out batched_out get_fallback_and_vmap_exhaustive F one_hot args assertEqual loop_out batched_out test_conj_bit x = torch tensor + j + j foo x assert x is_conj y = x conj assert y is_conj y res = vmap foo x assertEqual res x conj test_mode_key vmap_f x x + torch randn naive_f x shape x + torch randn shape torch manual_seed out = vmap vmap vmap_f randomness= different randomness= different torch ones torch manual_seed out = naive_f torch ones assertEqual out out torch manual_seed out = vmap vmap vmap_f randomness= different randomness= different torch ones torch manual_seed out = naive_f torch ones assertEqual out out assertTrue torch randn dim == parametrize in_dim parametrize out_dim parametrize randomness error same test_chunk_vmap in_dim out_dim randomness x = torch randn f x y = x sin randomness = error y = y + torch rand_like x y rs = torch get_rng_state expected = vmap f in_dims=in_dim out_dims=out_dim randomness=randomness x chunks torch set_rng_state rs output = chunk_vmap f in_dims=in_dim out_dims=out_dim randomness=randomness chunks=chunks x assertEqual output expected parametrize in_dim parametrize out_dim parametrize randomness error same test_vmap_chunksize in_dim out_dim randomness x = torch randn y = torch randn_like x fn Single Input Single Output f x y = x sin randomness = error y = y + torch rand_like x y f_args = x f_kwargs = in_dims in_dim out_dims out_dim randomness randomness fn Nested Input Single Output f pair x y = pair z = x sin + y cos randomness = error z = z + torch rand_like z z f _args = x y f _kwargs = in_dims in_dim out_dims out_dim randomness randomness fn Single Input Nested Output f x y = x sin randomness = error y = y + torch rand_like x out y out y + f _args = x f _kwargs = in_dims in_dim out_dims out_dim randomness randomness fn Nested Input Nested Output first tensor vmapped f inp_dict x = inp_dict inp y = inp_dict inp z = x sin + y cos randomness = error z = z + torch rand_like z z z tuple z z + f _args = inp x index_select in_dim torch tensor squeeze in_dim inp y f _kwargs = in_dims inp None inp in_dim out_dims out_dim randomness randomness fn Nested Input Nested Output first argument Tensor f inp_dict x = inp_dict inp y = inp_dict inp z = x + y cos randomness = error z = z + torch rand_like z z z tuple z z + f _args = inp inp y f _kwargs = in_dims inp None inp in_dim out_dims out_dim randomness randomness fns_and_args = f f_args f_kwargs f f _args f _kwargs f f _args f _kwargs f f _args f _kwargs f f _args f _kwargs fn args kwargs fns_and_args rs = torch get_rng_state expected_vmap = vmap fn kwargs args chunk_size torch set_rng_state rs output = vmap fn chunk_size=chunk_size kwargs args assertEqual output expected_vmap parametrize in_dim parametrize out_dim parametrize randomness error same test_vmap_chunksize_error in_dim out_dim randomness x = torch randn f x y = x sin randomness = error y = y + torch rand_like x y Incorrect ` chunk_size ` chunk_size - assertRaisesRegex ValueError vmap chunk_size should None greater than vmap f in_dims=in_dim out_dims=out_dim randomness=randomness chunk_size=chunk_size x Incorrect ` out_dims ` msg = out_dims compatible structure ` outputs ` assertRaisesRegex ValueError msg vmap f in_dims=in_dim out_dims= out_dim out_dim randomness=randomness chunk_size= x parametrize in_dim parametrize out_dim parametrize randomness error same test_vmap_chunksize_composition in_dim out_dim randomness x = torch randn y = torch randn_like x fn Single Input Single Output f x y = x sin randomness = error y = y + torch rand_like x y f_args = x fn Nested Input Single Output f pair x y = pair z = x sin + y cos randomness = error z = z + torch rand_like z z f _args = x y fn Single Input Nested Output f x y = x sin randomness = error y = y + torch rand_like x out y out y + f _args = x fn Nested Input Nested Output f inp_dict x = inp_dict inp y = inp_dict inp z = x sin + y cos randomness = error z = z + torch rand_like z z z tuple z z + f _args = inp x inp y fn args f f_args f f _args f f _args f f _args rs = torch get_rng_state expected = vmap vmap fn in_dims=in_dim out_dims=out_dim randomness=randomness in_dims=in_dim out_dims=out_dim randomness=randomness args chunk_size torch set_rng_state rs actual = vmap vmap fn in_dims=in_dim out_dims=out_dim randomness=randomness chunk_size=chunk_size in_dims=in_dim out_dims=out_dim randomness=randomness chunk_size=chunk_size args assertEqual actual expected instantiate_parametrized_tests TestVmapOperators construct_v output batch_size contig=False contig torch randn batch_size output shape dtype=output dtype device=output device result = torch randn output shape batch_size dtype=output dtype device=output device result movedim - as_tuple x isinstance x tuple x isinstance x list tuple x x differentiable args tuple arg arg as_tuple args isinstance arg torch Tensor arg requires_grad _get_rand_no_zeros args kwargs requires_grad = kwargs get requires_grad False kwargs_without_requires_grad = kwargs copy kwargs_without_requires_grad requires_grad = False result = torch rand args kwargs_without_requires_grad result clamp_min_ requires_grad_ requires_grad markDynamoStrictTest TestVmapBatchedGradient Namespace TestVmapBase _vmap_test args kwargs _vmap_test args kwargs Tests batched gradient computation outputs = op args kwargs comparing sequential map+stack fallback output_process_fn function maps outputs part should differentiated batch_size batch dim size batched grad _batched_grad_test op args kwargs=None output_process_fn=lambda x x batch_size= kwargs None kwargs = outputs = op args kwargs outputs = differentiable output_process_fn outputs contig True False batched_vectors = tuple construct_v out batch_size contig out outputs vector_jacobian_product vectors torch autograd grad outputs differentiable args vectors retain_graph=True _vmap_test vector_jacobian_product batched_vectors check_propagates_grad=False Tests batched second grad computation outputs = op args kwargs comparing sequential map+stack fallback output_process_fn function maps outputs part should differentiated batch_size batch dim size batched grad NB we only test computing batched gradients second gradient computation One specific use case does computing hessian matrix scalar-valued function useful Bayesian Logistic Regression It might useful have test computes batched first gradients then uses those compute batched second gradients future _batched_grad_grad_test op args kwargs=None output_process_fn=lambda x x batch_size= kwargs None kwargs = outputs = op args kwargs outputs = differentiable output_process_fn outputs ones = tuple torch ones_like out out outputs Same thing summing together all outputs calling backward first_grads = torch autograd grad outputs differentiable args ones create_graph=True first_grads = differentiable first_grads assertNotEqual len first_grads None first grads depend input contig True False batched_vectors = tuple construct_v grad batch_size contig grad first_grads vector_hessian_product vectors outputs = torch autograd grad first_grads differentiable args vectors retain_graph=True allow_unused=True outputs = tuple out out outputs out None assert len outputs outputs _vmap_test vector_hessian_product batched_vectors check_propagates_grad=False _test_arithmetic op device test_grad_grad=True x = torch randn requires_grad=True device=device y = _get_rand_no_zeros device=device requires_grad=True scalar = _batched_grad_test op x y _batched_grad_test op scalar y _batched_grad_test op x scalar test_grad_grad _batched_grad_grad_test op x y test_add device _test_arithmetic torch add device test_grad_grad=False _test_arithmetic lambda x y x + y device test_grad_grad=False test_sub device _test_arithmetic torch sub device test_grad_grad=False _test_arithmetic lambda x y x - y device test_grad_grad=False test_mul device _test_arithmetic torch mul device _test_arithmetic lambda x y x y device test_div device _test_arithmetic torch div device _test_arithmetic lambda x y x y device test_binary_cross_entropy device x = F sigmoid torch randn device=device requires_grad=True target = torch rand device=device op = functools partial F binary_cross_entropy target=target _batched_grad_test op x _batched_grad_grad_test op x test_log_softmax device op = functools partial torch log_softmax dim=- x = torch randn device=device requires_grad=True _batched_grad_test op x _batched_grad_grad_test op x test_expand device x = torch randn device=device requires_grad=True op x x expand _batched_grad_test op x allowVmapFallbackUsage test_index device x = torch randn requires_grad=True device=device index = torch tensor device=device op x y = x x y index _batched_grad_test op x _batched_grad_grad_test op x test_lgamma device x = torch randn requires_grad=True device=device _batched_grad_test Tensor lgamma x _batched_grad_grad_test Tensor lgamma x test_log device x = _get_rand_no_zeros device=device requires_grad=True _batched_grad_test torch log x _batched_grad_grad_test torch log x test_logsumexp device x = _get_rand_no_zeros device=device requires_grad=True op x torch logsumexp x - _batched_grad_test op x _batched_grad_grad_test op x test_log p device x = _get_rand_no_zeros device=device requires_grad=True _batched_grad_test torch log p x _batched_grad_grad_test torch log p x allowVmapFallbackUsage test_max device x = torch randn requires_grad=True device=device _batched_grad_test torch max x allowVmapFallbackUsage test_median device x = torch randn requires_grad=True device=device _batched_grad_test torch median x allowVmapFallbackUsage test_min device x = torch randn requires_grad=True device=device _batched_grad_test torch min x test_permute device x = torch randn requires_grad=True device=device op x x permute _batched_grad_test op x test_reshape device x = torch randn requires_grad=True device=device op x x reshape _batched_grad_test op x test_sigmoid device x = torch randn requires_grad=True device=device _batched_grad_test Tensor sigmoid x _batched_grad_grad_test Tensor sigmoid x test_stack device x = torch randn device=device requires_grad=True y = torch randn device=device requires_grad=True op x y torch stack x y _batched_grad_test op x y test_select device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x x _batched_grad_test lambda x x select x _batched_grad_test lambda x x select - x test_slice device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x x _batched_grad_test lambda x x x _batched_grad_test lambda x x x test_trace device x = torch randn device=device requires_grad=True _batched_grad_test Tensor trace x x = torch randn device=device sum_grad_trace x grad torch trace x sum output = vmap grad sum_grad_trace x assertEqual output torch zeros_like output test_where device x = torch randn device=device y = torch ones device=device f x y torch where x x y Check there no runtime error exactness tests done opinfo vmap f x y x = torch randint size= dtype=torch float f t torch where t assertRaisesRegex RuntimeError r Attempted vmap over aten where vmap f x test_threshold device x = torch randn device=device requires_grad=True _batched_grad_test lambda x F threshold x x parametrize backend PLATFORM_SPECIFIC_SDPA test_sdpa device backend device == cpu raise unittest SkipTest This test only CUDA now T args torch randn args dtype=torch float device=device backend_ctx = sdpa_kernel backend backend_ctx batching True True True True False False False True True size = batching query = T size query = T size batching key = T size key = T size batching value = T size value = T size in_dims = tuple b None b batching attention = F scaled_dot_product_attention _vmap_test attention query key value in_dims=in_dims Backwards test doesn t work yet _batched_grad_test lambda query key value F scaled_dot_product_attention query key value query key value B = query = torch rand B dtype=torch float device=device key = torch rand B dtype=torch float device=device value = torch rand dtype=torch float device=device _vmap_test F scaled_dot_product_attention query key value in_dims= None parametrize backend PLATFORM_SPECIFIC_SDPA parametrize randomness error same different test_randomness device randomness backend device == cpu raise unittest SkipTest This test only CUDA now backend_ctx = sdpa_kernel backend backend_ctx B = query = torch rand B dtype=torch float device=device key = torch rand B dtype=torch float device=device value = torch rand B dtype=torch float device=device f q k v dropout F scaled_dot_product_attention q k v dropout_p=dropout No matter randomness mode dropout= should pass vmap functools partial f dropout= in_dims= randomness=randomness query key value fail_with_randomness = randomness == error backend = SDPBackend MATH fail_with_randomness &#124; = randomness == same context = assertRaises RuntimeError We currently don t support randomness == same error should always error randomness fail_with_randomness contextlib nullcontext context vmap functools partial f dropout= in_dims= randomness=randomness query key value allowVmapFallbackUsage test_inplace_view device leaf = torch randn requires_grad=True func leaf Make sure function non-trivially twice differentiable base = leaf leaf view = base view cos_ view _batched_grad_test func leaf _batched_grad_grad_test func leaf allowVmapFallbackUsage test_inplace_manyview device leaf = torch randn requires_grad=True func leaf Make sure function non-trivially twice differentiable base = leaf leaf view = base transpose view = view view = view diagonal view = view view cos_ view _batched_grad_test func leaf _batched_grad_grad_test func leaf test_diagonal device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x diagonal x x = torch randn device=device requires_grad=True _batched_grad_test lambda x x diagonal - - x allowVmapFallbackUsage test_unrelated_output device B = x = torch randn requires_grad=True y = torch randn requires_grad=True gy = torch randn B requires_grad=True vjp v res = torch autograd grad y x v allow_unused=True torch zeros_like x res None res result = vmap vjp gy assertEqual result torch zeros B x shape device=device allowVmapFallbackUsage test_unrelated_output_multiple_grad device B = x = torch randn requires_grad=True y = torch randn requires_grad=True gy = torch randn B requires_grad=True vjp v res = torch autograd grad y x v allow_unused=True torch zeros_like x res None res _ = vjp gy result = vmap vjp gy assertEqual result torch zeros B x shape device=device discover_variants opinfo aliases = inplace_variants = opinfo inplace_variant inplace_variants append opinfo inplace_variant aliases append opinfo op alias opinfo aliases aliases append alias op alias inplace_variant inplace_variants append alias inplace_variant aliases inplace_variants TODO enable when we get bit closer getting torch vmap x torch compile working markDynamoStrictTest unMarkDynamoStrictTest TestVmapOperatorsOpInfo TestCase vmap_outplace_test func args kwargs in_dims check_shape_only=False postprocess_fn=None out_dim= vmap_out loop_out compute_quantities_for_vmap_test func args kwargs in_dims out_dim=out_dim postprocess_fn None loop_out = postprocess_fn loop_out vmap_out = postprocess_fn vmap_out check_shape_only assertEqual vmap_out shape loop_out shape continue assertEqual vmap_out loop_out vmap_inplace_test func args kwargs in_dims postprocess_fn=None out_dim= NB This test assumes first argument being modified This OK because s what every other OpInfo-based test assumes going need more robust solution eventually in_dims None Check we correctly raise error when vmap impossible in-place operation assertRaises RuntimeError _ compute_quantities_for_vmap_test func args kwargs in_dims out_dim=out_dim compute_loop_out=False clone_inputs=True pass vmap_out loop_out compute_quantities_for_vmap_test func args kwargs in_dims clone_inputs=True out_dim=out_dim postprocess_fn None loop_out = postprocess_fn loop_out vmap_out = postprocess_fn vmap_out assertEqual vmap_out loop_out opinfo_vmap_test device dtype op check_has_batch_rule skip_inplace= postprocess_fn=None test Error inputs check op error_inputs_func None error_inputs = op error_inputs device error_input error_inputs sample_input = error_input sample_input args = sample_input input + tuple sample_input args kwargs = sample_input kwargs batched_args in_dims _ generate_vmap_inputs args assertRaises Exception vmap op in_dims batched_args kwargs Sample inputs check sample_inputs_op = Take too long reference inputs special chebyshev_polynomial_t special chebyshev_polynomial_u special chebyshev_polynomial_v special chebyshev_polynomial_w special hermite_polynomial_he special laguerre_polynomial_l special legendre_polynomial_p special shifted_chebyshev_polynomial_t special shifted_chebyshev_polynomial_u special shifted_chebyshev_polynomial_v special shifted_chebyshev_polynomial_w op name sample_inputs_op sample_inputs_itr = op sample_inputs device dtype requires_grad=False use_subtests=True sample_inputs_itr = op reference_inputs device dtype requires_grad=False use_subtests=True aliases inplace_aliases = discover_variants op check_shape_only = op name empty_like new_empty sample_input subtest_ctx skip_xfail_ctx sample_inputs_itr subtest_ctx skip_xfail_ctx args = sample_input input + sample_input args any isinstance arg torch Tensor arg args At least one tensor required vmap continue kwargs = sample_input kwargs is_batch_norm_and_training = is_batch_norm_training op name kwargs out_dim = op name == NumpySplitCopyWithIntCustomOp special case custom op sample_vmap_out_dim_numpy_split_copy_with_int x splits dim _ range len splits + None out_dim = sample_vmap_out_dim_numpy_split_copy_with_int args batched_args in_dims _ generate_vmap_inputs args is_batch_norm_and_training=is_batch_norm_and_training func aliases vmap_outplace_test func batched_args kwargs in_dims check_shape_only postprocess_fn out_dim=out_dim op name skip_inplace continue is_valid_inplace_sample_input sample_input op op inplace_variant continue func inplace_aliases vmap_inplace_test func batched_args kwargs in_dims postprocess_fn check_has_batch_rule check_vmap_fallback test op test vmap_fail = -------------------- ALLOWED FAILURES -------------------------------- These things we either cannot fix actually problems xfail resize_ xfail resize_as_ xfail to_sparse xfail __getitem__ dynamic mask xfail index_put dynamic mask xfail nn functional dropout works can t check against loop because randomness inconsistency xfail nn functional scaled_dot_product_attention randomness xfail nn functional multi_head_attention_forward randomness xfail masked_select dynamic op xfail nonzero dynamic op xfail unique dynamic op xfail unique_consecutive dynamic op xfail allclose returns boolean xfail uniform randomness tested separately xfail rand_like randomness tested separately xfail randint_like randomness tested separately xfail randn_like randomness tested separately xfail bernoulli randomness tested separately xfail normal randomness tested separately xfail normal number_mean randomness tested separately xfail multinomial randomness xfail nn functional embedding we only support some cases xfail nn functional rrelu randomness xfail nn functional dropout d randomness xfail nn functional dropout d randomness xfail nn functional alpha_dropout randomness xfail nn functional feature_alpha_dropout with_train randomness xfail as_strided Our test runner can t handle manual test exists xfail as_strided_copy xfail as_strided_scatter no batching rule implemented default doesn t work skip new_empty_strided empty tensor data garbage so s hard make comparisons xfail nn functional fractional_max_pool d randomness xfail nn functional fractional_max_pool d randomness xfail pca_lowrank random operation xfail svd_lowrank random operation xfail sparse sampled_addmm sparse xfail sparse mm reduce sparse xfail NumpyCubeNotComposableAutogradFunction Not composable autograd Function skip _softmax_backward_data skip linalg eigh always same result same input see test_linalg_eigh manual test UnimplementedError data-dependent operators cannot vmapped xfail NumpyNonzeroCustomOp xfail NumpyNMSCustomOp ---------------------------------------------------------------------- ---------------------------- BUGS ------------------------------------ entries here don t work need fixed Each one these bug decorate frexp decorator=skipIfTorchDynamo xfail clamp_min Exception raised error input xfail clamp_max Exception raised error input xfail view_as_complex RuntimeError Tensor must have last dimension stride xfail tensor_split data_ptr xfail histogramdd expected Tensor element argument got tuple xfail nn functional gaussian_nll_loss data-dependent control flow error xfail nn functional embedding_bag embedding renorm vmap inplace incompatible xfail narrow Batching rule implemented aten narrow Tensor required rank tensor use channels_last format xfail bfloat xfail bool xfail byte xfail char xfail double xfail float xfail half xfail int xfail long xfail short xfail cdouble xfail cfloat xfail jiterator_binary device_type= cuda NYI querying is_contiguous inside vmap xfail jiterator_binary_return_by_ref device_type= cuda NYI querying is_contiguous inside vmap xfail jiterator_ inputs_with_extra_args device_type= cuda NYI querying is_contiguous inside vmap xfail equal TypeError object type bool has no len likely testrunner problem xfail jiterator_unary device_type= cuda NYI querying is_contiguous inside vmap xfail jiterator_ inputs_ outputs device_type= cuda NYI querying is_contiguous inside vmap --------------------------------------------------------------------- TypeError expected Tensor element argument got NotImplementedType xfail __rsub__ RuntimeError Batching rule implemented aten moveaxis int fallback path doesn t work out= view ops xfail movedim RuntimeError NYI querying is_contiguous inside vmap memory_format other than torch contiguous_format xfail contiguous RuntimeError NYI Tensor clone memory_format inside vmap only supported memory_format torch preserve_format torch contiguous_format got ChannelsLast xfail clone RuntimeError When vmap-ing torch nn functional one_hot please provide explicit positive num_classes argument xfail nn functional one_hot RuntimeError Expected all tensors same device found least two devices cuda cpu xfail eq device_type= cuda xfail ge device_type= cuda xfail gt device_type= cuda xfail le device_type= cuda xfail lt device_type= cuda xfail ne device_type= cuda RuntimeError aten _flash_attention_forward hit vmap fallback which currently disabled xfail torch ops aten _flash_attention_forward with_tf _off https github com pytorch pytorch issues ops op_db + additional_op_db + autograd_function_db + custom_op_db dtypes=OpDTypes any_one opsToleranceOverride TestVmapOperatorsOpInfo test_vmap_exhaustive tol linalg det torch float tol atol= e- rtol= e- device_type= cuda The following often flaky just windows We should investigate s actually problem tol nn functional conv_transpose d torch float tol atol= e- rtol= e- device_type= cuda toleranceOverride torch float tol atol= e- rtol= e- torch complex tol atol= e- rtol= e- skipOps TestVmapOperatorsOpInfo test_vmap_exhaustive vmap_fail union RuntimeError Batch norm got batched tensor input while running_mean running_var which will updated place batched xfail native_batch_norm xfail _native_batch_norm_legit TODO implement batching rule xfail _batch_norm_with_update xfail tril Exception raised error input xfail triu Exception raised error input xfail as_strided partial_views RuntimeError output shape doesn t match broadcast shape xfail addcdiv xfail addcmul xfail clamp xfail torch ops aten _efficient_attention_forward outputs ints TypeError expected Tensor element argument got float xfail item xfail unbind_copy Batching rule implemented aten unbind_copy int RuntimeError required rank tensor use channels_last format xfailIf lambda sample sample kwargs memory_format == torch channels_last test_vmap_exhaustive device dtype op needs fixed inplace_failure_list = opinfo_vmap_test device dtype op check_has_batch_rule=False skip_inplace=inplace_failure_list with_tf _off ops op_db + additional_op_db + autograd_function_db + custom_op_db dtypes=OpDTypes any_one opsToleranceOverride TestVmapOperatorsOpInfo test_op_has_batch_rule tol linalg det torch float tol atol= e- rtol= e- device_type= cuda toleranceOverride torch float tol atol= e- rtol= e- torch complex tol atol= e- rtol= e- skipOps TestVmapOperatorsOpInfo test_op_has_batch_rule vmap_fail union xfail as_strided partial_views skip RuntimeError required rank tensor use channels_last format xfail fill Batch norm got batched tensor input while running_mean running_var which will updated place batched xfail native_batch_norm xfail _native_batch_norm_legit TODO implement batching rule xfail _batch_norm_with_update xfail histogram ` index_put ` OpInfo pytorch pytorch has masked index input which supported xfail index_put xfail isin xfail masked_fill xfail masked_scatter xfail masked_select xfail nanquantile xfail ormqr xfail put xfail quantile xfail renorm xfail squeeze_copy xfail resize_as_ xfail take xfail tensor_split xfail transpose_copy xfail to_sparse TypeError expected Tensor element argument got float xfail item xfail tril Exception raised error input xfail triu Exception raised error input xfail unbind_copy Batching rule implemented aten unbind_copy int xfail __getitem__ xfail count_nonzero xfail nn functional dropout works can t check against loop because randomness inconsistency xfail nn functional scaled_dot_product_attention randomness xfail nn functional multi_head_attention_forward randomness xfail torch ops aten _efficient_attention_forward outputs ints xfail resize_ xfail view_as_complex xfail fft ihfft xfail fft ihfftn xfail allclose xfail argwhere xfail unique_consecutive xfail unique xfail nn functional ctc_loss xfail nn functional gaussian_nll_loss xfail histc xfail as_strided xfail as_strided_copy xfail permute_copy xfail t_copy xfail unsqueeze_copy xfail istft xfail nonzero xfail nn functional fractional_max_pool d xfail stft xfail isclose xfail nn functional fractional_max_pool d xfail nn functional bilinear xfail nn functional embedding_bag xfail linalg tensorsolve xfail bernoulli xfail nn functional feature_alpha_dropout with_train xfail nn functional kl_div xfail multinomial xfail pca_lowrank xfail normal xfail nn functional dropout d xfail normal number_mean xfail svd_lowrank xfail diagflat xfail special log_ndtr xfail narrow Batching rule implemented aten narrow Tensor xfail nn functional triplet_margin_loss xfail nn functional pdist xfail nn functional max_unpool d grad xfail nn functional multi_margin_loss xfail nn functional multilabel_margin_loss xfail nn functional max_unpool d grad xfail nn functional max_unpool d xfail nn functional max_unpool d grad xfail nn functional margin_ranking_loss xfail nn functional max_unpool d xfail nn functional soft_margin_loss xfail nn functional max_unpool d xfail linalg ldl_solve device_type= cpu xfail chalf xfail clamp_max xfail jiterator_binary_return_by_ref device_type= cuda xfail jiterator_unary device_type= cuda xfail jiterator_ inputs_ outputs device_type= cuda xfail special airy_ai xfail clamp_min xfail sparse sampled_addmm xfail sparse mm reduce xfail special chebyshev_polynomial_t xfail special chebyshev_polynomial_v xfail special chebyshev_polynomial_u xfail special chebyshev_polynomial_w xfail special shifted_chebyshev_polynomial_t xfail special shifted_chebyshev_polynomial_v xfail special shifted_chebyshev_polynomial_u xfail special shifted_chebyshev_polynomial_w xfail _segment_reduce offsets xfail index_reduce prod xfail index_reduce mean xfail index_reduce amin xfail index_reduce amax xfail special laguerre_polynomial_l xfail special legendre_polynomial_p xfail special hermite_polynomial_h xfail jiterator_binary device_type= cuda xfail jiterator_ inputs_with_extra_args device_type= cuda xfail _segment_reduce lengths xfail lu_solve xfail special hermite_polynomial_he xfail nn functional dropout d xfail as_strided_scatter xfail equal xfail linalg lu skip linalg ldl_solve skip _softmax_backward_data One more overload doesn t have Batch rule xfail bincount RuntimeError Expected all tensors same device found least two devices cuda cpu xfail ge device_type= cuda xfail searchsorted aten searchsorted Scalar hit vmap fallback which currently disabled test_op_has_batch_rule device dtype op needs fixed inplace_failures = addbmm addcdiv addcmul addmm addmv addr baddbmm clamp conj_physical cumprod cumsum floor_divide fmod heaviside hypot igamma igammac index_copy ldexp lerp neg nextafter polygamma pow remainder scatter square sub trunc xlogy opinfo_vmap_test device dtype op check_has_batch_rule=True skip_inplace=inplace_failures test_linalg_svd device linalg_svd returns tuple three tensors U S Vh Given same input may different tensors because svd isn t unique To test svd correct we multiply U diag S Vh check output vmap matches output for-loop compute_A out U S Vh = out m = U shape - n = Vh shape - diag_S = S new_zeros S shape - m n diag_S diagonal offset= dim =- dim =- copy_ S U diag_S Vh opinfos = op op op_db op name == linalg svd assert len opinfos op opinfos opinfo_vmap_test device torch float op check_has_batch_rule=True postprocess_fn=compute_A test_linalg_eigh device linalg_svd returns two tensors Q L Given same input may different tensors because eig decomposition isn t unique To test eigh correct we multiply Q diag L Qh check output vmap matches output for-loop compute_A out L Q = out n = Q shape - diag_L = L new_zeros L shape - n n diag_L diagonal offset= dim =- dim =- copy_ L Qh = Q transpose - - conj Q diag_L Qh opinfos = op op op_db op name == linalg eigh assert len opinfos op opinfos opinfo_vmap_test device torch float op check_has_batch_rule=True postprocess_fn=compute_A skipIfTorchDynamo test_slogdet device There s no OpInfo test B = x = torch randn B device=device vmap_outplace_test torch slogdet x check_vmap_fallback test torch slogdet test_index_fill device There s no OpInfo these tests B = test negative dim x = torch randn B device=device dim = - index = torch tensor device=device value = vmap_outplace_test torch index_fill x dim index value None None None test batched logical rank index logical rank x = torch zeros B device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None test batched logical rank index logical rank x = torch zeros B device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None test batched logical rank index logical rank x = torch zeros device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None None test batched logical rank index logical rank x = torch zeros device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None None test batched logical rank index logical rank x = torch zeros device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None None test batched logical rank index logical rank x = torch zeros device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None None test batched logical rank index logical rank x = torch zeros B device=device dim = index = torch tensor device=device value torch rand device=device vmap_outplace_test torch index_fill x dim index value None None test test test test test test test test test check_vmap_fallback test torch index_fill test_fill__Tensor device There s no OpInfo fill_ Tensor so here s extra test test B = args = torch randn B device=device torch randn B vmap_inplace_test Tensor fill_ args args = torch randn B device=device torch randn B vmap_inplace_test Tensor fill_ args - args = torch randn device=device torch randn B vmap_inplace_test Tensor fill_ args None args = torch randn B device=device torch randn vmap_inplace_test Tensor fill_ args None check_vmap_fallback test Tensor fill_ tf _on_and_off test_conv_double_backward device images = torch randn device=device weight = torch randn device=device bias = torch randn device=device ggI = torch randn_like images ggW = torch randn_like weight ggb = torch randn_like bias stride = padding = dilation = transposed = False output_padding = groups = output_mask = True True True gO = torch randn_like F conv d images weight bias stride padding dilation groups args = ggI ggW ggb gO weight images stride padding dilation transposed output_padding groups output_mask op = torch ops aten _convolution_double_backward generator = get_fallback_and_vmap_exhaustive op args is_cuda_sm = device startswith cuda torch cuda get_device_capability == atol rtol = e- e- is_cuda_sm e- e- test loop_out batched_out generator assertEqual loop_out batched_out atol=atol rtol=rtol check_vmap_fallback test op test_isnan device test = functools partial _vmap_test check_propagates_grad=False B N C H W = op = torch isnan x = torch randn B N C H W x x = float nan test op x in_dims= test_sum_scalar device x = torch tensor device=device y = vmap torch sum x assertEqual y x y = vmap lambda x x sum x assertEqual y x y = vmap lambda x x sum - x assertEqual y x test_isinf device test = functools partial _vmap_test check_propagates_grad=False B N C H W = op = torch isinf x = torch randn B N C H W x x = float inf test op x in_dims= test_foo_like device vfdev- Probably we can remove line Flake reported unused test = functools partial _vmap_test check_propagates_grad=False B N C H W = op torch ones_like torch zeros_like x = torch randn B N C H W todo chilli test these better Not testing correctness just they run vmap op in_dims= x test_flatten device test = functools partial _vmap_test check_propagates_grad=False op = torch flatten x = torch randn test op x in_dims= None None test_group_norm device test = functools partial _vmap_test check_propagates_grad=False B N C H W = op = F group_norm x = torch randn B N C H W weight = torch randn C bias = torch randn C test op x weight bias in_dims= None None None x = torch randn B N C H W weight = torch randn B C bias = torch randn B C test op x weight bias in_dims= None test_index_put device test f t idx values base = f t idx values assertEqual vmap f in_dims= t idx values base assertEqual vmap f in_dims= None None t idx values base assertEqual vmap f in_dims= None t idx values base assertEqual vmap f in_dims= None t idx values base f x y z x y = z x x = torch randn device=device y = torch zeros device=device long z = torch randn device=device test f x y z indexing innermost dim f t idx values t idx = values t t = torch zeros values = torch ones idx = torch tensor expand test f t idx values indexing middle dim f t idx values t idx = values t t = torch zeros values = torch ones idx = torch tensor expand test f t idx values indexing slices f t values t = values t base = f t values assertEqual vmap f in_dims= t values base assertEqual vmap f in_dims= None t values base index_put_ tensor = torch zeros value = torch ones idxs = torch tensor torch tensor torch tensor expected = torch index_put_ tensor clone idxs value f t idx v torch index_put_ t idx v t assertEqual vmap f in_dims= None None tensor idxs value expected assertEqual vmap f in_dims= None None None tensor idxs value expected boolean mask B = x = torch randn gy = torch randn B f x gy mask = x e- zeros = torch zeros index_put = torch ops aten index_put default gy mask zeros index_put vmap_outplace_test f x gy in_dims= None onlyCUDA parametrize inplace True False test_ d_tensor_index_put device inplace f t idx v fn = torch index_put_ inplace torch index_put fn t idx v N = t = torch zeros N device= cuda idx = torch tensor v = torch tensor dtype=t dtype device= cpu expected = torch tensor dtype=t dtype assertEqual expected vmap f in_dims= None None t idx v parametrize training True False parametrize track_running_stats True False parametrize affine True False test_batch_norm device affine track_running_stats training track_running_stats training test = functools partial _vmap_test check_propagates_grad=False BN = torch nn BatchNorm d ensemble_size = hidden_dim = weights buffers _ _ _ = functional_init_with_buffers BN ensemble_size hidden_dim affine=affine track_running_stats=track_running_stats inputs = torch randn ensemble_size hidden_dim device=device in_dims = append inp in_dim inputs append inp in_dims append in_dim track_running_stats running_mean running_var _ = buffers append running_mean device append running_var device append None None append None None affine weight bias = weights append weight device append bias device append None None append None None append training None op inp running_mean running_var weight bias training res = F batch_norm inp running_mean running_var weight bias training track_running_stats res running_mean running_var res test op tuple inputs in_dims=tuple in_dims test_torch_return_types_returns device t = torch randn device=device assertTrue isinstance vmap torch min None t torch return_types min assertTrue isinstance vmap torch max None t torch return_types max assertTrue isinstance vmap torch topk None None t torch return_types topk assertTrue isinstance vmap torch linalg eig t torch return_types linalg_eig test_namedtuple_returns device Point = namedtuple Point x y f x y Point x=x y=y x = torch randn device=device y = torch randn device=device assertTrue isinstance vmap f x y Point test_inplace_on_view device func leaf base = leaf leaf view = base transpose view = view diagonal sin_ view = view view cos_ view push_vjp leaf gout _ vjp_fn = vjp func leaf result = vjp_fn gout result leaf = torch randn device=device gout = torch randn device=device args = leaf gout batched_args in_dims _ generate_vmap_inputs args in_dims None triggers some composite compliance problem continue vmap_outplace_test push_vjp batched_args in_dims test_advanced_indexing device test f args loop_out batched_out get_fallback_and_vmap_exhaustive f args assertEqual loop_out batched_out f x idx x idx f x idx x idx f x idx x idx inps = torch randn device=device torch randn device=device torch randn device=device idxes = torch tensor device=device torch tensor device=device reshape torch tensor device=device reshape inp idx itertools product inps idxes test f inp idx test f inp idx test f inp idx test_nested_advanced_indexing device e = torch rand device=device idx = torch tensor device=device view simple reference implementation comparison _fake_vmap f in_dims= out_dims= w input r = f input select in_dims i i range input size in_dims torch stack r out_dims w with_vmap _vmap g idx_ f e_ e_ idx_ _vmap f in_dims= e r = _vmap g idx r = with_vmap vmap b = with_vmap _fake_vmap assertEqual b ops filter lambda op linalg op name op_db + additional_op_db allowed_dtypes= torch float skipOps TestVmapOperatorsOpInfo test_vmap_linalg_failure_ D_input xfail linalg vector_norm can accept vector inputs xfail linalg norm can accept vector inputs xfail linalg norm subgradients_at_zero can accept vector inputs xfail linalg vander can accept vector inputs skip linalg multi_dot accepts list tensor inputs has its own special test xfail linalg vecdot throws vmap CUDA IndexError Dimension out range expected range - got - passes locally xfail linalg diagonal skip linalg matrix_norm skip linalg ldl_solve test_vmap_linalg_failure_ D_input device dtype op sample op sample_inputs device dtype requires_grad=False sample input dim = sample input shape == continue test_input = sample input using sample input avoids numerical inconsistency issues assertRaisesRegex RuntimeError dimension op test_input sample args sample kwargs op_wrapper inp op inp sample args sample kwargs square inputs more likely pass linalg checks test_input = test_input expand test_input shape test_input shape assertRaisesRegex RuntimeError dimension vmap op_wrapper test_input test_vmap_multi_dot_failure_ D_input special exception first last tensors so making giving items avoids special cases inputs = torch randn torch randn torch randn assertRaisesRegex RuntimeError tensor must D got D torch linalg multi_dot inputs square inputs more likely pass linalg checks inputs = tuple i expand i shape i shape i inputs assertRaisesRegex RuntimeError tensor must D got D vmap torch linalg multi_dot inputs test_vmap_escaped_error escaped = None f x nonlocal escaped escaped = x x x = torch randn vmap f x common_message = r your tensor may have escaped inside function being vmapped Note These complete set tests all possible functions calling vmap_check_escaped assertRaisesRegex RuntimeError common_message format gen_vmap_plumbing escaped sin assertRaisesRegex RuntimeError common_message format boxed_tensor_inputs_batch_rule escaped sin_ assertRaisesRegex RuntimeError common_message format gen_vmap_inplace_plumbing escaped mul_ assertRaisesRegex RuntimeError common_message format binary_cross_entropy_plumbing torch nn functional binary_cross_entropy escaped torch zeros assertRaisesRegex RuntimeError common_message format boxed_existing_bdim_all_batch_rule torch nn functional adaptive_max_pool d escaped output_size= assertRaisesRegex RuntimeError common_message format boxed_reduction_batch_rule escaped argmin = torch zeros b = torch zeros dtype=torch long assertRaisesRegex RuntimeError common_message format boxed_all_tensors_have_optional_bdim torch ops aten adaptive_max_pool d_backward escaped b vmap f torch tensor dtype=torch int assertRaisesRegex RuntimeError common_message format gen_vmap_plumbing_no_returns torch ops aten _linalg_check_errors escaped linalg inv is_matrix=False test_vmap_with_anomaly_detection torch autograd set_detect_anomaly True x = torch zeros - fn x x sum per_sample_grad = vmap grad fn x assertEqual per_sample_grad torch ones_like x bad_fn x x sqrt sum err_msg = Function SqrtBackward returned nan values its th output assertRaisesRegex RuntimeError err_msg vmap grad bad_fn x test_searchsorted_bucketize device OpInfo generates test repeated samples batch dim Thus we test explicitly different samples across batch test boundaries = torch tensor device=device v = torch tensor device=device vmap_outplace_test torch searchsorted boundaries v None vmap_outplace_test torch bucketize v boundaries None boundaries = torch tensor device=device v = torch tensor device=device vmap_outplace_test torch searchsorted boundaries v vmap_outplace_test torch bucketize v boundaries test markDynamoStrictTest TestRandomness TestCase _reset_random generator orig_state use_generator seed generator set_state orig_state use_generator torch manual_seed seed _get_image batched_input batch_size device batched_input == first torch ones batch_size device=device batched_input == last torch ones batch_size device=device assert batched_input == none torch ones device=device _assert_all_slices_equal tensor expected = tensor assertTrue tensor == expected all _assert_all_slices_unique tensor B = tensor shape slices_equal = vmap vmap lambda x y x == y all None None tensor tensor assert slices_equal shape == B B slices_equal diagonal zero_ assertEqual slices_equal torch zeros_like slices_equal _assert_throws_in_error_mode fn args in_dims assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap fn in_dims=in_dims randomness= error args _assert_throws_in_different_mode_inplace fn args in_dims assertRaisesRegex RuntimeError r different inplace randomness unbatched tensor vmap fn in_dims=in_dims randomness= different args _assert_throws_in_same_mode_batched fn args in_dims assertRaisesRegex RuntimeError r Vmap does currently support same randomness batched tensor input vmap fn in_dims=in_dims randomness= same args _in_dims batched_strings get_in_dim batched_string batched_string == first batched_string == last - assert batched_string == none None batched_strings = batched_strings + first always batched first dim dummy argument tuple get_in_dim batched_string batched_string batched_strings parametrize randomness same different error parametrize use_generator True False test_factory_ops device randomness use_generator generator = torch Generator device=device orig_state = generator get_state kwargs = device device generator generator use_generator device device ops = lambda _ shape torch randn shape kwargs lambda _ shape torch rand shape kwargs lambda _ shape torch randint shape kwargs lambda _ shape torch randint shape kwargs lambda _ shape torch normal shape kwargs B = shape = seed = op ops passed = torch randn B device=device randomness == error _assert_throws_in_error_mode op passed shape in_dims= None generator = _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims= None randomness=randomness passed shape generator = _reset_random generator orig_state use_generator seed randomness == different expected = op passed B shape _assert_all_slices_unique vmap_result assertEqual vmap_result expected expected = op passed shape _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize randomness same different error parametrize use_generator True False test_randperm device randomness use_generator needs special case because randperm doesn t take batch size B = seed = passed = torch randn B device=device torch manual_seed seed generator = torch Generator device=device orig_state = generator get_state kwargs = device device generator generator use_generator device device randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap lambda _ torch randperm kwargs randomness=randomness passed vmap_result = vmap lambda _ torch randperm kwargs randomness=randomness passed generator = generator set_state orig_state torch manual_seed seed randomness == different i range B expected = torch randperm kwargs RNG differs between eager via dynamo trace CUDA TEST_WITH_TORCHDYNAMO torch device device type == cuda _assert_all_slices_unique vmap_result assertEqual vmap_result i expected expected = torch randperm kwargs RNG differs between eager via dynamo trace CUDA TEST_WITH_TORCHDYNAMO torch device device type == cuda _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize randomness error same different parametrize batched_input first last none test_dropout device randomness batched_input op t ignored torch nn functional dropout torch ones_like t training=True B = always_batched = torch randn B passed = _get_image batched_input B device in_dims = _in_dims batched_input randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap op randomness=randomness in_dims=in_dims passed always_batched vmap_result = vmap op randomness=randomness in_dims=in_dims passed always_batched Check randomness within bounds ideally close p_estimate = vmap_result mean assertTrue p_estimate assertTrue p_estimate randomness == different _assert_all_slices_unique vmap_result assert randomness == same _assert_all_slices_equal vmap_result parametrize randomness error same different parametrize batched_input first last none test_alpha_dropout device randomness batched_input op t ignored torch nn functional alpha_dropout torch ones_like t training=True B = always_batched = torch randn B passed = _get_image batched_input B device in_dims = _in_dims batched_input randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap op randomness=randomness in_dims=in_dims passed always_batched I have no clue how actually test correctness alpha dropout because docs seem wrong https github com pytorch pytorch issues vmap_result = vmap op randomness=randomness in_dims=in_dims passed always_batched randomness == different _assert_all_slices_unique vmap_result assert randomness == same _assert_all_slices_equal vmap_result parametrize randomness error same different parametrize batched_input first last none parametrize dim test_feature_dropout device randomness batched_input dim op t ignored f = torch nn functional dropout d dim == torch nn functional dropout d f torch ones_like t training=True B = always_batched = torch randn B passed = _get_image batched_input B device dim == unsqueeze_dim = - batched_input == last - passed = passed unsqueeze unsqueeze_dim in_dims = _in_dims batched_input randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap op randomness=randomness in_dims=in_dims passed always_batched vmap_result = vmap op randomness=randomness in_dims=in_dims passed always_batched Check feature pattern dims = - - dim == - - - planes_numel = vmap_result numel vmap_result shape vmap_result shape vmap_result shape planes = vmap_result sum dims result = planes == ^ planes == planes_numel assertEqual result torch ones_like result dtype=torch bool randomness == different _assert_all_slices_unique vmap_result assert randomness == same _assert_all_slices_equal vmap_result parametrize randomness error same different parametrize batched_input first last none test_feature_alpha_dropout device randomness batched_input op t ignored torch nn functional feature_alpha_dropout torch ones_like t training=True B = always_batched = torch randn B passed = _get_image batched_input B device unsqueeze_dim = - batched_input == last - passed = passed unsqueeze unsqueeze_dim in_dims = _in_dims batched_input randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap op randomness=randomness in_dims=in_dims passed always_batched vmap_result = vmap op randomness=randomness in_dims=in_dims passed always_batched I have no clue how actually test correctness alpha dropout because docs seem wrong https github com pytorch pytorch issues Check feature pattern dims = - - - planes = vmap_result sum dims max_elt = planes max min_elt = planes min result = planes == min_elt ^ planes == max_elt assertEqual result torch ones_like result dtype=torch bool randomness == different _assert_all_slices_unique vmap_result assert randomness == same _assert_all_slices_equal vmap_result parametrize randomness error same different parametrize batched_input first last none test_like_functions device randomness batched_input seed = supported_ops = lambda t _ torch randint_like t lambda t _ torch randint_like t lambda t _ torch rand_like t lambda t _ torch randn_like t B = op supported_ops always_batched = torch randn B passed = _get_image batched_input B device in_dims = _in_dims batched_input randomness == error assertRaisesRegex RuntimeError r called random operation while randomness error mode vmap op in_dims=in_dims randomness=randomness passed always_batched torch manual_seed seed vmap_result = vmap op randomness=randomness in_dims=in_dims passed always_batched torch manual_seed seed batched_input == last passed = passed movedim - randomness == different batched_input == none passed = passed expand B passed shape expected = op passed _assert_all_slices_unique vmap_result RNG differs between eager via dynamo trace CUDA TEST_WITH_TORCHDYNAMO torch device device type == cuda assertEqual expected vmap_result assert randomness == same batched_input = none passed = passed expected = op passed _assert_all_slices_equal vmap_result RNG differs between eager via dynamo trace CUDA TEST_WITH_TORCHDYNAMO torch device device type == cuda i range B assertEqual expected vmap_result i parametrize use_generator True False parametrize randomness error same different parametrize batched_input first last none test_random_unary_inplace device use_generator randomness batched_input generator = torch Generator device=device orig_state = generator get_state kwargs = generator generator use_generator ops = lambda t _ t random_ kwargs lambda t _ t random_ kwargs lambda t _ t random_ - kwargs lambda t _ t normal_ kwargs lambda t _ t bernoulli_ kwargs lambda t _ t cauchy_ kwargs lambda t _ t exponential_ kwargs lambda t _ t geometric_ kwargs lambda t _ t log_normal_ kwargs lambda t _ t uniform_ kwargs B = seed = in_dims = _in_dims batched_input op ops because place updates clone inputs always_batched = torch randn B device=device passed = _get_image batched_input B device passed_expected = passed clone randomness == error _assert_throws_in_error_mode op passed always_batched in_dims=in_dims randomness == different batched_input == none _assert_throws_in_different_mode_inplace op passed always_batched in_dims=in_dims generator = _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims=in_dims randomness=randomness passed always_batched batched_input == last passed_expected = passed_expected movedim - generator = _reset_random generator orig_state use_generator seed randomness == different expected = op passed_expected always_batched _assert_all_slices_unique vmap_result assertEqual vmap_result expected batched_input = none passed_expected = passed_expected clone bug pytorch normal_ views doesn t work expected = op passed_expected always_batched _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize use_generator True False parametrize randomness error same different parametrize batched_input first last none parametrize batched_probability first last none test_bernoulli_in_place device use_generator randomness batched_input batched_probability B = seed = generator = torch Generator device=device orig_state = generator get_state kwargs = generator generator use_generator in_dims = _in_dims batched_input batched_probability op t p ignored t bernoulli_ p kwargs because place updates clone inputs always_batched = torch randn B device=device input = _get_image batched_input B device input_expected = input clone probability = _get_image batched_probability B device - randomness == error _assert_throws_in_error_mode op input probability always_batched in_dims=in_dims randomness == same batched_probability = none _assert_throws_in_same_mode_batched op input probability always_batched in_dims=in_dims batched_input == none batched_probability = none regex = r there exists Tensor ` other ` extra_args has more elements than ` ` assertRaisesRegex RuntimeError regex vmap op in_dims=in_dims randomness=randomness input probability always_batched randomness == different batched_input == none _assert_throws_in_different_mode_inplace op input probability always_batched in_dims=in_dims _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims=in_dims randomness=randomness input probability always_batched _reset_random generator orig_state use_generator seed batched_input == last input_expected = input_expected movedim - batched_probability == last probability = probability movedim - randomness == different expected = op input_expected probability always_batched _assert_all_slices_unique vmap_result assertEqual vmap_result expected batched_input = none input_expected = input_expected expected = op input_expected probability always_batched _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize use_generator True False parametrize randomness error same different parametrize batched_input first last none parametrize batched_other first last none test_random_binary_out_of_place device use_generator randomness batched_input batched_other generator = torch Generator device=device orig_state = generator get_state kwargs = generator generator use_generator ops = lambda t o _ torch normal t o kwargs lambda t o _ torch binomial t o - kwargs B = seed = in_dims = _in_dims batched_input batched_other op ops always_batched = torch randn B device=device input = _get_image batched_input B device other = _get_image batched_other B device randomness == error _assert_throws_in_error_mode op input other always_batched in_dims=in_dims randomness == same batched_input = none batched_other = none _assert_throws_in_same_mode_batched op input other always_batched in_dims=in_dims generator = _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims=in_dims randomness=randomness input other always_batched batched_input == last input = input movedim - batched_other == last other = other movedim - generator = _reset_random generator orig_state use_generator seed randomness == different batched_input == none input = input expand B input shape expected = op input other always_batched _assert_all_slices_unique vmap_result assertEqual vmap_result expected assert batched_input == none batched_other == none expected = op input other always_batched _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize use_generator True False parametrize randomness error same different parametrize batched_input first last none test_random_unary_out_of_place device use_generator randomness batched_input generator = torch Generator device=device orig_state = generator get_state kwargs = generator generator use_generator ops = lambda t _ torch normal torch abs t kwargs lambda t _ torch normal t kwargs lambda t _ torch bernoulli t - kwargs lambda t _ torch bernoulli t kwargs lambda t _ torch _standard_gamma t kwargs lambda t _ torch _sample_dirichlet t kwargs lambda t _ torch poisson t kwargs B = seed = in_dims = _in_dims batched_input op ops always_batched = torch randn B device=device passed = _get_image batched_input B device randomness == error _assert_throws_in_error_mode op passed always_batched in_dims=in_dims randomness == same batched_input = none _assert_throws_in_same_mode_batched op passed always_batched in_dims=in_dims generator = _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims=in_dims randomness=randomness passed always_batched generator = _reset_random generator orig_state use_generator seed randomness == different batched_input == none passed = passed expand B passed shape batched_input == last passed = passed movedim - expected = op passed always_batched _assert_all_slices_unique vmap_result assertEqual vmap_result expected expected = op passed always_batched _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected parametrize use_generator True False parametrize randomness error same different parametrize batched_call True False parametrize batched_input first last none test_multinomial device use_generator randomness batched_call batched_input flatten_input input batch_call batch_location batch_call batch_location = none final_size = B B N batch_call batch_location == none final_size = N final_size = B N B N start_idx = final_size - end_idx = - batch_location == last start_idx -= end_idx -= gets correct final size because using negative indices ret = input flatten start_idx end_idx assert ret dim == final_size ret op input _ torch multinomial input kwargs generator = torch Generator device=device orig_state = generator get_state kwargs = generator generator use_generator B = seed = in_dims = _in_dims batched_input always_batched = torch randn B device=device passed = _get_image batched_input B device passed = flatten_input passed batched_call batched_input randomness == error _assert_throws_in_error_mode op passed always_batched in_dims=in_dims randomness == same batched_input = none _assert_throws_in_same_mode_batched op passed always_batched in_dims=in_dims generator = _reset_random generator orig_state use_generator seed vmap_result = vmap op in_dims=in_dims randomness=randomness passed always_batched generator = _reset_random generator orig_state use_generator seed randomness == different batched_input == none passed = passed expand B passed shape batched_input == last passed = passed movedim - orig_passed_size = passed shape batched_call passed shape passed = passed flatten batched_call passed expected = op passed always_batched expected = expected reshape orig_passed_size _assert_all_slices_unique vmap_result assertEqual vmap_result expected expected = op passed always_batched _assert_all_slices_equal vmap_result i range B assertEqual vmap_result i expected test_unsupported_random device x = torch randn device=device y = x abs z = x abs assertRaisesRegex RuntimeError calling out variants f x torch randn device=device out=y vmap f randomness= same x assertRaisesRegex RuntimeError calling out variants f x x torch normal x y out=x vmap f randomness= same z z assertRaisesRegex RuntimeError do yet support f z torch rrelu x vmap f randomness= same z parametrize in_dim parametrize out_dim test_chunk_vmap in_dim out_dim randomness = different x = torch randn f x y = x sin + torch rand_like x y chunks output = chunk_vmap f in_dims=in_dim out_dims=out_dim randomness=randomness chunks=chunks x _assert_all_slices_unique output parametrize in_dim parametrize out_dim test_vmap_chunksize in_dim out_dim randomness = different x = torch randn f x y = x sin + torch rand_like x y chunk_size output = vmap f in_dims=in_dim out_dims=out_dim randomness=randomness chunk_size=chunk_size x _assert_all_slices_unique output test_jacfwd_with_random checks behavior above just checks jacfwd respects randomness param x = torch rand assertRaisesRegex RuntimeError r called random operation while randomness error mode jacfwd torch bernoulli x x isn t batched so use bernoulli since doesn t do inplace randomness jacfwd torch bernoulli randomness= same x jacfwd torch bernoulli randomness= different x parametrize randomness error same different test_dropout_unbatched device randomness x = torch randn device=device y = torch randn device=device fn x y output dropout should Tensor B B= x + torch nn functional dropout y p= mean We just verify doesn t raise error ` same ` ` different ` randomness Ref https github com pytorch pytorch issues context = assertRaises RuntimeError randomness == error contextlib nullcontext context vmap fn in_dims= None randomness=randomness x y markDynamoStrictTest TestTransformFailure TestCase skipIfTorchDynamo parametrize transform vmap grad grad_and_value vjp jvp jacrev jacfwd test_fails_with_autograd_function device transform failed_build_envs = linux-focal-py -clang linux-focal-py -clang device == cpu transform grad vmap TEST_WITH_TORCHDYNAMO os getenv BUILD_ENVIRONMENT failed_build_envs raise unittest SkipTest Unexpected successes focal dynamo + see https github com pytorch pytorch issues Test torch autograd Function staticmethod forward _ input input staticmethod backward _ grad_input grad_input transform = getattr functorch transform f x Test apply x transform grad grad_and_value input = torch tensor input = torch randn transform == vjp transform = functools partial transform f transform == jvp input = input transform = functools partial transform f input transform = transform f assertRaisesRegex RuntimeError autograd Function transform input markDynamoStrictTest TestVmapDeviceType Namespace TestVmapBase _vmap_test args kwargs _vmap_test args kwargs test__is_all_true device test f x expected_result result = torch ops aten _is_all_true x assertFalse torch _C _functorch is_batchedtensor result assertEqual result shape torch Size assertEqual result item expected_result result x = torch rand device=device vmap f x = expected_result=True vmap f x expected_result=False x random choice range = - vmap f x = expected_result=False vmap f x expected_result=False x = -torch rand device=device vmap f x expected_result=False vmap f x = expected_result=True check_vmap_fallback test torch _is_all_true test__is_any_true device test f x expected_result result = torch ops aten _is_any_true x assertFalse torch _C _functorch is_batchedtensor result assertEqual result shape torch Size assertEqual result item expected_result result x = torch zeros device=device dtype=torch bool vmap f x expected_result=False x = True vmap f x expected_result=True vmap f x expected_result=True vmap f x expected_result=False check_vmap_fallback test torch _is_any_true test_check_tensor device test test_sizes = check_gte_ t torch _test_check_tensor t = error_message = Test message TORCH_CHECK_TENSOR_ALL size test_sizes t_all_gte_ = torch rand size device=device t_all_lt_ = t_all_gte_ - vmap check_gte_ t_all_gte_ len size = vmap vmap check_gte_ t_all_gte_ assertRaisesRegex RuntimeError error_message vmap check_gte_ t_all_lt_ len size = assertRaisesRegex RuntimeError error_message vmap vmap check_gte_ t_all_lt_ t_all_gte_ numel t_all_gte_ _but_one = t_all_gte_ clone idx = random choice range dim_size dim_size size t_all_gte_ _but_one idx = - assertRaisesRegex RuntimeError error_message vmap check_gte_ t_all_gte_ _but_one len size = assertRaisesRegex RuntimeError error_message vmap vmap check_gte_ t_all_gte_ _but_one check_vmap_fallback test torch _test_check_tensor markDynamoStrictTest TestVmapNestedTensor Namespace TestVmapBase _vmap_test args kwargs _vmap_test args kwargs dims should something like None None indicating random ragged structure should used _create_nt dims device sizes = d d None torch randint size= item d dims d range dims torch nested nested_tensor torch randn size size sizes device=device Creates NT matching another NT s number components shape ragged structure all dims specified - _nt_from_similar other dims assert len dims == other dim assert dims == - dims == other size ret_sizes = t other unbind other_size = t shape ret_size = i d enumerate dims d == - ret_size append other_size i ret_size append d ret_sizes append ret_size torch nested nested_tensor torch randn size size ret_sizes device=other device allowVmapFallbackUsage test_fallback_unary device f x x sin + nt = _create_nt None device=device _vmap_test f nt allowVmapFallbackUsage test_fallback_binary device f x y x y x = _create_nt None device=device y = _create_nt None device=device _vmap_test f x y allowVmapFallbackUsage test_fallback_binary_nt_and_unbatched_dense device f x y x y x = _create_nt None device=device y = torch randn device=device _vmap_test f x y in_dims= None allowVmapFallbackUsage test_fallback_binary_nt_and_batched_dense device f x y x y x = _create_nt None device=device y = torch randn device=device _vmap_test f x y test_nt_acts_as_dense_in_vmap device f x assert x is_nested x x = _create_nt None device=device _vmap_test f x test_cat_batching_rule device f x y dim torch cat x y dim=dim Different nested structure same other dims x = _create_nt None device=device y = _create_nt None device=device _vmap_test functools partial f dim= x y x = _create_nt None device=device y = _create_nt None device=device _vmap_test functools partial f dim= x y Same nested structure different other dims x = _create_nt None device=device y = _nt_from_similar x - - _vmap_test functools partial f dim= x y x = _create_nt None device=device y = _nt_from_similar x - - _vmap_test functools partial f dim= x y shape calls don t work NTs TODO Fix somehow unittest expectedFailure test_shape_call device f x x shape x x = _create_nt None _vmap_test f x test_nt_with_nonzero_in_dim_raises device f x x x = _create_nt None device=device assertRaisesRegex RuntimeError Nested tensors can only vmapped over dim= vmap f in_dims= x test_nt_with_nonzero_out_dim_raises device f x x x = _create_nt None device=device assertRaisesRegex RuntimeError Nested tensors can only vmapped over dim= vmap f out_dims= x test_fallback_with_nt_and_batched_dense_with_nonzero_bdim_raises device f x y x y x = _create_nt None device=device y = torch randn device=device assertRaisesRegex RuntimeError Fallback supported mixed nested non-nested arguments without bdim= vmap f in_dims= x y test_multilevel_vmap_raises device f x x sin + x = _create_nt None device=device assertRaisesRegex RuntimeError Only one level vmap supported vmap vmap f x assertRaisesRegex RuntimeError Only one level vmap supported vmap vmap vmap f x only_for = cpu cuda instantiate_device_type_tests TestVmapOperatorsOpInfo globals only_for=only_for instantiate_device_type_tests TestVmapBatchedGradient globals only_for=only_for instantiate_device_type_tests TestTransformFailure globals only_for=only_for instantiate_device_type_tests TestRandomness globals only_for=only_for instantiate_device_type_tests TestVmapDeviceType globals only_for=only_for instantiate_device_type_tests TestVmapNestedTensor globals only_for=only_for __name__ == __main__ run_tests