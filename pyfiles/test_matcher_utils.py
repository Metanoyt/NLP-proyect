Owner s module fx os sys collections abc Callable torch torch nn functional F torch export export torch fx symbolic_trace torch fx experimental proxy_tensor make_fx pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir unittest torch fx passes utils matcher_utils SubgraphMatcher torch fx passes utils matcher_with_name_node_map_utils SubgraphMatcherWithNameNodeMap torch testing _internal common_utils IS_WINDOWS torch testing _internal jit_utils JitTestCase WrapperModule torch nn Module __init__ fn Callable super __init__ fn = fn forward args kwargs fn args kwargs TestMatcher JitTestCase test_subgraph_matcher_with_attributes LargeModel torch nn Module __init__ - None super __init__ _weight = torch nn Parameter torch ones _bias = torch nn Parameter torch ones forward x torch ops aten addmm default _bias x _weight Large Model graph opcode name target args kwargs ------------- ------------- ------------------ ------------------- -------- placeholder x x get_attr _bias _bias get_attr _weight _weight call_function addmm_default aten addmm default _bias x _weight output output output addmm_default large_model_graph = symbolic_trace LargeModel graph PatternModel torch nn Module __init__ - None super __init__ _weight_ = torch nn Parameter torch ones _bias_ = torch nn Parameter torch ones forward x torch ops aten addmm default _bias_ x _weight_ pattern_graph = torch fx symbolic_trace PatternModel graph subgraph_matcher = SubgraphMatcher pattern_graph match_result = subgraph_matcher match large_model_graph assertEqual len match_result test_subgraph_matcher_with_list original x y torch ops aten view x y shape original_graph = torch fx symbolic_trace original graph pattern x y z torch ops aten view x z y shape pattern_graph = torch fx symbolic_trace pattern graph subgraph_matcher = SubgraphMatcher pattern_graph match_result = subgraph_matcher match original_graph assertEqual len match_result test_subgraph_matcher_with_list_bad original x y torch ops aten _reshape_alias_copy default x y shape y shape y shape original_graph = torch fx symbolic_trace original graph pattern x y b torch ops aten _reshape_alias_copy default x b y shape y shape y shape pattern_graph = torch fx symbolic_trace pattern graph subgraph_matcher = SubgraphMatcher pattern_graph match_result = subgraph_matcher match original_graph assertEqual len match_result test_subgraph_matcher_ignore_literals original x x + original_graph = make_fx original torch ones graph original_graph eliminate_dead_code pattern x x + pattern_graph = make_fx pattern torch ones graph pattern_graph eliminate_dead_code subgraph_matcher = SubgraphMatcher pattern_graph match_result = subgraph_matcher match original_graph assertEqual len match_result subgraph_matcher = SubgraphMatcher pattern_graph ignore_literals=True match_result = subgraph_matcher match original_graph assertEqual len match_result test_variatic_arg_matching inputs = torch randn maxpool x kernel_size stride padding dilation torch ops aten max_pool d_with_indices default x kernel_size stride padding dilation maxpool_graph = torch fx symbolic_trace maxpool graph maxpool_matcher = SubgraphMatcher maxpool_graph match_result = maxpool_matcher match maxpool_graph assertEqual len match_result Graph only contains stride argument maxpool_s = torch nn MaxPool d kernel_size= stride= eval maxpool_s_graph = make_fx maxpool_s inputs graph match_s_result = maxpool_matcher match maxpool_s_graph assertEqual len match_s_result Graph only contains padding argument maxpool_p = torch nn MaxPool d kernel_size= padding= maxpool_p_graph = make_fx maxpool_p inputs graph match_p_result = maxpool_matcher match maxpool_p_graph assertEqual len match_p_result Graph only contains stride padding argument maxpool_sp = torch nn MaxPool d kernel_size= stride= padding= maxpool_sp_graph = make_fx maxpool_sp inputs graph match_sp_result = maxpool_matcher match maxpool_sp_graph assertEqual len match_sp_result unittest skipIf IS_WINDOWS Windows yet supported torch compile test_split_to_graph_and_name_node_map Testing internal helper function splitting pattern graph torch fx passes utils matcher_with_name_node_map_utils _split_to_graph_and_name_node_map pattern x weight conv = F conv d x weight relu = F relu conv relu_mul_by_two = relu relu relu_mul_by_two conv conv relu relu example_inputs = torch randn torch randn pattern_gm = export WrapperModule pattern example_inputs strict=True module before_split_res = pattern_gm example_inputs pattern_gm _ = _split_to_graph_and_name_node_map pattern_gm after_split_res = pattern_gm example_inputs assertEqual before_split_res after_split_res assertEqual before_split_res after_split_res unittest skipIf IS_WINDOWS Windows yet supported torch compile test_matcher_with_name_node_map_function Testing SubgraphMatcherWithNameNodeMap function pattern target_graph x weight x = x weight = weight conv = F conv d x weight relu = F relu conv relu = relu relu + relu pattern x weight conv = F conv d x weight relu = F relu conv relu_mul_by_two = relu relu relu_mul_by_two conv conv relu relu example_inputs = torch randn torch randn pattern_gm = export WrapperModule pattern example_inputs strict=True module matcher = SubgraphMatcherWithNameNodeMap pattern_gm target_gm = export WrapperModule target_graph example_inputs strict=True module internal_matches = matcher match target_gm graph internal_match internal_matches name_node_map = internal_match name_node_map assert conv name_node_map assert relu name_node_map name_node_map conv meta custom_annotation = annotation check we correctly annotated target graph module n target_gm graph nodes n == name_node_map conv assert custom_annotation n meta n meta custom_annotation == annotation unittest skipIf IS_WINDOWS Windows yet supported torch compile test_matcher_with_name_node_map_module Testing SubgraphMatcherWithNameNodeMap module pattern M torch nn Module __init__ - None super __init__ linear = torch nn Linear forward x linear x Pattern torch nn Module __init__ - None super __init__ linear = torch nn Linear forward x linear = linear x Note we can t put weight linear weight dictionary since nn Parameter allowed output type dynamo linear linear linear x x example_inputs = torch randn pattern_gm = export Pattern example_inputs strict=True module matcher = SubgraphMatcherWithNameNodeMap pattern_gm target_gm = export M example_inputs strict=True module internal_matches = matcher match target_gm graph internal_match internal_matches name_node_map = internal_match name_node_map assert linear name_node_map assert x name_node_map name_node_map linear meta custom_annotation = annotation check we correctly annotated target graph module n target_gm graph nodes n == name_node_map linear assert custom_annotation n meta n meta custom_annotation == annotation __name__ == __main__ raise RuntimeError This test currently used should enabled discover_tests py required