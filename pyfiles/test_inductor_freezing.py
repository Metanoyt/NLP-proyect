Owner s module inductor contextlib copy functools importlib itertools os sys unittest weakref torch torch nn torch _dynamo utils counters torch _inductor config torch _inductor test_case TestCase InductorTestCase torch _inductor utils override_lowering run_and_get_code torch testing FileCheck torch testing _internal common_cuda SM OrLater tf _on_and_off torch testing _internal common_utils IS_FBCODE skipIfRocm skipIfXpu TEST_WITH_SLOW_GRADCHECK Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir inductor test_torchinductor manual=fbcode caffe test inductor test_inductor-library check_model check_model_gpu copy_tests torch testing _internal common_utils TEST_WITH_ROCM importlib import_module functorch importlib import_module filelock torch testing _internal inductor_utils GPU_TYPE HAS_CPU HAS_GPU requires_gpu aten = torch ops aten prims = torch ops prims TestCase InductorTestCase classmethod setUpClass cls super setUpClass cls _stack = contextlib ExitStack cls _stack enter_context config patch debug True cpp min_chunk_size triton autotune_pointwise False too slow implicit_fallbacks False freezing True freezing_discard_parameters True classmethod tearDownClass cls cls _stack close super tearDownClass setUp torch _dynamo reset super setUp tearDown super tearDown torch _dynamo reset ConvBN torch nn Module __init__ in_channels out_channels bias=False kwargs super __init__ conv = torch nn Conv d in_channels out_channels bias=bias kwargs bn = torch nn BatchNorm d out_channels eps= dtype=torch float forward x bn conv x ConvBNHardswish torch nn Module __init__ in_channels out_channels bias=False kwargs super __init__ conv = torch nn Conv d in_channels out_channels bias=bias kwargs bn = torch nn BatchNorm d out_channels eps= dtype=torch float hardswish = nn Hardswish inplace=True forward x hardswish bn conv x ConvFunctionalBN torch nn Module __init__ in_channels out_channels bias=False kernel_size= stride= running_mean=None running_var=None weight=None bn_bias=None super __init__ conv = torch nn Conv d in_channels out_channels bias=bias kernel_size=kernel_size stride=stride running_mean = running_mean running_var = running_var weight = weight bias = bn_bias forward x torch nn functional batch_norm conv x running_mean running_var weight bias False e- ConvMultiBN torch nn Module __init__ in_channels out_channels bias=False kwargs super __init__ conv = torch nn Conv d in_channels out_channels bias=bias kwargs bn = torch nn BatchNorm d out_channels eps= dtype=torch float bn = torch nn BatchNorm d out_channels eps= dtype=torch float forward x tmp = bn conv x tmp = bn conv x tmp + tmp ConvMultiFunctionalBN torch nn Module __init__ in_channels out_channels bias=False kernel_size= stride= running_mean=None running_var=None weight=None bn_bias=None running_mean =None super __init__ conv = torch nn Conv d in_channels out_channels bias=bias kernel_size=kernel_size stride=stride running_mean = running_mean running_var = running_var weight = weight bias = bn_bias running_mean = running_mean forward x tmp = torch nn functional batch_norm conv x running_mean running_var weight bias False e- tmp = torch nn functional batch_norm conv x running_mean running_var weight bias False e- tmp + tmp OptimizeForInferenceTemplate TestCase test_mutation Mod torch nn Module __init__ - None super __init__ mutated_param = torch nn Parameter torch zeros forward mutated_param add_ mutated_param torch no_grad mod = Mod device out_eager = mod out_eager = mod mod = Mod device torch compile foo mod mod out_comp = foo mod out_comp = foo mod assertEqual out_eager out_comp assertEqual out_eager out_comp test_aliased_param_return Mod torch nn Module __init__ - None super __init__ aliased_param = torch nn Parameter torch zeros forward aliased_param aliased_param mod = Mod device eval torch compile foo mod mod torch no_grad mod_eager = mod assertEqual foo mod mod_eager test_autocast device == cpu raise unittest SkipTest MLKDNN Bug mod = torch nn Linear device eval inp = torch rand device torch half torch compile foo mod inp mod inp torch no_grad torch autocast device out_eager = mod inp out_compiled code = run_and_get_code foo mod inp FileCheck check_not triton jit run code assertEqual out_eager out_compiled torch _inductor config patch cpp enable_concat_linear True test_mm_concat MM torch nn Module __init__ - None super __init__ t = torch nn Parameter torch rand t = torch nn Parameter torch rand t = torch nn Parameter torch rand forward x x t x t x t MM torch nn Module __init__ - None super __init__ t = torch nn Parameter torch rand t = torch nn Parameter torch rand forward x x t x t AddMM MM __init__ - None super __init__ b = torch nn Parameter torch rand b = torch nn Parameter torch rand b = torch nn Parameter torch rand forward x aten addmm b x p b p b t b t b t mod_fn lambda MM device lambda MM device lambda AddMM device mod = mod_fn inp = torch rand device torch compile foo mod inp mod inp kernel_invoke = kernel_cpp_ device == cpu triton jit mm_invoke = mm https github com pytorch pytorch blob e d b e c d db dc c torch _inductor fx_passes mkldnn_fusion py#L mkldnn_weight_pack_init = torch backends mkldnn enabled torch backends mkldnn is_available device == cpu mkldnn_weight_pack_init torch ops mkldnn _is_mkldnn_acl_supported aarch acl supported use mkldnn weight prepack https github com pytorch pytorch blob e d b e c d db dc c torch _inductor fx_passes mkldnn_fusion py#L -L mm_invoke = mkldnn _linear_pointwise default torch _C has_mkl mm_invoke = mkl_linear default torch no_grad out_eager = mod inp out code = run_and_get_code foo mod inp FileCheck check_not kernel_invoke check_count mm_invoke count= exactly=True run code assertEqual out_eager out mod = mod_fn mod t = torch nn Parameter torch rand device=self device mod t = torch nn Parameter torch rand device=self device hasattr mod b mod b = torch nn Parameter torch rand device=self device mod b = torch nn Parameter torch rand device=self device fused count = hasattr mod t torch no_grad out_eager = mod inp out code = run_and_get_code foo mod inp FileCheck check_not kernel_invoke check_count mm_invoke count=count exactly=True run code assertEqual out_eager out With inlining inbuilt nn modules Dynamo traces innards inbuilt module does modify eager module torch _dynamo config patch inline_inbuilt_nn_modules=False test_error_on_eager mod = ConvBN kernel_size= stride= eval device x = torch rand device torch compile foo mod x mod x torch no_grad foo mod x assertRaisesRegex RuntimeError Trying run Pytorch Eager Module after Dynamo Freezing mod x test_static_indices_cudagraph device = cuda mod = torch nn Sequential torch nn Linear device torch nn Linear device mod = copy deepcopy mod fn x y mod x add_ getattr mod bias add_ getattr mod weight add_ mod x + y x = torch randn device=self device y = torch randn device=self device x = x clone y = y clone opt_fn = torch compile fn mode= reduce-overhead torch no_grad ref = fn x y mod res = opt_fn x y mod assertEqual ref res assertEqual x x assertEqual y y test_rng_op torch compile foo torch rand device=self device + torch no_grad o = foo o = foo assertNotEqual o o test_symint_not_folded fn cos torch zeros shape shape fn_opt = torch compile fn backend= inductor dynamic=True inp = torch randn device torch _dynamo mark_dynamic inp torch _dynamo mark_dynamic inp torch no_grad assertEqual fn inp fn_opt inp inp = torch randn device torch _dynamo mark_dynamic inp torch _dynamo mark_dynamic inp assertEqual fn inp fn_opt inp requires_gpu test_conv_multiple_uses torch nn ToyModel nn Module __init__ args kwargs - None super __init__ args kwargs conv = nn Conv d bn = nn BatchNorm d bn weight data normal_ forward x y conv x + bn conv y model = ToyModel model eval GPU_TYPE = torch rand GPU_TYPE b = torch rand GPU_TYPE output = model b torch no_grad output = torch compile model b assertEqual output output test_unfolded_bn x = torch rand device mod = torch nn BatchNorm d eps= eval device torch compile foo mod x mod x + out_compiled_no_inference = foo mod x would error decomposed torch no_grad out_compiled = foo mod x assertEqual out_compiled_no_inference out_compiled torch _inductor config patch layout_optimization=False test_folded_conv_bn use_bias dtype itertools product True False torch float torch bfloat torch float device == cpu dtype == torch float continue device == GPU_TYPE dtype == torch bfloat SM OrLater continue mod = ConvBN bias=use_bias kernel_size= stride= eval device dtype x = torch rand device dtype torch _dynamo reset counters clear torch compile foo mod x mod x TODO - bias separate kernel right now we should only unfuse conv can fused torch no_grad out_eager = mod x out_optimized_for_infernece code = run_and_get_code foo mod x we unfuse conv bias should only have one constant kernel device == cuda FileCheck check_not run check conv check run check_same frozen_param check_not frozen_param check_next run code assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- assertEqual counters inductor binary_folding torch _inductor config patch layout_optimization=False test_folded_conv_bn_hardswish use_bias dtype itertools product True False torch float torch bfloat torch float device == cpu dtype == torch float continue device == GPU_TYPE dtype == torch bfloat SM OrLater continue mod = ConvBNHardswish bias=use_bias kernel_size= stride= eval device dtype x = torch rand device dtype torch _dynamo reset counters clear torch compile foo mod x mod x TODO - bias separate kernel right now we should only unfuse conv can fused torch no_grad out_eager = mod x out_optimized_for_infernece code = run_and_get_code foo mod x we unfuse conv bias should only have one constant kernel device == cuda FileCheck check_not run check conv check run check_same frozen_param check_not frozen_param check_next run code assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- assertEqual counters inductor binary_folding torch _inductor config patch layout_optimization=False test_folded_conv_bn_with_module_sharing mod = ConvBN bias=True kernel_size= stride= device torch float Update default parameters BN module _ range mod torch rand device torch float mod eval x = torch rand device torch float foo mod x mod x mod x torch no_grad out_eager = foo mod x out_optimized_for_infernece _ = run_and_get_code torch compile foo mod x assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- torch _inductor config patch layout_optimization=False test_folded_conv_functional_bn_with_module_sharing x = torch rand device torch float running_mean = torch mean x dim= device running_var = torch var x dim= device mod = ConvFunctionalBN bias=True kernel_size= stride= running_mean=running_mean running_var=running_var weight=torch ones device bn_bias=torch zeros device eval device torch float foo mod x mod x mod x torch no_grad out_eager = foo mod x out_optimized_for_infernece _ = run_and_get_code torch compile foo mod x assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- torch _inductor config patch layout_optimization=False test_conv_bn_with_multi_bn_share_conv mod = ConvMultiBN bias=True kernel_size= stride= device torch float Update default parameters BN module _ range mod torch rand device torch float mod eval x = torch rand device torch float foo mod x mod x torch no_grad out_eager = foo mod x out_optimized_for_infernece _ = run_and_get_code torch compile foo mod x assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- torch _inductor config patch layout_optimization=False test_conv_functional_bn_with_multi_bn_share_conv x = torch rand device torch float running_mean = torch mean x dim= device running_var = torch var x dim= device running_mean = torch mean x dim= device mod = ConvMultiFunctionalBN bias=True kernel_size= stride= running_mean=running_mean running_var=running_var weight=torch ones device bn_bias=torch zeros device running_mean =running_mean eval device torch float foo mod x mod x torch no_grad out_eager = foo mod x out_optimized_for_infernece _ = run_and_get_code torch compile foo mod x assertEqual out_optimized_for_infernece out_eager atol= e- rtol= e- torch _inductor config patch layout_optimization=False test_dont_change_dtype_folding dtype = torch float device == GPU_TYPE torch bfloat mod = torch nn Conv d bias=None kernel_size= stride= eval device dtype x = torch rand device dtype foo mod x mod x torch full device=self device foo_c = torch compile foo torch no_grad out_eager = foo mod x out_compiled = foo_c mod x assertEqual out_eager out_compiled test_param_deallocated TODO cpu path keeps extra copy graph around somewhere memory important cpu device == cpu raise unittest SkipTest NYI CPU Mod torch nn Module __init__ - None super __init__ param = torch nn Parameter torch zeros forward x param + + x mod = Mod eval device inp = torch rand device=self device torch no_grad eager = mod inp weight_ref = weakref ref mod param torch compile foo mod inp mod inp torch no_grad compiled = foo mod inp assertEqual eager compiled assertTrue weight_ref None test_conv_with_as_strided Model nn Module __init__ groups super __init__ kv = torch nn Conv d kernel_size= stride= bias=False groups=groups forward x convolution = kv x constant_pad_nd = torch ops aten constant_pad_nd default convolution as_strided inputs depend input s size stide as_strided = torch ops aten as_strided default constant_pad_nd as_strided_ = torch ops aten as_strided default as_strided clone = torch ops aten clone default as_strided_ memory_format=torch contiguous_format clone torch compile foo mod inp mod inp torch no_grad x = torch randn device groups mod = Model groups device eval mod_eager = mod x assertEqual foo mod x mod_eager skipIfXpu unittest skipIf IS_FBCODE Not yet runnable fbcode unittest skipIf TEST_WITH_SLOW_GRADCHECK Failing slow gradcheck cuda see https github com pytorch pytorch pull example test_cpp_wrapper mod = ConvBN kernel_size= stride= eval device x = torch rand device torch compile options= cpp_wrapper True foo mod x mod x out_eager = mod x torch no_grad assertEqual foo mod x out_eager assertEqual foo mod x out_eager tf _on_and_off test_conv_layout_convert_with_view Model torch nn Module __init__ - None super __init__ conv = nn Conv d kernel_size= padding= stride= bias=False bn = nn BatchNorm d forward x x = bn x x = conv x torch flatten x mod = Model device eval torch compile foo mod inp mod inp torch no_grad x = torch rand device mod_eager = mod x assertEqual foo mod x mod_eager skipIfRocm test_conv_weight_layout_convert Model torch nn Module __init__ - None super __init__ conv = nn Conv d kernel_size= padding= stride= bias=False forward x conv x staticmethod get_example_inputs torch rand device torch _inductor compile_fx compile_fx compile_fx_inner nconv = my_inner_compile gm example_inputs args kwargs out = compile_fx_inner gm example_inputs args kwargs nonlocal nconv convs = n n gm graph nodes n target == aten convolution default nconv += len convs conv convs weight_node = conv args weight_const_tensor = getattr gm weight_node target assertTrue weight_const_tensor is_contiguous memory_format=torch channels_last assertTrue weight_node meta val is_contiguous memory_format=torch channels_last out mod = torch compile Model eval device backend=functools partial compile_fx inner_compile=my_inner_compile inp = mod get_example_inputs torch no_grad mod inp Only check assertion CUDA For CPU we may get torch ops mkldnn _convolution_pointwise default joint graph rather than torch ops aten convolution default Currently we only handle aten convolution default layout optimization That s why count may here CPU device == cuda assertTrue nconv == test_unequal_bias_horizontal_addmm_fusion device = device Model torch nn Module __init__ - None super __init__ w = torch tensor device=device b = torch zeros device=device w = torch tensor device=device b = torch tensor - - - device=device w = torch tensor device=device b = torch tensor device=device forward x out = torch nn functional linear x w b out = torch nn functional linear x w b out = torch nn functional linear x w b out out out func = Model device eval x = torch tensor device=device torch no_grad out_eager = func x clone func = torch compile func out_compiled = func x clone assertEqual out_eager out_compiled skipIfRocm tf _on_and_off test_redundant_clone_for_layout_convert Model torch nn Module __init__ - None super __init__ conv = nn Conv d kernel_size= padding= stride= bias=False forward x y = x + conv x y staticmethod get_example_inputs torch rand device mod = Model eval device inp = mod get_example_inputs torch no_grad expected_outputs = mod inp num_same_stride = num_diff_stride = debug_inductor_force_stride_order orig_fn input_tensor stride nonlocal num_same_stride num_diff_stride input_tensor realize tuple input_tensor get_stride == tuple stride num_same_stride += num_diff_stride += orig_fn input_tensor stride override_lowering prims inductor_force_stride_order default debug_inductor_force_stride_order opt_mod = torch compile mod torch no_grad actual_outputs = opt_mod inp assertEqual len actual_outputs len expected_outputs assertEqual len actual_outputs actual expected zip actual_outputs expected_outputs assertEqual expected actual device == cpu CPU use different convolution implementation skip checks below assertTrue actual_outputs is_contiguous memory_format=torch contiguous_format assertTrue actual_outputs is_contiguous memory_format=torch contiguous_format we don t change stride y returned forward So there will no extra copy assertTrue num_same_stride == f num_same_stride num_same_stride we changed stride conv x returned forward So there may extra copy assertTrue num_diff_stride == f num_diff_stride num_diff_stride TEST_WITH_ROCM torch _inductor config force_layout_optimization = os environ PYTORCH_MIOPEN_SUGGEST_NHWC = HAS_CPU torch backends mps is_available FreezingCpuTests TestCase common = check_model device = cpu autocast = torch cpu amp autocast copy_tests OptimizeForInferenceTemplate FreezingCpuTests cpu HAS_GPU FreezingGpuTests TestCase common = check_model_gpu device = GPU_TYPE copy_tests OptimizeForInferenceTemplate FreezingGpuTests GPU_TYPE del OptimizeForInferenceTemplate __name__ == __main__ torch _inductor test_case run_tests HAS_CPU HAS_GPU run_tests needs= filelock