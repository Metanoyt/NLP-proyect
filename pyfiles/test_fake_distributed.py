Owner s module dynamo unittest skipIf torch torch distributed dist torch _dynamo test_case TestCase DynamoTestCase torch _dynamo testing AotEagerAndRecordGraphs normalize_gm torch testing _internal common_utils instantiate_parametrized_tests dist is_available torch distributed _functional_collectives all_to_all_single_autograd wait_tensor torch distributed device_mesh init_device_mesh normalize_graph gm normalize_gm gm print_readable print_output=False skipIf dist is_available requires distributed TestFakeDistributed DynamoTestCase setUp Use FakeProcessGroup run tests single process dist init_process_group backend= fake rank= world_size= local_rank = world_size = tearDown dist destroy_process_group test_all_to_all_single_autograd backend = AotEagerAndRecordGraphs torch compile fullgraph=True backend=backend fn x all_to_all_single_autograd x None Will use equal splits None Will use equal splits group=dist group WORLD Test backed shapes x = torch randn requires_grad=True torch _dynamo mark_dynamic x torch _dynamo mark_dynamic x wait_tensor fn x assertEqual len backend fw_graphs assertEqual len backend bw_graphs assertExpectedInline normalize_graph backend fw_graphs \ GraphModule torch nn Module forward primals_ Sym s primals_ Sym s primals_ f s s floordiv Sym s = primals_ all_to_all_single f s s = torch ops _c d_functional all_to_all_single default primals_ floordiv floordiv floordiv floordiv primals_ = None wait_tensor f s s = torch ops _c d_functional wait_tensor default all_to_all_single all_to_all_single = None wait_tensor primals_ primals_ floordiv noqa B assertExpectedInline normalize_graph backend bw_graphs \ GraphModule torch nn Module forward primals_ Sym s primals_ Sym s floordiv Sym s tangents_ f s s all_to_all_single_ f s s = torch ops _c d_functional all_to_all_single default tangents_ floordiv floordiv floordiv floordiv tangents_ = floordiv = None wait_tensor_ f s s = torch ops _c d_functional wait_tensor default all_to_all_single_ all_to_all_single_ = None None None wait_tensor_ noqa B backend fw_graphs clear backend bw_graphs clear Test unbacked shapes x = torch randn requires_grad=True torch _dynamo decorators mark_unbacked x torch _dynamo decorators mark_unbacked x torch _dynamo decorators mark_unbacked x wait_tensor fn x assertEqual len backend fw_graphs assertEqual len backend bw_graphs assertExpectedInline normalize_graph backend fw_graphs \ GraphModule torch nn Module forward primals_ Sym u primals_ Sym u primals_ Sym u primals_ f u u u ge_ Sym u = = primals_ = _assert_scalar = torch ops aten _assert_scalar default ge_ Runtime assertion failed expression u = node ge ge_ = _assert_scalar = None ge_ Sym u = = primals_ = _assert_scalar_ = torch ops aten _assert_scalar default ge_ Runtime assertion failed expression u = node ge_ ge_ = _assert_scalar_ = None ge_ Sym u = = primals_ = _assert_scalar_ = torch ops aten _assert_scalar default ge_ Runtime assertion failed expression u = node ge_ ge_ = _assert_scalar_ = None floordiv Sym u = primals_ all_to_all_single f u u u = torch ops _c d_functional all_to_all_single default primals_ floordiv floordiv floordiv floordiv primals_ = None wait_tensor f u u u = torch ops _c d_functional wait_tensor default all_to_all_single all_to_all_single = None wait_tensor primals_ primals_ primals_ floordiv noqa B assertExpectedInline normalize_graph backend bw_graphs \ GraphModule torch nn Module forward primals_ Sym u primals_ Sym u primals_ Sym u floordiv Sym u tangents_ f u u u all_to_all_single_ f u u u = torch ops _c d_functional all_to_all_single default tangents_ floordiv floordiv floordiv floordiv tangents_ = floordiv = None wait_tensor_ f u u u = torch ops _c d_functional wait_tensor default all_to_all_single_ all_to_all_single_ = None None None None wait_tensor_ noqa B test_device_mesh_get_local_rank device_mesh = init_device_mesh device_type= cpu mesh_shape= world_size mesh_dim_names= dp data parallel dimension torch compile backend= eager fullgraph=True fn x local_rank = device_mesh get_local_rank global_rank = device_mesh get_rank dp device_mesh mesh_dim_names x = x x + local_rank + global_rank x = torch ones res = fn x assertEqual res x instantiate_parametrized_tests TestFakeDistributed __name__ == __main__ torch _dynamo test_case run_tests run_tests