mypy allow-untyped-defs __future__ annotations dataclasses functools itertools logging re collections defaultdict math inf typing Any Callable cast Optional TYPE_CHECKING Union sympy torch torch _logging _prims_common is_integer_dtype utils _ordered_set OrderedSet utils _sympy functions FloorDiv ModularIndexing utils _sympy symbol symbol_is_type SymT utils _sympy value_ranges ValueRanges config ir codecache HalideCodeCache ir get_reduction_combine_fn metrics is_metric_table_enabled log_kernel_metadata ops_handler AddParenHandler runtime hints HalideInputSpec HalideMeta utils get_bounds_index_expr get_kernel_metadata parallel_num_threads sympy_index_symbol sympy_subs virtualized _ops ops V common BackendFeature CSEVariable DeferredLine IndentedBuffer KernelArgType OpOverrides PythonPrinter SizeArg TensorArg cpp DTYPE_TO_CPP cpp_utils cexpr simd constant_repr SIMDKernel SIMDScheduling TYPE_CHECKING collections abc Sequence ops_handler ReductionType StoreMode shape_propagation BlockShapeType log = logging getLogger __name__ halide_constant val isinstance val int - = val = info = torch iinfo torch int val == info min hl Int min val == info max hl Int max f hl i val r isinstance val float f hl f constant_repr val repr val Unsupported RuntimeError __init__ thing - None super __init__ f halide backend does support thing HalidePrinter PythonPrinter staticmethod cast_index expr f hl cast V kernel index_dtype expr staticmethod cast_float expr f hl cast hl Float expr _print_Float expr f hl f expr _print_ToFloat expr assert len expr args == f hl f _print expr args _print_floor expr assert len expr args == cast_index f hl floor _print expr args _print_FloorToInt = _print_floor _print_Trunc expr assert len expr args == cast_index f hl trunc _print expr args _print_TruncToInt = _print_Trunc _print_ceiling expr assert len expr args == cast_index f hl ceil _print expr args _helper_sqrt expr f hl sqrt cast_float _print expr _print_Where expr c = doprint expr args p = doprint expr args q = doprint expr args f hl select c p q _print_Min expr len expr args == _print expr args mid = len expr args = _print sympy Min expr args mid b = _print sympy Min expr args mid f hl min b _print_Max expr len expr args == _print expr args mid = len expr args = _print sympy Max expr args mid b = _print sympy Max expr args mid f hl max b _print_Abs expr assert len expr args == cast_index f hl abs _print expr args _print_OpaqueUnaryFn_cos expr assert len expr args == f hl cos _print expr args _print_OpaqueUnaryFn_cosh expr assert len expr args == f hl cosh _print expr args _print_OpaqueUnaryFn_acos expr assert len expr args == f hl acos _print expr args _print_OpaqueUnaryFn_sin expr assert len expr args == f hl sin _print expr args _print_OpaqueUnaryFn_sinh expr assert len expr args == f hl sinh _print expr args _print_OpaqueUnaryFn_asin expr assert len expr args == f hl asin _print expr args _print_OpaqueUnaryFn_tan expr assert len expr args == f hl tan _print expr args _print_OpaqueUnaryFn_tanh expr assert len expr args == f hl tanh _print expr args _print_OpaqueUnaryFn_atan expr assert len expr args == f hl atan _print expr args _print_OpaqueUnaryFn_log expr raise NotImplementedError log _print_FloorDiv expr expr is_integer super _print_FloorDiv expr x div = expr args x = cast_float doprint x div = cast_float doprint div cast_index f hl floor x div _print_Round expr assert len expr args == cast_index f hl round _print expr args _print_RoundToInt = _print_Round _print_IntTrueDiv expr b = expr args force cast float f b +hl f _print_RoundDecimal expr val n = expr args val = _print val n = int n f hl f -n r hl round val hl f n r texpr = HalidePrinter doprint pexpr = PythonPrinter doprint _halide_type = torch bool hl Bool torch bfloat hl BFloat torch float hl Float torch float hl Float torch float hl Float torch int hl Int torch int hl Int torch int hl Int torch int hl Int torch uint hl UInt torch uint hl UInt torch uint hl UInt torch uint hl UInt halide_type dtype _halide_type dtype halide_acc_type dtype is_integer_dtype dtype dtype is_signed dtype = torch int dtype = torch int dtype torch float torch bfloat dtype = torch float halide_type dtype HalideOverrides OpOverrides staticmethod to_dtype x dtype torch dtype src_dtype Optional torch dtype = None use_compute_types=True dtype == torch bool f x = f hl cast halide_type dtype x staticmethod to_dtype_bitcast x dtype torch dtype src_dtype torch dtype src_dtype torch float torch bfloat x = f hl cast halide_type src_dtype x body compute upcast fp line = f hl reinterpret halide_type dtype x dtype torch float torch bfloat line = f hl cast hl Float line line classmethod constant cls value dtype cls to_dtype halide_constant value dtype staticmethod abs x f hl abs x staticmethod exp x hasattr x name f hl exp x f hl fast_exp hl cast hl Float x x name type bits = hl exp x staticmethod sqrt x f hl sqrt x staticmethod minimum b f hl min b == handles nan wrong hasattr name f hl min b b = f hl cast name type b f hl select b &#124; hl is_nan b name type is_float hl min b staticmethod maximum b f hl max b == handles nan wrong hasattr name f hl max b b = f hl cast name type b f hl select b &#124; hl is_nan b name type is_float hl max b staticmethod where b c hasattr b name c = f hl cast b name type c f hl select b c staticmethod cos x f hl cos x staticmethod sin x f hl sin x staticmethod lgamma x raise Unsupported lgamma staticmethod erf x f hl erf x staticmethod cosh x f hl cosh x staticmethod sinh x f hl sinh x staticmethod acos x f hl acos x staticmethod acosh x f hl acosh x staticmethod asin x f hl asin x staticmethod asinh x f hl asinh x staticmethod atan x y f hl atan x y staticmethod atan x f hl atan x staticmethod atanh x f hl atanh x staticmethod copysign x y raise Unsupported copysign staticmethod erfinv x raise Unsupported erfinv staticmethod hypot x y f hl hypot x y staticmethod nextafter x y raise Unsupported nextafter staticmethod logical_and b f b staticmethod logical_not f == staticmethod logical_or b f &#124; b staticmethod logical_xor b f ^ b staticmethod bitwise_and b f b staticmethod bitwise_not f ~ staticmethod bitwise_or b f &#124; b staticmethod bitwise_xor b f ^ b staticmethod bitwise_left_shift b f b staticmethod bitwise_right_shift b f b staticmethod rand seed offset f halide_helpers rand seed offset staticmethod randn seed offset f halide_helpers randn seed offset staticmethod randint seed offset low high f halide_helpers randint seed offset low high staticmethod load_seed name offset f ops load name + V kernel args seed_offset load_seed_offset offset staticmethod rsqrt x f hl fast_inverse_sqrt x == accuracy issues f hl sqrt x staticmethod tan x f hl tan x staticmethod tanh x f hl tanh x staticmethod signbit x f hl reinterpret hl UInt hl cast hl Float x = staticmethod fmod b TODO jansel find better way do builtin has wrong sign f - hl trunc b b staticmethod pow b f hl pow b hl fast_pow fails accuracy staticmethod log x f hl log x hl fast_log fails accuracy staticmethod log x raise NotImplementedError log staticmethod isinf x workaround https github com halide Halide issues f hl is_inf hl cast hl Float x staticmethod isnan x workaround https github com halide Halide issues f hl is_nan hl cast hl Float x staticmethod round x f hl round x staticmethod floor x f hl floor x staticmethod int_truediv b f b + hl f staticmethod floordiv b TODO jansel find better ways do select-based trick triton py didn t work f hl floor hl cast hl Float max name type bits b classmethod sign cls x left = ops to_dtype ops lt x torch int right = ops to_dtype ops lt x torch int sub = ops sub left right f hl cast x name type sub staticmethod trunc x f hl trunc x staticmethod truncdiv b causes crashes floating point exception see test_div_zero_dim_cpu f hl div_round_to_zero b f hl trunc hl cast hl Float max name type bits b staticmethod ceil x f hl ceil x staticmethod relu x f hl max x classmethod index_expr cls expr dtype index = V kernel prepare_indexing expr var = V kernel genfunc V kernel index_to_str index V kernel used_dims_from_index index bounds=get_bounds_index_expr expr dtype torch int torch int ops to_dtype var dtype var classmethod indirect_indexing cls index_var size check=True wrap_neg=True TODO jansel Halide only supports -bit indexing we should error overflow index_var = ops to_dtype index_var torch int index_var = ops halide_clamp index_var size check index_var indirect_indexing_size = size sympy_index_symbol str index_var classmethod halide_clamp cls value size check end = V kernel kexpr V kernel rename_indexing size - isinstance size int sympy Integer end = f hl cast value name type end Skip unsafe_promise_clamped workaround https github com halide Halide issues #issuecomment- f hl unsafe_promise_clamped value end f hl clamp value end staticmethod masked mask body other V kernel mask_loads mask other new_mask result = body result bounds is_bool other = bool other Take dtype result prevent accidental promotion other = V kernel genfunc f hl cast result name type halide_constant other bounds=ValueRanges wrap other shape=result shape TODO jansel look into removing where same places triton does ops where new_mask result other staticmethod frexp x raise NotImplementedError frexp staticmethod device_assert_async cond msg raise NotImplementedError device_assert_async staticmethod pyrefly ignore bad-override partial_accumulate name str reduction_type str value CSEVariable extra_meta dict str Any - None raise NotImplementedError HalideOverrides _initialize_pointwise_overrides halide HalideCSEVariable CSEVariable undefined_re = re compile r \b tmp\d+ \ \ \ __init__ name bounds ValueRanges Any dtype Optional torch dtype = None shape BlockShapeType = None - None super __init__ name bounds dtype shape=shape used_dims Optional list sympy Symbol = None update_on_args name args kwargs used = OrderedSet used_dims arg itertools chain args kwargs values isinstance arg HalideCSEVariable assert arg used_dims None name arg args used update arg used_dims used_dims = V kernel sort_used_dims used index_str dims len dims == f name Reversed since Halide column major f name join map str dims __str__ - str used_dims None This will get recomputed replaced codegen_kernel f name index_str used_dims subs_str replacements assert used_dims None all isinstance x sympy Expr x used_dims index_str replacements get n n n used_dims dataclasses dataclass DimensionInfo expr Optional sympy Expr size sympy Expr stride sympy Expr __init__ expr size stride - None super __init__ V graph sizevars statically_known_lt stride stride = -stride expr = -expr expr = expr size = size stride = stride index_str replacements=None zero_vars=False assert expr None expr = expr zero_vars expr == hl Var replacements replacements = replacements pyrefly ignore missing-attribute sym expr free_symbols symbol_is_type sym SymT TMP assert isinstance sym sympy Symbol var = V kernel lookup_cse_var sym name assert isinstance var HalideCSEVariable replacements sym = sympy_index_symbol var subs_str replacements expr = sympy_subs expr replacements V kernel index_to_str expr eq left right V graph sizevars statically_known_equals left right True try = V graph sizevars size_hint_or_throw left b = V graph sizevars size_hint_or_throw right except TypeError unbacked symints False == b V graph sizevars check_equals left right == b lt left right V graph sizevars statically_known_lt left right True try = V graph sizevars size_hint_or_throw left b = V graph sizevars size_hint_or_throw right except TypeError unbacked symints gcd = sympy gcd left right gcd == left left = right False b V graph sizevars check_lt left right b HalideKernel SIMDKernel overrides = HalideOverrides type ignore assignment kexpr Callable sympy Expr str = texpr __init__ tiling dict str sympy Expr kwargs - None super __init__ tiling kwargs For halide we just write directly body compute = body loads = body stores = body indexing_code_dom = IndentedBuffer needs_dom_indexing = inside_reduction has_reduction = inside_reduction buffer_dimensions dict str list DimensionInfo = buffer_offsets dict str sympy Expr = h size h size halide_vars dict sympy Symbol sympy Expr = x h x h + h index_replacements dict sympy Expr sympy Expr = h hr reduction_renames dict sympy Symbol sympy Symbol = i h hi o dom_renames dict str dict sympy Symbol sympy Symbol = in_ptr in_ptr _view buffer_aliases dict str list str = defaultdict list has_indirect_indexing = False dtype_to_str dtype torch dtype - str halide_type dtype pyrefly ignore bad-override create_cse_var name bounds=None dtype=None shape=None body writeline f name = hl Func name r pyrefly ignore bad-argument-type HalideCSEVariable name bounds dtype shape finalize_indexing indices Sequence sympy Expr Hook called right before codegen every index will used fused kernel This populates halide_vars index_replacements reduction_renames which alternate indexing scheme avoids using divide modulus Instead xindex yindex rindex we base indexing larger number vars whose product combines those This function populates halide_vars index_replacements reduction_renames assert index_replacements halide_vars reduction_renames size_hint = functools partial V graph sizevars size_hint fallback=inf type ignore arg-type pyrefly ignore bad-assignment indices = dict fromkeys map super prepare_indexing indices all_used_symbols = OrderedSet Any sym_to_node = n symbol n n itertools chain from_iterable tree nodes values tree range_trees simplify expr sympy simplify V graph sizevars remove_precomputed_replacements expr visit_modular_indexing base divisor modulus base sym_to_node node = sym_to_node base all_used_symbols add node root lookup node divisor divisor V graph sizevars evaluate_min modulus FloorDiv node length divisor symbol visit_floor_div base divisor base sym_to_node node = sym_to_node base all_used_symbols add node root lookup node divisor divisor FloorDiv node length divisor symbol first figure out all_used_symbols do dead symbol elimination index indices index has ModularIndexing index replace ModularIndexing sympy Wild base sympy Wild divisor sympy Wild modulus visit_modular_indexing index has FloorDiv index replace FloorDiv sympy Wild base sympy Wild divisor visit_floor_div all_used_symbols update super prepare_indexing index free_symbols has_indirect_indexing = any symbol_is_type sym SymT INDIRECT sym all_used_symbols had_fallback = False tree reversed range_trees nodes = n n tree nodes values n symbol all_used_symbols nodes sort key=lambda n size_hint n divisor nodes nodes append tree lookup tree numel handled_count = divisor = sympy S One added_sym_size = decide minimal set symbols put them halide_vars while handled_count len nodes eq tree numel divisor sizes_to_add = simplify n length n nodes eq n divisor divisor handled_count += len sizes_to_add assert sizes_to_add nodes end = divisor functools reduce V graph sizevars evaluate_max sizes_to_add sizes_to_add extend simplify n divisor divisor n nodes lt divisor n divisor lt n divisor end while sizes_to_add next_size = functools reduce sympy gcd sizes_to_add eq next_size sizes share no common factors e g TODO jansel we should just prevent fusion cases hit next_size = simplify tree numel divisor assert eq next_size sizes_to_add = handled_count = len nodes had_fallback = True sym = sympy_index_symbol f h len halide_vars pyrefly ignore missing-argument tree is_reduction reduction_renames sym = sympy_index_symbol f hr len halide_vars halide_vars sym = next_size added_sym_size append sym next_size divisor = next_size new_sizes = n length n nodes eq n divisor divisor handled_count += len new_sizes prior_len = len sizes_to_add sizes_to_add = sympy simplify s next_size s sizes_to_add eq s next_size assert len sizes_to_add prior_len prior_len == sizes_to_add extend new_sizes create mapping new set symbols index_replacements node nodes try idx = divisor = while eq node divisor divisor sym size = added_sym_size idx idx += divisor = size length = expr = sympy S Zero while eq node length length sym size = added_sym_size idx idx += expr += length sym length = size index_replacements node symbol = expr except IndexError assert had_fallback full_index = sympy S Zero stride = sympy S One sym size added_sym_size full_index += stride sym stride = size index_replacements node symbol = V graph sizevars simplify_with_ranges ModularIndexing full_index node divisor node length halide_vars type ignore arg-type codegen variable definitions sym halide_vars indexing_code writeline f sym = hl Var sym name r reduction_renames codegen_rdom rdom rv halide_vars v v rv reduction_renames items setup_dom_indexing RDom based indexing uses explicit iteration ranges Func updates prefix = i inside_reduction o prefix dom_renames dom_renames prefix renames = var halide_vars keys inside_reduction var reduction_renames continue m = re match r ^h \d+ $ var name assert m renames var = sympy_index_symbol f h prefix m group codegen_rdom f prefix dom rv halide_vars v v rv renames items dom_renames prefix = renames renames codegen_rdom name vars rsizes = f hl Range kexpr rename_indexing size size vars values indexing_code writeline f name = hl RDom join rsizes i rsym enumerate vars keys indexing_code writeline f rsym = name i prepare_indexing index sympy Expr index = super prepare_indexing index index = sympy_subs index index_replacements V graph sizevars simplify_with_ranges index halide_vars type ignore arg-type sym_size sym The size index symbol symbol_is_type sym SymT TMP lookup_cse_var sym name indirect_indexing_size halide_vars sym indexing_to_dimensions var str index sympy Expr is_store bool Convert address-based indexing into dimensions using halide_vars symbols = sym sorted index free_symbols key=lambda x x name type ignore attr-defined symbol_is_type sym SymT HALIDE SymT TMP symbols append sym assert symbol_is_type sym SymT UNBACKED_INT SymT SIZE SymT PRECOMPUTED_SIZE sym group expression variables used offset = sympy S Zero split_expr = dict fromkeys symbols sympy S Zero split_failed list tuple list sympy Symbol sympy Expr = index = sympy expand rename_indexing index part index args isinstance index sympy Add index part_vars = v v part free_symbols v split_expr len part_vars == offset += part len part_vars == split_expr part_vars += part new_split_failed = i range len split_failed assert split_failed i None other_vars other_part = split_failed i OrderedSet other_vars OrderedSet part_vars part_vars extend v v other_vars v part_vars part += other_part new_split_failed append other_vars other_part split_failed = new_split_failed part_vars part expr_to_dimension expr syms expr = sympy factor expr len syms == stride_wild = sympy Wild wild exclude=symbols m = expr match stride_wild syms m DimensionInfo syms sym_size syms m stride_wild assert is_store expr length = sympy simplify sympy_subs expr sym sym_size sym - sym syms + stride = sympy S One isinstance expr sympy Mul term expr args isinstance term sympy Integer stride = term expr = sympy simplify expr term length = sympy simplify sympy ceiling length term DimensionInfo expr length stride try turn each group into strided access dims = syms expr split_failed v syms expr += split_expr pop v dims append expr_to_dimension expr syms sym expr split_expr items dims append expr_to_dimension expr sym dims sort key=lambda d V graph sizevars size_hint d stride fallback=inf type ignore arg-type dims scalar load store has_indirect_indexing workaround https github com halide Halide issues dims append DimensionInfo sympy S Zero V graph sizevars statically_known_equals dims stride Halide assumes dimension stride == so add dummy dimension dims insert DimensionInfo sympy S Zero is_store dims stride dims is_store var buffer_offsets V graph sizevars statically_known_geq offset buffer_offsets var reuse existing offset avoid needing input alias apply_offset_to_dimension dims offset - buffer_offsets var offset = buffer_offsets var V graph sizevars statically_known_gt offset TODO jansel negative offsets roll offset into dimensions cleaner indexing apply_offset_to_dimension dims offset offset = orig_var = var i itertools count install_dims var dims offset is_store var dims assert is_store var = f orig_var _view i var buffer_aliases orig_var buffer_aliases orig_var append var install_dims var dims offset is_store Try set buffer_dimensions var True success var buffer_dimensions buffer_dimensions var = dims buffer_offsets var = offset True buffer_offsets var = offset len buffer_dimensions var = len dims False is_store buffer_dimensions var == dims old new zip buffer_dimensions var dims old stride = new stride False old size = new size old expr = new expr old size = V graph sizevars evaluate_max old size new size old expr = None True apply_offset_to_dimension dims offset offset == i reversed range len dims dims i stride == V graph sizevars statically_known_geq offset dims i stride part = FloorDiv offset dims i stride offset -= part dims i stride dims i expr += part assert offset == used_dims_from_index index sympy Expr Detect which range trees used populate HalideCSEVariable used_dims used_dims = OrderedSet sympy Symbol sym index free_symbols assert isinstance sym sympy Symbol symbol_is_type sym SymT TMP indirect indexing cse_var = lookup_cse_var sym name assert isinstance cse_var HalideCSEVariable cse_var used_dims None used_dims update cse_var used_dims symbol_is_type sym SymT HALIDE used_dims add sym symbol_is_type sym SymT UNBACKED_INT SymT SIZE SymT PRECOMPUTED_SIZE SymT INDEX pass raise NotImplementedError f unhandled symbol sym sort_used_dims used_dims sort_used_dims used_dims assert all isinstance x sympy Expr x used_dims ordered = sym sym itertools chain halide_vars reduction_renames values sym used_dims assert len ordered == len used_dims ordered make_index_str dims replacements=None zero_vars=False index_str = join d index_str replacements zero_vars d dims len dims == index_str = len dims == workaround https github com halide Halide issues index_str = f index_str index_str load name str index sympy Expr Codegen load InputBuffer var = args input name index = prepare_indexing index var dims = indexing_to_dimensions var index False line = f var make_index_str dims dtype = V graph get_dtype name dtype torch float torch bfloat dtype = torch float line = f hl cast hl Float line _load_mask assert isinstance _load_mask HalideCSEVariable _load_mask used_dims None used_dims = OrderedSet used_dims_from_index index _load_mask used_dims result = newfunc sort_used_dims used_dims result used_dims body writeline f result name _mask = hl RDom hl Range body writeline f result name _mask where _load_mask other = kexpr _load_other type ignore arg-type body writeline f result = hl cast halide_type dtype other body writeline f result = line + hl cast halide_type dtype result name _mask scalar case body writeline f result = hl select _load_mask line hl cast halide_type dtype result genfunc line used_dims_from_index index lookup_cse_var name str cse varname_map re sub r \ name store name str index sympy Expr value CSEVariable mode StoreMode = None - None Codegen store OutputBuffer assert isinstance value HalideCSEVariable var = args output name index = prepare_indexing index var dims = indexing_to_dimensions var index True is_indirect_indexing index mode None replacements = setup_dom_indexing index_str = make_index_str dims replacements value_str = value subs_str replacements undef_dims = join hl Var len dims body writeline DeferredLine name f var undef_dims = hl undef var type index_str = make_index_str dims zero_vars=True value_str = str value dtype = V graph get_dtype name mode None line = f var index_str = hl cast halide_type dtype value_str mode == atomic_add line = f var index_str += hl cast halide_type dtype value_str raise NotImplementedError f store mode= mode body writeline DeferredLine name line reduction dtype torch dtype src_dtype torch dtype reduction_type ReductionType value Union CSEVariable tuple CSEVariable - Union CSEVariable tuple CSEVariable Codegen reduction operation assert inside_reduction assert _load_mask cache_key = src_dtype reduction_type value cache_key cse reduction_cache cse reduction_cache cache_key isinstance value tuple assert reduction_type == welford_combine cse reduction_cache cache_key = result_tuple = welford_combine_impl value result_tuple assert isinstance value HalideCSEVariable value used_dims None reduction_vars = OrderedSet reduction_renames result_var = newfunc v v value used_dims v reduction_vars reduction_vars - OrderedSet value used_dims value = genfunc f value sort_used_dims OrderedSet value used_dims reduction_vars shape=value shape value_str = value subs_str reduction_renames default = ir Reduction default_accumulator reduction_type src_dtype acc_type = halide_acc_type dtype reduction_type argmax argmin index = f result_var name _ reduction_type body writeline f index = hl reduction_type rdom value_str turn N-D argmax index into -D one parts = stride = i sym enumerate reduction_renames pyrefly ignore bad-argument-type parts append f index i stride = pyrefly ignore unsupported-operation parts - += f stride stride = halide_vars sym body writeline f result_var = + join parts reduction_type == welford_reduce TODO jansel implement welford_reduce without fallback result_var = welford_reduce_fallback dtype value combine_fn = get_reduction_combine_fn reduction_type acc_type V set_ops_handler AddParenHandler HalideOverrides combine_str = combine_fn result_var value_str type ignore arg-type default_str = f hl cast acc_type halide_constant default body writeline f result_var = default_str body writeline f result_var = combine_str cse reduction_cache cache_key = result_var result_var welford_combine_impl mean m weight assert isinstance mean HalideCSEVariable mean used_dims None assert isinstance m HalideCSEVariable m used_dims None assert isinstance weight HalideCSEVariable weight used_dims None used_dims = OrderedSet mean used_dims m used_dims weight used_dims halide_vars used_dims -= OrderedSet reduction_renames result_var = newfunc sort_used_dims used_dims default = f hl cast x name type x mean m weight pfx = result_var name body writeline f result_var = hl Tuple join default body writeline f pfx _mean_ = result_var body writeline f pfx _m _ = result_var body writeline f pfx _weight_ = result_var body writeline f pfx _mean_ = mean subs_str reduction_renames body writeline f pfx _m _ = m subs_str reduction_renames body writeline f pfx _weight_ = weight subs_str reduction_renames body writeline f pfx _delta = pfx _mean_ - pfx _mean_ body writeline f pfx _new_weight = pfx _weight_ + pfx _weight_ body writeline f pfx _w _over_w = hl select pfx _new_weight == pfx _weight_ pfx _new_weight update = f pfx _mean_ + pfx _delta pfx _w _over_w f pfx _m _ + pfx _m _ + pfx _delta pfx _delta pfx _weight_ pfx _w _over_w f pfx _new_weight body writeline f result_var = hl Tuple join update unpacked = i range unpacked append newfunc result_var used_dims body writeline f unpacked - = result_var i tuple unpacked scan dtypes tuple torch dtype combine_fn Callable tuple CSEVariable tuple CSEVariable tuple CSEVariable values_orig tuple CSEVariable - tuple CSEVariable assert inside_reduction assert len dtypes == len values_orig values list HalideCSEVariable = all_used_dims = OrderedSet sympy Symbol value values_orig assert isinstance value HalideCSEVariable value used_dims None OrderedSet value used_dims OrderedSet reduction_renames values append value values append genfunc f value value used_dims reduction_renames shape=value shape all_used_dims update value used_dims result_var = newfunc sort_used_dims all_used_dims assert result_var used_dims OrderedSet result_var used_dims OrderedSet reduction_renames initial = f hl cast halide_acc_type dtype value dtype value zip dtypes values length = kexpr rename_indexing range_trees - numel scan_dom = f result_var name _rdom scan = f scan_dom x body writeline f scan_dom = hl RDom hl Range length assert len reduction_renames == multi-dimensional scan implemented scan_var = reduction_renames type ignore misc scan_renames_cur = scan_var sympy_index_symbol scan scan_renames_pri = scan_var sympy_index_symbol scan - len values == maybe_tuple x x read_left = result_var subs_str scan_renames_pri read_right = result_var subs_str scan_renames_cur maybe_tuple x f hl Tuple join x read_left = result_var subs_str scan_renames_pri + f i i range len values read_right = result_var subs_str scan_renames_cur + f i i range len values body writeline f result_var = maybe_tuple initial Disable CSE update fn V set_ops_handler AddParenHandler HalideOverrides combine_str = combine_fn read_left read_right type ignore arg-type body writeline f result_var subs_str scan_renames_cur = maybe_tuple combine_str len values == result_var unpack_vars = newfunc sort_used_dims all_used_dims _ values i v enumerate unpack_vars body writeline f v = result_var i tuple unpack_vars genfunc line used_dims bounds=ValueRanges unknown shape BlockShapeType = None - HalideCSEVariable var = cse generate body line bounds=bounds shape=shape assert isinstance var HalideCSEVariable var used_dims = used_dims var newfunc used_dims shape BlockShapeType = None - HalideCSEVariable var = cse newvar shape=shape assert isinstance var HalideCSEVariable var used_dims = used_dims var halide_buffer_numel name str We map all tensors D buffers Halide since Halide has trouble representing some strides PyTorch supports If there gaps underlying layout numel we pass Halide includes gaps while PyTorch s numel excludes them V graph get_buffer name get_layout storage_size halide_argdefs Halide requires scalar inputs before outputs so need reorder args arg_order arg_tuple _call_str arg = arg_tuple isinstance arg SizeArg would normally end move middle out_ptr arg name assert in_ptr arg name result list tuple Optional str KernelArgType = _ b _ = args python_argdefs call_str arg sorted zip b key=arg_order result append call_str arg isinstance arg TensorArg assert arg offset == arg alias_of None result extend None TensorArg alias arg buffer arg dtype arg offset alias_of=arg name alias buffer_aliases get arg name result halide_kernel_meta - HalideMeta Compute metadata required codecache py argtypes = _ arg halide_argdefs isinstance arg SizeArg shape = None stride = None offset = None dtype = long shape = cexpr rename_indexing x size x buffer_dimensions arg name stride = cexpr rename_indexing x stride x buffer_dimensions arg name assert len shape == len stride offset = cexpr buffer_offsets arg name dtype = f DTYPE_TO_CPP arg dtype argtypes append HalideInputSpec dtype arg name shape=shape stride=stride offset=offset alias_of=arg alias_of current_device = V graph get_current_device_or_throw current_device type == cpu target = config halide cpu_target scheduler = config halide scheduler_cpu scheduler_flags = parallelism parallel_num_threads cuda_device = None assert current_device type == cuda only cpu cuda supported assert current_device index = only default device supported target = config halide gpu_target scheduler = config halide scheduler_cuda capability = torch cuda get_device_properties current_device cuda_capability target major minor capability major = major capability minor = minor target append f cuda_capability_ major minor break target append user_context scheduler_flags = parallelism capability multi_processor_count TODO jansel explore other flags see grep parser parse ~ Halide src autoschedulers anderson AutoSchedule cpp cuda_device = max current_device index strict_float requires correctness target append strict_float without we will initialize cuda once per kernel hit errors target append no_runtime config halide asserts target append no_asserts config halide debug target append debug index_dtype TODO jansel unclear does anything since input sizes still int target append large_buffers HalideMeta argtypes target= - join target scheduler=scheduler scheduler_flags=scheduler_flags type ignore arg-type cuda_device=cuda_device codegen_kernel name=None Called end generate final kernel string args inplace_buffers raise Unsupported inplace_buffers meta = halide_kernel_meta ensure needed args added early code = IndentedBuffer code splice halide hl torch _inductor runtime halide_helpers math inf nan hl generator name= kernel Kernel strip=True code do_indent _ arg halide_argdefs isinstance arg SizeArg code writeline f arg name = hl InputScalar index_dtype assert arg buffer arg argcls = hl OutputBuffer out arg name hl InputBuffer argtype = halide_type arg dtype ndim = len buffer_dimensions arg name code writeline f arg name = argcls argtype ndim code splice generate g code do_indent _ arg halide_argdefs code writeline f arg name = g arg name old new args aliases code writeline f old = new code splice indexing_code update_index m var = cast HalideCSEVariable cse varname_map m group assert var used_dims None var str var line body _lines isinstance line str fill missing indices line = HalideCSEVariable undefined_re sub update_index line code writeline line code writeline code writeline assert g using_autoscheduler _ arg halide_argdefs fallback= below because halide requires buffers least large estimates This causes crashes our estimate greater than vector length https github com halide Halide issues isinstance arg SizeArg hint = V graph sizevars size_hint arg expr fallback= code writeline f arg name set_estimate hint dims = buffer_dimensions arg name range_hints = i dim enumerate dims hint = _autoscheduler_workarounds V graph sizevars size_hint dim size fallback= dims pyrefly ignore bad-argument-type range_hints append f hl Range hint out arg name code writeline f arg name dim i set_min try code writeline f arg name dim i set_stride int dim stride except TypeError pass integer try code writeline f arg name dim i set_extent int dim size except TypeError pass integer code writeline f arg name set_estimates join range_hints code do_unindent code splice __name__ == __main__ hl main rstrip meta scheduler code splice f hl load_plugin HalideCodeCache find_libautoschedule meta scheduler r target = hl Target meta target r autoscheduler = hl AutoschedulerParams meta scheduler r meta scheduler_flags r hl GeneratorContext target autoscheduler gen = Kernel pipeline = gen _build_pipeline gen compile_to_callable does run autoscheduler pipeline apply_autoscheduler target autoscheduler kernel = pipeline compile_to_callable gen _get_input_parameter name _to_argument gen _get_arginfos dir == hl ArgInfoDirection Input target strip=True code splice f hl GeneratorContext hl Target meta target r kernel = Kernel compile_to_callable strip=True code getvalue staticmethod _autoscheduler_workarounds n dims len dims == config halide scheduler_cuda == Anderson V graph get_current_device_or_throw type == cuda workaround https github com halide Halide issues n = max n n call_kernel name str node=None deallocate_ws bool = True Codegen call kernel wrapper = V graph wrapper_code call_args = f n n arg halide_argdefs arg alias_of None current_device = V graph get_current_device_or_throw current_device type == cuda stream_name = wrapper write_get_raw_stream current_device index V graph name call_args append stream_name wrapper generate_kernel_call name call_args device=current_device triton=False generate_assert check False TODO jansel support asserts check_bounds expr sympy Expr size sympy Expr lower bool upper bool pass TODO jansel support asserts HalideScheduling SIMDScheduling kernel_type = HalideKernel type ignore arg-type assignment classmethod get_backend_features cls device torch device - OrderedSet BackendFeature result = OrderedSet BackendFeature TUPLE_REDUCTION BackendFeature PREFER_STORE_LOOP_ORDER BackendFeature REDUCE_TO_SINGLE_ELEMENT config halide scan_kernels result add BackendFeature SCAN result define_kernel src_code node_schedule kernel Codegen kernel definition go output wrapper code wrapper = V graph wrapper_code src_code wrapper src_to_kernel kernel_name = wrapper src_to_kernel src_code kernel_name = f halide_kernel_ wrapper next_kernel_suffix wrapper src_to_kernel src_code = kernel_name wrapper add_import_once torch _inductor runtime hints HalideMeta HalideInputSpec compile_wrapper = IndentedBuffer compile_wrapper writeline f async_compile halide kernel halide_kernel_meta r compile_wrapper splice src_code strip=True compile_wrapper writeline origins detailed_origins = get_kernel_metadata node_schedule wrapper metadata_comment = f origins \n detailed_origins wrapper define_kernel kernel_name compile_wrapper getvalue metadata_comment is_metric_table_enabled kernel_metadata log_kernel_metadata kernel_name src_code kernel_name