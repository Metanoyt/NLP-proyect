Owner s module inductor torch torch _inductor test_case run_tests TestCase torch testing _internal common_utils instantiate_parametrized_tests torch testing _internal inductor_utils GPU_TYPE HAS_HELION requires_helion HAS_HELION helion helion language hl HelionTests TestCase requires_helion test_add_kernel helion kernel config=helion Config block_sizes= add x torch Tensor y torch Tensor - torch Tensor match pytorch broadcasting rules x y = torch broadcast_tensors x y out = torch empty x shape match type promotion torch add dtype=torch promote_types x dtype y dtype device=x device tile will tuple blocks tile hl tile out size out tile = x tile + y tile out f x torch Tensor y torch Tensor - torch Tensor add x y x = torch randn device=GPU_TYPE dtype=torch float y = torch randn device=GPU_TYPE dtype=torch float out = add x y compiled_add = torch compile f fullgraph=True backend= inductor compiled_out = compiled_add x y assertEqual out x + y assertEqual compiled_out x + y requires_helion test_softmax_view_reshape helion kernel config= block_size softmax x torch Tensor - torch Tensor n _m = x size out = torch empty_like x tile_n hl tile n values = x tile_n amax = torch amax values dim= view tile_n exp = torch exp values - amax sum_exp = torch reshape torch sum exp dim= tile_n out tile_n = exp sum_exp out x = torch randn device=GPU_TYPE dtype=torch float result = softmax x assertEqual result torch nn functional softmax x dim= rtol= e- atol= e- instantiate_parametrized_tests HelionTests __name__ == __main__ run_tests