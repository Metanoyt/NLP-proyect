mypy allow-untyped-defs copy warnings collections defaultdict typing Any Optional torch torch nn torch ao pruning sparsifier utils fqn_to_module module_to_fqn __all__ = ActivationSparsifier ActivationSparsifier r The Activation sparsifier aims sparsify prune activations neural network The idea attach sparsifier layer layers zeroes out activations based mask_fn sparsification function input user The mask_fn applied once all inputs aggregated reduced i e mask = mask_fn reduce_fn aggregate_fn activations Note The sparsification mask computed input before goes through attached layer Args model nn Module The model whose layers will sparsified The layers needs sparsified should added separately using register_layer function aggregate_fn Optional Callable default aggregate_fn used specified while registering layer specifies how inputs should aggregated over time The aggregate_fn should usually take torch tensors aggregated tensor Example add_agg_fn tensor tensor tensor + tensor reduce_fn Optional Callable default reduce_fn used specified while registering layer reduce_fn will called aggregated tensor i e tensor obtained after calling agg_fn all inputs Example mean_reduce_fn agg_tensor agg_tensor mean dim= mask_fn Optional Callable default mask_fn used create sparsification mask using tensor obtained after calling reduce_fn This used default custom one passed register_layer Note mask_fn definition should contain sparse arguments passed sparse_config arguments features Optional list default selected features sparsify If non-empty then mask_fn will applied each feature input For example mask = mask_fn reduce_fn aggregated_fn input feature feature features feature_dim Optional int default dimension input features Again features along dim will chosen sparsification sparse_config Dict Default configuration mask_fn This config will passed mask_fn Example xdoctest +SKIP model = SomeModel act_sparsifier = ActivationSparsifier init activation sparsifier Initialize aggregate_fn agg_fn x y x + y Initialize reduce_fn reduce_fn x torch mean x dim= Initialize mask_fn mask_fn data torch eye data shape data device act_sparsifier register_layer model some_layer aggregate_fn=agg_fn reduce_fn=reduce_fn mask_fn=mask_fn start training process _ epoch starts model forward compute_loss model backwards epoch ends act_sparsifier step end training process sparsifier squash_mask __init__ model nn Module aggregate_fn=None reduce_fn=None mask_fn=None features=None feature_dim=None sparse_config model = model defaults dict str Any = defaultdict defaults sparse_config = sparse_config functions defaults aggregate_fn = aggregate_fn defaults reduce_fn = reduce_fn defaults mask_fn = mask_fn default feature feature_dim defaults features = features defaults feature_dim = feature_dim data_groups dict str dict = defaultdict dict contains all relevant info w r t each registered layer state dict str Any = defaultdict dict layer name - mask staticmethod _safe_rail_checks args Makes sure some functions attributes passed incorrectly features None then feature_dim must None features feature_dim = args features args feature_dim features None feature_dim None raise AssertionError need feature dim select features all _fns should callable fn_keys = aggregate_fn reduce_fn mask_fn key fn_keys fn = args key callable fn raise AssertionError f fn must callable _aggregate_hook name Returns hook computes aggregate activations passing through gather some data feature_dim = data_groups name feature_dim features = data_groups name features agg_fn = data_groups name aggregate_fn hook module input - None input_data = input data = data_groups name get data aggregated data features None no features associated data should list data None data = torch zeros_like input_data state name mask = torch ones_like input_data out_data = agg_fn data input_data data should list aggregated over each feature only data None out_data = _ range len features create one case st forward state name mask = _ range len features out_data = data list compute aggregate over each feature feature_idx range len features each feature either list scalar convert torch tensor feature_tensor = torch Tensor features feature_idx long input_data device data_feature = torch index_select input_data feature_dim feature_tensor data None curr_data = torch zeros_like data_feature state name mask feature_idx = torch ones_like data_feature curr_data = data feature_idx out_data feature_idx = agg_fn curr_data data_feature data_groups name data = out_data hook register_layer layer nn Module aggregate_fn=None reduce_fn=None mask_fn=None features=None feature_dim=None sparse_config r Registers layer sparsification The layer should part model Specifically registers pre-forward hook layer The hook will apply aggregate_fn store aggregated activations input over each step Note - There no need pass name layer automatically computed per fqn convention - All functions fn passed argument will called dim feature level name = module_to_fqn model layer name None raise AssertionError layer found model name data_groups unregister layer already present warnings warn layer already attached sparsifier deregistering layer registering new config stacklevel= unregister_layer name=name local_args = copy deepcopy defaults update_dict = aggregate_fn aggregate_fn reduce_fn reduce_fn mask_fn mask_fn features features feature_dim feature_dim layer layer local_args update arg val arg val update_dict items val None local_args sparse_config update sparse_config _safe_rail_checks local_args data_groups name = local_args agg_hook = layer register_forward_pre_hook _aggregate_hook name=name state name mask = None mask will created when model forward called attach agg hook data_groups name hook = agg_hook serialization purposes we know whether aggregate_hook attached sparsify_hook data_groups name hook_state = aggregate aggregate hook attached get_mask name Optional str = None layer Optional nn Module = None Returns mask associated layer The mask - torch tensor features layer None - list torch tensors each feature otherwise Note The shape mask unknown until model forward applied Hence get_mask called before model forward error will raised name None layer None raise AssertionError Need least name layer obj retrieve mask name None layer None raise AssertionError layer must provided when name None name = module_to_fqn model layer name None raise AssertionError layer found specified model name state raise ValueError Error layer given name found mask = state name get mask None mask None raise ValueError Error shape unknown call layer routine least once infer mask mask unregister_layer name Detaches sparsifier layer detach any hooks attached data_groups name hook remove pop state dict state pop name pop data groups data_groups pop name step Internally calls update_mask function each layer torch no_grad name configs data_groups items data = configs data update_mask name data configs data_groups name pop data reset accumulated data update_mask name data configs Called each registered layer does following- apply reduce_fn aggregated activations use mask_fn compute sparsification mask Note reduce_fn mask_fn called each feature dim over data mask = get_mask name sparse_config = configs sparse_config features = configs features reduce_fn = configs reduce_fn mask_fn = configs mask_fn features None data = reduce_fn data mask data = mask_fn data sparse_config feature_idx range len features data_feature = reduce_fn data feature_idx mask feature_idx data = mask_fn data_feature sparse_config _sparsify_hook name Returns hook applies sparsification mask input entering attached layer mask = get_mask name features = data_groups name features feature_dim = data_groups name feature_dim hook module input input_data = input features None apply all features input_data mask apply per feature feature_dim feature_idx range len features feature = torch Tensor features feature_idx long input_data device sparsified = torch index_select input_data feature_dim feature mask feature_idx input_data index_copy_ feature_dim feature sparsified input_data hook squash_mask attach_sparsify_hook=True kwargs Unregisters aggregate hook applied earlier registers sparsification hooks attach_sparsify_hook = True name configs data_groups items unhook agg hook configs hook remove configs pop hook data_groups name hook_state = None attach_sparsify_hook configs hook = configs layer register_forward_pre_hook _sparsify_hook name configs hook_state = sparsify signals sparsify hook now attached _get_serializable_data_groups Exclude hook layer config keys before serializing TODO Might have treat functions reduce_fn mask_fn etc different manner while serializing For time-being functions treated same way other attributes data_groups dict str Any = defaultdict name config data_groups items new_config = key value key value config items key hook layer data_groups name = new_config data_groups _convert_mask states_dict sparse_coo=True r Converts mask sparse coo dense depending ` sparse_coo ` argument If ` sparse_coo=True ` then mask stored sparse coo dense tensor states = copy deepcopy states_dict state states values state mask None isinstance state mask list idx range len state mask sparse_coo state mask idx = state mask idx to_sparse_coo state mask idx = state mask idx to_dense sparse_coo state mask = state mask to_sparse_coo state mask = state mask to_dense states state_dict - dict str Any r Returns state sparsifier ` dict ` It contains state - contains name - mask mapping data_groups - dictionary containing all config information each layer defaults - default config while creating constructor data_groups = _get_serializable_data_groups state = _convert_mask state state state data_groups data_groups defaults defaults load_state_dict state_dict dict str Any - None r The load_state_dict restores state sparsifier based state_dict Args state_dict - dictionary which current sparsifier needs restored state = state_dict state data_groups defaults = state_dict data_groups state_dict defaults __set_state__ state state data_groups data_groups defaults defaults __get_state__ - dict str Any data_groups = _get_serializable_data_groups state = _convert_mask state defaults defaults state state data_groups data_groups __set_state__ state dict str Any - None state state = _convert_mask state state sparse_coo=False convert mask dense tensor __dict__ update state need attach layer hook info into data_groups name config data_groups items fetch layer layer = fqn_to_module model name layer None raise AssertionError f layer name found model agg_mode True then layer aggregate mode hook_state config config hook_state == aggregate hook = layer register_forward_pre_hook _aggregate_hook name hook_state config config hook_state == sparsify hook = layer register_forward_pre_hook _sparsify_hook name config layer = layer config hook = hook type ignore possibly-undefined __repr__ format_string = __class__ __name__ + name config data_groups items format_string += \n format_string += \tData Group\n format_string += f \t name name \n key sorted config keys key data hook reduce_fn mask_fn aggregate_fn continue format_string += f \t key config key \n format_string += format_string