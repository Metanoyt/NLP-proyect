Owner s oncall distributed Copyright c Facebook Inc its affiliates All rights reserved This source code licensed under BSD license found LICENSE file root directory source tree copy sys contextlib nullcontext typing Any cast numpy np torch torch distributed dist dist is_available print Distributed available skipping tests file=sys stderr sys exit torch distributed algorithms ddp_comm_hooks ddp_zero_hook hook_with_zero_step hook_with_zero_step_interleaved torch distributed algorithms ddp_comm_hooks default_hooks allreduce_hook torch distributed algorithms join Join Joinable JoinHook torch distributed optim ZeroRedundancyOptimizer torch distributed optim zero_redundancy_optimizer _broadcast_object torch nn parallel DistributedDataParallel DDP torch optim AdamW SGD torch testing _internal common_distributed DistributedTestBase logger requires_accelerator_dist_backend requires_ddp_rank requires_gloo skip_if_lt_x_gpu skip_if_no_gpu skip_if_rocm_multiprocess skip_if_win torch testing _internal common_fsdp get_devtype torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests skipIfHpu try torchvision HAS_TORCHVISION = True except ImportError HAS_TORCHVISION = False device_type = str get_devtype TestZeroRedundancyOptimizer DistributedTestBase property device device_type property world_size TestZeroRedundancyOptimizerSingleRank TestZeroRedundancyOptimizer test_state_dict Check ZeroRedundancyOptimizer exposes expected state dict interface irrespective sharding create_pg device LR = LR = MOMENTUM = RECIPIENT_RANK = rank only rank since world size x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGD lr=LR momentum=MOMENTUM x backward o step assertEqual x torch tensor device=self device assertEqual o optim state x momentum_buffer torch tensor device=self device o zero_grad o consolidate_state_dict to=RECIPIENT_RANK state_dict = o state_dict Check state dict has keys compliant PyTorch assertIn param_groups state_dict keys assertIn state state_dict keys Check state has expected keys assertEqual state_dict param_groups lr assertEqual state_dict param_groups momentum assertFalse state_dict param_groups nesterov assertEqual state_dict param_groups weight_decay assertEqual state_dict param_groups dampening Check state ` param_groups ` attribute sync k state_dict param_groups k = params assertEqual state_dict param_groups k o param_groups k Check state reloaded correct values device o = ZeroRedundancyOptimizer x optimizer_class=SGD lr=LR o load_state_dict state_dict assertEqual o optim state x momentum_buffer torch tensor device=self device We should we using ` LR ` ` LR ` after reloading both within optimizer exposed ` param_groups ` attribute assertEqual o param_groups lr LR x backward o step assertEqual x torch tensor device=self device assertEqual o optim state x momentum_buffer torch tensor device=self device Check exposed ` param_groups ` ` proper device assertEqual o param_groups params device x device test_lr_scheduler Check normal PyTorch ` ` lr_scheduler ` ` usable ZeroRedundancyOptimizer create_pg device NUM_ITERS = LR = x = torch tensor device=self device requires_grad=True x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGD lr=LR o = torch optim SGD x lr=LR s = torch optim lr_scheduler StepLR o s = torch optim lr_scheduler StepLR o _ range NUM_ITERS x backward o zero_grad o step s step x backward o zero_grad o step s step assertEqual x x test_step_with_kwargs Check ` ` step kwargs ` ` interface properly exposed create_pg device LR = SGDWithStepKWArg torch optim SGD step closure=None kwarg=None super step kwarg append kwarg list Any = x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGDWithStepKWArg lr=LR x backward o step kwarg=kwarg assertEqual kwarg assertEqual x torch tensor device=self device test_step_with_extra_inner_key Check ZeroRedundancyOptimizer wrapping optimizer adds extra keys ` ` param_groups ` ` exposes those keys through ZeRO s own ` ` param_groups ` ` create_pg device LR = SGDWithNewKey torch optim SGD Dummy optimizer which adds new key param groups step closure=None super step param_groups new_key = x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGDWithNewKey lr=LR x backward o step assertEqual o param_groups new_key assertEqual x torch tensor device=self device test_step_without_closure Check ` ` step ` ` method without closure handled expected create_pg device LR = SGDWithoutClosure torch optim SGD step super step x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGDWithoutClosure lr=LR x backward o step assertEqual x torch tensor device=self device test_zero_grad Check ` ` zero_grad ` ` method properly handled create_pg device LR = x = torch rand m = torch nn Linear o = ZeroRedundancyOptimizer m parameters optimizer_class=SGD lr=LR y = m x y backward x assertNotEqual m weight grad torch zeros_like m weight assertNotEqual m weight grad torch zeros_like m weight o zero_grad assertIsNone m weight grad assertIsNone m bias grad test_constructor Check robustness ZeroRedundancyOptimizer constructor passing different values ` ` params ` ` argument create_pg device LR = m = torch nn Sequential torch nn Linear torch nn Linear torch nn Linear Test various constructor inputs form input expected error ctor_inputs = ValueError empty parameter list torch randn TypeError non-iterable ` torch Tensor ` TypeError non-iterable ` float ` params l weight l m params l bias l m None iterable dict list m parameters + TypeError iterable containing invalid type m parameters None ` params ` generator list m parameters None ` params ` list ctor_input error ctor_inputs context = assertRaises error error nullcontext context ZeroRedundancyOptimizer ctor_input optimizer_class=SGD lr=LR Test constructing multiple parameter groups more thoroughly WD = BETAS = EPS = e- params = params l weight l m weight_decay params l bias l m weight_decay WD o = ZeroRedundancyOptimizer params optimizer_class=AdamW lr=LR betas=BETAS eps=EPS assert len o param_groups == f Expected ZeRO param groups got len o param_groups assert len o optim param_groups == Expected local optimizer param groups got f len o optim param_groups test_same_dense_param_type Check ZeroRedundancyOptimizer raises exception input parameters include sparse tensors different dense types NOTE This test should removed once support sparse parameters varying parameter types added create_pg device LR = inputs = torch sparse_coo_tensor size= torch FloatTensor torch DoubleTensor torch FloatTensor torch FloatTensor torch sparse_coo_tensor size= input inputs assertRaises ValueError ZeroRedundancyOptimizer input optimizer_class=SGD lr=LR TestZeroRedundancyOptimizerDistributed TestZeroRedundancyOptimizer property world_size min max torch get_device_module device device_count property context requires_ddp_rank device torch get_device_module device device rank nullcontext _check_same_model_params model_a torch nn Module model_b torch nn Module message str = - None Check model parameters match p_a p_b zip model_a parameters model_b parameters torch testing assert_close p_a p_b atol= e- rtol= e- msg=f Model parameters differ \n p_a p_b \n + message Check model buffers match b_a b_b zip model_a buffers model_b buffers torch testing assert_close b_a b_b msg=f Model buffers differ \n b_a b_b \n + message skip_if_no_gpu skip_if_rocm_multiprocess test_step Check ZeroRedundancyOptimizer properly exposes ` ` step ` ` interface create_pg device LR = context x = torch tensor float rank + device=self device m = torch nn Linear m weight data = torch tensor m bias data = torch tensor m = m device m_zero = copy deepcopy m device o = SGD m parameters lr=LR o_zero = ZeroRedundancyOptimizer m_zero parameters optimizer_class=SGD lr=LR y = m x y backward x y_zero = m_zero x y_zero backward x p m parameters dist all_reduce p grad data op=dist ReduceOp SUM p grad data = world_size o step p m_zero parameters dist all_reduce p grad data op=dist ReduceOp SUM p grad data = world_size o_zero step assertEqual m weight m_zero weight assertEqual m bias m_zero bias skip_if_no_gpu skip_if_rocm_multiprocess test_step_with_closure Check ZeroRedundancyOptimizer properly exposes ` ` step closure ` ` interface create_pg device context bucket_view False True x_val = rank + weight = bias = error = target = torch tensor x_val weight + bias + error device=self device loss_fn = torch nn L Loss x = torch tensor float x_val device=self device m = torch nn Linear m weight data = torch tensor weight m bias data = torch tensor bias m device o = ZeroRedundancyOptimizer m parameters optimizer_class=SGD parameters_as_bucket_view=bucket_view lr= y = m x y backward x p m parameters dist all_reduce p grad data op=dist ReduceOp SUM p grad data = world_size closure o zero_grad output = m x loss = loss_fn output target loss backward loss loss = o step closure=closure assertEqual loss torch tensor error assertEqual m weight torch tensor assertEqual m bias torch tensor skip_if_no_gpu test_lr_scheduler Check normal PyTorch ` ` lr_scheduler ` ` usable ZeroRedundancyOptimizer create_pg device x = torch tensor device=self device requires_grad=True x = torch tensor device=self device requires_grad=True o = ZeroRedundancyOptimizer x optimizer_class=SGD lr= o = torch optim SGD x lr= s = torch optim lr_scheduler StepLR o s = torch optim lr_scheduler StepLR o _ range x backward o zero_grad o step s step x backward o zero_grad o step s step assertEqual x x test_sharding Check ZeroRedundancyOptimizer s parameter sharding construction time NOTE The correctness test depends ZeRO implementation using sorted-greedy partitioning algorithm For details see ` ` ZeroRedundancyOptimizer _partition_parameters ` ` zero_redundancy_optimizer py create_pg device LR = sizes = params = size sizes world_size params append torch rand size o = ZeroRedundancyOptimizer params optimizer_class=SGD lr=LR assertEqual sum x numel x o optim param_groups params sum sizes test_add_param_group Check ZeroRedundancyOptimizer properly handles adding new parameter group posteriori all ranks get shard contained parameters NOTE The correctness test depends ZeRO implementation using sorted-greedy partitioning algorithm For details see ` ` ZeroRedundancyOptimizer _partition_parameters ` ` zero_redundancy_optimizer py create_pg device LR = Test all parameters trainable begin all_trainable params = sizes = sizes_world = sizes world_size size sizes_world - params append torch rand size Make sure params trainable so they factored into size-based parameter partitioning p params p requires_grad = True o = ZeroRedundancyOptimizer params optimizer_class=SGD lr=LR assertEqual len o param_groups o add_param_group params torch rand Verify new group added correct partition making all partitions have same elements assertEqual len o param_groups assertEqual sum x numel g o optim param_groups x g params sum sizes assertEqual len o optim param_groups Test pathological config first big non-trainable param some_trainable params = size params append torch rand size Make sure all first param trainable so they factored into size-based parameter partitioning p params p requires_grad = True o = ZeroRedundancyOptimizer params optimizer_class=SGD lr=LR assertEqual len o param_groups o add_param_group params torch rand assertEqual len o param_groups assertEqual len o optim param_groups all_trainable some_trainable skip_if_no_gpu test_multiple_param_groups Check parity between constructing ZeRO multiple parameter groups upfront versus adding parameter groups ZeRO after construction versus non-sharded optimizer create_pg device BATCH_SIZE NUM_ITERS = INPUT_DIM HIDDEN_DIM OUTPUT_DIM = WD LR = model = torch nn Sequential torch nn Linear INPUT_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM OUTPUT_DIM model = copy deepcopy model model = copy deepcopy model model = model device model = model device model = model device inputs = torch randn BATCH_SIZE INPUT_DIM device _ range NUM_ITERS Construct ` optim ` both parameter groups upfront optim = ZeroRedundancyOptimizer params l weight l model weight_decay params l bias l model weight_decay WD optimizer_class=AdamW lr=LR Construct ` optim ` adding second parameter after optim = ZeroRedundancyOptimizer l weight l model optimizer_class=AdamW lr=LR weight_decay= optim add_param_group params l bias l model weight_decay WD Construct ` optim ` non-sharded optimizer optim = AdamW params l weight l model weight_decay params l bias l model weight_decay WD lr=LR Check parity over few iterations input inputs model optim model optim model optim model optim optim zero_grad out = model input loss = out sum loss backward optim step layer layer layer zip model model model torch testing assert_close layer weight layer weight torch testing assert_close layer weight layer weight torch testing assert_close layer bias layer bias torch testing assert_close layer bias layer bias skip_if_no_gpu skip_if_rocm_multiprocess test_collect_shards Check state consolidation mechanism state dict exposed ZeroRedundancyOptimizer create_pg device LR = e- MOMENTUM = BATCH_SIZE INPUT_DIM HIDDEN_DIM OUTPUT_DIM = REFERENCE_RANK = target = torch rand BATCH_SIZE OUTPUT_DIM device=self device inputs = torch rand BATCH_SIZE INPUT_DIM device=self device model = torch nn Sequential torch nn Linear INPUT_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM OUTPUT_DIM device loss_fn = torch nn L Loss loss_fn device optimizer = ZeroRedundancyOptimizer model parameters optimizer_class=SGD lr=LR momentum=MOMENTUM ensure there exists state shard closure optimizer zero_grad output = model inputs loss = loss_fn output target loss backward loss Run dummy step so optimizer state dict exists _ = optimizer step closure=closure Get optimizer state reference rank optimizer consolidate_state_dict to=REFERENCE_RANK rank == REFERENCE_RANK Check state has correct size optimizer_state_dict = optimizer state_dict assertEqual len optimizer_state_dict state len list model parameters optimizer_state_dict = Load optimizer state all ranks without any exceptions optimizer_state_dict = _broadcast_object optimizer_state_dict src_rank=REFERENCE_RANK group=dist group WORLD device=self device optimizer load_state_dict optimizer_state_dict test_nondefault_process_group Check ZeroRedundancyOptimizer works non-default process group consisting only even ranks Skip test below minimum world size since then test trivial MIN_WORLD_SIZE = world_size MIN_WORLD_SIZE logger info Skipping ` test_nondefault_process_group ` since world size s less than s world_size MIN_WORLD_SIZE Use GPU enough available fall back CPU otherwise torch get_device_module device device_count world_size device = torch device cpu device = torch device device create_pg device type Create new process group consisting even ranks exercise case where global local ranks do necessarily match subgroup_ranks = r r range world_size r == process_group = dist new_group ranks=subgroup_ranks backend=self backend device type Ranks participating new process group no longer needed rank subgroup_ranks Set different seeds across ranks so each rank gets different training data hence model sync check meaningful torch manual_seed rank np random seed rank EPOCHS BATCH_SIZE INPUT_DIM HIDDEN_DIM OUTPUT_DIM = LR = e- MOMENTUM = REFERENCE_RANK = assert REFERENCE_RANK subgroup_ranks Reference rank must new process group loss_fn = torch nn L Loss device check optimizer _ range EPOCHS target = torch rand BATCH_SIZE OUTPUT_DIM device=device inputs = torch rand BATCH_SIZE INPUT_DIM device=device closure optimizer zero_grad output = model inputs loss = loss_fn output target loss = world_size loss backward dist all_reduce loss group=process_group loss _ = optimizer step closure=closure Check parameters match across ranks after step pg optimizer param_groups p pg params receptacle = p clone _ subgroup_ranks rank == REFERENCE_RANK dist gather p receptacle dst=REFERENCE_RANK group=process_group rank == REFERENCE_RANK reference_param = receptacle param receptacle torch testing assert_close reference_param param msg= Models differ between ranks model = torch nn Sequential torch nn Linear INPUT_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM OUTPUT_DIM device optimizer = ZeroRedundancyOptimizer model parameters optimizer_class=SGD lr=LR momentum=MOMENTUM ensure there exists state shard process_group=process_group check optimizer skip_if_no_gpu parametrize optimizer_class_str Adam AdamW SGD Use string appease internal test name parser parametrize maximize False True test_local_optimizer_parity optimizer_class_str str maximize bool When combined DDP check local optimizer gives same results wrapping optimizer ZeroRedundancyOptimizer create_pg device BATCHES = BATCH_SIZE = LR = e- INPUT_DIM = HIDDEN_DIM = OUTPUT_DIM = torch manual_seed rank np random seed rank optimizer_class_str == Adam optimizer_class = torch optim Adam optimizer_class_str == AdamW optimizer_class = torch optim AdamW optimizer_class_str == SGD optimizer_class = torch optim SGD assert f Unsupported optimizer optimizer_class_str context Define base model different buffer each rank model = torch nn Sequential torch nn Linear INPUT_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM HIDDEN_DIM torch nn Linear HIDDEN_DIM OUTPUT_DIM device model test_buffer = torch nn Buffer torch ones device=self device rank Define models optimizers DDP ZeRO DDP local optimizer defaults = maximize True maximize sharded_optimizer = ZeroRedundancyOptimizer params=model parameters optimizer_class=optimizer_class lr=LR defaults sharded_ddp_model = DDP module=model device_ids= rank requires_ddp_rank device None broadcast_buffers=True find_unused_parameters=True local_model = copy deepcopy model device ddp_optimizer = optimizer_class local_model parameters lr=LR defaults ddp_model = DDP local_model device_ids= rank requires_ddp_rank device None broadcast_buffers=True find_unused_parameters=True Check model properly synchronized between ranks construction time _check_same_model_params sharded_ddp_model ddp_model Models differ start check_step input_tensor = torch rand BATCH_SIZE INPUT_DIM device closure_ddp input_tensor=input_tensor ddp_optimizer zero_grad ddp_loss = ddp_model input_tensor abs sum ddp_loss backward ddp_loss closure_sharded input_tensor=input_tensor sharded_optimizer zero_grad sharded_loss = sharded_ddp_model input_tensor abs sum sharded_loss backward sharded_loss loss_ddp = cast torch Tensor ddp_optimizer step closure=closure_ddp loss_sharded_optim = cast torch Tensor sharded_optimizer step closure=closure_sharded torch testing assert_close loss_ddp loss_sharded_optim msg= Losses differ between local optimizer ZeRO _check_same_model_params sharded_ddp_model ddp_model Models differ after step Check parity maintained i range BATCHES check_step For second half batches change parameter trainability further test parity i BATCHES next ddp_model parameters requires_grad = bool i next sharded_ddp_model parameters requires_grad = bool i Check ` state_dict ` checkpoints compatible between local optimizer ZeRO REFERENCE_RANK = - Get states ddp_state_dict = ddp_optimizer state_dict sharded_optimizer consolidate_state_dict to=REFERENCE_RANK sharded_optim_state_dict = sharded_optimizer state_dict rank == REFERENCE_RANK dist broadcast_object_list sharded_optim_state_dict src=REFERENCE_RANK group=dist group WORLD sharded_optim_state_dict = sharded_optim_state_dict - Cross-load states Run one step check models still same ddp_state_dict_ref = copy deepcopy ddp_state_dict ddp_optimizer load_state_dict sharded_optim_state_dict sharded_optimizer load_state_dict ddp_state_dict check_step - Reload their respective states Run one step check models still same ddp_optimizer load_state_dict ddp_state_dict_ref sharded_optimizer load_state_dict sharded_optim_state_dict check_step _test_zero_join device Check ZeRO join hook allows training uneven inputs when using given device NUM_INPUTS = NUM_EPOCHS = LR = torch manual_seed cpu device torch get_device_module device manual_seed rank = rank world_size = world_size create_pg device model = torch nn Sequential torch nn Linear torch nn Linear torch nn Linear model device DDP ensures correct gradients data parallel training so DDP local optimizers uneven inputs should equivalent ZeRO uneven inputs gradients being manually set ddp_model = DDP model device_ids= rank requires_ddp_rank device DDP model local_optim = torch optim Adam ddp_model parameters lr=LR zero_model = copy deepcopy model zero_model device zero_optim = ZeroRedundancyOptimizer zero_model parameters torch optim Adam lr=LR loss_fn = torch nn MSELoss Use uneven inputs rank i has i extra inputs inputs = torch randn device _ range NUM_INPUTS + rank labels = torch randn device Save gradients parameters DDP ground truth do so last-joining rank case largest rank grads_at_each_iter = params_at_each_iter = ddp_model join _ range NUM_EPOCHS input inputs output = ddp_model input loss_fn output labels backward rank == world_size - grads = p ddp_model parameters grads append p grad detach clone device local_optim step rank == world_size - params = p ddp_model parameters params append p detach clone device grads_at_each_iter append grads params_at_each_iter append params Broadcast saved gradients parameters all other ranks which joined early grads_and_params = grads_at_each_iter params_at_each_iter grads_and_params = _broadcast_object grads_and_params src_rank=world_size - group=dist group WORLD device=device grads_at_each_iter = grads_and_params params_at_each_iter = grads_and_params TODO Replace ` _broadcast_object ` ` broadcast_object_list ` once latter supports loading destination device instead source device A process must still set remaining gradients after joining so we define join hook do before ZeRO join hook _JoinGradInfo __init__ grads grads = grads remaining gradients set order index = _SetGradsJoinHook JoinHook __init__ zero_optim grads zero_optim _join_grad_info = _JoinGradInfo grads zero = zero_optim super __init__ main_hook join_grad_info = zero _join_grad_info grads = zero _join_grad_info grads join_grad_info index join_grad_info index += p grad zip zero _all_params grads p grad = grad detach clone device _GradientSetter Joinable __init__ - None super __init__ join_hook kwargs assert zero_optim kwargs assert grads kwargs zero_optim = kwargs zero_optim grads = kwargs grads _SetGradsJoinHook zero_optim grads property join_device device property join_process_group dist group WORLD num_grads_after_joining = NUM_EPOCHS world_size - rank - grads = grads_at_each_iter -num_grads_after_joining gradient_setter = _GradientSetter iter = Join gradient_setter zero_optim zero_optim=zero_optim grads=grads _ range NUM_EPOCHS input inputs Notify join context process has joined Join notify_join_context gradient_setter Set gradients manually p grad zip zero_model parameters grads_at_each_iter iter p grad = grad detach clone device Perform optimizer step check parity zero_optim step p ddp_p zip zero_model parameters params_at_each_iter iter torch testing assert_close p ddp_p msg= Parameters differ between using ZeRO local optimizer iter += requires_accelerator_dist_backend skip_if_no_gpu test_zero_join_gpu Check ZeRO join hook allows training uneven inputs GPU _test_zero_join device requires_gloo test_zero_join_cpu Check ZeRO join hook allows training uneven inputs CPU _test_zero_join cpu _test_zero_model_parallel parameters_as_bucket_view bool device str Use two processes each two GPUs assert rank NUM_EPOCHS = NUM_INPUTS = LR = torch manual_seed cpu device torch get_device_module device manual_seed ModelParallelModel torch nn Module __init__ dev dev super __init__ dev = dev dev = dev net = torch nn Linear dev relu = torch nn ReLU net = torch nn Linear dev forward x x = x dev x = relu net x x = x dev net x LocalModel torch nn Module __init__ - None super __init__ net = torch nn Linear relu = torch nn ReLU net = torch nn Linear forward x net relu net x dev = torch device rank dev = torch device rank + mp_model = ModelParallelModel dev dev ddp_model = DDP mp_model local_model = LocalModel dev Ensure parameters same across two models copy_param p torch nn Parameter p detach clone dev local_model net weight = copy_param mp_model net weight local_model net bias = copy_param mp_model net bias local_model net weight = copy_param mp_model net weight local_model net bias = copy_param mp_model net bias Compare parity between DDP model parallelism using ZeRO local model using local optimizer zero_optim = ZeroRedundancyOptimizer ddp_model parameters optimizer_class=torch optim Adam parameters_as_bucket_view=parameters_as_bucket_view lr=LR local_optim = torch optim Adam local_model parameters lr=LR inputs = torch randn dev _ range NUM_INPUTS _ range NUM_EPOCHS input inputs closure_local local_optim zero_grad local_loss = local_model input abs sum local_loss backward local_loss closure_ddp zero_optim zero_grad ddp_loss = ddp_model input abs sum ddp_loss backward ddp_loss local_loss = cast torch Tensor local_optim step closure=closure_local ddp_loss = cast torch Tensor zero_optim step closure=closure_ddp Increased tolerances needed pass when using TF See https github com pytorch pytorch issues torch testing assert_close local_loss cpu ddp_loss cpu rtol= e- atol= e- msg= Losses differ between local optimizer ZeRO local_p ddp_p zip local_model parameters ddp_model parameters torch testing assert_close local_p cpu ddp_p cpu rtol= e- atol= e- msg= Models differ after step skipIfHpu skip_if_lt_x_gpu parametrize parameters_as_bucket_view False True test_zero_model_parallel parameters_as_bucket_view bool Check ZeRO works model parallelism where model s layers assigned different devices rank = create_pg device world_size= _test_zero_model_parallel parameters_as_bucket_view device _test_ddp_zero_overlap device hook_constructor gradient_as_bucket_view static_graph kwargs SGD_LR = SGD_MOMENTUM = SGD_WEIGHT_DECAY = NUM_INPUTS = torch manual_seed cpu device torch get_device_module device manual_seed rank = rank models_to_test = torch nn Sequential torch nn Linear torch nn Linear torch randn device _ range NUM_INPUTS HAS_TORCHVISION models_to_test append torchvision models resnet torch randn device _ range NUM_INPUTS model inputs models_to_test Select deterministic context based device det_ctx = torch backends cudnn flags enabled=True deterministic=True benchmark=False cuda device torch use_deterministic_algorithms True det_ctx device_ids = rank requires_ddp_rank device None Set up DDP model overlapping ZeRO ddp_model_overlap = DDP copy deepcopy model device device_ids=device_ids gradient_as_bucket_view=gradient_as_bucket_view static_graph ddp_model_overlap _set_static_graph zero_optim = ZeroRedundancyOptimizer ddp_model_overlap parameters optimizer_class=torch optim SGD overlap_with_ddp=True lr=SGD_LR momentum=SGD_MOMENTUM weight_decay=SGD_WEIGHT_DECAY ddp_model_overlap register_comm_hook None hook_constructor allreduce_hook ddp_model_overlap zero_optim kwargs Set up DDP model local optimizer ddp_model_local = DDP copy deepcopy model device device_ids=device_ids gradient_as_bucket_view=gradient_as_bucket_view static_graph ddp_model_local _set_static_graph local_optim = torch optim SGD ddp_model_local parameters lr=SGD_LR momentum=SGD_MOMENTUM weight_decay=SGD_WEIGHT_DECAY Check parameters match initially p p zip ddp_model_overlap parameters ddp_model_local parameters assertEqual p p Save parameters ensure they updated init_params_overlap = copy deepcopy list ddp_model_overlap parameters Ensure test runs independently dist barrier Run DDP model overlapping ZeRO NOTE Overlapping currently requires warmup iterations ensure DDP buckets have been rebuilt depending value ` static_graph ` num_warmup_inputs = static_graph input inputs num_warmup_inputs output = ddp_model_overlap input loss = output sum loss backward input inputs zero_optim zero_grad output = ddp_model_overlap input loss = output sum loss backward Run DDP model local optimizer input inputs local_optim zero_grad output = ddp_model_local input loss = output sum loss backward local_optim step dist barrier Check parameters equal p p zip ddp_model_overlap parameters ddp_model_local parameters assertEqual p p Check parameters updated assertNotEqual init_params_overlap list ddp_model_overlap parameters Ensure test runs independently dist barrier NOTE The test skipped using Windows since functional optimizers currently supported skip_if_win requires_accelerator_dist_backend skip_if_no_gpu skip_if_rocm_multiprocess parametrize use_gpu True Add ` False ` once Gloo sync issue causing hangs fixed See https github com pytorch pytorch issues parametrize use_interleaved_hook False True parametrize gradient_as_bucket_view False True parametrize static_graph False True parametrize shard_buckets False True test_ddp_zero_overlap use_gpu bool use_interleaved_hook bool gradient_as_bucket_view bool static_graph bool shard_buckets bool Check overlapping DDP ZeRO using given method determined ` ` hook_constructor ` ` ` ` shard_buckets ` ` using given ZeRO DDP arguments achieves parity DDP using local optimizer create_pg device hook_constructor = hook_with_zero_step use_interleaved_hook hook_with_zero_step_interleaved _test_ddp_zero_overlap device use_gpu cpu hook_constructor gradient_as_bucket_view static_graph shard_buckets=shard_buckets instantiate_parametrized_tests TestZeroRedundancyOptimizerSingleRank instantiate_parametrized_tests TestZeroRedundancyOptimizerDistributed __name__ == __main__ unittest should used here tests properly registered run_tests