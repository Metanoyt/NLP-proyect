Owner s module meta tensors ruff noqa F contextlib copy dataclasses gc inspect io itertools pickle unittest weakref unittest mock patch numpy np torch torch _dynamo torch _functorch config torch _prims prims torch testing _internal optests optests torch utils _pytree pytree torch distributed dist torch _C _functorch _add_batch_dim get_unwrapped is_batchedtensor torch _dispatch python enable_python_dispatcher torch _dynamo testing make_test_cls_with_patches rand_strided torch _guards tracing TracingContext torch _higher_order_ops scan scan torch _subclasses fake_tensor _CacheKeyState DynamicOutputShapeException extract_tensor_metadata FakeTensor FakeTensorConverter FakeTensorMode MetadataMismatchError unset_fake_temporarily UnsupportedOperatorException torch fx experimental proxy_tensor make_fx torch fx experimental symbolic_shapes DimDynamic free_symbols ShapeEnv ShapeEnvSettings StatelessSymbolicContext statically_known_true torch fx passes fake_tensor_prop FakeTensorProp torch testing FileCheck torch testing _internal common_cuda PLATFORM_SUPPORTS_FLASH_ATTENTION torch testing _internal common_device_type instantiate_device_type_tests OpDTypes ops torch testing _internal common_dtype all_types_complex_float _and torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests skipIfCrossRef skipIfRocm skipIfTorchDynamo skipIfWindows TemporaryFileName TEST_WITH_TORCHDYNAMO TestCase xfailIfTorchDynamo torch testing _internal custom_op_db custom_op_db torch testing _internal inductor_utils GPU_TYPE torch testing _internal jit_utils RUN_CUDA torch testing _internal two_tensor TwoTensor torch utils _mode_utils no_dispatch torch utils _python_dispatch TorchDispatchMode aten = torch ops aten torch _dynamo config fake_tensor_cache_enabled = True torch _dynamo config fake_tensor_cache_crosscheck_enabled = True expectedFailurePropagateRealTensors fn fn _expected_failure_propagate_real_tensors = True fn FakeTensorTest TestCase checkType t device_str size assertTrue isinstance t FakeTensor assertEqual t device type device_str assertEqual list t size size unittest skipIf RUN_CUDA requires cuda test_cuda_initialized doesn t error FakeTensorMode p = torch randn requires_grad=True device= cuda x = torch randn device= cuda y = torch mm x p square sum y backward test_basic x = torch empty device= cpu y = torch empty device= cpu FakeTensorMode mode x = mode from_tensor x y = mode from_tensor y z = x + y assertEqual z shape assertEqual z device torch device cpu assertTrue isinstance z FakeTensor test_custom_op_fallback torch library impl Library try test_lib = Library my_test_op DEF noqa TOR test_lib define foo Tensor - Tensor impl test_lib foo CPU foo_impl cos x = torch empty device= cpu assertRaisesRegex UnsupportedOperatorException my_test_op foo default FakeTensorMode allow_fallback_kernels=True mode x = mode from_tensor x torch ops my_test_op foo x finally test_lib _destroy test_parameter_instantiation FakeTensorMode x = torch rand y = torch nn parameter Parameter x assertTrue isinstance y torch nn Parameter unittest skipIf dist is_available requires distributed test_fsdp_flat_param torch distributed fsdp _flat_param FlatParameter FakeTensorMode m data = torch randn param = FlatParameter data requires_grad=True assertIsInstance param FlatParameter assertIsInstance param torch nn Parameter assertIsInstance param FakeTensor test_non_parameter_grad mode = FakeTensorMode t = torch rand requires_grad=True fake_t = mode from_tensor t assertEqual fake_t requires_grad t requires_grad unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda parametrize dtype all_types_complex_float _and test_index_cuda_with_cpu dtype FakeTensorMode x = torch ones device= cuda dtype=dtype out = x torch zeros dtype=torch int checkType out cuda assertEqual out dtype dtype unittest skipIf RUN_CUDA requires cuda test_shape_take_not_device FakeTensorMode x = torch empty device= cpu y = torch empty device= cuda out = x resize_as_ y assertEqual out shape assertEqual out device type cpu assertTrue isinstance out FakeTensor test_repr FakeTensorMode x = torch empty device= cpu assertEqual repr x FakeTensor size= x = torch empty device= meta assertEqual repr x FakeTensor device= meta size= test_convert_fake_to_real x = torch ones FakeTensorMode allow_non_fake_inputs=True m _ = x + out = torch _subclasses fake_utils try_convert_fake_to_real x assertEqual torch ones out test_conv_nhwc x = torch randn memory_format=torch channels_last w = torch randn memory_format=torch channels_last b = torch randn Model torch nn Module __init__ - None super __init__ forward x w b torch ops aten convolution x w b False model = Model FakeTensorMode allow_non_fake_inputs=True mode fake_out = model forward x w b eager_out = model forward x w b assertEqual fake_out stride eager_out stride unittest skipIf RUN_CUDA requires cuda test_zero_dim FakeTensorMode mode x = torch tensor y = torch rand device= cuda out = x + y assertEqual out shape assertEqual out device y device assertTrue isinstance out FakeTensor unittest skipIf RUN_CUDA requires cuda test_op_with_zero_dim_bypassed torch _functorch config fake_tensor_propagate_real_tensors skipTest Propagate real tensor supported shape_env = ShapeEnv mode = FakeTensorMode shape_env=shape_env x = torch tensor device= cuda y = torch tensor fake_x = mode from_tensor x fake_y = mode from_tensor y assertRaisesRegex RuntimeError Unhandled FakeTensor Device Propagation exc torch nextafter fake_x fake_y test_nan_to_num FakeTensorMode dtype torch float torch float x = torch rand dtype=dtype y = torch nan_to_num x nan=None z = torch nan_to_num x assertEqual dtype y dtype assertEqual dtype z dtype unittest skipIf RUN_CUDA requires cuda test_throw x = torch tensor TODO tensor errors FakeTensorMode mode x_conv = mode from_tensor x y = torch rand device= cuda z = torch rand device= cpu assertRaises Exception lambda torch lerp x_conv y z unittest skipIf RUN_CUDA requires cuda test_type_as FakeTensorMode x = torch rand device= cpu y = torch rand device= cuda out = x type_as y assertEqual out device type cuda assertTrue isinstance out FakeTensor unittest skipIf RUN_CUDA requires cuda test_setitem device cpu cuda FakeTensorMode x = torch rand device=device x = unittest skipIf RUN_CUDA requires cuda test_device_inplace_copy FakeTensorMode x = torch rand device= cpu y = torch rand device= cuda assert x copy_ y device type == cpu assert y copy_ x device type == cuda test_fake_device t = torch ones t = t view fake_mode = FakeTensorMode allow_non_fake_inputs=True fake_t = fake_mode from_tensor t fake_t fake_device = torch device cuda fake_mode = FakeTensorMode allow_non_fake_inputs=True new_fake_t = fake_mode from_tensor fake_t assertEqual new_fake_t device fake_t device test_fake_dispatch_keys FakeTensorMode x = torch rand f = FileCheck check CPU check ADInplaceOrView check AutogradCPU check AutocastCPU f run torch _C _dispatch_key_set x torch inference_mode x = torch rand y = x + x FileCheck check CPU check AutocastCPU run torch _C _dispatch_key_set y FileCheck check_not ADInplaceOrView check_not Autograd run torch _C _dispatch_key_set y test_batch_tensor x = torch rand b = _add_batch_dim x mode = FakeTensorMode fake_b = mode from_tensor b prims utils compare_tensor_meta b fake_b check_strides=True b = _add_batch_dim x b = _add_batch_dim b fake_b = mode from_tensor b prims utils compare_tensor_meta b fake_b check_strides=True assertTrue is_batchedtensor fake_b fake_b = get_unwrapped fake_b assertTrue is_batchedtensor fake_b fake_tensor = get_unwrapped fake_b assertIsInstance fake_tensor FakeTensor test_constructor FakeTensorMode x = torch rand device= cpu assertTrue isinstance x FakeTensor assertTrue x device type == cpu test_mode FakeTensorMode y = torch rand device= cpu out = y + y assertTrue isinstance out FakeTensor test_full Test torch full returns tensor correct dtype torch _subclasses CrossRefFakeMode y = torch full check_function_with_fake fn out = fn torch _subclasses FakeTensorMode out_fake = fn b zip pytree tree_leaves out pytree tree_leaves out_fake isinstance torch Tensor assertTrue isinstance b torch Tensor continue prims utils compare_tensor_meta b check_strides=True unittest skipIf RUN_CUDA requires cuda test_non_kwarg_device FakeTensorMode x = torch rand device= cpu y = x torch device cpu assertIs x y z = x torch device cuda assertEqual z device type cuda test_non_overlapping_stride_zero foo x = torch empty_strided x half check_function_with_fake foo test_fake_mode_error x = torch rand assertRaisesRegex Exception Please convert all Tensors FakeTensorMode y = x test_no_tag_func functools torch nn attention flex_attention _identity flex_attention create_attention score_mod block_mask enable_gqa=False functools partial flex_attention score_mod=score_mod block_mask=block_mask enable_gqa=enable_gqa input_shape = q = torch randn input_shape dtype=torch bfloat device= cpu requires_grad=False k = torch randn input_shape dtype=torch bfloat device= cpu requires_grad=False v = torch randn input_shape dtype=torch bfloat device= cpu requires_grad=False sdpa_partial = create_attention _identity None FakeTensorMode allow_non_fake_inputs=True sdpa_partial q k v return_lse=False unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile test_fake_grad_copy x = torch rand requires_grad=True x grad = torch rand mode = FakeTensorMode fake_x = mode from_tensor x prims utils compare_tensor_meta fake_x x prims utils compare_tensor_meta fake_x grad x grad assertTrue isinstance fake_x grad FakeTensor unittest skipIf RUN_CUDA requires cuda test_index_put_error mode = FakeTensorMode context contextlib nullcontext lambda mode context y = torch randn x = torch randn cuda assertRaises RuntimeError x = y assertRaises RuntimeError torch ops aten index_put x torch tensor device= cuda y no error torch ops aten index_put x torch tensor device= cuda torch tensor torch ops aten index_put_ x torch tensor device= cuda torch tensor unittest skipIf RUN_CUDA requires cuda test_like_constructor FakeTensorMode x = torch rand y = torch ones_like x assertTrue isinstance y FakeTensor assertEqual y device type cpu z = torch ones_like x device= cuda assertTrue isinstance z FakeTensor assertEqual z device type cuda test_binary_op_type_promotion FakeTensorMode x = torch empty dtype=torch float y = torch empty dtype=torch int out = x y assertEqual out dtype torch float assertEqual out device type cpu unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile test_from_numpy FakeTensorMode x = torch tensor np zeros checkType x cpu test_randperm x = torch randperm y = torch randperm device= cpu FakeTensorMode x = torch randperm prims utils compare_tensor_meta x x y = torch randperm device= cpu prims utils compare_tensor_meta y y test_print_in_fake_mode x = torch zeros does fail FakeTensorMode out = str x assert FakeTensor out unittest skipIf RUN_CUDA requires cuda test_upsample_bilinear_small_channels out = mode = FakeTensorMode context contextlib nullcontext lambda mode context arg _ = torch empty_strided dtype=torch float device= cuda unsqueeze = torch ops aten unsqueeze default arg _ out append torch ops aten upsample_bilinear d default unsqueeze False assertTrue out is_contiguous checkMetaProps out out test_split_return_self fn x torch functional split x meta should FakeTensorMode enable_python_dispatcher out_fake = fn torch empty out_eager = fn torch empty checkMetaProps out_fake out_eager unittest skipIf RUN_CUDA requires cuda test_cpu_fallback FakeTensorMode allow_fallback_kernels=False filters = torch randn cuda inputs = torch randn cuda out = torch nn functional conv d inputs filters padding= assertEqual out device type cuda assertEqual list out size FakeTensorMode allow_fallback_kernels=True intentionally bad inputs filters = torch randn cuda inputs = torch randn cuda assertRaises RuntimeError torch nn functional conv d inputs filters padding= FakeTensorMode allow_fallback_kernels=True filters = torch randn cuda inputs = torch randn cuda out = torch nn functional conv d inputs filters padding= assertEqual out device type cuda assertEqual list out size unittest skipIf RUN_CUDA requires cuda test_out_multi_device FakeTensorMode x = torch rand y = torch rand device= cuda assertRaisesRegex Exception found +two +devices torch sin x out=y assertRaisesRegex Exception found +two +devices x add_ y unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda test_normalize_device FakeTensorMode x = torch empty device= cuda y = torch empty device=f cuda torch cuda current_device out = x + y checkType out cuda test_recursive_invocation mode = FakeTensorMode mode x = torch tensor mode in_kernel_invocation = True y = x + x assertTrue mode in_kernel_invocation unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile skipIfRocm parametrize allow_fallback_kernels False True lambda with_fallback without_fallback unittest skipIf RUN_CUDA requires cuda test_cudnn_rnn allow_fallback_kernels fn b b b b b b b b b b b b b b b b = b b b b b b b b b b b b b b b b torch ops aten _cudnn_rnn False False True None mode = FakeTensorMode allow_fallback_kernels=allow_fallback_kernels i context enumerate contextlib nullcontext lambda mode context inps = torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda torch randn cuda inps = inps inps len inps - = None argument ` cx ` can None inps inps inps out = fn inps assertIs out inps - ten out i == assertTrue isinstance ten FakeTensor assertEqual ten device type cuda unittest skipIf RUN_CUDA requires cuda test_cuda_lstm Ensure CUDA non-cuDNN impl succeeds fake tensors torch backends cudnn flags enabled=False fake_tensor_mode = FakeTensorMode allow_fallback_kernels=False fake_tensor_mode N = L = H_in = hidden_size = proj_size = num_layers = bidir = False D = bidir H_out = proj_size proj_size hidden_size lstm = torch nn LSTM input_size=H_in hidden_size=hidden_size num_layers=num_layers proj_size=proj_size batch_first=False bias=True bidirectional=bidir device= cuda h_ = torch randn num_layers D N H_out device= cuda c_ = torch randn num_layers D N hidden_size device= cuda inp = torch randn L N H_in device= cuda output h_n c_n = lstm inp h_ c_ output sum backward assertEqual output shape L N D H_out assertEqual h_n shape D num_layers N H_out assertEqual c_n shape D num_layers N hidden_size test_data_dependent_operator FakeTensorMode allow_fallback_kernels=False x = torch rand assertRaises DynamicOutputShapeException lambda torch nonzero x test_parameter_view x = torch nn Parameter torch randn x_view = x view mode = FakeTensorMode fake_x_view = mode from_tensor x_view fake_x = mode from_tensor x assertFalse isinstance fake_x_view torch nn Parameter assertTrue isinstance fake_x torch nn Parameter test_tolist shape_env = ShapeEnv FakeTensorMode allow_fallback_kernels=False shape_env=shape_env x = torch rand x tolist Propagate real tensors doesn t work fake-on-fake expectedFailurePropagateRealTensors test_same_shape_env_preserved shape_env = ShapeEnv mode = FakeTensorMode shape_env=shape_env t = mode from_tensor torch randn symbolic_context=StatelessSymbolicContext dynamic_sizes= DimDynamic DYNAMIC constraint_sizes= None mode = FakeTensorMode shape_env=shape_env t = mode from_tensor t t size still dynamic even though we didn t pass DYNAMIC here assertIsNot t t assertIs t fake_mode mode assertIs t fake_mode mode assertIs t size node shape_env t size node shape_env assertEqual str t size str t size TODO Support NJT There s also some funny business dynamic shapes which would need dealt well expectedFailurePropagateRealTensors test_jagged_fake_to_fake_preserved torch nested _internal nested_tensor jagged_from_list S S S = D = = torch randn S D requires_grad=True dtype=torch float b = torch randn S D requires_grad=True dtype=torch float c = torch randn S D requires_grad=True dtype=torch float offsets = None jt _ = jagged_from_list b c offsets shape_env = ShapeEnv mode = FakeTensorMode shape_env=shape_env t = mode from_tensor jt mode = FakeTensorMode shape_env=shape_env t = mode from_tensor t It s obvious invocation above makes dynamic does assertTrue free_symbols t size assertIsNot t t assertIs t offsets fake_mode mode assertIs t offsets fake_mode mode assertIs t size node shape_env t size node shape_env assertEqual str t size str t size checkMetaProps t t prims utils compare_tensor_meta t t check_strides=True skipIfCrossRef test_deepcopy FakeTensorMode mode pass mod = torch nn BatchNorm d torch _subclasses fake_tensor FakeCopyMode mode mod_copied = copy deepcopy mod check_copy mod mod_copied name param itertools chain mod named_parameters mod named_buffers param_copied = getattr mod_copied name checkMetaProps param param_copied assertTrue isinstance param_copied FakeTensor assertEqual isinstance param torch nn Parameter isinstance param_copied torch nn Parameter assertEqual param requires_grad param_copied requires_grad check_copy mod mod_copied ModuleNew torch nn Module __init__ - None super __init__ = torch rand b = c = mod = ModuleNew torch _subclasses fake_tensor FakeCopyMode mode mod_copied = copy deepcopy mod assertIs mod_copied mod_copied b assertEqual mod_copied b storage _cdata mod_copied storage _cdata unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda test_new FakeTensorMode = torch rand checkType new cpu checkType new cpu b = torch rand device= cuda checkType b new device= cuda cuda checkType new torch rand cpu unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile test_scalar_inputs FakeTensorMode checkType torch div cpu ten = torch zeros dtype=torch int assertEqual ten dtype torch float checkType ten cpu unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile test_allow_meta run_meta FakeTensorMode x = torch rand device= meta x + x checkType run_meta meta patch object torch _functorch config fake_tensor_allow_meta False assertRaises Exception run_meta test_embedding_bag_meta f This behavior originally unintentional we see people relying embedding = torch nn EmbeddingBag mode= sum device= meta input = torch tensor dtype=torch long offsets = torch tensor dtype=torch long embedding input offsets real_out = f FakeTensorMode fake_out = f r f zip real_out fake_out assertEqual r size f size assertEqual r device f device unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile test_mixed_real_and_fake_inputs _TestPattern torch nn Module __init__ - None super __init__ conv = torch nn Conv d bn = torch nn BatchNorm d forward input running_std = torch sqrt bn running_var + bn eps scale_factor = bn weight running_std weight_shape = len conv weight shape weight_shape = - bias_shape = len conv weight shape bias_shape = - scaled_weight = conv weight scale_factor reshape weight_shape zero_bias = torch zeros_like conv bias dtype=input dtype conv = conv _conv_forward input scaled_weight zero_bias conv_orig = conv scale_factor reshape bias_shape conv_orig = conv_orig + conv bias reshape bias_shape conv = bn conv_orig conv example_inputs = torch randn mod = _TestPattern FakeTensorMode allow_non_fake_inputs=True out = mod torch randn checkType out cpu unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda test_aten_copy_multi_device FakeTensorMode x = torch rand device= cpu x = torch rand device= cuda copy = torch ops aten copy default x x copy = torch ops aten copy default x x out = torch empty device= cpu torch ops aten copy out x x out=out checkType copy cpu checkType copy cuda checkType out cpu unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda test_aten_index_multi_device FakeTensorMode x = torch rand device= cpu x = torch rand device= cuda i = torch tensor device= cuda i = torch tensor device= cpu NB This one does work cuda indices allowed cpu tensor r = torch ops aten index x i r = torch ops aten index x i y = torch rand device= cpu y = torch rand device= cuda j = torch tensor device= cuda j = torch tensor device= cpu r = torch ops aten index_put default x j y r = torch ops aten index_put default x j y checkType r cpu checkType r cuda checkType r cpu checkType r cuda unittest skipIf TEST_WITH_TORCHDYNAMO isinstance check FakeTensor won t work compile unittest skipIf RUN_CUDA requires cuda test_aten_slice_scatter_multi_device FakeTensorMode x = torch rand device= cpu y = torch rand device= cuda x = torch rand device= cuda y = torch rand device= cpu out = torch empty device= cpu r = torch ops aten slice_scatter default x y start= r = torch ops aten slice_scatter default x y start= r = torch ops aten slice_scatter out x y out=out start= checkType r cpu checkType r cuda checkType r cpu checkType out cpu test__adaptive_avg_pool d_backward FakeTensorMode grad_out = torch rand inp = torch rand memory_format=torch channels_last grad_in = torch ops aten _adaptive_avg_pool d_backward grad_out inp assertTrue torch _prims_common suggest_memory_format grad_in == torch channels_last test_export_numpy MyNumpyModel torch nn Module forward input input = input numpy input + np random randn input shape FakeTensorMode ep = torch export export MyNumpyModel args= torch randn strict=True assertTrue isinstance ep torch export ExportedProgram test_unsqueeze_copy shape_env = ShapeEnv t = torch ones FakeTensorMode shape_env=shape_env fake_mode t = fake_mode from_tensor t symbolic_context=StatelessSymbolicContext dynamic_sizes= DimDynamic DYNAMIC DimDynamic STATIC DimDynamic STATIC assertEqual t shape torch ops aten unsqueeze_copy t shape test_alias_call fwAD = torch autograd forward_ad f x x torch _subclasses fake_tensor FakeTensorMode fwAD dual_level x = torch randn device= cpu y = torch ones_like x dual = fwAD make_dual x y r = f dual assertIsInstance r FakeTensor assertEqual r size parametrize reverse False True test_scan reverse add x y x + y x + y torch _subclasses fake_tensor FakeTensorMode x = torch randn device= cpu init = torch randn device= cpu r = scan add init x dim= reverse=reverse assertIsInstance r FakeTensor assertIsInstance r FakeTensor test_fast_div mode = FakeTensorMode mode x = torch empty device= cpu dtype=torch int torch _subclasses fake_impls get_fast_op_impls fast_div = get_fast_op_impls torch ops aten div Tensor y = fast_div mode x assertEqual y dtype torch float test_nanmean_out Regression test ensure we don t error out torch _subclasses fake_tensor FakeTensorMode mode x = torch randn out = torch empty torch nanmean x out=out assertEqual out dtype x dtype test_unbind_copy_out Regression test ensure we don t error out torch _subclasses fake_tensor FakeTensorMode mode eye = torch eye out = torch zeros torch zeros torch zeros torch unbind_copy eye out=out assertEqual out dtype eye dtype assertEqual out dtype eye dtype assertEqual out dtype eye dtype instantiate_parametrized_tests FakeTensorTest make_propagate_real_tensors_cls cls cls = make_test_cls_with_patches cls PropagateRealTensors _propagate_real_tensors torch _functorch config fake_tensor_propagate_real_tensors True xfail_prop= _expected_failure_propagate_real_tensors decorator=skipIfTorchDynamo propagate_real_tensors affects Dynamo cls __file__ = __file__ cls __module__ = __name__ globals cls __name__ = cls make_propagate_real_tensors_cls FakeTensorTest FakeTensorConstHandling TestCase assertConst args arg args assertTrue arg constant None assertNotConst args arg args assertTrue arg constant None test_simple FakeTensorMode x = torch tensor assertEqual x item test_inplace_add FakeTensorMode x = torch tensor y = x add_ assertEqual x item assertEqual y item assertConst x y test_shared_storages FakeTensorMode x = torch tensor y = x assertEqual x storage _cdata y storage _cdata assertEqual x constant storage _cdata y constant storage _cdata test_constant_invalidation FakeTensorMode x = torch tensor assertConst x y = torch rand x add_ y assertNotConst x test_inplace_view_invalidation FakeTensorMode x = torch tensor assertConst x x resize_ assertEqual x size assertNotConst x test_fake_tensor_in_intlist_repro fn tensors max_size = torch tensor dtype=torch int batch_shape = len tensors + list tensors shape - + list max_size tensors new_full batch_shape assertRaises torch _subclasses fake_tensor DataDependentOutputException torch _subclasses fake_tensor FakeTensorMode = torch randn b = torch randn inputs = b ref = fn inputs test_fake_tensor_batch_norm_cpu torch _subclasses CrossRefFakeMode m = torch nn Sequential torch nn BatchNorm d torch nn ReLU m eval out = m torch randn test_shared_storage_invalidation FakeTensorMode x = torch tensor y = x assertConst x y y add_ torch rand assertNotConst x y test_aliased_const_write FakeTensorMode x = torch tensor y = x expand assertNotConst y y = assertNotConst x test_constant_propagate_through_functions FakeTensorMode y = torch div rounding_mode= trunc assertConst y make_propagate_real_tensors_cls FakeTensorConstHandling contains_type type torch Type maybe_contained_type torch Type maybe_contained_type isSubtypeOf type any contains_type e maybe_contained_type e type containedTypes FakeTensorOpInfoTest TestCase ops custom_op_db dtypes=OpDTypes any_one test_fake device dtype op sample_inputs_itr = op sample_inputs device dtype requires_grad=False sample_input sample_inputs_itr args = sample_input input + sample_input args kwargs = sample_input kwargs optests fake_check op args kwargs make_propagate_real_tensors_cls FakeTensorOpInfoTest instantiate_device_type_tests FakeTensorOpInfoTest globals only_for= cpu cuda instantiate_device_type_tests PropagateRealTensorsFakeTensorOpInfoTest noqa F globals only_for= cpu FakeTensorConverterTest TestCase test_memoized_conversion_to_meta x = torch rand mode = FakeTensorMode assertTrue mode from_tensor x mode from_tensor x test_memoized_conversion_from_meta x = torch rand device= meta mode = FakeTensorMode converter = mode fake_tensor_converter assertTrue converter from_meta_and_device mode x cpu converter from_meta_and_device mode x cpu test_separate_tensor_storages_view x = torch rand y = x mode = FakeTensorMode converter = mode fake_tensor_converter x_conv = converter from_real_tensor mode x y_conv = converter from_real_tensor mode y assertEqual torch _C _storage_id x_conv torch _C _storage_id y_conv xfailIfTorchDynamo test_separate_tensor_storages_non_view x = torch rand y = torch rand y set_ x storage mode = FakeTensorMode converter = mode fake_tensor_converter x_conv = converter from_real_tensor mode x y_conv = converter from_real_tensor mode y stor_id = torch _C _storage_id x_conv assertEqual stor_id torch _C _storage_id y_conv del x del x_conv assertEqual len converter tensor_memo assertEqual len converter meta_converter storage_memo del y del y_conv assertEqual len converter tensor_memo assertEqual len converter meta_converter storage_memo test_dead_weak_ref x = torch rand y = x mode = FakeTensorMode converter = FakeTensorConverter x_conv = converter from_real_tensor mode x x_conv_storage = x_conv untyped_storage del x_conv assertFalse x converter tensor_memo y_conv = converter from_real_tensor mode y assertIs x_conv_storage y_conv untyped_storage xfailIfTorchDynamo test_dead_key x = torch rand mode = FakeTensorMode converter = FakeTensorConverter x_conv = converter from_real_tensor mode x assertEqual len converter tensor_memo x_conv = converter from_real_tensor mode x assert x_conv x_conv del x del x_conv del x_conv assertEqual len converter tensor_memo test_no_active_mode FakeTensorMode mode x = torch empty device= cpu y = torch empty device= cpu out = x + y assertEqual mode out fake_mode assertTrue isinstance out FakeTensor assertEqual out device type cpu test_multiple_modes t = torch rand t = torch rand FakeTensorMode m FakeTensorMode m t_fake = m from_tensor t t _fake = m from_tensor t assertRaisesRegex Exception Mixing fake modes t_fake + t _fake test_separate_mode_error FakeTensorMode x = torch empty device= cpu FakeTensorMode y = torch empty device= cpu assertRaises Exception lambda x y xfailIfTorchDynamo test_no_ref_cycle x = torch rand mode = FakeTensorMode y = mode from_tensor x assertEqual len mode fake_tensor_converter tensor_memo mode_weak = weakref ref mode y_weak = weakref ref mode del mode del y assert mode_weak None assert y_weak None make_propagate_real_tensors_cls FakeTensorConverterTest FakeTensorOperatorInvariants TestCase get_aten_op schema namespace name = schema name split overload = schema overload_name schema overload_name default assert namespace == aten getattr getattr torch ops aten name overload get_all_aten_schemas schema torch _C _jit_get_all_schemas namespace = schema name split namespace = aten continue yield schema test_non_kwarg_only_device schema get_all_aten_schemas ten_type = torch _C TensorType get any contains_type arg type ten_type arg itertools chain schema arguments schema returns continue opt_device = torch _C OptionalType torch _C DeviceObjType get has_non_kwarg_device = any arg kwarg_only arg type isSubtypeOf opt_device arg schema arguments has_non_kwarg_device assertTrue get_aten_op schema torch _subclasses fake_tensor _device_not_kwarg_ops test_tensor_constructors_all_have_kwarg_device schema get_all_aten_schemas op = get_aten_op schema torch _subclasses fake_tensor _is_tensor_constructor op continue opt_device = torch _C OptionalType torch _C DeviceObjType get has_kwarg_device = any arg kwarg_only arg type isSubtypeOf opt_device arg schema arguments assertTrue has_kwarg_device op == torch ops aten _list_to_tensor default unittest expectedFailure test_sparse_new FakeTensorMode indices = torch randn dtype=torch int values = torch randn extra = sparse = torch randn to_sparse This used segfault now does still raises error sparse = sparse new indices values extra test_tensor_new FakeTensorMode x = torch Tensor assertIsInstance x FakeTensor test_like_ops schema get_all_aten_schemas _like == schema name - op = get_aten_op schema assertIn op torch _subclasses fake_tensor _like_tensor_constructors test_str_storage x = torch zeros FakeTensorMode m y = m from_tensor x assertExpectedInline str x storage \ torch storage TypedStorage dtype=torch float device=cpu size assertExpectedInline str y storage \ torch storage TypedStorage dtype=torch float device=meta size assertExpectedInline str y storage \ torch storage TypedStorage dtype=torch float device=meta size _embedding_bag has no op info returns extra tensors embedding bag throws away test_embedding_bag_private args = torch ones torch ones dtype=torch int torch arange dtype=torch int False mode = max ref_out = torch ops aten _embedding_bag args FakeTensorMode m meta_args = m from_tensor isinstance torch Tensor args meta_out = torch ops aten _embedding_bag meta_args assertEqual len ref_out len meta_out ref_o meta_o zip ref_out meta_out assertEqual ref_o size meta_o size test_cross_entropy_loss inp = torch randn target = torch randint dtype=torch long weight = torch rand fn = torch nn functional cross_entropy w weight None args = inp target w ref = fn args FakeTensorMode m meta_args = m from_tensor isinstance torch Tensor args meta_out = torch nn functional cross_entropy meta_args label_smoothing= assertEqual ref size meta_out size unittest skipIf PLATFORM_SUPPORTS_FLASH_ATTENTION Does support SDPA pre-SM hardware test_flash_attention Repro torch nn Module __init__ - None super __init__ forward arg arg arg torch ops aten _scaled_dot_product_flash_attention arg arg arg scale= args_new = torch float cuda torch float cuda torch float cuda torch float cuda torch float cuda torch float cuda args_list args_new args = rand_strided bsz num_heads seq_len head_dim bsz num_heads seq_len head_dim args_list try torch _subclasses CrossRefFakeMode Repro args except MetadataMismatchError e We expect cross ref succeed first output fail rng state see Note Seed Offset assertTrue output str e __class__ __name__ startswith PropagateRealTensors assertTrue Real tensor propagation found metadata mismatch str e assertTrue found mismatched tensor metadata output str e IMPORTANT Always run even CUDA available test_fake_gpu_no_init Skip test we will try run CUDA operations real prop so clearly will work CPU runner torch _functorch config fake_tensor_propagate_real_tensors skipTest Propagate real tensor supported FakeTensorMode allow_non_fake_inputs=True assertEqual torch empty device=GPU_TYPE device type GPU_TYPE assertEqual torch ones device=GPU_TYPE device type GPU_TYPE assertEqual torch zeros device=GPU_TYPE device type GPU_TYPE assertEqual torch rand device=GPU_TYPE device type GPU_TYPE assertEqual torch tensor device=GPU_TYPE device type GPU_TYPE assertEqual torch tensor device=GPU_TYPE device type GPU_TYPE unittest skipIf torch backends cuda is_built requires CUDA build test_move_module_under_fake torch _functorch config fake_tensor_propagate_real_tensors skipTest Propagate real tensor supported Module torch nn Module __init__ super __init__ linear = torch nn Linear buffer = torch nn Buffer torch rand param = torch nn Parameter torch rand forward x linear x + buffer + param m = Module input = torch rand gpu_device = torch device GPU_TYPE FakeTensorMode allow_non_fake_inputs=True m device=gpu_device arg = input device=gpu_device out = m arg p m parameters assertTrue isinstance p FakeTensor assertEqual p device gpu_device b m buffers assertTrue isinstance b FakeTensor assertEqual b device gpu_device assertTrue isinstance out FakeTensor assertEqual out device gpu_device unittest skipIf RUN_CUDA requires cuda test_move_meta_tensor torch _functorch config fake_tensor_propagate_real_tensors skipTest Propagate real tensor supported meta_tensor = torch ones device= meta FakeTensorMode allow_non_fake_inputs=True assertEqual meta_tensor device= cpu device type cpu assertEqual meta_tensor device=GPU_TYPE device type GPU_TYPE unittest skipIf RUN_CUDA requires cuda test_conv_c _backward Repro torch nn Module __init__ - None super __init__ forward arg arg arg torch ops aten convolution_backward default arg arg arg False True True False args_new = torch float cuda torch float cuda torch float cuda args = rand_strided sh st dt dev sh st dt dev args_new torch _subclasses CrossRefFakeMode Repro args test_no_dispatch_with_like_function CountingMode TorchDispatchMode __init__ - None count = __torch_dispatch__ func types args= kwargs=None count += func args kwargs FakeTensorMode x = torch randn CountingMode mode no_dispatch torch zeros_like x assertEqual mode count PropagateRealTensors installs weakrefs expectedFailurePropagateRealTensors unittest skipIf RUN_CUDA requires cuda test_module_to _check_device sd device_type v sd values assertEqual v device type device_type FakeTensorMode m = torch nn Linear _check_device m state_dict cpu m cuda _check_device m state_dict cuda make_propagate_real_tensors_cls FakeTensorOperatorInvariants FakeTensorPropTest TestCase test_fake_tensor_prop_on_nn_module ToyNnModuleWithParameters torch nn Module __init__ - None super __init__ layer = torch nn Linear layer = torch nn Linear forward value value = layer value value = torch relu value value = layer value value model = ToyNnModuleWithParameters value = torch randn Convert nn Module GraphModule so FakeTensorProp runs graph_model = torch fx symbolic_trace model value The following block runs FakeTensorProp graph_module w same FakeTensorMode TODO wschin there should API run FakeTensorProp GraphModule parameters buffers FakeTensorMode fake_tensor_mode to_fake_tensor x isinstance x torch Tensor isinstance x FakeTensor fake_tensor_mode from_tensor x x fake_parameters_and_buffers = k to_fake_tensor v k v itertools chain graph_model named_parameters graph_model named_buffers torch nn utils stateless _reparametrize_module graph_model fake_parameters_and_buffers This case uses same fake tensor mode create fake parameters fake buffers run FakeTensorProp The result should correct result = FakeTensorProp graph_model fake_tensor_mode propagate value assertTrue isinstance result FakeTensor assertEqual result shape This case uses different fake tensor modes create fake parameters fake buffers run FakeTensorProp The following code should fail failed = False try FakeTensorProp graph_model propagate value except AssertionError AssertionError tensor s device must ` meta ` got cpu instead failed = True assertTrue failed test_fake_tensor_prop_on_nn_module_with_optional_args OptionalArgumentInBetween torch nn Module __init__ - None super __init__ layer = torch nn Linear layer = torch nn Linear forward value another_value=None another_optional_value=None Mimic huggingface s ` forward ` methods which have several optional arguments For example GPT accepts forward input_ids None attention_mask To apply FakeTensorProp its from_real_tensor needs accept None another_value None another_value = torch rand_like value another_optional_value None another_optional_value = torch rand_like value value = value + another_value + another_optional_value value value fake_mode = FakeTensorMode allow_non_fake_inputs=True allow_fallback_kernels=False fake_mode model = OptionalArgumentInBetween value = torch randn another_optional_value = torch randn graph_model = torch fx symbolic_trace model value None another_optional_value FakeTensorProp graph_model fake_mode propagate value None another_optional_value test_unbacked_shape_realloc f x x nonzero shape_env = ShapeEnv fake_mode = FakeTensorMode shape_env=shape_env fake_mode value = torch randn gm = make_fx f value nonzero_nodes = n n gm graph nodes n target torch ops aten nonzero default assertEqual len nonzero_nodes assertIsInstance nonzero_nodes meta val shape torch SymInt u = nonzero_nodes meta val shape FakeTensorProp gm fake_mode propagate value u = nonzero_nodes meta val shape Test test actually doing something FakeTensorProp actually triggered reallocation If assert failing could because we started memoizing nnz count nonzero which nice some sense no reallocation helpful test which checking what we do when we have reallocate If so you need make example more complicated e g maybe have nontrivial computation input before feeding into nonzero have some sort randomness assertIsNot u u assertTrue statically_known_true u == u test_nonzero_stride shape_env = ShapeEnv fake_mode = FakeTensorMode shape_env=shape_env fake_mode value = torch ones fake_r = value nonzero r = torch ones nonzero assertEqual fake_r T is_contiguous r T is_contiguous test_nan_to_num shape_env = ShapeEnv fake_mode = FakeTensorMode shape_env=shape_env fake_mode x = torch randn t y = torch nan_to_num x nan= posinf= neginf= assertEqual x size y size assertEqual x stride y stride unittest skipIf RUN_CUDA requires cuda test_torch_load_with_fake_mode model = torch nn Linear sd = model state_dict sd tt = TwoTensor torch randn torch randn _read_tensor_and_check key sd_loaded all_bytes device dtype = torch float t = sd_loaded key assertEqual t device type device isinstance t TwoTensor untyped_storage_a untyped_storage_b = t untyped_storage t b untyped_storage offset_a offset_b = untyped_storage_a _checkpoint_offset untyped_storage_b _checkpoint_offset nbytes_a nbytes_b = untyped_storage_a nbytes untyped_storage_b nbytes result_a = torch frombuffer all_bytes dtype=dtype count=nbytes_a offset=offset_a resize_ t size result_b = torch frombuffer all_bytes dtype=dtype count=nbytes_b offset=offset_b resize_ t b size assertEqual TwoTensor result_a result_b sd key untyped_storage = t untyped_storage offset = untyped_storage _checkpoint_offset nbytes = untyped_storage nbytes result = torch frombuffer all_bytes dtype=dtype count=nbytes offset=offset resize_ t size assertEqual result sd key TemporaryFileName f torch serialization safe_globals TwoTensor Create state_dict loaded later torch save sd f open f rb g all_bytes = g read fake_mode = FakeTensorMode fake_mode sd_loaded = torch load f k sd _read_tensor_and_check k sd_loaded all_bytes cpu fake_mode sd_loaded = torch load f map_location= cuda k sd _read_tensor_and_check k sd_loaded all_bytes cuda k sd keys sd k = sd k cuda TemporaryFileName f torch serialization safe_globals TwoTensor torch save sd f open f rb g all_bytes = g read fake_mode = FakeTensorMode fake_mode sd_loaded = torch load f k sd _read_tensor_and_check k sd_loaded all_bytes cuda fake_mode sd_loaded = torch load f map_location= cpu k sd _read_tensor_and_check k sd_loaded all_bytes cpu make_propagate_real_tensors_cls FakeTensorPropTest FakeTensorSerialization TestCase test_serialization x = torch tensor device= cpu FakeTensorMode y = pickle loads pickle dumps x assertEqual type y FakeTensor assertEqual y device type meta unset_fake_temporarily y = pickle loads pickle dumps x assertEqual x device y device test_serialization_with_tracing x = torch tensor device= cpu tracing TracingContext FakeTensorMode y = pickle loads pickle dumps x assertEqual x device y device FakeTensorDispatchCache TestCase test_shape_env_settings Validation any boolean settings ShapeEnv present ShapeEnvSettings We hope ensure any new settings might affect FakeTensor dispatch included cache key calculation If test fails consider updating ShapeEnvSettings change test omit checking new field init_sig = inspect signature ShapeEnv _init args = name name param init_sig parameters items type param default bool settings = f name f dataclasses fields ShapeEnvSettings arg args assertTrue arg settings _test_cache_key fm x y z Helper all test_cache_key_ tests below Assert cache keys inputs x y same z different func = aten add Tensor state = _CacheKeyState key_x = fm _cache_key state func x key_y = fm _cache_key state func y key_z = fm _cache_key state func z assertEqual key_x key_y assertNotEqual key_x key_z test_cache_key_dtype FakeTensorMode fm x = torch randn dtype=torch float y = torch randn dtype=torch float z = x dtype=torch float _test_cache_key fm x y z test_cache_key_shape FakeTensorMode fm x = torch randn y = torch randn z = torch randn _test_cache_key fm x y z test_cache_key_stride FakeTensorMode fm x = torch randn y = torch randn z = x as_strided _test_cache_key fm x y z unittest skipIf RUN_CUDA requires cuda test_cache_key_device FakeTensorMode fm x = torch randn y = torch randn z = x device= cuda _test_cache_key fm x y z test_cache_key_memory_format FakeTensorMode fm x = torch randn y = torch randn z = x memory_format=torch channels_last _test_cache_key fm x y z test_cache_key_storage_offset FakeTensorMode fm x = torch randn y = torch randn z = torch randn _test_cache_key fm x y z test_cache_key_requires_grad FakeTensorMode fm x = torch randn y = torch randn z = torch randn requires_grad=True _test_cache_key fm x y z test_cache_key_is_conj FakeTensorMode fm x = torch randn dtype=torch complex y = torch randn dtype=torch complex z = torch randn dtype=torch complex torch _C _set_conj z z is_conj _test_cache_key fm x y z test_cache_key_is_neg FakeTensorMode fm x = torch randn dtype=torch complex y = torch randn dtype=torch complex z = torch randn dtype=torch complex torch _C _set_neg z z is_neg _test_cache_key fm x y z test_cache_key_is_inference torch inference_mode True t = torch randn FakeTensorMode fm x = torch randn y = torch randn z = fm from_tensor t _test_cache_key fm x y z test_cache_key_constants FakeTensorMode fm Python hashes same value Make sure cache key calculation differentiates them _test_cache_key fm _test_cache_key fm test_empty_list FakeTensorMode fm func = aten any dims state = _CacheKeyState x = torch ones key_x = fm _cache_key state func x key_y = fm _cache_key state func x assertNotEqual key_x key_y assertHitsMisses hits misses Helper assert number recorded hits misses info = FakeTensorMode cache_info assertEqual info hits hits assertEqual info misses misses assertBypasses reason count Helper assert number recorded bypasses info = FakeTensorMode cache_info count assertIn reason info bypasses assertEqual info bypasses reason count assertNotIn reason info bypasses test_cache_hit Test cache hit miss counters updated correctly FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses res = x + y assertHitsMisses res = x + y assertHitsMisses assertEqual extract_tensor_metadata res extract_tensor_metadata res test_cache_bypass Test cache bypass counters updated correctly FakeTensorMode x = torch randn FakeTensorMode cache_clear assertBypasses inplace view x unsqueeze_ assertBypasses inplace view test_cache_default_dtype Test default dtype respected when serving cached results FakeTensorMode x = torch tensor dtype=torch int torch set_default_dtype torch float FakeTensorMode cache_clear assertHitsMisses y = x + assertEqual y dtype torch float assertHitsMisses torch set_default_dtype torch float y = x + assertEqual y dtype torch float assertHitsMisses torch set_default_dtype torch float y = x + assertEqual y dtype torch float assertHitsMisses unittest skipIf RUN_CUDA requires cuda test_cache_default_device Test default device respected when serving cached results FakeTensorMode FakeTensorMode cache_clear assertHitsMisses torch set_default_device cpu x = torch tensor y = x + assertEqual y device type cpu assertHitsMisses torch set_default_device cuda x = torch tensor y = x + assertEqual y device type cuda assertHitsMisses torch set_default_device cpu x = torch tensor y = x + assertEqual y device type cpu assertHitsMisses test_cache_inplace_op Test inplace ops served cache correctly reference input parameter FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses z = x add_ y assertHitsMisses assertEqual id x id z w = x add_ y assertHitsMisses assertEqual id x id w test_cache_view_op Test view ops handled correctly when served cache FakeTensorMode x = torch ones requires_grad=True clone x = torch ones requires_grad=True clone y = x view - Test operating non-view tensor then same operation view tensor Assert view property set correctly z = x mul_ assertFalse z _is_view z = y mul_ assertTrue z _is_view Now other way around first operate view tensor then same operation non-view tensor z = y mul_ assertTrue z _is_view z = x mul_ assertFalse z _is_view test_cache_dispatch_key_set Test operations change dispatch key set bypass caching FakeTensorMode FakeTensorMode cache_clear assertBypasses dispatch_key_set mismatch x = torch _efficientzerotensor assertTrue x _is_zerotensor assertBypasses dispatch_key_set mismatch y = torch _efficientzerotensor assertTrue y _is_zerotensor assertBypasses dispatch_key_set mismatch test_fft_hfft _issue FakeTensorMode s = s = s = s = s = s = x = torch randn s s s out = torch randn s s s kwargs = s s s dim s norm ortho r = torch _C _fft fft_hfft x kwargs out=out assertEqual r shape out shape test_inference_mode Test caching handles inference mode correctly FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses Expect miss when inference mode different res = x + y torch inference_mode res = x + y assertHitsMisses assertFalse res is_inference assertTrue res is_inference Second tries should see hits res = x + y assertHitsMisses assertFalse res is_inference assertEqual extract_tensor_metadata res extract_tensor_metadata res torch inference_mode res = x + y assertHitsMisses assertTrue res is_inference assertEqual extract_tensor_metadata res extract_tensor_metadata res unittest skipIf RUN_CUDA requires cuda test_wrapper_tensor_subclass_different_device DifferentDeviceTensor torch Tensor staticmethod __new__ cls kwargs = kwargs strides = stride kwargs storage_offset = storage_offset kwargs device = torch device cpu kwargs layout = layout kwargs requires_grad = requires_grad kwargs dtype = dtype out = torch Tensor _make_wrapper_subclass cls size kwargs out __init__ inner_tensor = __repr__ f DifferentDeviceTensor repr inner_tensor __tensor_flatten__ inner_tensor None staticmethod __tensor_unflatten__ inner_tensors meta outer_size outer_stride assert meta None DifferentDeviceTensor inner_tensors inner_tensor classmethod __torch_dispatch__ cls func types args kwargs kwargs None kwargs = args = pytree tree_map_only DifferentDeviceTensor lambda x x inner_tensor args kwargs = pytree tree_map_only DifferentDeviceTensor lambda x x inner_tensor kwargs Returns unwrapped tensor func args kwargs = torch ones device= cuda wrapped_a = DifferentDeviceTensor Outer Tensor cpu inner cuda assertTrue wrapped_a is_cpu assertFalse wrapped_a inner_tensor is_cpu FakeTensorMode fake_mode fake_wrapped_a = fake_mode from_tensor wrapped_a assertTrue fake_wrapped_a is_cpu assert isinstance fake_wrapped_a DifferentDeviceTensor assertFalse fake_wrapped_a inner_tensor is_cpu test__upsample_bilinear d_aa_backward_dynamic_shapes f x torch nn functional interpolate x size= mode= bilinear align_corners=False antialias=True shape_env = ShapeEnv fake_m = FakeTensorMode shape_env=shape_env x = fake_m from_tensor torch randn requires_grad=True symbolic_context=StatelessSymbolicContext dynamic_sizes= DimDynamic STATIC DimDynamic STATIC DimDynamic DYNAMIC DimDynamic DYNAMIC constraint_sizes= None None None None fake_m enable_python_dispatcher out = f x out sum backward assertEqual x shape x grad shape test_from_buffer FakeTensorMode obj = f = io BytesIO pickle Pickler f dump obj storage = torch UntypedStorage from_buffer f getvalue dtype=torch uint t = torch ByteTensor storage assertTrue isinstance t FakeTensor assertEqual t device torch device cpu test_meta_tensor_to_fake_cpu x = torch randn device= meta FakeTensorMode allow_non_fake_inputs=True x_cpu = x device= cpu assertTrue isinstance x_cpu FakeTensor assertEqual x_cpu device torch device cpu test_cache_tuple_outputs Test check ops tuple outputs work FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses ref = torch split x assertHitsMisses res = torch split y assertHitsMisses assertEqual len ref len res b zip ref res assertEqual extract_tensor_metadata extract_tensor_metadata b test_cache_aten_index FakeTensorMode x = torch randn idx_tensor = torch tensor idx_tensor = torch tensor FakeTensorMode cache_clear assertHitsMisses ref = torch ops aten index x None idx_tensor idx_tensor assertHitsMisses res = torch ops aten index x None idx_tensor idx_tensor assertHitsMisses assertEqual extract_tensor_metadata ref extract_tensor_metadata res FakeTensorMode x = torch randn idx_tensor = torch tensor True True False True assertRaises DynamicOutputShapeException lambda torch ops aten index x None idx_tensor idx_tensor = torch tensor - - dtype=torch int assertRaises DynamicOutputShapeException lambda torch ops aten index x None idx_tensor skipIfWindows msg= weird bug - cache may cleared after https github com pytorch pytorch pull skipIfTorchDynamo cache hit miss changes invoke_subgraph caching test_invoke_subgraph Tests invoke subgraph invoke_subgraph = torch _higher_order_ops invoke_subgraph run fn x y x + y Ensure there no caching non-Fx graph module inputs FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses ref = invoke_subgraph fn subgraph x y assertHitsMisses assertBypasses function argument res = invoke_subgraph fn subgraph x y The hits ops inside fn assertHitsMisses assertBypasses function argument res = invoke_subgraph fn subgraph x y The hits ops inside fn assertHitsMisses assertBypasses function argument Get mod its going through torch compile backend = torch _dynamo testing AotEagerAndRecordGraphs x = torch randn y = torch randn torch compile fn backend=backend fullgraph=True x y assertEqual len backend fw_graphs mod = backend fw_graphs Ensure we see hits every time FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses ref = invoke_subgraph mod subgraph x y assertHitsMisses res = invoke_subgraph mod subgraph x y The hits re-running subgraph assertHitsMisses res = invoke_subgraph mod subgraph x y The hits re-running subgraph assertHitsMisses assertEqual len ref len res assertEqual len ref len res b zip ref res assertEqual extract_tensor_metadata extract_tensor_metadata b assertTrue count_invoke_subgraph_keys count_invoke_subgraph_keys invoke_subgraph_keys = cache_key FakeTensorMode cache keys isinstance cache_key key torch _ops HigherOrderOperator invoke_subgraph_keys += invoke_subgraph_keys Check graph gc clears cache run torch compiler reset gc collect assertTrue count_invoke_subgraph_keys == skipIfTorchDynamo cache hit miss changes invoke_subgraph caching test_invoke_subgraph_cacheable_inplace invoke_subgraph = torch _higher_order_ops invoke_subgraph fn x y aten ops used so eager backend graph suitable fake tensor testing cos = torch ops aten cos default x inplace-view - should cause whole invoke_subgraph being able cache t = torch ops aten t_ default cos mul = torch ops aten mul Tensor t y mul Get mod its going through torch compile backend = torch _dynamo testing AotEagerAndRecordGraphs x = torch randn y = torch randn torch compile fn backend=backend fullgraph=True x y assertEqual len backend graphs mod = backend graphs Ensure invoke_subgraph result still cached FakeTensorMode x = torch randn y = torch randn FakeTensorMode cache_clear assertHitsMisses ref = invoke_subgraph mod subgraph x y assertHitsMisses res = invoke_subgraph mod subgraph x y The hits ops inside fn subgraph assertHitsMisses res = invoke_subgraph mod subgraph x y The hits ops inside fn subgraph assertHitsMisses assertEqual len ref len res assertEqual len ref len res b zip ref res assertEqual extract_tensor_metadata extract_tensor_metadata b skipIfTorchDynamo cache hit miss changes invoke_subgraph caching test_unbacked_output The point test have op which has no symbols input symbol output make sure we skip caching LengthsGather torch nn Module forward input torch Tensor lengths torch Tensor indices torch Tensor offsets torch Tensor - torch Tensor bias = torch gather offsets indices lengths_selected = torch gather lengths indices index = torch repeat_interleave bias lengths_selected dim= index input = torch tensor lengths = torch tensor indices = torch tensor offsets = torch cumsum lengths ep = torch export export LengthsGather input lengths indices offsets strict=False FakeTensorMode cache_clear ep run_decompositions assertBypasses unrepresented symbol output FakeTensorPreferDeviceType TestCase unittest skipIf RUN_CUDA requires cuda test_fake_tensor_prefer_device_type Test fake_tensor_prefer_device_type configuration works correctly device mismatch scenarios Create custom operation would normally cause device mismatch mixed_device_op b This simulates operation where MTIA CUDA b created CPU cpu_tensor = torch arange shape device= cpu + cpu_tensor unsqueeze - FakeTensorMode Test default behavior should raise error device mismatch cuda_tensor = torch randn device= cuda Without config should raise device mismatch error assertRaisesRegex RuntimeError Unhandled FakeTensor Device Propagation mixed_device_op cuda_tensor None Test prefer_device_type set cuda torch _functorch config patch fake_tensor_prefer_device_type= cuda FakeTensorMode cuda_tensor = torch randn device= cuda This should now work prefer CUDA device result = mixed_device_op cuda_tensor None The result should CUDA device preferred device type assertEqual result device type cuda assertEqual result shape assertTrue isinstance result FakeTensor Test configuration doesn t affect normal operations torch _functorch config patch fake_tensor_prefer_device_type= cuda FakeTensorMode Normal same-device operations should work before x = torch randn device= cuda y = torch randn device= cuda result = x + y assertEqual result device type cuda CPU operations should still work x_cpu = torch randn device= cpu y_cpu = torch randn device= cpu result_cpu = x_cpu + y_cpu assertEqual result_cpu device type cpu Test configuration properly scoped FakeTensorMode cuda_tensor = torch randn device= cuda After exiting config context should raise error again assertRaisesRegex RuntimeError Unhandled FakeTensor Device Propagation mixed_device_op cuda_tensor None test_fake_tensor_prefer_device_type_cpu_only Test fake_tensor_prefer_device_type works correctly when only CPU tensors involved torch _functorch config patch fake_tensor_prefer_device_type= cuda FakeTensorMode When all tensors CPU result should still CPU x = torch randn device= cpu y = torch randn device= cpu result = x + y assertEqual result device type cpu assertTrue isinstance result FakeTensor __name__ == __main__ run_tests