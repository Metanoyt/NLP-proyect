Inductor Pattern Matcher The pattern matcher enables search replace within FX graph The main entrypoint pattern matcher register_replacement Given search function replacement function will register replacement pass such torch _inductor fx_passes joint_graph patterns Internally pattern matcher represents patterns graph DAG Creating new patterns manually graph cumbersome error-prone so standard way create patterns using register_replacement provide search function replacement function which traced converted into graph Because search functions built somewhat generic they tend ignore tensor sizes example register_replacement allows you specify ` extra_check ` function which performs additional checks verify matched pattern fully matches before returning ## Precompiled Patterns New patterns added using register_replacement Patterns added way can have compile-time overhead because they need traced before use Patterns can precompiled added using gen_register_replacement instead To do you call gen_register_replacement instead register_replacement The arguments same except additional unique name which used lookup key ## Internals The match DAG represented graph ` PatternExpr ` nodes Each PatternExpr implements ` _match ` method which returns either ` Match ` object successful match ` FailedMatch ` object failure match __future__ annotations contextlib dataclasses functools importlib inspect itertools logging operator os re textwrap typing abc ABC abstractmethod collections defaultdict collections abc Collection Generator Iterable Mapping Sequence pathlib Path typing Any Callable NoReturn Optional Protocol TypeVar Union typing_extensions Self TypeIs torch torch _guards torch fx torch utils _pytree pytree torch _dispatch python enable_python_dispatcher torch _dynamo utils counters torch _prims_common is_integer_dtype torch _subclasses fake_tensor unset_fake_temporarily torch fx experimental proxy_tensor make_fx torch fx experimental symbolic_shapes guard_or_false statically_known_true torch fx graph_module _get_attr torch fx immutable_collections immutable_dict immutable_list torch fx passes graph_transform_observer GraphTransformObserver torch fx traceback preserve_node_meta torch utils _ordered_set OrderedSet _functorch config functorch_config _functorch aot_autograd aot_function make_boxed_func _functorch partitioners default_partition _subclasses FakeTensor FakeTensorMode fx Transformer config decomposition select_decomp_table lowering fallback_node_due_to_unsupported_type log = logging getLogger __name__ aten = torch ops aten prims = torch ops prims Constant = Any NodeOrConstant = Union Constant torch fx Node backend = os environ get TORCHINDUCTOR_PATTERN_MATCH_BACKEND inductor SearchFn Protocol __name__ str __call__ args Any kwargs Any - Any ReplaceFn Protocol __call__ args Any kwargs Any - Any TraceFn Protocol __call__ fn Union SearchFn ReplaceFn args Any kwargs Any - torch fx GraphModule T = TypeVar T What s better name FnsType = Union torch fx node Target str Multiple __init__ - None Ensure we re really singleton assert MULTIPLE globals MULTIPLE Sentinel indicating multiple quantities can matched MULTIPLE = Multiple _transfer_meta new_meta dict str Any old_node torch fx Node pass_name str = - None torch fx traceback NodeSource NodeSourceAction transfer metadata after pattern matching occurs skip val tensor_meta because info too specific s unlikely remain accurate after pattern matching has occurred config trace provenance_tracking_level == We handle from_node field node meta specially record new node comes old_node new_from_node = new_meta get from_node copy new_from_node append NodeSource old_node pass_name NodeSourceAction REPLACE new_meta update k v k v old_node meta items k torch fx proxy _COPY_META_FIELDS new_meta from_node = new_from_node new_meta update k v k v old_node meta items k torch fx proxy _COPY_META_FIELDS stack_trace old_node meta new_meta stack_trace = old_node meta stack_trace Match Represents successfully matched pattern The ` Match ` object returned represent successfully matched pattern Included Match pattern matched graph nodes matched any args used during matching The args kwargs specific type pattern matched provide hints about what matched pattern PatternExpr args list Any kwargs dict str Any nodes list torch fx Node targets dict _TargetExpr torch fx node Target ctx MatchContext replacement_graph Optional torch fx GraphModule __init__ ctx MatchContext pattern PatternExpr args Optional Sequence Any = None kwargs Optional dict str Any = None - None super __init__ pattern = pattern The input nodes must passed result args = list args kwargs = kwargs The nodes matched expression nodes = Mapping CallFunction node target targets = ctx = ctx replacement_graph = None property graph - torch fx Graph ctx graph extend other Match - None kwargs key OrderedSet kwargs keys OrderedSet other kwargs keys kwargs key = other kwargs key raise FailedMatch kwarg mismatch key args extend other args nodes extend other nodes kwargs update other kwargs targets update other targets bundle - Match Wrap args extra list args = tuple args args __repr__ - str f Match args kwargs erase_nodes - None graph = graph n reversed nodes n _erased n users graph erase_node n output_nodes - list Optional torch fx Node ctx pattern_to_node p p None None p ctx outputs output_node - torch fx Node next p p output_nodes p replace_with_graph replacement_graph torch fx Graph args Sequence Any - None ReplacementPatternEntry replace_with_graph ctx graph replacement_graph args replace_by_example replacement_fn ReplaceFn args Sequence Any trace_fn Optional TraceFn = None run_functional_passes bool = True - None Replace graph generated tracing replacement_fn Args run_functional_passes bool If we should run passes assume functional IR like DCE remove_noop_ops replacement graph torch _inductor virtualized NullHandler V context = V fake_mode isinstance V fake_mode NullHandler V fake_mode None contextlib nullcontext should_propagate_eager_input_vals nodes list torch fx Node - bool len nodes = False node = nodes eager_input_vals node meta False node target OrderedSet torch ops higher_order triton_kernel_wrapper_functional torch ops higher_order auto_functionalized torch ops higher_order auto_functionalized_v pyrefly ignore bad-context-manager context trace_fn None trace_fn = functools partial fwd_only run_functional_passes=run_functional_passes should_propagate_eager_input_vals nodes Our strategy trace out graph eager_input_vals which have accurate eager-mode metadata trace out graph vals which have accurate Inductor metadata Propagate eager_input_vals first graph second Use second graph replacement graph Construct map node - FakeTensor val eager_input_vals node_to_val = fake_args fake_kwargs = nodes meta eager_input_vals fake_kwargs = fake_kwargs match_args match_kwargs = tuple args kwargs record node torch fx Node val Any - None isinstance node torch fx Node node_to_val node = val torch utils _pytree tree_map record match_args match_kwargs fake_args fake_kwargs map args their FakeTensor val eager_input_vals example_vals = torch fx map_arg args lambda arg node_to_val arg first graph graph_with_eager_vals = trace_fn replacement_fn example_vals second graph example_vals = torch fx map_arg args lambda arg arg meta val replacement = trace_fn graph_with_eager_vals example_vals propagate metadata first graph second NB This assertion might true general true two use cases we have triton_kernel_wrapper_functional auto_functionalized assert len graph_with_eager_vals graph nodes == len replacement graph nodes old_node new_node zip graph_with_eager_vals graph nodes replacement graph nodes eager_input_vals old_node meta new_node meta eager_input_vals = old_node meta eager_input_vals example_vals = torch fx map_arg args lambda arg arg meta val val arg meta arg meta example_value replacement = trace_fn replacement_fn example_vals len nodes == n replacement graph nodes _transfer_meta new_meta=n meta old_node=self nodes pass_name= replace_by_example ReplacementPatternEntry replace_with_graph ctx graph replacement args FailedMatch RuntimeError Represents unsuccessful match The ` FailedMatch ` object returned represent failure match pattern format_string str __init__ format_string str args Any kwargs Any - None format_string = format_string We want construct error messages lazily instead eagerly constructing them eagerly can significantly worsen compile times len format_string raise RuntimeError f Format string too long - use lazy construction strings instead Format string is\n format_string args = args kwargs = kwargs __str__ - str format_string format args kwargs __bool__ - bool False MatchResult = Union Match FailedMatch is_match m MatchResult - TypeIs Match TypeIs cannot act ` ` Thus function exists let mypy recognize FailedMatch __bool__ TypeIs bool m MatchContext Internal state needed while running PatternExpr _match outputs list Optional PatternExpr pattern_to_node dict PatternExpr Optional torch fx Node graph torch fx Graph exclusive_node_set list NodeOrConstant __init__ outputs list Optional PatternExpr pattern_to_node Optional dict PatternExpr torch fx Node = None graph torch fx Graph - None outputs = outputs pattern_to_node = pattern_to_node None dict pattern_to_node graph = graph exclusive_node_set = match pattern PatternExpr node NodeOrConstant - MatchResult wrapper check reused nodes patterns pattern pattern_to_node pattern_to_node pattern == node Match pattern already checked node FailedMatch repeated pattern differs m = pattern _match node assert pattern pattern_to_node pattern_to_node pattern = node m None m filter_multi_user_patterns - dict PatternExpr torch fx Node pattern node pattern node pattern_to_node items pattern has_multiple_users node None PatternExpr ABC Base types patterns abstractmethod _match node torch fx Node ctx MatchContext - MatchResult match node torch fx Node - MatchResult try MatchContext graph=node graph match node except FailedMatch e e has_multiple_users - bool False __repr__ - str __class__ __name__ + find_anchor_nodes ctx MatchContext searched OrderedSet torch fx Node - Generator Optional torch fx Node None None ctx pattern_to_node yield ctx pattern_to_node pattern_eq other Any - bool Compare two ` PatternExpr ` s true they same Note NOT matching pattern - comparing pattern structures debugging isinstance other __class__ Arg PatternExpr Capture arg which will become input handler Args passed depth first order _match node NodeOrConstant ctx MatchContext - MatchResult Match ctx args= node matches anything Ignored PatternExpr Match arg don t pass handler _match node NodeOrConstant ctx MatchContext - MatchResult Match ctx matches anything __repr__ - str pretty_print pp PatternPrettyPrinter - str Ignored KeywordArg PatternExpr Capture kwarg which will become input handler __init__ name str - None super __init__ name = name __repr__ - str f KeywordArg name r _match node NodeOrConstant ctx MatchContext - MatchResult Match ctx kwargs= name node matches anything pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other name == other name ExclusiveKeywordArg PatternExpr Capture kwarg which will become input handler name str __init__ name str - None super __init__ name = name __repr__ - str f ExclusiveKeywordArg name r _match node NodeOrConstant ctx MatchContext - MatchResult node ctx exclusive_node_set FailedMatch exclusive arg appears twice ctx exclusive_node_set append node Match ctx kwargs= name node matches anything pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other name == other name _TargetExpr PatternExpr Base filtering match node target fns list FnsType fns_set OrderedSet FnsType __init__ fns Union FnsType Sequence FnsType users Union Multiple int = - None super __init__ fns = fns callable fns isinstance fns str list fns fn fns isinstance fn torch _ops OpOverloadPacket fns extend getattr fn overload overload fn overloads noqa B fns = fns fns_set = OrderedSet fns users = users property abstractmethod op - str fns_repr - str first_repr = fns isinstance first_repr str first_repr = first_repr __name__ len fns f first_repr fns getattr torch first_repr None f torch first_repr fns getattr operator first_repr None f operator first_repr isinstance fns torch _ops OpOverload str fns first_repr __repr__ - str users MULTIPLE comma_users = MULTIPLE users = comma_users = f users comma_users = f __class__ __name__ fns_repr comma_users has_multiple_users - bool isinstance users Multiple users find_anchor_nodes ctx MatchContext searched OrderedSet torch fx Node - Generator Optional torch fx Node None None raise NotImplementedError _match_fns node torch fx Node - bool isinstance node torch fx Node node op == op extract_target node fns_set _match_users node torch fx Node ctx MatchContext - bool ctx outputs users MULTIPLE len node users == users pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other op == other op fns == other fns users == other users _SimpleSpec = tuple Any _TargetArgsExpr _TargetExpr Base filtering match node target args kwargs __init__ fns Union torch fx node Target str Sequence Any args Any _users Union int Multiple = kwargs Any - None super __init__ fns _users args = tuple args kwargs = dict kwargs any isinstance x dict list tuple x itertools chain args kwargs values flatten = pytree_flatten flatten = simple_flatten flat_args_kwargs = flatten args kwargs staticmethod simple_flatten args Sequence Any kwargs Mapping Any Any - tuple Sequence Any Union _SimpleSpec pytree TreeSpec values = args kwargs values spec = len args kwargs keys values spec staticmethod pytree_flatten args Sequence Any kwargs Mapping Any Any - tuple Sequence Any Union _SimpleSpec pytree TreeSpec type_mapping dict type type = immutable_list tuple list tuple immutable_dict dict convert_type x Any - Any cls = type x convert_fn = type_mapping get cls convert_fn None pytree tree_map convert_type convert_fn x is_leaf=lambda x type x type_mapping x normalized_args_tree = pytree tree_map convert_type args kwargs is_leaf=lambda x type x type_mapping flat spec = pytree tree_flatten normalized_args_tree flat spec __repr__ - str args = fns_repr map repr args f k = v k v kwargs items users MULTIPLE args append _users=MULTIPLE users = args append f _users= users f __class__ __name__ join args pretty_print pp PatternPrettyPrinter - str args = fns_repr pp pretty_print x x args f k = pp pretty_print v k v kwargs items users MULTIPLE args append _users=MULTIPLE users = args append f _users= users joiner_str = f __class__ __name__ joiner_str join args _match node torch fx Node ctx MatchContext - MatchResult _match_fns node len node args = len args FailedMatch function_mismatch node= pattern= node _match_users node ctx FailedMatch multiple_users _args = node args _kwargs = node kwargs len _kwargs len kwargs torch fx operator_schemas normalize_function assert callable node target normalized_args_and_kwargs = normalize_function node target node args node kwargs normalized_args_and_kwargs None FailedMatch function_mismatch node= pattern= node _args _kwargs = normalized_args_and_kwargs len _args == len args len _kwargs = len kwargs _kwargs = i _kwargs i i _kwargs i kwargs FailedMatch function_mismatch node= pattern= node _kwargs = i _kwargs i i _kwargs i kwargs node_items node_spec = flatten _args _kwargs self_items self_spec = flat_args_kwargs node_spec = self_spec FailedMatch args_structure node_spec self_spec assert len node_items == len self_items m = Match ctx pattern child_node zip self_items node_items isinstance pattern PatternExpr child_match = ctx match pattern child_node is_match child_match child_match m extend child_match isinstance child_node torch fx Node child_node = pattern FailedMatch constant_args r = pattern r node child_node m nodes append node m targets = node target m find_anchor_nodes ctx MatchContext searched OrderedSet torch fx Node - Generator Optional torch fx Node None None This used when we matching pattern multiple outputs There partial match stored ctx we want walk pattern find connection already-matched node Yields candidate nodes ` _match ` might like ctx pattern_to_node yield ctx pattern_to_node pattern flat_args_kwargs isinstance pattern PatternExpr other_node pattern find_anchor_nodes ctx searched isinstance other_node torch fx Node continue node other_node users node searched _match_fns node yield node searched add node pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other flat_args_kwargs == other flat_args_kwargs all pattern_eq b isinstance PatternExpr == b b zip flat_args_kwargs other flat_args_kwargs CallFunction _TargetArgsExpr Matches call_function node FX graphs ` fns i args kwargs ` op = call_function CallMethod _TargetArgsExpr Matches call_method node FX graphs ` fns i method args kwargs ` op = call_method CallModule _TargetArgsExpr Matches call_module node FX graphs ` module args kwargs ` op = call_module _TargetExprVarArgs _TargetExpr Matches call_function node any arguments which passed into pattern _match node torch fx Node ctx MatchContext - MatchResult _match_fns node FailedMatch function_mismatch _match_users node ctx FailedMatch multiple_users m = Match ctx m nodes append node m targets = node target m args extend node args m kwargs update node kwargs m CallFunctionVarArgs _TargetExprVarArgs op = call_function CallMethodVarArgs _TargetExprVarArgs op = call_method CallModuleVarArgs _TargetExprVarArgs op = call_module ListOf PatternExpr Matches repeated pattern __init__ pattern PatternExpr partial bool = False - None super __init__ assert isinstance pattern PatternExpr pattern = pattern partial = partial __repr__ - str f __class__ __name__ pattern _match node list torch fx Node ctx MatchContext - MatchResult type ignore override isinstance node list tuple len node == FailedMatch non_list m = Match ctx Propagating patterns multiple users will ensure we don t revisit same nodes pattern_to_node = ctx filter_multi_user_patterns matched = False i child_node enumerate node child_ctx = MatchContext ctx outputs pattern_to_node graph=child_node graph child_match = child_ctx match pattern child_node pattern_to_node = child_ctx filter_multi_user_patterns is_match child_match partial FailedMatch list i child_match continue matched = True m extend child_match bundle matched FailedMatch list no_match m bundle pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other pattern pattern_eq other pattern partial == other partial MultiOutputPattern PatternExpr outputs list Optional PatternExpr __init__ outputs Sequence Optional PatternExpr - None super __init__ assert isinstance outputs _TargetExpr assert all x None isinstance x PatternExpr x outputs outputs outputs = list outputs op = outputs op property fns - Union Callable Any str Sequence Any This cast checked above __init__ output = typing cast _TargetExpr outputs output fns __repr__ - str f __class__ __name__ outputs pretty_print pp PatternPrettyPrinter - str args = pp pretty_print x x outputs joiner_str = f \n str_out = f __class__ __name__ joiner_str join args str_out = f str_out \n str_out _match node torch fx Node ctx MatchContext - MatchResult output = typing cast _TargetExpr outputs m = ctx match output node is_match m m pattern outputs pattern None continue child_match = _match_from_anchors pattern ctx is_match child_match child_match m extend child_match m _match_from_anchors pattern PatternExpr ctx MatchContext - MatchResult prior = dict ctx pattern_to_node m MatchResult = FailedMatch no anchor found node pattern find_anchor_nodes ctx OrderedSet m = ctx match pattern node is_match m m revert any partial matches ctx pattern_to_node = dict prior m match node torch fx Node - MatchResult try MatchContext outputs graph=node graph match node except FailedMatch e e pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other len outputs == len other outputs all pattern_eq b isinstance PatternExpr == b b zip outputs other outputs RepeatedExpr PatternExpr Checks repeated pattern Useful repeated operations after node such ` split ` ` unbind ` __init__ inner_pattern _TargetExpr - None super __init__ inner_pattern = inner_pattern op = inner_pattern op property fns - Sequence FnsType inner_pattern fns _match node torch fx Node ctx MatchContext - MatchResult m = ctx match inner_pattern node is_match m m ctx pattern_to_node pop inner_pattern Check all anchor nodes match pattern anchor_node inner_pattern find_anchor_nodes ctx OrderedSet anchor_m = MatchContext graph=node graph match inner_pattern anchor_node is_match anchor_m anchor_m m extend anchor_m m pattern_eq other Any - bool other = typing cast Self other super makes sure true super pattern_eq other inner_pattern pattern_eq other inner_pattern PatternPrettyPrinter Serializes Patterns executable python XXX currently only used tested fuse attention patterns May cover all patterns __init__ - None namespace = torch fx graph _Namespace memoized_objs_names dict PatternExpr str = memoized_objs_pp dict PatternExpr str = staticmethod functools cache run obj PatternExpr output_name str = output - str Serializes obj python code obj written out ` output_name ` pp = PatternPrettyPrinter assert hasattr obj pretty_print out_str = obj pretty_print pp=pp output = f pp memoized_objs_names key = pp memoized_objs_pp key key pp memoized_objs_names output append f output_name = out_str \n join output pretty_print obj Any - str isinstance obj _TargetArgsExpr memoized_name = memoized_objs_names get obj memoized_name memoize obj hasattr obj pretty_print obj pretty_print repr obj memoize obj _TargetArgsExpr - str obj_str = obj pretty_print obj_name = obj fns_repr prefix aten torch prims obj_name = obj_name replace prefix tmp_name = namespace create_name obj_name None memoized_objs_names obj = tmp_name memoized_objs_pp obj = obj_str tmp_name _PassDictsType Protocol __getitem__ k tuple str torch fx node Target - list PatternEntry dataclasses dataclass PatternEntry pattern PatternExpr extra_check Callable Match bool apply match Match graph torch fx Graph node torch fx Node - None raise NotImplementedError register pass_dicts Union _PassDictsType Sequence _PassDictsType target Union torch fx node Target None = None prepend bool = False - None target None assert hasattr pattern fns fn pattern fns register pass_dicts fn prepend=prepend isinstance pass_dicts dict PatternMatcherPass assert hasattr pattern op prepend pass_dicts pattern op target insert pass_dicts pattern op target append pass_dicts = typing cast Sequence _PassDictsType pass_dicts x pass_dicts register x target prepend=prepend dataclasses dataclass LoweringPatternEntry PatternEntry handler Callable Any apply match Match graph torch fx Graph node torch fx Node - None handler = functools wraps handler functools partial handler match graph inserting_before node replacement = graph call_function handler tuple match args match kwargs replacement meta update node meta node replace_all_uses_with replacement assert match nodes - node match erase_nodes dataclasses dataclass GraphPatternEntry PatternEntry A pattern runs function FX graph handler Callable Any apply match Match graph torch fx Graph node torch fx Node - None graph inserting_before node handler match match args match kwargs dataclasses dataclass ReplacementPatternEntry PatternEntry The replacement pattern graph normalize_args Callable list Any staticmethod replace_with_graph match Match graph torch fx Graph replacement_graph Union torch fx Graph torch fx GraphModule args Sequence torch fx Node - None Inserts replacement graph into toplevel graph match added_replacement_nodes list torch fx Node = Replacer torch fx Interpreter call_method = None type ignore assignment call_module = None type ignore assignment get_attr = None type ignore assignment run_node node torch fx Node - Any node op placeholder output super run_node node target = node target args kwargs = fetch_args_kwargs_from_env node node op == call_function assert callable target result = graph call_function target args kwargs added_replacement_nodes append result _transfer_meta new_meta=result meta old_node=node pass_name= Interpreter_Replacer This function copy-pastes replacement graph into graph If replacement graph had any eager_input_vals val tensor_meta we propagate those over eager_input_vals node meta result meta eager_input_vals = node meta eager_input_vals val node meta val result meta result meta val = node meta val isinstance node meta val torch Tensor assert tensor_meta node meta result meta tensor_meta = node meta tensor_meta result node op == get_attr If replacement graph contains HOP subgraphs HOP get_attr nodes We need fetch subgraph HOP then register subgraph replaced graph s root torch _higher_order_ops utils unique_graph_name_with_root sub_gm = super get_attr target args kwargs isinstance sub_gm torch fx GraphModule raise NotImplementedError f NYI replacement_graph target graph module Got sub_gm assert graph owning_module None graph_name = None n mod graph owning_module named_modules sub_gm mod graph_name = n break graph_name None assert isinstance target str _ graph_name = unique_graph_name_with_root pyrefly ignore unbound-name graph owning_module target pyrefly ignore unbound-name graph owning_module register_module graph_name sub_gm pyrefly ignore unbound-name getattr_node = graph get_attr graph_name added_replacement_nodes append getattr_node getattr_node raise NotImplementedError f unhandled node output_nodes = match output_nodes len output_nodes == last_node = output_nodes assert output_nodes nodes = list output_nodes graph nodes indices = nodes index n n n output_nodes isinstance n torch fx Node last_node = min indices key=operator itemgetter percolate_tags node torch fx Node tag_name str tag_value str input_stops OrderedSet torch fx Node - None queue = node visited = OrderedSet torch fx Node while queue arg = queue pop arg visited arg input_stops hasattr arg meta visited add arg arg meta tag_name = tag_value queue extend arg all_input_nodes graph inserting_before last_node assert isinstance replacement_graph torch fx GraphModule replacement = Replacer replacement_graph run args isinstance replacement torch fx Node replacement = replacement maybe_getitem node torch fx Node - Any node op = call_function None node target = operator getitem None assert len node args == node args replace old Union torch fx Node None new Union torch fx Node Sequence torch fx Node None - None filter_nodes_in_newly_added_nodes node torch fx Node - bool Do replace use node being used nodes replaced graph node added_replacement_nodes old None assert new None assert isinstance old torch fx Node new None old replace_all_uses_with None type ignore arg-type delete_user_cb=filter_nodes_in_newly_added_nodes len old users == graph erase_node old isinstance new torch fx Node val new meta new meta update old meta Preserve recompute tags replacement graph We look recompute tags original output node propagate tag output all way input args named args replace_with_graph Note best effort Since patterns many many there no easy way correctly map recomputable tags It possible some scenarios we incorrectly tag some nodes recomputables tag_name recompute ac_graph_id tag_name old meta percolate_tags new tag_name old meta tag_name OrderedSet args old replace_all_uses_with new delete_user_cb=filter_nodes_in_newly_added_nodes len old users == graph erase_node old ` new ` node s list nodes This happens when we want replace node has single packed multiple unpacked returns We need do some graph surgery here Example original_graph x = op x b = c = Assume we want replace op x graph new_op x w = x + z = x + w z We need replace ` op ` contents ` new_op ` then rewrite w z so new_graph x w = x + z = x + b = w c = z old_uses = list old users keys user old_uses idx = maybe_getitem user idx None raise AssertionError Deleted index getitem did you erase index properly replace replace user new idx graph erase_node old len output_nodes == len replacement old new zip output_nodes replacement replace old new assert len output_nodes == replace output_nodes replacement match erase_nodes apply match Match graph torch fx Graph node torch fx Node - None assert match replacement_graph None replace_with_graph match graph match replacement_graph normalize_args match args match kwargs _return_true match Match - bool True log_trace_failure search_fn Callable Any e RuntimeError - None log info Replacement pattern s failed apply due shape mismatch s search_fn __name__ e check_and_add_duplicate_pattern pattern PatternExpr graph Optional torch fx Graph seen_patterns dict str list Optional str skip_duplicates bool = False - bool Check pattern duplicate Because we ignore certain types searching matching use graph distinguish equivalent search patterns Returns True duplicate found ` skip_duplicates=True ` passed Errors ` skip_duplicates ` False duplicate found pattern_repr = PatternPrettyPrinter run pattern equiv_pattern_reprs = seen_patterns get pattern_repr equiv_pattern_reprs seen_patterns pattern_repr append str graph graph None False graph None skip_duplicates True torch _check False lambda f Duplicate pattern pattern_repr no graph new_graph_str = str graph graph_str equiv_pattern_reprs new_graph_str = graph_str continue skip_duplicates True torch _check False lambda f Duplicate pattern pattern_repr duplicated match graph graph_str equiv_pattern_reprs append new_graph_str False register_replacement search_fn SearchFn replace_fn ReplaceFn example_inputs Iterable Any trace_fn TraceFn pass_dicts Union _PassDictsType Sequence _PassDictsType extra_check Callable Match bool = _return_true scalar_workaround Union dict str Union float int None = None exclusive_arg_names Sequence str = search_fn_pattern Union PatternExpr None = None skip_duplicates bool = False - bool Create replacement rule based example functions get traced create patterns This supports both training inference when run joint forward+backward graph Args search_fn traced give original pattern replace_fn traced give replacement graph example_inputs example inputs initial trace trace_fn fwd_only joint_fwd_bwd pass_dict dict passes register extra_check additional check run match using real shapes argnames_static = inspect signature search_fn parameters keys check_fn match Match - bool Often shapes get burned into pattern so our initial match ran ` ignore_types= int ` Recheck match correct shapes argnames = list argnames_static name argnames name match kwargs raise RuntimeError f Not all inputs pattern found match kwargs Perhaps one f inputs unused argnames= argnames match kwargs= match kwargs args = list torch fx map_arg match kwargs name name argnames lambda n n meta val sym_args list torch SymInt = fake_mode = torch _dynamo utils detect_fake_mode args assert fake_mode None fake_mode i grad enumerate requires_grad isinstance args i torch Tensor grad is_integer_dtype args i dtype False args i = torch empty_strided args i size args i stride dtype=args i dtype device=args i device requires_grad=grad v itertools chain args i shape args i stride isinstance v torch SymInt all statically_known_true v = sym_args sym_args append v If we given pre-traced pattern then use instead retracing Note means pattern has independent its args specific_pattern = search_fn_pattern specific_pattern sym_args AOT Autograd make fx will dedupe symbolic shape size accesses sym ints appear inputs We don t want sym_size uses interfere pattern matching so we provide them inputs Later when we actually do replacement symbolic shape sizes will get re-traced added graph search_fn_new args_new Any - Any search_fn args_new len args_new - len args try pyrefly ignore bad-argument-type specific_graph = trace_fn search_fn_new sym_args + args except RuntimeError e log_trace_failure search_fn e False correct argnames graph sym_arg_names = i placeholder zip range len sym_args + len args specific_graph graph nodes i len sym_args sym_arg_names append placeholder target continue specific_graph graph inserting_after placeholder new_node = specific_graph graph placeholder argnames i - len sym_args new_node target = new_node name placeholder replace_all_uses_with new_node specific_graph graph erase_node placeholder argnames = sym_arg_names + argnames try specific_graph = trace_fn search_fn args except RuntimeError e log_trace_failure search_fn e False specific_pattern = fx_to_pattern specific_graph argnames=argnames exclusive_arg_names=exclusive_arg_names scalar_workaround=scalar_workaround node = match output_nodes assert node None specific_pattern_match = specific_pattern match node is_match specific_pattern_match extra_check specific_pattern_match trace pattern using shapes user program match replacement_graph = trace_fn replace_fn args len match nodes == n match replacement_graph graph nodes _transfer_meta new_meta=n meta old_node=match nodes pass_name= replacement True False normalize_args kwargs Any - list Any args = kwargs pop name name argnames_static i range len kwargs + f tangents_ i kwargs break args append kwargs pop f tangents_ i assert kwargs f leftover kwargs kwargs r args trace_fn joint_fwd_bwd If inference mode enabled during compilation assume we don t want match any training graph patterns torch is_inference_mode_enabled False TODO Revisit functionalize_rng_ops lowmem dropout functorch_config patch functionalize_rng_ops=False requires_grad list bool = isinstance x torch Tensor x requires_grad x example_inputs search_fn_pattern None pattern gm = gen_pattern_and_search_gm search_fn example_inputs trace_fn scalar_workaround exclusive_arg_names pattern = search_fn_pattern gm = None pattern_matcher_pass pass_dicts isinstance pass_dicts Sequence pass_dicts isinstance pattern_matcher_pass PatternMatcherPass check_and_add_duplicate_pattern pattern gm graph gm None pattern_matcher_pass seen_patterns skip_duplicates=skip_duplicates False pattern = ReplacementPatternEntry pattern=pattern extra_check=check_fn normalize_args=normalize_args pattern register pass_dicts pattern pattern type ignore return-value _serialized_patterns OrderedSet str = OrderedSet _serialize_pattern unique_name str search_fn SearchFn example_inputs Sequence Any trace_fn TraceFn scalar_workaround Union dict str Union float int None - PatternExpr get_file_template - str auto_generated_msg = textwrap dedent \ This auto-generated file Please do modify hand To re-generate run cd ~ pytorch python torchgen fuse gen_patterns py file_template = textwrap dedent \ mypy ignore-errors noqa F E msg torch torch _inductor operator aten = torch ops aten prims = torch ops prims format msg=auto_generated_msg pattern_matcher_imports = name dir torch _inductor pattern_matcher attr = getattr torch _inductor pattern_matcher name try isinstance attr type issubclass attr PatternExpr _TargetExpr pyrefly ignore bad-argument-type pattern_matcher_imports append name except TypeError pass formatted_imports = \n join pattern_matcher_imports formatted_imports = f torch _inductor pattern_matcher \n formatted_imports \n \n f file_template formatted_imports SERIALIZED_PATTERN_PATH is_dir raise RuntimeError f Could find serialized patterns directory SERIALIZED_PATTERN_PATH pattern_name = search_fn __name__ torch _functorch config functorch_config functorch_config patch functionalize_rng_ops=False pattern = gen_pattern search_fn example_inputs trace_fn scalar_workaround serialized_pattern = PatternPrettyPrinter run pattern output_name=unique_name pattern_name _serialized_patterns write_mode = w _serialized_patterns add pattern_name write_mode = file_template = get_file_template open SERIALIZED_PATTERN_PATH f pattern_name py write_mode f write_mode == w f write file_template f write \n\n f write serialized_pattern f write \n pattern SERIALIZED_PATTERN_PATH = Path __file__ parent fx_passes serialized_patterns This set serialized patterns we ve registered Used test_serialized_patterns_up_to_date ensure patterns up date _known_precompiled_patterns list tuple Any Iterable Any Callable Callable Any Iterable Any torch fx GraphModule Any PatternExpr = gen_register_replacement unique_name str search_fn SearchFn replace_fn ReplaceFn example_inputs Iterable Any trace_fn TraceFn pass_dicts Union _PassDictsType Sequence _PassDictsType extra_check Callable Match bool = _return_true scalar_workaround Union dict str Union float int None = None exclusive_arg_names Sequence str = skip_duplicates bool = False - None Make sure example_inputs materialized example_inputs = tuple example_inputs PYTORCH_GEN_PATTERNS os environ pat = _serialize_pattern unique_name search_fn example_inputs trace_fn scalar_workaround pattern_name = search_fn __name__ m = importlib import_module f torch _inductor fx_passes serialized_patterns pattern_name m hasattr m unique_name log warning Precompiled pattern r found Run torchgen fuse gen_patterns py unique_name pat = getattr m unique_name arg pytree tree_iter example_inputs isinstance arg FakeTensor arg constant None This can problem - small fake tensors e g ` tensor ` will hold onto their original constant value - stashing here will cause memory leak constant value GPU Since just optimization we can clear out arg constant = None _known_precompiled_patterns append search_fn example_inputs trace_fn scalar_workaround pat register_replacement search_fn replace_fn example_inputs trace_fn pass_dicts extra_check scalar_workaround exclusive_arg_names search_fn_pattern=pat skip_duplicates=skip_duplicates functorch_config patch functionalize_rng_ops=False type ignore misc gen_pattern_and_search_gm search_fn SearchFn example_inputs Sequence Any trace_fn TraceFn scalar_workaround Union dict str Union float int None = None exclusive_arg_names Sequence str = - tuple PatternExpr torch fx GraphModule argnames = inspect signature search_fn parameters keys scalar_workaround None scalar_workaround = flat_inputs = input_idx = Positional arguments index argname argnames argname scalar_workaround flat_inputs append scalar_workaround argname flat_inputs append example_inputs input_idx input_idx += search_gm = trace_fn search_fn flat_inputs fx_to_pattern search_gm ignore_types= int float list torch device torch dtype argnames=argnames scalar_workaround=scalar_workaround exclusive_arg_names=exclusive_arg_names search_gm gen_pattern search_fn SearchFn example_inputs Sequence Any trace_fn TraceFn scalar_workaround Union dict str Union float int None = None exclusive_arg_names Sequence str = - PatternExpr gen_pattern_and_search_gm search_fn example_inputs trace_fn scalar_workaround exclusive_arg_names register_lowering_pattern pattern PatternExpr extra_check Callable Match bool = _return_true pass_dict _PassDictsType prepend bool = False - Callable Callable Any Callable Any Register aten inductor IR replacement pattern The decorated function saved then called lowering time allowing direct pattern inductor IR conversion decorator handler Callable Any - Callable Any assert callable handler LoweringPatternEntry pattern=pattern extra_check=extra_check handler=handler register pass_dict prepend=prepend handler _inductor_lowering_function = True type ignore attr-defined handler decorator register_graph_pattern pattern PatternExpr extra_check Callable Match bool = _return_true pass_dict _PassDictsType prepend bool = False - Callable Callable Any Callable Any Register pattern runs function FX graph allowing custom transformation code decorator handler Callable Any - Callable Any assert callable handler GraphPatternEntry pattern=pattern extra_check=extra_check handler=handler register pass_dict prepend=prepend handler decorator is_start_of_fx_graph graph torch fx Graph node torch fx Node - bool first node graph node next iter graph nodes match copy_ relu_ _set_grad_enabled manual_seed _enter_autocast etc doesn t match __rshift__ etc _mutation_op_re = re compile r _ _$ &#124; _ &#124; \b &#124; _ set &#124; enter &#124; exit &#124; seed \b &#124; _ _ fixme_incorrect_inductor_schema_op op torch _ops OpOverload - bool op namespace = inductor False TODO - fix schema Dont add any more op torch ops inductor accumulate_grad_ default torch ops inductor resize_storage_bytes_ default is_mutation_op node torch fx Node - bool isinstance node target torch _ops OpOverload fixme_incorrect_inductor_schema_op node target node target _schema is_mutable isinstance node target torch _higher_order_ops auto_functionalize AutoFunctionalized False node op == call_function assert callable node target _mutation_op_re search node target __name__ True node op == call_method assert isinstance node target str _mutation_op_re search node target True node kwargs get out None same_mutation_regions torch fx Node b torch fx Node - bool assert mutation_region_id meta assert mutation_region_id b meta meta mutation_region_id == b meta mutation_region_id get_mutation_region_id graph torch fx Graph node torch fx Node - int n = node while mutation_region_id n meta is_start_of_fx_graph graph n n = n prev mutation_region_id = n meta get mutation_region_id while n node n = n next is_mutation_op n mutation_region_id += n meta mutation_region_id = mutation_region_id mutation_region_id should_compute_mutation_region_ids graph torch fx Graph - bool mutation_region_id next iter graph nodes meta compute_mutation_region_ids graph torch fx Graph - None mutation_region_id = nd graph nodes is_mutation_op nd mutation_region_id += nd meta mutation_region_id = mutation_region_id PatternMatcherPass __init__ pass_name Optional str = None subsystem Optional str = None - None super __init__ patterns defaultdict tuple str torch fx node Target list PatternEntry = defaultdict list pass_name = pass_name subsystem = subsystem For particular generated pattern repr store all str representations graph used generate them Because we ignore certain patterns searching matching use graph distinguish two equivalent searches actually different seen_patterns dict str list Optional str = defaultdict list __getitem__ item tuple str torch fx node Target - list PatternEntry patterns item apply gm Union torch fx GraphModule torch fx Graph - int patterns isinstance gm torch fx GraphModule graph = gm graph isinstance gm torch fx Graph graph = gm gm = graph owning_module raise RuntimeError f The input PatternMatcherPass must GraphModule Graph got type gm should_compute_mutation_region_ids graph compute_mutation_region_ids graph get_mutation_region_id_partial = functools partial get_mutation_region_id graph count = nodes = has_call_module = False op target patterns op == call_module has_call_module = True nodes append graph find_nodes op=op target=target sort=False has_call_module nodes append graph find_nodes op= call_module sort=False pass_name = pass_name pass_name None pattern_matcher assert isinstance gm torch fx GraphModule GraphTransformObserver gm pass_name subsystem node sorted itertools chain from_iterable nodes reverse=True target = extract_target node node op == call_module node op target patterns continue conservatively applying pattern cpu input since some patterns induce codegen split nodes Note we will only skip cpu compute disable_cpp_codegen=True fallback_node_due_to_unsupported_type node allow_cpu_inputs=False continue entry patterns node op target node _erased break m = entry pattern match node pattern match crosses mutation barrier - discard is_match m len OrderedSet map get_mutation_region_id_partial m nodes = continue os environ get TORCHINDUCTOR_PATTERN_MATCH_DEBUG == node name log warning s s s s node node args m entry pattern is_match m guard_or_false entry extra_check m count += entry apply m graph node counters backend pattern_matcher_count += counters backend pattern_matcher_nodes += len m nodes count clear - None patterns clear _not_implemented args Any kwargs Any - NoReturn raise NotImplementedError fx_to_pattern gm Union torch fx GraphModule torch fx Graph ignore_types Sequence type Any = argnames Sequence str = scalar_workaround Union dict str Union float int None = None exclusive_arg_names Sequence str = - PatternExpr Convert FX graph into PatternExpr This useful simple patterns can only match single functions fixed-length lists scalar_workaround hack capture dropout_p see https github com pytorch pytorch issues scalar_workaround = scalar_workaround inv_scalar_workaround = v k k v scalar_workaround items assert len inv_scalar_workaround == len scalar_workaround process_arg x T ignore_types_override Optional Sequence type Any = None - Union T KeywordArg Ignored current_ignore_types = ignore_types_override ignore_types_override None ignore_types isinstance x float int x inv_scalar_workaround KeywordArg inv_scalar_workaround x type x current_ignore_types Ignored isinstance x list all isinstance y Ignored y x x Ignored x argnum = itertools count Converter torch fx Interpreter pyrefly ignore bad-override call_method = _not_implemented pyrefly ignore bad-override call_module = _not_implemented pyrefly ignore bad-override get_attr = _not_implemented pyrefly ignore bad-override placeholder target str type ignore override args Sequence Any kwargs Mapping str Any - Union ExclusiveKeywordArg KeywordArg n = next argnum n len argnames name = argnames n argnames assert target startswith tangent name = target target = re sub r _\d+$ target de-mangle arg name name = target name exclusive_arg_names ExclusiveKeywordArg name KeywordArg name pyrefly ignore bad-override call_function target str type ignore override args Sequence Any kwargs Mapping str Any - PatternExpr process_arg_fn = process_arg Indexing critical matching getitem nodes so we can t ignore int args here target operator getitem process_arg_fn_impl x T ignore_types_override Optional Sequence type Any = tuple t t ignore_types t int - Union T KeywordArg Ignored process_arg x ignore_types_override process_arg_fn = process_arg_fn_impl args kwargs = pytree tree_map process_arg_fn args kwargs list ignore_types Handle burned tensor size which now Ignored Ignored args = process_arg_fn args kwargs = k process_arg_fn k kwargs items CallFunction target args kwargs run_node n torch fx Node - Any rv = super run_node n n op == output isinstance rv tuple args = n args assert isinstance args Collection assert len rv == len args r arg zip rv args pyrefly ignore missing-attribute r users = len arg users rv users = len n users rv assert isinstance gm torch fx GraphModule pattern = Converter gm run isinstance pattern PatternExpr MultiOutputPattern pytree tree_leaves pattern pattern torch no_grad fwd_only fn Callable Any args Sequence Any run_functional_passes bool = True get_decomp_fn Optional Callable Any = None - torch fx GraphModule Build normalized inference graph use fx_to_pattern TODO - look into using aot autograd asserting no mutating ops here enable_python_dispatcher preserve_node_meta decompositions = get_decomp_fn get_decomp_fn None select_decomp_table gm = make_fx fn decompositions tracing_mode= real args fx_passes post_grad remove_noop_ops run_functional_passes remove_noop_ops gm graph gm graph eliminate_dead_code gm recompile gm torch enable_grad joint_fwd_bwd fn Callable Any args Sequence Any - torch fx GraphModule Build normalized training graph use fx_to_pattern gm Optional torch fx GraphModule = None record_joint_graph joint_graph torch fx GraphModule inputs Sequence Any kwargs Any - tuple torch fx GraphModule torch fx GraphModule nonlocal gm assert gm gm = clone_graph joint_graph default_partition joint_graph inputs kwargs torch _guards tracing None aot_function fn lambda g i make_boxed_func g partition_fn=record_joint_graph decompositions=select_decomp_table keep_inference_input_mutations=True enable_log=False args assert gm fx_passes post_grad remove_noop_ops remove_noop_ops gm graph fx_passes joint_graph pointless_view matcher_pass = PatternMatcherPass pattern = CallFunction torch ops aten view default KeywordArg arg KeywordArg size GraphPatternEntry pattern=pattern handler=pointless_view extra_check=_return_true pyrefly ignore bad-argument-type register matcher_pass patterns matcher_pass apply gm graph remove out specs gm graph _codegen = torch fx graph CodeGen gm graph eliminate_dead_code gm recompile gm _args n torch fx Node - list torch fx node Argument args list torch fx node Argument = torch fx map_arg n args n kwargs args append args stable_topological_sort graph torch fx Graph - None Nodes exactly one these three collections - Nodes ` pending ` waiting processed reverse order pending = list reversed graph nodes - Nodes ` ready ` have been processed already correct order ready = OrderedSet torch fx Node - ` waiting ` mapping dependency nodes which depend dependency waiting = defaultdict list The cursor indicates last processed node so we can add new nodes after cursor = None while pending node = pending pop waiting_for = x x _args node x ready waiting_for We have unprocessed input nodes Might well wait last arg so already sorted list will only recheck node once waiting waiting_for - append node ready add node cursor cursor next node cursor append node cursor = node Mark nodes have been waiting node finish ready check again pending extend reversed waiting pop node assert waiting len ready == len graph nodes init_once_fakemode fn Callable Any - Callable Any Wrapper around lazy init functions fx_passes functools cache functools wraps fn lazy_init - Any counters_ref = counters backend copy torch _guards tracing None unset_fake_temporarily FakeTensorMode result = fn clear view matches encountered during tracing counters backend = counters_ref result lazy_init config_flag name str - Callable Match Any Function extra_check put pass behind flag flag_check match Match - Any getattr config name flag_check clone_graph input_graph torch fx GraphModule - torch fx GraphModule CopyGraph Transformer run_node old_node torch fx Node - torch fx Node new_node = super run_node old_node isinstance new_node torch fx Proxy new_node node meta update old_node meta new_node node name = new_graph _graph_namespace create_name old_node name None pyrefly ignore bad-return new_node CopyGraph input_graph transform TODO remove follow up diff used internally _seen_patterns OrderedSet str = OrderedSet get_arg_value node torch fx Node arg_number int kwarg_name Optional str = None - Any len node args arg_number node args arg_number kwarg_name None None node kwargs get kwarg_name filter_nodes nodes Iterable torch fx Node fn Any - list torch fx Node fns = fn isinstance fn torch _ops OpOverloadPacket fns extend getattr fn overload overload fn overloads node node nodes node target fns extract_target node torch fx Node - torch fx node Target For call_function call_method we directly use target function For call_module target string we treat module function node op == call_module assert isinstance node target str _get_attr node graph owning_module node target __class__ node target