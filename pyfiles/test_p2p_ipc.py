Owner s oncall distributed To run python test distributed test_p p_ipc py torch torch multiprocessing reductions reduce_tensor torch testing _internal common_distributed MultiProcContinuousTest torch testing _internal common_utils requires_cuda_p p_access run_tests So tests written device-agnostic way device_type = cuda device_module = torch get_device_module device_type requires_cuda_p p_access P PIpcTest MultiProcContinuousTest classmethod backend_str cls gloo _init_device - None init pin process device device_module set_device device torch empty device=self device property device - torch device torch device device_type rank test_p p_ipc - None Test cross-process P P access works reducing tensor then constructing new tensor reduced tensor while modifying -th argument This test here help stabilize P P share mechanism preventing bc-breakage _init_device tensor torch Tensor rank == tensor = torch randn device=self device tensor_meta = reduce_tensor tensor torch distributed broadcast_object_list tensor_meta src= recv_list = None torch distributed broadcast_object_list recv_list src= tensor_meta = recv_list func args = tensor_meta args = list args args = rank tensor = func args torch distributed barrier rank == tensor fill_ device_module synchronize torch distributed barrier assert tensor allclose tensor torch distributed barrier __name__ == __main__ run_tests