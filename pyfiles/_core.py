mypy allow-untyped-defs flake noqa B We do need flake complains line length __future__ annotations ctypes datetime inspect itertools logging operator pathlib textwrap traceback typing collections abc Callable Mapping Sequence typing Any Literal onnxscript onnxscript evaluator onnxscript ir onnxscript ir convenience ir_convenience torch torch fx torch export graph_signature torch onnx _internal _lazy_import onnxscript_apis torch onnx _internal exporter _analysis _building _capture_strategies _constants _dispatching _errors _flags _fx_passes _ir_passes _onnx_program _registration _reporting _tensors _type_casting _verification typing TYPE_CHECKING os numpy typing npt Define utilities convert PyTorch data types so users do need specify manually _TORCH_DTYPE_TO_ONNX dict torch dtype ir DataType = torch bfloat ir DataType BFLOAT torch bool ir DataType BOOL torch complex ir DataType COMPLEX torch complex ir DataType COMPLEX torch float ir DataType FLOAT torch float ir DataType FLOAT torch float ir DataType DOUBLE torch float _e m fn ir DataType FLOAT E M FN torch float _e m fnuz ir DataType FLOAT E M FNUZ torch float _e m ir DataType FLOAT E M torch float _e m fnuz ir DataType FLOAT E M FNUZ torch float _e m fn_x ir DataType FLOAT E M torch int ir DataType INT torch int ir DataType INT torch int ir DataType INT torch int ir DataType INT torch uint ir DataType UINT torch uint ir DataType UINT torch uint ir DataType UINT torch uint ir DataType UINT _BLUE = \ m _END = \ m _STEP_ONE_ERROR_MESSAGE = textwrap dedent f \ Failed export model torch export _BLUE This step _END exporting model ONNX Next steps - Modify model code ` torch export export ` succeed Refer https pytorch org docs stable generated exportdb index html more information - Debug ` torch export export ` submit PR PyTorch - Create issue PyTorch GitHub repository against _BLUE torch export _END component attach full error stack well reproduction scripts _STEP_TWO_ERROR_MESSAGE = textwrap dedent f \ Failed decompose FX graph ONNX compatibility _BLUE This step _END exporting model ONNX Next steps - Create issue PyTorch GitHub repository against _BLUE torch export _END component attach full error stack well reproduction scripts - Create error report ` torch onnx export report=True ` save ExportedProgram pt file Create issue PyTorch GitHub repository against _BLUE onnx _END component Attach error report pt model _STEP_THREE_ERROR_MESSAGE = textwrap dedent f \ Failed convert exported program ONNX model _BLUE This step _END exporting model ONNX Next steps - If there missing ONNX function implement register registry - If there internal error during ONNX conversion debug error submit PR PyTorch - Create error report ` torch onnx export report=True ` save ExportedProgram pt file Create issue PyTorch GitHub repository against _BLUE onnx _END component Attach error report pt model logger = logging getLogger __name__ The current tracer being used trace operators used torch onnx _internal exporter _torchlib ops hop py current_tracer _building OpRecorder &#124; None = None torch_dtype_to_onnx_dtype dtype torch dtype - ir DataType _TORCH_DTYPE_TO_ONNX dtype TorchTensor ir Tensor __init__ tensor torch Tensor name str &#124; None = None Pass tensor raw data ir Tensor s constructor tensor dtype == torch float _e m fn_x Change shape unpacked shape shape = ir Shape _type_casting get_float _shape tensor frozen=True The base will set shape tensor s shape shape = None super __init__ tensor dtype=torch_dtype_to_onnx_dtype tensor dtype shape=shape name=name numpy - npt NDArray raw torch Tensor Handle dtypes natively supported NumPy We pick uint dtype has same size original dtype view tensor dtype so convertible NumPy then view back proper dtype using ml_dtypes obtained calling dtype numpy pyrefly ignore missing-attribute dtype == ir DataType BFLOAT pyrefly ignore missing-attribute raw view torch uint numpy force=True view dtype numpy dtype ir DataType FLOAT E M FN ir DataType FLOAT E M FNUZ ir DataType FLOAT E M ir DataType FLOAT E M FNUZ pyrefly ignore missing-attribute raw view torch uint numpy force=True view dtype numpy dtype == ir DataType FLOAT E M _type_casting unpack_float x _as_uint raw view pyrefly ignore missing-attribute dtype numpy raw numpy force=True __array__ dtype Any = None copy bool &#124; None = None - npt NDArray del copy Unused needed signature dtype None numpy numpy __array__ dtype _get_cbytes Get ctypes byte array pointing tensor data torch _subclasses fake_tensor torch _subclasses fake_tensor unset_fake_temporarily Disable any fake mode so calling detach etc will real tensor tensor = raw detach cpu contiguous isinstance tensor torch _subclasses fake_tensor FakeTensor raise TypeError pyrefly ignore missing-attribute f Cannot take content out FakeTensor name Please replace tensor tensor backed real data using ONNXProgram apply_weights save model without initializers setting include_initializers=False Return tensor ensure garbage collected while ctypes array use tensor ctypes c_ubyte tensor element_size tensor numel from_address tensor data_ptr tobytes - bytes Implement tobytes support native PyTorch types so we can use types like bloat Reading memory directly also more efficient because avoids copying NumPy array _ data = _get_cbytes bytes data tofile file - None _ data = _get_cbytes file write data https github com pytorch pytorch blob ee cb daa f ea aaa f torch export graph_signature py#L C -L C InputKind Enum USER_INPUT = auto PARAMETER = auto BUFFER = auto CONSTANT_TENSOR = auto CUSTOM_OBJ = auto TOKEN = auto https github com pytorch pytorch blob ee cb daa f ea aaa f torch export graph_signature py#L C -L C OutputKind Enum USER_OUTPUT = auto LOSS_OUTPUT = auto BUFFER_MUTATION = auto GRADIENT_TO_PARAMETER = auto GRADIENT_TO_USER_INPUT = auto USER_INPUT_MUTATION = auto TOKEN = auto _set_shape_types values Sequence ir Value meta_vals Sequence torch Tensor complex_to_float bool = True - None isinstance meta_vals Sequence logger warning Expected meta_vals sequence got s There may internal error meta_vals meta_vals = meta_vals value meta_val zip values meta_vals _set_shape_type value meta_val complex_to_float=complex_to_float _set_shape_type value ir Value meta_val torch Tensor &#124; torch SymBool &#124; torch SymInt &#124; torch SymFloat &#124; tuple torch Tensor complex_to_float bool - None isinstance meta_val tuple logger warning Setting shape type tensors supported yet isinstance meta_val torch Tensor dims = shape tuple int meta_val dtype == torch float _e m fn_x Change shape unpacked shape shape = _type_casting get_float _shape meta_val shape = meta_val shape dim shape isinstance dim int dims append dim pyrefly ignore bad-argument-type dims append str dim node If dtype set already e g onnx_symbolic ops we don t need set again When user specifies complex onnx_symbolic we consider intention even though non ONNX ops deals complex values In case we don t change dtype shape tensor value dtype None value dtype = torch_dtype_to_onnx_dtype meta_val dtype complex_to_float meta_val dtype == torch complex value dtype = ir DataType FLOAT Add last dimension tensor complex hold real imag parts dims append meta_val dtype == torch complex value dtype = ir DataType DOUBLE Add last dimension tensor complex hold real imag parts dims append value shape = ir Shape dims isinstance meta_val int torch SymInt aten sym_size output int tensor which stands size one dim We treat scalar value dtype = ir DataType INT value shape = ir Shape isinstance meta_val bool torch SymBool value dtype = ir DataType BOOL value shape = ir Shape isinstance meta_val float torch SymFloat value dtype = ir DataType FLOAT value shape = ir Shape _get_qualified_module_name cls Any - str isinstance cls str cls module = cls __module__ module None module == str __class__ __module__ cls __name__ module + + cls __name__ _get_node_namespace node torch fx Node - tuple str list str list str Get namespace scope node Example L__self__ torchvision models resnet ResNet L__self___avgpool avgpool torch nn modules pooling AdaptiveAvgPool d Will yield namespace torchvision models resnet ResNet avgpool torch nn modules pooling AdaptiveAvgPool d node_name node_target class_hierarchy torchvision models resnet ResNet torch nn modules pooling AdaptiveAvgPool d node_target name_scopes avgpool node_name Args node The node get namespace scope Returns namespace class_hierarchy name_scope nn_module_stack = node meta get nn_module_stack logger debug s nn_module_stack nn_module_stack None logger warning nn_module_stack found node s Skip adding metadata node name f node name node target str node target node name namespaces = class_hierarchy = name_scopes = name nn_module nn_module_stack values name_scopes append name nn_module_name = _get_qualified_module_name nn_module class_hierarchy append nn_module_name namespaces append f name _get_qualified_module_name nn_module namespaces append f node name node target class_hierarchy append str node target name_scopes append node name join namespaces class_hierarchy name_scopes _set_node_metadata fx_node torch fx Node ir_node ir Node - None Adds namespace other node metadata ONNX node namespace class_hierarchy name_scopes = _get_node_namespace fx_node ir_node metadata_props namespace = namespace ir_node metadata_props pkg torch onnx class_hierarchy = repr class_hierarchy ir_node metadata_props pkg torch onnx name_scopes = repr name_scopes ir_node metadata_props pkg torch onnx fx_node = str fx_node format_node ir_node metadata_props pkg torch onnx stack_trace = fx_node meta get stack_trace _handle_getitem_node node torch fx Node node_name_to_values dict str ir Value &#124; Sequence ir Value - ir Value Handle getitem node Add input value getting mapping then value There two cases node The output Sequence traced we can simply get value sequence The output produced SplitToSequence node we need get value sequence value This function only handles first case assert len node all_input_nodes == source = node all_input_nodes source_outputs = node_name_to_values source name assert isinstance source_outputs Sequence f Expected source name output sequence got node_name_to_values source name index = typing cast int node args value = source_outputs index Save getitem value values mapping case one graph outputs node_name_to_values node name = value Rename name value getitem name value name = node name value _handle_call_function_node graph_like ir Graph &#124; ir Function node torch fx Node node_name_to_values dict str ir Value &#124; Sequence ir Value - None Handle call_function node Args graph The ONNX graph construction node The FX node translate node_name_to_values A mapping FX node names their produced ir Value node target operator getitem _handle_getitem_node node node_name_to_values Add op graph op = str node target fx_inputs attributes input_names output_names = _get_inputs_and_attributes node inputs list ir Value &#124; None = i input_ enumerate fx_inputs input_ None inputs append None hasattr input_ name isinstance input_ torch fx Node input_ target operator getitem actual_input = _handle_getitem_node input_ node_name_to_values inputs append actual_input value = node_name_to_values input_ name assert isinstance value Sequence inputs append value attributes f arg_ i = input_ outputs = ir Value name=name name output_names len outputs _set_shape_types outputs node meta val complex_to_float=False node_name_to_values node name = outputs _set_shape_type outputs node meta val complex_to_float=False node_name_to_values node name = outputs ir_node = ir Node pkg torch ops op inputs attributes=ir_convenience convert_attributes attributes outputs=outputs name=node name ir_node meta node = node ir_node metadata_props pkg torch onnx input_names = repr input_names Record nn Module stack node _set_node_metadata node ir_node graph_like append ir_node _convert_fx_arg_to_onnx_arg arg node_name_to_values dict str ir Value &#124; Sequence ir Value node_name_to_local_functions dict str ir Function - Any Convert FX argument ONNX compatible argument This function - Converts torch dtype integer - Converts torch device memory_format layout string - Converts torch fx Node ir Value - Converts sequence torch fx Node sequence ir Value - Converts get_attr node ir Function arg None None arguments modified because when arg ONNX input we need preserve None value when arg ONNX attribute we want drop value The actual dropping None attribute value done OpRecorder None hasattr arg name isinstance arg torch fx Node arg target operator getitem source = arg all_input_nodes source_outputs = node_name_to_values source name isinstance source_outputs Sequence If node getting input another node get actual value node retrieving _handle_getitem_node arg node_name_to_values ` source_outputs ` sequence tensor value we need use SequenceAt get value This handled torchlib pass isinstance arg torch fx Node arg op == get_attr node_name_to_local_functions arg name If input node get value mapping node_name_to_values arg name isinstance arg list tuple _convert_fx_arg_to_onnx_arg elem node_name_to_values node_name_to_local_functions elem arg isinstance arg torch device torch memory_format torch layout str arg isinstance arg torch dtype torch_dtype_to_onnx_dtype arg Maybe Python value arg _get_onnxscript_opset opset_version int - onnxscript values Opset onnxscript values Opset opset_version _is_onnx_op op Any - bool Whether op overload ONNX custom op implemented PyTorch isinstance op torch _ops OpOverload False op name startswith onnx _parse_onnx_op op torch _ops OpOverload - tuple str int Parse ONNX custom op overload name get op type opset version name = op name len onnx name _ opset = name partition opset name int opset _handle_call_function_node_with_lowering model ir Model node torch fx Node node_name_to_values dict str ir Value &#124; Sequence ir Value graph_like ir Graph &#124; ir Function constant_farm dict Any ir Value registry _registration ONNXRegistry opset onnxscript values Opset node_name_to_local_functions dict str ir Function - None Translate call_function node ONNX node Args model The ONNX model construction node The FX node translate node_name_to_values A mapping FX node names their produced ONNX ` ` Value ` ` graph_like The current ONNX graph construction Must add nodes graph because can subgraph currently being constructed constant_farm A mapping constant values existing ONNX ` ` Value ` ` s registry The registry all aten ONNX decomposition functions opset The ONNX Script opset object constructing ONNX nodes node_name_to_local_functions A mapping subgraph names corresponding ONNX functions node target operator getitem source = node all_input_nodes source_outputs = node_name_to_values source name isinstance source_outputs Sequence _handle_getitem_node node node_name_to_values ` source_outputs ` sequence tensor value we need use SequenceAt get value This handled torchlib pass Map FX inputs ONNX inputs fill optional inputs torch_args torch_kwargs op-level validation fx_args = node args fx_kwargs = node kwargs Replace input FX nodes ONNX values onnx_args = _convert_fx_arg_to_onnx_arg input_ node_name_to_values node_name_to_local_functions input_ fx_args onnx_kwargs = key value fx_kwargs items onnx_kwargs key = _convert_fx_arg_to_onnx_arg value node_name_to_values node_name_to_local_functions key == dtype onnx_kwargs key None Set dtype - None TODO justinchuby Maybe keep None onnx_kwargs key = - _is_onnx_op node target Handle torch ops onnx ops These ops can directly added graph op_type opset_version = _parse_onnx_op node target type ignore arg-type If final inputs None strip them node inputs input_ reversed onnx_args input_ None break onnx_args pop onnx_node = ir Node op_type onnx_args ir convenience convert_attributes onnx_kwargs name=node name num_outputs=len node target _schema returns type ignore union-attr version=opset_version Store single node list consistent rest code further processing onnx_nodes = onnx_node len onnx_node outputs == outputs = onnx_node outputs outputs = onnx_node outputs type ignore assignment Find matching ONNX overload node TODO Log message here expose false positives onnx_function message = _dispatching dispatch node registry onnx_function None raise _errors DispatchError f No ONNX function found node target r Failure message message onnxscript evaluator default_as tracer = _building OpRecorder opset constant_farm global current_tracer current_tracer = tracer try outputs = onnx_function onnx_args onnx_kwargs except Exception e raise _errors GraphConstructionError f Error when calling function onnx_function args onnx_args kwargs onnx_kwargs e finally current_tracer = None Add defined functions model identifier onnxscript_function tracer functions items identifier model functions continue isinstance onnxscript_function ir Function ir_function = onnxscript_function TODO Get IR function directly when onnxscript updated proto = onnxscript_function to_function_proto ir_function = ir serde deserialize_function proto model functions identifier = ir_function Opset imports added model final add_opset_imports pass onnx_nodes = tracer nodes del tracer tracer no longer needed NOTE Instead using output names node target _schema we always use index there more than one outputs so names can programmatically reconstructed This useful comparing values ONNX graph those FX graph When there multiple outputs output names will node_name__ node_name__ etc isinstance outputs Sequence _set_shape_types outputs node meta val complex_to_float=True node_name_to_values node name = outputs i output enumerate outputs output name = f node name __ i Set name producing node using value name correspondence producer = output producer producer None producer name = f node_ output name _set_shape_type outputs node meta val complex_to_float=True node_name_to_values node name = outputs outputs name = node name producer = outputs producer producer None producer name = f node_ outputs name ir_node onnx_nodes ir_node meta node = node Record nn Module stack node _set_node_metadata node ir_node Add traced nodes current graph Must add nodes graph model graph because can subgraph currently being constructed graph_like extend onnx_nodes _handle_placeholder_node node torch fx Node node_name_to_values dict str ir Value &#124; Sequence ir Value graph_like ir Graph &#124; ir Function lower str opset onnxscript values Opset - None Placeholder nodes user inputs We need create new tensor each user input add graph s inputs name = node name input_ = _tensors SymbolicTensor opset name=name input_ meta node = node _set_shape_type input_ node meta val complex_to_float=lower = none node_name_to_values name = input_ The inputs should add graph here graph_like inputs append input_ _handle_get_attr_node node torch fx Node owned_graphs Mapping str ir Function node_name_to_local_functions dict str ir Function - None Handle get_attr node assigning corresponding ONNX function node name An example ExportedProgram has uses get_attr nodes ExportedProgram GraphModule torch nn Module forward arg _ f true_graph_ = true_graph_ get_attr false_graph_ = false_graph_ get_attr conditional = torch ops higher_order cond False true_graph_ false_graph_ arg _ true_graph_ = false_graph_ = arg _ = None getitem f = conditional conditional = None getitem lambda torch nn Module forward arg _ f cos f = torch ops aten cos default arg _ arg _ = None cos lambda torch nn Module forward arg _ f sin f = torch ops aten sin default arg _ arg _ = None sin Args node The FX node translate owned_graphs A mapping subgraph names corresponding ONNX functions node_name_to_local_functions A mapping local function names their corresponding ONNX functions isinstance node target str logger warning Expected node target node s string got s There may internal error node type node target function = owned_graphs node target node_name_to_local_functions node name = function _handle_output_node node torch fx Node node_name_to_values dict str ir Value &#124; Sequence ir Value graph_like ir Graph &#124; ir Function - None Handle output node adding output graph s outputs Args node The FX node translate node_name_to_values A mapping FX node names their produced ONNX ` ` Value ` ` graph_like The ONNX graph construction node args can tuple more than one elements This happens when example subgraph has multiple outputs We flatten them all ONNX graph outputs output node args type ignore index union-attr output None logger warning Output node s has None output The output ignored exported graph Please ensure graph output order expected node name continue output_value_name = output name type ignore union-attr assert isinstance output_value_name str f Bug Expected output_value_name r string values = node_name_to_values output_value_name isinstance values Sequence graph_like outputs extend values graph_like outputs append values _translate_fx_graph fx_graph torch fx Graph model ir Model graph_like ir Graph &#124; ir Function owned_graphs Mapping str ir Function lower Literal at_conversion none registry _registration ONNXRegistry - dict str ir Value &#124; Sequence ir Value Translate submodule ONNX function Any functions used traced functions will added model Args fx_graph The FX graph module translate model The ONNX model construction current_scope The current name scope submodule excluding current module name E g true_graph_ false_graph_ graph_name The name submodule E g true_graph_ graph The ONNX graph construction owned_graphs The subgraphs owned current graph lower The lowering strategy use registry The registry all aten ONNX decomposition functions Returns A mapping FX node names their produced ONNX ` ` Value ` ` node_name_to_values dict str ir Value &#124; Sequence ir Value = The reason we need node_name_to_local_functions addition owned_graphs because get_attr nodes may assign different name than GraphModule name subgraph This typical valid Python node_name_to_local_functions dict str ir Function = constant_farm dict Any ir Value = opset = _get_onnxscript_opset registry opset_version node fx_graph nodes logger debug s node name node args node target node op node type node kwargs try node op == placeholder _handle_placeholder_node node node_name_to_values graph_like=graph_like lower=lower opset=opset node op == call_function lower == at_conversion _handle_call_function_node_with_lowering model node node_name_to_values graph_like=graph_like constant_farm=constant_farm registry=registry opset=opset node_name_to_local_functions=node_name_to_local_functions No lowering _handle_call_function_node graph_like node node_name_to_values node op == get_attr _handle_get_attr_node node owned_graphs=owned_graphs node_name_to_local_functions=node_name_to_local_functions node op == output _handle_output_node node node_name_to_values graph_like=graph_like except Exception e raise _errors ConversionError f Error when translating node node format_node See stack trace more information e node_name_to_values _get_inputs_and_attributes node torch fx Node - tuple list torch fx Node &#124; None dict str Any list str list str Find Fill provided kwargs default values Returns inputs attributes input_names output_names inspect isbuiltin node target isinstance node target str inputs = list node args inputs node name type ignore return-value The target should ATen operator now assert hasattr node target _schema f The target should ATen operator now node target node target has no schema node_schema torch FunctionSchema = node target _schema This function assumes order arguments FX op same order arguments TorchScript op inputs list Any = type ignore no-redef input_names list str = attributes dict str Any = inspect isbuiltin node target inputs = list node args arg schema_arg zip node args node_schema arguments arg None isinstance arg torch fx Node inputs append arg input_names append schema_arg name isinstance arg Sequence all elem None isinstance elem torch fx Node elem arg inputs extend arg input_names extend schema_arg name len arg isinstance arg torch device attributes schema_arg name = str arg isinstance arg torch dtype attributes schema_arg name = torch_dtype_to_onnx_dtype arg attributes schema_arg name = arg schema_arg node_schema arguments schema_arg name node kwargs continue kwarg = node kwargs schema_arg name schema_arg name layout device requires_grad memory_format implicit isinstance kwarg torch device attr = str kwarg isinstance kwarg torch dtype attr = torch_dtype_to_onnx_dtype kwarg type ignore assignment attr = kwarg type ignore assignment attributes schema_arg name = attr output_names = f node name _ output name output node_schema returns inputs attributes input_names output_names type ignore return-value _maybe_start_profiler should_profile bool - Any should_profile pyinstrument type ignore import-not-found profiler = pyinstrument Profiler async_mode= disabled profiler start profiler None _maybe_stop_profiler_and_get_result profiler - str &#124; None profiler None None profiler stop profiler output_text unicode=True _format_exception e Exception - str Format full traceback Python would show \n join traceback format_exception type e e e __traceback__ _summarize_exception_stack e BaseException - str Format exception stack showing text each exception causes = e while e __cause__ None causes append e __cause__ e = e __cause__ \n\n## Exception summary\n\n + ‚¨ÜÔ∏è\n join f type e e \n e reversed causes + \n Refer full stack trace above more information _format_exceptions_for_all_strategies results list _capture_strategies Result - str Format all exceptions capture strategies \n join f ‚ö†Ô∏è Errors strategy result strategy ----------------------- \n\n f _format_exception result exception \n result results result exception None exported_program_to_ir exported_program torch export ExportedProgram registry _registration ONNXRegistry &#124; None = None lower Literal at_conversion none = at_conversion - ir Model Convert exported program ONNX IR model Reference - ExportedProgram spec https pytorch org docs stable export ir_spec html Args exported_program The exported program convert lower Whether lower graph core ONNX operators at_conversion Lower when translating FX graph ONNX IR none Do lower graph registry The registry all ONNX Script decomposition registry None registry = _registration ONNXRegistry from_torchlib lower = none exported_program = _prepare_exported_program_for_export exported_program registry=registry _exported_program_to_onnx_program exported_program registry=registry lower=lower model _prepare_exported_program_for_export exported_program torch export ExportedProgram registry _registration ONNXRegistry - torch export ExportedProgram Decompose apply pre-export transformations exported program Support dynamism input dim torch fx experimental _config patch backed_size_oblivious=True type ignore attr-defined Decompose graph given implemented torch ops ONNX exported_program = _fx_passes decompose_with_registry exported_program registry graph_module = exported_program graph_module Include explicit type promotion nodes _fx_passes insert_type_promotion_nodes graph_module graph_module = _fx_passes remove_assertion_nodes graph_module Reassign graph module save some runtime exported_program _graph_module = graph_module exported_program _get_scope_name scoped_name str - tuple str str Get scope name node Examples _get_scope_name _get_scope_name true_graph true_graph _get_scope_name true_graph false_graph true_graph false_graph _get_scope_name true_graph false_graph some_graph true_graph false_graph some_graph Args scoped_name The scoped name node Returns scope name scoped_name scope name = scoped_name rsplit scope name = scoped_name scope name _exported_program_to_onnx_program exported_program torch export ExportedProgram registry _registration ONNXRegistry lower Literal at_conversion none = at_conversion - _onnx_program ONNXProgram Convert exported program ONNX Program The exported_program field returned ONNXProgram one after decompositions have been applied Reference - ExportedProgram spec https pytorch org docs stable export ir_spec html Args exported_program The exported program convert The exported program should one after decompositions have been applied lower Whether lower graph core ONNX operators at_conversion Lower when translating FX graph ONNX IR none Do lower graph registry The registry all ONNX Script decomposition model = ir Model graph=ir Graph nodes= Opset imports added model final add_opset_imports pass name= main_graph metadata_props= pkg torch export ExportedProgram graph_signature str exported_program graph_signature pkg torch export ExportedProgram range_constraints str exported_program range_constraints ir_version=_constants ONNX_IR_VERSION producer_name= pytorch producer_version=torch __version__ A dictionary storing translated subgraphs ONNX functions made available outer graphs subgraph_scope subgraph_name IR function scoped_subgraphs dict str dict str ir Function = values = None Translate all nodes all subgraphs main graph Create dictionary values main graph step - add inputs outputs module torch fx GraphModule Reverse order modules so innermost module processed first made available outer module name module reversed tuple exported_program graph_module named_modules remove_duplicate=False Obtain graphs previously built owned current module owned_graphs = scoped_subgraphs setdefault name fx_graph = module graph graph_like ir Graph &#124; ir Function name == Root graph graph_like = model graph function_name = name replace __ Inputs outputs will created within _translate_fx_graph func = ir Function domain=_constants LOCAL_FUNCTION_DOMAIN name=function_name graph=ir Graph nodes= attributes= Make function available outer graph scope subgraph_name = _get_scope_name name scoped_subgraphs setdefault scope subgraph_name = func model functions func identifier = func graph_like = func values = _translate_fx_graph fx_graph model graph_like=graph_like owned_graphs=owned_graphs lower=lower registry=registry assert name == The last module processed should root module assert values None Clear input output main graph add them back step - using more accurate graph signature model graph inputs clear model graph outputs clear Add user inputs all parameters buffers graph Since node names tensor names different we need rename nodes match tensor names later For now we will just use node names user_inputs = spec spec exported_program graph_signature input_specs spec kind == graph_signature InputKind USER_INPUT non_user_inputs = spec spec exported_program graph_signature input_specs spec kind = graph_signature InputKind USER_INPUT spec itertools chain user_inputs non_user_inputs Put user inputs first then parameters buffers isinstance spec arg graph_signature ConstantArgument logger debug Skipping constant argument s spec arg continue value_name = spec arg name input_kind = spec kind persistent = spec persistent value = values value_name assert isinstance value Sequence f Input value_name should sequence This unexpected value metadata_props pkg torch export graph_signature InputSpec kind = input_kind name value metadata_props pkg torch export graph_signature InputSpec persistent = str persistent input_kind == graph_signature InputKind USER_INPUT Add only user inputs graph Subsequent passes can decide they want add initializers inputs model graph inputs append value model graph initializers value_name = value Add user outputs graph assign metadata all outputs user_outputs = spec spec exported_program graph_signature output_specs spec kind == graph_signature OutputKind USER_OUTPUT non_user_outputs = spec spec exported_program graph_signature output_specs spec kind = graph_signature OutputKind USER_OUTPUT spec itertools chain user_outputs non_user_outputs isinstance spec arg graph_signature ConstantArgument logger warning Skipping constant argument s spec arg continue value_name = spec arg name output_kind = spec kind value = values value_name isinstance value ir Value Sequence raise TypeError f Output value_name should ir Value Actual type type value value r This may due incorrect implementation ONNX function produced output The output value may sequence meaning operator has multiple outputs _values = value isinstance value Sequence value len _values logger warning Model output s has multiple values s output spec s Please make sure expected value_name _values spec value _values value metadata_props pkg torch export graph_signature OutputSpec kind = output_kind name output_kind == graph_signature OutputKind USER_OUTPUT model graph outputs append value Rename initializers match tensor names name param_name itertools chain exported_program graph_signature inputs_to_parameters items exported_program graph_signature inputs_to_buffers items exported_program graph_signature inputs_to_lifted_tensor_constants items initializer = model graph initializers pop name initializer name = param_name Record original name so users can search metadata correspond FX graph initializer metadata_props pkg torch onnx original_node_name = name model graph initializers param_name = initializer Add initializers graph ExportedProgram stores parameters buffers state_dict non_persistent_buffers lifted_tensor_constants there so we need get them name_ apis name torch_tensor itertools chain exported_program named_parameters pyrefly ignore bad-argument-type exported_program named_buffers exported_program constants items initializer = model graph initializers get name type ignore assignment initializer None logger warning Tensor s one initializers name continue isinstance torch_tensor torch Tensor raise NotImplementedError f Tensor name should torch Tensor Actual type type torch_tensor torch_tensor r This unexpected yet supported ir_tensor = TorchTensor torch_tensor name=name initializer const_value = ir_tensor _set_shape_type initializer torch_tensor complex_to_float=lower = none TODO Decide we should keep mutated buffers inputs outputs Collect add opset imports model _ir_passes add_opset_imports model _onnx_program ONNXProgram model exported_program _verbose_printer verbose bool &#124; None - Callable None Prints messages based ` verbose ` verbose False lambda _ __ None pyrefly ignore not-iterable lambda args kwargs print torch onnx args kwargs _flags set_onnx_exporting_flag export model torch nn Module &#124; torch export ExportedProgram &#124; torch fx GraphModule &#124; torch jit ScriptModule &#124; torch jit ScriptFunction args tuple Any = kwargs dict str Any &#124; None = None registry _registration ONNXRegistry &#124; None = None dynamic_shapes dict str Any &#124; tuple Any &#124; list Any &#124; None = None input_names Sequence str &#124; None = None output_names Sequence str &#124; None = None report bool = False verify bool = False profile bool = False dump_exported_program bool = False artifacts_dir str &#124; os PathLike = verbose bool &#124; None = None - _onnx_program ONNXProgram Export PyTorch model ONNXProgram Args model The model export This can PyTorch nn Module ExportedProgram args The arguments pass model kwargs The keyword arguments pass model registry The registry all ONNX decompositions dynamic_shapes Dynamic shapes graph input_names If provided rename inputs output_names If provided rename outputs report Whether generate error report export fails verify Whether verify ONNX model after exporting profile Whether profile export process When report True profile result will saved report Otherwise profile result will printed dump_exported_program Whether save exported program file artifacts_dir The directory save exported program error reports verbose Whether print verbose messages If None default some messages will printed Returns The ONNXProgram exported IR graph Raises TorchExportError If export process fails torch export ConversionError If ExportedProgram ONNX translation fails Set up error reporting facilities timestamp = datetime datetime now strftime Y- m- d_ H- M- S- f profiler = _maybe_start_profiler profile Create artifacts directory does exist artifacts_dir = pathlib Path artifacts_dir report profile dump_exported_program artifacts_dir mkdir parents=True exist_ok=True verbose_print = _verbose_printer verbose export_status = _reporting ExportStatus failed_results list _capture_strategies Result = program torch export ExportedProgram &#124; None = None capture_strategy str &#124; None = None Step Export model torch export export model already ExportedProgram isinstance model torch export ExportedProgram We know model already exported program so args kwargs dynamic_shapes used program = model torch export export has strict default False export_status torch_export_non_strict = True Convert nn Module ExportedProgram Try everything üê∞ all paths getting ExportedProgram When input JIT module last strategy will succeed so handled result _capture_strategies Result &#124; None = None strategy_class _capture_strategies CAPTURE_STRATEGIES strategy = strategy_class type ignore abstract verbose=verbose False Treat None verbose dump=dump_exported_program artifacts_dir=artifacts_dir timestamp=timestamp result = strategy model args kwargs dynamic_shapes=dynamic_shapes Record status strategy_class _capture_strategies TorchExportNonStrictStrategy export_status torch_export_non_strict = result success strategy_class _capture_strategies TorchExportStrictStrategy export_status torch_export_strict = result success strategy_class _capture_strategies TorchExportDraftExportStrategy export_status torch_export_draft_export = result success result exception None failed_results append result result success assert result exported_program None program = result exported_program break assert result None capture_strategy = result strategy result exported_program None If all strategies fail produce error report raise first error profile_result = _maybe_stop_profiler_and_get_result profiler report report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status try _reporting create_torch_export_error_report report_path _format_exceptions_for_all_strategies failed_results export_status=export_status profile_result=profile_result except Exception e_report verbose_print f Failed save error report due error e_report report_path = None first_error = failed_results exception assert first_error None NOTE We only throw torch export first exception because we want focus torch export export error Errors other strategies like torch jit trace due fallback can confusing users We save all errors error report raise _errors TorchExportError _STEP_ONE_ERROR_MESSAGE + f \nError report has been saved report_path report + _summarize_exception_stack first_error first_error assert program None dump_exported_program verbose_print Dumping ExportedProgram because ` dump_exported_program=True ` program_path = artifacts_dir f onnx_export_ timestamp pt try torch export save program program_path except Exception e verbose_print f Failed save ExportedProgram due error e verbose_print f ExportedProgram has been saved program_path Step Decompose exported program insert type promotion nodes verbose_print Run decomposition try Build ONNX function registry registry None registry = _registration ONNXRegistry from_torchlib Process exported program run decompositions type promotions etc decomposed_program = _prepare_exported_program_for_export program registry=registry except Exception e export_status decomposition = False verbose_print Run decomposition ‚ùå profile_result = _maybe_stop_profiler_and_get_result profiler report report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status Run analysis get error report try _reporting create_onnx_export_report report_path f _format_exceptions_for_all_strategies failed_results \n\n _format_exception e program export_status=export_status profile_result=profile_result registry=registry except Exception logger exception Failed save report due error report_path = None raise _errors ConversionError _STEP_TWO_ERROR_MESSAGE + f \nError report has been saved report_path report + _summarize_exception_stack e e export_status decomposition = True verbose_print Run decomposition ‚úÖ Step Translate decomposed program ONNX produce ONNXProgram verbose_print Translate graph into ONNX report profile pre_decomp_unique_ops post_decomp_unique_ops = _analysis compare_ops program decomposed_program pre_decomp_unique_ops = None post_decomp_unique_ops = None try Convert exported program ONNX model onnx_program = _exported_program_to_onnx_program decomposed_program registry=registry Record strategy used getting exported program unit test assertions onnx_program _capture_strategy = capture_strategy Run ONNX passes input_names _ir_passes rename_inputs onnx_program model input_names output_names _ir_passes rename_outputs onnx_program model output_names export_status onnx_translation = True verbose_print Translate graph into ONNX ‚úÖ except Exception e export_status onnx_translation = False verbose_print Translate graph into ONNX ‚ùå profile_result = _maybe_stop_profiler_and_get_result profiler report report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status try assert pre_decomp_unique_ops None assert post_decomp_unique_ops None Run analysis get error report _reporting create_onnx_export_report report_path f _format_exceptions_for_all_strategies failed_results \n\n _format_exception e decomposed_program decomp_comparison=_reporting format_decomp_comparison pre_decomp_unique_ops post_decomp_unique_ops export_status=export_status profile_result=profile_result registry=registry verbose_print f Export report has been saved report_path except Exception logger exception Failed save report due error report_path = None raise _errors ConversionError _STEP_THREE_ERROR_MESSAGE + f \nError report has been saved report_path report + _summarize_exception_stack e e profile_result = _maybe_stop_profiler_and_get_result profiler assert onnx_program exported_program None verify Return verification requested report try assert pre_decomp_unique_ops None assert post_decomp_unique_ops None report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status _reporting create_onnx_export_report report_path No errors failed_results _format_exceptions_for_all_strategies failed_results onnx_program exported_program decomp_comparison=_reporting format_decomp_comparison pre_decomp_unique_ops post_decomp_unique_ops export_status=export_status profile_result=profile_result model=onnx_program model registry=registry verbose_print f Export report has been saved report_path except Exception logger exception Failed save report due error profile profile_result None verbose_print Profile result verbose_print profile_result onnx_program Step verify=True Check ONNX model ONNX checker try verbose_print Check ONNX model onnxscript_apis check_model onnx_program model export_status onnx_checker = True verbose_print Check ONNX model ‚úÖ except Exception e export_status onnx_checker = False verbose_print Check ONNX model ‚ùå report try assert pre_decomp_unique_ops None assert post_decomp_unique_ops None report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status _reporting create_onnx_export_report report_path f _format_exceptions_for_all_strategies failed_results \n\n _format_exception e onnx_program exported_program decomp_comparison=_reporting format_decomp_comparison pre_decomp_unique_ops post_decomp_unique_ops export_status=export_status profile_result=profile_result model=onnx_program model registry=registry verbose_print f Export report has been saved report_path except Exception logger exception Failed save report due error logger warning Conversion successful ONNX model fails ONNX checker noqa G Please create issue f PyTorch GitHub repository against _BLUE onnx _END component attach full error stack well reproduction scripts exc_info=e onnx_program Step verify=True Execute model ONNX Runtime try verbose_print Execute model ONNX Runtime verification_results = _verification verify_onnx_program onnx_program verbose_print Execute model ONNX Runtime ‚úÖ export_status onnx_runtime = True onnx_runtime_error_message = None except Exception e verbose_print Execute model ONNX Runtime ‚ùå export_status onnx_runtime = False onnx_runtime_error_message = _format_exception e verification_message = None Step verify=True Validate output values verbose_print Verify output accuracy export_status output_accuracy = True verification_result verification_results TODO justinchuby The threshold arbitrary right now verification_result max_abs_diff = e- logger warning Output s has large absolute difference f verification_result name verification_result max_abs_diff export_status output_accuracy = False verification_result max_rel_diff = e- logger warning Output s has large relative difference f verification_result name verification_result max_rel_diff export_status output_accuracy = False export_status output_accuracy verbose_print Verify output accuracy ‚úÖ verbose_print Verify output accuracy ‚ùå verification_message = _reporting format_verification_infos verification_results report try assert pre_decomp_unique_ops None assert post_decomp_unique_ops None traceback_lines = failed_results traceback_lines append _format_exceptions_for_all_strategies failed_results onnx_runtime_error_message traceback_lines append ‚ö†Ô∏è ONNX Runtime error ----------------------- traceback_lines append onnx_runtime_error_message traceback_lines traceback_lines append No errors report_path = artifacts_dir _reporting construct_report_file_name timestamp export_status _reporting create_onnx_export_report report_path \n\n join traceback_lines onnx_program exported_program profile_result=profile_result export_status=export_status decomp_comparison=_reporting format_decomp_comparison pre_decomp_unique_ops post_decomp_unique_ops model=onnx_program model registry=registry verification_result=verification_message verbose_print f Export report has been saved report_path except Exception logger exception Failed save report due error Release inference session created during verification onnx_program release onnx_program