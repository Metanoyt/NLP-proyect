mypy allow-untyped-decorators mypy allow-untyped-defs Owner s module tests torch torch utils data numpy np contextlib gc io inspect itertools math random re copy os tempfile unittest warnings types pickle textwrap subprocess weakref sys copyreg torch inf nan itertools product combinations permutations chain functools partial torch multiprocessing mp torch testing make_tensor torch testing _internal common_optimizers optim_db optims _get_optim_inputs_including_global_cliquey_kwargs torch testing _internal common_utils type ignore attr-defined MI _ARCH TEST_WITH_TORCHINDUCTOR TEST_WITH_ROCM run_tests IS_JETSON IS_FILESYSTEM_UTF _ENCODING IS_SANDCASTLE IS_FBCODE IS_REMOTE_GPU skipIfRocmArch skipIfTorchInductor load_tests slowTest slowTestIf skipIfCrossRef TEST_WITH_CROSSREF skipIfTorchDynamo skipRocmIfTorchInductor set_default_dtype skipCUDAMemoryLeakCheckIf BytesIOContext skipIfRocm skipIfNoSciPy TemporaryFileName TemporaryDirectoryName wrapDeterministicFlagAPITest DeterministicGuard CudaSyncGuard bytes_to_scalar parametrize skipIfMPS noncontiguous_like AlwaysWarnTypedStorageRemoval TEST_WITH_TORCHDYNAMO xfailIfTorchDynamo xfailIfS X set_warn_always_context multiprocessing reduction ForkingPickler torch testing _internal common_device_type expectedFailureMeta expectedFailureXLA instantiate_device_type_tests onlyCUDA onlyCPU dtypes dtypesIfCUDA dtypesIfCPU deviceCountAtLeast skipMeta PYTORCH_CUDA_MEMCHECK largeTensorTest onlyNativeDeviceTypes skipCUDAIfNotRocm get_all_device_types skipXLA torch backends quantized torch testing _internal data torch testing _internal common_cuda tf _on_and_off TEST_CUDNN TEST_MULTIGPU _create_scaling_case _create_scaling_models_optimizers torch testing _internal common_mkldnn reduced_f _on_and_off torch testing _internal common_dtype floating_types_and get_all_math_dtypes all_types_and_complex_and complex_types all_types_and floating_types floating_and_complex_types integral_types_and get_all_qint_dtypes all_types_complex_float _and torch testing _internal two_tensor TwoTensor torch testing _internal common_utils IS_WINDOWS TEST_WITH_TORCHINDUCTOR torch _inductor test_case TestCase torch testing _internal common_utils TestCase type ignore assignment Protects against includes accidentally setting default dtype assert torch get_default_dtype torch float load_tests torch testing _internal common_utils used automatically filter tests sharding sandcastle This line silences flake warnings load_tests = load_tests noqa PLW AMPERE_OR_ROCM = TEST_WITH_ROCM torch cuda is_tf _supported contextlib contextmanager torch_vital_set value stash = None TORCH_VITAL os environ stash = os environ TORCH_VITAL os environ TORCH_VITAL = value try yield finally stash os environ TORCH_VITAL = stash del os environ TORCH_VITAL Tests Vital Signs Torch FIXME document deprecate whatever TestBasicVitalSigns TestCase test_basic_vitals torch_vital_set assertFalse torch vitals_enabled torch_vital_set ON assertTrue torch vitals_enabled test_basic_vitals_read_write torch_vital_set ON assertTrue torch vitals_enabled This tests code path setting vital assertTrue torch set_vital Dataloader basic_unit_test TEST_VALUE_STRING assertIn TEST_VALUE_STRING torch read_vitals assertIn CUDA used torch read_vitals test_dataloader_vitals torch_vital_set ON inps = torch arange dtype=torch float view tgts = torch arange dtype=torch float view dataset = torch utils data TensorDataset inps tgts torch utils data DataLoader dataset batch_size= assertIn Dataloader enabled\t\t True torch read_vitals FIXME document deprecate whatever TestVitalSignsCuda TestCase onlyCUDA test_cuda_vitals_gpu_only device torch_vital_set ON assertIn CUDA used\t\t true torch read_vitals is_cuda_sm = torch cuda is_available torch cuda get_device_capability == TestTorchDeviceType TestCase exact_dtype = True TODO move all tensor creation common ops _rand_shape dim min_size max_size shape = _ range dim shape append random randint min_size max_size tuple shape Validates mathematical constants defined properly required Python Array API https data-apis org array-api latest API_specification constants html onlyCPU test_constants device assertIsInstance torch e float assertEqual torch e math e atol= rtol= assertIsInstance torch pi float assertEqual torch pi math pi atol= rtol= assertIsInstance torch nan float assertEqual torch nan math nan equal_nan=True assertIsInstance torch inf float assertEqual torch inf math inf onlyNativeDeviceTypes slowTestIf IS_WINDOWS dtypes torch int torch uint torch int torch int torch int torch bool torch float torch complex torch float torch complex torch uint torch uint torch uint test_bytes_to_scalar device dtype rand_byte dtype == torch bool torch randint item torch randint item element_size = torch _utils _element_size dtype _ range bytes_list = rand_byte _ range element_size scalar = bytes_to_scalar bytes_list dtype device assertEqual scalar storage untyped tolist bytes_list For testing support upsample_nearest d onlyCUDA largeTensorTest GB device= cuda dtypes torch bfloat unittest skipIf IS_JETSON Large tensor tests too large Jetson test_int _upsample d device dtype x = torch ones dtype=dtype device=device try torch nn functional interpolate x scale_factor= mode= nearest except Exception e fail f Unexpected exception raised e dtypes torch int torch uint torch int torch int torch int torch bool torch float torch complex torch float torch complex torch uint torch uint torch uint slowTestIf IS_WINDOWS test_storage device dtype v = make_tensor dtype=dtype device=device low=- high= assertEqual v storage v assertEqual v storage v v_s = v storage el_num range v numel dim = el_num v size dim = el_num v size assertEqual v_s el_num v dim dim v_s_byte = v storage untyped el_size = v element_size el_num range v numel start = el_num el_size end = start + el_size dim = el_num v size dim = el_num v size assertEqual bytes_to_scalar v_s_byte start end dtype device v dim dim onlyNativeDeviceTypes dtypes torch int torch uint torch int torch int torch int torch bool torch float torch complex torch float torch complex torch quint torch qint torch qint torch quint x slowTestIf IS_WINDOWS test_storage_setitem device dtype Skip quantized dtypes CUDA since they re supported torch device device type == cuda dtype torch quint torch qint torch qint torch quint x storage_type_name = torch storage _dtype_to_storage_type_map dtype torch device device type == cuda storage_type = eval torch cuda + storage_type_name storage_type = eval torch + storage_type_name N = s = storage_type N s = l = N assertEqual s storage_type l i range N s i = i l i = i assertEqual s storage_type l l = s = assertEqual s storage_type l skipIfTorchDynamo Not suitable test TorchDynamo onlyNativeDeviceTypes slowTestIf IS_WINDOWS test_storage_use_count device = torch randn device=device prev_cf = torch _C _storage_Use_Count untyped_storage _cdata assertEqual prev_cf b = view assertEqual torch _C _storage_Use_Count b untyped_storage _cdata prev_cf + xfailIfTorchDynamo onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_tensor_storage_type device dtype = make_tensor dtype=dtype device=device low=- high= module = torch cuda torch device device type == cuda torch expected_storage_type = getattr module torch storage _dtype_to_storage_type_map dtype assertEqual storage_type expected_storage_type onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool torch bfloat torch uint torch uint torch uint slowTestIf IS_WINDOWS test_tensor_from_storage device dtype = make_tensor dtype=dtype device=device low=- high= a_s = storage b = torch tensor a_s device=device dtype=dtype reshape size assertEqual b c = torch tensor a_s untyped device=device dtype=dtype reshape size assertEqual c error_dtype all_types_and_complex_and torch half torch bool torch bfloat error_dtype == dtype continue assertRaisesRegex RuntimeError r Expected Storage type error_storage = error_dtype storage torch tensor error_storage device=device dtype=dtype onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_set_storage device dtype = make_tensor dtype=dtype device=device low=- high= a_s = storage b = torch tensor device=device dtype=dtype set_ a_s reshape size assertEqual b c = torch tensor device=device dtype=dtype set_ a_s untyped reshape size assertEqual c error_dtype all_types_and_complex_and torch half torch bool torch bfloat error_dtype == dtype continue assertRaisesRegex RuntimeError r Expected Storage type error_storage = error_dtype storage b = torch tensor device=device dtype=dtype set_ error_storage _check_storage_meta s s_check assertTrue isinstance s torch UntypedStorage torch TypedStorage isinstance s_check type s s s_check must both one UntypedStorage TypedStorage got f type s __name__ type s_check __name__ assertEqual s device type meta assertEqual s nbytes s_check nbytes assertEqual s size s_check size assertEqual s data_ptr assertRaisesRegex NotImplementedError r Not available s isinstance s torch TypedStorage assertEqual s dtype s_check dtype _check_storage_meta s untyped s_check untyped onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_typed_storage_meta device dtype args_list = args args_list s_check = torch TypedStorage args dtype=dtype device=device s = torch TypedStorage args dtype=dtype device= meta _check_storage_meta s s_check onlyNativeDeviceTypes slowTestIf IS_WINDOWS test_untyped_storage_meta device args_list = args args_list s_check = torch UntypedStorage args device=device s = torch UntypedStorage args device= meta _check_storage_meta s s_check onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_storage_meta_from_tensor device dtype t_check = make_tensor dtype=dtype device=device low=- high= t = t_check meta s_check = t_check storage s = t storage _check_storage_meta s s_check dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_storage_meta_errors device dtype s = torch TypedStorage device= meta dtype=dtype assertRaisesRegex NotImplementedError r Cannot copy out s cpu assertRaisesRegex RuntimeError r only available CPU s _share_fd_cpu_ assertRaisesRegex RuntimeError r only available CPU s _share_filename_cpu_ torch cuda is_available assertRaisesRegex NotImplementedError r Cannot copy out s cuda assertRaisesRegex RuntimeError r only available CUDA s _share_cuda_ assertRaisesRegex TypeError r cannot pin torch storage UntypedStorage only CPU memory can pinned s pin_memory assertRaisesRegex RuntimeError r only available CPU s share_memory_ assertRaisesRegex NotImplementedError r Not available s tolist tempfile NamedTemporaryFile f assertRaisesRegex NotImplementedError r Cannot copy out s _write_file f True True s element_size device cpu cuda torch cuda is_available cpu s = torch TypedStorage device=device dtype=dtype assertRaisesRegex NotImplementedError r Cannot copy out s copy_ s onlyCPU dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_storage_meta_ok device dtype s = torch TypedStorage device= meta dtype=dtype This OK changes meta storage size without allocating s resize_ onlyCUDA test_module_share_memory Test fix issue See https github com pytorch pytorch issues model = torch nn Linear _model_cuda = model cuda model share_memory dtypes torch float torch complex slowTestIf IS_WINDOWS test_deepcopy device dtype copy deepcopy = torch randn dtype=dtype device=device b = torch randn dtype=dtype device=device c = view q = storage b storage b c w = deepcopy q assertEqual w q atol= rtol= assertEqual w q atol= rtol= assertEqual w q atol= rtol= assertEqual w q atol= rtol= assertEqual w q atol= rtol= Check deepcopy preserves sharing w add_ i range numel assertEqual w i q i + assertEqual w c + w sub_ i range numel assertEqual w i q i - Check deepcopy preserves attributes foo = assertEqual deepcopy foo dtypes torch float torch complex slowTestIf IS_WINDOWS test_deepcopy_scalar device dtype copy deepcopy = torch tensor dtype=dtype device=device assertEqual size deepcopy size assertEqual deepcopy check_internal_mem_overlap inplace_op num_inputs dtype device expected_failure=False isinstance inplace_op str inplace_op = getattr torch Tensor inplace_op input = torch randn dtype=dtype device=device expand inputs = input + torch randn_like input i range num_inputs - expected_failure assertRaisesRegex RuntimeError single memory location inplace_op inputs assertRaises AssertionError assertRaisesRegex RuntimeError single memory location inplace_op inputs unary_check_input_output_mem_overlap data sz op expected_failure=False _test op output input output_exp = torch empty_like output op input out=output_exp assertEqual op input out=output output_exp msg=op __name__ output identical input _test op output=data sz input=data sz output input independent _test op output=data sz input=data sz sz output partially overlaps input expected_failure assertRaisesRegex RuntimeError unsupported operation _test op data sz data sz + assertRaises AssertionError assertRaisesRegex RuntimeError unsupported operation _test op data sz data sz + output transpose input length = int math sqrt sz input = data length view length length out = input t expected_failure assertRaisesRegex RuntimeError unsupported operation _test op out input assertRaises AssertionError assertRaisesRegex RuntimeError unsupported operation _test op out input ternary_check_input_output_mem_overlap op device expected_failure=False sz = data = torch randn sz device=device other = torch randn sz device=device other = torch randn sz device=device unary_check_input_output_mem_overlap data sz lambda input out op input other view input shape other view input shape out=out expected_failure=expected_failure unary_check_input_output_mem_overlap data sz lambda input out op other view input shape input other view input shape out=out expected_failure=expected_failure unary_check_input_output_mem_overlap data sz lambda input out op other view input shape other view input shape input out=out expected_failure=expected_failure _select_broadcastable_dims dims_full=None select full dimensionality dims_full None dims_full = ndims = random randint dims_full = random randint _ range ndims ndims = len dims_full select actual dimensions ops larger full ndims individual sizes may reduced smaller possibly reduced ndims sizes may reduced smaller_ndims = random randint ndims dims_small = dims_large = i range ndims - - - j = random randint j == no reduced singleton dimension ds = dims_full i dl = dims_full i j == larger may have reduced singleton dimension ds = dims_full i dl = len dims_small smaller_ndims dims_full i j == smaller may have reduced singleton dimension ds = dl = dims_full i dims_large = dl + dims_large len dims_small smaller_ndims dims_small = ds + dims_small dims_small dims_large dims_full collected tests ops used scalar_check Declarations cwrap correctness test_scalar_check device zero_d = torch randn device=device one_d = torch randn device=device remainder assertEqual torch remainder zero_d zero_d shape assertEqual torch remainder zero_d shape assertEqual torch remainder zero_d one_d shape assertEqual torch remainder one_d zero_d shape fmod assertEqual torch fmod zero_d zero_d shape assertEqual torch fmod zero_d shape assertEqual torch fmod zero_d one_d shape assertEqual torch fmod one_d zero_d shape exp cos cosh tan atan tanh erf erfc reciprocal assertEqual torch exp zero_d shape assertEqual torch cos zero_d shape assertEqual torch cosh zero_d shape assertEqual torch tan zero_d shape assertEqual torch atan zero_d shape assertEqual torch acosh zero_d shape assertEqual torch asinh zero_d shape assertEqual torch atanh zero_d shape assertEqual torch tanh zero_d shape assertEqual torch erf zero_d shape assertEqual torch erfc zero_d shape assertEqual torch reciprocal zero_d shape assertEqual torch exp one_d shape assertEqual torch cos one_d shape assertEqual torch cosh one_d shape assertEqual torch tan one_d shape assertEqual torch atan one_d shape assertEqual torch acosh one_d shape assertEqual torch asinh one_d shape assertEqual torch atanh one_d shape assertEqual torch tanh one_d shape assertEqual torch erf one_d shape assertEqual torch erfc one_d shape assertEqual torch reciprocal one_d shape clamp assertEqual torch clamp zero_d min= max= shape assertEqual torch clamp zero_d min= shape assertEqual torch clamp zero_d max= shape assertEqual torch clamp one_d min= max= shape assertEqual torch clamp one_d min= shape assertEqual torch clamp one_d max= shape cumsum cumprod cummax cummin assertEqual torch logcumsumexp zero_d shape assertEqual torch cumsum zero_d shape assertEqual torch cumprod zero_d shape assertEqual torch cummax zero_d shape assertEqual torch cummin zero_d shape sort topk assertEqual x shape x torch sort zero_d False assertEqual x shape x torch sort zero_d True assertEqual x shape x torch topk zero_d False assertEqual x shape x torch topk zero_d True max min assertEqual torch max zero_d zero_d shape assertEqual torch max one_d zero_d shape assertEqual torch max zero_d one_d shape assertEqual torch min zero_d zero_d shape assertEqual torch min one_d zero_d shape assertEqual torch min zero_d one_d shape zero_d_int = torch tensor device=device one_d_int = torch tensor device=device lshift rshift assertEqual zero_d_int zero_d_int shape assertEqual zero_d_int shape assertEqual one_d_int zero_d_int shape assertEqual zero_d_int one_d_int shape assertEqual one_d_int shape assertEqual zero_d_int zero_d_int shape assertEqual zero_d_int shape assertEqual one_d_int zero_d_int shape assertEqual zero_d_int one_d_int shape assertEqual one_d_int shape assertEqual zero_d_int &#124; zero_d_int shape assertEqual zero_d_int &#124; shape assertEqual one_d_int &#124; zero_d_int shape assertEqual zero_d_int &#124; one_d_int shape assertEqual one_d_int &#124; shape assertEqual zero_d_int zero_d_int shape assertEqual zero_d_int shape assertEqual one_d_int zero_d_int shape assertEqual zero_d_int one_d_int shape assertEqual one_d_int shape clone assertEqual zero_d clone shape zero_d_bool = torch tensor True device=device one_d_bool = torch tensor True device=device masked_select assertEqual torch masked_select zero_d_bool zero_d_bool shape assertEqual torch masked_select zero_d_bool one_d_bool shape assertEqual torch masked_select one_d_bool zero_d_bool shape torch tensor dtype=torch uint device=device torch tensor dtype=torch uint device=device mode assertEqual x shape x torch mode zero_d dim= keepdim=True assertEqual x shape x torch mode zero_d dim= keepdim=False assertEqual x shape x torch mode one_d dim= keepdim=True assertEqual x shape x torch mode one_d dim= keepdim=False max assertEqual x shape x torch max zero_d dim= keepdim=True assertEqual x shape x torch max zero_d dim= keepdim=False assertEqual x shape x torch max one_d dim= keepdim=True assertEqual x shape x torch max one_d dim= keepdim=False amax assertEqual torch amax zero_d dim= keepdim=True shape assertEqual torch amax zero_d dim= keepdim=False shape assertEqual torch amax one_d dim= keepdim=True shape assertEqual torch amax one_d dim= keepdim=False shape min assertEqual x shape x torch min zero_d dim= keepdim=True assertEqual x shape x torch min zero_d dim= keepdim=False assertEqual x shape x torch min one_d dim= keepdim=True assertEqual x shape x torch min one_d dim= keepdim=False amin assertEqual torch amin zero_d dim= keepdim=True shape assertEqual torch amin zero_d dim= keepdim=False shape assertEqual torch amin one_d dim= keepdim=True shape assertEqual torch amin one_d dim= keepdim=False shape set_ zero_d_clone = zero_d clone one_d_clone = one_d clone assertEqual zero_d_clone set_ one_d storage shape assertEqual zero_d_clone set_ one_d storage shape assertEqual one_d_clone set_ one_d storage shape assertEqual one_d_clone set_ one_d storage shape assertEqual zero_d clone set_ zero_d shape assertEqual one_d clone set_ zero_d shape assertEqual zero_d clone set_ one_d shape assertEqual one_d clone set_ one_d shape take assertEqual torch randn device=device take zero_d_int shape assertEqual torch randn device=device take one_d_int shape gather assertEqual torch gather zero_d torch zeros dtype=torch int device=device shape assertEqual torch gather zero_d torch zeros dtype=torch int device=device shape assertEqual torch gather one_d torch zeros dtype=torch int device=device shape assertEqual torch gather one_d torch zeros dtype=torch int device=device shape normal std must = zero_d_ge_ = torch rand device=device documentation says out shape matches shape mean assertEqual torch normal zero_d zero_d_ge_ shape assertEqual torch normal one_d zero_d_ge_ shape assertEqual torch normal zero_d_ge_ shape assertEqual torch normal zero_d shape assertEqual torch normal one_d shape TODO behavior differs CPU GPU see https github com pytorch pytorch issues assertEqual torch normal zero_d one_d shape assertEqual torch normal one_d shape convolutions Yes we testing nn functional here seems justified given its similar other tests w = torch randn device=device div_ requires_grad_ assertRaises RuntimeError lambda torch nn functional conv d zero_d w groups= assertRaises RuntimeError lambda torch nn functional conv d zero_d w groups= nll_loss -- verify input can t -dimensional assertRaises ValueError lambda torch nn functional nll_loss zero_d zero_d reduction= none assertRaises ValueError lambda torch nn functional nll_loss zero_d one_d reduction= none verify output -dimensional when reduction = none input target torch randn device=device torch tensor device=device torch randn device=device torch tensor device=device assertEqual torch nn functional nll_loss input target reduction= mean shape assertEqual torch nn functional nll_loss input target reduction= sum shape Test ` torch _check_tensor_all ` raises errors correct cases test_check_tensor_all device default_message = Expected cond True check_fn = torch _check_tensor_all expected_error = RuntimeError cond must tensor assertRaisesRegex TypeError cond must tensor check_fn True cond tensor must boolean assertRaisesRegex TypeError cond tensor must have dtype torch bool check_fn torch ones device=device test_sizes = size test_sizes t_all_true = torch ones size dtype=torch bool device=device t_all_false = torch zeros size dtype=torch bool device=device Should raise error check_fn t_all_true assertRaisesRegex expected_error default_message check_fn t_all_false t_all_true numel t_all_true_but_one = t_all_true clone Choose random element set false idx = random choice range dim_size dim_size size t_all_true_but_one idx = False assertRaisesRegex expected_error default_message check_fn t_all_true_but_one Test simple failure message message = message assertRaisesRegex expected_error message check_fn t_all_false lambda message Test message tensor message torch arange assertRaisesRegex expected_error re escape str message check_fn t_all_false message Test format string message message f test True True torch arange assertRaisesRegex expected_error re escape str message check_fn t_all_false message Test ` TORCH_CHECK_TENSOR_ALL ` raises errors propagate C++ Python test_check_tensor_internal device test_sizes = size test_sizes t_all_true = torch ones size dtype=torch bool device=device t_all_false = torch zeros size dtype=torch bool device=device Should raise error torch _test_check_tensor t_all_true assertRaisesRegex RuntimeError Test message TORCH_CHECK_TENSOR_ALL torch _test_check_tensor t_all_false t_all_true numel t_all_true_but_one = t_all_true clone Choose random element set false idx = random choice range dim_size dim_size size t_all_true_but_one idx = False assertRaisesRegex RuntimeError Test message TORCH_CHECK_TENSOR_ALL torch _test_check_tensor t_all_true_but_one Uses mismatched arange out size trigger warning skipIfTorchDynamo Not suitable test TorchDynamo unittest skipIf TEST_WITH_CROSSREF crossref perturbs line numbering test_cpp_warnings_have_python_context device Creates long string advance avoid too-long Python line s = +Triggered internally +RangeFactories + nvfuser deprecation warning filter warnings filterwarnings ignore torch jit fuser cuda UserWarning cpp_warn_fn out = torch empty torch arange out=out out Checks eager-mode cpp warning warnings catch_warnings record=True w cpp_warn_fn frameinfo = inspect getframeinfo inspect currentframe warning = w Checks cpp context warning message escaped_warning_message = str warning message encode unicode_escape assertTrue re search s repr escaped_warning_message re IGNORECASE None Checks Python features warning Note eager mode warning refers line function throws warning assertEqual frameinfo lineno - warning lineno assertEqual len w Checks jitted cpp warning warnings catch_warnings record=True w scripted_cpp_warn_fn = torch jit script cpp_warn_fn scripted_cpp_warn_fn warning = w Checks cpp context warning message escaped_warning_message = str warning message encode unicode_escape assertTrue re search s repr escaped_warning_message re IGNORECASE None Checks Python features warning Note jitted warning s lineno refers call jitted function which our test suite has layer indirection makes checking Python lineno fragile assertEqual len w Checks jitted Python warning warn_fn warnings warn Warning The jit mimics eager-mode Python warning case warnings catch_warnings record=True w scripted_warn_fn = torch jit script warn_fn scripted_warn_fn frameinfo = inspect getframeinfo inspect currentframe warning = w assertTrue re search Warning str warning message None Checks Python features warning assertEqual frameinfo lineno - warning lineno assertEqual len w FIXME move test_testing onlyCPU test_warn_always_caught device Check we can catch TORCH_WARN_ONCE warning twice since assertWarnsOnceRegex uses set_warn_always True which changes TORCH_WARN_ONCE TORCH_WARN = np arange flags writeable = False assertWarnsOnceRegex UserWarning non-writable torch from_numpy OK got once now try again assertWarnsOnceRegex UserWarning non-writable torch from_numpy Make sure emitting two warnings will pass assertWarnsOnceRegex context manager assertWarnsOnceRegex UserWarning non-writable torch from_numpy torch from_numpy onlyNativeDeviceTypes test_complex_half_experimental_warning device msg = ComplexHalf support experimental assertWarnsOnceRegex UserWarning msg t = torch randn dtype=torch chalf device=device assertWarnsOnceRegex UserWarning msg torch rand dtype=torch chalf device=device assertWarnsOnceRegex UserWarning msg torch empty dtype=torch chalf device=device assertWarnsOnceRegex UserWarning msg torch ones dtype=torch chalf device=device assertWarnsOnceRegex UserWarning msg torch zeros dtype=torch chalf device=device assertWarnsOnceRegex UserWarning msg torch randn_like t assertWarnsOnceRegex UserWarning msg torch rand_like t assertWarnsOnceRegex UserWarning msg torch empty_like t assertWarnsOnceRegex UserWarning msg torch ones_like t assertWarnsOnceRegex UserWarning msg torch zeros_like t assertWarnsOnceRegex UserWarning msg t + allocates new tensor result using empty t + onlyCUDA test_dtypetensor_warnings device msg = The torch cuda DtypeTensor constructors no longer recommended assertWarnsOnceRegex UserWarning msg torch cuda FloatTensor assertWarnsOnceRegex UserWarning msg torch cuda DoubleTensor test_set_default_tensor_type_warnings device msg = deprecated PyTorch please use torch set_default_dtype default_type = torch tensor type try assertWarnsOnceRegex UserWarning msg torch set_default_tensor_type torch FloatTensor torch cuda is_available assertWarnsOnceRegex UserWarning msg torch set_default_tensor_type torch cuda FloatTensor finally torch set_default_tensor_type default_type TODO test should test_nn py test_conv_transposed_backward_agnostic_to_memory_format device in_channels = out_channels = scale_factor = batch_size = length = conv = torch nn ConvTranspose d in_channels out_channels kernel_size=scale_factor stride=scale_factor device layer_norm = torch nn LayerNorm out_channels device input_ = torch randn batch_size in_channels length device contiguous input_ = conv input_ contiguous input_ = layer_norm input_ transpose contiguous contiguous input_ sum backward d conv = torch nn ConvTranspose d kernel_size= device input = torch randn batch_size length length length device=device out = conv input out backward torch ones_like out transpose - - TODO test should test_nn py onlyCUDA largeTensorTest GB test_conv_transposed_large device ConvTranspose d works large input tensors gh- in_channels = out_channels = kernel_size = conv = torch nn ConvTranspose d in_channels out_channels kernel_size=kernel_size stride= padding= output_padding= device x = torch rand device conv x test_is_set_to device t = torch empty device=device t = torch empty device=device t = torch tensor device=device set_ t t = t clone resize_ assertFalse t is_set_to t assertTrue t is_set_to t assertTrue t is_set_to t is_set_to should symmetric assertFalse t is_set_to t assertFalse torch tensor is_set_to torch tensor Tensors no storages should appear set each other t = torch tensor True True dtype=torch bool device=device t = torch tensor dtype=torch bool device=device set_ t assertTrue t is_set_to t test sizes must match t = torch empty device=device t = t view assertFalse t is_set_to t assertFalse t is_set_to t test legacy empty size behavior used respected i e all empty tensors logically collapsed size t = torch empty device=device t = t view assertFalse t is_set_to t assertFalse t is_set_to t See https github com pytorch pytorch issues skipIfMPS skipMeta parametrize fn dist atan pow lerp add sub mul div fmod remainder eq ge gt le lt max min ne addcdiv addcmul masked_scatter masked_select masked_fill map map copy test_broadcast fn device functions three tensor arguments fns_ _args = map fns_value_kwarg = addcdiv addcmul dims_small dims_large dims_full = _select_broadcastable_dims full d = torch randn dims_full device=device flatten float small = torch randn dims_small device=device float large = torch randn dims_large device=device float small_expanded = small expand dims_full large_expanded = large expand dims_full small = None small _expanded = None fn fns_ _args fn fns_value_kwarg create another smaller tensor dims_small _ _ = _select_broadcastable_dims dims_full small = torch randn dims_small device=device float small _expanded = small expand dims_full small is_cuda fn map map map map implemented CUDA tensors hasattr large_expanded fn run through tensor versions functions verify fully expanded inputs give same results expanded = large large_expanded small small_expanded small small _expanded tensorfn myfn t t fn == lerp myfn t fn == masked_select myfn t fn == masked_scatter myfn t full d fn == masked_fill myfn t fn fns_ _args myfn t t fn fns_value_kwarg myfn t t value= myfn t test various orders first second third large small small small large small small small large small large small first None break ignore last iter when small None method_expanded = getattr expanded first fn method = getattr first fn r = tensorfn method_expanded expanded second expanded third r = tensorfn method second third assertEqual r r now torch versions functions hasattr torch fn fntorch = getattr torch fn expanded = large large_expanded small small_expanded small small _expanded torchfn t t t fn == lerp fntorch t t fn == masked_select fntorch t t fn == masked_scatter fntorch t t full d fn == masked_fill fntorch t t fn fns_ _args fntorch t t t fn fns_value_kwarg fntorch t t t value= fntorch t t test various orders first second third large small small small large small small small large small large small first None break ignore last iter when small None r = torchfn expanded first expanded second expanded third r = torchfn first second third assertEqual r r now place functions in-place tensor broadcastable test only guaranteed work broadcasting other argument s hasattr large_expanded fn + _ need clone largeExpanded so we can reuse since functions in-place large_expanded_clone = large_expanded clone tensorfn_inplace t t t =None t _fn = getattr t fn + _ fn == lerp t _fn t fn == masked_scatter t _fn t full d fn == masked_fill t _fn t fn == map t _fn t lambda x y x + y fn == map t _fn t t lambda x y z x + y + z fn fns_ _args t _fn t t fn fns_value_kwarg t _fn t t value= t _fn t in-place pointwise operations don t actually work in-place tensor -strided numpy has same issue large_expanded stride large_expanded_clone stride r = tensorfn_inplace large_expanded small_expanded small _expanded r = tensorfn_inplace large_expanded_clone small small assertEqual r r broadcastable t t t =None try t expand_as t t None t expand_as t except RuntimeError False True _test_in_place_broadcastable t t t =None broadcastable t t t same_size = t numel == t numel t numel == t numel t None True same_size Functionalization converts inplace out-of-place which causes us error We should fix error probably bad inputs isn t hi-pri PT item TEST_WITH_TORCHINDUCTOR assertRaises RuntimeError lambda tensorfn_inplace t t t tensorfn_inplace t t t fn fns_ _args fn fns_value_kwarg _test_in_place_broadcastable small large_expanded _test_in_place_broadcastable small large _test_in_place_broadcastable small small_expanded large_expanded _test_in_place_broadcastable small small large onlyCPU skipIfTorchInductor https github com pytorch pytorch issues dtypes get_all_qint_dtypes test_nondeterministic_resize_quantized device dtype = torch tensor - dtype=torch float device=device b = torch quantize_per_tensor dtype check_nondeterministic_alert lambda b resize_ quantized_resize_cpu_ skipXLA skipIfTorchInductor https github com pytorch pytorch issues dtypes all_types_and_complex_and torch half torch bool torch bfloat torch uint torch uint torch uint test_deterministic_resize device dtype test_cases = size stride resize_size None None None None None size stride resize_size test_cases stride None = torch zeros size dtype=dtype device=device = torch empty_strided size stride dtype=dtype device=device fill_ old_storage = untyped_storage clone DeterministicGuard True fill_uninitialized_memory=True resize_ resize_size new_storage = untyped_storage If storage size increased check new section filled NaN MAX_INT Otherwise check storages equal old_tensor = torch tensor old_storage dtype=dtype old_numel = old_tensor numel new_tensor = torch tensor new_storage dtype=dtype new_numel = new_tensor numel new_numel old_numel assertEqual new_tensor old_numel old_tensor fill_section = new_tensor old_numel dtype is_floating_point dtype is_complex assertTrue fill_section isnan all dtype == torch bool max_val = True max_val = torch iinfo dtype max assertTrue fill_section eq max_val all assertEqual old_tensor new_tensor When deterministic algorithms enabled ` torch empty ` should fill floating point tensors NaN integer tensors MAX_INT skipXLA skipIfTorchInductor https github com pytorch pytorch issues dtypes all_types_and_complex_and torch half torch bool torch bfloat torch uint torch uint torch uint torch complex test_deterministic_empty device dtype gen_fns = lambda torch empty device=device dtype=dtype lambda torch empty out=torch zeros device=device dtype=dtype lambda torch empty_like torch zeros device=device dtype=dtype lambda torch empty_like torch zeros device=device dtype=dtype memory_format=torch contiguous_format lambda torch empty_strided device=device dtype=dtype lambda torch empty_permuted device=device dtype=dtype gen_fn gen_fns DeterministicGuard True fill_uninitialized_memory=True res = gen_fn dtype is_floating_point dtype is_complex assertTrue res isnan all dtype == torch bool max_val = True max_val = torch iinfo dtype max assertTrue res eq max_val all FIXME update OpInfos support nondeterministic samples port these tests architecture skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_AvgPool d device module = torch nn AvgPool d input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True avg_pool d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_AdaptiveAvgPool d device module = torch nn AdaptiveAvgPool d input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True adaptive_avg_pool d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_AdaptiveAvgPool d device module = torch nn AdaptiveAvgPool d input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True adaptive_avg_pool d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_MaxPool d device module = torch nn MaxPool d input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True max_pool d_with_indices_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_AdaptiveMaxPool d device module = torch nn AdaptiveMaxPool d input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True adaptive_max_pool d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_FractionalMaxPool d device module = torch nn FractionalMaxPool d output_ratio= input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True fractional_max_pool d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_FractionalMaxPool d device module = torch nn FractionalMaxPool d output_ratio= input = torch randn requires_grad=True device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True fractional_max_pool d_backward_cuda torch device device type == cuda dtypes floating_types_and torch half onlyNativeDeviceTypes test_nondeterministic_alert_MaxUnpool d device dtype dtype == torch half torch device device type == cpu skipTest float implemented CPU module = torch nn MaxUnpool d input = torch randn dtype=dtype device=device indices = torch zeros_like input dtype=torch long device=device check_nondeterministic_alert lambda module input indices max_unpooling d_forward_out dtypes floating_types_and torch half onlyNativeDeviceTypes test_nondeterministic_alert_MaxUnpool d device dtype dtype == torch half torch device device type == cpu skipTest float implemented CPU module = torch nn MaxUnpool d input = torch randn dtype=dtype device=device indices = torch zeros_like input dtype=torch long device=device check_nondeterministic_alert lambda module input indices max_unpooling d_forward_out dtypes floating_types_and torch half onlyNativeDeviceTypes test_nondeterministic_alert_MaxUnpool d device dtype dtype == torch half torch device device type == cpu skipTest float implemented CPU module = torch nn MaxUnpool d input = torch randn dtype=dtype device=device indices = torch zeros_like input dtype=torch long device=device check_nondeterministic_alert lambda module input indices max_unpooling d_forward_out skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_interpolate_linear device input = torch randn device=device requires_grad=True res = torch nn functional interpolate input size= mode= linear align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad upsample_linear d_backward_out_cuda torch device device type == cuda skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_interpolate_bilinear device input = torch randn device=device requires_grad=True res = torch nn functional interpolate input size= mode= bilinear align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad upsample_bilinear d_backward_out_cuda torch device device type == cuda test_no_nondeterministic_alert_interpolate_bilinear device input = torch randn device=device requires_grad=True fn res = torch nn functional interpolate input size= mode= bilinear align_corners=False grad = torch ones_like res res backward grad check_nondeterministic_alert fn upsample_bilinear d_backward_out_cuda False test_no_nondeterministic_alert_interpolate_trilinear device input = torch randn device=device requires_grad=True fn res = torch nn functional interpolate input size= mode= trilinear align_corners=False grad = torch ones_like res res backward grad check_nondeterministic_alert fn upsample_trilinear d_backward_out_cuda False skipIfTorchInductor aot-autograd issue test_deterministic_replication_pad d device test_cases = size padding torch device device type = xla test_cases += - - - - - size padding test_cases input = torch randn size device=device requires_grad=True grad = None DeterministicGuard True res = torch nn functional pad input padding mode= replicate res backward torch ones_like res grad None grad = input grad assertEqual grad input grad atol= rtol= input grad = None skipIfTorchInductor https github com pytorch pytorch issues test_deterministic_interpolate_bilinear device input = torch randn device=device requires_grad=True grad = None DeterministicGuard True _ range res = torch nn functional interpolate input size= mode= bilinear align_corners=False res backward torch ones_like res grad None grad = input grad assertEqual grad input grad atol= rtol= input grad = None skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_interpolate_bicubic device input = torch randn device=device requires_grad=True res = torch nn functional interpolate input size= mode= bicubic align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad upsample_bicubic d_backward_out_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_interpolate_trilinear device input = torch randn device=device requires_grad=True res = torch nn functional interpolate input size= mode= trilinear align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad upsample_trilinear d_backward_out_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_ReflectionPad d device module = torch nn ReflectionPad d input = torch randn device=device requires_grad=True res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True reflection_pad d_backward_out_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_ReflectionPad d device module = torch nn ReflectionPad d input = torch randn device=device requires_grad=True res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True reflection_pad d_backward_out_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_ReplicationPad d device module = torch nn ReplicationPad d input = torch randn device=device requires_grad=True res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True replication_pad d_backward_cuda torch device device type == cuda skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_ReplicationPad d device module = torch nn ReplicationPad d input = torch randn device=device requires_grad=True res = module input grad = torch ones_like res Nondeterministic alert should only raised forward call nondeterministic check_nondeterministic_alert lambda res backward grad retain_graph=True replication_pad d_backward_cuda torch device device type == cuda DeterministicGuard True res = module input grad = torch ones_like res If forward call deterministic nondeterministic alert should raised check_nondeterministic_alert lambda res backward grad retain_graph=True replication_pad d_backward_cuda False skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_ReplicationPad d device module = torch nn ReplicationPad d input = torch randn device=device requires_grad=True res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True replication_pad d_backward_cuda torch device device type == cuda skipIfTorchDynamo Warning raised test_nondeterministic_alert_NLLLoss device module = torch nn NLLLoss input = torch randn device=device target = torch rand device=device mul floor long check_nondeterministic_alert lambda module input target nll_loss d_forward_out_cuda_template torch device device type == cuda skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_CTCLoss device module = torch nn CTCLoss input = torch randn device=device requires_grad=True target = torch randint device=device input_lengths = target_lengths = res = module input target input_lengths target_lengths grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True ctc_loss_backward_gpu torch device device type == cuda skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_EmbeddingBag_max device module = torch nn EmbeddingBag None False max _weight=torch randn device=device requires_grad=True input = torch randint device=device res = module input grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True embedding_bag_backward_cuda_max torch device device type == cuda skipIfRocmArch MI _ARCH skipIfTorchInductor https github com pytorch pytorch issues onlyCUDA test_deterministic_cumsum device test_cases = size dim size dim test_cases input = torch rand size device=device DeterministicGuard True res = input cumsum dim _ range res = input cumsum dim assertEqual res res atol= rtol= res_cpu = input cpu cumsum dim assertEqual res res_cpu atol= e- rtol= e- test double complex has fewer threads than CTAs s problem large GPUS H sms test very tailored will provide signal smaller GPUs num_sms = elems_per_cta = N = num_sms elems_per_cta input = torch rand N dtype=torch complex device=device DeterministicGuard True res = input cumsum dim _ range res = input cumsum dim assertEqual res res atol= rtol= res_cpu = input cpu cumsum dim assertEqual res res_cpu atol= e- rtol= e- onlyCUDA largeTensorTest GB test_cumsum_ bit_indexing device b = torch ones dtype=torch float device= cuda b = d = b cumsum dim=- chunk = b shape - i range b shape chunk end = min i + chunk b shape b i end cumsum_ dim=- cheat bit avoid OOM assertEqual b d atol= e- rtol= e- assertEqual b - d - atol= e- rtol= e- expectedFailureMeta expected non-determinitic error raised onlyNativeDeviceTypes test_nondeterministic_alert_put device = torch randn device=device indices = torch tensor device=device values = torch tensor device=device op_call torch Tensor put torch Tensor put_ check_nondeterministic_alert lambda op_call indices values accumulate=False put_ warn_only=False correctly raises RuntimeError put_ does have deterministic implementation warn_only=True logs warning FallbackKernel torch ops aten put_ default instead UserWarning W Context cpp lineno Warning put_ does have deterministic implementation skipIfTorchInductor warning logged FallbackKernel torch ops aten put_ default when warn_only=True test_nondeterministic_alert_put_accumulate device = torch randn device=device indices = torch tensor device=device values = torch tensor device=device op_call torch Tensor put torch Tensor put_ check_nondeterministic_alert lambda op_call indices values accumulate=True put_ torch device device type == cuda dtypes torch float dtypesIfCUDA torch float torch int skipIfMPS test_nondeterministic_alert_histc device dtype = torch tensor device=device dtype=dtype op_call torch histc torch Tensor histc check_nondeterministic_alert lambda op_call min= max= _histc_cuda floating point input torch device device type == cuda dtype is_floating_point skipIfMPS test_nondeterministic_alert_bincount device = torch tensor device=device dtype=torch long weights = torch tensor device=device op_call torch bincount torch Tensor bincount Error should only raised when device CUDA weights given check_nondeterministic_alert lambda op_call weights _bincount_cuda torch device device type == cuda check_nondeterministic_alert lambda op_call _bincount_cuda False skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_grid_sample_ d device input = torch empty device=device requires_grad=True grid = torch empty device=device res = torch nn functional grid_sample input grid align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True grid_sampler_ d_backward_cuda torch device device type == cuda skipIfMPS skipIfTorchInductor https github com pytorch pytorch issues test_nondeterministic_alert_grid_sample_ d device input = torch empty device=device requires_grad=True grid = torch empty device=device res = torch nn functional grid_sample input grid align_corners=False grad = torch ones_like res check_nondeterministic_alert lambda res backward grad retain_graph=True grid_sampler_ d_backward_cuda torch device device type == cuda test_invalid_shapes_grid_sampler device make_arg = partial make_tensor device=device dtype=torch float requires_grad=True inputs = input grid d d interpolation_mode = padding_mode = align_corners = True err = expected grid input have same batch size input grid inputs input = make_arg input grid = make_arg grid low=- high= Wrapper d d cuDNN functions listed below assertRaisesRegex RuntimeError err torch grid_sampler input grid interpolation_mode padding_mode align_corners Expects d input assertRaisesRegex RuntimeError err torch grid_sampler_ d input grid interpolation_mode padding_mode align_corners Expects d input assertRaisesRegex RuntimeError err torch grid_sampler_ d input grid interpolation_mode padding_mode align_corners Expects d input assertRaisesRegex RuntimeError err torch _grid_sampler_ d_cpu_fallback input grid interpolation_mode padding_mode align_corners Expects d input CUDA Doesn t work CPU ROCm device = cpu TEST_CUDNN TEST_WITH_ROCM assertRaisesRegex RuntimeError err torch cudnn_grid_sampler input grid test_dist device run_test x y p inf -inf dist_xy = torch dist x y p dist_xy_norm = torch norm x - y p assertEqual dist_xy dist_xy_norm run_test torch randn device=device torch randn device=device x = torch zeros device=device y = torch zeros device=device y = run_test x y Ensures median throws nondeterministic alerts correct cases dtypes torch double test_nondeterministic_alert_median device dtype test_func call_type S = = torch randn S device=device call_type == function torch median call_type == function indices torch median call_type == method median call_type == method indices median call_type == out indices result = torch empty_like indices = torch empty dtype=torch long device=device torch median out= result indices fail f call_type valid call type test_func_expect_error call_type should_error check_nondeterministic_alert lambda test_func call_type median CUDA indices output should_error is_cuda = torch device device type == cuda test_func_expect_error function False test_func_expect_error function indices is_cuda test_func_expect_error method False test_func_expect_error method indices is_cuda test_func_expect_error out indices is_cuda FIXME move test_scatter_gather_ops _test_gather_backward_one_dim device deterministic bool = False - None DeterministicGuard deterministic m = random randint elems = random randint m m dim = src = torch randn m device=device requires_grad=True idx = torch randint m elems device=device res = torch gather src dim idx weight = torch rand_like res device=device res backward weight assert src grad None grad = src grad detach clone torch device device type == cuda _ range src grad data zero_ res = torch gather src dim idx res backward weight assertEqual src grad grad atol= rtol= expected = torch zeros_like src device=device i range elems expected idx i += weight i assertEqual grad expected atol= rtol= FIXME move test_scatter_gather_ops onlyNativeDeviceTypes test_gather_backward_deterministic_path device - None _test_gather_backward_one_dim device True FIXME move test_scatter_gather_ops onlyCPU test_gather_backward_one_dim device - None _test_gather_backward_one_dim device False FIXME move test_scatter_gather_ops onlyNativeDeviceTypes test_scatter_add_one_dim_deterministic device - None DeterministicGuard True m = random randint elems = random randint m m dim = src = torch randn elems device=device idx = torch randint m elems device=device x = torch zeros m device=device res = x scatter_add dim idx src Checking scatter_add deterministic _ range res_next = x scatter_add dim idx src assertEqual res res_next atol= rtol= res = res_next expected = torch zeros m device=device i range elems expected idx i += src i assertEqual res expected atol= e- rtol= e- FIXME move test_scatter_gather_ops onlyNativeDeviceTypes test_scatter_zero_size_index device - None null_index = torch zeros dtype=torch int null_arr = torch zeros original = torch arange dtype=torch float result = original scatter null_index null_arr assertEqual result original atol= rtol= onlyCUDA skipIfTorchInductor FIXME test_sync_warning device _sync_raises_helper f level CudaSyncGuard level level == assertWarnsRegex UserWarning called synchronizing f level == assertRaisesRegex RuntimeError called synchronizing f _no_sync_helper f level CudaSyncGuard level f _ind_put_fn x ind val x ind = val x _ind_get_fn x ind x ind _cond_fn x x taking boolean value tensor synchronizes x x prepare inputs subsequent ops size = x = torch rand size device=device y = torch rand device=device ind = torch randint size device=device ind_cpu = ind cpu repeats = torch full device=device mask = torch randint size device=device dtype=bool mask_cpu = mask cpu expect_no_sync = lambda _ind_put_fn x mask lambda _ind_put_fn x mask_cpu y lambda _ind_put_fn x ind y lambda _ind_get_fn x mask_cpu lambda _ind_get_fn x ind lambda torch nn functional one_hot ind num_classes=size lambda torch randperm device=device lambda torch repeat_interleave x output_size= size lambda torch repeat_interleave x repeats output_size= size lambda torch any y expect_sync = lambda _ind_put_fn x mask y lambda _ind_put_fn x ind_cpu y lambda _ind_get_fn x mask lambda _ind_get_fn x ind_cpu lambda x nonzero lambda _cond_fn y lambda torch nn functional one_hot ind lambda torch repeat_interleave x repeats f level product expect_no_sync _no_sync_helper f level f level product expect_sync _sync_raises_helper f level dtypes floating_types_and torch half torch bfloat skipIfMPS test_log_normal device dtype = torch tensor dtype=dtype device=device log_normal_ assertEqual dtype dtype assertEqual size torch Size dtypes all_types_and torch half torch bfloat skipIfMPS test_geometric device dtype = torch tensor dtype=dtype device=device geometric_ assertEqual dtype dtype assertEqual size torch Size skipIfMPS test_repeat_interleave device y = torch tensor device=device exercise single argument function signature temp = y repeat_interleave assertEqual torch Size temp size dtype torch int torch long lengths = torch tensor dtype=dtype device=device output_size = torch sum lengths = torch repeat_interleave y lengths dim= assertEqual dtype y dtype assertEqual size torch Size a_with_output = torch repeat_interleave y lengths dim= output_size=output_size assertEqual a_with_output dtype y dtype assertEqual a_with_output size torch Size dtypes floating_types dtypesIfCPU floating_types_and torch bfloat torch half dtypesIfCUDA floating_types_and torch half test_bernoulli_p device dtype trivial_p x = torch tensor trivial_p dtype=dtype device=device assertEqual x bernoulli tolist trivial_p isBinary t torch ne t mul_ torch ne t sum item == p = torch rand dtype=dtype device=device assertTrue isBinary p bernoulli p = torch rand dtype=dtype device=device expand assertTrue isBinary p bernoulli p = torch rand dtype=dtype device=device torch bernoulli torch rand_like p out=p assertTrue isBinary p RngUniform implemented Integral type XLA test dtypes floating_types dtypesIfCPU all_types_and torch bool torch half dtypesIfCUDA all_types_and torch bool torch half test_bernoulli_self device dtype isBinary t torch ne t mul_ torch ne t sum item == t = torch empty dtype=dtype device=device t fill_ t bernoulli_ assertTrue isBinary t p_dtype floating_types_and torch half device startswith cuda p = torch rand dtype=p_dtype device=device expand t fill_ t bernoulli_ p assertTrue isBinary t t fill_ torch bernoulli torch rand_like t dtype=p_dtype out=t assertTrue isBinary t t fill_ t bernoulli_ torch rand_like t dtype=p_dtype assertTrue isBinary t slowTest dtypes floating_types_and torch half dtypesIfCUDA floating_types_and torch half test_bernoulli_edge_cases device dtype Need draw lot samples cover every random floating point number = torch zeros dtype=dtype device=device probability drawing num_ones = torch bernoulli == sum assertEqual num_ones b = torch ones dtype=dtype device=device probability drawing num_zeros = torch bernoulli b == sum assertEqual num_zeros dtypes floating_types_and torch half torch bfloat skipIfMPS test_exponential device dtype = torch tensor dtype=dtype device=device exponential_ assertEqual dtype dtype assertEqual size torch Size Tests extremal behavior t = torch empty device=device dtype=dtype exponential_ float inf assertTrue t item == Tests negative lambda fails assertRaises RuntimeError torch empty device=device dtype=dtype exponential_ - onlyCUDA dtypes torch half torch float test_exponential_no_zero device dtype naively exponential can generated probability ^- so we need more samples check s generated instead doing one don t test CPU would long test x = torch empty device=device dtype=dtype exponential_ assertTrue x min _generate_correlation_tensors device dtype yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device yield make_tensor dtype=dtype device=device noncontiguous=True dtype = torch int yield torch tensor - nan inf dtype=dtype device=device tf _on_and_off onlyNativeDeviceTypes dtypes torch int torch float torch cfloat test_corrcoef device dtype x _generate_correlation_tensors device dtype res = torch corrcoef x ref = np corrcoef x cpu numpy assertEqual res ref atol= e- rtol= e- exact_dtype=False skipRocmIfTorchInductor dtypes torch int torch float torch cfloat test_cov device dtype check t correction= fweights=None aweights=None res = torch cov t correction=correction fweights=fweights aweights=aweights t = t cpu numpy fweights = fweights cpu numpy fweights None None aweights = aweights cpu numpy aweights None None ref = np cov t ddof=correction fweights=fweights aweights=aweights assertEqual res ref atol= e- rtol= e- exact_dtype=False x _generate_correlation_tensors device dtype check x num_observations = x numel x ndim x size num_observations fweights = torch randint num_observations device=device aweights = make_tensor num_observations dtype=torch float device=device low= correction fw aw product None fweights None aweights check x correction fw aw skipIfNoSciPy dtypes floating_types_and torch half torch bfloat test_uniform_kstest device dtype scipy stats size = from_ - to_ - to_ from_ t = torch empty size dtype=dtype device=device uniform_ from_ to_ res = stats kstest t cpu torch double uniform args= from_ to_ - from_ assertTrue res statistic skipIfNoSciPy dtypes floating_types_and torch half dtypesIfCUDA floating_types_and torch half torch bfloat test_normal_kstest device dtype scipy stats size = mean - std t = torch empty size dtype=dtype device=device normal_ mean=mean std=std res = stats kstest t cpu torch double norm args= mean std assertTrue res statistic skipIfMPS skipIfNoSciPy skipRocmIfTorchInductor dtypes floating_types_and torch half torch bfloat test_lognormal_kstest device dtype scipy stats size = mean - std t = torch empty size dtype=dtype device=device log_normal_ mean=mean std=std res = stats kstest t cpu torch double lognorm args= std math exp mean dtype == torch half assertTrue res statistic assertTrue res statistic skipIfMPS skipIfNoSciPy dtypes floating_types_and torch half torch bfloat test_exponential_kstest device dtype scipy stats size = lambd t = torch empty size dtype=dtype device=device exponential_ lambd=lambd res = stats kstest t cpu torch double expon args= lambd assertTrue res statistic skipIfMPS skipIfNoSciPy skipRocmIfTorchInductor dtypes floating_types_and torch half torch bfloat test_cauchy_kstest device dtype scipy stats size = median - sigma t = torch empty size dtype=dtype device=device cauchy_ median=median sigma=sigma res = stats kstest t cpu torch double cauchy args= median sigma assertTrue res statistic slowTest onlyCUDA dtypes torch bfloat torch float test_cauchy_no_inf device dtype torch float will have ` inf ` because its smaller range _ range x = torch empty dtype=dtype device=device x cauchy_ assertFalse x isinf sum dtypes floating_types_and torch half torch bfloat test_cauchy device dtype = torch tensor dtype=dtype device=device cauchy_ assertEqual dtype dtype assertEqual size torch Size Tests extremal behavior t = torch empty device=device dtype=dtype cauchy_ float inf assertTrue t item == float inf Tests non-positive rate fails assertRaises RuntimeError torch empty device=device dtype=dtype cauchy_ skipIfMPS skipIfNoSciPy skipRocmIfTorchInductor dtypes all_types_and torch half torch bfloat test_geometric_kstest device dtype scipy stats size = p t = torch empty size dtype=dtype device=device geometric_ p=p actual = np histogram t cpu torch double np arange expected = stats geom p pmf np arange size res = stats chisquare actual expected assertEqual res pvalue atol= rtol= FIXME find test suite pdist cdist test_pairwise_distance_empty device shape = x = torch randn shape device=device y = torch randn shape device=device assertEqual torch zeros device=device torch pairwise_distance x y assertEqual torch zeros device=device torch pairwise_distance x y keepdim=True shape = x = torch randn shape device=device y = torch randn shape device=device assertEqual torch zeros device=device torch pairwise_distance x y assertEqual torch zeros device=device torch pairwise_distance x y keepdim=True test_pdist_empty device shape = x = torch randn shape device=device assertEqual torch empty device=device torch pdist x shape = x = torch randn shape device=device assertEqual torch empty device=device torch pdist x shape = x = torch randn shape device=device assertEqual torch zeros device=device torch pdist x test_cdist_empty device x = torch randn device=device y = torch randn device=device assertEqual torch empty device=device torch cdist x y x = torch randn device=device y = torch randn device=device assertEqual torch empty device=device torch cdist x y x = torch randn device=device y = torch randn device=device assertEqual torch zeros device=device torch cdist x y x = torch randn device=device y = torch randn device=device assertEqual torch empty device=device torch cdist x y _brute_cdist x y p= r = x shape - r = y shape - r == r == torch empty r r device=x device torch norm x None - y None p=p dim=- skipIfMPS test_cdist_norm device r m r p float inf x = torch randn r m device=device y = torch randn r m device=device p == cm use_mm_for_euclid_dist donot_use_mm_for_euclid_dist actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertEqual expected actual rtol= atol= actual = torch cdist x y p=p expected = _brute_cdist x y p=p assertEqual expected actual skipIfMPS test_cdist_norm_batch device r m r p float inf x = torch randn r m device=device y = torch randn r m device=device p == cm use_mm_for_euclid_dist donot_use_mm_for_euclid_dist actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertEqual expected actual rtol= atol= actual = torch cdist x y p=p expected = _brute_cdist x y p=p assertEqual expected actual onlyCUDA test_cdist_cuda_backward device l l p float inf x = torch randn l device=device requires_grad=True x = x clone detach_ requires_grad_ y = torch randn l device=device requires_grad=True y = y clone detach_ requires_grad_ p == cm use_mm_for_euclid_dist donot_use_mm_for_euclid_dist z = torch cdist x y p= compute_mode=cm mean z = _brute_cdist x y p= mean z backward z backward assertEqual x grad x grad rtol= atol= assertEqual y grad y grad rtol= atol= z = torch cdist x y p=p mean z = _brute_cdist x y p=p mean assertEqual x grad x grad rtol= atol= assertEqual y grad y grad rtol= atol= skipIfRocmArch MI _ARCH tf _on_and_off reduced_f _on_and_off test_cdist_large device cm use_mm_for_euclid_dist_if_necessary use_mm_for_euclid_dist donot_use_mm_for_euclid_dist x = torch randn device=device y = torch randn device=device actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertEqual expected actual slowTest tf _on_and_off reduced_f _on_and_off test_cdist_large_batch device cm use_mm_for_euclid_dist_if_necessary use_mm_for_euclid_dist donot_use_mm_for_euclid_dist x = torch randn device=device y = torch randn device=device actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertEqual expected actual tf _on_and_off reduced_f _on_and_off test_cdist_non_contiguous device cm use_mm_for_euclid_dist donot_use_mm_for_euclid_dist x = torch randn device=device mT y = torch randn device=device mT actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertFalse x is_contiguous assertFalse y is_contiguous assertEqual expected actual x = torch randn device=device y = torch randn device=device t actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertTrue x is_contiguous assertFalse y is_contiguous assertEqual expected actual x = torch randn device=device t y = torch randn device=device actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertFalse x is_contiguous assertTrue y is_contiguous assertEqual expected actual tf _on_and_off reduced_f _on_and_off test_cdist_non_contiguous_batch device cm use_mm_for_euclid_dist donot_use_mm_for_euclid_dist x = torch randn device=device mT y = torch randn device=device mT actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertFalse x is_contiguous assertFalse y is_contiguous assertEqual expected actual x = torch randn device=device y = torch randn device=device mT actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertTrue x is_contiguous assertFalse y is_contiguous assertEqual expected actual x = torch randn device=device mT y = torch randn device=device actual = torch cdist x y p= compute_mode=cm expected = _brute_cdist x y p= assertFalse x is_contiguous assertTrue y is_contiguous assertEqual expected actual Maybe merge into OpInfo test_cdist_euclidean_large device _test_euclidean_large_cdist sizex sizey=None sizey None sizey = sizex x = torch randn sizex device=device dtype=torch float y = torch randn sizey device=device dtype=torch float eps = e- avoid extremum x = x - x - y eps float eps x requires_grad = True y requires_grad = True dist = torch cdist x y p= Do backward pass check valid large matrices loss = dist sum loss backward _test_euclidean_large_cdist Ensure cdist backward p does produce NaNs skipIfMPS test_cdist_grad_p_lt_ _no_nan device p x = torch randn device=device y = x detach clone + torch tensor device=device x requires_grad = True y requires_grad = True result = torch cdist x y p=p result backward torch ones_like result assertFalse torch isnan x grad any assertFalse torch isnan y grad any test_cdist_same_inputs device Test detect issues cdist gradient calculation When distances sizex = p float inf x = torch randn sizex device=device dtype=torch float dist_grad = torch randn device=device dtype=torch float y = x clone x requires_grad = True d = torch cdist x y p=p d backward dist_grad Check backward pass does contain invalid values such nan inf assert torch isfinite x grad all skipIfMPS test_cumsum device x = torch rand device=device res = torch cumsum x res = torch tensor device torch cumsum x out=res assertEqual res res x cumsum_ assertEqual res x = torch tensor True False True False False False True True True device=device b = byte aRes = torch cumsum bRes = torch cumsum b assertEqual aRes bRes assertEqual aRes torch tensor aRes = torch cumsum bRes = torch cumsum b assertEqual aRes bRes assertEqual aRes torch tensor Check cumulative sum over zero length dimension doesn t crash backprop Also check cumsum over other dimensions tensor zero-length dimensiuon also works Also include basic suite similar tests other bases cases shapes = shape shapes dim range len shape raw_tensor = torch zeros shape requires_grad=True integrated = raw_tensor cumsum dim=dim Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape Check scalar example raw_tensor = torch tensor requires_grad=True integrated = raw_tensor cumsum dim=- assertEqual raw_tensor integrated Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape skipIfMPS test_cumprod device x = torch rand device=device res = torch cumprod x res = torch tensor device TEST_WITH_TORCHINDUCTOR torch cumprod x out=res assertEqual res res x cumprod_ assertEqual res x = torch tensor True False True False False False True True True dtype=torch bool device=device b = byte aRes = torch cumprod bRes = torch cumprod b assertEqual aRes bRes assertEqual aRes torch tensor aRes = torch cumprod bRes = torch cumprod b assertEqual aRes bRes assertEqual aRes torch tensor Check cumulative prod over zero length dimension doesn t crash backprop Also check cumprod over other dimensions tensor zero-length dimensiuon also works Also include basic suite similar tests other bases cases shapes = shape shapes dim range len shape raw_tensor = torch zeros shape requires_grad=True integrated = raw_tensor cumprod dim=dim Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape Check scalar example raw_tensor = torch tensor requires_grad=True integrated = raw_tensor cumprod dim=- assertEqual raw_tensor integrated Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape skipIfMPS test_cummax_cummin device test_ops op string_of_function_name expected_output expected_output x = torch rand device=device out = op x res = torch empty device=device indices = torch empty dtype=torch int device=device op x out= res indices assertEqual out res assertEqual out indices = torch tensor True False True False False False True True True dtype=torch bool device=device b = byte aRes = op bRes = op b assertEqual aRes bRes bool assertEqual aRes expected_output bool test inf nan input x = torch tensor inf -inf nan xRes = op x assertEqual xRes expected_output op shouldn t support values indices dtype device type layout different input tensor t = torch randn values = torch empty dtype=torch int indices = torch empty dtype=torch int assertRaisesRegex RuntimeError expected scalar_type Float found Short op t out= values indices Range-check -d tensors x = torch rand dim = assertRaisesRegex IndexError Expected reduction dim - scalar got op x dim Check op over zero length dimension doesn t crash backprop Also check op over other dimensions tensor zero-length dimension also works Also include basic suite similar tests other bases cases shapes = shape shapes dim range len shape raw_tensor = torch zeros shape requires_grad=True integrated = getattr raw_tensor string_of_function_name dim=dim Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape Check scalar example raw_tensor = torch tensor requires_grad=True integrated = getattr raw_tensor string_of_function_name dim=- Check backward does crash integrated sum backward Check output maintained correct shape assertEqual raw_tensor shape raw_tensor grad shape expected_out = torch tensor inf inf inf inf nan nan test_ops torch cummax cummax torch tensor expected_out expected_out = torch tensor -inf -inf nan nan test_ops torch cummin cummin torch tensor expected_out skipIfMPS test_logcumsumexp device logcumsumexp axis torch cumsum exp axis=axis log_ axis = - = torch randn device=device actual = logcumsumexp axis expected = logcumsumexp axis assertEqual dtype actual dtype assertEqual expected shape actual shape assertEqual expected actual check -inf nan handling x = torch tensor -float inf -float inf float inf float inf float nan device=device x d = x unsqueeze expand - inp x x d actual = inp logcumsumexp axis expected = logcumsumexp inp axis assertEqual expected actual Check out actually inplace b = torch randn device=device inplace_out = torch zeros device=device expected = logcumsumexp b axis torch logcumsumexp b axis=axis out=inplace_out assertEqual inplace_out expected Check input inplace_output type mismatch b = torch randn device=device dtype=torch float inplace_out = torch zeros device=device dtype=torch float assertRaisesRegex RuntimeError expected scalar_type Double found Float torch logcumsumexp b axis out=inplace_out _test_diff_numpy t dims=None Helper test_diff compare NumPy reference implementation to_np t t dtype == torch bfloat t dtype=torch float device= cpu numpy t cpu numpy dim dims dims range t dim prepend = t narrow dim append = t narrow dim np_t = to_np t test when no prepend append n range t size dim actual = torch diff t dim=dim n=n expected = torch from_numpy np diff np_t axis=dim n=n assertEqual actual expected t dtype test when prepend append s size along dim n range t size dim + actual = torch diff t dim=dim n=n prepend=prepend append=append expected = torch from_numpy np diff np_t axis=dim n=n prepend=to_np prepend append=to_np append assertEqual actual expected t dtype test when prepend append s size along dim = n range t size dim actual = torch diff t dim=dim n=n prepend=t append=t expected = torch from_numpy np diff np_t axis=dim n=n prepend=np_t append=np_t assertEqual actual expected t dtype All tensors appear contiguous XLA onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bool test_diff_noncontig device dtype shapes = shape shapes contig = make_tensor shape dtype=dtype device=device low=- high= non_contig = torch empty shape + device=device dtype=dtype non_contig = non_contig select - - non_contig copy_ contig assertTrue non_contig is_contiguous shape == _test_diff_numpy non_contig RngNormal implemented type f XLA dtypes all_types_and_complex_and torch bool dtypesIfCPU all_types_and_complex_and torch half torch bool dtypesIfCUDA all_types_and_complex_and torch half torch bool test_diff device dtype shapes = shape shapes contig = make_tensor shape dtype=dtype device=device low=- high= _test_diff_numpy contig t = torch ones assertRaisesRegex RuntimeError diff expects prepend append same dimension input invalid_prepend = torch tensor device=device dtype=dtype t diff dim= prepend=invalid_prepend assertRaisesRegex RuntimeError diff expects shape tensor prepend append match input invalid_prepend = torch tensor device=device dtype=dtype t diff dim= prepend=invalid_prepend assertRaisesRegex RuntimeError diff expects input least one-dimensional scalar = torch tensor device=device dtype=dtype torch diff scalar given input arg list returns list single element arg _wrap_to_list input_array list input_array isinstance input_array list tuple input_array To ensure inf -inf nan values do cause divergence between Numpy PyTorch There two types possible divergence When we compute b both real numbers has very small absolute values i e very near then result b inf -inf nan cause divergence When we dividing complex numbers zero For example when = torch tensor + j we have equal nan + nan j PyTorch inf + inf j Numpy _inf_nan_preprocess actual expected i range len expected expected i = np nan_to_num expected i nan=nan posinf=nan neginf=nan nan_to_num defined complex tensors PyTorch actual i dtype == torch complex actual i real = torch nan_to_num actual i real nan=nan posinf=nan neginf=nan actual i imag = torch nan_to_num actual i imag nan=nan posinf=nan neginf=nan actual i = torch nan_to_num actual i nan=nan posinf=nan neginf=nan actual expected onlyNativeDeviceTypes dtypes torch long torch float torch complex test_gradient_all device dtype create_scalar shape make_tensor device= cpu dtype=dtype low= item create_list shape make_tensor len shape device= cpu dtype=dtype low= tolist create_coordinate_tensors shape tensor_list = i range len shape tensor_list append make_tensor shape i device=device dtype=dtype tensor_list filter_shape shape dim filtered_shape = i range len dim filtered_shape append shape dim i filtered_shape shape dims format test_cases = - case contig edge_order space_fn product test_cases True False create_scalar create_list create_coordinate_tensors shape dims = case filter shape dims before passing filtered shape create_ functions filtered_shape = filter_shape shape dims spacing = space_fn filtered_shape t = make_tensor shape device=device dtype=dtype noncontiguous=not contig t_np = t cpu numpy actual = torch gradient t spacing=spacing dim=dims edge_order=edge_order space_fn == create_coordinate_tensors spacing device = cpu spacing = space cpu detach numpy space spacing expected = np gradient t_np _wrap_to_list spacing axis=dims edge_order=edge_order actual expected = _inf_nan_preprocess list actual _wrap_to_list expected assertEqual actual expected equal_nan=True atol= e- rtol= exact_dtype=False onlyNativeDeviceTypes slowTestIf TEST_WITH_TORCHINDUCTOR dtypes torch long torch float torch complex test_gradient_extreme_cases device dtype Test behaviour inf nan values actual = torch gradient torch tensor - inf inf -inf -inf inf -inf nan nan inf nan expected = np gradient np array - inf inf -inf -inf inf -inf nan nan inf nan assertEqual actual _wrap_to_list expected exact_dtype=False Test behaviour very big tensors large_size = t = make_tensor large_size dtype=dtype device=device t_np = t cpu numpy coordinates_np = np random randn large_size coordinates = torch tensor coordinates_np device=device actual = torch gradient t spacing=coordinates dim= edge_order= expected = np gradient t_np coordinates_np axis= edge_order= assertEqual actual expected exact_dtype=False actual = torch gradient t spacing=coordinates dim= edge_order= expected = np gradient t_np coordinates_np axis= edge_order= assertEqual actual expected exact_dtype=False onlyNativeDeviceTypes test_gradient_type_promotion device inputs = make_tensor device=device dtype=torch float make_tensor device=device dtype=torch complex make_tensor device=device dtype=torch int spacing = make_tensor device= cpu dtype=torch float item make_tensor device= cpu dtype=torch int item make_tensor device= cpu dtype=torch complex item make_tensor device= cpu dtype=torch float low= tolist make_tensor device= cpu dtype=torch int low= tolist make_tensor device= cpu dtype=torch complex tolist make_tensor device=device dtype=torch float make_tensor device=device dtype=torch float make_tensor device=device dtype=torch int make_tensor device=device dtype=torch int make_tensor device=device dtype=torch complex make_tensor device=device dtype=torch complex input spacing_or_coord edge_order product inputs spacing input_np = input cpu numpy input_np = input cpu numpy actual = torch gradient input spacing=spacing_or_coord dim= edge_order=edge_order spacing_or_coord_wrapped = _wrap_to_list spacing_or_coord spacing_or_coord_np = torch is_tensor spacing_or_coord_wrapped torch device spacing_or_coord_wrapped device type = cpu i range len spacing_or_coord_wrapped spacing_or_coord_np append spacing_or_coord_wrapped i detach clone cpu numpy spacing_or_coord_np = spacing_or_coord_wrapped expected = np gradient input_np spacing_or_coord_np axis= edge_order=edge_order actual dtype == torch complex input dtype = torch complex i range len actual assertEqual actual i real expected i real exact_dtype=False Type promotion fails Numpy when spacing given complex number input given real Result given just real number all imaginary parts equal zero assertEqual expected i imag torch zeros actual i shape exact_dtype=False actual expected = _inf_nan_preprocess list actual list expected assertEqual actual expected equal_nan=True exact_dtype=False onlyNativeDeviceTypes dtypes torch long torch float torch complex test_gradient_spacing_list_length_error device dtype t = make_tensor device=device dtype=dtype spacing = make_tensor device=device dtype=dtype assertRaisesRegex RuntimeError r expected spacing torch gradient t spacing=spacing spacing = make_tensor device=device dtype=dtype torch gradient t spacing=spacing spacing = make_tensor device=device dtype=dtype assertRaisesRegex RuntimeError r expected spacing torch gradient t spacing=spacing spacing = assertRaisesRegex RuntimeError r expected spacing torch gradient t spacing=spacing spacing = torch gradient t spacing=spacing spacing = assertRaisesRegex RuntimeError r expected spacing torch gradient t spacing=spacing _test_large_cum_fn_helper x fn expected = fn x cpu float actual = fn x cpu float Avoid assertEqual save memory torch testing assert_close expected actual unittest skipIf IS_FBCODE IS_REMOTE_GPU sandcastle OOM current tpx gpu re configuration unittest skipIf IS_JETSON psutil issue largeTensorTest Too large Jetson onlyCUDA dtypes torch half only small dtype get oom largeTensorTest GB device= cpu largeTensorTest GB device= cuda test_large_cumsum device dtype initialization avoid overflow half caveats x = torch empty + device=device dtype=dtype x = - x = x = _test_large_cum_fn_helper x lambda x torch cumsum x onlyCUDA dtypes torch half only small dtype get oom largeTensorTest GB device= cpu largeTensorTest GB device= cuda unittest skipIf IS_JETSON psutil issue largeTensorTest Too large Jetson test_large_cumprod device dtype initialization avoid overflow half caveats x = torch empty + device=device dtype=dtype x = x = x = _test_large_cum_fn_helper x lambda x torch cumprod x skipIfTorchDynamo Torchdynamo fails unknown reason skipIfMPS test_discontiguous_out_cumsum device x = torch randn device=device y = torch empty device=device out = torch cumsum x torch cumsum x out=y assertFalse y is_contiguous assertEqual out y atol= rtol= _test_cumminmax_helper x fn expected_val expected_ind val ind = fn x - assertEqual val expected_val atol= rtol= assertEqual ind expected_ind atol= rtol= out_val = torch empty_like val t contiguous t out_ind = torch empty_like ind t contiguous t fn x - out= out_val out_ind TODO Fix It reproduces aot_eager too looks like functionalization bug problematic case seems rare we re calling out= op directly user code where passed-in out tensors non-contiguous TEST_WITH_TORCHINDUCTOR assertFalse out_val is_contiguous assertFalse out_ind is_contiguous assertEqual out_val expected_val atol= rtol= assertEqual out_ind expected_ind atol= rtol= skipIfMPS test_cummax_discontiguous device x = torch tensor device=device dtype=torch float t contiguous t expected_val = torch tensor device=device dtype=torch float expected_ind = torch tensor device=device dtype=torch long _test_cumminmax_helper x torch cummax expected_val expected_ind skipIfMPS test_cummin_discontiguous device x = torch tensor device=device dtype=torch float t contiguous t expected_val = torch tensor device=device dtype=torch float expected_ind = torch tensor device=device dtype=torch long _test_cumminmax_helper x torch cummin expected_val expected_ind test_bool_tensor_value_change device x = torch tensor True False dtype=torch bool device=device x = False x = True assertEqual x torch tensor False True dtype=torch bool device=device FIXME move data movement test suite test_copy_all_dtypes_and_devices device copy copy dt all_types_and_complex_and torch half torch bool torch bfloat x = torch tensor dtype=dt device=device _x_clone = x clone y = copy x y fill_ copy shallow copy only copies tensor view data assertEqual x y onlyCPU test_bfloat _neg_abs device src = torch randn src = torch nan src = -torch nan src = torch inf src = -torch inf src_bf = src bfloat assertEqual src neg bfloat src_bf neg assertEqual src abs bfloat src_bf abs onlyCPU dtypes torch bfloat torch half test_reduced_type_float_copy device dtype shape input = torch randn shape dtype=torch float device=device out = input dtype=dtype assertEqual input out atol=None rtol=None exact_dtype=False out = out torch float assertEqual out out atol= rtol= exact_dtype=False input_s = input out = input_s dtype=dtype assertEqual input_s out atol=None rtol=None exact_dtype=False out = out torch float assertEqual out out atol= rtol= exact_dtype=False FIXME move data movement test suite onlyNativeDeviceTypes test_copy_math_view device dst_dtype src_dtype torch float torch float torch float torch float torch int torch int torch complex torch complex src = make_tensor dtype=src_dtype device=device dst = torch empty dtype=dst_dtype device=device dst copy_ src assertEqual dst src exact_dtype=False dst copy_ src _neg_view assertEqual dst src neg exact_dtype=False dst _neg_view copy_ torch _neg_view src assertEqual dst src exact_dtype=False dst _neg_view copy_ src assertEqual dst src neg exact_dtype=False issue https github com pytorch pytorch issues dst _neg_view copy_ dst assertEqual dst src exact_dtype=False dst_dtype src_dtype torch complex torch complex torch complex torch complex src = make_tensor dtype=src_dtype device=device dst = torch empty dtype=dst_dtype device=device dst conj copy_ src assertEqual dst src conj_physical exact_dtype=False dst conj copy_ src _neg_view assertEqual dst src neg conj_physical exact_dtype=False FIXME move data movement test suite onlyNativeDeviceTypes dtypes torch int torch float torch complex test_copy_transpose_math_view device dtype src = make_tensor dtype=dtype device=device transpose dst = torch empty dtype=dtype device=device dst _neg_view copy_ src assertEqual dst -src dst _neg_view copy_ src _neg_view assertEqual dst src dst copy_ src _neg_view assertEqual dst -src dtype is_complex dst conj copy_ src assertEqual dst src conj_physical dst conj copy_ src conj assertEqual dst src dst copy_ src conj assertEqual dst src conj_physical test_clone_all_dtypes_and_devices device dt all_types_and_complex_and torch half torch bool torch bfloat x = torch tensor dtype=dt device=device y = x clone assertEqual x y test_clone_zero_stride_dim device stride zero size axis contiguous x = torch randn y = x as_strided assertEqual y y clone test_clone_not_memory_dense github issue https github com pytorch pytorch issues x = torch randn t y = x clone should retain permutation after densification assertTrue y stride == FIXME move elementwise ternary test suite parametrize use_cpu_scalar True False dtypesIfCUDA set get_all_math_dtypes cuda dtypes set get_all_math_dtypes cpu test_addcmul device dtype use_cpu_scalar Returns floating integral scalar corresponding dtype _number floating integer dtype dtype torch half torch float torch double torch bfloat floating dtype torch cfloat torch cdouble floating + j integer rand_tensor size dtype device dtype is_floating_point dtype is_complex torch rand size=size dtype=dtype device=device dtype == torch uint torch randint size=size dtype=dtype device=device torch randint - size=size dtype=dtype device=device = rand_tensor dtype=dtype device=device b = rand_tensor dtype=dtype device=device use_cpu_scalar c = rand_tensor device= cpu dtype=dtype c = rand_tensor dtype=dtype device=device alpha = _number dtype actual = torch addcmul b c value=alpha expected = + alpha b c assertEqual expected actual assertWarnsOnceRegex UserWarning This overload addcmul deprecated assertEqual actual torch addcmul alpha b c device_type == cuda dtype == torch half = torch tensor device=device dtype=dtype b = torch tensor device=device dtype=dtype c = torch tensor device=device dtype=dtype out = torch addcmul b c value=- assertTrue out isnan out isinf onlyCUDA test_addcmul_cuda_errors_with_cpu_scalars device Logic dtype agnostic so dtype isn t tested alpha = = torch rand device=device b = torch rand device=device c = torch rand device=device scalar = torch rand device= cpu assertRaisesRegex RuntimeError r CPU Scalar support tensor argument torch addcmul scalar c value=alpha assertRaisesRegex RuntimeError r CPU Scalar support argument torch addcmul scalar b c value=alpha FIXME move shape ops test suite test_narrow_empty device x = torch randn device=device d range x dim y = x narrow d x size d sz = list x size sz d = assertEqual sz y size test_narrow_copy_non_contiguous device see https github com pytorch pytorch issues inp = torch randn device=device movedim - expected = torch narrow_copy inp contiguous actual = torch narrow_copy inp assertEqual expected actual FIXME find test suite take operator dtypes all_types_and_complex_and torch half torch bool torch bfloat slowTestIf IS_WINDOWS test_take device dtype idx_size = make_arg = partial make_tensor device=device dtype=dtype make_idx = partial make_tensor low= device=device dtype=torch int ref_take src idx dtype == torch bfloat src = src half src = src cpu numpy idx = idx cpu numpy out = torch from_numpy np take src idx device=device dtype=dtype out src_contig idx_contig idx_reshape product True False repeat= src_size src = make_arg src_size noncontiguous=not src_contig idx = make_idx idx_size high=src numel noncontiguous=not idx_contig idx_reshape idx = idx reshape out = torch take src idx out = ref_take src idx assertEqual out out Create possible combinations scalar sizes source index size_s size_i product repeat= source = make_arg size_s idx = make_idx size_i high= out = source take idx assertEqual out item source item FIXME find test suite put operator The bool instance does work GPU See https github com pytorch pytorch issues dtypes all_types_and_complex_and torch half torch bfloat test_put device dtype src_size = make_arg = partial make_tensor device=device dtype=dtype make_idx = partial make_tensor low= device=device dtype=torch int ref_put dst idx src accumulate new_dst = dst clone memory_format=torch contiguous_format view - new_idx = idx contiguous view - new_src = src contiguous view - method = new_dst index_add_ accumulate new_dst index_copy_ method new_idx new_src view_as dst dst_contig src_contig idx_contig idx_reshape accumulate product True False repeat= dst_size dst = make_arg dst_size noncontiguous=not dst_contig src = make_arg src_size noncontiguous=not src_contig If accumulate=True ` put_ ` should deterministic regardless inputs CPU On CUDA may test has enough tolerance account accumulate idx = make_idx src_size high=dst numel idx = torch randperm dst numel dtype=torch int device=device src_size idx_contig idx = torch repeat_interleave idx dim=- idx_reshape idx = idx reshape out = torch put dst idx src accumulate out-place reference = ref_put dst idx src accumulate assertEqual out reference in-place dst put_ idx src accumulate assertEqual dst reference Create possible combinations scalar sizes target index source scalars = make_arg size_t make_idx size_i high= make_arg size_s size_t size_i size_s product repeat= dest idx source accumulate product scalars True False dest_init = dest clone out-place out = torch put dest idx source accumulate=accumulate in-place dest = dest clone dest put_ idx source accumulate=accumulate d out dest accumulate assertEqual d item dest_init + source item assertEqual d item source item Empty case dest = make_arg reference = dest clone idx = make_idx high= source = make_arg accumulate True False out = torch put dest idx source accumulate=accumulate assertEqual out reference dest put_ idx source accumulate=accumulate assertEqual dest reference FIXME find test suite put operator The bool instance does work GPU See https github com pytorch pytorch issues dtypes all_types_and_complex_and torch half torch bfloat test_put_accumulate device dtype Test parallel adds accumulate == True low_precision = dtype == torch half dtype == torch bfloat Less numbers avoid overflow low_precision Grainsize for_loop parallelized CPU sizes = low_precision Bfloat has particularly bad performance here This operation nondeterministic GPU so we generous rtol rtol atol = e- e- low_precision e- e- make_arg = partial make_tensor low=- high= device=device dtype=dtype Dump everything into -th position make_idx = partial torch zeros device=device dtype=torch int args = make_idx size make_arg size size sizes idx source args orig = make_arg out = orig put idx source accumulate=True assertEqual out orig + source sum rtol=rtol atol=atol FIXME find test suite take operator skipIfMPS test_take_empty device input_shape indices_shape input = torch empty input_shape device=device indices = torch empty indices_shape dtype=torch int device=device assertEqual indices torch take input indices exact_dtype=False FIXME find test suite put operator test_put_empty device dst_shape indices_shape accumulate False True dst = torch randn dst_shape device=device indices = torch empty indices_shape dtype=torch int device=device src = torch randn indices_shape device=device assertEqual dst dst put_ indices src accumulate=accumulate FIXME port test_scatter_gather_ops py scatter_allow_reduce device dtype reduceop device_type = torch device device type device_type = cuda reduceop == multiply dtype is_floating_point dtypes floating_and_complex_types dtypesIfCPU all_types_and_complex_and torch half torch bool torch bfloat dtypesIfCUDA all_types_and_complex_and torch half torch bool torch bfloat test_scatter_reduce_operations_to_large_input device dtype index = torch tensor device=device dtype=torch long test_data = torch zeros device=device dtype=dtype torch ones device=device dtype=dtype torch tensor device=device dtype=dtype add torch tensor device=device dtype=dtype repeat torch tensor device=device dtype=dtype repeat torch tensor device=device dtype=dtype multiply input src result operation test_data scatter_allow_reduce device dtype operation continue input scatter_ index src reduce=operation assertEqual input result dtypes floating_and_complex_types dtypesIfCPU all_types_and_complex_and torch half torch bool torch bfloat dtypesIfCUDA all_types_and_complex_and torch half torch bool torch bfloat test_scatter_reduce_scalar device dtype index = torch tensor device=device dtype=torch long test_data = torch zeros device=device dtype=dtype torch tensor device=device dtype=dtype add torch tensor device=device dtype=dtype repeat torch tensor device=device dtype=dtype multiply input src result operation test_data scatter_allow_reduce device dtype operation continue input scatter_ index src reduce=operation assertEqual input result FIXME port test_scatter_gather_ops py TODO remove after scatter_add_ deprecated test_scatter_add_non_unique_index device height = width = input = torch ones height width device=device index = torch zeros height width dtype=torch long device=device src = torch ones height width device=device input scatter_add_ index src assertEqual input torch tensor device=device dtype=torch float repeat width dtypes floating_and_complex_types dtypesIfCPU all_types_and_complex_and torch half torch bool torch bfloat dtypesIfCUDA all_types_and_complex_and torch half torch bool torch bfloat test_scatter_reduce_non_unique_index device dtype height = width = index = torch zeros height width dtype=torch long device=device test_data = torch ones height width device=device dtype=dtype torch ones height width device=device dtype=dtype torch tensor device=device dtype=dtype repeat width add torch tensor device=device dtype=dtype repeat height width torch tensor device=device dtype=dtype repeat height width torch tensor device=device dtype=dtype repeat width multiply input src result operation test_data scatter_allow_reduce device dtype operation continue input scatter_ index src reduce=operation assertEqual input result msg=f result result input input method str operation onlyCUDA dtypes complex_types test_scatter_reduce_multiply_unsupported_dtypes device dtype height = width = index = torch zeros height width dtype=torch long device=device input = torch ones height width device=device dtype=dtype src = torch ones height width device=device dtype=dtype assertRaises RuntimeError input scatter_ index src reduce= multiply FIXME port test_scatter_gather_ops py test_scatter_to_large_input device input = torch zeros device=device src = torch ones device=device index = torch tensor device=device dtype=torch long input scatter_ index src assertEqual input torch tensor device=device dtype=torch float FIXME port test_scatter_gather_ops py test_scatter_add_to_large_input device input = torch zeros device=device src = torch ones device=device index = torch tensor device=device dtype=torch long input scatter_add_ index src assertEqual input torch tensor device=device dtype=torch float FIXME port test_scatter_gather_ops py test_scatter_bool device x = torch tensor True True True True True True device=device res = torch zeros dtype=torch bool device=device res = res scatter_ torch tensor device=device x assertEqual res torch tensor True False False False True False False False True device=device FIXME port test_scatter_gather_ops py test_scatter_add_bool device x = torch tensor True True True True True True True True True True device=device res = torch zeros dtype=torch bool device=device res = res scatter_add_ torch tensor device=device x assertEqual res torch tensor True True True True True False True False True False True False True False True device=device FIXME find test suite masked scatter operator onlyNativeDeviceTypes dtypes all_types_and_complex_and torch half torch bfloat test_masked_scatter device dtype dt = dtype num_copy num_dest = dest = torch tensor dtype=dt device=device dest = dest clone dest_ones = dest clone dest_ones_expected = dest clone src = torch tensor dtype=dt device=device src_ones = torch tensor dtype=dt device=device mask = torch tensor dtype=torch bool device=device dest masked_scatter_ mask src j = i range num_dest mask i dest i = src j dest_ones_expected i = src_ones j j += assertEqual dest dest atol= rtol= dest_ones masked_scatter_ mask src_ones assertEqual dest_ones dest_ones_expected atol= rtol= Bound checking CUDA done inside kernel order avoid synchronization means we can clear failures So there no way test then recover device_type = cuda make src smaller should fail src = torch zeros num_copy - dtype=dt device=device assertRaises RuntimeError dest masked_scatter_ mask src empty tensor dest = torch empty dtype=dt device=device mask = torch ones_like dest dtype=torch bool device=device src = torch empty dtype=dt device=device dest masked_scatter_ mask src dest = torch empty dtype=dt device=device mask = torch ones dtype=torch bool device=device src = torch empty dtype=dt device=device dest masked_scatter_ mask src FIXME find test suite masked scatter operator skipIfMPS test_masked_scatter_bool_tensor device src = torch tensor True True True device=device dst = torch tensor False False False device=device mask = torch tensor False True False device=device dst masked_scatter_ mask src assertEqual dst torch tensor False True False device=device mask = torch tensor True False True device=device dst = dst masked_scatter mask src assertEqual dst torch tensor True True True device=device FIXME find test suite masked scatter operator test_scatter_gather_ops test_masked_ops onlyCUDA largeTensorTest GB test_masked_scatter_large_tensor device t_cpu = torch empty + dtype=torch bool random_ t = t_cpu device result_cpu = t_cpu masked_scatter t_cpu t_cpu result = t masked_scatter t t assertEqual result result_cpu FIXME find test suite masked select operator dtypes all_types_and_complex_and torch half torch bool torch bfloat test_masked_select device dtype maskType integral_types_and torch bool num_src = src = torch tensor dtype=dtype device=device mask = torch randint num_src device=device dtype=maskType maskType torch bool assertRaisesRegex RuntimeError r expected BoolTensor mask dst = src masked_select mask continue dst = src masked_select mask dst = i range num_src mask i dst += src i assertEqual dst torch tensor dst atol= rtol= dst = torch empty device=device dtype=dtype torch masked_select src mask out=dst assertEqual dst torch tensor dst dtype=dst dtype atol= rtol= Since half CPU supported need skip remaining test cases dtype == torch half torch device device type == cpu Ensure masks expanded match tensor properly = torch rand device=device mul dtype mask_first_el_each_row = torch zeros device=device dtype=torch bool mask_first_el_each_row = True a_masked = masked_select mask_first_el_each_row assertEqual a_masked mask_first_row = torch zeros device=device dtype=torch bool mask_first_row = True a_masked = masked_select mask_first_row assertEqual a_masked Ensure tensor expanded match mask properly = torch rand device=device mul dtype mask_copy_ _times = torch tensor True True False True device=device a_masked = masked_select mask_copy_ _times assertEqual a_masked unsqueeze expand flatten FIXME find test suite masked select operator test_masked_select_discontiguous device size vals = torch rand size size device=device mask = torch full size size False dtype=torch bool device=device mask = True vals_list = vals vals t mask_list = mask mask t out_dc = torch empty size size device=device v m product vals_list mask_list m is_contiguous expected = v clone reshape - expected = v clone reshape - out = torch masked_select v m assertEqual out expected atol= rtol= torch masked_select v m out=out_dc assertEqual out_dc expected atol= rtol= FIXME find test suite masked fill operator dtypes product all_types_and_complex_and torch half torch bool torch bfloat torch uint torch bool test_masked_fill device dtypes dtype = dtypes mask_dtype = dtypes num_dest = dst = torch zeros num_dest dtype=dtype mask = torch randint num_dest dtype=mask_dtype val = random random dst = dst clone mask_dtype torch bool assertRaisesRegex RuntimeError only supports boolean masks dst masked_fill_ mask val dst masked_fill_ mask val i range num_dest mask i dst i = val assertEqual dst dst atol= rtol= test non-contiguous case dst = torch randn num_dest num_dest num_dest dtype permute dst = dst contiguous dtype is_complex mask = dst abs mask = dst assertTrue dst is_contiguous assertTrue dst is_contiguous dst masked_fill_ mask mask_dtype val dst masked_fill_ mask mask_dtype val assertEqual dst dst atol= rtol= FIXME find test suite masked fill operator test_masked_fill_bool_tensor device dst = torch tensor True False True device=device mask = torch tensor False True False device=device dst masked_fill_ mask True assertEqual dst torch tensor True True True device=device dst = dst masked_fill mask False assertEqual dst torch tensor True False True device=device test_tensor_shape_empty device x = torch randn device=device flatten assertEqual torch flatten x shape assertEqual torch flatten x shape assertEqual torch flatten x shape squeeze unsqueeze assertEqual torch unsqueeze x shape assertEqual torch squeeze x shape assertEqual torch squeeze x shape transpose t assertEqual torch transpose x shape y = torch randn device=device assertEqual y t shape select assertEqual torch select x shape repeat permute assertEqual x repeat shape assertEqual x permute shape diagonal diagflat assertEqual torch diagonal torch randn device=device shape assertEqual torch diagonal torch randn device=device shape off end offsets valid assertEqual torch diagonal torch randn device=device offset= shape assertEqual torch diagonal torch randn device=device offset= shape check non-zero sized offsets off end assertEqual torch diagonal torch randn device=device offset= shape assertEqual torch diagonal torch randn device=device offset=- shape assertEqual torch diagflat torch tensor device=device shape assertEqual torch zeros torch diagflat torch tensor device=device offset= assertEqual torch diagflat torch tensor device=device shape assertEqual torch zeros torch diagflat torch tensor device=device offset= stack split chunk assertEqual torch stack x x x x shape assertEqual z shape z torch chunk x dim= assertEqual z shape z torch chunk x dim= assertEqual z shape z torch chunk x dim= NOTE split_with_sizes behaves differently than NumPy takes sizes rather than offsets assertEqual z shape z torch split x dim= assertRaises RuntimeError lambda torch split x dim= This strange because split size larger than dim size consistent how split handles case generally when no s involved assertEqual z shape z torch split x dim= assertEqual z shape z torch split x dim= functions operate over dimension don t reduce test_dim_function_empty device shape = x = torch randn shape device=device size stride assertEqual x size assertEqual x size assertEqual x stride assertEqual x stride assertEqual x torch nn functional glu x assertEqual torch nn functional glu x shape softmax logsoftmax assertEqual x torch nn functional softmax x assertEqual x torch nn functional softmax x assertEqual x torch nn functional softmax x assertEqual x torch nn functional log_softmax x assertEqual x torch nn functional log_softmax x assertEqual x torch nn functional log_softmax x cumsum cumprod cummax cummin assertEqual shape torch cumsum x shape assertEqual shape torch cumsum x shape assertEqual shape torch cumprod x shape assertEqual shape torch cumprod x shape assertEqual shape torch cummax x shape assertEqual shape torch cummax x shape assertEqual shape torch cummin x shape assertEqual shape torch cummin x shape assertEqual shape torch logcumsumexp x shape assertEqual shape torch logcumsumexp x shape flip assertEqual x x flip assertEqual x x flip roll assertEqual x x roll roll - assertEqual x x roll x size assertEqual x x roll assertEqual x x roll unbind assertEqual x unbind assertEqual torch empty device=device torch empty device=device x unbind cross y = torch randn device=device assertEqual y shape torch cross y y shape renorm assertEqual shape torch renorm x shape assertEqual shape torch renorm x shape sort assertEqual shape shape z shape z torch sort x dim= assertEqual shape shape z shape z torch sort x dim= topk assertEqual shape shape z shape z torch topk x dim= assertEqual z shape z torch topk x dim= y = torch randn device=device assertEqual z shape z torch topk y gather assertEqual shape torch gather x torch empty shape dtype=torch int device=device shape assertEqual shape torch gather x torch empty shape dtype=torch int device=device shape larger_shape = torch empty dtype=torch int device=device assertEqual larger_shape shape torch gather x larger_shape shape smaller_shape = torch empty dtype=torch int device=device assertEqual smaller_shape shape torch gather x smaller_shape shape y = torch randn device=device assertEqual torch gather y torch empty dtype=torch int device=device shape scatter scatter_add dim y = torch randn shape device=device y_src = torch randn shape device=device ind = torch empty shape dtype=torch int device=device assertEqual shape y scatter_ dim ind y_src shape assertEqual shape y scatter_add_ dim ind y_src shape z = torch randn device=device z_src = torch randn device=device assertEqual z z scatter_ torch empty dtype=torch int device=device z_src assertEqual z z scatter_add_ torch empty dtype=torch int device=device z_src index_fill index_copy index_add c = x clone c_clone = c clone ind_empty = torch tensor dtype=torch int device=device ind_ = torch tensor dtype=torch int device=device assertEqual c_clone c index_fill_ ind_empty - assertEqual c_clone c index_fill_ ind_empty - assertEqual c_clone c index_fill_ ind_ - assertEqual c_clone c index_copy_ ind_empty torch empty device=device assertEqual c_clone c index_copy_ ind_empty torch empty device=device assertEqual c_clone c index_copy_ ind_ torch empty device=device assertEqual c_clone c index_add_ ind_empty torch empty device=device assertEqual c_clone c index_add_ ind_empty torch empty device=device assertEqual c_clone c index_add_ ind_ torch empty device=device c = torch randn device=device c_clone = c clone assertEqual c_clone c index_fill_ ind_empty - assertEqual c_clone c index_copy_ ind_empty torch empty device=device assertEqual c_clone c index_add_ ind_empty torch empty device=device assertEqual c_clone c index_fill_ ind_empty - assertEqual c_clone c index_copy_ ind_empty torch empty device=device assertEqual c_clone c index_add_ ind_empty torch empty device=device index fill copy add non-empty z = torch randn device=device assertEqual z z index_fill_ ind_empty - z = torch randn device=device assertEqual z z index_copy_ ind_empty torch empty device=device z = torch randn device=device assertEqual z z index_add_ ind_empty torch empty device=device index_select assertEqual x x index_select ind_empty assertEqual x index_select ind_empty shape assertEqual x x index_select ind_ z = torch randn device=device non-empty assertEqual z index_select ind_empty shape c = torch randn device=device assertEqual c c index_select ind_empty c = torch randn device=device assertEqual c c index_select ind_empty w = torch randn device=device assertEqual w index_select ind_ shape w = torch randn device=device assertEqual w index_select ind_ shape ind_ _int = torch tensor dtype=torch int device=device assertEqual w index_select ind_ _int shape s = torch randn device=device ind_ = torch tensor dtype=torch int device=device assertEqual s index_select ind_ shape device == cpu w = torch randn device=device assertRaisesRegex RuntimeError indexing axis dim should positive torch index_select w ind_ ind_ = torch tensor dtype=torch int device=device assertRaisesRegex RuntimeError INDICES element out DATA bounds torch index_select w ind_ assertRaisesRegex RuntimeError Index scalar can have only value torch index_select s ind_empty assertRaisesRegex RuntimeError Index scalar can have only value torch ones index_select torch Tensor int FIXME find test suite pdist operator unittest skipIf IS_FBCODE IS_REMOTE_GPU sandcastle OOM current tpx gpu re configuration skipIfRocm onlyCUDA largeTensorTest GB device= cpu largeTensorTest GB device= cuda test_pdist_norm_large device use dim = forward see https github com pytorch pytorch issues Compare output using GPU CPU implementation x = torch randn dtype=torch float k bytes = KB Will require float s expected_cpu = torch pdist x p= ~ M bytes = GB CPU actual_cpu = torch pdist x device p= cpu GB GPU + GB CPU Workaround large memory overhead assertTrue see assertTrue torch allclose expected_cpu actual_cpu ~ GB allclose FIXME move elementwise ternary test suite onlyNativeDeviceTypes dtypesIfCUDA set get_all_math_dtypes cuda dtypes set get_all_math_dtypes cpu test_addcdiv device dtype Returns floating integral scalar corresponding dtype _number floating integer dtype dtype torch half torch float torch double torch bfloat floating dtype torch cfloat torch cdouble floating + j integer non_zero_rand size dtype device dtype is_floating_point dtype is_complex = torch rand size=size dtype=dtype device=device dtype == torch uint = torch randint size=size dtype=dtype device=device = torch randint - size=size dtype=dtype device=device + == dtype _test_addcdiv = non_zero_rand dtype=dtype device=device b = non_zero_rand dtype=dtype device=device c = non_zero_rand dtype=dtype device=device alpha = _number dtype expected = + alpha b c actual = torch addcdiv b c value=alpha assertEqual expected actual assertWarnsOnceRegex UserWarning This overload addcdiv deprecated assertEqual actual torch addcdiv alpha b c dtype is_floating_point dtype is_complex Integer division addcdiv prohibited assertRaises RuntimeError _test_addcdiv _test_addcdiv device_type == cuda dtype == torch half = torch tensor device=device dtype=dtype b = torch tensor device=device dtype=dtype c = torch tensor device=device dtype=dtype out = torch addcmul b c value=- assertTrue out isnan out isinf test_nullary_op_mem_overlap device ops = random_ uniform_ cauchy_ log_normal_ exponential_ geometric_ normal_ x = torch rand expand op args ops assertRaisesRegex RuntimeError unsupported operation getattr x op args FIXME move elementwise ternary test suite make OpInfo test https github com pytorch pytorch issues xfailIfTorchDynamo skipIfTorchInductor https github com pytorch pytorch issues dtypes torch double test_ternary_op_mem_overlap device dtype device == cpu TEST_WITH_TORCHINDUCTOR skipTest Failing cpu ops = addcmul True True cpu addcmul True True cuda addcdiv True True cpu addcdiv True True cuda lerp True True cpu lerp True True cuda fn has_input_output_mem_overlap_check has_internal_mem_overlap_check dev ops dev = device continue out_op = getattr torch fn inplace_op = getattr torch Tensor fn + _ check_internal_mem_overlap inplace_op dtype device expected_failure=not has_internal_mem_overlap_check ternary_check_input_output_mem_overlap out_op dev expected_failure=not has_input_output_mem_overlap_check expectedFailureMeta RuntimeError raised dtypes torch double onlyNativeDeviceTypes test_copy_mem_overlap device dtype check_internal_mem_overlap torch Tensor copy_ num_inputs= dtype=dtype device=device sz = doubles = torch randn sz dtype=dtype device=device unary_check_input_output_mem_overlap doubles sz lambda input out out copy_ input FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors onlyNativeDeviceTypes test_index_add_mem_overlap device x = torch rand device=device expand y = torch rand device=device ind = torch tensor device=device value = torch rand device=device assertRaisesRegex RuntimeError unsupported operation x index_add_ ind value assertRaisesRegex RuntimeError unsupported operation y index_add_ ind y assertRaisesRegex RuntimeError unsupported operation ind index_add_ ind ind clone assertRaisesRegex RuntimeError unsupported operation ind index_add_ ind clone ind onlyCUDA skipCUDAIfNotRocm This UT throws OOM error CUDA test_index_add_large_inputs device D = x = torch zeros D device=device dtype=torch bfloat index = torch randint device=device dtype=torch int output = torch ones D device=device dtype=torch bfloat Use random values test x_before = x clone Manually update x_before generate expected values batch range output shape Loop over batch size case idx range output shape Loop over index idx_val = index batch idx item x_before idx_val += output batch idx Run index_add get actual values x index_add_ index view - output view - D assertEqual x_before x FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors onlyNativeDeviceTypes test_index_copy_mem_overlap device x = torch rand device=device expand y = torch rand device=device ind = torch tensor device=device value = torch rand device=device assertRaisesRegex RuntimeError unsupported operation x index_copy_ ind value assertRaisesRegex RuntimeError unsupported operation y index_copy_ ind y assertRaisesRegex RuntimeError unsupported operation ind index_copy_ ind ind clone assertRaisesRegex RuntimeError unsupported operation ind index_copy_ ind clone ind FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta Warning triggered onlyNativeDeviceTypes test_index_fill_mem_overlap device x = torch rand device=device expand ind = torch tensor device=device assertWarnsRegex UserWarning index_fill_ expanded tensors x index_fill_ ind assertRaisesRegex RuntimeError unsupported operation ind index_fill_ ind FIXME convert ErrorInputs expectedFailureMeta RuntimeError raised onlyNativeDeviceTypes test_shift_mem_overlap device x = torch rand device=device assertRaisesRegex RuntimeError unsupported operation x - = x assertRaisesRegex RuntimeError unsupported operation x - = x FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta RuntimeError raised onlyNativeDeviceTypes test_bernoulli_mem_overlap device x = torch rand device=device expand assertRaisesRegex RuntimeError unsupported operation x bernoulli_ assertRaisesRegex RuntimeError unsupported operation x bernoulli_ p= p = torch rand device=device assertRaisesRegex RuntimeError unsupported operation x bernoulli_ p=p FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta RuntimeError raised onlyNativeDeviceTypes test_put_mem_overlap device x = torch rand device=device expand y = torch rand device=device ind = torch tensor device=device value = torch rand device=device assertRaisesRegex RuntimeError unsupported operation x put_ ind value assertRaisesRegex RuntimeError unsupported operation y put_ ind y assertRaisesRegex RuntimeError unsupported operation ind put_ ind ind assertRaisesRegex RuntimeError unsupported operation y put_ ind y assertRaisesRegex RuntimeError unsupported operation ind put_ ind ind clone assertRaisesRegex RuntimeError unsupported operation ind put_ ind clone ind FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta UserWarning triggered onlyNativeDeviceTypes test_index_put_mem_overlap device x = torch rand device=device expand y = torch rand device=device ind = torch tensor device=device value = torch rand device=device assertWarnsRegex UserWarning expanded tensors x index_put_ ind value assertRaisesRegex RuntimeError unsupported operation y index_put_ ind y assertRaisesRegex RuntimeError unsupported operation ind index_put_ ind ind assertRaisesRegex RuntimeError unsupported operation y index_put_ ind y assertRaisesRegex RuntimeError unsupported operation ind index_put_ ind ind clone assertRaisesRegex RuntimeError unsupported operation ind index_put_ ind clone ind FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta UserWarning triggered onlyNativeDeviceTypes test_masked_fill_mem_overlap device x = torch rand device=device expand mask = torch tensor True False True True False False device=device assertWarnsRegex UserWarning expanded tensors x masked_fill_ mask fill_val = torch tensor device=device assertWarnsRegex UserWarning expanded tensors x masked_fill_ mask fill_val assertRaisesRegex RuntimeError unsupported operation mask masked_fill_ mask - False FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors expectedFailureMeta RuntimeError raised onlyNativeDeviceTypes test_masked_scatter_mem_overlap device x = torch rand device=device expand src = torch rand device=device mask = torch tensor True False True True False False device=device assertRaisesRegex RuntimeError unsupported operation x masked_scatter_ mask src FIXME convert ErrorInputs have extend ErrorInputs handle inplace-only errors onlyNativeDeviceTypes test_scatter_mem_overlap device x = torch rand device=device expand src = torch rand device=device ind = torch tensor device=device dtype=torch int assertRaisesRegex RuntimeError unsupported operation x scatter_ ind src assertRaisesRegex RuntimeError unsupported operation src scatter_ ind src assertRaisesRegex RuntimeError unsupported operation ind scatter_ ind ind clone FIXME move test distributions onlyCUDA test_multinomial_device_constrain device x = torch empty device= cpu y = torch empty device=device assertRaisesRegex RuntimeError Expected all tensors same device lambda torch multinomial x out=y FIXME move test distributions deviceCountAtLeast onlyCUDA skipIfTorchInductor FIXME error thrown test_multinomial_gpu_device_constrain devices x = torch empty device=devices y = torch empty device=devices dtype=torch long assertRaisesRegex RuntimeError Expected all tensors same device lambda torch multinomial x out=y FIXME convert automated OpInfo test deviceCountAtLeast onlyCUDA test_device_guard devices verify all operators ` device_guard False ` behave properly multiple devices TODO we had operator introspection we could figure out set operators automatically x = torch randn device=devices y = torch zeros device=devices scalar = torch tensor device=devices property ops torch cudnn_is_acceptable x x is_distributed x is_floating_point x is_complex x is_same_size y x is_signed x size x stride x numel x is_set_to y x data_ptr scalar is_nonzero sparse property ops y = y_sparse = y to_sparse y_sparse sparse_dim y_sparse _dimI y_sparse dense_dim y_sparse _dimV y_sparse _nnz y_sparse is_coalesced y_sparse _indices y_sparse _values y_sparse indices y_sparse values in-place ops inplace torch randn device=devices inplace as_strided_ y size y stride inplace resize_ y size inplace squeeze_ inplace squeeze_ inplace unsqueeze_ inplace transpose_ inplace squeeze_ t_ inplace set_ x storage inplace set_ x storage x storage_offset x size x stride inplace set_ x inplace set_ y_sparse _coalesced_ True shape modification x as_strided y size y stride x expand x expand_as x x sum_to_size torch broadcast_tensors x x x reshape x reshape_as y x squeeze x squeeze x squeeze t x transpose x unsqueeze x view x view_as y chunk split etc x chunk dim= x split dim= x split_with_sizes dim= x unfold dimension= size= step= x narrow x select torch isnan x torch empty out=y torch empty_like x torch empty_like x dtype=torch int x x x y x x copy=True test_is_signed device assertEqual torch IntTensor device is_signed True assertEqual torch ByteTensor device is_signed False assertEqual torch CharTensor device is_signed True assertEqual torch FloatTensor device is_signed True assertEqual torch HalfTensor device is_signed True test_tensor_type t torch _tensor_classes cuda t __module__ assertEqual t is_cuda True assertEqual t is_cuda False xpu t __module__ assertEqual t is_xpu True assertEqual t is_xpu False Note - reports leak bytes CUDA device deviceCountAtLeast skipCUDAMemoryLeakCheckIf True onlyCUDA test_tensor_set_errors_multigpu devices f_cuda = torch randn dtype=torch float device=devices f_cuda = torch randn dtype=torch float device=devices assertRaises RuntimeError lambda f_cuda set_ f_cuda storage assertRaises RuntimeError lambda f_cuda set_ f_cuda storage f_cuda size f_cuda stride assertRaises RuntimeError lambda f_cuda set_ f_cuda FIXME move test_serialization onlyCUDA deviceCountAtLeast Note Tests works one prefers more devices test_serialization devices _test_serialization filecontext_lambda t = torch cuda FloatTensor fill_ torch cuda device devices - tn = torch cuda FloatTensor fill_ torch cuda set_device devices b = t tn filecontext_lambda f torch save b f f seek c = torch load f assertEqual b c atol= rtol= u un = c assertEqual str u device devices assertEqual str un device devices - _test_serialization tempfile NamedTemporaryFile _test_serialization BytesIOContext FIXME move memory format tests their own test suite test_memory_format_preserved_after_permute device x = torch randn device=device nhwc = x contiguous memory_format=torch channels_last y = nhwc permute permute assertTrue y is_contiguous memory_format=torch channels_last x = torch randn device=device ndhwc = x contiguous memory_format=torch channels_last_ d y = ndhwc permute permute assertTrue y is_contiguous memory_format=torch channels_last_ d test_memory_format_propagation_rules device contiguous = torch rand device=device cl = torch rand device=device contiguous memory_format=torch channels_last ambiguous = torch rand device=device contiguous memory_format=torch channels_last assertTrue ambiguous is_contiguous memory_format=torch channels_last assertTrue ambiguous is_contiguous memory_format=torch contiguous_format bias = torch rand device=device contiguous memory_format=torch channels_last _test_propagation_rules contiguous cl ambiguous bias options = ambiguous contiguous torch contiguous_format ambiguous cl torch channels_last contiguous ambiguous torch contiguous_format contiguous cl torch contiguous_format cl ambiguous torch channels_last cl contiguous torch channels_last bias cl torch channels_last cl bias torch channels_last b mf options result = + b assertTrue result is_contiguous memory_format=mf _test_propagation_rules contiguous cl ambiguous bias cl = cl memory_format=torch channels_last ambiguous = ambiguous memory_format=torch channels_last bias = bias memory_format=torch channels_last _test_propagation_rules contiguous cl ambiguous bias test cases when strides matter ambiguous tensors mf torch channels_last torch contiguous_format ambiguous = torch rand device=device memory_format=mf bias = torch rand device=device result = ambiguous + bias assertEqual ambiguous stride result stride result = bias + ambiguous assertEqual ambiguous stride result stride result = ambiguous assertEqual ambiguous stride result stride skipIfMPS test_memory_format_empty_like device test_helper x memory_format xc = x contiguous memory_format=memory_format like = torch empty_like xc memory_format=torch preserve_format assertFalse like is_contiguous assertTrue like is_contiguous memory_format=memory_format like_x = torch empty_like x memory_format=torch preserve_format assertTrue like_x is_contiguous assertFalse like_x is_contiguous memory_format=memory_format like = torch empty_like x memory_format=memory_format assertFalse like is_contiguous assertTrue like is_contiguous memory_format=memory_format like = torch empty_like xc memory_format=torch contiguous_format assertTrue like is_contiguous assertFalse like is_contiguous memory_format=memory_format like = torch empty_like xc assertFalse like is_contiguous assertTrue like is_contiguous memory_format=memory_format sparse = x to_sparse assertRaises RuntimeError torch empty_like sparse memory_format=torch preserve_format test_helper torch randn device=device torch channels_last test_helper torch randn device=device torch channels_last_ d test_memory_format_consistency device x = torch randn device=device x_rep = x as_strided x size x stride assertEqual x size x_rep size assertEqual x stride x_rep stride assertEqual x is_contiguous x_rep is_contiguous assertEqual x is_contiguous memory_format=torch channels_last x_rep is_contiguous memory_format=torch channels_last assertEqual x is_contiguous memory_format=torch channels_last_ d x_rep is_contiguous memory_format=torch channels_last_ d FIXME make elementwise unary elementwise binary OpInfo test test_memory_format_operators device _chunk_op x y x x = x chunk dim= x + x _unsqueeze_op_add x y x unsqueeze + _unsqueeze_op_clone x y x unsqueeze clone _test_helper x y bias memory_format return_contig_fns = lambda x y y + x lambda x y y x lambda x y y addcdiv x y value= lambda x y y addcmul x y value= bias_fns = lambda x b x + b lambda x b b + x fns = lambda x y x clone lambda x y x + lambda x y x lambda x y x + y lambda x y x y lambda x y abs x lambda x y x abs lambda x y x abs_ lambda x y x acos lambda x y x acos_ lambda x y x add y alpha= lambda x y x add_ y alpha= lambda x y x addcdiv y y value= lambda x y x addcdiv_ y y value= lambda x y x addcmul y y value= lambda x y x addcmul_ y y value= lambda x y x acosh lambda x y x acosh_ lambda x y x asinh lambda x y x asinh_ lambda x y x atanh lambda x y x atanh_ lambda x y x asin lambda x y x asin_ lambda x y x atan lambda x y x atan y lambda x y x atan _ y lambda x y x ceil lambda x y x ceil_ lambda x y x clamp - lambda x y x cos lambda x y x cosh lambda x y x div lambda x y x div_ lambda x y x div y lambda x y x div_ y lambda x y x digamma lambda x y x digamma_ lambda x y x erf lambda x y x erfc lambda x y x erfinv lambda x y x erfinv_ lambda x y x exp lambda x y x expm lambda x y x expm _ lambda x y x floor lambda x y x floor_ lambda x y x fmod lambda x y x frac lambda x y x hypot y lambda x y x hypot_ y lambda x y x i lambda x y x i _ lambda x y x lerp y lambda x y x log lambda x y x log_ lambda x y x log lambda x y x log _ lambda x y x log p lambda x y x log p_ lambda x y x log lambda x y x log _ lambda x y x mul lambda x y x mul_ lambda x y x neg lambda x y x neg_ lambda x y x pow lambda x y x pow_ lambda x y x pow lambda x y x pow lambda x y x reciprocal lambda x y x remainder lambda x y x round lambda x y x round_ lambda x y x rsqrt lambda x y x rsqrt_ lambda x y x sigmoid lambda x y x sigmoid_ lambda x y x logit lambda x y x logit_ lambda x y x logit e- lambda x y x logit_ e- lambda x y x sign lambda x y x sign_ lambda x y x sgn lambda x y x sgn_ lambda x y x sin lambda x y x sin_ lambda x y x sinh lambda x y x sinh_ lambda x y x sqrt lambda x y x sqrt_ lambda x y x tan lambda x y x tanh lambda x y x trunc lambda x y x trunc_ _chunk_op _unsqueeze_op_add _unsqueeze_op_clone x_c = x contiguous y_c = y contiguous b_c = bias contiguous fn fns is_inplace = _ inspect getsource fn x_clone = x clone is_inplace x x_c_clone = x_c clone is_inplace x_c result_c = fn x_c_clone y_c result = fn x_clone y assertEqual result result_c f Failed inspect getsource fn strip assertTrue result is_contiguous memory_format=memory_format f result inspect getsource fn strip memory_format format fn bias_fns result_c = fn x_c b_c result = fn x bias assertEqual result result_c f Failed inspect getsource fn strip assertTrue result is_contiguous memory_format=memory_format f result inspect getsource fn strip memory_format format fn return_contig_fns result_c = fn x_c y_c result = fn x y assertEqual result result_c f Failed inspect getsource fn strip assertTrue result is_contiguous memory_format=torch contiguous_format f result inspect getsource fn strip torch contiguous_format format _test_helper torch randn device=device contiguous memory_format=torch channels_last abs torch randn device=device + torch randn device=device contiguous memory_format=torch channels_last torch channels_last _test_helper torch randn device=device contiguous memory_format=torch channels_last_ d abs torch randn device=device + torch randn device=device contiguous memory_format=torch channels_last_ d torch channels_last_ d FIXME make elementwise unary elementwise binary OpInfo test test_strides_propagation device _test_helper x op unary=False compare_strides s s div sdiv = s div s s assertEqual sdiv s dim = x dim we produce memory dense outputs so when input strided last dimension we need divide dimension stride compare input result strides div = x stride - p permutations range dim xp = x permute p unary y = torch randn xp size - device=x device dtype=x dtype inputs xp xp xp y y xp res = op inputs compare_strides xp stride res stride div assertEqual xp size res size out = torch empty device=xp device dtype=res dtype res = op inputs out=out compare_strides xp stride res stride div assertEqual xp size res size res = op xp compare_strides xp stride res stride div assertEqual xp size res size out = torch empty device=xp device dtype=res dtype res = op xp out=out compare_strides xp stride res stride div assertEqual xp size res size torch eq default calls TensorIterator defined output torch add undefined binary_ops = torch eq torch add unary_ops = torch exp memory dense sliced ambiguous sliced ambiguous dense loses permutation information xs = torch randn device=device torch randn device=device torch randn device=device op binary_ops x xs _test_helper x op op unary_ops x xs _test_helper x op unary=True onlyCUDA unittest skipIf PYTORCH_CUDA_MEMCHECK is_pinned uses failure detect pointer property skipIfTorchDynamo NotImplementedError PrimTorch does support pinned memory test_pin_memory_from_constructor device _get_like t kwargs torch rand_like t kwargs torch randn_like t kwargs torch empty_like t kwargs torch full_like t kwargs torch zeros_like t kwargs torch ones_like t kwargs _get_tensors kwargs torch tensor kwargs torch randn kwargs torch rand kwargs torch randint kwargs unsupported torch zeros kwargs torch randperm kwargs torch empty kwargs torch ones kwargs torch eye kwargs torch arange kwargs pinned_tensors = _get_tensors pin_memory=True + _get_like torch empty dtype=torch float pin_memory=True x pinned_tensors assertTrue x is_pinned tensors = _get_tensors + _get_like torch empty dtype=torch float pin_memory=True x tensors assertFalse x is_pinned deviceCountAtLeast onlyCUDA parametrize non_blocking True False test_storage_all_devices devices non_blocking device devices t = torch randn device=device assertEqual t dtype t storage dtype s = t untyped_storage s_cpu = s device= cpu non_blocking=non_blocking non_blocking torch cuda synchronize assertTrue s_cpu is_pinned assertFalse s_cpu is_pinned t_cpu = torch empty set_ s_cpu assertEqual t cpu t_cpu Note lazy_clone_ tests inductor enabled These ` lazy_clone_ ` tests written way makes them pass both eager mode compiled mode ` PYTORCH_TEST_WITH_INDUCTOR= ` There cases where COW tensors can materialize different times different ways compiled mode versus eager mode those cases need avoided There two main wrinkles aware The first wrinkle these tests have check internal properties tensors make sure they materialize expected way those checks cause dynamo graph breaks Depending situation graph break in-between two compiled graphs operate same COW tensor can make tensor materialize when would materialize eager mode causing checks fail The strategy avoiding make all operations COW tensors get compiled into same graph doing any checks between operations just do all checks end test If we really do want perform checks between two operations ` op ` ` op ` solution create two different tests One test performs just ` op ` then checks The other test performs ` op ` followed immediately ` op ` then checks The second wrinkle eager mode we perform writes two COW tensors where one lazy clone other first tensor written will materialized new data pointer second tensor will just reuse original data pointer when materialized But compiled mode these writes happen same graph order which tensors materialize can different than eager mode So case strategy purposefully cause graph break happen in-between two write operations adding checks between them so they have materialize expected order skipXLA dtypes all_types_and_complex_and torch half torch bool torch bfloat test_lazy_clone device dtype t = torch tensor device=device dtype=dtype t_orig_storage_addr = torch _C _storage_address t orig_data_ptr = torch _C _data_address t clone = t _lazy_clone Lazy cloning tensor should cause both its clone become COW tensors They should have different storages same data pointer assertTrue torch _C _is_cow_tensor clone assertTrue torch _C _is_cow_tensor t assertTrue torch _C _storage_address t == t_orig_storage_addr assertTrue torch _C _storage_address clone = t_orig_storage_addr assertTrue torch _C _data_address t == orig_data_ptr assertTrue torch _C _data_address clone == orig_data_ptr See Note lazy_clone_ tests inductor enabled skipXLA dtypes all_types_and_complex_and torch half torch bool torch bfloat test_lazy_clone_view device dtype t = torch tensor device=device dtype=dtype t_orig_storage_addr = torch _C _storage_address t orig_data_ptr = torch _C _data_address t clone = t _lazy_clone view = t view Viewing ` t ` should cause copy materialize happen All tensors should still COW have same data pointer ` view ` ` t ` should have same storage ` clone ` should have different storage assertTrue torch _C _is_cow_tensor t assertTrue torch _C _is_cow_tensor view assertTrue torch _C _is_cow_tensor clone assertTrue torch _C _storage_address t == t_orig_storage_addr assertTrue torch _C _storage_address view == t_orig_storage_addr assertTrue torch _C _storage_address clone = t_orig_storage_addr assertTrue torch _C _data_address t == orig_data_ptr assertTrue torch _C _data_address clone == orig_data_ptr assertTrue torch _C _data_address view == orig_data_ptr See Note lazy_clone_ tests inductor enabled skipXLA dtypes all_types_and_complex_and torch half torch bool torch bfloat test_lazy_clone_view_materialize device dtype t = torch tensor device=device dtype=dtype t_orig_storage_addr = torch _C _storage_address t orig_data_ptr = torch _C _data_address t clone = t _lazy_clone view = t view view += torch ones device=device dtype=dtype Writing ` t ` should cause storage under ` t ` ` view ` copied materialized should affect ` clone ` assertFalse torch _C _is_cow_tensor t assertFalse torch _C _is_cow_tensor view assertTrue torch _C _is_cow_tensor clone assertTrue torch _C _storage_address t == t_orig_storage_addr assertTrue torch _C _storage_address view == t_orig_storage_addr assertTrue torch _C _storage_address clone = t_orig_storage_addr t_new_data_addr = torch _C _data_address t assertTrue t_new_data_addr = orig_data_ptr assertTrue torch _C _data_address view == t_new_data_addr assertTrue torch _C _data_address clone == orig_data_ptr clone += torch ones device=device dtype=dtype Writing ` clone ` should materialize so should no longer COW However since ` clone ` s storage only COW storage left holds reference original data pointer materialization should actually cause copy -- should just reuse original data pointer assertFalse torch _C _is_cow_tensor t assertFalse torch _C _is_cow_tensor view assertFalse torch _C _is_cow_tensor clone assertTrue torch _C _storage_address t == t_orig_storage_addr assertTrue torch _C _storage_address view == t_orig_storage_addr assertTrue torch _C _storage_address clone = t_orig_storage_addr assertTrue torch _C _data_address t == t_new_data_addr assertTrue torch _C _data_address view == t_new_data_addr assertTrue torch _C _data_address clone == orig_data_ptr skipXLA dtypes all_types_and_complex_and torch half torch bool torch bfloat test_lazy_clone_binary_op_no_materialize device dtype t = torch tensor device=device dtype=dtype clone = t _lazy_clone t + clone assertTrue torch _C _is_cow_tensor t assertTrue torch _C _is_cow_tensor clone This tests COW materialization attempted inside ` parallel_for ` loop function then error raised This test implemented Python rather than C++ because C++ tests built without multithreading support ` parallel_for ` skipXLA skipIfTorchDynamo Torchdynamo fails we do need test here anyway dtypes all_types_and_complex_and torch half torch bool torch bfloat test_parallel_cow_materialize_error device dtype run num_threads num_parallel skip_first should_error orig_num_threads = torch get_num_threads try torch set_num_threads num_threads = torch tensor device=device dtype=dtype _lazy_clone should_error assertRaisesRegex RuntimeError r Materializing storage torch _test_parallel_materialize num_parallel skip_first torch _test_parallel_materialize num_parallel skip_first Error should raise any case tensor COW b = torch tensor device=device dtype=dtype torch _test_parallel_materialize b num_parallel skip_first finally torch set_num_threads orig_num_threads run False True run True False run False True run True True run False True run True False run False True run True True run False True run True True FIXME move test distributions skipIfMPS dtypesIfCUDA torch float torch double torch half dtypes torch float torch double torch half test_multinomial device dtype make_prob_dist shape is_contiguous is_contiguous dtype == torch half torch zeros shape device=device uniform_ dtype=torch half torch zeros shape device=device dtype=dtype uniform_ len shape == dtype == torch half torch zeros shape + device=device uniform_ dtype=torch half torch zeros shape + device=device dtype=dtype uniform_ num dim = new_shape = shape shape dtype == torch half prob_dist = torch zeros new_shape device=device uniform_ dtype=torch half prob_dist = torch zeros new_shape device=device dtype=dtype uniform_ prob_dist = prob_dist transpose prob_dist = prob_dist assert prob_dist is_contiguous sanity check prob_dist is_contiguous True False replacement n_row = n_col range + prob_dist = make_prob_dist n_row n_col is_contiguous indices shouldn t sampled means none zero_prob_indices = torch LongTensor n_row random_ - n_col tolist i j enumerate zero_prob_indices j = prob_dist i j = n_sample = n_col sample_indices = torch multinomial prob_dist n_sample True assertEqual prob_dist dim assertEqual sample_indices size n_sample i range n_row zero_prob_idx = zero_prob_indices i zero_prob_idx continue j range n_sample assertNotEqual sample_indices i j zero_prob_idx msg= sampled index zero probability without replacement n_row = n_col range + prob_dist = make_prob_dist n_row n_col is_contiguous indices shouldn t sampled means none zero_prob_indices = torch LongTensor n_row random_ - n_col tolist i j enumerate zero_prob_indices j = prob_dist i j = n_sample = max n_col - sample_indices = torch multinomial prob_dist n_sample False assertEqual prob_dist dim assertEqual sample_indices size n_sample i range n_row row_samples = zero_prob_idx = zero_prob_indices i j range n_sample sample_idx = sample_indices i j zero_prob_idx = assertNotEqual sample_idx zero_prob_idx msg= sampled index zero probability assertNotIn sample_idx row_samples sampled index twice row_samples sample_idx = True vector n_col = prob_dist = make_prob_dist n_col is_contiguous fill_ zero_prob_idx = index shouldn t sampled prob_dist zero_prob_idx = n_sample = sample_indices = torch multinomial prob_dist n_sample True sample_index sample_indices assertNotEqual sample_index zero_prob_idx msg= sampled index zero probability assertEqual sample_indices dim msg= wrong number dimensions assertEqual prob_dist dim msg= wrong number prob_dist dimensions assertEqual sample_indices size n_sample msg= wrong number samples CUDA misalignment issue n_row n_col = prob_dist = make_prob_dist n_row n_col True n_sample = sample_indices = torch multinomial prob_dist n_sample True assertEqual sample_indices dim msg= wrong number dimensions assertEqual sample_indices size n_sample msg= wrong number samples FIXME move test distributions onlyCUDA dtypes torch float torch double torch half test_multinomial_deterministic device dtype gen = torch Generator device=device trials = seed = prob_dist = torch rand device=device dtype=dtype n_sample = _ range trials gen manual_seed seed samples_ = torch multinomial prob_dist n_sample True generator=gen gen manual_seed seed samples_ = torch multinomial prob_dist n_sample True generator=gen assertEqual samples_ samples_ assertEqual samples_ dim msg= wrong number dimensions assertEqual samples_ size n_sample msg= wrong number samples FIXME move test distributions slowTest dtypes torch float test_multinomial_rng_state_advance device dtype corpus_size = freqs = torch ones corpus_size dtype=torch float device=device n_sample = samples = torch multinomial freqs n_sample replacement=True samples = torch multinomial freqs n_sample replacement=True samples = torch cat samples samples expect no more than repeating elements generated attempts probability least element being repeated surprisingly large assertLessEqual n_sample - samples unique size samples = torch multinomial freqs n_sample replacement=False samples = torch multinomial freqs n_sample replacement=False samples = torch cat samples samples expect no more than repeating elements generated attempts assertLessEqual n_sample - samples unique size _test_memory_format_transformations device input_generator_fn transformation_fn memory_format compare_data=True default_is_preserve=False assert memory_format == torch channels_last memory_format == torch channels_last_ d xc channels last tensor xc = input_generator_fn device xc memory dense looks like channels last We don t preserve non-dense striding TEST_WITH_TORCHINDUCTOR memory_format == torch channels_last xc = xc xc = xc clone = transformation_fn xc memory_format=torch preserve_format assertFalse clone is_contiguous assertTrue clone is_contiguous memory_format=memory_format TEST_WITH_TORCHINDUCTOR assertFalse xc is_contiguous assertFalse xc is_contiguous memory_format=memory_format compare_data assertEqual xc clone xc xc = input_generator_fn device clone = transformation_fn xc memory_format=torch contiguous_format assertTrue clone is_contiguous assertFalse clone is_contiguous memory_format=memory_format compare_data assertEqual xc clone xc xc = input_generator_fn device clone = transformation_fn xc default_is_preserve assertFalse clone is_contiguous assertTrue clone is_contiguous memory_format=memory_format assertTrue clone is_contiguous assertFalse clone is_contiguous memory_format=memory_format compare_data assertEqual xc clone xc TODO copy _like constructors stride permutation instead just layout TEST_WITH_TORCHINDUCTOR x = torch randn device=device _ range permutation = list range len x shape random shuffle permutation x = x permute permutation assertEqual x stride transformation_fn x memory_format=torch preserve_format stride test_memory_format_to device get_generator memory_format shape input_generator_fn device torch randn shape device=device dtype=torch float contiguous memory_format=memory_format input_generator_fn transformation_fn tensor kwargs tensor dtype=torch float kwargs formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes _test_memory_format_transformations device get_generator mf shape transformation_fn mf default_is_preserve=True test_memory_format_type device get_generator memory_format shape input_generator_fn device torch randn shape device=device dtype=torch float contiguous memory_format=memory_format input_generator_fn transformation_fn tensor kwargs tensor torch float kwargs formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes _test_memory_format_transformations device get_generator mf shape transformation_fn mf default_is_preserve=True test_memory_format_clone device get_generator memory_format shape input_generator_fn device torch randn shape device=device dtype=torch float contiguous memory_format=memory_format input_generator_fn transformation_fn tensor kwargs tensor clone kwargs formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes _test_memory_format_transformations device get_generator mf shape transformation_fn mf True default_is_preserve=True test_memory_format_factory_like_functions_preserve device get_generator memory_format shape input_generator_fn device torch randn shape device=device dtype=torch float contiguous memory_format=memory_format input_generator_fn transformation_fns = lambda t kwargs torch zeros_like t kwargs lambda t kwargs torch ones_like t kwargs lambda t kwargs torch randint_like t kwargs lambda t kwargs torch randint_like t kwargs lambda t kwargs torch randn_like t kwargs lambda t kwargs torch rand_like t kwargs lambda t kwargs torch full_like t kwargs lambda t kwargs torch empty_like t kwargs formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes transformation_fn transformation_fns _test_memory_format_transformations device get_generator mf shape transformation_fn mf compare_data=False default_is_preserve=True test_memory_format_type_shortcuts device get_generator memory_format shape dtype input_generator_fn device torch randn shape device=device dtype=dtype clamp \ round contiguous memory_format=memory_format input_generator_fn get_fn fn_name transformation_fn tensor kwargs fn = getattr tensor fn_name fn kwargs transformation_fn shortcuts = byte char double bool half int long short device == cpu shortcuts += bfloat formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes fn_name shortcuts _test_memory_format_transformations device get_generator mf shape torch float get_fn fn_name mf default_is_preserve=True Test float separately avoid float- float no-op mf shape formats_shapes _test_memory_format_transformations device get_generator mf shape torch float get_fn float mf default_is_preserve=True onlyCUDA test_memory_format_cpu_and_cuda_ops device get_generator memory_format shape input_generator_fn device torch randn shape device=device dtype=torch float contiguous memory_format=memory_format input_generator_fn transformation_cpu_fn tensor kwargs tensor cpu kwargs transformation_cuda_fn tensor kwargs tensor cuda kwargs formats_shapes = torch channels_last torch channels_last_ d mf shape formats_shapes _test_memory_format_transformations cuda get_generator mf shape transformation_cpu_fn mf default_is_preserve=True _test_memory_format_transformations cpu get_generator mf shape transformation_cuda_fn mf default_is_preserve=True FIXME move test_serialization onlyNativeDeviceTypes test_pickle_gradscaler device This test should pass cases cuda cuda available cuda available device cuda cuda available device cuda In case b disable themselves construction shouldn t try pickle workhorse attributes In case b enabled Workhorse attributes participate pickling none lazy-inited cuda Tensors because I don t want do cuda things device cuda In case b enabled we may also try lazy-initing _scale cuda tensor device = torch device device try_lazy_inits = True False GradScaler = partial torch GradScaler device=device type lazy_init_scale try_lazy_inits = GradScaler init_scale= growth_factor= backoff_factor= growth_interval= device type == cuda assertTrue is_enabled torch cuda amp common amp_definitely_not_available is_enabled assertTrue is_enabled lazy_init_scale Dummy scale call lazy-inits _scale Tensor scale torch tensor dtype=torch float device=device assertTrue _scale device type == device type The following three lines should work whether cuda available serialized = pickle dumps b = pickle loads serialized assertEqual b is_enabled is_enabled is_enabled assertEqual b get_scale assertEqual b get_growth_factor assertEqual b get_backoff_factor assertEqual b get_growth_interval assertEqual b _init_growth_tracker supplies dummy key test defaultdict s default_factory assertEqual b _per_optimizer_states fdsa torch amp grad_scaler _refresh_per_optimizer_state lazy_init_scale assertEqual b scale torch tensor dtype=torch float device=device FIXME move test distributions _test_multinomial_empty device replacement num_samples probs = torch ones device=device expected = torch empty num_samples dtype=torch int out = torch multinomial probs num_samples=num_samples replacement=replacement assertEqual out expected FIXME move test distributions test_multinomial_empty_w_replacement device _test_multinomial_empty device True _test_multinomial_empty device True FIXME move test distributions test_multinomial_empty_wo_replacement device _test_multinomial_empty device False _test_multinomial_empty device False onlyNativeDeviceTypes dtypes torch float torch double test_grad_scaling_unscale device dtype device = torch device device device = cuda device type == cuda cpu inv_scale = torch full dtype=torch float device=device found_inf = torch full dtype=torch float device=device size = g = torch full size size dtype=dtype device=device ginf = g clone ginf = float inf gnan = g clone gnan = float nan Tries selected combinations - contiguous grads - g clone t which contiguous still non overlapping dense - variants g clone which non overlapping dense Non overlapping dense grads route into multi tensor apply kernel others use fallback per-tensor kernel so we should try both cases = g clone g clone False g clone g clone t False g clone g clone False g clone g clone False g clone ginf clone True g clone gnan clone True g clone ginf clone True g clone gnan clone True ginf clone g clone True ginf clone g clone True grads has_inf cases found_inf zero_ torch _amp_foreach_non_finite_check_and_unscale_ grads found_inf inv_scale has_inf assertEqual found_inf assertEqual found_inf grad grads assertEqual grad torch ones_like grad rtol= e- atol= e- When passing lists mismatched dtypes raw _amp_foreach_non_finite_check_and_unscale_ call CUDA s expected fall back single-tensor TensorIterator kernel grads = g clone g dtype=torch float torch _amp_foreach_non_finite_check_and_unscale_ grads found_inf inv_scale grad grads assertEqual grad torch ones_like grad rtol= e- atol= e- Passing lists mismatched devices raw _amp_foreach_non_finite_check_and_unscale_ call should raise errors device type == cuda TEST_MULTIGPU assertRaisesRegex RuntimeError r Expected all tensors same device torch _amp_foreach_non_finite_check_and_unscale_ g clone g device= cuda found_inf inv_scale Creates list grads mismatched dtypes devices ensure scaler _unscale_grads_ organizes grads dtype device before calling _amp_foreach_non_finite_check_and_unscale_ each set If inject_inf = writes inf into one grad _unscale_grads_ find perfect_storm_grads inject_inf grads = g clone g clone g dtype=torch float g dtype=torch float device type == cuda TEST_MULTIGPU grads += g device= cuda g device= cuda g device= cuda dtype=torch float g device= cuda dtype=torch float inject_inf = grads inject_inf = float inf grads GradScaler = partial torch GradScaler device=device type scaler = GradScaler dummy_params = torch empty_like g g perfect_storm_grads - dummy_opt = torch optim SGD dummy_params lr= Ensures inf nan checking can find inf injected onto any grad perfect storm inject_inf range - len dummy_params found_inf = torch full dtype=torch float device=device grads = perfect_storm_grads inject_inf i p enumerate dummy_params p grad = grads i found_inf_per_device = scaler _unscale_grads_ dummy_opt inv_scale found_inf True inject_inf No inf injected ensures unscaling worked normally assertTrue sum v item v found_inf_per_device values == grad grads assertEqual grad torch ones_like grad rtol= e- atol= e- inf injected ensures inf found assertTrue sum v item v found_inf_per_device values == onlyNativeDeviceTypes dtypes torch float test_grad_scaling_update_scale device dtype growth = backoff = growth_interval = scale = torch full dtype=dtype device=device growth_tracker = torch full dtype=torch int device=device found_inf = torch full dtype=torch float device=device Simulates consecutive unskipped iterations torch _amp_update_scale_ scale growth_tracker found_inf growth backoff growth_interval assertEqual growth_tracker assertEqual scale torch _amp_update_scale_ scale growth_tracker found_inf growth backoff growth_interval assertEqual growth_tracker assertEqual scale Simulates skipped iteration found_inf fill_ torch _amp_update_scale_ scale growth_tracker found_inf growth backoff growth_interval assertEqual growth_tracker assertEqual scale skipIfTorchDynamo Failed running call_function sparse_coo_tensor See https github com pytorch pytorch issues onlyNativeDeviceTypes dtypes torch float test_grad_scaling_unscale_sparse device dtype device = torch device device scaler = torch GradScaler device=device type inv_scale = torch full dtype=dtype device=device found_inf = torch empty dtype=dtype device=device cur = found_inf device i = torch tensor device=device dtype=torch int v = torch tensor device=device dtype=torch float s = torch sparse_coo_tensor i v torch Size device=device dtype=dtype p = s clone assert p is_sparse opt = torch optim SGD p lr= p grad = s clone found_inf zero_ found_inf = scaler _unscale_grads_ opt inv_scale found_inf False cur assertEqual found_inf assertEqual p grad to_dense s to_dense v = torch FloatTensor float inf p grad = torch sparse_coo_tensor i v torch Size device=device dtype=dtype found_inf zero_ found_inf = scaler _unscale_grads_ opt inv_scale found_inf False cur assertEqual found_inf v = torch FloatTensor float nan p grad = torch sparse_coo_tensor i v torch Size device=device dtype=dtype found_inf zero_ found_inf = scaler _unscale_grads_ opt inv_scale found_inf False cur assertEqual found_inf p = s clone half assert p is_sparse opt = torch optim SGD p lr= p grad = s clone half found_inf zero_ found_inf = scaler _unscale_grads_ opt inv_scale found_inf True cur assertEqual found_inf assertEqual p grad to_dense s half to_dense Creates fp sparse tensor duplicated indices uncoalesced The uncoalesced representation does overflow fp coalesced representation would because + fp max _amp_non_finite_check_and_unscale_ should report overflow here i = torch LongTensor v = torch FloatTensor p grad = torch sparse_coo_tensor i v torch Size device=device dtype=torch float found_inf zero_ found_inf = scaler _unscale_grads_ opt inv_scale found_inf True cur assertEqual found_inf onlyNativeDeviceTypes test_grad_scaling_state_dict device device = torch device device GradScaler = partial torch GradScaler device=device type lazy_init_scale True False s = GradScaler init_scale= growth_factor= backoff_factor= growth_interval= s = GradScaler init_scale= growth_factor= backoff_factor= growth_interval= sets random value load_state_dict overwrite s _init_growth_tracker = lazy_init_scale Dummy scale call ensure scale tensor lazily initialized s scale torch full dtype=torch float device=device cuda == device type assertTrue isinstance s _scale torch cuda FloatTensor assertTrue isinstance s _scale torch FloatTensor s load_state_dict s state_dict assertEqual s get_scale assertEqual s get_growth_factor assertEqual s get_backoff_factor assertEqual s get_growth_interval assertEqual s _init_growth_tracker _run_scaling_case generalizes some single-optimizer test logic avoid too much copy-pasting below _run_scaling_case device run unskipped skipped atol= e- optimizer_ctor=torch optim SGD optimizer_kwargs=None Ensure scaling can disabled without changing user control flow enabled True False mod_control mod_scaling opt_control opt_scaling data loss_fn skip_iter = _create_scaling_case device=device optimizer_ctor=optimizer_ctor optimizer_kwargs=optimizer_kwargs For functionality test modest initial scale unrealistically-large growth factor so any potential errors growth factor handling will magnified GradScaler = partial torch GradScaler device=device scaler = GradScaler init_scale= growth_factor= enabled=enabled growth_interval= _ = run device data mod_control opt_control scaler loss_fn skip_iter False ret = run device data mod_scaling opt_scaling scaler loss_fn skip_iter True Allows run optionally different scaler instance scaler = ret ret scaler If scaling enabled scale factor should have been multiplied growth factor len data - skipped times backoff factor skipped times enabled net_growth = scaler get_growth_factor unskipped unskipped net_backoff = scaler get_backoff_factor skipped skipped assertTrue scaler get_scale == net_growth net_backoff assertTrue scaler get_scale == c s zip mod_control parameters mod_scaling parameters assertEqual c grad s grad atol=atol rtol= e- c_state s_state = opt_control state c opt_scaling state s k c_state assertEqual c_state k s_state k atol=atol rtol= e- msg=k assertEqual c s atol=atol rtol= e- onlyNativeDeviceTypes parametrize foreach fused None None True None None True optims optim optim optim_db optim optim_cls torch optim AdamW torch optim Adam torch optim SGD dtypes= torch float test_grad_scaling_autocast device dtype optim_info foreach fused try_pickle = False run device data model optimizer scaler loss_fn skip_iter try_scaling_api i input target enumerate data optimizer zero_grad torch autocast device_type=device dtype=torch half enabled=try_scaling_api output = model input loss = loss_fn output target try_scaling_api scaler scale loss backward i == skip_iter scaler is_enabled torch no_grad model weight grad fill_ float inf scaler step optimizer scaler update try_pickle scaler = pickle loads pickle dumps scaler loss backward scaler is_enabled i = skip_iter optimizer step scaler optimizer_ctor = optim_info optim_cls Compares no scaling + no autocasting against scaling + autocasting NOTE mkozuki With current way testing ` torch optim Adam ` failing spite ` foreach ` ` fused ` Giving some flexibility test might help context = contextlib nullcontext optimizer_ctor torch optim Adam torch optim AdamW functools partial context = partial assertRaises AssertionError context sets atol= e- because we re comparing pure fp arithmetic vs mixture fp fp _run_scaling_case device run unskipped= skipped= atol= e- optimizer_ctor=optimizer_ctor optimizer_kwargs= foreach foreach fused fused will picked up try_pickle within run try_pickle = True _run_scaling_case device run unskipped= skipped= atol= e- optimizer_ctor=optimizer_ctor optimizer_kwargs= foreach foreach fused fused Make sure parameters become nonsense when scaled gradients finite they get invalidated before ` optimizer step ` after ` GradScaler unscale_ ` _test_params_invalidated_with_grads_invalidated_between_unscale_and_step device dtype optim_info optimizer_ctor = optim_info optim_cls all_optim_inputs = _get_optim_inputs_including_global_cliquey_kwargs device dtype optim_info skip= differentiable optim_input all_optim_inputs model _ optimizer _ data loss_fn _ = _create_scaling_case device optimizer_ctor=optimizer_ctor optimizer_kwargs=optim_input kwargs scaler = torch GradScaler device=device init_scale= input target data optimizer zero_grad torch autocast device_type=device dtype=torch half output = model input loss = loss_fn output target scaler scale loss backward scaler unscale_ optimizer deliberately break grads j param enumerate model parameters param grad copy_ torch inf j torch nan scaler step optimizer scaler update assertTrue all p isnan any p isinf any p model parameters onlyNativeDeviceTypes optims optim optim optim_db optim optim_cls torch optim AdamW torch optim Adam torch optim SGD dtypes= torch float test_params_invalidated_with_grads_invalidated_between_unscale_and_step device dtype optim_info _test_params_invalidated_with_grads_invalidated_between_unscale_and_step device dtype optim_info onlyNativeDeviceTypes optims optim optim optim_db optim optim_cls torch optim AdamW torch optim Adam torch optim SGD dtypes= torch float torch _inductor config patch graph_partition True test_params_invalidated_with_grads_invalidated_and_graph_partition device dtype optim_info _test_params_invalidated_with_grads_invalidated_between_unscale_and_step device dtype optim_info onlyNativeDeviceTypes test_grad_scale_will_not_overflow device device = torch device device model = torch nn Linear device optimizer = torch optim Adam model parameters scaler = torch GradScaler device=device type growth_interval= growth_factor= init_scale= e optimizer zero_grad x = torch randn device y = e- torch randn device l = model x - y mean scaler scale l backward scaler step optimizer scaler update assert scaler _scale = float inf scaler _scale = float nan onlyNativeDeviceTypes test_grad_scaling_clipping device device = torch device device run device data model optimizer scaler loss_fn skip_iter try_scaling_api max_norm = A reasonable value actually has effect based printouts grads i input target enumerate data optimizer zero_grad output = model input loss = loss_fn output target try_scaling_api scaler scale loss backward torch nn utils clip_grad_norm_ model parameters max_norm scaler get_scale i == skip_iter scaler is_enabled model weight grad data fill_ float inf scaler step optimizer scaler update loss backward torch nn utils clip_grad_norm_ model parameters max_norm scaler is_enabled i = skip_iter optimizer step _run_scaling_case device type run unskipped= skipped= atol= e- onlyNativeDeviceTypes test_grad_scaling_clipping_separate_unscale device device = torch device device run device data model optimizer scaler loss_fn skip_iter try_scaling_api max_norm = A reasonable value actually has effect based printouts grads i input target enumerate data optimizer zero_grad output = model input loss = loss_fn output target try_scaling_api scaler scale loss backward i == skip_iter scaler is_enabled model weight grad data fill_ float inf scaler unscale_ optimizer torch nn utils clip_grad_norm_ model parameters max_norm error_if_nonfinite=False scaler step optimizer scaler update loss backward torch nn utils clip_grad_norm_ model parameters max_norm scaler is_enabled i = skip_iter optimizer step _run_scaling_case device type run unskipped= skipped= onlyNativeDeviceTypes test_grad_scaling_penalty device device = torch device device run device data model optimizer scaler loss_fn skip_iter try_scaling_api i input target enumerate data optimizer zero_grad output = model input loss = loss_fn output target try_scaling_api grad_params = torch autograd grad scaler scale loss model parameters create_graph=True inv_scale = scaler get_scale grad_params = p inv_scale p grad_params grad_params = torch autograd grad loss model parameters create_graph=True grad_norm = grad grad_params grad_norm += grad pow sum grad_norm = grad_norm sqrt loss = loss + grad_norm try_scaling_api scaler scale loss backward i == skip_iter scaler is_enabled model weight grad data fill_ float inf scaler step optimizer scaler update loss backward scaler is_enabled i = skip_iter optimizer step _run_scaling_case device type run unskipped= skipped= onlyNativeDeviceTypes test_grad_scaling_accumulation device device = torch device device run device data model optimizer scaler loss_fn skip_iter try_scaling_api iters_to_accumulate = i input target enumerate data output = model input loss = loss_fn output target loss = loss iters_to_accumulate try_scaling_api scaler scale loss backward loss backward i + iters_to_accumulate == try_scaling_api scaler step optimizer scaler update optimizer zero_grad optimizer step optimizer zero_grad _run_scaling_case device type run unskipped= skipped= onlyNativeDeviceTypes test_grad_scaling_multiple device device = torch device device Tests gradient scaling models optimizers both receive gradients losses Some logic here cannot reuse generic helper functions created -optimizer cases enabled True False mod_control mod_scaling opt_control opt_scaling data loss_fn skip_iter = \ _create_scaling_case device type mod_control mod_scaling opt_control opt_scaling = \ _create_scaling_models_optimizers device type GradScaler = partial torch GradScaler device=device type scaler = GradScaler init_scale= growth_factor= enabled=enabled growth_interval= run model model optimizer optimizer try_scaling_api i input target enumerate data optimizer zero_grad optimizer zero_grad output = model input output = model input loss = loss_fn output + output target loss = loss_fn output - output target try_scaling_api scaler scale loss backward retain_graph=True scaler scale loss backward i == skip_iter scaler is_enabled model weight grad data fill_ float inf As additional stress test separately unscale one optimizers scaler unscale_ optimizer scaler step optimizer scaler step optimizer scaler update loss backward retain_graph=True loss backward optimizer step scaler is_enabled i = skip_iter optimizer step run mod_control mod_control opt_control opt_control False run mod_scaling mod_scaling opt_scaling opt_scaling True The loss scale should have been multiplied growth factor times backoff factor once assertTrue scaler get_scale == scaler get_growth_factor scaler get_backoff_factor enabled c s zip chain mod_control parameters mod_control parameters chain mod_scaling parameters mod_scaling parameters assertEqual c s rtol= e- atol= e- onlyNativeDeviceTypes test_grad_scaler_pass_itself device device = torch device device GradScaler = partial torch amp GradScaler device=device type _PlaceHolderOptimizer torch optim Optimizer tester = __init__ params defaults=None defaults None defaults = super __init__ params defaults _step_supports_amp_scaling = True Optimizer _PlaceHolderOptimizer step closure=None grad_scaler=None tester assertTrue isinstance grad_scaler torch amp GradScaler tester assertFalse hasattr grad_scale tester assertFalse hasattr found_inf Optimizer _PlaceHolderOptimizer step closure=None tester assertTrue isinstance grad_scale torch Tensor tester assertTrue isinstance found_inf torch Tensor x = torch randn device m = torch nn Linear device o = Optimizer m parameters o = Optimizer m parameters scaler = GradScaler init_scale= torch autocast device_type=device type dtype=torch half y = m x loss = y mean scaler scale loss backward assertWarns FutureWarning scaler step o scaler step o scaler update onlyNativeDeviceTypes test_grad_scaler_deprecated_warning device device = torch device device GradScaler = torch cuda amp GradScaler cuda == device type torch cpu amp GradScaler assertWarnsRegex FutureWarning rf ` torch device type amp GradScaler\ args \ ` deprecated _ = GradScaler init_scale= dtypesIfCUDA torch float torch double torch half dtypesIfCPU torch float torch double torch bfloat torch half dtypes torch float torch double test_multinomial_cpu device dtype make_prob_dist shape is_contiguous is_contiguous dtype == torch half dtype == torch bfloat torch zeros shape device=device uniform_ dtype=dtype torch zeros shape device=device dtype=dtype uniform_ len shape == dtype == torch half dtype == torch bfloat torch zeros shape + device=device uniform_ dtype=dtype torch zeros shape + device=device dtype=dtype uniform_ num dim = new_shape = shape shape dtype == torch half dtype == torch bfloat prob_dist = torch zeros new_shape device=device uniform_ dtype=dtype prob_dist = torch zeros new_shape device=device dtype=dtype uniform_ prob_dist = prob_dist transpose prob_dist = prob_dist assert prob_dist is_contiguous sanity check prob_dist FIXME move elementwise ternary test suite As test fails Runtime Error raised XLA onlyNativeDeviceTypes test_where_scalar_handcrafted_values device Tests ScalarxScalar ScalarxTensor TensorxScalar variant ` where ` against NumPy version handcrafted values condition_shape = dtypes = torch bool torch uint torch int torch int torch int torch float torch float torch float torch complex torch complex shapes = torch no_grad tensors = torch empty shape dtype=dtype device=device fill_ shape dtype product shapes dtypes Use different values ` x ` ` y ` they output values which compared x_vals = True + j y_vals = itertools chain False + j tensors x x_vals y y_vals condition = torch empty condition_shape dtype=torch bool device=device bernoulli_ common_dtype = torch result_type x y check_equal condition x y condition_np = condition cpu numpy x_np = x cpu numpy isinstance x torch Tensor x y_np = y cpu numpy isinstance y torch Tensor y NumPy aggressively promotes double hence cast output correct dtype expected = torch from_numpy np where condition_np x_np y_np common_dtype result = torch where condition x y assertEqual expected result check_equal condition x y check_equal condition y x device_type == cuda check_equal condition torch tensor x y check_equal condition y torch tensor x isinstance y torch Tensor check_equal condition torch tensor y torch tensor x isinstance y torch Tensor y ndim check_equal torch tensor True x y check_equal torch tensor True y x skipIfTorchInductor FIXME test_hook_remove device Reference https github com pytorch pytorch issues _test_helper remove_hook install_hook tensor handle = None hook tensor remove_hook handle remove torch zeros_like tensor handle = tensor register_hook hook t = torch ones device=device requires_grad=True install_hook t First call backward t mean backward assertEqual t grad torch zeros_like t Second call backward t mean backward remove_hook After removing hook make sure usual gradient returned assertEqual t grad torch ones_like t assertEqual t grad torch zeros_like t _test_helper remove_hook=True _test_helper remove_hook=False FIXME get PyTorch XLA run test_testing This test should ideally test_testing py since pytorch xla runs tests test_torch py we have here skipXLA test_skip_xla device device_type == xla Should reach here assertTrue False FIXME get PyTorch XLA run test_testing This test should ideally test_testing py since pytorch xla runs tests test_torch py we have here expectedFailureXLA test_expected_failure_xla device device_type == xla assertTrue False FIXME get PyTorch XLA run test_testing This test should ideally test_testing py since pytorch xla runs tests test_torch py we have here test_assertRaisesRegex_ignore_msg_non_native_device device Verify assertRaisesRegex only checks Error ignores message non-native devices x = torch randn device=device t = torch empty dtype=torch int device=device random_ invalid_weight = torch randn device=device msg = weight tensor should defined either all classes no classes XLA raises RuntimeError different message assertRaisesRegex RuntimeError msg torch nn functional nll_loss x t weight=invalid_weight dtypes all_types_and_complex_and torch bool torch half torch bfloat torch complex test_copy_ device dtype can_cast src_dtype dst_dtype torch can_cast torch int torch uint returns True which isn t actually safe-cast This function returns False case is_unsigned_int dtype dtype torch uint is_unsigned_int dst_dtype is_unsigned_int src_dtype torch can_cast src_dtype dst_dtype make_tensor_wrapper shape dtype dtype torch complex Make tensor does support generating complex tensor make_tensor shape device=device dtype=dtype torch randn shape device=device dtype=dtype t = make_tensor_wrapper dtype src_dtypes = all_types_and_complex_and torch bool torch half torch bfloat torch complex src_dtype src_dtypes src = make_tensor_wrapper dtype=src_dtype t copy_ src dst = make_tensor_wrapper dtype=src_dtype can_cast src_dtype dtype rtol = None atol = None dtype torch half torch complex rtol = e- atol = e- dtype torch bfloat rtol = e- atol = e- assertEqual src dst copy_ t rtol=rtol atol=atol dtypes all_types_complex_float _and torch bool torch half torch bfloat torch complex torch uint torch uint torch uint test_item device dtype xla_unsupported_dtypes = torch uint torch uint torch uint torch float _e m fn torch float _e m torch float _e m fnuz torch float _e m fnuz torch device device type == xla dtype xla_unsupported_dtypes skipTest uint float implemented XLA t = torch ones device=device dtype=dtype assertEqual t item test__local_scalar_dense_with_empty_tensor device input = torch randn device=device assertRaisesRegex RuntimeError Empty tensor supported torch ops aten _local_scalar_dense input onlyNativeDeviceTypes test_masked_scatter_inplace_noncontiguous device t = torch zeros dtype=torch long device=device t_non_contig = t transpose t_contig = t_non_contig contiguous assert t_contig is_contiguous assert t_non_contig is_contiguous mask = torch tensor False True False True False False True True True True device=device mask_non_contig = mask transpose mask_contig = mask_non_contig contiguous assert mask_contig is_contiguous assert mask_non_contig is_contiguous source always converted contiguous op source = torch tensor device=device t contig mask contig expected = t_contig masked_scatter_ mask_contig source t non-contig mask non-contig actual = t_non_contig masked_scatter_ mask_non_contig source assertEqual actual expected t contig mask non-contig actual = t_contig masked_scatter_ mask_non_contig source assertEqual actual expected t non-contig mask contig actual = t_non_contig masked_scatter_ mask_contig source assertEqual actual expected Tests compare device s computation gold-standard CPU s TestDevicePrecision TestCase exact_dtype = True FIXME move indexing test suite onlyCUDA test_index_add_bfloat device inp_tensor = torch randn device= cpu bfloat t = torch tensor dtype=torch bfloat device= cpu index = torch tensor device= cpu out_cpu = inp_tensor index_add index t inp_tensor = inp_tensor device=device t = t device=device index = index device=device out_gpu = inp_tensor index_add index t assertEqual out_cpu out_gpu atol= e- rtol= FIXME move serialization test suite test_device_serialization device x = torch randn device=device tempfile NamedTemporaryFile f torch save x f f seek x_copy = torch load f assertEqual x_copy x assertIs type x_copy type x assertEqual x_copy device x device FIXME move serialization test suite deviceCountAtLeast test_multidevice_serialization devices x = torch randn device=devices torch randn device=devices tempfile NamedTemporaryFile f torch save x f f seek x_copy = torch load f original cp zip x x_copy assertEqual cp original assertIs type cp type original assertEqual cp device original device FIXME move data movement test suite deviceCountAtLeast test_copy_noncontig devices do_test d d x = torch tensor device=d y = torch tensor device=d assertNotEqual x dtype y dtype y copy_ x assertEqual y do_test cpu devices do_test devices cpu len devices do_test devices devices deviceCountAtLeast test_type_conversions_same_device devices x = torch randn device=devices assertEqual x int device torch device devices assertEqual x type torch int device torch device devices assertEqual x torch int device torch device devices dtypesIfCUDA torch half torch float torch double torch int torch short torch int torch long torch uint dtypes torch float torch double torch int torch short torch int torch long torch uint test_from_sequence device dtype seq = list range i i + i range reference = torch arange resize_ assertEqual torch tensor seq dtype=dtype device=device reference exact_dtype=False FIXME moved indexing test suite deviceCountAtLeast test_advancedindex_mixed_cpu_devices devices - None test x torch Tensor ia torch Tensor ib torch Tensor - None test getitem assertEqual x ia None ib cpu x cpu ia cpu None ib cpu assertEqual x ia x cpu ia cpu test setitem x_clone = x clone x_clone = x clone first_shape = x ia None ib shape second_shape = x ia shape x_clone ia None ib = torch randn first_shape x_clone x_clone ia = torch randn second_shape x_clone cpu = torch device cpu device devices x = torch randn ia = torch tensor ib = torch tensor Index device tensor cpu tensor x = x device ia = ia cpu ib = ib cpu test x ia ib Index device tensor mixed cpu device tensors x = x device ia = ia cpu ib = ib device test x ia ib deviceCountAtLeast test_advancedindex_mixed_devices_error devices - None test x torch Tensor ia torch Tensor ib torch Tensor - None test getitem assertRaisesRegex RuntimeError fr indices should either \ x device \ x ia None ib assertRaisesRegex RuntimeError fr indices should either \ x device \ x ib cpu = torch device cpu device devices Index cpu tensor device tensor x = torch randn ia = torch tensor device ib = torch tensor device test x ia ib Index cpu tensor mixed cpu device tensors x = x cpu ia = ia cpu ib = ib device test x ia ib len devices other_device = devices device == devices devices Index device tensor mixed cpu device tensors different devices x = x device ia = ia cpu ib = ib other_device test x ia ib FIXME move data movement test suite test_copy_broadcast device - None x = torch randn y = torch randn device=device x copy_ y assertEqual x y x = torch randn device=device y = torch randn x copy_ y assertEqual x y FIXME move elementwise ternary test suite dtypes torch int torch float torch float test_clamp device dtype test_args = product shape True False non-contiguous shape noncontig test_args x = make_tensor shape device=device dtype=dtype noncontiguous=noncontig ub = make_tensor shape device=device dtype=dtype noncontiguous=noncontig lb = make_tensor shape device=device dtype=dtype noncontiguous=noncontig expect = x max lb min ub actual = x clamp lb ub assertEqual expect actual expect = np clip x cpu numpy lb cpu numpy ub cpu numpy assertEqual expect actual expect = x max lb actual = x clamp min=lb assertEqual expect actual expect = x min ub actual = x clamp max=ub assertEqual expect actual Test broadcasting min max expect = x max lb min ub actual = x clamp lb ub assertEqual expect actual Test broadcasting x expect = x max lb min ub actual = x clamp lb ub assertEqual expect actual test_cuda_device_idx device x = torch zeros device=device y = torch _efficientzerotensor device=device assertEqual x device y device we implemented custom deallocation subclasses so behooves us make sure all these bits work We ll use __del__ track objects die Tracker __init__ marker marker = marker staticmethod make marker = False marker Tracker marker __del__ marker = True contextlib contextmanager disable_gc gc isenabled try gc disable yield finally gc enable yield TestTorch TestCase exact_dtype = True test_dir dir torch test_wildcard_import exec torch test_newaxis_numpy_comparison run_test tensor idx npt = tensor numpy assertEqual tensor idx npt idx D Tensor Tests x = torch arange cases = None None None Ellipsis None None Ellipsis None None Ellipsis None Ellipsis None Ellipsis None None Ellipsis None Ellipsis None Ellipsis case cases run_test x case D Tensor Tests x = torch arange view cases = None None None None None None Ellipsis None Ellipsis None None None Ellipsis None Ellipsis None None None Ellipsis None None Ellipsis Ellipsis None None Ellipsis Ellipsis None Ellipsis None None Ellipsis None Ellipsis None Ellipsis None Ellipsis None Ellipsis None None Ellipsis None Ellipsis None Ellipsis case cases run_test x case _consecutive size start= sequence = torch ones torch tensor size prod cumsum sequence add_ start - sequence resize_ size test_newindex reference = _consecutive This relies __index__ being correct - we have separate tests checkPartialAssign index reference = torch zeros reference index = _consecutive index assertEqual reference index _consecutive index atol= rtol= reference index = assertEqual reference torch zeros atol= rtol= checkPartialAssign checkPartialAssign checkPartialAssign checkPartialAssign checkPartialAssign checkPartialAssign checkPartialAssign torch LongTensor assertRaises IndexError reference = assertRaises IndexError reference = assertRaises IndexError reference = assertRaises IndexError reference = assertRaises TypeError reference = assertRaises IndexError reference = assertRaises IndexError reference = assertRaises IndexError reference = assertRaises IndexError reference = Test ` torch _check ` functions test_check test_cases = check function expected error torch _check RuntimeError torch _check_index IndexError torch _check_value ValueError torch _check_type TypeError torch _check_not_implemented NotImplementedError check_fn expected_error test_cases cond=True should raise error check_fn True Test default failure message cond=False default_message = Expected cond True assertRaisesRegex expected_error default_message check_fn False Test simple failure message message = message assertRaisesRegex expected_error message check_fn False lambda message Test message tensor message torch arange assertRaisesRegex expected_error re escape str message check_fn False message Test format string message message f test True True torch arange assertRaisesRegex expected_error re escape str message check_fn False message Test incorrect ` cond ` arg type assertRaisesRegex TypeError cond must bool check_fn wrong type assertRaisesRegex TypeError cond must bool check_fn torch tensor True FIXME move indexing test suite test_index_add device get_all_device_types dest_contig src_contig index_contig product True False repeat= other_sizes dtype torch int torch long num_copy num_dest = dest = torch randn num_dest other_sizes device=device dest_contig dest = make_tensor dest shape device=device dtype=dest dtype noncontiguous=True src = torch randn num_copy other_sizes device=device src_contig src = noncontiguous_like src idx = torch randperm num_dest dtype=dtype device=device narrow num_copy index_contig idx = noncontiguous_like idx index_add_ without alpha argument dest = dest clone dest index_add_ idx src i range idx size dest idx i += src i assertEqual dest dest index_add_ alpha argument dest = dest clone dest index_add_ idx src alpha= i range idx size dest idx i += src i assertEqual dest dest FIXME resolve comment below move indexing test suite add coverage issue atomic add appeared only specific dtypes cuda https github com pytorch pytorch issues test_index_add_all_dtypes device get_all_device_types dtype get_all_math_dtypes device idx_dtype torch int torch long size = dtype is_floating_point dtype is_complex tensor = torch rand size dtype=dtype device=device dtype is_signed tensor = torch randint - size dtype=dtype device=device tensor = torch randint size dtype=dtype device=device index_add calls atomicAdd cuda zeros = torch zeros size dtype=dtype device=device added = zeros index_add torch arange size dtype=idx_dtype device=device tensor assertEqual added tensor added = zeros index_add torch arange size dtype=idx_dtype device=device tensor alpha=- assertEqual added -tensor unittest mock patch object torch _dynamo config suppress_errors False set_default_dtype torch double test_index_add_correctness Check whether index_add can get correct result when alpha dtype index torch long i e using scatter_add helper dim dtype device size_result size_source tensor = torch zeros size_result dtype=dtype device=device index = torch randint size_result dim size_source dim dtype=torch long device=device dtype is_floating_point dtype is_complex source = torch rand size_source dtype=dtype device=device dtype is_signed source = torch randint - size_source dtype=dtype device=device source = torch randint size_source dtype=dtype device=device ref_out = tensor index_add dim index source alpha= ref_out = ref_out dtype=dtype out = tensor index_add dim index source device == cuda assertEqual out ref_out atol= e- rtol= e- scatter_add uses fp accumulate type while index_add doesn t assertEqual out ref_out dtype=dtype atol= e- rtol= e- dim - - - dtype all_types_and_complex_and torch half torch bfloat device get_all_device_types size helper dim dtype device size size Check bound result = torch zeros dtype=dtype source = torch ones dtype=dtype index = torch ones dtype=torch long assertRaises RuntimeError lambda result index_add_ dim index source index = torch ones dtype=torch long assertRaises RuntimeError lambda result index_add_ dim index source test_index_add_cornercase device get_all_device_types dest = torch randn device=device index = torch tensor device=device source = torch randn device=device assertRaisesRegex RuntimeError r source tensor shape must match tensor shape excluding specified dimension dest index_add index source test_linspace_logspace Ensure output does require grad regardless inputs requiring guard The output factory functions should part any computational graph start = end = step assertFalse torch linspace torch tensor start requires_grad=True torch tensor end requires_grad=True step requires_grad assertFalse torch linspace torch tensor start requires_grad=True end step requires_grad assertFalse torch linspace start torch tensor end requires_grad=True step requires_grad assertFalse torch logspace torch tensor start requires_grad=True torch tensor end requires_grad=True step requires_grad assertFalse torch logspace torch tensor start requires_grad=True end step requires_grad assertFalse torch logspace start torch tensor end requires_grad=True step requires_grad FIXME move shape ops test suite test_unflatten test args tensor int sizes assertEqual torch tensor unflatten torch empty assertEqual torch tensor unflatten torch tensor assertEqual torch tensor unflatten torch tensor assertEqual torch tensor unflatten torch tensor assertEqual torch tensor unflatten torch Size torch tensor assertEqual torch ones unflatten torch ones assertEqual torch tensor unflatten - torch tensor assertEqual torch ones unflatten - torch ones assertEqual torch ones unflatten - torch ones assertEqual torch ones unflatten - torch ones assertEqual torch ones unflatten - torch ones test invalid args tensor str sizes assertRaisesRegex TypeError r unflatten\ \ argument dim \ position \ must int str torch tensor unflatten A test invalid args tensor str namedshape assertRaisesRegex RuntimeError r Name A found Tensor\ None\ torch ones unflatten A A B test other invalid arguments assertRaisesRegex RuntimeError r sizes must non-empty torch tensor unflatten assertRaisesRegex RuntimeError r Provided sizes \ \ don t multiply up size dim \ \ torch tensor unflatten assertRaisesRegex RuntimeError r Dimension specified tensor has no dimensions torch tensor unflatten assertRaisesRegex RuntimeError r only one dimension can inferred torch randn unflatten - - assertRaisesRegex RuntimeError r Provided sizes \ - \ don t multiply up size dim \ \ torch randn unflatten - assertRaisesRegex RuntimeError r unspecified dimension size - can any value ambiguous torch randn unflatten - Test warnings generated C++ translated correct type test_warn_types test_cases = function warning type message torch _C _warn UserWarning r Test message TORCH_WARN torch _C _warn_deprecation DeprecationWarning r Test message TORCH_WARN_DEPRECATION fn warning_type message test_cases warnings catch_warnings record=True w warnings resetwarnings warnings filterwarnings always category=warning_type fn assertEqual len w msg=f warning_type raised warning = w message assertTrue isinstance warning warning_type msg=f warning_type raised assertTrue re search message str warning test_structseq_repr = torch arange reshape expected = torch return_types max values=tensor indices=tensor assertEqual repr max textwrap dedent expected strip test_is_same_size t = torch empty t = torch empty t = torch empty t = torch empty assertFalse t is_same_size t assertFalse t is_same_size t assertTrue t is_same_size t nt = torch nested nested_tensor torch ones torch ones torch ones nt = torch nested nested_tensor torch ones torch ones torch ones nt = torch nested nested_tensor torch ones torch ones nt = torch nested nested_tensor torch ones torch ones torch ones assertFalse nt is_same_size nt assertFalse nt is_same_size nt assertTrue nt is_same_size nt assertRaisesRegex RuntimeError Expected both other nested tensors t is_same_size nt assertRaisesRegex RuntimeError Expected both other nested tensors nt is_same_size t test_tensor_set t = torch tensor t = torch empty uniform_ t set_ t assertEqual t storage _cdata t storage _cdata size = torch Size t set_ t storage size assertEqual t size size t set_ t storage tuple size assertEqual t size size assertEqual t stride stride = t set_ t storage size stride assertEqual t stride stride t set_ t storage size=size stride=stride assertEqual t size size assertEqual t stride stride test argument names t = torch tensor case when source tensor t set_ source=t assertEqual t storage _cdata t storage _cdata case when source storage t set_ source=t storage assertEqual t storage _cdata t storage _cdata case when source storage other args also specified t set_ source=t storage storage_offset= size=size stride=stride assertEqual t size size assertEqual t stride stride t = torch tensor True True dtype=torch bool t = torch tensor False False dtype=torch bool t set_ t assertEqual t storage _cdata t storage _cdata test_tensor_set_errors f_cpu = torch randn dtype=torch float d_cpu = torch randn dtype=torch float storage_offset = x assertRaisesRegex RuntimeError out bounds storage size t = torch randn t set_ t untyped_storage storage_offset t size size changes set_ will resize storage inplace t = torch randn size = torch Size t set_ t untyped_storage storage_offset size assertEqual t storage_offset storage_offset assertEqual t untyped_storage nbytes storage_offset + size size change dtype assertRaises RuntimeError lambda f_cpu set_ d_cpu storage assertRaises RuntimeError lambda f_cpu set_ d_cpu storage d_cpu size d_cpu stride assertRaises RuntimeError lambda f_cpu set_ d_cpu change device torch cuda is_available f_cuda = torch randn dtype=torch float device= cuda cpu - cuda assertRaises RuntimeError lambda f_cpu set_ f_cuda storage assertRaises RuntimeError lambda f_cpu set_ f_cuda storage f_cuda size f_cuda stride assertRaises RuntimeError lambda f_cpu set_ f_cuda cuda - cpu assertRaises RuntimeError lambda f_cuda set_ f_cpu storage assertRaises RuntimeError lambda f_cuda set_ f_cpu storage f_cpu size f_cpu stride assertRaises RuntimeError lambda f_cuda set_ f_cpu FIXME move test test_testing py along allclose testing NOTE test_equal will deprecated favor torch testing assert_close once torch testing out beta test_equal device cpu cuda device == cuda torch cuda is_available continue Contiguous D t = torch tensor device=device t = t contiguous t = torch tensor device=device t = torch tensor device=device t = torch tensor device=device assertTrue t equal t assertFalse t equal t assertFalse t equal t assertFalse t equal t assertTrue torch equal t t assertFalse torch equal t t assertFalse torch equal t t assertFalse torch equal t t Non contiguous D s = torch tensor device=device s = s s = s clone s = torch tensor device=device s = torch tensor device=device assertFalse s is_contiguous assertTrue s equal s assertTrue s equal s assertFalse s equal s assertTrue torch equal s s assertTrue torch equal s s assertFalse torch equal s s Different dtypes x = torch tensor dtype=torch float device=device y = torch tensor dtype=torch int device=device z = torch tensor - dtype=torch int device=device assertTrue torch equal x y assertFalse torch equal z x Fast path test tensor flags like neg conj neg_ = torch tensor dtype=torch float device=device neg_ = neg_ _neg_view assertTrue neg_ is_neg assertEqual neg_ data_ptr neg_ data_ptr assertEqual neg_ storage_offset neg_ storage_offset assertEqual neg_ stride neg_ stride assertEqual neg_ size neg_ size assertFalse torch equal neg_ neg_ FIXME Disable following check due inductor failure See https github com pytorch pytorch issues https github com pytorch pytorch issues TEST_WITH_TORCHINDUCTOR assertTrue torch equal neg_ neg_ _neg_view conj_ = torch tensor + j + j device=device conj_ = conj_ conj assertTrue conj_ is_conj assertEqual conj_ data_ptr conj_ data_ptr assertEqual conj_ storage_offset conj_ storage_offset assertEqual conj_ stride conj_ stride assertEqual conj_ size conj_ size assertFalse torch equal conj_ conj_ FIXME Disable following check due inductor failure See https github com pytorch pytorch issues https github com pytorch pytorch issues TEST_WITH_TORCHINDUCTOR assertTrue torch equal conj_ conj_ conj Fast path test two tensors share same storage different dtype s_ = torch rand dtype=torch float device=device s_ = s_ view dtype=torch int assertEqual s_ data_ptr s_ data_ptr assertEqual s_ storage_offset s_ storage_offset assertEqual s_ stride s_ stride assertEqual s_ size s_ size assertFalse torch equal s_ s_ Fast path test two tensors share same storage different strides t_ = torch rand dtype=torch float device=device t_ = t_ t assertEqual t_ data_ptr t_ data_ptr assertEqual t_ storage_offset t_ storage_offset assertNotEqual t_ stride t_ stride assertNotEqual t_ size t_ size assertFalse torch equal t_ t_ Fast path tensor containing ` nan ` equal dtype floating_and_complex_types t = torch tensor float nan dtype=dtype assertFalse torch equal t t test_element_size byte = torch ByteStorage element_size char = torch CharStorage element_size short = torch ShortStorage element_size int = torch IntStorage element_size long = torch LongStorage element_size float = torch FloatStorage element_size double = torch DoubleStorage element_size bool = torch BoolStorage element_size bfloat = torch BFloat Storage element_size complexfloat = torch ComplexFloatStorage element_size complexdouble = torch ComplexDoubleStorage element_size assertEqual byte torch ByteTensor element_size assertEqual byte torch ByteTensor itemsize assertEqual char torch CharTensor element_size assertEqual char torch CharTensor itemsize assertEqual short torch ShortTensor element_size assertEqual short torch ShortTensor itemsize assertEqual int torch IntTensor element_size assertEqual int torch IntTensor itemsize assertEqual long torch LongTensor element_size assertEqual long torch LongTensor itemsize assertEqual float torch FloatTensor element_size assertEqual float torch FloatTensor itemsize assertEqual double torch DoubleTensor element_size assertEqual double torch DoubleTensor itemsize assertEqual bool torch BoolTensor element_size assertEqual bool torch BoolTensor itemsize assertEqual bfloat torch tensor dtype=torch bfloat element_size assertEqual bfloat torch tensor dtype=torch bfloat itemsize assertEqual complexfloat torch tensor dtype=torch complex element_size assertEqual complexfloat torch tensor dtype=torch complex itemsize assertEqual complexdouble torch tensor dtype=torch complex element_size assertEqual complexdouble torch tensor dtype=torch complex itemsize assertGreater byte assertGreater char assertGreater short assertGreater int assertGreater long assertGreater float assertGreater double assertGreater bool assertGreater bfloat assertGreater complexfloat assertGreater complexdouble These tests portable necessarily strict your system assertEqual byte assertEqual char assertEqual bool assertGreaterEqual short assertGreaterEqual int assertGreaterEqual int short assertGreaterEqual long assertGreaterEqual long int assertGreaterEqual double float test_permute orig = perm = torch randperm tolist x = torch empty orig fill_ new = i - i x permute perm size assertEqual perm new assertEqual x size orig skipIfTorchDynamo TorchDynamo fails unknown reason test_reversed val = torch arange assertEqual reversed val torch arange - - val = torch arange view assertEqual reversed val torch tensor val = torch tensor assertEqual reversed val torch tensor test_contains x = torch arange assertEqual x True assertEqual x False x = torch arange view val = torch arange assertEqual val x True val += assertEqual val x False assertRaisesRegex RuntimeError f Tensor __contains__ only supports Tensor scalar you passed str lambda foo x assertRaisesRegex RuntimeError f Tensor __contains__ only supports Tensor scalar you passed type lambda x skipIfTorchDynamo TorchDynamo fails unknown reason test_deepcopy_parameter copy deepcopy l = torch nn Linear s = l state_dict keep_vars=True assertEqual torch nn Parameter type s weight assertEqual torch nn Parameter type s bias s = deepcopy s assertEqual torch nn Parameter type s weight assertEqual torch nn Parameter type s bias test_pickle pickle = torch randn serialized = pickle dumps b = pickle loads serialized assertEqual b skipIfTorchDynamo TorchDynamo fails unknown reason test_pickle_parameter pickle = torch nn Parameter torch randn serialized = pickle dumps b = pickle loads serialized assertTrue isinstance b torch nn Parameter assertEqual requires_grad b requires_grad assertEqual b skipIfTorchDynamo TorchDynamo fails unknown reason test_pickle_parameter_no_requires_grad pickle = torch nn Parameter torch randn requires_grad=False serialized = pickle dumps b = pickle loads serialized assertTrue isinstance b torch nn Parameter assertEqual requires_grad b requires_grad assertEqual b test_pickle_dtype t = torch float serialized = pickle dumps t b = pickle loads serialized assertTrue isinstance b torch dtype assertEqual id b id t test_pickle_size = torch rand size serialized = pickle dumps b = pickle loads serialized assertTrue isinstance b torch Size assertEqual b test_pickle_function https github com pytorch pytorch issues = torch tanh serialized = pickle dumps b = pickle loads serialized assertEqual b test_generator_cpu test default generators equal assertEqual torch default_generator torch default_generator tests Generator API manual_seed seed initial_seed get_state set_state g = torch Generator g = torch Generator g manual_seed g manual_seed assertEqual g initial_seed g initial_seed g seed g seed assertNotEqual g initial_seed g initial_seed g = torch Generator g _state = g get_state g _randn = torch randn generator=g g set_state g _state g _randn = torch randn generator=g assertEqual g _randn g _randn default_state = torch default_generator get_state q = torch empty g _normal = q normal_ g = torch Generator g set_state default_state g _normal = q normal_ generator=g assertEqual g _normal g _normal test_invalid_generator_raises assertRaises RuntimeError lambda torch Generator opengl test_pickle_generator - None devices = cpu torch cuda is_available devices += cuda device devices subTest device=device generator = torch Generator device=device manual_seed device = cpu generator set_offset torch randn generator=generator device=device progress RNG state reserialized torch Generator = pickle loads pickle dumps generator assertEqual generator device reserialized device assertEqual generator initial_seed reserialized initial_seed device = cpu assertEqual generator get_offset reserialized get_offset torch testing assert_close generator get_state reserialized get_state _sobol_reference_samples scramble bool - torch Tensor scramble theoretical values Joe Kuo torch tensor theoretical values unknown convergence properties checked torch tensor test_sobolengine_bounds scramble bool = False engine = torch quasirandom SobolEngine scramble=scramble seed= sample = engine draw assertTrue torch all sample = assertTrue torch all sample = test_sobolengine_bounds_scrambled test_sobolengine_bounds scramble=True test_sobolengine_draw scramble bool = False ref_sample = _sobol_reference_samples scramble=scramble engine = torch quasirandom SobolEngine scramble=scramble seed= sample = engine draw n=len ref_sample assertEqual sample ref_sample assertEqual engine num_generated len ref_sample test_sobolengine_draw_scrambled test_sobolengine_draw scramble=True test_sobolengine_first_point dtype torch float torch double engine = torch quasirandom SobolEngine scramble=False sample = engine draw dtype=dtype assertTrue torch all sample == assertEqual sample dtype dtype dtype torch float torch double engine = torch quasirandom SobolEngine scramble=True seed= sample = engine draw dtype=dtype assertTrue torch all sample = assertEqual sample dtype dtype test_sobolengine_continuing scramble bool = False ref_sample = _sobol_reference_samples scramble=scramble engine = torch quasirandom SobolEngine scramble=scramble seed= n_half = len ref_sample _ = engine draw n=n_half sample = engine draw n=n_half torch testing assert_close sample ref_sample n_half test_sobolengine_continuing_scrambled test_sobolengine_continuing scramble=True test_sobolengine_reset scramble bool = False ref_sample = _sobol_reference_samples scramble=scramble engine = torch quasirandom SobolEngine scramble=scramble seed= _ = engine draw n=len ref_sample engine reset assertEqual engine num_generated sample = engine draw n=len ref_sample torch testing assert_close sample ref_sample test_sobolengine_reset_scrambled test_sobolengine_reset scramble=True test_sobolengine_fast_forward scramble bool = False ref_sample = _sobol_reference_samples scramble=scramble engine = torch quasirandom SobolEngine scramble=scramble seed= engine fast_forward sample = engine draw n= torch testing assert_close sample ref_sample alternate fast forwarding sampling engine reset even_draws = i range i == even_draws append engine draw engine fast_forward torch testing assert_close ref_sample i i range i == torch from_numpy np concatenate even_draws test_sobolengine_fast_forward_scrambled test_sobolengine_fast_forward scramble=True test_sobolengine_default_dtype engine = torch quasirandom SobolEngine dimension= scramble=True seed= Check default dtype correctly handled assertEqual engine draw n= dtype torch float set_default_dtype torch float engine = torch quasirandom SobolEngine dimension= scramble=True seed= Check default dtype correctly handled when set float assertEqual engine draw n= dtype torch float Check explicitly passed dtype adhered assertEqual engine draw n= dtype=torch float dtype torch float Reinitialize engine check first draw dtype correctly handled engine = torch quasirandom SobolEngine dimension= scramble=True seed= assertEqual engine draw n= dtype=torch float dtype torch float skipIfTorchDynamo np float restored float after graph break test_sobolengine_distribution scramble=False d = engine = torch quasirandom SobolEngine d scramble=scramble seed= sample = engine draw torch testing assert_close torch mean sample dim= torch full d atol= rtol= torch testing assert_close np percentile sample axis= astype np float np repeat d atol= rtol= torch testing assert_close np percentile sample axis= astype np float np repeat d atol= rtol= skipIfTorchDynamo np float restored float after graph break test_sobolengine_distribution_scrambled test_sobolengine_distribution scramble=True test_sobolengine_draw_base scramble=False ref_sample = _sobol_reference_samples scramble=scramble engine = torch quasirandom SobolEngine scramble=scramble seed= sample = engine draw_base assertEqual ref_sample sample resampling still having N= n sample = engine draw_base assertEqual ref_sample sample test_sobolengine_draw_base _scrambled test_sobolengine_draw_base scramble=True test_sobolengine_raise maxdim = torch quasirandom SobolEngine MAXDIM assertRaises ValueError torch quasirandom SobolEngine maxdim + test_sobolengine_high_dim engine = torch quasirandom SobolEngine scramble=False seed= samples = engine draw vals counts = torch unique samples return_counts=True samples = engine draw vals counts = torch unique samples return_counts=True assertEqual vals item assertEqual counts item assertEqual vals item assertEqual counts item test_parsing_int accepts integer arguments x = torch cumsum torch ones assertEqual x torch cumsum torch ones torch tensor doesn t accept floating point variables assertRaises TypeError lambda torch cumsum torch ones torch tensor test_parsing_double accepts floating point integer arguments x = torch randn torch isclose x x assertTrue torch isclose x x all assertTrue torch isclose x x all accepts floating point integer tensors assertTrue torch isclose x x torch tensor torch tensor all assertTrue torch isclose x x torch tensor torch tensor all doesn t accept variables requires_grad assertRaises TypeError lambda torch isclose x x torch tensor torch tensor requires_grad=True all test_parsing_intlist parse integer variables assertEqual torch Size torch ones torch tensor torch tensor shape assertEqual torch Size torch ones torch tensor torch tensor shape parse numpy integers assertEqual torch Size torch ones np array np int shape assertEqual torch Size torch ones np array np int shape assertEqual torch Size torch ones np int np array shape assertEqual torch Size torch ones np int np array shape fail parse float variables assertRaises TypeError lambda torch ones torch tensor torch tensor fail parse numpy floats assertRaises TypeError lambda torch ones torch tensor assertRaises TypeError lambda torch ones np array torch tensor fail parse element variables assertRaises TypeError lambda torch ones torch tensor assertRaises TypeError lambda torch ones torch tensor assertRaises TypeError lambda torch ones np array assertRaises TypeError lambda torch ones np array fail parse additional positional args after intlist arg assertRaisesRegex TypeError received invalid combination arguments lambda torch LongTensor assertRaisesRegex TypeError missing required positional arguments lambda torch tensor new_zeros test_from_buffer = bytearray assertEqual torch ByteStorage from_buffer tolist shorts = torch ShortStorage from_buffer big assertEqual shorts size assertEqual shorts tolist ints = torch IntStorage from_buffer little assertEqual ints size assertEqual ints f = bytearray x x x x floats = torch FloatStorage from_buffer f big assertEqual floats size assertEqual floats f = bytearray x x x x x x x x bools = torch BoolStorage from_buffer f big assertEqual bools size assertEqual bools tolist False True True True True True True True assertEqual bools type torch BoolStorage assertTrue isinstance bools torch BoolStorage f = bytearray b \x \x \x a\nl\xfc\x cF\xf j\xa P\x \x \x M\xe bools = torch BoolStorage from_buffer f big assertEqual bools size f = bytearray b \ x A bools = torch BoolStorage from_buffer f big assertEqual bools size assertEqual bools tolist False True True True bytes = torch ByteStorage from_buffer assertEqual bytes nbytes assertEqual bytes tolist assertTrue isinstance bytes torch ByteStorage test_storage_error quantized_storages = torch QInt Storage torch QInt Storage torch QUInt x Storage torch QUInt x Storage torch QUInt Storage assertRaisesRegex RuntimeError r Only child classes _LegacyStorage can instantiated torch storage _LegacyStorage storage_class torch _storage_classes storage_class torch UntypedStorage torch TypedStorage continue device = cuda storage_class __module__ == torch cuda cpu dtype = storage_class dtype device == cuda torch cuda is_available continue Legacy type Storage constructor errors assertRaisesRegex RuntimeError r device cannot specified storage_class device= cpu assertRaisesRegex RuntimeError r dtype cannot specified storage_class dtype=torch float assertRaisesRegex TypeError r got unexpected keyword storage_class sdlkjf=torch float assertRaisesRegex RuntimeError r Too many positional arguments storage_class assertRaisesRegex TypeError r invalid data type storage_class string assertRaisesRegex TypeError r Argument type recognized storage_class torch tensor s = storage_class assertRaisesRegex RuntimeError r No positional arguments storage_class wrap_storage=s untyped assertRaisesRegex TypeError r must UntypedStorage storage_class wrap_storage=s torch cuda is_available storage_class quantized_storages assertRaisesRegex RuntimeError r Cannot create CUDA storage quantized dtype s cuda s is_cuda s_other_device = s cpu s_other_device = s cuda assertRaisesRegex RuntimeError r Device wrap_storage must storage_class wrap_storage=s_other_device untyped TypedStorage constructor errors assertRaisesRegex RuntimeError r No positional arguments torch TypedStorage wrap_storage=s untyped dtype=dtype assertRaisesRegex RuntimeError r Argument dtype must specified torch TypedStorage wrap_storage=s untyped assertRaisesRegex TypeError r Argument dtype must torch dtype torch TypedStorage wrap_storage=s untyped dtype= assertRaisesRegex RuntimeError r Argument device should specified torch TypedStorage wrap_storage=s untyped dtype=dtype device=device assertRaisesRegex TypeError r Argument wrap_storage must UntypedStorage torch TypedStorage wrap_storage=s dtype=dtype assertRaisesRegex RuntimeError r Storage device recognized torch TypedStorage dtype=dtype device= xla torch cuda is_available storage_class quantized_storages assertRaisesRegex RuntimeError r Cannot create CUDA storage quantized dtype torch TypedStorage dtype=dtype device= cuda assertRaisesRegex TypeError r Argument type recognized torch TypedStorage torch tensor dtype=dtype device=device assertRaisesRegex RuntimeError r Too many positional arguments torch TypedStorage dtype=dtype device=device isinstance s torch TypedStorage s_other = torch TypedStorage device=device dtype=dtype assertRaisesRegex RuntimeError r cannot set item s fill_ s_other test_storage_error_no_attribute storage_classes = torch cuda ByteStorage torch cuda FloatStorage storage_class storage_classes assertRaisesRegex RuntimeError r Not available CUDA storage storage_class from_buffer assertRaisesRegex RuntimeError r Not available CUDA storage storage_class _new_with_weak_ptr assertRaisesRegex RuntimeError r Not available CUDA storage storage_class _new_shared_filename test_storage_casts storage = torch IntStorage - assertEqual storage size assertEqual storage tolist - assertEqual storage type torch IntStorage assertIs storage dtype torch int floatStorage = storage float assertEqual floatStorage size assertEqual floatStorage tolist - assertEqual floatStorage type torch FloatStorage assertEqual floatStorage int tolist - assertIs floatStorage dtype torch float halfStorage = storage half assertEqual halfStorage size assertEqual halfStorage tolist - assertEqual halfStorage type torch HalfStorage assertEqual halfStorage int tolist - assertIs halfStorage dtype torch float bfloat Storage = storage bfloat assertEqual bfloat Storage size assertEqual bfloat Storage tolist - assertEqual bfloat Storage type torch BFloat Storage assertEqual bfloat Storage int tolist - assertIs bfloat Storage dtype torch bfloat longStorage = storage long assertEqual longStorage size assertEqual longStorage tolist - assertEqual longStorage type torch LongStorage assertEqual longStorage int tolist - assertIs longStorage dtype torch int shortStorage = storage short assertEqual shortStorage size assertEqual shortStorage tolist - assertEqual shortStorage type torch ShortStorage assertEqual shortStorage int tolist - assertIs shortStorage dtype torch int doubleStorage = storage double assertEqual doubleStorage size assertEqual doubleStorage tolist - assertEqual doubleStorage type torch DoubleStorage assertEqual doubleStorage int tolist - assertIs doubleStorage dtype torch float charStorage = storage char assertEqual charStorage size assertEqual charStorage tolist - assertEqual charStorage type torch CharStorage assertEqual charStorage int tolist - assertIs charStorage dtype torch int byteStorage = storage byte assertEqual byteStorage size assertEqual byteStorage tolist assertEqual byteStorage type torch ByteStorage assertEqual byteStorage int tolist assertIs byteStorage dtype torch uint boolStorage = storage bool assertEqual boolStorage size assertEqual boolStorage tolist True False True True True True assertEqual boolStorage type torch BoolStorage assertEqual boolStorage int tolist assertIs boolStorage dtype torch bool complexfloat_storage = torch ComplexFloatStorage - + j j - j assertEqual complexfloat_storage size assertEqual complexfloat_storage tolist - + j j - j assertEqual complexfloat_storage type torch ComplexFloatStorage assertIs complexfloat_storage dtype torch complex complexdouble_storage = complexfloat_storage complex_double assertEqual complexdouble_storage size assertEqual complexdouble_storage tolist - + j j - j assertEqual complexdouble_storage type torch ComplexDoubleStorage assertIs complexdouble_storage dtype torch complex test_storage_byteswap input = swapped_ bytes = swapped_ bytes = swapped_ bytes = swapped_ byte = storage = torch storage TypedStorage input dtype=torch uint _untyped_storage storage_f = storage __copy__ storage_f byteswap torch float assertEqual storage_f tolist swapped_ bytes storage_f = storage __copy__ storage_f byteswap torch float assertEqual storage_f tolist swapped_ bytes storage_f = storage __copy__ storage_f byteswap torch float assertEqual storage_f tolist swapped_ bytes storage_bf = storage __copy__ storage_bf byteswap torch bfloat assertEqual storage_bf tolist swapped_ bytes storage_i = storage __copy__ storage_i byteswap torch int assertEqual storage_i tolist swapped_ bytes storage_i = storage __copy__ storage_i byteswap torch int assertEqual storage_i tolist swapped_ bytes storage_i = storage __copy__ storage_i byteswap torch int assertEqual storage_i tolist swapped_ bytes storage_i = storage __copy__ storage_i byteswap torch int assertEqual storage_i tolist swapped_ byte storage_ui = storage __copy__ storage_ui byteswap torch uint assertEqual storage_ui tolist swapped_ byte storage_bool = storage __copy__ storage_bool byteswap torch bool assertEqual storage_bool tolist swapped_ byte storage_c = storage __copy__ storage_c byteswap torch complex assertEqual storage_c tolist swapped_ bytes storage_c = storage __copy__ storage_c byteswap torch complex assertEqual storage_c tolist swapped_ bytes Test internal versions functions related TypedStorage do produce deprecation warning test_typed_storage_internal_no_warning s = torch FloatStorage s _untyped = s untyped t = torch randn funcs = lambda torch FloatStorage _internal=True lambda torch TypedStorage dtype=torch float device= cpu _internal=True lambda torch TypedStorage wrap_storage=s _untyped dtype=s dtype _internal=True lambda torch FloatStorage _dtype lambda s _resize_ lambda s _size lambda s _untyped_storage lambda s _is_shared lambda s _share_memory_ lambda s _pickle_storage_type lambda s _setitem slice s _size lambda s _element_size lambda s _deepcopy lambda s _data_ptr lambda s _nbytes lambda t _typed_storage torch cuda is_available s = torch cuda FloatStorage s _untyped = s untyped t = torch randn device= cuda funcs += lambda torch cuda FloatStorage _internal=True lambda torch TypedStorage dtype=torch float device= cuda _internal=True lambda torch TypedStorage wrap_storage=s _untyped dtype=s dtype _internal=True lambda torch cuda FloatStorage _dtype lambda s _resize_ lambda s _size lambda s _untyped_storage lambda s _is_shared lambda s _share_memory_ lambda s _pickle_storage_type lambda s _setitem slice s _size lambda s _element_size lambda s _deepcopy lambda s _data_ptr lambda s _nbytes lambda t _typed_storage Check each TypedStorage internal function calls do produce deprecation warning f funcs warnings catch_warnings warnings filterwarnings error TypedStorage deprecated f Test public functions related TypedStorage produce deprecation warning skipIfTorchInductor FIXME test_typed_storage_deprecation_warning s = torch FloatStorage funcs = lambda torch FloatStorage lambda torch FloatStorage dtype lambda s fill_ lambda s is_cuda lambda s untyped lambda len s lambda s torch cuda is_available s = torch cuda FloatStorage funcs += lambda torch cuda FloatStorage lambda torch cuda FloatStorage dtype lambda s fill_ lambda s is_cuda lambda s untyped lambda len s lambda s Check each TypedStorage function calls produce warning warnings reset between each f funcs AlwaysWarnTypedStorageRemoval True warnings catch_warnings record=True w warnings resetwarnings f assertEqual len w msg=str str w warning = w message assertTrue warning DeprecationWarning assertTrue re search ^TypedStorage deprecated str warning Test only first warning raised default torch storage _reset_warn_typed_storage_removal warnings catch_warnings record=True w warnings resetwarnings torch FloatStorage torch randn storage assertEqual len w msg=str str w warning = w message assertTrue re search ^TypedStorage deprecated str warning Check line code warning s stack open w filename encoding= utf- f code_line = f readlines w lineno - assertTrue re search re escape torch FloatStorage code_line Check warnings emitted happened past warnings catch_warnings record=True w warnings resetwarnings torch FloatStorage torch randn storage assertEqual len w msg=str str w test_from_file assert_with_filename filename size = s = torch FloatStorage from_file filename True size t = torch FloatTensor s copy_ torch randn size assertEqual s data_ptr torch FloatTensor s data_ptr check mapping s = torch FloatStorage from_file filename True size t = torch FloatTensor s assertEqual t t atol= rtol= check changes t t rnum = random uniform - t fill_ rnum assertEqual t t atol= rtol= check changes t t rnum = random uniform - t fill_ rnum assertEqual t t atol= rtol= release tensors del s t s t TemporaryFileName fname assert_with_filename fname IS_FILESYSTEM_UTF _ENCODING TemporaryDirectoryName suffix= \u e d\u dname TemporaryFileName dir=dname fname assert_with_filename fname test_torch_from_file assert_with_filename filename size = s = torch from_file filename True size dtype=torch float t = torch FloatTensor s copy_ torch randn size check mapping s = torch from_file filename True size dtype=torch float t = torch FloatTensor s assertEqual t t atol= rtol= check changes t t rnum = random uniform - t fill_ rnum assertEqual t t atol= rtol= check changes t t rnum = random uniform - t fill_ rnum assertEqual t t atol= rtol= release tensors del s t s t TemporaryFileName fname assert_with_filename fname IS_FILESYSTEM_UTF _ENCODING TemporaryDirectoryName suffix= \u e d\u dname TemporaryFileName dir=dname fname assert_with_filename fname test_print default_type = torch tensor type t torch _tensor_classes t == torch HalfTensor continue HalfTensor does support fill t is_sparse continue t is_cuda torch cuda is_available continue obj = t fill_ obj __repr__ str obj test half tensor obj = torch rand device= cpu half obj __repr__ str obj t torch _storage_classes t == torch BFloat Storage continue Fix once fill enabled bfloat t is_cuda torch cuda is_available continue t == torch BoolStorage t == torch cuda BoolStorage obj = t fill_ True obj = t fill_ obj __repr__ str obj test complex tensor complex tensor print uses two formatters one real values other imag values consistent numpy x = torch tensor + j + j assertEqual x __repr__ str x assertExpectedInline str x tensor + j + j test complex half tensor x = torch tensor + j - + j dtype=torch chalf assertEqual x __repr__ str x assertExpectedInline str x tensor + j - + j dtype=torch complex test scientific notation complex tensors x = torch tensor e + j - e- j assertEqual x __repr__ str x assertExpectedInline str x tensor e+ + e+ j - e+ - e- j test big integer x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor test scientific notation x = torch tensor e e- assertEqual x __repr__ str x assertExpectedInline str x tensor e+ e- test scientific notation using set_printoptions x = torch tensor e e- torch set_printoptions sci_mode=True assertEqual x __repr__ str x assertExpectedInline str x tensor e+ e- torch set_printoptions sci_mode=False assertEqual x __repr__ str x assertExpectedInline str x tensor torch set_printoptions sci_mode=None reset default value test no leading space all elements positive x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor test leading space there negative elements x = torch tensor - assertEqual x __repr__ str x assertExpectedInline str x tensor - test inf nan x = torch tensor inf -inf nan assertEqual x __repr__ str x assertExpectedInline str x tensor inf -inf nan y = torch tensor inf complex inf complex -inf complex nan inf complex nan assertEqual y __repr__ str y expected_str = \ tensor + j inf+ j +infj -inf+ j + j nan+infj +nanj assertExpectedInline str y expected_str test dtype set_default_dtype torch float x = torch tensor e- e- e- e e e dtype=torch float assertEqual x __repr__ str x expected_str = \ tensor e+ e- e- e+ e+ inf dtype=torch float assertExpectedInline str x expected_str test changing default dtype set_default_dtype torch float assertEqual x __repr__ str x expected_str = \ tensor e+ e- e- e+ e+ inf assertExpectedInline str x expected_str test summary x = torch zeros assertEqual x __repr__ str x assertExpectedInline str x tensor test internal summary function x = torch rand summary = torch _tensor_str get_summarized_data x assertEqual summary shape first_and_last = - - - assertEqual summary x first_and_last first_and_last test device torch cuda is_available x = torch tensor device= cuda assertEqual x __repr__ str x assertExpectedInline str x tensor device= cuda test changing default cuda torch set_default_tensor_type torch cuda FloatTensor assertEqual x __repr__ str x assertExpectedInline str x tensor test printing tensor different gpu than current one torch cuda device_count = torch cuda device assertEqual x __repr__ str x assertExpectedInline str x tensor device= cuda test printing cpu tensor when default device cuda y = torch tensor device= cpu assertEqual y __repr__ str y assertExpectedInline str y tensor device= cpu torch set_default_tensor_type default_type test integral floats requires_grad x = torch tensor requires_grad=True assertEqual x __repr__ str x assertExpectedInline str x tensor requires_grad=True test non-contiguous print sliced tensor should have PRINT_OPTS threshold elements x = torch ones y = x as_strided size= stride= assertEqual str y y __repr__ expected_str = \ tensor \ assertExpectedInline str y expected_str x = torch ones + j y = x as_strided size= stride= assertEqual str y y __repr__ expected_str = \ tensor + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j + j \ assertExpectedInline str y expected_str test print -dim tensor there s no -dim Numpy we match arrayprint style x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor e- test print boolean tensor x = torch tensor True assertEqual x __repr__ str x assertExpectedInline str x tensor True x = torch tensor True assertEqual x __repr__ str x assertExpectedInline str x tensor True Numpy test print float sci_mode when min x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor e- Numpy test print complex sci_mode when real_min imag_min x = torch tensor + j assertEqual x __repr__ str x assertExpectedInline str x tensor e- + e- j Numpy test print float sci_mode when max e TODO Pytorch uses fixed precision print while Numpy uses dragon _scientific do automatic trimming padding x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor e+ Numpy test print float sci_mode when max min x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor e- e+ Numpy test print int max min no sci_mode x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor Numpy test print int e no sci_mode x = torch tensor e assertEqual x __repr__ str x assertExpectedInline str x tensor Numpy test printing float int_mode x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor Numpy test printing float int_mode sci format when max min x = torch tensor assertEqual x __repr__ str x assertExpectedInline str x tensor e+ e+ test_sizeof - None sizeof_empty = torch randn storage __sizeof__ sizeof_ = torch randn storage __sizeof__ sizeof_ = torch randn storage __sizeof__ assertEqual sizeof_ - sizeof_empty sizeof_ - sizeof_empty assertEqual sizeof_ - sizeof_empty sizeof_ - sizeof_empty sizeof_empty = torch randn torch uint storage __sizeof__ sizeof_ = torch randn torch uint storage __sizeof__ sizeof_ = torch randn torch uint storage __sizeof__ assertEqual sizeof_ - sizeof_empty sizeof_ - sizeof_empty assertEqual sizeof_ - sizeof_empty sizeof_ - sizeof_empty skipIfTorchDynamo Not suitable test TorchDynamo test_resizable - None x = torch randn assertTrue x storage resizable x numpy assertFalse x storage resizable test_iter - None x = torch randn i sub enumerate x assertEqual sub x i noqa PLR x = torch tensor assertEqual list x test_new - None x = torch autograd Variable torch tensor y = torch autograd Variable torch randn z = torch autograd Variable torch IntTensor assertEqual x new shape assertEqual x new x assertEqual x new shape assertEqual x new torch Size shape assertEqual x new shape assertEqual x new tolist assertEqual x new tolist assertEqual x new np int np float tolist assertEqual x new np array tolist assertEqual x new z z + tolist assertEqual x new size= shape assertEqual x new shape assertEqual x new y storage data_ptr y data_ptr assertEqual x new y data_ptr y data_ptr assertIsNot x new y y assertRaises TypeError lambda x new z TypeError would better assertRaises RuntimeError lambda x new z storage unittest skipIf PYTORCH_CUDA_MEMCHECK is_pinned uses failure detect pointer property test_pin_memory x = torch randn assertFalse x is_pinned torch cuda is_available pinned = x pin_memory assertTrue pinned is_pinned assertEqual pinned x assertNotEqual pinned data_ptr x data_ptr test pin_memory already pinned tensor has no effect assertIs pinned pinned pin_memory assertEqual pinned data_ptr pinned pin_memory data_ptr test_error_msg_type_translation assertRaisesRegex RuntimeError message includes both Double Long = Double = Long Calls model LongTensor input DoubleTensor weights input = torch zeros dtype=torch long weight = torch nn Parameter torch zeros dtype=torch double model = torch nn Conv d stride= padding= bias=False model weight = weight model input test_apply x = torch arange res = x clone apply_ lambda k k + k assertEqual res x assertRaises TypeError lambda x apply_ lambda k str test_map x = torch autograd Variable torch randn y = torch autograd Variable torch randn res = x clone res map_ y lambda b + b assertEqual res x + y assertRaisesRegex TypeError callable lambda res map_ y str test_map x = torch autograd Variable torch randn y = torch autograd Variable torch randn z = torch autograd Variable torch randn res = x clone res map _ y z lambda b c + b c assertEqual res x + y z z requires_grad = True assertRaisesRegex RuntimeError requires grad lambda res map _ y z lambda b c + b c test_Size expects iterable int Tensor assertRaises TypeError lambda torch Size torch ones initialization empty_size = torch Size size = torch Size assertIsInstance empty_size tuple assertIsInstance size tuple value check __len__ assertEqual len empty_size assertEqual len size type check __getitem__ int assertIsInstance size int assertIsInstance size int assertIsInstance size int value check __getitem__ int assertEqual size assertEqual size assertEqual size type check __getitem__ slice assertIsInstance size torch Size assertIsInstance size - torch Size assertIsInstance size torch Size value check __getitem__ slice assertEqual size assertEqual size - assertEqual size type check __add__ assertIsInstance empty_size + torch Size assertIsInstance size + torch Size assertIsInstance size + torch Size assertIsInstance size + size torch Size value check __add__ assertEqual empty_size + assertEqual size + assertEqual size + assertEqual size + size type check __radd__ assertIsInstance + empty_size torch Size assertIsInstance + size torch Size value check __radd__ assertEqual + size assertEqual + size type check __mul__ assertIsInstance empty_size torch Size assertIsInstance size torch Size assertIsInstance size torch Size assertIsInstance size torch Size value check __mul__ assertEqual empty_size assertEqual size assertEqual size assertEqual size type check __rmul__ assertIsInstance empty_size torch Size assertIsInstance size torch Size assertIsInstance size torch Size assertIsInstance size torch Size value check __rmul__ assertEqual empty_size assertEqual size assertEqual size assertEqual size test_Size_concat_non_tuple_sequence check TypeError gets raised adding non-tuple sequences collections abc Sequence DummySequence Sequence vals = list range __len__ len vals __getitem__ i vals i __iter__ iter vals size = torch Size seq = DummySequence msg = r can only concatenate tuple \ \w+\ torch Size assertRaisesRegex TypeError msg lambda size + seq msg = r unsupported operand type assertRaisesRegex TypeError msg lambda seq + size test_Size_concat_wildcard check rd party classes can support addition torch Size Wildcard __add__ other __radd__ other size = torch Size wildcard = Wildcard assertEqual wildcard + size assertEqual size + wildcard test_Size_scalar three = torch tensor two = torch tensor x = torch Size two three i range assertEqual x i i test_Size_iter sizes iter range x = torch Size sizes i range assertEqual x i i + test_t_not_ d_error assertRaises RuntimeError lambda torch randn t assertRaises RuntimeError lambda torch randn t_ skip test now affects all tests unittest skipIf True flush_denormal supported test_set_flush_denormal tiny_float = e- tiny_double = e- float_tensor = torch FloatTensor tiny_float double_tensor = torch DoubleTensor tiny_float tiny_double assertEqual float_tensor atol= rtol= assertEqual float_tensor tiny_float atol=tiny_float rtol= assertEqual double_tensor atol= rtol= assertEqual double_tensor tiny_float atol= rtol= assertEqual double_tensor tiny_double atol= rtol= torch set_flush_denormal True assertEqual float_tensor atol= rtol= assertEqual float_tensor atol= rtol= tiny_float zero assertEqual double_tensor atol= rtol= tiny_float converted zero double type assertEqual double_tensor tiny_float atol= rtol= assertEqual double_tensor atol= rtol= tiny_double zero torch set_flush_denormal False test_show_config We can t usefully test output just make sure doesn t crash torch __config__ show unittest skipIf IS_FBCODE CXX_FLAGS only OSS build test_cxx_flags torch __config__ _cxx_flags test_parallel_info torch __config__ parallel_info test_get_cpu_capability This method primarily exposed torchvision s resize torch backends cpu get_cpu_capability We have ensure method torchscriptable torchvision s resize should torchscriptable torch jit script torch backends cpu get_cpu_capability slowTest test_slow_test Just smoketest make sure our slowTest decorator works pass test_is_nonzero assertRaisesRegex RuntimeError Boolean value Tensor no values ambiguous torch tensor is_nonzero assertRaisesRegex RuntimeError Boolean value Tensor more than one value ambiguous torch tensor is_nonzero assertFalse torch tensor is_nonzero assertTrue torch tensor is_nonzero assertFalse torch tensor is_nonzero assertTrue torch tensor is_nonzero assertFalse torch tensor is_nonzero assertTrue torch tensor is_nonzero assertTrue torch tensor is_nonzero assertTrue torch tensor - is_nonzero assertFalse torch tensor is_nonzero assertTrue torch tensor True is_nonzero assertFalse torch tensor False is_nonzero assertFalse torch tensor + j is_nonzero assertTrue torch tensor + j is_nonzero test_assert_async assertRaisesRegex RuntimeError Boolean value Tensor no values ambiguous torch _assert_async torch tensor assertRaisesRegex RuntimeError Boolean value Tensor more than one value ambiguous torch _assert_async torch tensor assertRaisesRegex RuntimeError Expected Tensor single nonzero value got zero torch _assert_async torch tensor torch _assert_async torch tensor torch _assert_async torch tensor torch _assert_async torch tensor - assertRaisesRegex RuntimeError Expected Tensor single nonzero value got zero torch _assert_async torch tensor torch _assert_async torch tensor True assertRaisesRegex RuntimeError Expected Tensor single nonzero value got zero torch _assert_async torch tensor False torch _assert_async torch tensor + j assertRaisesRegex RuntimeError Expected Tensor single nonzero value got zero torch _assert_async torch tensor + j NB we must built CUDA we built CUDA no CUDA available we get different error unittest skipIf torch backends cuda is_built IS_SANDCASTLE CUDA built can t test CUDA built error test_cuda_not_built msg = Torch compiled CUDA enabled assertRaisesRegex AssertionError msg lambda torch cuda current_device assertRaisesRegex AssertionError msg lambda torch tensor device= cuda assertRaisesRegex AssertionError msg lambda torch tensor cuda assertRaisesRegex TypeError msg lambda torch cuda FloatTensor assertRaisesRegex TypeError msg lambda torch set_default_tensor_type torch cuda FloatTensor assertRaisesRegex AssertionError msg lambda torch tensor device= cuda test_has_internal_overlap OVERLAP_NO = OVERLAP_YES = OVERLAP_TOO_HARD = Check contiguous tensors = torch randn assertEqual torch _debug_has_internal_overlap OVERLAP_NO Checks zero strides b = torch randn b_expanded = b expand assertEqual torch _debug_has_internal_overlap b_expanded OVERLAP_YES Check zero strided size axis non-contiguous storage gh- c = torch randn as_strided assertEqual torch _debug_has_internal_overlap c OVERLAP_NO c = torch randn as_strided assertEqual torch _debug_has_internal_overlap c OVERLAP_TOO_HARD test_allow_tensor_metadata_change torch ones Metadata changes allowed view tensors created detach test_memory_format test_helper x memory_format y = x contiguous memory_format=memory_format assertFalse y is_contiguous assertTrue y is_contiguous memory_format=memory_format assertEqual y x test_helper torch randn torch channels_last test_helper torch randn torch channels_last_ d test_memory_format_contiguous_returns_same_tensor_if_already_satisfies test_helper x memory_format alias = x contiguous memory_format=memory_format alias fill_ assertEqual x alias test_helper torch randn permute torch channels_last test_helper torch randn permute torch channels_last_ d test_memory_format_empty test_helper dim dim memory_format assertRaises RuntimeError x = torch empty dim memory_format=memory_format x = torch empty dim memory_format=memory_format assertTrue x is_contiguous memory_format=memory_format test_helper torch channels_last test_helper torch channels_last_ d skipIfCrossRef test_dim_order shape = t = torch empty shape assertSequenceEqual t dim_order seq_type=tuple assertSequenceEqual t dim_order ambiguity_check=True seq_type=tuple transpose doesn t really change underlying physical memory so expecting dim_order change reflect like strides assertSequenceEqual t transpose dim_order t = torch empty shape memory_format=torch channels_last assertSequenceEqual t dim_order t = torch empty memory_format=torch channels_last_ d assertSequenceEqual t dim_order dim_order itertools permutations range assertSequenceEqual dim_order torch empty_permuted shape dim_order dim_order target_shapes = shape target_shapes memory_format torch contiguous_format torch channels_last t = torch empty shape memory_format=memory_format assertRaises RuntimeError t dim_order ambiguity_check=True memory_format == torch contiguous_format dim_order_target = list range len shape memory_format == torch channels_last dim_order_target = list range len shape assertSequenceEqual dim_order_target t dim_order ambiguity_check= torch contiguous_format torch channels_last ambiguous_shapes = shape ambiguous_shapes memory_format torch contiguous_format torch channels_last t = torch empty shape memory_format=memory_format assertRaises RuntimeError t dim_order ambiguity_check=True t dim_order ambiguity_check= torch contiguous_format torch channels_last assertRaises TypeError torch empty dim_order ambiguity_check= ILLEGAL_STR sparse tensor does support dim order assertRaises AttributeError indices = torch tensor row column indices values = torch tensor values those indices sparse_tensor = torch sparse_coo_tensor indices values size= sparse_tensor dim_order test_subclass_tensors raise error when trying subclass FloatTensor assertRaisesRegex TypeError type torch FloatTensor acceptable base type Foo torch FloatTensor pass allow subclassing Tensor Foo torch Tensor foo f = Foo assertEqual f foo test_ndim = torch randn assertEqual ndim b = torch randn assertEqual b ndim c = torch randn assertEqual c ndim test_nbytes = torch randn dtype=torch float assertEqual numel element_size nbytes b = torch randn assertEqual b numel b element_size b nbytes c = torch randn assertEqual c numel c element_size c nbytes test_fill_diagonal = torch randn = clone v = i range i i = v fill_diagonal_ v assertEqual b = torch randn b = b clone i range b i i = v b i + i = v b fill_diagonal_ v wrap=True assertEqual b b c = torch rand c = c clone i range c i i i = v c fill_diagonal_ v assertEqual c c non-contiguous tensor d = torch rand d = d clone i range d i i = v d fill_diagonal_ v assertEqual d d e = torch rand e = e clone i range e i i = v e i + i = v e fill_diagonal_ v wrap=True assertEqual e e test_setting_real_imag_to_a_number x = torch randn dtype=torch cfloat x real = x imag = zeros = torch zeros assertEqual x real zeros assertEqual x imag zeros test_batch_norm_cpu_inference input nchw inputs = torch tensor - torch tensor - - - - - output nchw outputs = torch tensor - torch tensor - - - - - i range len inputs affine False True m = torch nn BatchNorm d inputs i size e- affine=affine m eval contiguous case input = inputs i contiguous output = m input non-contiguous case input = input permute output = m input permute channels last case input = input contiguous memory_format=torch channels_last output = m input assertEqual output outputs i assertEqual output output assertEqual output output FIXME move these meta tests their own test suite distribute them among appropriate test suites their ops skipIfTorchDynamo Fails after Triton update see https github com pytorch pytorch issues test_empty_meta x = torch empty device= meta y = torch empty device= meta z = x + y assertEqual z size assertRaises RuntimeError lambda z item skipIfTorchDynamo Fails after Triton update see https github com pytorch pytorch issues test_format_scalar_meta x = torch empty device= meta assertEqual format x repr x test_upsample_nearest d_meta TODO test should triggered test_nn py right now meta enabled even we probably missing too many meta functions get through test unmolested NB Can t make exponent too big will overflow signed -bit integer x = torch empty device= meta z = torch nn functional interpolate x scale_factor= assertEqual z size assertRaises RuntimeError lambda z item TODO out tests cannot triggered test_nn py because we don t actually do out= arguments nn functions so there no public API which get out version interpolate doesn t seem support out= sure why passing None here doesn t work How strange z = torch empty device= meta torch _C _nn upsample_nearest d x out=z assertEqual z size assertRaises RuntimeError lambda z item test_upsample_nearest d_meta TODO out tests cannot triggered test_nn py because we don t actually do out= arguments nn functions so there no public API which get out version Make sure we don t clobber strides out tensor NB test must done d d because d doesn t have any meaningful layout support x = torch empty device= meta out = torch empty device= meta memory_format=torch channels_last torch _C _nn upsample_nearest d x out=out assertTrue out is_contiguous memory_format=torch channels_last x = torch empty device= meta memory_format=torch channels_last out = torch empty device= meta torch _C _nn upsample_nearest d x out=out assertTrue out is_contiguous But resize occurs do clobber x = torch empty device= meta memory_format=torch channels_last out = torch empty device= meta torch _C _nn upsample_nearest d x out=out assertTrue out is_contiguous memory_format=torch channels_last Complain out dtype mismatch x = torch empty device= meta dtype=torch float out = torch empty device= meta dtype=torch double assertExpectedRaisesInline RuntimeError lambda torch _C _nn upsample_nearest d x out=out Expected out tensor have dtype torch float got torch float instead Complain out device mismatch x = torch empty device= meta out = torch empty device= cpu FIXME compiling should properly error device mismatch TEST_WITH_TORCHINDUCTOR assertExpectedRaisesInline RuntimeError lambda torch _C _nn upsample_nearest d x out=out Attempting copy device meta device cpu cross-device copies allowed test_add_meta_scalar From https github com pytorch pytorch issues x = torch empty device= meta y = x + assertEqual y size x size test_normal_shape device get_all_device_types tensor = torch rand device=device tensor = torch rand device=device tensor = torch rand device=device tensor = torch rand device=device tensor = torch rand device=device tensor _non_contiguous = torch rand device=device permute tensor _channels_last = tensor contiguous memory_format=torch channels_last output = torch zeros device=device output = torch zeros device=device inputs have same size assertEqual torch normal tensor tensor size assertEqual torch normal tensor _non_contiguous tensor size assertEqual torch normal tensor tensor _channels_last size assertEqual torch normal tensor _non_contiguous tensor _channels_last size scalar case assertEqual torch normal tensor size assertEqual torch normal tensor size inputs expandable tensors assertEqual torch normal tensor tensor size assertEqual torch normal tensor tensor size inputs non-expandable tensors they have same number elements assertRaisesRegex RuntimeError r The size tensor \ \ must match size r tensor b \ \ non-singleton dimension assertEqual torch normal tensor tensor size assertRaisesRegex RuntimeError r The size tensor \ \ must match size r tensor b \ \ non-singleton dimension assertEqual torch normal tensor tensor size inputs non-expandable tensors they don t have same number elements assertRaisesRegex RuntimeError r The size tensor \ \ must match size r tensor b \ \ non-singleton dimension torch normal tensor tensor output inputs size compatible assertEqual torch normal tensor tensor out=output size output inputs size compatible assertWarnsRegex UserWarning This behavior deprecated future PyTorch release outputs will resized unless they have zero elements assertEqual torch normal tensor tensor out=output size assertRaisesRegex RuntimeError r The size tensor \ \ must match size r tensor b \ \ non-singleton dimension inputs expandable output size same mean torch normal tensor tensor out=output test_tensoriterator_output_setup Test whether output s memory layout correct test_memory_layout x y scale zero_point out assertEqual x dim assertEqual x size y size assertEqual y size out size shape = x size n range shape c range shape h range shape w range shape scale None zero_point None assertEqual out n c h w torch ops quantized add x n c h w y n c h w scale zero_point assertEqual out n c h w x n c h w + y n c h w xraw = torch rand yraw = torch rand qxraw = torch quantize_per_tensor xraw torch quint qyraw = torch quantize_per_tensor yraw torch quint contiguous case fast setup test_memory_layout xraw yraw None None xraw + yraw test_memory_layout qxraw qyraw torch ops quantized add qxraw qyraw channels last case fast setup x = xraw contiguous memory_format=torch channels_last y = yraw contiguous memory_format=torch channels_last test_memory_layout x y None None x + y qx = qxraw contiguous memory_format=torch channels_last qy = qyraw contiguous memory_format=torch channels_last test_memory_layout qx qy torch ops quantized add qx qy non contiguous case fast setup dense non-overlapping same shape strides x = xraw permute y = yraw permute test_memory_layout x y None None x + y qx = qxraw permute qy = qyraw permute test_memory_layout qx qy torch ops quantized add qx qy non contiguous case fast setup dense non-overlapping input tensors have same shape strides output tensor have same shape input tensors different stride output tensor should preserve its strides case x = xraw permute y = yraw permute out = torch empty_like xraw out = out permute expected_stride = out stride test_memory_layout x y None None torch add x y out=out assertEqual expected_stride out stride non contiguous case non fast setup x = xraw permute y = yraw permute test_memory_layout x y None None x + y qx = qxraw permute qy = qyraw permute test_memory_layout qx qy torch ops quantized add qx qy test_conj_physical_meta_stride = torch zeros dtype=torch complex device= meta b = torch _fft_c c True c = torch conj_physical b assertEqual b stride c stride Tests make sure we still handle data properly until removed test_dot_data_use data allows change Tensors types inplace check we still raise nice error assertRaisesRegex RuntimeError message includes both Double ComplexFloat = Double = ComplexFloat Calls model LongTensor input DoubleTensor weights input = torch randn dtype=torch double weight = torch zeros dtype=torch complex model = torch nn Conv d stride= padding= bias=False model weight data = weight model input test_empty_storage_view we should able modify slices -element array without error being raised due trying resize its storage t = torch from_numpy np empty t = test_has_storage assertIsNotNone torch tensor storage assertIsNotNone torch empty storage assertIsNotNone torch tensor clone storage assertIsNotNone torch tensor nonzero storage assertIsNotNone torch tensor new storage FIXME Extend test put TensorProperties test test_numel b = torch ByteTensor assertEqual b nelement assertEqual b numel Verifies deep copies dtypes same objects test_copy_dtypes dtype all_types_and_complex_and torch half torch bfloat torch bool copied_dtype = copy deepcopy dtype assertIs dtype copied_dtype test_dtype_is_signed dtype all_types_and_complex_and torch half torch bfloat torch half assertEqual dtype is_signed torch is_signed torch tensor dtype=dtype assertRaisesRegex RuntimeError supported quantized lambda torch quint is_signed assertRaisesRegex RuntimeError supported quantized lambda torch qint is_signed assertRaisesRegex RuntimeError supported quantized lambda torch qint is_signed FIXME Put following random tests into their own test test suite skipIfTorchDynamo requires https github com pytorch torchdynamo pull test_RNGState state = torch get_rng_state stateCloned = state clone before = torch rand assertEqual state ne stateCloned long sum atol= rtol= torch set_rng_state state after = torch rand assertEqual before after atol= rtol= skipIfTorchDynamo requires https github com pytorch torchdynamo pull test_RNGStateAliasing Fork random number stream point gen = torch Generator gen set_state torch get_rng_state assertEqual gen get_state torch get_rng_state target_value = torch rand Dramatically alter internal state main generator _ = torch rand forked_value = torch rand generator=gen assertEqual target_value forked_value atol= rtol= msg= RNG has forked correctly skipIfTorchDynamo requires https github com pytorch torchdynamo pull test_RNG_after_pickle torch random manual_seed before = torch rand torch random manual_seed buf = io BytesIO tensor = torch tensor ForkingPickler buf pickle HIGHEST_PROTOCOL dump tensor after = torch rand assertEqual before after atol= rtol= skipIfTorchDynamo requires https github com pytorch torchdynamo pull test_boxMullerState torch manual_seed odd_number = seeded = torch randn odd_number state = torch get_rng_state midstream = torch randn odd_number torch set_rng_state state repeat_midstream = torch randn odd_number torch manual_seed reseeded = torch randn odd_number assertEqual midstream repeat_midstream atol= rtol= msg= get_rng_state set_rng_state generating same sequence normally distributed numbers assertEqual seeded reseeded atol= rtol= msg= repeated calls manual_seed generating same sequence normally distributed numbers skipIfTorchDynamo requires https github com pytorch torchdynamo pull test_manual_seed rng_state = torch get_rng_state torch manual_seed x = torch randn assertEqual torch initial_seed torch manual_seed y = torch randn assertEqual x y max_int = x fff_ffff_ffff_ffff min_int = -max_int - max_uint = xffff_ffff_ffff_ffff Check all boundary cases valid seed value inputs test_cases = seed expected_initial_seed Positive seeds should unchanged max_int max_int max_int + max_int + max_uint max_uint Negative seeds wrap around starting largest seed value - max_uint min_int max_int + seed expected_initial_seed test_cases torch manual_seed seed actual_initial_seed = torch initial_seed msg = f expected initial_seed = expected_initial_seed x f after calling manual_seed seed x got actual_initial_seed x instead assertEqual expected_initial_seed actual_initial_seed msg=msg invalid_seed min_int - max_uint + assertRaisesRegex ValueError r Overflow when unpacking long long torch manual_seed invalid_seed torch set_rng_state rng_state FIXME Describe test port generic device framework more appropriate test suite copy operation test_copy_transpose x = torch arange dtype=torch float reshape t y = torch empty dtype=torch float y copy_ x assertEqual y range assertEqual y range y = torch empty dtype=torch double y copy_ x assertEqual y range assertEqual y range Validates regression reported https github com pytorch pytorch issues x = torch arange reshape dtype=torch cfloat t y = torch empty dtype=torch cfloat y copy_ x assertEqual y range assertEqual y range x = torch arange reshape dtype=torch complex t y = torch empty dtype=torch complex y copy_ x assertEqual y range assertEqual y range FIXME Port more appropriate test suite test_copy_broadcast torch zeros copy_ torch zeros assertRaises RuntimeError lambda torch zeros copy_ torch zeros FIXME Port more appropriate test suite Fails inductor aot_eager because functionalization replaces copy_ copy which doesn t properly error bad inputs test_copy_many_to_one Testing in-place copy where attempt write many memory storage single storage would cause RuntimeError thrown assertRaises RuntimeError lambda torch zeros expand copy_ torch zeros test_copy_float Check fbgemm code no longer reads memory out bounds see copy_impl fbgemm Float ToFloat_ref https github com pytorch pytorch issues Types test different code paths copy_impl dtypes = out_dtype src_dtype torch float torch float fbgemm torch float torch float fbgemm torch float torch float TensorIterator cases = out_shape src_shape is_ok These cases used crash fbgemm make sure these also raise exceptions TensorIterator False same strides allowed TI False same strides allowed TI False different strides False different strides False different strides False same numel These cases should pass fbgemm TensorIterator True same strides True same strides True different strides allowed TI True different strides allowed TI out_shape src_shape is_ok out_dtype src_dtype itertools product cases dtypes out = torch zeros out_shape dtype=out_dtype device=torch device cpu src = torch ones src_shape dtype=src_dtype device=torch device cpu is_ok torch cuda is_available out_cuda = out cuda src_cuda = src cuda res = out copy_ src torch cuda is_available res_cuda = out_cuda copy_ src_cuda assertEqual res res_cuda assertRaises RuntimeError lambda out copy_ src FIXME Port more appropriate test suite _test_to_with_layout layout test_copy_behavior t non_blocking=False assertIs t t t non_blocking=non_blocking assertIs t t t dtype non_blocking=non_blocking assertIs t t torch empty_like t non_blocking=non_blocking assertIsNot t t t non_blocking=non_blocking copy=True assertIsNot t t t dtype non_blocking=non_blocking copy=True assertIsNot t t torch empty_like t non_blocking=non_blocking copy=True devices = t device t device type == cuda t device index == - devices append f cuda torch cuda current_device t device index == torch cuda current_device devices append cuda device devices assertIs t t device non_blocking=non_blocking assertIs t t device t dtype non_blocking=non_blocking assertIsNot t t device non_blocking=non_blocking copy=True assertIsNot t t device t dtype non_blocking=non_blocking copy=True = torch tensor layout == torch sparse_csr = torch tensor to_sparse_csr test_copy_behavior assertEqual device cpu device assertEqual device cpu dtype=torch float device assertIs torch float cpu dtype=torch float dtype assertEqual device torch float device assertIs torch float dtype=torch float dtype test_data_ptr getter assertEqual getter getter cpu assertEqual getter getter dtype=a dtype device=a device copy=False assertEqual getter getter cpu copy=False assertNotEqual getter getter cpu copy=True layout == torch sparse_csr TODO compressed sparse tensors currently don t support data_ptr Exercising failure will allow us widen coverage test once does assertRaisesRegex RuntimeError Cannot access data pointer Tensor doesn t have storage data_ptr While compressed sparse tensors don t have concept data_ptr underlying tensors do The implementation appropriately forwards call components which what we re test here test_data_ptr lambda values data_ptr test_data_ptr lambda crow_indices data_ptr test_data_ptr lambda col_indices data_ptr test_data_ptr lambda data_ptr torch cuda is_available non_blocking True False cuda cuda cuda torch cuda device_count == cuda b = torch tensor device=cuda test_copy_behavior b non_blocking assertEqual b device b cuda non_blocking=non_blocking device assertEqual device b cpu non_blocking=non_blocking device assertEqual b device cuda non_blocking=non_blocking device assertIs torch int b cpu dtype=torch int non_blocking=non_blocking dtype assertEqual device b cpu dtype=torch int non_blocking=non_blocking device assertIs torch int b dtype=torch int dtype assertEqual b device b dtype=torch int device test_to _test_to_with_layout torch strided torch version cuda None _test_to_with_layout torch sparse_csr FIXME describe test test_as_subclass SubTensor torch Tensor member_var = object t = torch tensor t = torch tensor t = torch tensor s = t as_subclass SubTensor s = t as_subclass SubTensor s = t as_subclass SubTensor Check correct type returned assertTrue type s SubTensor assertTrue type s SubTensor assertTrue type s SubTensor Check data equal assertEqual t s assertEqual t s assertEqual t s t = t = t = Check data equal even after modification assertEqual t s assertEqual t s assertEqual t s Check member variables passed through assertTrue s member_var SubTensor member_var assertTrue s member_var SubTensor member_var assertTrue s member_var SubTensor member_var Test autograd propagated t = torch tensor dtype=torch float requires_grad=True Run calculation tensor exp_t = torch exp t Cast exp_t subclass exp_s = exp_t as_subclass SubTensor Make sure t grad initially None assertTrue t grad None Run autograd calculation exp_s backward Make sure autograd propagated original tensor declared requires_grad assertTrue t grad None Make sure invalid subclasses raise nice errors BadSubTensor member_var = object err_msg = Creating Tensor subclass does inherit Tensor assertRaisesRegex RuntimeError err_msg s = t as_subclass BadSubTensor FIXME Port test suite better fits slicing test_slice empty = torch empty x = torch arange view assertEqual x x assertEqual x x start stop clamped size dim assertEqual x x start = stop then result empty assertEqual x empty assertEqual x empty out bounds also empty assertEqual x empty additional correctness checks assertEqual x tolist assertEqual x - tolist assertEqual x - tolist assertEqual x - tolist test_split_with_sizes_copy_out device = torch device cuda torch cuda is_available torch device cpu shape = x = torch rand shape device=device cases = - - dim split_sizes cases views = x split_with_sizes split_sizes dim=dim expects = v clone v views out = torch zeros_like v v views expect t zip expects out expect numel = assertFalse expect eq t all item torch split_with_sizes_copy x split_sizes dim=dim out=out expect t zip expects out assertTrue expect eq t all item torch cuda is_available continue Test cuda graph out = torch zeros_like v v views expect t zip expects out expect numel = assertFalse expect eq t all item g = torch cuda CUDAGraph torch cuda graph g torch split_with_sizes_copy x split_sizes dim=dim out=out g replay expect t zip expects out assertTrue expect eq t all item test_type x = torch randn double assertEqual x type torch FloatTensor dtype torch float assertEqual x type torch FloatTensor dtype torch float assertEqual x int type torch Tensor dtype torch get_default_dtype assertEqual x type torch int dtype torch int FIXME port quantization test suite xfailIfS X test_qengine qengines = torch backends quantized supported_engines original_qe = torch backends quantized engine qe qengines torch backends quantized engine = qe assert torch backends quantized engine == qe qengine set successfully torch backends quantized engine = original_qe test_terminate_handler_on_crash cmd = sys executable -c os os environ \ TORCH_CUSTOM_TERMINATE\ = \ torch torch _C torch _C _abort assertRaises subprocess CalledProcessError cm subprocess check_output cmd shell=False e = cm exception output = e stdout decode utf- assertNotEqual e returncode assertNotEqual output None assertIn Unhandled exception caught c util AbortHandler h output FIXME port distributed test suite slowTest test_multinomial_invalid_probs _spawn_method method arg try mp set_start_method spawn except RuntimeError pass mp Pool pool out = pool map method arg assertTrue out _test_multinomial_invalid_probs probs try n_sample = special case test n_sample= which more general torch multinomial probs cpu False Should reached except RuntimeError e probability tensor contains either ` inf ` ` nan ` element str e _spawn_method _test_multinomial_invalid_probs torch tensor - _spawn_method _test_multinomial_invalid_probs torch tensor inf _spawn_method _test_multinomial_invalid_probs torch tensor -inf _spawn_method _test_multinomial_invalid_probs torch tensor nan FIXME port more appropriate test suite test_to_with_tensor = torch tensor assertEqual device device torch cuda is_available non_blocking True False cuda cuda cuda torch cuda device_count == cuda b = torch tensor device=cuda assertEqual b device b b non_blocking=non_blocking device assertEqual device b non_blocking=non_blocking device assertEqual b device b non_blocking=non_blocking device test_device cpu = torch device cpu assertEqual cpu str cpu assertEqual cpu cpu type assertEqual None cpu index cpu = torch device cpu assertEqual cpu str cpu assertEqual cpu cpu type assertEqual cpu index cpu = torch device cpu assertEqual cpu str cpu assertEqual cpu cpu type assertEqual cpu index cuda = torch device cuda assertEqual cuda str cuda assertEqual cuda cuda type assertEqual None cuda index cuda = torch device cuda assertEqual cuda str cuda assertEqual cuda cuda type assertEqual cuda index cuda = torch device cuda assertEqual cuda str cuda assertEqual cuda cuda type assertEqual cuda index cuda = torch device cuda assertEqual cuda str cuda assertEqual cuda cuda type assertEqual cuda index assertRaises RuntimeError lambda torch device cpu - assertRaises RuntimeError lambda torch device cuda - assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda assertRaises RuntimeError lambda torch device cuda cuda assertRaises RuntimeError lambda torch device cuda +cuda assertRaises RuntimeError lambda torch device cuda cuda assertRaises RuntimeError lambda torch device - assertRaises RuntimeError lambda torch device other assertRaises RuntimeError lambda torch device other device_set = cpu cpu cuda cuda cuda cuda cuda device_hash_set = set device_hash_set update hash torch device device device device_set assertEqual len device_set len device_hash_set get_expected_device_repr device device index None f device type= device type index= device index f device type= device type device device_set dev = torch device device assertEqual repr dev get_expected_device_repr dev Tests use_deterministic_flag can set expected wrapDeterministicFlagAPITest test_deterministic_flag deterministic warn_only product True False True False torch use_deterministic_algorithms deterministic warn_only=warn_only assertEqual deterministic torch are_deterministic_algorithms_enabled assertEqual warn_only torch is_deterministic_algorithms_warn_only_enabled deterministic warn_only debug_mode = debug_mode = debug_mode = assertEqual debug_mode torch get_deterministic_debug_mode debug_mode torch set_deterministic_debug_mode debug_mode assertEqual debug_mode torch get_deterministic_debug_mode deterministic = debug_mode warn_only = debug_mode == assertEqual deterministic torch are_deterministic_algorithms_enabled assertEqual warn_only torch is_deterministic_algorithms_warn_only_enabled debug_mode debug_mode_str default warn error torch set_deterministic_debug_mode debug_mode_str assertEqual debug_mode torch get_deterministic_debug_mode assertRaisesRegex TypeError r _set_deterministic_algorithms\ \ argument mode \ position \ must bool int torch use_deterministic_algorithms assertRaisesRegex TypeError r _set_deterministic_algorithms\ \ argument warn_only must bool int torch use_deterministic_algorithms False warn_only= Tests torch utils deterministic fill_uninitialized_memory can set expected test_deterministic_fill_uninitialized_memory DeterministicGuard True fill_uninitialized_memory=False assertFalse torch utils deterministic fill_uninitialized_memory assertFalse torch _C _get_deterministic_fill_uninitialized_memory DeterministicGuard True fill_uninitialized_memory=True assertTrue torch utils deterministic fill_uninitialized_memory assertTrue torch _C _get_deterministic_fill_uninitialized_memory assertFalse torch utils deterministic fill_uninitialized_memory assertFalse torch _C _get_deterministic_fill_uninitialized_memory torch utils deterministic fill_uninitialized_memory = False assertFalse torch utils deterministic fill_uninitialized_memory assertFalse torch _C _get_deterministic_fill_uninitialized_memory torch utils deterministic fill_uninitialized_memory = True assertTrue torch utils deterministic fill_uninitialized_memory assertTrue torch _C _get_deterministic_fill_uninitialized_memory torch _C _set_deterministic_fill_uninitialized_memory False assertFalse torch utils deterministic fill_uninitialized_memory assertFalse torch _C _get_deterministic_fill_uninitialized_memory torch _C _set_deterministic_fill_uninitialized_memory True assertTrue torch utils deterministic fill_uninitialized_memory assertTrue torch _C _get_deterministic_fill_uninitialized_memory assertRaisesRegex RuntimeError r expected bool got int torch utils deterministic fill_uninitialized_memory = test_type_conversion_via_dtype_name x = torch tensor assertEqual x byte dtype torch uint assertEqual x bool dtype torch bool assertEqual x char dtype torch int assertEqual x double dtype torch float assertEqual x float dtype torch float assertEqual x half dtype torch float assertEqual x int dtype torch int assertEqual x bfloat dtype torch bfloat cfloat = x cfloat assertEqual cfloat dtype torch complex assertEqual cfloat real x float assertEqual cfloat imag torch zeros_like cfloat imag cdouble = x cdouble assertEqual cdouble dtype torch complex assertEqual cdouble real x double assertEqual cdouble imag torch zeros_like cdouble imag chalf = x chalf assertEqual chalf dtype torch complex assertEqual chalf real x half assertEqual chalf imag torch zeros_like chalf imag test_type_alias type_alias_map = torch float torch double torch float torch float torch int torch int torch int torch long torch int torch short torch float torch half torch complex torch chalf torch complex torch cfloat dtype alias type_alias_map items assertIs alias dtype test_doc_template - None Test all public API doc strings use same standard template all common arguments such tensor dim torch _torch_docs __file__ doc_file torch _torch_docs multi_dim_common single_dim_common factory_common_args factory_like_common_args open doc_file encoding= utf- f doc_strs = f read matches = re findall r add_docstr\ ^ + ^ \ &#124; \ \ \ &#124; \ \ \ \ &#124; ^ \ \ doc_strs re MULTILINE &#124; re DOTALL assertTrue matches m matches func = m strip desc = m strip common_args multi_dim_common single_dim_common factory_common_args factory_like_common_args k v common_args items assertNotIn v desc f The argument description v func can f replaced k test_doc checked_types = types MethodType types FunctionType types BuiltinFunctionType types BuiltinMethodType _test_namespace ns skips isinstance ns object ns_name = ns __class__ __name__ ns_name = ns __name__ skip_regexes = r skips isinstance r str skip_regexes append re compile f ^ re escape r $ skip_regexes append r name dir ns name startswith _ continue name real imag y = torch randn dtype=torch cfloat var = getattr y name name H mT mH y = torch randn var = getattr y name var = getattr ns name isinstance var checked_types continue doc = var __doc__ has_doc = doc None len doc strip full_name = ns_name + + name any r match name r skip_regexes assertFalse has_doc f New docs have been added full_name please remove skipped list TestTorch test_doc assertTrue has_doc f full_name missing documentation FIXME All following should marked expected failures so easier tell when missing has been added FIXME fix all skipped ones below test_namespace torch randn noqa F as_strided_ re compile ^clamp_ min &#124; max _ $ is_distributed is_nonzero is_same_size log_softmax map _ new reinforce relu relu_ prelu resize resize_as softmax split_with_sizes unsafe_split_with_sizes _autocast_to_fp _autocast_to_fp test_namespace torch nn noqa F test_namespace torch nn functional assert_int_or_pair noqa F TODO add torch tests when we have proper namespacing ATen functions test_namespace torch FIXME deprecate torch Tensor constructor test_tensor_ctor_scalar x = torch Tensor torch tensor assertEqual x torch tensor test_deepcopy_gradient copy deepcopy = torch zeros grad = torch ones assertEqual grad deepcopy grad s = torch zeros to_sparse s grad = torch ones to_sparse assertEqual s grad deepcopy s grad ensure sharing broken c = deepcopy grad assertTrue c grad c test_tensor_base_init Direct construction OK assertRaises RuntimeError lambda torch _C TensorBase Subclassing directly no OK assertRaisesRegex RuntimeError Cannot subclass Tfail torch _C TensorBase pass Doing so Tensor ok though T torch Tensor pass T test_storage_base_init Direct construction OK assertRaises RuntimeError lambda torch _C StorageBase But construction subclass OK T torch _C StorageBase pass T test_tensor_base_new OK call super __new__ see https github com pytorch pytorch issues TestTensor torch Tensor staticmethod __new__ cls x args kwargs super __new__ cls x args kwargs x = torch ones TestTensor x test_storage_base_new OK call super __new__ see https github com pytorch pytorch issues TestStorage torch _C StorageBase staticmethod __new__ cls x args kwargs super __new__ cls x args kwargs x = torch UntypedStorage TestStorage x test_pyobj_preserved x = torch empty x foo = put something __dict__ y = torch empty y grad = x del x x dead Python assertEqual y grad foo z = y grad s live del z s dead again assertEqual y grad foo test_subclass_preserved MyTensor torch Tensor pass x = MyTensor torch empty y = torch empty y grad = x del x x dead Python assertEqual type y grad MyTensor z = y grad s live del z s dead again assertEqual type y grad MyTensor skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_dealloc m t = Tracker make s = torch UntypedStorage s = s s _tracker = t del t assertFalse m del s assertFalse m del s assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_from_tensor_dealloc m t = Tracker make = torch randn s = untyped_storage s _tracker = t del t s = untyped_storage assertTrue s s assertTrue hasattr s _tracker del assertFalse m del s assertFalse m del s assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_from_tensor_dealloc_zombie m t = Tracker make = torch randn s = untyped_storage s _tracker = t del t s = untyped_storage assertTrue s s assertTrue hasattr s _tracker assertFalse m del s assertFalse m del s assertFalse m del assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_from_tensor_dealloc_resurrected m t = Tracker make = torch randn s = untyped_storage s _tracker = t del t s = untyped_storage assertTrue s s assertTrue hasattr s _tracker assertFalse m del s assertFalse m del s assertFalse m s = untyped_storage assertTrue isinstance s torch UntypedStorage del assertFalse m del s assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_dealloc_resurrected m t = Tracker make s = torch UntypedStorage s _tracker = t del t = torch tensor s assertFalse m del s assertFalse m s = untyped_storage assertTrue isinstance s torch UntypedStorage del assertFalse m del s assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_dealloc_subclass_zombie MyStorage torch UntypedStorage finalized_count = __del__ MyStorage finalized_count += m t = Tracker make s = MyStorage s _tracker = t del t = torch tensor s assertFalse m del s assertEqual MyStorage finalized_count assertFalse m del assertEqual MyStorage finalized_count assertTrue m skipIfTorchDynamo Tracker hook does work TorchDynamo test_storage_dealloc_subclass_resurrected MyStorage torch UntypedStorage finalized_count = __del__ MyStorage finalized_count += m t = Tracker make s = MyStorage s _tracker = t del t = torch tensor s assertFalse m del s assertEqual MyStorage finalized_count assertFalse m s = untyped_storage del assertFalse m assertEqual MyStorage finalized_count assertTrue isinstance s MyStorage del s assertEqual MyStorage finalized_count assertTrue m test_tensor_ressurecting_clear Regression test https github com pytorch pytorch issues A Tensor custom __dict__ Autograd here c++ reference later t = torch rand requires_grad=True clone t foo = part cycle l = l append l l append t Keep Tensor alive c++ Using autograd graph here any other mean would work t = t assertIs t grad_fn _saved_self t Clear all python references trigger gc del t l gc collect We used loose dict assertTrue hasattr t grad_fn _saved_self foo test_tensor_slot_dealloc SlotTensor torch Tensor __slots__ = slot SlotTensor SlotTensor __slots__ = slot m t = Tracker make m t = Tracker make slot_tensor = SlotTensor torch empty slot_tensor slot = t slot_tensor slot = t del t del t assertFalse m assertFalse m del slot_tensor assertTrue m assertTrue m test_storage_slot_dealloc SlotStorage torch _C StorageBase __slots__ = slot SlotStorage SlotStorage __slots__ = slot m t = Tracker make m t = Tracker make slot_storage = SlotStorage torch UntypedStorage slot_storage slot = t slot_storage slot = t del t del t assertFalse m assertFalse m del slot_storage assertTrue m assertTrue m skipIfTorchDynamo Not suitable test TorchDynamo test_tensor_dict_dealloc m t = Tracker make x = torch empty x arf = t del t assertFalse m del x assertTrue m skipIfTorchDynamo Not suitable test TorchDynamo test_storage_dict_dealloc m t = Tracker make x = torch UntypedStorage x arf = t del t assertFalse m del x assertTrue m test_tensor_finalizer_dealloc m = False FinalizerTensor torch Tensor __del__ m = True fin_tensor = FinalizerTensor torch empty assertFalse m del fin_tensor assertTrue m test_storage_finalizer_dealloc m = False FinalizerStorage torch _C StorageBase __del__ m = True fin_storage = FinalizerStorage torch UntypedStorage assertFalse m del fin_storage assertTrue m skipIfTorchDynamo https github com pytorch torchdynamo issues test_tensor_weakref_dealloc x = torch empty m = False cb r m = True wref = weakref ref x cb del x assertTrue m assertEqual wref None skipIfTorchDynamo https github com pytorch torchdynamo issues test_storage_weakref_dealloc x = torch UntypedStorage m = False cb r m = True wref = weakref ref x cb del x assertTrue m assertEqual wref None skipIfTorchDynamo Not suitable test TorchDynamo test_tensor_cycle_via_dict m t = Tracker make x = torch empty x _tracker = t del t m t = Tracker make y = torch empty y _tracker = t del t x _loop = y y _loop = x C++ reference should keep cycle live This exercise THPVariable_subtype_traverse NB Because z grad reference done entirely C++ cycles involving directly NOT broken Python GC you ve set up good old C++ reference cycle which we cannot safely break because C++ references allowed accessed multithreaded-ly TODO except maybe you can prove only Python has access C++ object which case you can also prove no multithreaded access occurs z = torch empty z grad = x del x del y gc collect assertFalse m assertFalse m disable_gc del z assertFalse m assertFalse m gc collect assertTrue m assertTrue m skipIfTorchDynamo Not suitable test TorchDynamo test_storage_cycle_via_dict m t = Tracker make x = torch UntypedStorage x _tracker = t del t m t = Tracker make y = torch UntypedStorage y _tracker = t del t x _loop = y y _loop = x C++ reference should keep cycle live This exercise THPVariable_subtype_traverse NB Because z grad reference done entirely C++ cycles involving directly NOT broken Python GC you ve set up good old C++ reference cycle which we cannot safely break because C++ references allowed accessed multithreaded-ly TODO except maybe you can prove only Python has access C++ object which case you can also prove no multithreaded access occurs z = torch UntypedStorage z grad = x del x del y gc collect assertFalse m assertFalse m disable_gc del z assertFalse m assertFalse m gc collect assertTrue m assertTrue m test_tensor_cycle_via_slots m = False m = False SlotTensor torch Tensor __slots__ = slot __del__ m = True SlotTensor SlotTensor __slots__ = slot __del__ m = True x = SlotTensor torch empty x_ref = weakref ref x y = SlotTensor torch empty x slot = y y slot = x del x disable_gc del y assertFalse m assertFalse m gc collect assertTrue m assertTrue m assertIsNone x_ref At point we know finalizer ran weakref cleared But object really gone assertFalse any isinstance o SlotTensor o gc get_objects test_storage_cycle_via_slots m = False m = False SlotStorage torch _C StorageBase __slots__ = slot __del__ m = True SlotStorage SlotStorage __slots__ = slot __del__ m = True x = SlotStorage torch UntypedStorage y = SlotStorage torch UntypedStorage x slot = y y slot = x del x disable_gc del y assertFalse m assertFalse m gc collect assertTrue m assertTrue m skipIfTorchDynamo Not suitable test TorchDynamo test_storage_preserve_nonhermetic_in_hermetic_context torch library Library impl global _my_storage my_lib = Library my_lib DEF noqa TOR my_lib define my_func - None = torch tensor _my_storage = untyped_storage m t = Tracker make _my_storage _tracker = t del t impl my_lib my_func my_func global _my_storage del _my_storage assertFalse m torch ops my_lib my_func assertFalse m s = untyped_storage del del s assertTrue m FIXME move test_autograd skipIfTorchDynamo TorchDynamo does work well hooks test_backward_hooks_traverse m t = Tracker make m t = Tracker make x = torch empty requires_grad=True x _tracker = t y = torch empty requires_grad=True y _tracker = t del t del t hits special setter s just __dict__ entry x _backward_hooks = y y _backward_hooks = x del x disable_gc del y assertFalse m assertFalse m gc collect assertTrue m assertTrue m skipIfTorchDynamo https github com pytorch torchdynamo issues test_tensor_dead_weak_ref x = torch empty w_x = weakref ref x y = torch empty y grad = x del x x = w_x Ideally x would keep tensor live But CPython doesn t provide enough hooks do So will go dead x will transmute into undefined tensor Not great best we can do del y assertRaises RuntimeError lambda x sigmoid skipIfTorchDynamo https github com pytorch torchdynamo issues test_storage_dead_weak_ref x = torch UntypedStorage w_x = weakref ref x y = torch tensor x del x x = w_x Ideally x would keep storage live But CPython doesn t provide enough hooks do So will go dead x will transmute into storage null StorageImpl Not great best we can do del y assertRaisesRegex RuntimeError Got null Storage lambda x assertRaisesRegex RuntimeError Got null Storage lambda x float test_tensor_resurrected_weak_ref x = torch empty w_x = weakref ref x y = torch empty y grad = x del x x = w_x Use manually fix weak references after dereferencing them x _fix_weakref del y x sigmoid test_storage_resurrected_weak_ref x = torch UntypedStorage w_x = weakref ref x y = torch tensor x del x x = w_x Use manually fix weak reference after dereferencing them x _fix_weakref del y x float skipIfTorchDynamo https github com pytorch torchdynamo issues test_tensor_fix_weakref_no_leak weakref called = False = torch randn callback w nonlocal called called = True _wa = weakref ref callback _fix_weakref del assertTrue called skipIfTorchDynamo https github com pytorch torchdynamo issues test_storage_fix_weakref_no_leak weakref called = False = torch UntypedStorage callback w nonlocal called called = True _wa = weakref ref callback _fix_weakref del assertTrue called FIXME move test_linalg torch inference_mode test_bmm_multithreaded device = cpu num_threads = torch get_num_threads torch set_num_threads batch_sizes = M N O = dtype = torch float numpy_dtype = dtype invert_perm p d = x i i x enumerate p d d d generate_inputs num_batches transposed tensors perm perm itertools product itertools permutations repeat= b = make_tensor num_batches M N dtype=dtype device=device low=- high= b = make_tensor num_batches N O dtype=dtype device=device low=- high= b = b permute perm contiguous permute invert_perm perm b = b permute perm contiguous permute invert_perm perm yield b b broadcasting tensors b b b b b b itertools product True False repeat= shape = num_batches b M b N b shape = num_batches b N b O b b = make_tensor shape dtype=dtype device=device low=- high= expand num_batches M N b = make_tensor shape dtype=dtype device=device low=- high= expand num_batches N O yield b b zero-sized tensors z z z z itertools product True False repeat= shape = num_batches z M z N z shape = num_batches z N z O z b = torch randn shape dtype=dtype device=device b = torch randn shape dtype=dtype device=device yield b b try num_batches batch_sizes b b perm itertools product generate_inputs num_batches itertools permutations res = torch bmm b b res = torch full num_batches M O math nan dtype=dtype device=device \ permute perm contiguous permute invert_perm perm torch bmm b b out=res expect = torch from_numpy b numpy_dtype cpu numpy b numpy_dtype cpu numpy device=device dtype=dtype assertEqual expect res assertEqual expect res finally torch set_num_threads num_threads test_conj_neg_tolist x = torch randn dtype=torch cfloat y = x conj y _expect = x conj_physical y = y imag assertEqual y y _expect tolist assertEqual y y _expect imag tolist unittest skipIf torch backends cuda is_built Skipped cuda-enabled build test_no_cuda_monkeypatch Note test_cuda py whole file skipped when cuda available assertRaisesRegex RuntimeError torch cuda Stream requires CUDA support torch cuda Stream assertRaisesRegex RuntimeError Tried instantiate dummy base Event torch cuda Event assertRaisesRegex RuntimeError Tried instantiate dummy base CUDAGraph torch cuda graphs CUDAGraph test_tensor_where_scalar = torch arange not_zero = b generated through torch where function not_zero being scalar parameter b = torch where = not_zero c generated through Tensor where method not_zero being scalar parameter c = where = not_zero assertEqual b c test_data_ptr_of_empty_tensor_with_storage t = torch empty assertNotEqual t data_ptr t resize_ assertEqual t data_ptr test_data_ptr_of_empty_view_with_storage t = torch empty assertNotEqual t data_ptr t = t view assertEqual t data_ptr test_size_stride - None t = torch rand dtype=torch float assertEqual t size assertEqual t size dim=None torch Size assertEqual t stride dim=None torch Size assertEqual t t stride torch Size test_invalid_arg_error_handling - None Tests errors old TH functions propagated back invalid_val - assertRaises ValueError RuntimeError lambda torch set_num_threads invalid_val assertRaises ValueError RuntimeError lambda torch set_num_interop_threads invalid_val _get_tensor_prop t preserved = id t Refcount values get modified Dynamo resume frames TEST_WITH_TORCHDYNAMO sys getrefcount t slotnames = copyreg _slotnames t __class__ moved = slotnames id t __dict__ tuple t __dict__ keys getattr t name None name slotnames preserved moved _checked_swap t t t _pres t _moved = _get_tensor_prop t t _pres t _moved = _get_tensor_prop t torch utils swap_tensors t t new_t _pres new_t _moved = _get_tensor_prop t new_t _pres new_t _moved = _get_tensor_prop t assertEqual t _pres new_t _pres assertEqual t _pres new_t _pres assertEqual t _moved new_t _moved assertEqual t _moved new_t _moved tests PyObject slots TensorImpl correctly swapped checking when function applied swapped tensor returns doesn t change TensorImpl returned value which given returning reference PyObject TensorImpl s PyObjectSlot still correct assertEqual id t fill_ id t assertEqual id t fill_ id t unittest skipIf TEST_WITH_TORCHDYNAMO Dynamo adds weakrefs test_swap_basic ts = torch rand torch rand torch empty dtype=torch int TwoTensor torch rand torch rand t t itertools combinations ts t = t clone t = t clone t foo = bar holder = holder append t _checked_swap t t assertIs holder t assertEqual t foo bar t is_floating_point t = t detach clone requires_grad_ True out = t torch utils swap_tensors t t assertRaisesRegex RuntimeError AccumulateGrad node poisoned swap_tensors out sum backward _wr = weakref ref t assertRaisesRegex RuntimeError has weakref torch utils swap_tensors t t unittest skipIf TEST_WITH_TORCHDYNAMO Dynamo adds weakrefs test_swap_fail_slots MyTwoTensor TwoTensor __slots__ = b MyTwoTensor TwoTensor __slots__ = b MyTwoTensor TwoTensor __slots__ = b c d MyTwoTensor TwoTensor __slots__ = c t = torch rand t = TwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand t = MyTwoTensor torch rand torch rand _checked_swap t t assertRaisesRegex RuntimeError Cannot swap t t they have different slots torch utils swap_tensors t t assertRaisesRegex RuntimeError Cannot swap t t they have different slots torch utils swap_tensors t t assertRaisesRegex RuntimeError Cannot swap t t they have different slots torch utils swap_tensors t t _checked_swap t t _checked_swap t t assertRaisesRegex RuntimeError Cannot swap t t they have different slots torch utils swap_tensors t t t c = foo t d = bar _checked_swap t t assertEqual t c foo assertEqual t d bar t c = cat t d = dog _checked_swap t t unittest skipIf torch cuda is_available Test specific CPU test_bf _supported_on_cpu assertFalse torch cuda is_bf _supported test_tensor_with_grad_to_scalar_warning - None warnings catch_warnings record=True w set_warn_always_context True warnings simplefilter always x = torch tensor requires_grad=True math pow x calling results warning assertEqual len w assertTrue issubclass w category UserWarning assertIn Converting tensor requires_grad=True scalar may lead unexpected behavior str w message test_tensor_item_no_warning warnings catch_warnings record=True w set_warn_always_context True warnings simplefilter always x = torch tensor requires_grad=True max x No warning x item No warning assertEqual len w The following block extends TestTorch negative dim wrapping tests FIXME replace these OpInfo sample inputs systemic OpInfo tests Functions test negative dimension wrapping METHOD = INPLACE_METHOD = FUNCTIONAL = DIM_ARG None = None make_neg_dim_test name tensor_arg arg_constr types extra_dim= neg_dim_test isinstance tensor_arg list assert METHOD types INPLACE_METHOD types x = torch randn arg arg tensor_arg ndim = len tensor_arg - x = torch randn tensor_arg ndim = len tensor_arg ndim += extra_dim n_dim_to_test = sum e DIM_ARG e arg_constr dims_val combinations range ndim n_dim_to_test arg = arg_constr arg_neg = copy deepcopy arg idx = i v enumerate arg v DIM_ARG arg i = dims_val idx arg_neg i = dims_val idx - ndim idx += METHOD types = getattr x name arg b = getattr x name arg_neg assertEqual b INPLACE_METHOD types = x clone getattr name + _ arg b = x clone getattr b name + _ arg_neg assertEqual b FUNCTIONAL types = getattr torch name x arg b = getattr torch name x arg_neg assertEqual b neg_dim_test idx_tensor size max_val torch LongTensor size random_ max_val - add_neg_dim_tests neg_dim_tests = narrow lambda DIM_ARG METHOD transpose lambda DIM_ARG DIM_ARG METHOD INPLACE_METHOD FUNCTIONAL size lambda DIM_ARG METHOD cat lambda DIM_ARG FUNCTIONAL chunk lambda DIM_ARG METHOD FUNCTIONAL gather lambda DIM_ARG idx_tensor METHOD FUNCTIONAL index_select lambda DIM_ARG idx_tensor METHOD FUNCTIONAL split lambda DIM_ARG METHOD FUNCTIONAL squeeze lambda DIM_ARG METHOD INPLACE_METHOD FUNCTIONAL unbind lambda DIM_ARG FUNCTIONAL unsqueeze lambda DIM_ARG METHOD INPLACE_METHOD FUNCTIONAL logcumsumexp lambda DIM_ARG METHOD FUNCTIONAL cumprod lambda DIM_ARG METHOD FUNCTIONAL cumsum lambda DIM_ARG METHOD FUNCTIONAL cummax lambda DIM_ARG METHOD FUNCTIONAL cummin lambda DIM_ARG METHOD FUNCTIONAL mean lambda DIM_ARG METHOD FUNCTIONAL median lambda DIM_ARG METHOD FUNCTIONAL nanmedian lambda DIM_ARG METHOD FUNCTIONAL mode lambda DIM_ARG METHOD FUNCTIONAL norm lambda DIM_ARG METHOD FUNCTIONAL prod lambda DIM_ARG METHOD FUNCTIONAL std lambda DIM_ARG METHOD FUNCTIONAL sum lambda DIM_ARG METHOD FUNCTIONAL var lambda DIM_ARG METHOD FUNCTIONAL kthvalue lambda DIM_ARG METHOD FUNCTIONAL max lambda DIM_ARG METHOD FUNCTIONAL min lambda DIM_ARG METHOD FUNCTIONAL sort lambda DIM_ARG METHOD FUNCTIONAL topk lambda DIM_ARG METHOD FUNCTIONAL renorm lambda DIM_ARG METHOD INPLACE_METHOD FUNCTIONAL index_add lambda DIM_ARG idx_tensor torch randn INPLACE_METHOD index_copy lambda DIM_ARG idx_tensor torch randn INPLACE_METHOD index_fill lambda DIM_ARG idx_tensor INPLACE_METHOD scatter lambda DIM_ARG idx_tensor torch randn INPLACE_METHOD select lambda DIM_ARG METHOD unfold lambda DIM_ARG METHOD decl neg_dim_tests len decl == name tensor_arg arg_constr types = decl extra_dim = len decl == name tensor_arg arg_constr types extra_dim = decl test_name = test_ + name + _neg_dim assert hasattr TestTorch test_name Duplicated test name + test_name setattr TestTorch test_name make_neg_dim_test name tensor_arg arg_constr types extra_dim TODO these empty classes temporarily instantiated XLA compatibility once XLA updates their test suite should removed TestViewOps TestCase pass TestTensorDeviceOps TestCase pass Generates tests Note test generation must done file scope within main pytest will fail add_neg_dim_tests instantiate_device_type_tests TestViewOps globals instantiate_device_type_tests TestVitalSignsCuda globals instantiate_device_type_tests TestTensorDeviceOps globals instantiate_device_type_tests TestTorchDeviceType globals instantiate_device_type_tests TestDevicePrecision globals except_for= cpu __name__ == __main__ TestCase _default_dtype_check_enabled = True run_tests