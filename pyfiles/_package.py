glob io json logging os tempfile zipfile dataclasses dataclass typing Any IO Optional TYPE_CHECKING TypeAlias Union torch torch utils _pytree pytree torch _export serde schema torch _export serde serialize _dataclass_to_dict _dict_to_dataclass deserialize_device deserialize_scalar_type deserialize_size deserialize_storage_offset deserialize_stride ExportedProgramDeserializer serialize serialize_tensor_meta SerializedArtifact torch _inductor cpp_builder normalize_path_separator torch _subclasses fake_tensor FakeTensor torch export ExportedProgram torch export _tree_utils reorder_kwargs torch export pt _archive _package_weights get_complete group_weights TensorProperties Weights torch export pt _archive constants AOTINDUCTOR_DIR ARCHIVE_FORMAT_PATH ARCHIVE_FORMAT_VALUE ARCHIVE_VERSION_PATH ARCHIVE_VERSION_VALUE CONSTANTS_CONFIG_FILENAME_FORMAT CONSTANTS_DIR CUSTOM_OBJ_FILENAME_PREFIX EXECUTORCH_DIR EXTRA_DIR MODELS_DIR MODELS_FILENAME_FORMAT SAMPLE_INPUTS_FILENAME_FORMAT TENSOR_CONSTANT_FILENAME_PREFIX WEIGHT_FILENAME_PREFIX WEIGHTS_CONFIG_FILENAME_FORMAT WEIGHTS_DIR torch types FileLike TYPE_CHECKING torch utils _ordered_set OrderedSet DEFAULT_PICKLE_PROTOCOL = AOTI_FILES TypeAlias = Union list Union str Weights dict str list Union str Weights logger logging Logger = logging getLogger __name__ is_pt _package serialized_model Union bytes str - bool Check serialized model PT Archive package try zip_reader = zipfile ZipFile io BytesIO serialized_model isinstance serialized_model bytes serialized_model root_folder = zip_reader namelist split os path sep archive_format_path = f root_folder ARCHIVE_FORMAT_PATH archive_format_path zip_reader namelist zip_reader read archive_format_path == b pt except Exception logger info Model PT package False PT ArchiveWriter Context manager writing PT archive __init__ archive_path_or_buffer FileLike isinstance archive_path_or_buffer str archive_path_or_buffer = normalize_path_separator archive_path_or_buffer archive_file = torch _C PyTorchFileWriter archive_path_or_buffer type ignore arg-type NOTICE version here different archive_version version zip file format which used PyTorchFileWriter which write data version archive_version version PT archive spec which write archive_version archive_file set_min_version __enter__ - PT ArchiveWriter __exit__ args Any - None has_record ARCHIVE_FORMAT_PATH write_string ARCHIVE_FORMAT_PATH ARCHIVE_FORMAT_VALUE has_record ARCHIVE_VERSION_PATH write_string ARCHIVE_VERSION_PATH ARCHIVE_VERSION_VALUE close has_record name str - bool Check record exists archive name archive_file get_all_written_records count_prefix prefix str - int Count number records start given prefix sum record archive_file get_all_written_records record startswith prefix write_bytes name str data bytes - None Write bytes object archive name The destination file inside archive data The bytes object write assert isinstance data bytes f Expected bytes got type data archive_file write_record name data len data write_string name str data str - None Write string object archive name The destination file inside archive data The string object write assert isinstance data str f Expected string got type data data_bytes = data encode write_bytes name data_bytes write_file name str file_path str - None Copy file into archive name The destination file inside archive file_path The source file disk assert os path isfile file_path f file_path valid file path open file_path rb f file_bytes = f read write_bytes name file_bytes write_folder archive_dir str folder_dir str - None Copy folder into archive archive_dir The destination folder inside archive folder_dir The source folder disk assert os path isdir folder_dir f folder_dir valid directory path file_paths = filter os path isfile glob glob f folder_dir recursive=True file_path file_paths pyrefly ignore no-matching-overload filename = os path relpath file_path folder_dir archive_path = os path join archive_dir filename pyrefly ignore bad-argument-type write_file archive_path file_path close - None Close archive archive_file write_end_of_file PT ArchiveReader Context manager reading PT archive __init__ archive_path_or_buffer FileLike isinstance archive_path_or_buffer str archive_path_or_buffer = normalize_path_separator archive_path_or_buffer archive_file = torch _C PyTorchFileReader archive_path_or_buffer type ignore arg-type assert read_string ARCHIVE_FORMAT_PATH == ARCHIVE_FORMAT_VALUE Invalid archive format __enter__ - PT ArchiveReader __exit__ args Any - None torch _C PyTorchFileReader doesn t have close method pass read_bytes name str - bytes Read bytes object archive name The source file inside archive archive_file get_record name read_string name str - str Read string object archive name The source file inside archive data = read_bytes name data decode archive_version - int Get archive version try archive_version = read_string ARCHIVE_VERSION_PATH except Exception archive_version found means archive older than version In case we assume archive version archive_version = int archive_version get_file_names - list str Get file names archive archive_file get_all_records is_pt _package __module__ = torch export pt _archive PT ArchiveWriter __module__ = torch export pt _archive PT ArchiveReader __module__ = torch export pt _archive _package_aoti_files archive_writer PT ArchiveWriter aoti_files Optional AOTI_FILES pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - None aoti_files None isinstance aoti_files list aoti_files = model aoti_files assert isinstance aoti_files dict all_weights dict str Weights = model_name - weight weights_configs dict str dict str Any = model_name - weight_name - filename shape stride offset model_name files aoti_files items num_so_files = weights_configs model_name = file files file == continue isinstance file Weights all_weights model_name = file continue file endswith so num_so_files += num_so_files raise RuntimeError f Multiple so files found files You might need clear your cache directory before calling aoti_compile again filename = os path basename file filename startswith CUSTOM_OBJ_FILENAME_PREFIX new_filepath = os path join CONSTANTS_DIR filename new_filepath = os path join AOTINDUCTOR_DIR model_name filename logger debug Saving AOTI generated file s archive s file new_filepath archive_writer write_file str new_filepath file len all_weights Dedup weights grouped_tensors list OrderedSet tuple str str = group_weights all_weights idx group enumerate grouped_tensors filename = f WEIGHT_FILENAME_PREFIX idx model_name weight_name = get_complete group all_weights complete_tensor _ = all_weights model_name get_weight weight_name buffer = io BytesIO torch save complete_tensor buffer pickle_protocol=pickle_protocol archive_writer write_bytes os path join WEIGHTS_DIR filename buffer getvalue model_name weight_name group _ w_property = all_weights model_name get_weight weight_name weights_configs model_name weight_name = filename w_property shape w_property stride w_property offset model_name weights_config weights_configs items archive_writer write_string os path join AOTINDUCTOR_DIR model_name weights_config json json dumps weights_config logger debug packaging weights_config model s model_name logger debug weights_config _is_fake_tensor t torch Tensor - bool isinstance t FakeTensor _is_tensor_subclass t torch Tensor - bool isinstance t torch Tensor type t data torch Tensor _get_raw_tensor_bytes value torch Tensor - bytes Get raw bytes tensor This used save tensor pt archive NOTE don t chain cpu data_ptr If HtoD copy needs performed CPU copy needs kept alive when its underlying memory accessed ctypes _is_fake_tensor value value_bytes = b value data_ptr cpu_tensor = value cpu value_untyped_storage = cpu_tensor untyped_storage we store raw bytes untyped storage Tensor metadata stored separately value_bytes = bytes ctypes cast value_untyped_storage data_ptr ctypes POINTER ctypes c_ubyte value_untyped_storage size contents empty tensor value_bytes = b value_bytes _should_use_pickle t torch Tensor - bool _is_tensor_subclass t _is_fake_tensor t _save_pickled_tensors pickled_items list tuple str torch Tensor archive_writer PT ArchiveWriter config dict str schema PayloadMeta directory str filename_prefix str idx int pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - int Save pickled tensors update config Returns updated index item_fqn tensor pickled_items path_name = f filename_prefix idx archive_path = os path join directory path_name buffer = io BytesIO torch save tensor buffer pickle_protocol=pickle_protocol archive_writer write_bytes archive_path buffer getvalue config item_fqn = schema PayloadMeta path_name=path_name is_param=isinstance tensor torch nn Parameter use_pickle=True tensor_meta=serialize_tensor_meta tensor idx += idx _save_raw_tensors raw_items dict str tuple torch Tensor TensorProperties model_name str archive_writer PT ArchiveWriter config dict str schema PayloadMeta directory str filename_prefix str idx int - int Save deduplicated raw tensor bytes update config Returns updated index raw_items idx weights_dict = model_name Weights raw_items storage_groups = group_weights weights_dict group storage_groups Find complete tensor covers all others storage group model_name complete_item_name = get_complete group weights_dict complete_tensor _ = weights_dict model_name get_weight complete_item_name path_name = f filename_prefix idx archive_path = os path join directory path_name tensor_bytes = _get_raw_tensor_bytes complete_tensor archive_writer write_bytes archive_path tensor_bytes idx += _ item_fqn group tensor _ = weights_dict model_name get_weight item_fqn config item_fqn = schema PayloadMeta path_name=path_name is_param=isinstance tensor torch nn Parameter use_pickle=False tensor_meta=serialize_tensor_meta tensor idx _package_state_dict model_name str exported_program ExportedProgram archive_writer PT ArchiveWriter pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - schema PayloadConfig weights_config dict str schema PayloadMeta = pickled_weights list tuple str torch Tensor = raw_weights dict str tuple torch Tensor TensorProperties = Categorize weights weight_fqn weight_tensor exported_program state_dict items assert isinstance weight_tensor torch Tensor only torch Tensor allowed state_dict _should_use_pickle weight_tensor pickled_weights append weight_fqn weight_tensor raw_weights weight_fqn = weight_tensor TensorProperties weight_tensor idx = archive_writer count_prefix os path join WEIGHTS_DIR WEIGHT_FILENAME_PREFIX Save weights pickle format idx = _save_pickled_tensors pickled_weights archive_writer weights_config WEIGHTS_DIR WEIGHT_FILENAME_PREFIX idx pickle_protocol Save weights raw bytes format _save_raw_tensors raw_weights model_name archive_writer weights_config WEIGHTS_DIR WEIGHT_FILENAME_PREFIX idx schema PayloadConfig config=weights_config _package_constants model_name str exported_program ExportedProgram archive_writer PT ArchiveWriter pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - schema PayloadConfig constants_config dict str schema PayloadMeta = pickled_constants list tuple str torch Tensor = raw_constants dict str tuple torch Tensor TensorProperties = custom_objects list tuple str torch _C ScriptObject = Categorize constants constant_fqn constant exported_program constants items isinstance constant torch Tensor _should_use_pickle constant pickled_constants append constant_fqn constant raw_constants constant_fqn = constant TensorProperties constant isinstance constant torch _C ScriptObject custom_objects append constant_fqn constant raise RuntimeError f Unsupported constant type type constant tensor_idx = archive_writer count_prefix os path join CONSTANTS_DIR TENSOR_CONSTANT_FILENAME_PREFIX custom_obj_idx = archive_writer count_prefix os path join CONSTANTS_DIR CUSTOM_OBJ_FILENAME_PREFIX Save constants pickle format tensor_idx = _save_pickled_tensors pickled_constants archive_writer constants_config CONSTANTS_DIR TENSOR_CONSTANT_FILENAME_PREFIX tensor_idx pickle_protocol Save constants raw bytes format _save_raw_tensors raw_constants model_name archive_writer constants_config CONSTANTS_DIR TENSOR_CONSTANT_FILENAME_PREFIX tensor_idx Handle custom objects constant_fqn constant custom_objects path_name = f CUSTOM_OBJ_FILENAME_PREFIX custom_obj_idx archive_path = os path join CONSTANTS_DIR path_name custom_obj_bytes = torch _C _pickle_save constant archive_writer write_bytes archive_path custom_obj_bytes constants_config constant_fqn = schema PayloadMeta path_name=path_name is_param=False use_pickle=True tensor_meta=None custom_obj_idx += schema PayloadConfig config=constants_config _package_payload_config archive_writer PT ArchiveWriter payload_config schema PayloadConfig config_file str - None Save payload config json file archive archive_writer write_string config_file json dumps _dataclass_to_dict payload_config _package_exported_programs archive_writer PT ArchiveWriter exported_programs Optional Union ExportedProgram dict str ExportedProgram opset_version Optional dict str int = None pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - None exported_programs None isinstance exported_programs ExportedProgram exported_programs = model exported_programs assert isinstance exported_programs dict model_name ep exported_programs items weights_config = _package_state_dict model_name ep archive_writer pickle_protocol weights_config_file = WEIGHTS_CONFIG_FILENAME_FORMAT format model_name _package_payload_config archive_writer weights_config weights_config_file constants_config = _package_constants model_name ep archive_writer pickle_protocol constants_config_file = CONSTANTS_CONFIG_FILENAME_FORMAT format model_name _package_payload_config archive_writer constants_config constants_config_file artifact SerializedArtifact = serialize ep opset_version pickle_protocol archive_writer write_bytes MODELS_FILENAME_FORMAT format model_name artifact exported_program archive_writer write_bytes SAMPLE_INPUTS_FILENAME_FORMAT format model_name artifact example_inputs _package_extra_files archive_writer PT ArchiveWriter extra_files Optional dict str Any - None extra_files None extra_file_name content extra_files items archive_writer write_string f EXTRA_DIR extra_file_name content _package_executorch_files archive_writer PT ArchiveWriter executorch_files Optional dict str bytes - None executorch_files None file_name content executorch_files items archive_writer write_bytes f EXECUTORCH_DIR file_name content package_pt f FileLike exported_programs Optional Union ExportedProgram dict str ExportedProgram = None aoti_files Optional AOTI_FILES = None extra_files Optional dict str Any = None opset_version Optional dict str int = None pickle_protocol int = DEFAULT_PICKLE_PROTOCOL executorch_files Optional dict str bytes = None - FileLike r Saves artifacts PT Archive format The artifact can then loaded using ` ` load_pt ` ` Args f str &#124; os PathLike str &#124; IO bytes A file-like object has implement write flush string containing file name exported_programs Union ExportedProgram dict str ExportedProgram The exported program save dictionary mapping model name exported program save The exported program will saved under models \ json If only one ExportedProgram specified will automatically named model aoti_files Union list str dict str list str A list files generated AOTInductor via ` ` torch _inductor aot_compile aot_inductor package True ` ` dictionary mapping model name its AOTInductor generated files If only one set files specified will automatically named model extra_files Optional Dict str Any Map filename contents which will stored part pt opset_version Optional Dict str int A map opset names version opset pickle_protocol can specified override default protocol executorch_files Optional dict str bytes Optional executorch artifacts save assert exported_programs None aoti_files None extra_files None No value passed ` exported_programs ` ` aoti_files ` ` extra_files ` implying you do plan saving anything isinstance f io IOBase IO f writable f seekable isinstance f str os PathLike os fspath f endswith pt isinstance f tempfile _TemporaryFileWrapper f name endswith pt TODO turn into error logger warning Expect archive file file ending pt buffer Instead got s f isinstance f str os PathLike f = os fspath f pyrefly ignore bad-argument-type PT ArchiveWriter f archive_writer _package_exported_programs archive_writer exported_programs pickle_protocol=pickle_protocol _package_aoti_files archive_writer aoti_files pickle_protocol=pickle_protocol _package_extra_files archive_writer extra_files _package_executorch_files archive_writer executorch_files isinstance f io IOBase IO f seek pyrefly ignore bad-return f AOTICompiledModel Callable AOT Inductor loaded model pt __init__ loader torch _C _aoti AOTIModelPackageLoader - None loader = loader __call__ args kwargs type ignore no-untyped-def call_spec = loader get_call_spec in_spec = pytree treespec_loads call_spec out_spec = pytree treespec_loads call_spec flat_inputs = pytree tree_flatten args reorder_kwargs kwargs in_spec flat_inputs = x x flat_inputs isinstance x torch Tensor flat_outputs = loader boxed_run flat_inputs pytree tree_unflatten flat_outputs out_spec get_metadata - dict str str loader get_metadata load_constants constants_map dict str torch Tensor check_full_update bool user_managed bool = False - None Given mapping constant fqns tensors load constants into model You can use ` ` get_constant_fqns ` ` get list constant fqns needed compiled model Args constants_map A mapping constant fqns tensors check_full_update Whether add check see all constants updated have values loader load_constants constants_map False check_full_update user_managed get_constant_fqns - list str loader get_constant_fqns __deepcopy__ memo Optional dict Any Any - AOTICompiledModel logger warning AOTICompiledModel deepcopy warning AOTICompiledModel loader deepcopied AOTICompiledModel loader dataclass PT ArchiveContents exported_programs dict str ExportedProgram aoti_runners dict str AOTICompiledModel extra_files dict str Any _create_flat_tensor_from_bytes tensor_bytes bytes tensor_meta schema TensorMeta - torch Tensor Create flat tensor raw bytes dtype device requires_grad It will re-strided based size stride storage_offset later dtype = deserialize_scalar_type tensor_meta dtype size = deserialize_size tensor_meta sizes device = deserialize_device tensor_meta device len tensor_bytes = tensor = torch frombuffer tensor_bytes dtype=dtype requires_grad=tensor_meta requires_grad device cannot call torch frombuffer empty bytes logger warning Cannot call torch frombuffer empty bytes Creating tensor zeros workaround tensor = torch zeros size dtype=dtype device=device tensor _build_file_map archive_reader PT ArchiveReader config schema PayloadConfig base_dir str - dict str torch Tensor Build map file path payload flat tensor format file_map dict str torch Tensor = payload_meta config config values skip pickled objects payload_meta use_pickle continue skip files already exist map payload_meta path_name file_map continue tensor_bytes = archive_reader read_bytes os path join base_dir payload_meta path_name assert payload_meta tensor_meta None tensor = _create_flat_tensor_from_bytes tensor_bytes payload_meta tensor_meta file_map payload_meta path_name = tensor file_map _load_payload_config archive_reader PT ArchiveReader config_file str - schema PayloadConfig Load parse payload config archive _dict_to_dataclass schema PayloadConfig json loads archive_reader read_string config_file _load_state_dict archive_reader PT ArchiveReader model_name str - Union dict str torch Tensor bytes Make BC compatible legacy weight files legacy_weights_file = f WEIGHTS_DIR model_name pt legacy_weights_file archive_reader get_file_names logger warning You loading weight legacy format Please generate new pt file using torch export save archive_reader read_bytes legacy_weights_file weights_config_file = WEIGHTS_CONFIG_FILENAME_FORMAT format model_name assert weights_config_file archive_reader get_file_names f weights_config_file found PT archive weights_config = _load_payload_config archive_reader weights_config_file construct mapping file name e g weight_ flat weight payload state_dict_file_map = _build_file_map archive_reader weights_config WEIGHTS_DIR chain mapping weight FQN - weight file name - strided weight payload so aliasing weights preserved state_dict dict str torch Tensor = weight_fqn payload_meta weights_config config items payload_meta use_pickle weight_bytes = archive_reader read_bytes os path join WEIGHTS_DIR payload_meta path_name state_dict weight_fqn = torch load io BytesIO weight_bytes weights_only=False tensor_meta = payload_meta tensor_meta assert tensor_meta None weight_tensor = torch as_strided input=state_dict_file_map payload_meta path_name size=deserialize_size tensor_meta sizes stride=deserialize_stride tensor_meta strides storage_offset=deserialize_storage_offset tensor_meta storage_offset payload_meta is_param state_dict weight_fqn = torch nn Parameter weight_tensor requires_grad=tensor_meta requires_grad state_dict weight_fqn = weight_tensor state_dict _load_constants archive_reader PT ArchiveReader model_name str - Union dict str torch Tensor bytes Make BC compatible legacy constant files legacy_constants_file = f CONSTANTS_DIR model_name pt legacy_constants_file archive_reader get_file_names logger warning You loading constant legacy format Please generate new pt file using torch export save archive_reader read_bytes legacy_constants_file constants_config_file = CONSTANTS_CONFIG_FILENAME_FORMAT format model_name assert constants_config_file archive_reader get_file_names f constants_config_file found PT archive constants_config = _load_payload_config archive_reader constants_config_file construct mapping file name e g constant_ constant payload constant_file_map = _build_file_map archive_reader constants_config CONSTANTS_DIR chain mapping constant FQN - constant file name - strided constant payload so aliasing constants preserved constants dict str torch Tensor = constant_fqn payload_meta constants_config config items path_name = payload_meta path_name path_name startswith TENSOR_CONSTANT_FILENAME_PREFIX payload_meta use_pickle constant_bytes = archive_reader read_bytes os path join CONSTANTS_DIR path_name constants constant_fqn = torch load io BytesIO constant_bytes weights_only=False tensor_meta = payload_meta tensor_meta assert tensor_meta None constant_tensor = torch as_strided input=constant_file_map path_name size=deserialize_size tensor_meta sizes stride=deserialize_stride tensor_meta strides storage_offset=deserialize_storage_offset tensor_meta storage_offset constants constant_fqn = constant_tensor path_name startswith CUSTOM_OBJ_FILENAME_PREFIX constant_bytes = archive_reader read_bytes os path join CONSTANTS_DIR path_name constants constant_fqn = torch _C _pickle_load_obj constant_bytes raise RuntimeError f Unsupported constant type path_name constants _load_exported_programs archive_reader PT ArchiveReader file_names list str expected_opset_version Optional dict str int - dict str ExportedProgram exported_program_files = file file file_names file startswith MODELS_DIR exported_programs = file exported_program_files prefix suffix = MODELS_FILENAME_FORMAT split split models json into models json model_name = file len prefix -len suffix given models foo json we can now get foo sample_inputs_file = SAMPLE_INPUTS_FILENAME_FORMAT format model_name serialized_sample_inputs = archive_reader read_bytes sample_inputs_file torch _export serde serialize _bytes_to_dataclass exported_program_bytes = archive_reader read_bytes file serialized_exported_program = _bytes_to_dataclass schema ExportedProgram exported_program_bytes state_dict = _load_state_dict archive_reader model_name constants = _load_constants archive_reader model_name ep = ExportedProgramDeserializer expected_opset_version deserialize serialized_exported_program state_dict constants serialized_sample_inputs exported_programs model_name = ep exported_programs _load_extra_files archive_reader PT ArchiveReader file_names list str - dict str Any extra_files = file file file_names file startswith EXTRA_DIR extra_file_contents dict str Any = file extra_files contents = archive_reader read_string file extra_file_contents file len EXTRA_DIR = contents extra_file_contents _load_aoti file str model_name str run_single_threaded bool num_runners int device_idx int - AOTICompiledModel loaded_metadata = torch _C _aoti AOTIModelPackageLoader load_metadata_from_package type ignore attr-defined file model_name device = loaded_metadata AOTI_DEVICE_KEY current_device_info = torch _inductor codecache get_device_information device k v current_device_info items k loaded_metadata v = loaded_metadata k logger warning Device information mismatch s s vs s This could cause some issues when loading AOTInductor compiled artifacts k v loaded_metadata k aoti_compiled_model = AOTICompiledModel torch _C _aoti AOTIModelPackageLoader file model_name run_single_threaded num_runners device_idx aoti_compiled_model load_pt f FileLike expected_opset_version Optional dict str int = None run_single_threaded bool = False num_runners int = device_index int = - load_weights_from_disk bool = False - PT ArchiveContents type ignore type-arg Loads all artifacts previously saved ` ` package_pt ` ` Args f str &#124; os PathLike str &#124; IO bytes A file-like object has implement write flush string containing file name expected_opset_version Optional Dict str int A map opset names expected opset versions num_runners int Number runners load AOTInductor artifacts run_single_threaded bool Whether model should run without thread synchronization logic This useful avoid conflicts CUDAGraphs device_index int The index device which PT package loaded By default ` device_index=- ` used which corresponds device ` cuda ` when using CUDA Passing ` device_index= ` would load package ` cuda ` example Returns A ` ` PT ArchiveContents ` ` object which contains all objects PT torch _inductor cpp_builder normalize_path_separator isinstance f io IOBase IO f readable f seekable isinstance f str os PathLike os fspath f endswith pt TODO turn into error logger warning Unable load package f must buffer file ending pt Instead got s f isinstance f str os PathLike f = os fspath f weights = weight_maps = pyrefly ignore bad-argument-type PT ArchiveReader f archive_reader version = archive_reader read_string ARCHIVE_VERSION_PATH version = ARCHIVE_VERSION_VALUE raise ValueError f Saved archive version version does match our current f archive version ARCHIVE_VERSION_VALUE file_names = archive_reader get_file_names exported_programs = _load_exported_programs archive_reader file_names expected_opset_version extra_files = _load_extra_files archive_reader file_names Get list AOTI model names aoti_model_names set str = set file file_names file startswith AOTINDUCTOR_DIR file_end = file len AOTINDUCTOR_DIR remove data aotinductor prefix file_end = normalize_path_separator file_end Win need normalize path before split model_name = file_end split split model_name cpp into model_name aoti_model_names add model_name load_weights_from_disk file endswith weights_config json weight_map = json loads archive_reader read_string file weight_maps model_name = weight_map load_weights_from_disk file startswith WEIGHTS_DIR weight_file_name = file len WEIGHTS_DIR remove data weights prefix weight_bytes = archive_reader read_bytes file loaded_weight = torch load io BytesIO weight_bytes weights weight_file_name = loaded_weight isinstance f io IOBase IO len aoti_model_names Workaround AOTIModelPackageLoader reading buffers tempfile NamedTemporaryFile suffix= pt tf f seek tf write f read f seek logger debug Writing buffer tmp file located s tf name aoti_runners = model_name _load_aoti tf name model_name run_single_threaded num_runners device_index model_name aoti_model_names aoti_runners = aoti_runners = model_name _load_aoti f model_name run_single_threaded num_runners device_index model_name aoti_model_names weight_maps model_name aoti_model_names model_weights = weight_name file shape stride storage_offset weight_maps model_name items weight = weights file model_weights weight_name = weight as_strided shape stride storage_offset user_managed=True ensures weights updates shared all runners aoti_runners model_name load_constants model_weights check_full_update=True user_managed=True PT ArchiveContents exported_programs aoti_runners extra_files load_weights_to_pt _contents pt _contents PT ArchiveContents weights_map dict str Any - None Load weights into models PT archive contents Args pt _contents PT ArchiveContents The contents PT archive model_name weights weights_map items model_name pt _contents aoti_runners raise RuntimeError f Model model_name found PT archive contents pt _contents aoti_runners model_name load_constants weights check_full_update=True user_managed=True