torch torch _inductor config torch _export aot_compile torch export Dim torch manual_seed Net torch nn Module __init__ device size= super __init__ w_pre = torch randn size size device=device w_add = torch randn size size device=device forward x w_transpose = torch transpose w_pre w_relu = torch nn functional relu w_transpose w = w_relu + w_add torch matmul x w NetWithTensorConstants torch nn Module __init__ - None super __init__ w = torch randn device= cuda forward x y z = w x y z data = large_data = cuda_alloc_data = data_with_tensor_constants = Basice AOTI model test generation generate_basic_tests device cpu cuda torch cuda is_available cpu use_runtime_constant_folding True False device == cpu use_runtime_constant_folding We do test runtime const folding cpu mode continue model = Net device device=device x = torch randn device=device torch no_grad ref_output = model x torch _dynamo reset torch no_grad dim _x = Dim dim _x min= max= dynamic_shapes = x dim _x model_so_path = aot_compile model x dynamic_shapes=dynamic_shapes options= aot_inductor use_runtime_constant_folding use_runtime_constant_folding Also store pt file using aoti_compile_and_package API pt _package_path = torch _inductor aoti_compile_and_package torch export export model x dynamic_shapes=dynamic_shapes inductor_configs= aot_inductor use_runtime_constant_folding use_runtime_constant_folding suffix = f device use_runtime_constant_folding suffix += _use_runtime_constant_folding data update f model_so_path_ suffix model_so_path f pt _package_path_ suffix pt _package_path f inputs_ suffix x f outputs_ suffix ref_output f w_pre_ suffix model w_pre f w_add_ suffix model w_add generate_basic_tests_consts_cpp backup_consts_asm_cfg bool = torch _inductor config aot_inductor use_consts_asm_build torch _inductor config aot_inductor use_consts_asm_build = False Test consts cpp build again generate_basic_tests torch _inductor config aot_inductor use_consts_asm_build = backup_consts_asm_cfg generate_large_tests device = cuda model = Net device size= device=device x = torch randn device=device torch no_grad ref_output = model x torch _dynamo reset use_runtime_constant_folding True False torch no_grad model_so_path = aot_compile model x options= aot_inductor use_runtime_constant_folding use_runtime_constant_folding Also store pt file using aoti_compile_and_package API pt _package_path = torch _inductor aoti_compile_and_package torch export export model x inductor_configs= aot_inductor use_runtime_constant_folding use_runtime_constant_folding suffix = _use_runtime_constant_folding use_runtime_constant_folding large_data update noqa F f model_so_path suffix model_so_path f pt _package_path suffix pt _package_path inputs x outputs ref_output w_pre model w_pre w_add model w_add generate_cuda_alloc_test device = cuda model = Net device size= device=device x = torch randn device=device torch no_grad ref_output = model x torch _dynamo reset torch no_grad model_so_path = aot_compile model x options= aot_inductor weight_use_caching_allocator True cuda_alloc_data update noqa F model_so_path model_so_path inputs x outputs ref_output w_pre model w_pre w_add model w_add AOTI model which will create additional tensors during autograd generate_test_with_additional_tensors torch cuda is_available model = NetWithTensorConstants x = torch randn device= cuda y = torch randn device= cuda torch no_grad ref_output = model x y torch _dynamo reset torch no_grad model_so_path = aot_compile model x y Also store pt file using aoti_compile_and_package API pt _package_path = torch _inductor aoti_compile_and_package torch export export model x y data_with_tensor_constants update model_so_path model_so_path pt _package_path pt _package_path inputs x y outputs ref_output w model w generate_basic_tests generate_basic_tests_consts_cpp generate_large_tests generate_test_with_additional_tensors generate_cuda_alloc_test Use communicate tensors cpp code Serializer torch nn Module __init__ data super __init__ key data setattr key data key torch jit script Serializer data save data pt torch jit script Serializer large_data save large_data pt torch jit script Serializer data_with_tensor_constants save data_with_tensor_constants pt torch jit script Serializer cuda_alloc_data save cuda_alloc_data pt