Owner s oncall distributed checkpointing tempfile unittest mock MagicMock patch torch torch distributed checkpoint _hf_utils _HFStorageInfo torch distributed checkpoint metadata MetadataIndex torch distributed checkpoint planner LoadItemType ReadItem torch distributed checkpoint quantized_hf_storage QuantizedHuggingFaceStorageReader torch testing _internal common_utils run_tests TestCase TestQuantizedHfStorage TestCase setUp Set up common test fixtures temp_dir = tempfile TemporaryDirectory path = temp_dir name tearDown Clean up test fixtures temp_dir cleanup test_dequantization Test quantized tensors weights scales both same different files reader = QuantizedHuggingFaceStorageReader path thread_count= Test data two different weights quantized_tensor = torch ones dtype=torch float quantized_tensor = torch ones dtype=torch float Different values scale_inv = torch tensor dtype=torch float scale_inv = torch tensor dtype=torch float Different scale Define weight scale tensor names weight _fqn = model layers self_attn q_proj weight Scale same file scale _fqn = model layers self_attn q_proj weight_scale_inv weight _fqn = model layers self_attn k_proj weight Scale different file scale _fqn = model layers self_attn k_proj weight_scale_inv file _name = model- -of- safetensors file _name = model- -of- safetensors Setup weight-scale mapping file locations reader _weight_scale_mapping = weight _fqn scale _fqn weight _fqn scale _fqn reader _weight_map = weight _fqn file _name Weight file scale _fqn file _name Scale also file same file scenario weight _fqn file _name Weight file scale _fqn file _name Scale file different file scenario Populate tensor shapes cache would normally built read_metadata reader _tensor_full_shapes = weight _fqn torch Size weight _fqn torch Size Mock main safetensors file file mock_file = MagicMock Mock get_slice different tensors based tensor name mock_get_slice tensor_name mock_tensor = MagicMock tensor_name == weight _fqn mock_tensor __getitem__ = lambda _ _slice quantized_tensor tensor_name == weight _fqn mock_tensor __getitem__ = lambda _ _slice quantized_tensor mock_tensor mock_file get_slice = mock_get_slice Mock get_tensor same-file scale scale mock_file get_tensor return_value = scale_inv Mock cross-file safetensors file file scale mock_file = MagicMock mock_file get_tensor return_value = scale_inv Test Same-file scenario weight + scale both file read_item = ReadItem type=LoadItemType TENSOR storage_index=MetadataIndex fqn=weight _fqn offset=torch Size dest_index=MetadataIndex fqn=weight _fqn offset=torch Size storage_offsets= dest_offsets= lengths= target_tensor = torch zeros dtype=torch float mock_planner = MagicMock mock_planner resolve_tensor return_value = target_tensor Process first weight same file scenario reader _process_read_request mock_file read_item mock_planner Verify first tensor dequantized ones = twos expected_result = torch ones dtype=torch float mock_planner commit_tensor assert_called_once Check target_tensor updated correctly args _ = mock_planner commit_tensor call_args committed_tensor = args torch testing assert_close committed_tensor expected_result Test Cross-file scenario weight file scale file read_item = ReadItem type=LoadItemType TENSOR storage_index=MetadataIndex fqn=weight _fqn offset=torch Size dest_index=MetadataIndex fqn=weight _fqn offset=torch Size storage_offsets= dest_offsets= lengths= target_tensor = torch zeros dtype=torch float mock_planner = MagicMock mock_planner resolve_tensor return_value = target_tensor Mock entire safetensors module since may available test environment mock_safetensors = MagicMock mock_safe_open = MagicMock mock_safetensors safe_open = mock_safe_open Set up mock context manager yields mock_file mock_safe_open return_value __enter__ return_value = mock_file mock_safe_open return_value __exit__ return_value = False Mock module safe_open function patch dict sys modules safetensors mock_safetensors Process second weight cross-file scenario reader _process_read_request mock_file read_item mock_planner Verify safe_open called correct file path expected_path = f path file _name mock_safe_open assert_called_once call_args = mock_safe_open call_args assertEqual str call_args expected_path Verify scale tensor loaded correct file mock_file get_tensor assert_called_once_with scale _fqn Verify second tensor dequantized = expected_result = torch ones dtype=torch float mock_planner commit_tensor assert_called_once Check target_tensor updated correctly args _ = mock_planner commit_tensor call_args committed_tensor = args torch testing assert_close committed_tensor expected_result test_dtensor_slice_dequantization_block_alignment Test DTensor slice dequantization proper block alignment logic reader = QuantizedHuggingFaceStorageReader path thread_count= block_size= Small block size easier testing Create larger tensor test multiple blocks Full tensor x block size x so we have x = blocks full_tensor_shape = torch Size Create quantized tensor data slice rows cols This slice spans across multiple blocks slice_tensor = torch ones dtype=torch float Create scale inverse tensor different values each block Scale tensor shape x blocks scale_inv = torch tensor Block = Block = Block = Block = dtype=torch float Define tensor names weight_fqn = model layers attn q_proj weight scale_fqn = model layers attn q_proj weight_scale_inv file_name = model- -of- safetensors Setup mappings reader _weight_scale_mapping = weight_fqn scale_fqn reader _weight_map = weight_fqn file_name scale_fqn file_name Mock storage_data provide tensor shape information reader storage_data = MetadataIndex fqn=weight_fqn offset= _HFStorageInfo relative_path=file_name shape=full_tensor_shape dtype=torch float Populate tensor shapes cache would normally built read_metadata reader _tensor_full_shapes = weight_fqn full_tensor_shape Create ReadItem slice spans multiple blocks Request slice full x tensor read_item = ReadItem type=LoadItemType TENSOR storage_index=MetadataIndex fqn=weight_fqn offset=torch Size dest_index=MetadataIndex fqn=weight_fqn offset=torch Size storage_offsets= Start row col dest_offsets= lengths= x slice Mock safetensors file mock_file = MagicMock Mock get_slice slice tensor mock_tensor_slice = MagicMock mock_tensor_slice __getitem__ = lambda _ _slice slice_tensor mock_file get_slice return_value = mock_tensor_slice Mock get_tensor scale mock_file get_tensor return_value = scale_inv Create target tensor target_tensor = torch zeros dtype=torch float mock_planner = MagicMock mock_planner resolve_tensor return_value = target_tensor Process request reader _process_read_request mock_file read_item mock_planner Verify result mock_planner commit_tensor assert_called_once args _ = mock_planner commit_tensor call_args committed_tensor = args Expected result calculation The slice intersects blocks follows - Block covers - intersection - local scale - Block covers - intersection - local scale - Block covers - intersection - local scale - Block covers - intersection - local scale expected_result = torch zeros dtype=torch float Fill expected values based block intersections expected_result = Block intersection expected_result = Block intersection expected_result = Block intersection expected_result = Block intersection torch testing assert_close committed_tensor expected_result __name__ == __main__ run_tests