mypy allow-untyped-defs __future__ annotations functools logging ctypes byref c_int c_size_t c_void_p typing Any Callable Optional TYPE_CHECKING Union torch torch _inductor config torch _inductor autotune_process BenchmarkRequest GPUDeviceBenchmarkMixin TensorMeta torch _inductor codecache DLLWrapper ROCmCodeCache TYPE_CHECKING collections abc Iterable log = logging getLogger __name__ ROCmBenchmarkRequest GPUDeviceBenchmarkMixin BenchmarkRequest Important Instances have serializable across process boundaries Do put CUDA Tensors here __init__ kernel_name str input_tensor_meta Union TensorMeta list TensorMeta output_tensor_meta Union TensorMeta list TensorMeta extra_args Iterable Any source_code str - None super __init__ kernel_name input_tensor_meta output_tensor_meta extra_args source_code = source_code workspace_size int = workspace Optional torch Tensor = None DLL Optional DLLWrapper = None _workspace_size_updated = False hash_key str = source_file str = hash_key source_file = ROCmCodeCache write source_code so precompile Prepopulate code cache may happen separate Threadpool log debug Precompiling s ROCmCodeCache compile source_code so config rocm generate_test_runner ROCmCodeCache compile source_code exe log debug Done precompiling s make_run_fn input_tensors torch Tensor out torch Tensor - Callable None ensure_dll_loaded update_workspace_size args = c_void_p tensor data_ptr tensor list input_tensors + out size_args = c_int arg arg extra_args log debug make_run_fn kernel_name= s source_file= s hash_key= s DLL= s args= s extra_args= s kernel_name source_file hash_key DLL args extra_args stream_ptr = c_void_p torch cuda current_stream cuda_stream run_method = getattr DLL kernel_name workspace_ptr = c_void_p workspace_size workspace = torch zeros workspace_size + dtype=torch float device=out device workspace_ptr = c_void_p workspace data_ptr Generate partial function functools partial run_method args size_args None null workspace size ptr workspace_ptr set workspace ptr stream_ptr update_workspace_size - None _workspace_size_updated ensure_dll_loaded unique_input_count = len dict fromkeys meta name meta input_tensor_meta args = c_void_p None _ range unique_input_count + stream_ptr = c_void_p torch cuda current_stream cuda_stream run_method = getattr DLL kernel_name Retrieve workspace_size initialize workspace c_workspace_size = c_size_t size_args = c_int arg arg extra_args run_method args input ptrs output ptrs size_args byref c_workspace_size set workspace size ptr retrieve workspace size None null workspace ptr stream_ptr torch cuda synchronize shake out any CUDA errors workspace_size = c_workspace_size value log debug update_workspace_size called new workspace size= d kernel_name= s source_file= s hash_key= s DLL= s args= s extra_args= s noqa B workspace_size kernel_name source_file hash_key DLL args extra_args _workspace_size_updated = True ensure_dll_loaded DLL None DLL hash_key source_file = ROCmCodeCache load source_code so cleanup_run_fn - None DLL None DLL close workspace = None __str__ - str f kernel_name= source_file= hash_key=