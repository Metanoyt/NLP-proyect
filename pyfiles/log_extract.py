mypy allow-untyped-defs contextlib contextmanager typing Any cast random torch time torch utils benchmark Timer extract_ir filename str - list str BEGIN = GRAPH_EXPORT END = GRAPH_EXPORT pfx = None graphs = open filename f split_strs = f read split BEGIN i split_str enumerate split_strs i == continue end_loc = split_str find END end_loc == - continue s = split_str end_loc pfx = split_strs i - splitlines - lines = x len pfx x s splitlines keepends=True graphs append join lines graphs make_tensor_from_type inp_type torch _C TensorType size = inp_type sizes stride = inp_type strides device = inp_type device dtype = inp_type dtype size None raise AssertionError make_tensor_from_type size None inp_type sizes returned None stride None raise AssertionError make_tensor_from_type stride None inp_type strides returned None device None raise AssertionError make_tensor_from_type device None inp_type device returned None dtype None raise AssertionError make_tensor_from_type dtype None inp_type dtype returned None torch empty_strided size=size stride=stride device=device dtype=dtype load_graph_and_inputs ir str - tuple Any list Any graph = torch _C parse_ir ir parse_tensor_constants=True graph makeMultiOutputIntoTuple inputs = inp graph inputs isinstance inp type torch _C FloatType inputs append random uniform isinstance inp type torch _C IntType inputs append random randint isinstance inp type torch _C TensorType tensorType = cast torch _C TensorType inp type inputs append make_tensor_from_type tensorType isinstance inp type torch _C BoolType inputs append random randint == raise NotImplementedError f A default value implemented type inp type func = torch _C _create_function_from_graph forward graph torch _C _jit_pass_erase_shape_information func graph func inputs time_cuda fn inputs test_runs t = Timer stmt= fn inputs globals= fn fn inputs inputs times = t blocked_autorange times median time ms time_cpu fn inputs test_runs s = time perf_counter _ range test_runs fn inputs e = time perf_counter e - s test_runs time ms run_test ir inputs warmup_runs= test_runs= - float graph _ = load_graph_and_inputs ir _ range warmup_runs graph inputs is_cpu = None input inputs isinstance input torch Tensor is_cpu = input device type == cpu break is_cpu None raise AssertionError No tensor found inputs out = time_cpu graph inputs test_runs is_cpu time_cuda graph inputs test_runs out contextmanager no_fuser args kwargs old_optimize = torch _C _get_graph_executor_optimize False try yield finally torch _C _get_graph_executor_optimize old_optimize run_baseline_no_fusion ir inputs - float no_fuser run_test ir inputs run_nnc ir inputs dynamic - float try strat = DYNAMIC dynamic STATIC old_strat = torch jit set_fusion_strategy strat torch jit fuser fuser run_test ir inputs finally torch jit set_fusion_strategy old_strat run_nvfuser ir inputs - float torch jit fuser fuser run_test ir inputs