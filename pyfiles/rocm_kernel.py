mypy allow-untyped-defs logging collections abc Sequence typing Any Callable Optional TYPE_CHECKING Union torch _inductor config config torch _inductor codegen cpp_wrapper_cpu CppWrapperCpu torch _inductor utils do_bench_using_profiling ir Buffer ChoiceCaller IRNode Layout PrimitiveInfoType ShapeAsConstantBuffer TensorBox virtualized V common Kernel OpOverrides WorkspaceArg WorkspaceZeroMode cpp_utils CppPrinter rocm_benchmark_request ROCmBenchmarkRequest rocm_template_buffer ROCmTemplateBuffer rocm_utils DTYPE_TO_ROCM_TYPE TYPE_CHECKING torch _inductor codegen rocm rocm_template ArgInfo ROCmTemplate log = logging getLogger __name__ cexpr = CppPrinter doprint _normalize_idx index int total_length int - int index index = index + total_length ROCmKernel Kernel Baseclass ROCm based Kernels overrides = OpOverrides type ignore assignment ROCmTemplateKernel ROCmKernel Template kernels defined ROCm C++ _EXTRA_CPP_ARGS = size_t workspace_size uint _t workspace hipStream_t stream __init__ kernel_name str runtime_arg_info list ArgInfo runtime_arg_values list Any - None Initializes new instance ROCmTemplateKernel Args kernel_name str The name kernel super __init__ kernel_name = kernel_name Mapping arg name IRNode named_nodes dict str IRNode = runtime_arg_info = runtime_arg_info runtime_arg_values = runtime_arg_values get_signature signature def_kernel inputs list IRNode outputs list IRNode size_args list str names_str str = input_reorder Optional list int = None - str Hook called template code generate function definition needed args Args inputs List input IRNodes outputs List output IRNodes names_str Comma separated list input + output argument names input_reorder The actual order input nodes e g The template might have input argument defined X W Bias actual input passed into template could Bias X W In case ` input_reorder ` would names = x strip x names_str strip split len inputs + len outputs = len names raise RuntimeError f len inputs + len outputs = = len names = inputs= outputs= names= input_reorder == input_reorder = input_reorder None assert len inputs == len input_reorder input_reorder = list range len inputs idx input_reorder name = names idx node = inputs idx node None named_nodes name = node args input_buffers node get_name = name name node zip names len inputs len inputs + len outputs outputs node None named_nodes name = node args output_buffers node get_name = name arg_defs _ = args cpp_argdefs DTYPE_TO_ROCM_TYPE runtime_arg_defs = f arg ty arg name arg runtime_arg_info signature = f int kernel_name join arg_defs + size_args + runtime_arg_defs _EXTRA_CPP_ARGS signature = signature signature call_kernel name str node ROCmTemplateBuffer type ignore name-defined - None Generates code call kernel through V graph wrapper_code used within torch _inductor wrapper PythonWrapperCodegen name Name kernel function node The ROCmTemplateBuffer node which contains information about kernel s fused epilogue nodes well all required inputs outputs wrapper = V graph wrapper_code arg_types list Any V graph cpp_wrapper Make sure we initialize these kernels since they re exported C-style symbol names assert isinstance wrapper CppWrapperCpu wrapper initialized_kernels name = Kinda hacky because we always originally initialize name KERNEL_NAME So we replace real kernel name passed arg function signature = signature replace KERNEL_NAME name _ call_args arg_types = args cpp_argdefs DTYPE_TO_ROCM_TYPE _ call_args _ arg_types = args python_argdefs kernel_args = arg call_args dynamo wraps unspec variable d CPU tensor need convert scalar V graph is_unspec_arg arg arg = arg + item V graph cpp_wrapper arg = f c_void_p arg data_ptr kernel_args append arg add size args size_args = f V graph sizevars simplify sarg sarg node template size_args V graph cpp_wrapper kernel_args extend size_args kernel_args extend f c_int sarg sarg size_args V graph cpp_wrapper arg_types extend int len node template size_args runtime args come right after size args kernel_args extend runtime_arg_values arg runtime_arg_info arg_types append arg ty workspace_size ptr NULL mark call intended retrieving workspace_size workspace_size should have already been retrieved prior call kernel_args append nullptr V graph cpp_wrapper None V graph cpp_wrapper arg_types append size_t node get_workspace_size ws = WorkspaceArg count=node get_workspace_size device=V graph get_current_device_or_throw zero_mode=WorkspaceZeroMode UNINITIALIZED outer_name=WorkspaceArg unique_name wrapper generate_workspace_allocation ws data_ptr = f ws outer_name data_ptr kernel_args append data_ptr V graph cpp_wrapper f c_void_p data_ptr ws = None kernel_args append nullptr V graph cpp_wrapper None V graph cpp_wrapper arg_types append uint _t wrapper generate_kernel_call name kernel_args triton=False arg_types=arg_types ws wrapper generate_workspace_deallocation ws ROCmTemplateCaller ChoiceCaller ROCmTemplateCaller This represents caller ROCm template kernels It subclass ChoiceCaller Attributes name str The name caller category str The category caller bmreq ROCmBenchmarkRequest The benchmark request caller template_buffer ROCmTemplateBuffer The template buffer caller __init__ name str category str input_nodes list Buffer layout Layout make_kernel_render Callable ROCmTemplateBuffer Optional Sequence IRNode str bmreq ROCmBenchmarkRequest template ROCmTemplate type ignore name-defined info_kwargs Optional dict str Union PrimitiveInfoType list PrimitiveInfoType type ignore type-arg - None super __init__ name input_nodes layout description= category = category make_kernel_render = make_kernel_render bmreq = bmreq template = template info_kwargs = info_kwargs precompile - None assert bmreq None bmreq precompile benchmark args out - float assert bmreq None config profile_bandwidth_with_do_bench_using_profiling algo = bmreq make_run_fn args out=out do_bench_using_profiling algo bmreq benchmark args out=out __str__ - str f ROCmTemplateCaller source_file= bmreq source_file info_dict call_name - str f rocm_template_kernels name hash_key - str - join category bmreq hash_key info_dict - dict str Union PrimitiveInfoType list PrimitiveInfoType Information returned here logged autotune log file when enabled backend ROCm name name dict info_kwargs op dict_items type ignore union-attr index output_node - Union TensorBox ShapeAsConstantBuffer bmreq update_workspace_size TensorBox create ROCmTemplateBuffer layout=self layout inputs=self input_nodes make_kernel_render=self make_kernel_render workspace_size=self bmreq workspace_size template=self template