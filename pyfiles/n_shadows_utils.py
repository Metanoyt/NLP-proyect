mypy allow-untyped-defs collections copy operator collections abc Callable typing Any Optional torch torch fx torch ao ns fx graph_passes _maybe_get_fqn torch ao ns fx ns_types NSResultsType NSSingleResultValuesType torch ao ns fx utils TODO future PR make work correctly methods get_normalized_nth_input get_target_type_str torch ao quantization QConfigMapping torch ao quantization fx match_utils _MatchResult torch ao quantization qconfig QConfigAny torch ao quantization utils getattr_from_fqn torch fx Graph GraphModule Node torch utils _pytree tree_map SHADOW_NODE_NAME_PREFIX = shadow SHADOW_WRAPPER_NODE_NAME_PREFIX = shadow_wrapper TODO future PR reuse existing mapping instead creating new one BINARY_FUNCTIONS = torch add torch Tensor add operator add torch mul torch Tensor mul operator mul _get_attr_name subgraph_idx subgraph_candidate_idx f SHADOW_NODE_NAME_PREFIX _ subgraph_idx _ subgraph_candidate_idx _get_attr_wrapper_name subgraph_idx subgraph_candidate_idx f SHADOW_WRAPPER_NODE_NAME_PREFIX _ subgraph_idx _ subgraph_candidate_idx OutputProp Output propagation modeled shape propagation Given GraphModule example input saves output flowing through each node ` node traced_result ` Code based example https pytorch org docs stable fx html#the-interpreter-pattern __init__ mod mod = mod graph = mod graph modules = dict mod named_modules propagate args args_iter = iter args env dict str Node = load_arg torch fx graph map_arg lambda n env n name fetch_attr target str target_atoms = target split attr_itr = mod i atom enumerate target_atoms hasattr attr_itr atom raise RuntimeError f Node referenced nonexistent target join target_atoms i attr_itr = getattr attr_itr atom attr_itr node graph nodes node op == placeholder result = next args_iter node op == get_attr result = fetch_attr node target node op == call_function result = node target load_arg node args load_arg node kwargs node op == call_method self_obj args = load_arg node args kwargs = load_arg node kwargs result = getattr self_obj node target args kwargs node op == call_module result = modules node target load_arg node args load_arg node kwargs isinstance result torch Tensor type ignore possibly-undefined pyrefly ignore unbound-name node traced_result = result pyrefly ignore unsupported-operation pyrefly ignore unbound-name env node name = result None _get_dedup_subgraphs matches dict str _MatchResult - dict str list Node original matches variable unique node make unique subgraph instead seen_nodes = set subgraphs_dedup = Dict items reversible until Python so we hack compatible previous Python versions TODO future PR try reversed list matches items matches_items_reversed list tuple str _MatchResult = list reversed matches items Note order important ` matches ` currently provides matches reverse order We would like process matches non-reverse order so we can create intuitive naming scheme such naming first op s submodules ` shadow_ _ ` through ` shadow_ _ n- ` name cur_match matches_items_reversed type ignore call-overload was_seen = False node_or_tuple cur_match Cur_match has unusual type It says s ` List Node ` really Furthermore contents field can change match results multiple nodes same pattern For example conv - bn - relu we see match_results = conv relu bn conv relu bn relu bn conv relu relu relu bn conv relu Ideally we should clean up ` find_matches ` function make more intuitive For purposes prototype we hack around isinstance node_or_tuple Node node_or_tuple seen_nodes was_seen = True seen_nodes add node_or_tuple isinstance node_or_tuple tuple raise AssertionError f Expected tuple got type node_or_tuple node node_or_tuple isinstance node Node raise AssertionError f Expected Node got type node node seen_nodes was_seen = True seen_nodes add node was_seen continue Start unusual type convert op_ op_n list_of_nodes = len cur_match == list_of_nodes = cur_match len cur_match = raise ValueError f Expected cur_match have length got len cur_match either b b c c b cannot make any assumptions order clear what _find_matches function doing populate TODO future PR make code less confusing see discussion https github com pytorch pytorch pull files#r _order_nodes node_a node_b node_c - list Node nodes = node_a node_b node_c first_node = None mid_node = None last_node = None n nodes prev_n = n args next_n = next iter n users prev_n nodes first_node = n next_n nodes last_node = n mid_node = n first_node None mid_node None last_node None raise AssertionError Expected all nodes non-None mid_node args first_node raise AssertionError Expected mid_node args first_node last_node args mid_node raise AssertionError Expected last_node args mid_node last_node mid_node first_node isinstance cur_match Node isinstance cur_match Node b list_of_nodes = cur_match isinstance cur_match tuple b c node_a node_b = cur_match node_c = cur_match list_of_nodes = _order_nodes node_a node_b node_c isinstance cur_match tuple b c node_a node_b = cur_match node_c = cur_match list_of_nodes = _order_nodes node_a node_b node_c node_n node_ note order reversed make chronological simple subgraphs list_of_nodes reverse subgraphs_dedup name = list_of_nodes subgraphs_dedup _get_logger_for_subgraph model GraphModule first_node Node last_node Node subgraph_idx int subgraph_candidate_idx int qconfig_str str logger_cls Callable fqn Optional str - torch nn Module Given model linear subgraph starting ` first_node ` ending ` last_node ` creates logger end subgraph fqn None fqn = logger_mod_orig = logger_cls first_node name ref_node_name last_node name prev_node_name f subgraph_ subgraph_idx _ subgraph_candidate_idx model_name model ref_name get_target_type_str last_node model prev_node_target_type get_target_type_str first_node model ref_node_target_type NSSingleResultValuesType NODE_OUTPUT value results_type index_within_arg index_of_arg fqn fqn qconfig_str Usually we expect user add loggers then calibrate then convert then populate loggers This why loggers start disabled TODO future PR reconsider design make more intuitive logger_mod_orig enabled = False logger_mod_orig create_submodule_from_subgraph model torch nn Module first_node Node last_node Node - GraphModule Input model linear subgraph within model first_node last_node Output new submodule containing copy subgraph inputs first node becoming inputs submodule all other nodes subgraph being copied Example inputs ` model ` module graph x - op - x - op - x &#124; arg ` first_node ` op ` last_node ` op Example output new module graph input - op _copy - x - op _copy - output &#124; arg create blank GraphModule empty graph M torch nn Module forward x pass m = M gm = torch fx symbolic_trace m g = gm graph node reversed gm graph nodes g erase_node node modify graph have copy our subgraph cur_node_orig = first_node cur_name_idx = iteration_limit = cur_iteration = while True cur_node_orig first_node we first node we need set up graph inputs TODO future some graphs could have placeholders which unrelated first node need handle cur_args_copy = cur_kwargs_copy = seen_names set str = set old_name_to_new_node dict str Node = _add_placeholder g Graph node Node seen_names old_name_to_new_node note graphs starting patterns such ` y = x + x ` we need ensure we do add multiple placeholders same name counter = while node name + _ + str counter seen_names counter += cur_name = node name + _ + str counter seen_names add cur_name placeholder = g placeholder cur_name old_name_to_new_node node name = placeholder placeholder arg cur_node_orig args isinstance arg Node p = _add_placeholder g arg seen_names old_name_to_new_node cur_args_copy append p isinstance arg list tuple new_arg = inner_arg arg isinstance inner_arg Node new_arg append _add_placeholder g inner_arg seen_names old_name_to_new_node new_arg append inner_arg cur_args_copy append new_arg cur_args_copy append arg TODO future PR handle non-normalized kwargs kwarg_name kwarg cur_node_orig kwargs items isinstance kwarg Node cur_kwargs_copy kwarg_name = _add_placeholder g kwarg seen_names old_name_to_new_node isinstance kwarg list tuple new_kwarg = inner_kwarg kwarg p = _add_placeholder g inner_kwarg type ignore arg-type seen_names old_name_to_new_node new_kwarg append p cur_kwargs_copy kwarg_name = new_kwarg cur_kwargs_copy kwarg_name = kwarg cur_args_copy = tuple cur_args_copy type ignore assignment we first node first arg previous node all other args copied current implementation simplistic cannot handle ops two more arguments which need passed previous op so we assert them out cur_node_orig target BINARY_FUNCTIONS raise AssertionError f Unexpected binary function target cur_node_orig target point code cur_node_copy pointing copy previous node TODO future PR handling complicated graphs correctly need look actual relationships instead assuming sequential graph TODO future PR ignoring kwargs will need support kwargs any fusion pattern which has them node first node cur_args_copy = cur_node_copy type ignore has-type possibly-undefined noqa F len cur_node_orig args arg cur_node_orig args isinstance arg torch nn Parameter new_arg = arg detach clone type ignore assignment mod_name = f mod_ cur_name_idx cur_name_idx += setattr gm mod_name new_arg new_arg_placeholder = gm placeholder mod_name type ignore operator pyrefly ignore missing-attribute cur_args_copy append new_arg_placeholder isinstance arg float int torch dtype pyrefly ignore missing-attribute cur_args_copy append arg raise AssertionError f arg type type arg handled yet cur_args_copy = tuple cur_args_copy type ignore assignment copy node cur_node_orig op == call_module orig_mod = getattr_from_fqn model cur_node_orig target type ignore arg-type orig_mod_copy = copy deepcopy orig_mod mod_name = f mod_ cur_name_idx setattr gm mod_name orig_mod_copy cur_name_idx += cur_node_copy = g call_module mod_name cur_args_copy cur_kwargs_copy type ignore possibly-undefined arg-type cur_node_orig op == call_function cur_node_copy = g call_function cur_node_orig target type ignore arg-type cur_args_copy type ignore arg-type cur_kwargs_copy type ignore possibly-undefined cur_node_orig op == call_method cur_node_copy = g call_method cur_node_orig target type ignore arg-type cur_args_copy type ignore arg-type cur_kwargs_copy type ignore possibly-undefined raise AssertionError f cur_node_orig op supported yet cur_node_orig last_node break go next node len cur_node_orig users keys = raise AssertionError f cur_node_orig has more than users supported yet cur_node_orig = next iter cur_node_orig users keys cur_iteration += cur_iteration iteration_limit raise AssertionError iteration limit exceeded set up outputs g output cur_node_copy gm recompile gm create_one_transformed_and_logged_copy_of_subgraph mt GraphModule subgraph_idx int subgraph_candidate_idx int first_node Node last_node Node fqn Optional str list_of_node_name_to_qconfig list dict str QConfigAny example_inputs Any last_added_shadow_node_list list Optional Node custom_prepare_fn Optional Callable = None custom_prepare_kwargs Optional dict str Any = None - None Given subgraph ` mt ` subgraph candidate idx inserts subgraph candidate copy instruments loggers If subgraph_candidate_idx baseline fp subgraph we just add logger end If subgraph_candidate_idx we create copy subgraph prepare ` prepare_fx ` TODO future PR move logger classes utils remove circular dependency torch ao ns _numeric_suite_fx OutputComparisonLogger OutputLogger subgraph_candidate_idx == idx = floating point original version subgraph We keep subgraph add logger end qconfig_str = logger_mod_orig = _get_logger_for_subgraph mt first_node last_node subgraph_idx subgraph_candidate_idx qconfig_str OutputLogger fqn attr_name = _get_attr_name subgraph_idx subgraph_candidate_idx hasattr mt attr_name raise AssertionError f Unexpected attribute attr_name found mt setattr mt attr_name logger_mod_orig mt graph inserting_after last_node new_node = mt graph call_module attr_name args= last_node kwargs= last_added_shadow_node_list = new_node idx means we have candidate qconfig try so we need make copy subgraph feed right inputs add logger end get qconfig subtract one because first candidate floating point version subgraph node_name_to_qconfig = list_of_node_name_to_qconfig subgraph_candidate_idx - qconfig = node_name_to_qconfig first_node name no quantization requested skip TODO future PR deduplicate equivalent qconfigs come different qconfig mapping objects qconfig None qconfig_mapping = QConfigMapping set_global qconfig create copy submodule wrapped separate module orig_mod_copy_wrapped = create_submodule_from_subgraph mt first_node last_node add call prepare_fx wrapper module custom_prepare_fn None orig_mod_copy_wrapped = torch ao quantization quantize_fx prepare_fx orig_mod_copy_wrapped qconfig_mapping example_inputs=example_inputs custom_prepare_kwargs None custom_prepare_kwargs = kwarg_name example_inputs prepare_custom_config qconfig_mapping kwarg_name custom_prepare_kwargs raise AssertionError f cannot specify kwarg_name custom_prepare_kwargs prepare_kwargs dict str Any = example_inputs example_inputs qconfig_mapping qconfig_mapping prepare_kwargs update custom_prepare_kwargs orig_mod_copy_wrapped = custom_prepare_fn orig_mod_copy_wrapped prepare_kwargs attach wrapper model attr_name = _get_attr_wrapper_name subgraph_idx subgraph_candidate_idx hasattr mt attr_name raise AssertionError f Unexpected attribute attr_name found mt setattr mt attr_name orig_mod_copy_wrapped add call wrapper module parent graph insert_after_node = last_added_shadow_node_list mt graph inserting_after insert_after_node TODO future PR handle fusion patterns where non-first nodes need inputs pass all node args kwargs new_args = arg first_node args isinstance arg Node new_args append arg isinstance arg list tuple len arg isinstance arg Node new_args extend inner_arg inner_arg arg isinstance inner_arg Node new_kwargs = name old_kwarg first_node kwargs items isinstance old_kwarg Node new_kwargs name = old_kwarg isinstance old_kwarg list tuple len old_kwarg TODO future PR clarify why we adding kwargs args new_args extend old_kwarg type ignore arg-type new_args = tuple new_args type ignore assignment new_node = mt graph call_module attr_name args=new_args kwargs=new_kwargs type ignore arg-type add logger parent graph observe shadow wrapper logger_mod_orig = _get_logger_for_subgraph mt first_node last_node subgraph_idx subgraph_candidate_idx str qconfig OutputComparisonLogger fqn attr_name = _get_attr_name subgraph_idx subgraph_candidate_idx hasattr mt attr_name raise AssertionError f Unexpected attribute attr_name found mt setattr mt attr_name logger_mod_orig mt graph inserting_after new_node logger = mt graph call_module attr_name args= new_node last_node kwargs= last_added_shadow_node_list = logger mt recompile create_n_transformed_and_logged_copies_of_subgraph mt GraphModule subgraph_idx int match_name str nodes_in_this_subgraph list Any qconfig_mappings list QConfigMapping list_of_node_name_to_qconfig list dict str QConfigAny custom_prepare_fn Optional Callable = None custom_prepare_kwargs Optional dict str Any = None - None Given model ` mt ` subgraph_idx creates needed copies subgraph all qconfigs instruments them loggers now assume first node has one input last node has one output now ignore all subgraphs contain non-nodes tuples etc TODO future PR implement any isinstance node Node node nodes_in_this_subgraph first_node = nodes_in_this_subgraph last_node = nodes_in_this_subgraph - We used output propagation populate example values each node Use example values previous node input current node prev_node = get_normalized_nth_input first_node mt isinstance prev_node list example_inputs = x traced_result x prev_node isinstance prev_node tuple example_inputs = x traced_result x prev_node type ignore assignment currently some customer models do have traced_result every node so we have guard case since we cannot quantize without example input TODO future PR add test case once we have easy repro see https github com pytorch pytorch pull files#r additional context hasattr prev_node traced_result example_inputs = prev_node traced_result type ignore attr-defined assignment print unable get example input node + f first_node format_node skipping If there no quantization configs subgraph skip adding loggers This reduces memory usage models where all layers quantized TODO future consider making configurable found_at_least_one_qconfig = False subgraph_candidate_idx range len qconfig_mappings + subgraph_candidate_idx == fp baseline does need qconfig continue we have N shadows so len qconfig_mappings N b we will have fp layer + N shadows so overall number original_op + shadows will N+ c since ` subgraph_candidate_idx ` represents b we need subtract query node_name_to_qconfig = list_of_node_name_to_qconfig subgraph_candidate_idx - qconfig = node_name_to_qconfig first_node name qconfig None found_at_least_one_qconfig = True break found_at_least_one_qconfig print unable find least one qconfig node + f first_node format_node skipping fqn = _maybe_get_fqn first_node mt We want results contain subgraphs natural order graph also contain shadow wrappers shadow loggers natural order If we just iterate reverse graph will natural order eventual results will reverse order So we keep track last shadow logger we added always insert after last_added_shadow_node_list list Optional Node = None subgraph_candidate_idx range len qconfig_mappings + create_one_transformed_and_logged_copy_of_subgraph mt subgraph_idx subgraph_candidate_idx first_node last_node fqn list_of_node_name_to_qconfig example_inputs last_added_shadow_node_list custom_prepare_fn custom_prepare_kwargs create_add_loggers_graph model GraphModule subgraphs_dedup dict str list Node qconfig_mapping QConfigMapping node_name_to_qconfig dict str QConfigAny - None r Given model model graph partition currently set matched subgraphs instructions how transform each subgraph currently quantizing according qconfig_mapping modifies model graph create alternate path through original graph each subgraphs quantized This useful compare propagation error transformation such quantization For example given layer op op there four cases when handling op op op quantized op op unquantized op quantized op unquantized op unquantized op quantized Example input case code x _ - op _ - x _ - log ----- op _ - x _ - log \ \ \ \ noqa W --- op _ - x _ ---- clog op _ - x _ ---- clog Example output case code x _ - op _ - x _ - log ----- op _ - x _ - log \ \ \ noqa W --- op _ - x _ ---- clog - op _ - x _ ---- clog TODO future PR move logger classes utils remove circular dependency torch ao ns _numeric_suite_fx OutputComparisonLogger OutputLogger _get_subgraph_containing_node node subgraphs_dedup subgraph subgraphs_dedup values node subgraph subgraph None First we need create shadow branches going x - op - x - x - op _ - x _ - log - \ \ - op _ - x _ - clog Later outputs each shadow will rerouted calculate propagation error Note we cannot iterate over matched subgraphs because some nodes may matched So we iterate over nodes graph associate them matched subgraphs possible nodes_to_skip = set each subgraph save mapping first node subgraph first last node shadow subgraph orig_first_node_to_shadow_in_node = orig_first_node_to_shadow_out_node = need record original list because we will mutate graph we go orig_nodes = list model graph nodes type ignore union-attr arg-type cur_subgraph_idx = n orig_nodes n op placeholder get_attr output n nodes_to_skip continue maybe_subgraph = _get_subgraph_containing_node n subgraphs_dedup insert_submodule_copy = False maybe_subgraph None first_node last_node = maybe_subgraph maybe_subgraph - nodes_to_skip update maybe_subgraph qconfig = node_name_to_qconfig first_node name qconfig None insert_submodule_copy = True first_node last_node = n n insert_submodule_copy match_name = first_node name create_n_transformed_and_logged_copies_of_subgraph model cur_subgraph_idx match_name pyrefly ignore bad-argument-type maybe_subgraph qconfig_mapping node_name_to_qconfig None None type ignore arg-type find created shadow module record so we can find easily step expected_shadow_target = f shadow_wrapper_ cur_subgraph_idx _ new_shadow_mod = None maybe_shadow_mod model graph nodes maybe_shadow_mod op == call_module maybe_shadow_mod target == expected_shadow_target new_shadow_mod = maybe_shadow_mod break new_shadow_mod None raise AssertionError Expected new_shadow_mod non-None orig_first_node_to_shadow_in_node first_node = new_shadow_mod orig_first_node_to_shadow_out_node first_node = new_shadow_mod create copy subgraph only copying FX nodes copying any parameters minimize memory usage subgraph_to_use = maybe_subgraph maybe_subgraph None first_node add regular logger after last_node qconfig_str = subgraph_candidate_idx = fqn = _maybe_get_fqn first_node model logger_mod_orig = _get_logger_for_subgraph model first_node last_node cur_subgraph_idx subgraph_candidate_idx qconfig_str OutputLogger fqn attr_name = _get_attr_name cur_subgraph_idx subgraph_candidate_idx hasattr model attr_name raise AssertionError f Unexpected attribute attr_name found model setattr model attr_name logger_mod_orig insertion_point = last_node model graph inserting_after insertion_point logger = model graph call_module attr_name args= last_node kwargs= insertion_point = logger create copy subgraph cur_node_orig = first_node cur_node_copy = None first_node_copy = None pyrefly ignore bad-assignment while cur_node_orig subgraph_to_use TODO future PR make support all possible args kwargs cur_node_orig first_node new_args = cur_node_orig args new_kwargs = cur_node_orig kwargs first_arg_for_copy Optional Node = cur_node_copy new_args = first_arg_for_copy cur_node_orig args new_kwargs = cur_node_orig kwargs make copy cur_node_orig model graph inserting_after insertion_point cur_node_copy = model graph create_node cur_node_orig op cur_node_orig target new_args new_kwargs cur_node_orig name TODO future PR set name explicitly first_node_copy None first_node_copy = cur_node_copy since now only linear subgraphs supported all nodes except last one must have only one user cur_node_orig = last_node len cur_node_orig users keys = raise AssertionError f Expected exactly got len cur_node_orig users cur_node_orig = next iter cur_node_orig users keys cur_node_orig name startswith SHADOW_NODE_NAME_PREFIX raise AssertionError cur_node_orig should start SHADOW_NODE_NAME_PREFIX insertion_point = cur_node_copy add comparison logger after last_node s copy subgraph_candidate_idx = logger_mod_orig = _get_logger_for_subgraph model first_node last_node cur_subgraph_idx subgraph_candidate_idx qconfig_str OutputComparisonLogger fqn attr_name = _get_attr_name cur_subgraph_idx subgraph_candidate_idx hasattr model attr_name raise AssertionError f Unexpected attribute attr_name found model setattr model attr_name logger_mod_orig model graph inserting_after insertion_point logger = model graph call_module attr_name args= cur_node_copy last_node kwargs= save final node so we can use step orig_first_node_to_shadow_in_node first_node = first_node_copy orig_first_node_to_shadow_out_node first_node = cur_node_copy cur_subgraph_idx += model recompile Now we go x - op _ - x _ - log - x - op _ - \ \ \ - op _ - x _ - clog - op _ - x - op _ - x _ - log -- x _ - op _ - \ \ - op _ - x _ - clog - x _ - op _ - sample values key internal variables example above orig_first_node_to_shadow_in_node = op _ op _ op _ op _ orig_first_node_to_shadow_out_node = op _ op _ op _ op _ note subgraphs more than one node in_node will different compared out_node nodes_to_skip = set n orig_nodes n op placeholder get_attr output n nodes_to_skip continue maybe_subgraph = _get_subgraph_containing_node n subgraphs_dedup maybe_subgraph None first_node last_node = maybe_subgraph maybe_subgraph - nodes_to_skip update maybe_subgraph first_node last_node = n n maybe_remap_node_to_shadow node If unshadowed ` node ` has shadow version If ` node ` isinstance node Node handle scalars node node op placeholder get_attr node Find shadowed version arg previous subgraph For we need navigate first node previous subgraph get output shadow wrapper which has input For now assume arg matched subgraphs In future we may have handle case where true prev_subgraph = _get_subgraph_containing_node node subgraphs_dedup prev_subgraph None prev_subgraph = node prev_first_node = prev_subgraph prev_shadow_output = orig_first_node_to_shadow_out_node prev_first_node prev_shadow_output cur_shadow_input = orig_first_node_to_shadow_in_node first_node cur_shadow_input None raise AssertionError Expected cur_shadow_input non-None cur_shadow_input args = tree_map maybe_remap_node_to_shadow cur_shadow_input args cur_shadow_input kwargs = tree_map maybe_remap_node_to_shadow cur_shadow_input kwargs model recompile _get_weight_info_from_shadow_wrapper shadow_wrapper torch nn Module input shadow wrapper module output shadow wrapper module has weighted op quantize_fn quantize_fn_args output shadow wrapper module doesn t have weighted op None For now assume weight second input shadow module If changes we can fix later placeholders_seen = shadow_n shadow_wrapper graph nodes type ignore union-attr shadow_n op = placeholder continue placeholders_seen += placeholders_seen = continue subgraph looks like _input_scale_ = _input_scale_ _input_zero_point_ = _input_zero_point_ quantize_per_channel = torch quantize_per_channel w _ _input_scale_ _input_zero_point_ torch qint we have ` w _ ` navigating subgraph get ` _input_scale_ ` ` _input_zero_point_ ` len shadow_n users = raise AssertionError f Expected exactly got len shadow_n users quant_node = next iter shadow_n users keys new_args Any = None quant_node target torch quantize_per_channel _weight scale_node zp_node axis dtype = quant_node args scale_val = getattr_from_fqn shadow_wrapper scale_node target zp_val = getattr_from_fqn shadow_wrapper zp_node target new_args = scale_val zp_val axis dtype quant_node target = torch quantize_per_tensor raise AssertionError f Expected torch quantize_per_tensor got quant_node target _weight scale_node zp_node dtype = quant_node args scale_val = getattr_from_fqn shadow_wrapper scale_node target zp_val = getattr_from_fqn shadow_wrapper zp_node target new_args = scale_val zp_val dtype quant_node target new_args None extract_weight_comparison m GraphModule - NSResultsType example graph w = w b = b linear = torch _C _nn linear x w b shadow_ _ = shadow_ _ linear shadow_wrapper_ _ = shadow_wrapper_ _ x w b shadow_ _ = shadow_ _ shadow_wrapper_ _ linear algorithm each call_function node matching our allowlist corresponding shadow wrapper exists extract weight pair Note super robust s ok because just legacy customers who depend previous two-model version API TBD we need make robust Note modules supported since existing customers only use functions TODO future PR move config weighted_ops = torch nn functional linear results NSResultsType = model NSSingleResultValuesType WEIGHT value n m graph nodes type ignore union-attr n op == call_function n target weighted_ops continue Check we have corresponding shadow wrapper TODO future PR needed support kwargs TODO future PR needed support multiple shadow users first_arg = n args shadow_wrapper_node = None user first_arg users TODO before land fix string match user op == call_module user target startswith shadow_wrapper shadow_wrapper_node = user break shadow_wrapper_node None continue shadow_wrapper = getattr_from_fqn m shadow_wrapper_node target type ignore arg-type weight_info = _get_weight_info_from_shadow_wrapper shadow_wrapper weight_info None continue get weight w_node = n args w_obj = getattr_from_fqn m w_node target detach get quantized version weight quant_fn quant_fn_args_except_first = weight_info new_args = w_obj quant_fn_args_except_first w_obj_q = quant_fn new_args add comparison ref_node_name = n name prev_node_name = n name ref_node_type = get_target_type_str n m prev_node_type = ref_node_type fqn = None hasattr m _node_name_to_scope fqn = m _node_name_to_scope n name type ignore index comparison = torch ao ns fx utils compute_sqnr w_obj w_obj_q result_fp = res_type NSSingleResultValuesType WEIGHT value values w_obj prev_node_name prev_node_name prev_node_target_type prev_node_type ref_node_name ref_node_name ref_node_target_type ref_node_type index_within_arg index_of_arg fqn fqn qconfig_str comparisons comparison comparison_fn_name sqnr result_q = res_type NSSingleResultValuesType WEIGHT value values w_obj_q prev_node_name prev_node_name prev_node_target_type prev_node_type ref_node_name ref_node_name ref_node_target_type ref_node_type index_within_arg index_of_arg fqn fqn qconfig_str comparisons comparison comparison_fn_name sqnr go subgraph_n_ subgraph_n_ _ _ node_idx _ = shadow_wrapper_node target split _ name_fp = f subgraph_ node_idx _ name_q = f subgraph_ node_idx _ results model NSSingleResultValuesType WEIGHT value name_fp = result_fp results model NSSingleResultValuesType WEIGHT value name_q = result_q results TODO future PR redesign make easier consume outputs group_results_by_subgraph results NSResultsType - Any Creates comparison results Input model node_output subgraph_ _ values torch tensor ref_node_name ref_node_target_type qconfig_str comparisons comparison_fn_name fqn subgraph_ _ values torch tensor ref_node_name ref_node_target_type qconfig_str comparisons torch tensor comparison_fn_name fqn Output subgraph_ ref_node_name ref_node_target_type values torch tensor qconfig_str None comparisons torch tensor comparison_fn_name fqn ref_node_name ref_node_target_type values torch tensor qconfig_str comparisons torch tensor comparison_fn_name fqn subgraph_name_to_subgraph_results Any = collections defaultdict dict node_output weight key_to_use = next iter results model keys subgraph_name_with_idx subgraph_candidate_results results model key_to_use items convert ` subgraph_m_n ` ` subgraph_m ` ` n ` subgraph_str subgraph_idx subgraph_candidate_idx = subgraph_name_with_idx split _ subgraph_name = f subgraph_str _ subgraph_idx subgraph_results = ref_node_name subgraph_candidate_results ref_node_name ref_node_target_type subgraph_candidate_results ref_node_target_type fqn subgraph_candidate_results fqn values subgraph_candidate_results values qconfig_str subgraph_candidate_results qconfig_str comparisons subgraph_candidate_results comparisons comparison_fn_name subgraph_candidate_results comparison_fn_name subgraph_name_to_subgraph_results subgraph_name subgraph_candidate_idx = subgraph_results dict subgraph_name_to_subgraph_results TODO future PR redesign make easier consume outputs create_results_comparison results_grouped - Any Input subgraph_ ref_node_name ref_node_target_type values torch tensor qconfig_str comparisons comparison_fn_name fqn ref_node_name ref_node_target_type values torch tensor qconfig_str comparisons torch tensor comparison_fn_name sqnr fqn Output subgraph_ ref_node_name ref_node_target_type fqn candidates qconfig_str comparison_fn_name sqnr cmp_raw cmp_mean results_comparison = subgraph_name subgraph_results results_grouped items candidates = subgraph_inner_name subgraph_inner_result subgraph_results items skip comparing baseline baseline subgraph_inner_name == continue we expect comparisons precalculated calibration so we just fetch them here cmp_raw = subgraph_inner_result comparisons cmp_raw_tensor = torch stack cmp_raw candidates subgraph_inner_name = qconfig_str subgraph_inner_result qconfig_str comparison_fn_name subgraph_inner_result comparison_fn_name cmp_raw cmp_raw_tensor cmp_mean torch mean cmp_raw_tensor results_comparison subgraph_name = ref_node_name subgraph_results ref_node_name ref_node_target_type subgraph_results ref_node_target_type fqn subgraph_results fqn candidates candidates results_comparison TODO future PR redesign make easier consume outputs print_n_shadows_summary results_comparison - None Input subgraph_ ref_node_name linear ref_node_target_type fqn candidates qconfig_str comparison_fn_name cmp_raw cmp_mean Prints node_name &#124; node_type &#124; fqn &#124; &#124; &#124; linear &#124; &#124; &#124; &#124; &#124; try tabulate tabulate except ImportError print ` print_tabular ` relies library ` tabulate ` which could found machine Run ` pip install tabulate ` install library results = subgraph_data results_comparison values mean_all_candidates = candidate cmp_mean candidate_name candidate subgraph_data candidates items data_row = subgraph_data ref_node_name subgraph_data ref_node_target_type subgraph_data fqn mean_all_candidates results append data_row max_candidate_idx_len = - data_row results max_candidate_idx_len = max max_candidate_idx_len len data_row candidate_idx_headers = str x x range max_candidate_idx_len headers = node_name node_type fqn candidate_idx_headers print tabulate results headers=headers