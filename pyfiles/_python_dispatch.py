mypy allow-untyped-defs contextlib functools warnings collections deque collections abc Sequence dataclasses dataclass typing cast Optional overload Protocol Union typing_extensions TypeIs torch torchgen torchgen model torch _C _get_dispatch_stack_at _len_torch_dispatch_stack _pop_torch_dispatch_stack _push_on_torch_dispatch_stack DispatchKey TODO Limitations things about enable_torch_dispatch_mode we should fix before exposing - We need better user-facing api _DisableTorchDispatch able selectively disable __torch_dispatch__ particular - It doesn t work tensor constructors torch tensor torch Tensor - Better name see https github com pytorch pytorch pull #discussion_r _is_in_torch_dispatch_mode = False _is_in_non_infra_torch_dispatch_mode = False If inside any mode has ignore_compile_internals = False _is_in_any_mode_without_ignore_compile_internals = False is_in_torch_dispatch_mode include_infra_modes bool = True - bool _is_in_torch_dispatch_mode include_infra_modes _is_in_non_infra_torch_dispatch_mode is_in_any_mode_without_ignore_compile_internals - bool _is_in_any_mode_without_ignore_compile_internals TorchDispatchMode A ` ` TorchDispatchMode ` ` allows you override meaning all ` ` __torch_dispatch__ ` ` overrideable functions within dynamic scope without having actually create tensor subclass manually monkey-patch functions PyTorch API Some common situations where you should use mode You want override meaning factory functions other functions do otherwise take tensor argument these cannot overridden tensor subclasses You want override behavior all functions without needing wrap your inputs tensor subclasses e g you just interested logging intermediate computations You want control order execution various tensor subclasses explicitly rather than implicitly via ` ` NotImplemented ` ` Independent subclasses ` TorchDispatchMode ` compositional modes can pushed onto stack using ` ` MyMode ` ` When you call functions PyTorch API inside your ` ` __torch_dispatch__ ` ` implementation default they will forward next mode mode stack If you want recursively call back into your current ` ` __torch_dispatch__ ` ` implementation either explicitly invoke ` ` __torch_dispatch__ ` ` use context manager ` ` ` ` make PyTorch API self-referential beware infinite loops case - When False custom torch dispatch mode will error out explicitly when hop called under mode - When True custom torch dispatch mode s __torch_dispatch__ will triggered Mode authors can implement how mode interacts higher order operators supports_higher_order_operators = False __init__ _dispatch_key=None _dispatch_key None isinstance _dispatch_key torch _C DispatchKey raise AssertionError _dispatch_key must torch _C DispatchKey __dict__ _dispatch_key = _dispatch_key old_dispatch_mode_flags deque bool = deque old_non_infra_dispatch_mode_flags deque bool = deque old_without_ignore_compile_internals_dispatch_mode_flags deque bool = deque _lazy_init_old_dispatch_mode_flags hasattr old_dispatch_mode_flags old_dispatch_mode_flags deque bool = deque type ignore no-redef hasattr old_non_infra_dispatch_mode_flags old_non_infra_dispatch_mode_flags deque bool = deque type ignore no-redef hasattr old_without_ignore_compile_internals_dispatch_mode_flags old_without_ignore_compile_internals_dispatch_mode_flags deque type ignore no-redef bool = deque __torch_dispatch__ func types args= kwargs=None raise NotImplementedError __enter__ global _is_in_torch_dispatch_mode global _is_in_non_infra_torch_dispatch_mode global _is_in_any_mode_without_ignore_compile_internals Previously there wasn t any state constructor super calls added existing modes any new modes will replicate previous behavior strictly needing call super __init__ _lazy_init_old_dispatch_mode_flags old_dispatch_mode_flags append _is_in_torch_dispatch_mode _is_in_torch_dispatch_mode = True old_non_infra_dispatch_mode_flags append _is_in_non_infra_torch_dispatch_mode _is_in_non_infra_torch_dispatch_mode = _is_in_non_infra_torch_dispatch_mode is_infra_mode old_without_ignore_compile_internals_dispatch_mode_flags append _is_in_any_mode_without_ignore_compile_internals _is_in_any_mode_without_ignore_compile_internals = _is_in_any_mode_without_ignore_compile_internals ignore_compile_internals _push_mode __exit__ exc_type exc_val exc_tb mb_dk_or_mode_key = __dict__ get _dispatch_key None mb_dk_or_mode_key None Today mode keys used all per-dispatch-key-mode logic pre-dispatch We should probably revisit mb_dk_or_mode_key = __dict__ get _mode_key None global _is_in_torch_dispatch_mode _is_in_torch_dispatch_mode = old_dispatch_mode_flags pop global _is_in_non_infra_torch_dispatch_mode _is_in_non_infra_torch_dispatch_mode = old_non_infra_dispatch_mode_flags pop global _is_in_any_mode_without_ignore_compile_internals _is_in_any_mode_without_ignore_compile_internals = old_without_ignore_compile_internals_dispatch_mode_flags pop _pop_mode mb_dk_or_mode_key classmethod push cls args kwargs warnings warn ` Mode push ` no longer necessary can replaced just ` Mode ` stacklevel= instance = cls args kwargs instance classmethod is_infra_mode cls False classmethod ignore_compile_internals cls Ignore operators compiled via torch compile If ` ` True ` ` then TorchDispatchMode ignores operators optimized func ` torch compile ` Mechanically involves turning off TorchDispatchMode throughout whole compilation process turning back runtime compiled artifact s For example torch compile f x x sin cos LoggingMode f x The above example will log anything ` ` LoggingMode ignore_compile_internals ` ` True torch compile will fuse sin cos into single operation TorchDispatchMode will passed sin cos If ` ` False ` ` default func ` torch compile ` will respect eager semantics passing TorchDispatchMode all operators would have run during eager execution The way will usually happen func ` torch compile ` will just fallback eager-mode PyTorch cls is_infra_mode True False _get_current_dispatch_mode - Optional TorchDispatchMode Return top user mode stack next one would executed there any stack_len = _len_torch_dispatch_stack stack_len _get_dispatch_stack_at stack_len - None _detect_infra_mode key key torch _C _TorchDispatchModeKey FUNCTIONAL torch _C _TorchDispatchModeKey PROXY raise AssertionError f key must either FUNCTIONAL torch _C _TorchDispatchModeKey FUNCTIONAL \ PROXY torch _C _TorchDispatchModeKey PROXY _TorchDispatchModeKey \ got key torch _ops _get_dispatch_mode_pre_dispatch pre_dispatch_mode = _get_dispatch_mode_pre_dispatch key post_dispatch_mode = torch _C _get_dispatch_mode key pre_dispatch_mode None post_dispatch_mode None raise AssertionError At most one pre_dispatch_mode post_dispatch_mode may active pre_dispatch_mode None post_dispatch_mode pre_dispatch_mode _unset_infra_mode key torch _ops _get_dispatch_mode_pre_dispatch unset_mode_pre_dispatch pre_dispatch_mode = _get_dispatch_mode_pre_dispatch key post_dispatch_mode = torch _C _get_dispatch_mode key pre_dispatch_mode post_dispatch_mode raise AssertionError Can t have active infra mode both pre post dispatch mode stack pre_dispatch_mode mode = unset_mode_pre_dispatch key mode post_dispatch_mode torch _C _unset_dispatch_mode key _disable_infra_mode key key torch _C _TorchDispatchModeKey FUNCTIONAL torch _C _TorchDispatchModeKey PROXY raise AssertionError key must either FUNCTIONAL PROXY _TorchDispatchModeKey mode_unset = _unset_infra_mode key try yield mode_unset finally mode_unset None _push_mode mode_unset _get_current_dispatch_mode_stack - list TorchDispatchMode Returns current stack dispatch modes most recent i e one will processed first end list standard stack convention stack_len = _len_torch_dispatch_stack _get_dispatch_stack_at i i range stack_len _push_mode mode TorchDispatchMode k = mode _dispatch_key hasattr mode _dispatch_key None k None k = torch _C DispatchKey PreDispatch raise AssertionError mode _dispatch_key must None DispatchKey PreDispatch k None _push_on_torch_dispatch_stack mode torch _ops _set_mode_pre_dispatch get_cached_ops See Note Not Caching Per-Dispatch-Key Mode Handlers Clear cache every op has been used so far particular key ks = torch _C _functionality_to_backend_keys k op get_cached_ops key ks op _uncache_dispatch key _set_mode_pre_dispatch mode _pop_mode k Optional Union DispatchKey torch _C _TorchDispatchModeKey = None k == torch _C DispatchKey PreDispatch type ignore attr-defined torch _ops _pop_mode_from_pre_dispatch _pop_mode_from_pre_dispatch k None isinstance k torch _C _TorchDispatchModeKey _pop_torch_dispatch_stack k contextlib contextmanager _pop_mode_temporarily k Optional DispatchKey = None old = _pop_mode k try yield old finally _push_mode old contextlib contextmanager _disable_current_modes torch _ops _len_torch_dispatch_stack_pre_dispatch _pop_mode_from_pre_dispatch torch _subclasses functional_tensor FunctionalTensorMode torch _subclasses schema_check_mode SchemaCheckMode torch fx experimental proxy_tensor ProxyTorchDispatchMode mode_len_pre_dispatch = _len_torch_dispatch_stack_pre_dispatch old_pre_dispatch_modes = _pop_mode_from_pre_dispatch _ range mode_len_pre_dispatch has_proxy_mode_in_pre_dispatch = False has_functional_mode_in_pre_dispatch = False has_schema_check_mode_in_pre_dispatch = False i old_pre_dispatch_modes isinstance i ProxyTorchDispatchMode has_proxy_mode_in_pre_dispatch = True isinstance i FunctionalTensorMode has_functional_mode_in_pre_dispatch = True isinstance i SchemaCheckMode has_schema_check_mode_in_pre_dispatch = True mode_len = _len_torch_dispatch_stack old_modes = _pop_mode _ range mode_len old old_modes isinstance old FunctionalTensorMode has_functional_mode_in_pre_dispatch raise AssertionError Can t have FunctionalMode available both PreDispatch Python Key isinstance old ProxyTorchDispatchMode has_proxy_mode_in_pre_dispatch raise AssertionError Can t have ProxyTorchDispatchMode available both PreDispatch Python Key isinstance old SchemaCheckMode has_schema_check_mode_in_pre_dispatch raise AssertionError Can t have SchemaCheckMode available both PreDispatch Python Key Manually disable proxy fake modes any active try yield old_pre_dispatch_modes + old_modes finally mode reversed old_modes _push_mode mode mode reversed old_pre_dispatch_modes _push_mode mode BaseTorchDispatchMode TorchDispatchMode __torch_dispatch__ func types args= kwargs=None kwargs None kwargs = func args kwargs Subtypes which have __tensor_flatten__ __tensor_unflatten__ TensorWithFlatten Protocol __tensor_flatten__ - tuple Sequence str object staticmethod __tensor_unflatten__ inner_tensors int flatten_spec int outer_size int outer_stride int - torch Tensor It would really nice able say is_traceable_wrapper_subclass Intersection torch Tensor TensorWithFlatten - doesn t exist shape torch _C Size overload stride dim None = None - tuple int overload stride dim int - int overload size dim None = None - tuple int overload size dim int - int storage_offset - int dim - int overload dtype torch types _dtype non_blocking bool = False copy bool = False memory_format Optional torch memory_format = None - torch Tensor overload device Optional torch _prims_common DeviceLikeType = None dtype Optional torch types _dtype = None non_blocking bool = False copy bool = False memory_format Optional torch memory_format = None - torch Tensor overload other torch Tensor non_blocking bool = False copy bool = False memory_format Optional torch memory_format = None - torch Tensor is_traceable_wrapper_subclass t object - TypeIs TensorWithFlatten Returns whether tensor subclass implements __torch_dispatch__ traceable torch compile In order tensor subclass support TorchDispatchMode-style tracing PT It must implement two magic methods __tensor_flatten__ __tensor_unflatten__ It also expected obey some restrictions around traceability aliasing The subclass s __torch_dispatch__ implementation should desugar into pytorch dispatcher operations can traced into graph The subclass should use return_and_correct_aliasing This needed today make sure torch compile does right thing few cases around input mutation output aliasing Expected magic method signatures attrs ctx = t __tensor_flatten__ attrs list attribute name strings inner tensors ctx dict containing any other subclass-specific metadata needed unflattening t = MySubClass __tensor_unflatten__ inner_tensors ctx outer_size outer_stride inner_tensors dict mapping attribute name - tensor each inner tensor ctx dict subclass metadata form __tensor_flatten__ produces outer_size expected possibly symbolic size returned subclass instance should have Note arg useful certain subclasses require shape info constructed In most cases arg can safely ignored outer_stride expected possibly symbolic stride returned subclass instance should have Note arg useful certain subclasses require stride info constructed In most cases arg can safely ignored is_subclass = isinstance t torch Tensor type t torch Tensor is_subclass hasattr t __tensor_flatten__ hasattr t __tensor_unflatten__ is_traceable_wrapper_subclass_type t type - TypeIs type TensorWithFlatten Same above takes type argument instead instance issubclass t torch Tensor t torch Tensor hasattr t __tensor_flatten__ hasattr t __tensor_unflatten__ transform_subclass t callback outer_size=None outer_stride=None Given traceable wrapper tensor subclass ` ` t ` ` implements ` ` __torch_dispatch__ ` ` holds some inner tensors callback type ` ` Callable str torch Tensor torch Tensor ` ` ` transform_subclass ` will construct fresh instance wrapper tensor subclass It will do so grabbing each inner tensor attribute wrapper passing them into ` ` callback ` ` get transformed tensor putting each transformed tensor into fresh tensor subclass instance Note function will handle ensuring fresh subclass gets same autograd aliasing metadata original tensor This generally handled other subsystems like AOTAutograd outer_size = outer_size outer_size None t size outer_stride = outer_stride outer_stride None t stride attrs ctx = t __tensor_flatten__ transformed_tensors_dict = attr attrs transformed_tensors_dict attr = callback attr getattr t attr sub = type t __tensor_unflatten__ transformed_tensors_dict ctx outer_size outer_stride NB Purposefully guard here simplify inner outer symbols Using sym_eq symbolic comparison can result expression s too difficult guard so we use == here sub shape = outer_size raise AssertionError f Expected value type t __tensor_unflatten__ have f shape equal outer_size got sub shape sub stride = outer_stride raise AssertionError f Expected value type t __tensor_unflatten__ have f stride equal outer_stride got sub stride sub _correct_storage_aliasing func schema_info args outs Given OpOverload SchemaInfo cached information torchgen about schema inputs outputs OpOverload function checks see func view operator checking any outputs op s schema immutable aliases inputs If so function manually aliases storage output tensor its corresponding input tensor alias It does unsafely overwriting storage field output tensor same storage input isinstance func torch _ops OpOverload raise AssertionError f func must OpOverload got type args isinstance args tuple raise AssertionError f args must tuple got type args isinstance outs list tuple raise AssertionError f outs must list tuple got type args alias_non_inplace_storage arg ret This hopefully reasonable assert subclasses rely API output aliasing should always wrapper tensor subclasses us manually alias theory subclass needs API wants sometimes plain tensors we could remove assert just perform aliasing seems safer learn more about case first Performance note This all just assert argument result types match checking cheaper than is_traceable_wrapper_subclass_type multiple returns relatively unlikely so just check up front arg_type = type arg ret_type = type ret arg_type ret_type is_traceable_wrapper_subclass_type arg_type is_traceable_wrapper_subclass_type ret_type ret_list = ret isinstance ret list ret r ret_list type arg type r raise AssertionError f Called str func input type type arg \n f output type type ret But expected types match Need call non-dispatcher helper because we explicitly do want our subclass intercept set_ call instead our subclass should directly have its storage swapped out we explicitly don t want reset sizes ret storage implies size change Why The purpose API change size strides our output- we assume s already correct We just want fix up storage aliasing without modifying output s metadata Example out = inp expand inp shape inp shape This requires swapping storage out same inp we do want change sizes strides compute out isinstance ret list r ret torch _functionalize_unsafe_set r arg isinstance ret torch Tensor raise AssertionError f expected torch Tensor got type ret torch _functionalize_unsafe_set ret arg arg_idx return_idx schema_info read_only_alias_match_indexes alias_non_inplace_storage args arg_idx outs return_idx _get_write_alias x - Optional str alias_set = x alias_set alias_set x is_write None torchscript allows complicated alias sets our dispatcher ops only really involve simple aliasing len alias_set = raise AssertionError Expected alias_set contain exactly one element timeit says next iter alias_set faster than list alias_set even set size Python next iter alias_set This abstracts over fact return_and_correct_aliasing we sometimes use torchgen schema parsing aten ops since torchscript s schema parsing sometimes buggy sometimes use torchscript schema parsing custom ops which torchgen parsing untested dataclass AliasInfo alias_set set str is_write bool name Optional str dataclass SchemaInfo args list AliasInfo outs list AliasInfo is_inplace_view_op bool _get_write_alias x x outs Guaranteed contain no Nones we coerce all-Nones result empty list instead we don t support some-but-not-all-Nones outs_write_aliases Optional list str List arg_idx return_idx where args arg_idx alias_set outs out_idx alias_set empty args arg_idx is_write read_only_alias_match_indexes list tuple int int Given OpOverload returns schema information This cached efficiency since can involve running torchgen functools cache get_alias_info func - SchemaInfo For ATen ops use torchgen since torchscript parser doesn t handle alias annotations properly some ops output tensorlists func namespace == aten torchgen_schema_str = str func _schema torchgen_schema_str startswith aten raise AssertionError Expected torchgen schema string start aten remove aten namespace which added torchscript parser torchgen doesn t know how handle torchgen_schema_str = torchgen_schema_str re torchscript parser ends up converting int = into int = which torchgen chokes torchgen_schema_str = re sub r =\ +\ = torchgen_schema_str torchgen_schema_str = re sub r =\ +\ = torchgen_schema_str aten rot aten fft_ torchgen_schema_str = re sub r =\ - - + - - + \ r = \ \ torchgen_schema_str torchgen_schema = torchgen model FunctionSchema parse torchgen_schema_str arg_schemas = AliasInfo alias_set= set annotation None set annotation alias_set is_write=a annotation None annotation is_write name=a name torchgen_schema arguments flat_all out_schemas = AliasInfo alias_set= set annotation None set annotation alias_set is_write=a annotation None annotation is_write name=a name torchgen_schema returns For non-aten ops torchgen untested so we rely torchscript schema parsing arg_schemas = AliasInfo alias_set= set alias_info None set alias_info before_set is_write=a alias_info None alias_info is_write name=a name func _schema arguments out_schemas = AliasInfo alias_set= set alias_info None set alias_info before_set is_write=a alias_info None alias_info is_write name=a name func _schema returns read_only_alias_match_indexes = arg_idx schema_arg enumerate arg_schemas return_idx schema_out enumerate out_schemas is_read_only_alias_match = schema_arg alias_set schema_out alias_set schema_arg is_write is_read_only_alias_match read_only_alias_match_indexes append arg_idx return_idx outs_write_aliases_list list Optional str = _get_write_alias r r out_schemas non_nones = sum x None x outs_write_aliases_list non_nones == outs_write_aliases Optional list str = None non_nones = len outs_write_aliases_list simplifying assumption we don t have any ops types like - Tensor Tensor raise RuntimeError Unsupported schema + str func _schema outs_write_aliases = cast list str outs_write_aliases_list schema_info = SchemaInfo args=arg_schemas outs=out_schemas This check surprisingly expensive because pybind enum_s inefficient Just cache is_inplace_view_op=torch Tag inplace_view func tags outs_write_aliases=outs_write_aliases read_only_alias_match_indexes=read_only_alias_match_indexes schema_info return_and_correct_aliasing func args kwargs out This function should used wrapper tensor ` ` __torch_dispatch__ ` ` subclasses would like work torch compile It ensures subclass properly implements aliasing behavior every op which needed correctness AOTAutograd This function will handle When we see view op we will alias storages any input output tensor subclasses When we see inplace out= op we will directly corresponding input tensor instead returning potentially fresh output tensor Caching here because torchgen parsing definitely fast function called once every op graph during functionalization schema_info = get_alias_info func get_arg_from_alias output_alias schema_info args kwargs new_args new_kwargs = torch fx operator_schemas normalize_function type ignore misc func args=args kwargs=kwargs arg_indices = i i enumerate schema_info args output_alias alias_set For any dispatcher op output alias we expect map exactly one alias schema s input arguments len arg_indices = raise AssertionError Expected exactly one argument index given output alias idx = arg_indices arg_info = schema_info args idx arg_info name None arg_info name new_kwargs new_kwargs arg_info name new_args idx Fix up storages any outs so they point same storage input func view op _correct_storage_aliasing func schema_info args out isinstance out tuple out For inplace_view ops particular we ll try hard make sure wrapper subclass s metadata set correctly schema_info is_inplace_view_op no_dispatch make sure we secretly change metadata wrapper don t end up dispatching op anywhere mutated_args = x i x enumerate args _get_write_alias schema_info args i None Assumption we have very small number inplace_view ops follow strict schema there only single argument gets its metadata mutated len mutated_args = raise AssertionError expected exactly one mutated arg inplace_view ops This check exists because we generally do want update metadata any wrapper subclasses FunctionalTensor special overrides all size stride calls plumb inner tensor so we don t actually need update metadata attempting do so causes errors torch _subclasses functional_tensor FunctionalTensor isinstance mutated_args FunctionalTensor torch utils _mode_utils no_dispatch See Note Fake Tensor Dispatch Keys we re borrowing way modifies dispatch key TLS meta_in_tls = torch _C _meta_in_tls_dispatch_include torch _C _set_meta_in_tls_dispatch_include True try func args kwargs finally torch _C _set_meta_in_tls_dispatch_include meta_in_tls Next we need make sure inputs directly output mutable alias e g add_ schema_info_outs_write_aliases = schema_info outs_write_aliases simple case none our outputs have mutable aliases so we can output as-is schema_info_outs_write_aliases None out len schema_info_outs_write_aliases == get_arg_from_alias schema_info_outs_write_aliases schema_info args kwargs In multi-return case all aten ops tuple list so cast accordingly outs_to_return = type out get_arg_from_alias write_alias schema_info args kwargs write_alias schema_info_outs_write_aliases outs_to_return