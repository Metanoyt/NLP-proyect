usr bin env python This script building AARCH wheels using AWS EC instances To generate binaries release follow these steps Update mappings each Domain Libraries adding new row table like v rc Run script following arguments each supported python versions required tag example build_aarch _wheel py -- key-name YourPemKey -- use-docker -- python -- branch v -rc os subprocess sys time typing Optional Union boto AMI images us-east- change following based your ~ aws config os_amis = ubuntu _ ami- eac edaa d f login_name ubuntu ubuntu _ ami- c c c c login_name ubuntu redhat ami- b ddcf login_name ec -user ubuntu _ _ami = os_amis ubuntu _ compute_keyfile_path key_name Optional str = None - tuple str str key_name None key_name = os getenv AWS_KEY_NAME key_name None os getenv SSH_KEY_PATH homedir_path = os path expanduser ~ default_path = os path join homedir_path ssh f key_name pem os getenv SSH_KEY_PATH default_path key_name ec = boto resource ec ec _get_instances filter_name filter_value ec instances filter Filters= Name filter_name Values filter_value ec _instances_of_type instance_type= t g xlarge ec _get_instances instance-type instance_type ec _instances_by_id instance_id rc = list ec _get_instances instance-id instance_id rc len rc None start_instance key_name ami=ubuntu _ _ami instance_type= t g xlarge ebs_size int = inst = ec create_instances ImageId=ami InstanceType=instance_type SecurityGroups= ssh-allworld KeyName=key_name MinCount= MaxCount= BlockDeviceMappings= DeviceName dev sda Ebs DeleteOnTermination True VolumeSize ebs_size VolumeType standard print f Create instance inst id inst wait_until_running running_inst = ec _instances_by_id inst id print f Instance started running_inst public_dns_name running_inst RemoteHost addr str keyfile_path str login_name str container_id Optional str = None ami Optional str = None __init__ addr str keyfile_path str login_name str = ubuntu addr = addr keyfile_path = keyfile_path login_name = login_name _gen_ssh_prefix - list str ssh -o StrictHostKeyChecking=no -i keyfile_path f login_name addr -- staticmethod _split_cmd args Union str list str - list str args split isinstance args str args run_ssh_cmd args Union str list str - None subprocess check_call _gen_ssh_prefix + _split_cmd args check_ssh_output args Union str list str - str subprocess check_output _gen_ssh_prefix + _split_cmd args decode utf- scp_upload_file local_file str remote_file str - None subprocess check_call scp -i keyfile_path local_file f login_name addr remote_file scp_download_file remote_file str local_file Optional str = None - None local_file None local_file = subprocess check_call scp -i keyfile_path f login_name addr remote_file local_file start_docker image= quay io pypa manylinux _aarch latest - None run_ssh_cmd sudo apt-get install -y docker io run_ssh_cmd f sudo usermod -a -G docker login_name run_ssh_cmd sudo service docker start run_ssh_cmd f docker pull image container_id = check_ssh_output f docker run -t -d -w root image strip using_docker - bool container_id None run_cmd args Union str list str - None using_docker run_ssh_cmd args assert container_id None docker_cmd = _gen_ssh_prefix + docker exec -i container_id bash p = subprocess Popen docker_cmd stdin=subprocess PIPE p communicate input= join source bashrc + _split_cmd args encode utf- rc = p wait rc = raise subprocess CalledProcessError rc docker_cmd check_output args Union str list str - str using_docker check_ssh_output args assert container_id None docker_cmd = _gen_ssh_prefix + docker exec -i container_id bash p = subprocess Popen docker_cmd stdin=subprocess PIPE stdout=subprocess PIPE out err = p communicate input= join source bashrc + _split_cmd args encode utf- rc = p wait rc = raise subprocess CalledProcessError rc docker_cmd output=out stderr=err out decode utf- upload_file local_file str remote_file str - None using_docker scp_upload_file local_file remote_file tmp_file = os path join tmp os path basename local_file scp_upload_file local_file tmp_file run_ssh_cmd docker cp tmp_file f container_id root remote_file run_ssh_cmd rm tmp_file download_file remote_file str local_file Optional str = None - None using_docker scp_download_file remote_file local_file tmp_file = os path join tmp os path basename remote_file run_ssh_cmd docker cp f container_id root remote_file tmp_file scp_download_file tmp_file local_file run_ssh_cmd rm tmp_file download_wheel remote_file str local_file Optional str = None - None using_docker local_file None basename = os path basename remote_file local_file = basename replace -linux_aarch whl -manylinux _aarch whl download_file remote_file local_file list_dir path str - list str check_output ls - path split \n wait_for_connection addr port timeout= attempt_cnt= socket i range attempt_cnt try socket create_connection addr port timeout=timeout except ConnectionRefusedError TimeoutError noqa PERF i == attempt_cnt - raise time sleep timeout update_apt_repo host RemoteHost - None time sleep host run_cmd sudo systemctl stop apt-daily service &#124; &#124; true host run_cmd sudo systemctl stop unattended-upgrades service &#124; &#124; true host run_cmd while systemctl is-active -- quiet apt-daily service do sleep done host run_cmd while systemctl is-active -- quiet unattended-upgrades service do sleep done host run_cmd sudo apt-get update time sleep host run_cmd sudo apt-get update install_condaforge host RemoteHost suffix str = latest download Miniforge -Linux-aarch sh - None print Install conda-forge host run_cmd f curl -OL https github com conda-forge miniforge releases suffix host run_cmd f sh -f os path basename suffix -b host run_cmd f rm -f os path basename suffix host using_docker host run_cmd echo PATH=$ HOME miniforge bin $ PATH bashrc host run_cmd sed -i ^# If running interactively i PATH=$ HOME miniforge bin $ PATH bashrc install_condaforge_python host RemoteHost python_version= - None python_version == Python- EOLed compatible conda- install_condaforge host suffix= download - Miniforge - - -Linux-aarch sh host run_cmd f conda install -y python= python_version numpy pyyaml install_condaforge host suffix= download - Miniforge - - -Linux-aarch sh Pytorch- older compatible setuptools= newer host run_cmd f conda install -y python= python_version numpy pyyaml setuptools = embed_libgomp host RemoteHost use_conda wheel_name - None host run_cmd pip install auditwheel host run_cmd conda install -y patchelf use_conda sudo apt-get install -y patchelf tempfile NamedTemporaryFile NamedTemporaryFile tmp tmp write embed_library_script encode utf- tmp flush host upload_file tmp name embed_library py print Embedding libgomp into wheel host using_docker host run_cmd f python embed_library py wheel_name -- update-tag host run_cmd f python embed_library py wheel_name checkout_repo host RemoteHost branch str = main url str git_clone_flags str mapping dict str tuple str str - Optional str prefix mapping branch startswith prefix continue tag = f v mapping prefix - mapping prefix host run_cmd f git clone url -b tag git_clone_flags mapping prefix host run_cmd f git clone url -b branch git_clone_flags None build_torchvision host RemoteHost branch str = main use_conda bool = True git_clone_flags str run_smoke_tests bool = True - str print Checking out TorchVision repo build_version = checkout_repo host branch=branch url= https github com pytorch vision git_clone_flags=git_clone_flags mapping= v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc print Building TorchVision wheel Please note libnpg jpeg required build image so extension use_conda host run_cmd conda install -y libpng jpeg Remove so files force static linking host run_cmd rm miniforge lib libpng so miniforge lib libpng so miniforge lib libjpeg so And patch setup py include libz dependency libpng host run_cmd sed -i -e \ s image_link_flags\\ append png image_link_flags += png z \ vision setup py build_vars = branch == nightly version = host check_output -f vision version txt then cat vision version txt fi strip len version == In older revisions version embedded setup py version = host check_output grep version = \ vision setup py strip split - build_date = host check_output cd vision git log -- pretty=format s - strip split replace - build_vars += f BUILD_VERSION= version dev build_date build_version None build_vars += f BUILD_VERSION= build_version PYTORCH_VERSION= branch split - maxsplit= host using_docker build_vars += CMAKE_SHARED_LINKER_FLAGS=-Wl -z max-page-size= x host run_cmd f cd vision build_vars python -m build -- wheel -- no-isolation vision_wheel_name = host list_dir vision dist embed_libgomp host use_conda os path join vision dist vision_wheel_name print Copying TorchVision wheel host download_wheel os path join vision dist vision_wheel_name run_smoke_tests host run_cmd f pip install os path join vision dist vision_wheel_name host run_cmd python vision test smoke_test py print Delete vision checkout host run_cmd rm -rf vision vision_wheel_name build_torchdata host RemoteHost branch str = main use_conda bool = True git_clone_flags str = - str print Checking out TorchData repo git_clone_flags += -- recurse-submodules build_version = checkout_repo host branch=branch url= https github com pytorch data git_clone_flags=git_clone_flags mapping= v v rc v rc print Building TorchData wheel build_vars = branch == nightly version = host check_output -f data version txt then cat data version txt fi strip build_date = host check_output cd data git log -- pretty=format s - strip split replace - build_vars += f BUILD_VERSION= version dev build_date build_version None build_vars += f BUILD_VERSION= build_version PYTORCH_VERSION= branch split - maxsplit= host using_docker build_vars += CMAKE_SHARED_LINKER_FLAGS=-Wl -z max-page-size= x host run_cmd f cd data build_vars python -m build -- wheel -- no-isolation wheel_name = host list_dir data dist embed_libgomp host use_conda os path join data dist wheel_name print Copying TorchData wheel host download_wheel os path join data dist wheel_name wheel_name build_torchtext host RemoteHost branch str = main use_conda bool = True git_clone_flags str = - str print Checking out TorchText repo git_clone_flags += -- recurse-submodules build_version = checkout_repo host branch=branch url= https github com pytorch text git_clone_flags=git_clone_flags mapping= v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc print Building TorchText wheel build_vars = branch == nightly version = host check_output -f text version txt then cat text version txt fi strip build_date = host check_output cd text git log -- pretty=format s - strip split replace - build_vars += f BUILD_VERSION= version dev build_date build_version None build_vars += f BUILD_VERSION= build_version PYTORCH_VERSION= branch split - maxsplit= host using_docker build_vars += CMAKE_SHARED_LINKER_FLAGS=-Wl -z max-page-size= x host run_cmd f cd text build_vars python -m build -- wheel -- no-isolation wheel_name = host list_dir text dist embed_libgomp host use_conda os path join text dist wheel_name print Copying TorchText wheel host download_wheel os path join text dist wheel_name wheel_name build_torchaudio host RemoteHost branch str = main use_conda bool = True git_clone_flags str = - str print Checking out TorchAudio repo git_clone_flags += -- recurse-submodules build_version = checkout_repo host branch=branch url= https github com pytorch audio git_clone_flags=git_clone_flags mapping= v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc v rc print Building TorchAudio wheel build_vars = branch == nightly version = host check_output grep version = \ audio setup py strip split - build_date = host check_output cd audio git log -- pretty=format s - strip split replace - build_vars += f BUILD_VERSION= version dev build_date build_version None build_vars += f BUILD_VERSION= build_version PYTORCH_VERSION= branch split - maxsplit= host using_docker build_vars += CMAKE_SHARED_LINKER_FLAGS=-Wl -z max-page-size= x host run_cmd f cd audio export FFMPEG_ROOT=$ pwd third_party ffmpeg export USE_FFMPEG= \ packaging ffmpeg build sh \ build_vars python -m build -- wheel -- no-isolation wheel_name = host list_dir audio dist embed_libgomp host use_conda os path join audio dist wheel_name print Copying TorchAudio wheel host download_wheel os path join audio dist wheel_name wheel_name configure_system host RemoteHost compiler str = gcc- use_conda bool = True python_version str = - None use_conda install_condaforge_python host python_version print Configuring system host using_docker update_apt_repo host host run_cmd sudo apt-get install -y ninja-build g++ git cmake gfortran unzip host run_cmd yum install -y sudo host run_cmd conda install -y ninja scons use_conda host run_cmd sudo apt-get install -y python -dev python -yaml python -setuptools python -wheel python -pip host run_cmd pip install dataclasses typing-extensions use_conda print Installing Cython + numpy PyPy host run_cmd sudo pip install Cython host run_cmd sudo pip install numpy build_domains host RemoteHost branch str = main use_conda bool = True git_clone_flags str = - tuple str str str str vision_wheel_name = build_torchvision host branch=branch use_conda=use_conda git_clone_flags=git_clone_flags audio_wheel_name = build_torchaudio host branch=branch use_conda=use_conda git_clone_flags=git_clone_flags data_wheel_name = build_torchdata host branch=branch use_conda=use_conda git_clone_flags=git_clone_flags text_wheel_name = build_torchtext host branch=branch use_conda=use_conda git_clone_flags=git_clone_flags vision_wheel_name audio_wheel_name data_wheel_name text_wheel_name start_build host RemoteHost branch str = main compiler str = gcc- use_conda bool = True python_version str = pytorch_only bool = False pytorch_build_number Optional str = None shallow_clone bool = True enable_mkldnn bool = False - tuple str str str str str git_clone_flags = -- depth -- shallow-submodules shallow_clone host using_docker use_conda print Auto-selecting conda option docker images use_conda = True host using_docker print Disable mkldnn host builds enable_mkldnn = False configure_system host compiler=compiler use_conda=use_conda python_version=python_version host using_docker print Move libgfortant into standard location HACK pypa gforntran compiled without PIC which leads following error libgfortran error o text _gfortrani_st_printf+ x unresolvable R_AARCH _ADR_PREL_PG_HI relocation against symbol ` __stack_chk_guard GLIBC_ noqa E B Workaround copying gfortran library host host run_ssh_cmd sudo apt-get install -y gfortran- host run_cmd mkdir -p usr lib gcc aarch -linux-gnu host run_ssh_cmd docker cp usr lib gcc aarch -linux-gnu libgfortran f host container_id opt rh devtoolset- root usr lib gcc aarch -redhat-linux print Checking out PyTorch repo host run_cmd f git clone -- recurse-submodules -b branch https github com pytorch pytorch git_clone_flags host run_cmd pytorch ci docker common install_openblas sh print Building PyTorch wheel build_opts = pytorch_build_number None build_opts += f -C -- build-option= -- build-number= pytorch_build_number Breakpad build fails aarch build_vars = USE_BREAKPAD= branch == nightly build_date = host check_output cd pytorch git log -- pretty=format s - strip split replace - version = host check_output cat pytorch version txt strip - build_vars += f BUILD_TEST= PYTORCH_BUILD_VERSION= version dev build_date PYTORCH_BUILD_NUMBER= branch startswith v v build_vars += f BUILD_TEST= PYTORCH_BUILD_VERSION= branch branch find - PYTORCH_BUILD_NUMBER= host using_docker build_vars += CMAKE_SHARED_LINKER_FLAGS=-Wl -z max-page-size= x enable_mkldnn host run_cmd pytorch ci docker common install_acl sh print build pytorch mkldnn+acl backend build_vars += USE_MKLDNN=ON USE_MKLDNN_ACL=ON build_vars += BLAS=OpenBLAS build_vars += OpenBLAS_HOME= opt OpenBLAS build_vars += ACL_ROOT_DIR= acl host run_cmd f cd $ HOME pytorch build_vars python -m build -- wheel -- no-isolation build_opts print Repair wheel pytorch_wheel_name = host list_dir pytorch dist ld_library_path = acl build $ HOME pytorch build lib host run_cmd f export LD_LIBRARY_PATH= ld_library_path auditwheel repair $ HOME pytorch dist pytorch_wheel_name print replace original wheel repaired one pytorch_repaired_wheel_name = host list_dir wheelhouse host run_cmd f cp $ HOME wheelhouse pytorch_repaired_wheel_name $ HOME pytorch dist pytorch_wheel_name print build pytorch without mkldnn backend host run_cmd f cd pytorch build_vars python -m build -- wheel -- no-isolation build_opts print Deleting build folder host run_cmd cd pytorch rm -rf build pytorch_wheel_name = host list_dir pytorch dist embed_libgomp host use_conda os path join pytorch dist pytorch_wheel_name print Copying wheel host download_wheel os path join pytorch dist pytorch_wheel_name print Installing PyTorch wheel host run_cmd f pip install pytorch dist pytorch_wheel_name pytorch_only pytorch_wheel_name None None None None domain_wheels = build_domains host branch=branch use_conda=use_conda git_clone_flags=git_clone_flags pytorch_wheel_name domain_wheels embed_library_script = usr bin env python auditwheel patcher Patchelf auditwheel wheeltools InWheelCtx auditwheel elfutils elf_file_filter auditwheel repair copylib auditwheel lddtree lddtree subprocess check_call os shutil sys tempfile TemporaryDirectory replace_tag filename open filename r f lines = f read split \\n i line enumerate lines line startswith Tag continue lines i = line replace -linux_ -manylinux _ print f Updated tag line lines i open filename w f f write \\n join lines AlignedPatchelf Patchelf set_soname file_name str new_soname str - None check_call patchelf -- page-size -- set-soname new_soname file_name replace_needed file_name str soname str new_soname str - None check_call patchelf -- page-size -- replace-needed soname new_soname file_name embed_library whl_path lib_soname update_tag=False patcher = AlignedPatchelf out_dir = TemporaryDirectory whl_name = os path basename whl_path tmp_whl_name = os path join out_dir name whl_name InWheelCtx whl_path ctx torchlib_path = os path join ctx _tmpdir name torch lib ctx out_wheel=tmp_whl_name new_lib_path new_lib_soname = None None filename elf elf_file_filter ctx iter_files filename startswith torch lib continue libtree = lddtree filename lib_soname libtree needed continue lib_path = libtree libs lib_soname path lib_path None print f Can t embed lib_soname could found break lib_path startswith torchlib_path continue new_lib_path None new_lib_soname new_lib_path = copylib lib_path torchlib_path patcher patcher replace_needed filename lib_soname new_lib_soname print f Replacing lib_soname new_lib_soname filename update_tag Add manylinux tag filename ctx iter_files os path basename filename = WHEEL continue replace_tag filename shutil move tmp_whl_name whl_path __name__ == __main__ embed_library sys argv libgomp so len sys argv sys argv == -- update-tag run_tests host RemoteHost whl str branch= main - None print Configuring system update_apt_repo host host run_cmd sudo apt-get install -y python -pip git host run_cmd sudo pip install Cython host run_cmd sudo pip install numpy host upload_file whl host run_cmd f sudo pip install whl host run_cmd python -c torch print torch rand host run_cmd f git clone -b branch https github com pytorch pytorch host run_cmd cd pytorch test python test_torch py -v get_instance_name instance - Optional str instance tags None None tag instance tags tag Key == Name tag Value None list_instances instance_type str - None print f All instances type instance_type instance ec _instances_of_type instance_type ifaces = instance network_interfaces az = ifaces subnet availability_zone len ifaces None print f instance id get_instance_name instance instance public_dns_name instance state Name az terminate_instances instance_type str - None print f Terminating all instances type instance_type instances = list ec _instances_of_type instance_type instance instances print f Terminating instance id instance terminate print Waiting termination complete instance instances instance wait_until_terminated parse_arguments argparse ArgumentParser parser = ArgumentParser Build test AARCH wheels using EC parser add_argument -- key-name type=str parser add_argument -- debug action= store_true parser add_argument -- build-only action= store_true parser add_argument -- test-only type=str group = parser add_mutually_exclusive_group group add_argument -- os type=str choices=list os_amis keys group add_argument -- ami type=str parser add_argument -- python-version type=str choices= f d d range default=None parser add_argument -- alloc-instance action= store_true parser add_argument -- list-instances action= store_true parser add_argument -- pytorch-only action= store_true parser add_argument -- keep-running action= store_true parser add_argument -- terminate-instances action= store_true parser add_argument -- instance-type type=str default= t g xlarge parser add_argument -- ebs-size type=int default= parser add_argument -- branch type=str default= main parser add_argument -- use-docker action= store_true parser add_argument -- compiler type=str choices= gcc- gcc- gcc- clang default= gcc- parser add_argument -- use-torch-from-pypi action= store_true parser add_argument -- pytorch-build-number type=str default=None parser add_argument -- disable-mkldnn action= store_true parser parse_args __name__ == __main__ args = parse_arguments ami = args ami args ami None os_amis args os args os None ubuntu _ _ami keyfile_path key_name = compute_keyfile_path args key_name args list_instances list_instances args instance_type sys exit args terminate_instances terminate_instances args instance_type sys exit len key_name == raise RuntimeError Cannot start build without key_name please specify -- key-name argument AWS_KEY_NAME environment variable len keyfile_path == os path exists keyfile_path raise RuntimeError f Cannot find keyfile name key_name path keyfile_path please check ` ~ ssh ` folder manually set SSH_KEY_PATH environment variable Starting instance inst = start_instance key_name ami=ami instance_type=args instance_type ebs_size=args ebs_size instance_name = f args key_name - args os args python_version None instance_name += f -py args python_version inst create_tags DryRun=False Tags= Key Name Value instance_name addr = inst public_dns_name wait_for_connection addr host = RemoteHost addr keyfile_path host ami = ami args use_docker update_apt_repo host host start_docker args test_only run_tests host args test_only sys exit args alloc_instance args python_version None sys exit install_condaforge_python host args python_version sys exit python_version = args python_version args python_version None args use_torch_from_pypi configure_system host compiler=args compiler python_version=python_version print Installing PyTorch wheel host run_cmd pip install torch build_domains host branch=args branch git_clone_flags= -- depth -- shallow-submodules start_build host branch=args branch compiler=args compiler python_version=python_version pytorch_only=args pytorch_only pytorch_build_number=args pytorch_build_number enable_mkldnn=not args disable_mkldnn args keep_running print f Waiting instance inst id terminate inst terminate inst wait_until_terminated