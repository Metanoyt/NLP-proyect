Owner s oncall profiler os unittest unittest skipIf torch torch utils cpp_extension torch _environment is_fbcode torch testing _internal common_utils IS_WINDOWS run_tests TestCase is_fbcode caffe test profiler_test_cpp_thread_lib cpp manual= caffe test profiler_test_cpp_thread_lib cpp extensions use relative paths Those paths relative file so we ll change working directory temporarily old_working_dir = os getcwd os chdir os path dirname os path abspath __file__ cpp = torch utils cpp_extension load name= profiler_test_cpp_thread_lib sources= test_cpp_thread cpp verbose=True working directory see setUp os chdir old_working_dir KinetoProfiler = None IterationCount = ActivateIteration = device = None blueprint text print f \ m text \ m onIterationStart will called C++ training engine cpp_thread_test_lib cpp PythonProfilerEventHandler cpp ProfilerEventHandler onIterationStart iteration int - None global KinetoProfiler IterationCount important start profiler same thread step called yes onIterationStart will always called same thread iteration == also means step starts iteration KinetoProfiler start blueprint starting kineto profiler iteration == IterationCount - KinetoProfiler stop blueprint stopping kineto profiler blueprint stepping kineto profiler KinetoProfiler step emulateTraining iteration int thread_id int - None global device blueprint f training iteration iteration thread thread_id torch_device = getattr torch device assert hasattr torch_device synchronize sync_func = torch_device synchronize torch autograd profiler record_function user_function = torch ones device=device b = torch ones device=device torch add b cpu sync_func CppThreadTestCUDA TestCase ThreadCount = set debugging EventHandler = None TraceObject = None classmethod setUpClass cls - None super TestCase cls setUpClass CppThreadTestCUDA EventHandler = PythonProfilerEventHandler cpp ProfilerEventHandler Register CppThreadTestCUDA EventHandler classmethod tearDownClass cls is_fbcode torch testing _internal common_utils remove_cpp_extensions_build_root setUp - None torch cuda is_available skipTest Test machine does have cuda global device device = cuda clears off events initialization start_profiler False cpp start_threads IterationCount False start_profiler profile_memory global KinetoProfiler KinetoProfiler = torch profiler profile schedule=torch profiler schedule wait= warmup= active=ActivateIteration repeat= on_trace_ready=self set_trace with_stack=True profile_memory=profile_memory record_shapes=True set_trace trace_obj - None CppThreadTestCUDA TraceObject = trace_obj assert_text condition text msg condition print f \ m text \ m print f \ m text \ m assertTrue condition msg check_trace expected mem=False - None blueprint verifying trace event_list = CppThreadTestCUDA TraceObject events key values expected items count = values min_count = count ActivateIteration - device = values filtered = filter lambda ev ev name == key str ev device_type == f DeviceType device event_list mem actual = ev filtered sev = str ev has_cuda_memory_usage = sev find cuda_memory_usage= sev find cuda_memory_usage= has_cuda_memory_usage actual += assert_text actual = min_count f key actual = min_count enough event cuda_memory_usage set actual = len list filtered count == test_without count = ActivateIteration assert_text actual == count f key actual == count baseline event count incorrect assert_text actual = min_count f key actual = min_count enough event recorded skipIf IS_WINDOWS Failing windows cuda see https github com pytorch pytorch pull slightly more context test_with_enable_profiler_in_child_thread_cuda - None start_profiler False cpp start_threads ThreadCount IterationCount True check_trace aten add ThreadCount CPU user_function ThreadCount CUDA skipIf IS_WINDOWS Failing windows cuda see https github com pytorch pytorch pull slightly more context test_without_enable_profiler_in_child_thread_cuda - None start_profiler False cpp start_threads ThreadCount IterationCount False check_trace aten add CPU user_function CUDA skipIf IS_WINDOWS Failing windows cuda see https github com pytorch pytorch pull slightly more context test_profile_memory_cuda - None start_profiler True cpp start_threads ThreadCount IterationCount True check_trace aten add ThreadCount CPU mem=True Here duplicate CppThreadTest enable xpu cases because instantiate_device_type_tests will call method setUpClass In function setUpClass instantiated e g CppThreadTestCPU CppThreadTestXPU needs called get member EventHandler while period input argument cls CppThreadTest which defined any more We cannot detect which instantiated being created setUpClass so duplicate here enabling xpu test cases CppThreadTestXPU TestCase ThreadCount = set debugging EventHandler = None TraceObject = None classmethod setUpClass cls - None super TestCase cls setUpClass CppThreadTestXPU EventHandler = PythonProfilerEventHandler cpp ProfilerEventHandler Register CppThreadTestXPU EventHandler classmethod tearDownClass cls is_fbcode torch testing _internal common_utils remove_cpp_extensions_build_root setUp - None torch xpu is_available skipTest Test machine does have xpu global device device = xpu clears off events initialization start_profiler False cpp start_threads IterationCount False start_profiler profile_memory global KinetoProfiler KinetoProfiler = torch profiler profile schedule=torch profiler schedule wait= warmup= active=ActivateIteration repeat= on_trace_ready=self set_trace with_stack=True profile_memory=profile_memory record_shapes=True set_trace trace_obj - None CppThreadTestXPU TraceObject = trace_obj assert_text condition text msg condition print f \ m text \ m print f \ m text \ m assertTrue condition msg check_trace expected mem=False - None blueprint verifying trace event_list = CppThreadTestXPU TraceObject events key values expected items count = values min_count = count ActivateIteration - device = values filtered = filter lambda ev ev name == key str ev device_type == f DeviceType device event_list mem actual = ev filtered sev = str ev has_cuda_memory_usage = sev find xpu_memory_usage= sev find xpu_memory_usage= has_cuda_memory_usage actual += assert_text actual = min_count f key actual = min_count enough event xpu_memory_usage set actual = len list filtered count == test_without count = ActivateIteration assert_text actual == count f key actual == count baseline event count incorrect assert_text actual = min_count f key actual = min_count enough event recorded unittest skip reason= The XPU Profiler will cover case now Will support next period test_with_enable_profiler_in_child_thread_xpu - None start_profiler False cpp start_threads ThreadCount IterationCount True check_trace aten add ThreadCount CPU user_function ThreadCount XPU unittest skip reason= The XPU Profiler will cover case now Will support next period test_without_enable_profiler_in_child_thread_xpu - None start_profiler False cpp start_threads ThreadCount IterationCount False check_trace aten add CPU user_function XPU unittest skip reason= The XPU Profiler will cover case now Will support next period test_profile_memory_xpu - None start_profiler True cpp start_threads ThreadCount IterationCount True check_trace aten add ThreadCount CPU mem=True __name__ == __main__ run_tests