mypy allow-untyped-defs copy enum functools logging re time abc ABC abstractmethod typing Any Optional Union torch torch utils _pytree pytree torch _inductor autotune_process TensorMeta torch _inductor codegen cuda cutlass_cache maybe_fetch_ops torch _inductor codegen wrapper PythonWrapperCodegen torch _inductor runtime runtime_utils dynamo_timed torch _inductor scheduler BaseSchedulerNode torch _inductor select_algorithm create_inputs_key torch _inductor utils clear_on_fresh_cache ir config cuda inductor_cuda_config ir Buffer ChoiceCaller CUDATemplateBuffer FixedLayout IRNode Layout ReinterpretView utils is_dynamic Placeholder virtualized V common IndentedBuffer cutlass_utils cuda_kernel CUDATemplateKernel cuda_template CUTLASSTemplate cutlass_python_evt CutlassEVTCodegen scaled_mm_evt cutlass_utils ACCUMULATOR_DTYPES dtype_match torch_dtype_to_cutlass_type XW_DTYPES GemmOperation = Any EVTArgRenames = Any log = logging getLogger __name__ Jinja template GEMM Kernel used CUTLASSGemm xTemplate below GEMM_TEMPLATE_CUTLASS_ X = r template header getvalue template globals getvalue epilogue_visitor_tree instance_definition When workspace_size nullptr populates requested workspace_size returns Otherwise computes Gemm kernel using given workspace ptr extern C PT_EXPORT kernel_call_signature try using ElementComputeEpilogue = instance_type ElementAccumulator using coord_t = cutlass gemm GemmCoord Index static cutlass KernelHardwareInfo hw_info hw_info sm_count == hw_info sm_count = cutlass KernelHardwareInfo query_device_multiprocessor_count CUTLASS_TRACE_HOST Query result SM count per device hw_info sm_count instance_type Arguments arguments template render_gemm_arguments argument_template epilogue_template should_swap_xw X W Bias Y alpha beta kernel epilogue_args instance_type gemm_op workspace_size workspace_size = gemm_op get_workspace_size arguments check null pointers after workspace size since querying workspace size doesn t require valid data pointers #ifndef CUTLASS_BACKEND_DISABLE_CHECKS auto status = gemm_op can_implement arguments CUTLASS_CHECK status #endif #ifdef CUTLASS_DEBUG_TRACE_LEVEL #if CUTLASS_DEBUG_TRACE_LEVEL == Print maximum number active blocks per SM kernel CUTLASS_DEBUG_TRACE_LEVEL == we don t need print statement s happening inside function gemm_op maximum_active_blocks #endif #endif auto status = gemm_op initialize arguments workspace stream CUTLASS_CHECK status auto status = gemm_op stream CUTLASS_CHECK status catch std exception e std cerr Runtime error e what std endl - catch - configuration name op_conf_name Jinja template Cutlass x GEMM Kernel arguments used CUTLASSGemmTemplate below GEMM_ARGS_CUTLASS_ X = r Initialize GemmUniversal xInstance arguments arguments = template gemm_mode GemmUniversalMode mode static_cast coord_t M static_cast coord_t N static_cast coord_t K static_cast coord_t B ProblemShape problem_shape template cutlass_type_cast X kernel ptr X ElementA const ptr_A template cute_int kernel stride X - stride_x template cute_int kernel stride X - stride_x template cute_int kernel batch_stride X batch_stride_x StrideA dA template cutlass_type_cast W kernel ptr W ElementB const ptr_B template cute_int kernel stride W - stride_w template cute_int kernel stride W - stride_w template cute_int kernel batch_stride W batch_stride_w StrideB dB MainloopArguments mainloop epilogue_arguments hw_info arguments scheduler max_swizzle_size = swizzle Jinja template Cutlass x GEMM Kernel arguments epilogue fusion applied used CUTLASSGemmTemplate below GEMM_ARGS_CUTLASS_ X_EPILOGUE = r see https tinyurl com rk z epilogue_args thread typename FusionCallbacks Arguments EVT ThreadEpilogueOp Params non-EVT template cutlass_type_cast Bias kernel ptr Bias ElementC const ptr_C template cute_int kernel stride Bias - stride_bias template cute_int kernel stride Bias - stride_bias template cute_int kernel batch_stride Bias batch_stride_bias StrideC dC template cutlass_type_cast Y kernel ptr Y ElementD const ptr_D template cute_int kernel stride Y - stride_y template cute_int kernel stride Y - stride_y template cute_int kernel batch_stride Y batch_stride_y StrideD dD EpilogueArguments epilogue Jinja template GEMM Kernel used CUTLASS xGemmTemplate below GEMM_TEMPLATE_CUTLASS_ X = r template header getvalue template globals getvalue instance_definition When workspace_size nullptr populates requested workspace_size returns Otherwise computes Gemm kernel using given workspace ptr extern C PT_EXPORT kernel_call_signature try int B = kernel size Y - default_value= using ElementComputeEpilogue = instance_type ElementAccumulator using coord_t = cutlass gemm GemmCoord Index static cutlass KernelHardwareInfo hw_info hw_info sm_count == hw_info sm_count = cutlass KernelHardwareInfo query_device_multiprocessor_count CUTLASS_TRACE_HOST Query result SM count per device hw_info sm_count instance_type Arguments arguments template render_gemm_arguments instance_type argument_template epilogue_template should_swap_xw X W Bias Meta Y alpha beta kernel epilogue_args instance_type gemm_op workspace_size workspace_size = gemm_op get_workspace_size arguments check null pointers after workspace size since querying workspace size doesn t require valid data pointers #ifndef CUTLASS_BACKEND_DISABLE_CHECKS auto status = gemm_op can_implement arguments CUTLASS_CHECK status #endif #ifdef CUTLASS_DEBUG_TRACE_LEVEL #if CUTLASS_DEBUG_TRACE_LEVEL == Print maximum number active blocks per SM kernel CUTLASS_DEBUG_TRACE_LEVEL == we don t need print statement s happening inside function gemm_op maximum_active_blocks #endif #endif auto status = gemm_op initialize arguments workspace stream CUTLASS_CHECK status auto status = gemm_op stream CUTLASS_CHECK status catch std exception e std cerr Runtime error e what std endl - catch - Jinja template Cutlass x GEMM Kernel arguments used CUTLASS xGemmTemplate below GEMM_ARGS_CUTLASS_ X = r int _t batch_stride_x = kernel stride X - int _t row_stride_x = kernel row_or_column_stride X int _t batch_stride_w = kernel stride W - int _t row_stride_w = kernel row_or_column_stride W int _t batch_stride_bias = kernel stride Bias - int _t row_stride_bias = kernel row_or_column_stride Bias int _t batch_stride_y = kernel stride Y - int _t row_stride_y = kernel row_or_column_stride Y Initialize GemmUniversalInstance arguments arguments = template gemm_mode GemmUniversalMode mode static_cast coord_t M static_cast coord_t N static_cast coord_t K GemmCoord problem_size split_k split_k B int batch_count ElementComputeEpilogue alpha ElementComputeEpilogue beta typename EpilogueOutputOp Params epilogue template cutlass_type_cast X kernel ptr X void const ptr_A template cutlass_type_cast W kernel ptr W void const ptr_B template cutlass_type_cast Bias kernel ptr Bias void const ptr_C template cutlass_type_cast Y kernel ptr Y void ptr_D batch_stride_x int _t batch_stride_A batch_stride_w int _t batch_stride_B batch_stride_bias int _t batch_stride_C batch_stride_y int _t batch_stride_D row_stride_x typename LayoutA Stride LongIndex lda row_stride_w typename LayoutB Stride LongIndex ldb row_stride_bias typename LayoutC Stride LongIndex ldc row_stride_y typename LayoutC Stride LongIndex ldd GEMM_ARGS_SPARSE_CUTLASS_ X = r using TensorRefA = cutlass TensorRef instance_type ElementA instance_type LayoutA using TensorRefB = cutlass TensorRef instance_type ElementB instance_type LayoutB using TensorRefC = cutlass TensorRef instance_type ElementC instance_type LayoutC using TensorRefE = cutlass TensorRef instance_type ElementE instance_type LayoutE Note X W names may misleading here Namely sparse GEMM first argument always sparse while typically weight matrix implied name W will sparse applications Thus just remember here X refers first argument sparse W second dense TensorRefA X_ref template cutlass_type_cast X kernel ptr X kernel row_or_column_stride X TensorRefB W_ref template cutlass_type_cast W kernel ptr W kernel row_or_column_stride W TensorRefC Y_ref template cutlass_type_cast Y kernel ptr Y kernel row_or_column_stride Y TensorRefE Meta_ref template cutlass_sparse_meta_type_cast Meta kernel ptr Meta TensorRefE Layout packed kernel size Meta kernel size Meta Initialize GemmSparse arguments arguments = static_cast coord_t M static_cast coord_t N static_cast coord_t K GemmCoord problem_size X_ref TensorRef ElementA const LayoutA ref_A W_ref TensorRef ElementB const LayoutB ref_B Y_ref TensorRef ElementC const LayoutC ref_C Y_ref TensorRef ElementC LayoutC ref_D Meta_ref TensorRef ElementE const LayoutE ref_E ElementComputeEpilogue alpha ElementComputeEpilogue beta typename EpilogueOutputOp Params epilogue Additional includes which necessary standalone test debug runner generated well GEMM_STANDALONE_RUNNER_ADDITIONAL_INCLUDES = r #ifdef GENERATE_STANDALONE_RUNNER #include cutlass util distribution h #include cutlass util host_tensor h #include cutlass util packed_stride hpp #include cutlass util tensor_view_io h #include cutlass util reference device gemm_complex h #include cutlass util reference device tensor_compare h #include cutlass util reference device tensor_fill h #include iostream #endif Jinja template standalone runner may generated part code GEMM_STANDALONE_RUNNER_TEMPLATE = r #ifdef GENERATE_STANDALONE_RUNNER Helper initialize block device data template Element bool initialize_block cutlass DeviceAllocation Element block uint _t seed float max= float min=- block size = false Element scope_max static_cast Element max scope_min static_cast Element min cutlass reference device BlockFillRandomUniform Element block get block size seed scope_max scope_min true Meta defined Meta none template Element bool initialize_block_meta cutlass DeviceAllocation Element block uint _t seed block size = false cutlass reference device BlockFillRandomSparseMeta Element block get block size seed instance_type kMetaSizeInBits true endif extern C int run_standalone uint _t seed int repetitions std cout Starting GEMM Standalone test run seed seed std endl size_t workspace_size = size_t workspace_size_ptr = workspace_size int M = kernel get_layout_args int N = kernel get_layout_args int K = kernel get_layout_args int B = kernel get_layout_args int lda = kernel get_layout_args int ldb = kernel get_layout_args int ldc = kernel get_layout_args int ldd = kernel get_layout_args uint _t swizzle = kernel runtime_arg_values using ElementA = kernel cutlass_dtype X using ElementB = kernel cutlass_dtype W using ElementC = kernel cutlass_dtype Bias default_dtype= uint _t may void using ElementD = kernel cutlass_dtype Y Meta defined Meta none using ElementE = kernel cutlass_dtype Meta endif cutlass DeviceAllocation ElementA X_data kernel max_valid_index X + initialize_block X_data seed++ cutlass DeviceAllocation ElementB W_data kernel max_valid_index W + initialize_block W_data seed++ cutlass DeviceAllocation ElementC Bias_data kernel max_valid_index Bias + initialize_block Bias_data seed++ cutlass DeviceAllocation ElementD Y_data kernel max_valid_index Y + Meta defined Meta none cutlass DeviceAllocation ElementE Meta_data kernel max_valid_index Meta + initialize_block_meta Meta_data seed++ endif cutlass DeviceAllocation uint _t workspace_data Call once workspace_size_ptr set get workspace size std cout Calling once get workspace size std endl test_call_statement Allocate workspace necessary workspace_size workspace_data reset workspace_size std cout Allocated workspace size workspace_size bytes std endl std cout Calling Kernel test_call_statement std endl workspace_size_ptr = nullptr int i= i repetitions i++ test_call_statement cudaError_t result = cudaDeviceSynchronize result = cudaSuccess std cerr Device synchronize failed error cudaGetErrorString result std endl result int main int argc char argv warmup run_standalone repeat run_standalone #endif noqa B clear_on_fresh_cache CUTLASSGemmTemplate CUTLASSTemplate ABC CUTLASS GEMM Template which used generate CUTLASS GEMM kernels including those which allow flexible fusions epilogues filtered_ops_cache dict str list Any = cache_clear = staticmethod filtered_ops_cache clear __init__ input_nodes list Buffer layout Layout alpha float beta float input_reorder Optional list int = None use_fast_accum Optional bool = None - None Args input_nodes List Buffer List input nodes GEMM kernel layout Layout Layout type resulting output node alpha float The scaling factor product inputs GEMM operation beta float The scaling factor applied output matrix input_reorder Optional List int Specifies reordering input nodes If provided no reordering performed Defaults None super __init__ str Placeholder KERNEL_NAME input_nodes layout input_reorder alpha = alpha beta = beta use_fast_accum = use_fast_accum assert = len input_nodes = assert _are_inputs_layout_compatible node get_layout node input_nodes cache_key str = create_inputs_key input_nodes staticmethod abstractmethod add_cutlass_gemm_choices choices list ChoiceCaller layout ir Layout input_nodes list Buffer alpha Union float int = beta Union float int = input_reorder Optional list int = None use_fast_accum Optional bool = None extra_kwargs - None raise NotImplementedError staticmethod abstractmethod _get_supported_ops - list cutlass_library gemm_operation GemmOperation type ignore name-defined noqa F raise NotImplementedError staticmethod abstractmethod _has_tma_epilogue - bool raise NotImplementedError abstractmethod _get_template - str raise NotImplementedError abstractmethod _get_template_args op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - tuple str Optional str raise NotImplementedError abstractmethod _are_inputs_layout_compatible layouts list Layout - bool raise NotImplementedError abstractmethod _shape_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool raise NotImplementedError abstractmethod _alignment_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool raise NotImplementedError abstractmethod _set_bias_layout_and_alignment op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool raise NotImplementedError abstractmethod _define_gemm_instance op GemmOperation evt_name Optional str = None - tuple str str raise NotImplementedError abstractmethod _get_extra_inputs_and_names op cutlass_gemm_op GemmOperation = None type ignore name-defined noqa F - tuple Optional Buffer list Optional Buffer list str raise NotImplementedError abstractmethod _update_arg_names_for_test_call_statement arg_names list str input_nodes list Buffer - list str raise NotImplementedError _add_cutlass_gemm_choices choices list ChoiceCaller layout ir Layout input_nodes list Buffer alpha Union float int = beta Union float int = input_reorder Optional list int = None extra_kwargs - None Adds Cutlass GEMM configurations choices auto-tuning list This function mutates passed list choices appending choices Cutlass GEMM configs Args choices list The list which choices appended layout ir Layout The layout configuration input_nodes list The list input nodes alpha float int Scaling factor defaults beta float int Offset defaults input_reorder list optional Order inputs defaults None extra_kwargs Additional keyword arguments ops = gen_ops pre-computation layout_repr str = str layout input_tensor_meta Union TensorMeta list TensorMeta = TensorMeta from_irnodes input_nodes output_tensor_meta Union TensorMeta list TensorMeta = TensorMeta from_irnodes output_node dynamo_timed CUTLASSGemmTemplate maybe_append_choice name op ops swizzle inductor_cuda_config cutlass_max_profiling_swizzle_options description = f name swizzle= swizzle maybe_append_choice choices op=op name=name description=description input_key=self cache_key layout_repr=layout_repr input_tensor_meta=input_tensor_meta output_tensor_meta=output_tensor_meta swizzle=swizzle len ops == log info No suitable Cutlass GEMM configs found fallbacks used len ops = d output_layout= s input_layouts= s input_strides= s len ops layout node get_layout node input_nodes node get_stride node input_nodes log debug Added d Cutlass gemm configs len ops header - IndentedBuffer Returns buffer containing CUDA C++ code header section CUTLASS GEMM template This section primarily includes necessary header files Returns IndentedBuffer An instance IndentedBuffer contains generated CUDA C++ header code res = super header res splice #include cutlass gemm gemm h #include cutlass gemm device gemm_universal h #include cutlass gemm device gemm_universal_adapter h #include cutlass gemm kernel gemm_universal hpp #include cutlass gemm device gemm_sparse h #include cutlass gemm collective collective_builder hpp #include cutlass epilogue collective collective_builder hpp #include cutlass epilogue collective default_epilogue hpp #include cutlass epilogue thread linear_combination h #include cutlass epilogue thread activation h #include cutlass gemm dispatch_policy hpp #include cutlass gemm kernel tile_scheduler hpp #include cutlass tensor_ref h #include cutlass util distribution h #include cutlass util packed_stride hpp #include cutlass util tensor_view_io h inductor_cuda_config generate_test_runner is_dynamic input_nodes output_node res splice GEMM_STANDALONE_RUNNER_ADDITIONAL_INCLUDES res staticmethod cutlass_layout torch_layout ir Layout - Optional cutlass_lib LayoutType type ignore name-defined noqa F Converts ir Layout instance into corresponding cutlass_library LayoutType enum value RowMajor ColumnMajor None no matching value found Args torch_layout ir Layout The layout needs looked up Returns cutlass_lib LayoutType The converted layout corresponding ` torch_layout ` None no matching value found assert cutlass_utils try_import_cutlass cutlass_library library cutlass_lib V graph sizevars statically_known_equals torch_layout stride - cutlass_lib LayoutType RowMajor V graph sizevars statically_known_equals torch_layout stride - cutlass_lib LayoutType ColumnMajor None staticmethod flip_cutlass_layout cutlass_layout cutlass_lib LayoutType type ignore name-defined noqa F - cutlass_lib LayoutType type ignore name-defined noqa F Helper method Flips given cutlass layout cutlass_lib LayoutType RowMajor ColumnMajor vice versa assert cutlass_utils try_import_cutlass cutlass_library library cutlass_lib cutlass_layout == cutlass_lib LayoutType RowMajor cutlass_lib LayoutType ColumnMajor cutlass_lib LayoutType RowMajor staticmethod functools lru_cache layout_match torch_layout ir Layout cutlass_layout cutlass_lib LayoutType type ignore name-defined noqa F - bool Helper Method Determines whether given torch layout matches given Cutlass layout CUTLASSGemmTemplate cutlass_layout torch_layout == cutlass_layout staticmethod set_layout tensor_desc TensorDescription torch_layout ir Layout - None type ignore name-defined noqa F Helper method Sets layout given tensor description match given torch layout CUTLASSGemmTemplate layout_match torch_layout tensor_desc layout tensor_desc layout = CUTLASSGemmTemplate cutlass_layout torch_layout staticmethod set_alignment torch_layout op_element - bool Helper method update alignment given CUTLASS GEMM op operand s element This method modifies alignment given Cutlass GEMM op operand s element match layout corresponding ir Buffer node Args torch_layout The layout corresponding ir Buffer node op_element The Cutlass GEMM op operand s element whose alignment updated Returns bool True alignment successfully updated False otherwise alignment = cutlass_utils get_max_alignment torch_layout cuda_arch = cutlass_utils get_cuda_arch cuda_arch int cuda_arch = alignment op_element alignment False op_element alignment = alignment True staticmethod should_swap_XW bias IRNode - bool Helper method determine whether we should do explicit transpose switching order matmul operands This might necessary when we can t otherwise arrive right memory layout given Bias operand Note This method workaround CUDA Errors seemingly non-deterministically occurred practice some CUTLASS GEMM Kernels Linear epilogues have bias term might make sense check newer Cutlass releases whether makes sense keep returning True certain cases whether becomes unnecessary If bias row major swap all M N dimensions bias None len bias get_stride = bias get_stride - log debug GEMM Layout swapped X W - explicit transpose True False staticmethod swap_XW op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - cutlass_library gemm_op GemmOperation type ignore name-defined noqa F Swap operands X W aka operans A B GEMM operation This requires transposing operands which done swapping strides Note we don t change apparent external layout just operand layout intentional new_op = copy deepcopy op new_op A layout = CUTLASSGemmTemplate flip_cutlass_layout new_op A layout new_op B layout = CUTLASSGemmTemplate flip_cutlass_layout new_op B layout new_op A new_op B = new_op B new_op A new_op C layout = CUTLASSGemmTemplate flip_cutlass_layout new_op C layout new_op D layout = CUTLASSGemmTemplate flip_cutlass_layout new_op D layout new_op fix_op_layout op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F X Buffer W Buffer Bias Optional Buffer Y Union Buffer ReinterpretView - cutlass_library gemm_op GemmOperation type ignore name-defined noqa F This workaround deal cases where input layouts have changed between autotuning rendering This happens inputs layout FlexibleLayout instances In case we need update op s input layouts It hack because now op we benchmarked same op we render there no simple way fix autotuner since would potentially disable other optimizations a_layout = X get_layout b_layout = W get_layout c_layout = Bias get_layout Bias None None d_layout = copy deepcopy Y get_layout match_list = CUTLASSGemmTemplate layout_match buf get_layout op_layout buf op_layout zip X W Bias Y op A layout op B layout op C layout op D layout buf None all_match = all match_list all_match op log warning f Cutlass GEMM Layout change Input output layouts have changed between autotuning retuning call render Applying workaround This can lead suboptimal performance Match List match_list noqa G B new_op = copy deepcopy op a_layout None new_op A layout = CUTLASSGemmTemplate cutlass_layout a_layout b_layout None new_op B layout = CUTLASSGemmTemplate cutlass_layout b_layout c_layout None new_op C layout = CUTLASSGemmTemplate cutlass_layout c_layout new_op C element = cutlass_utils torch_dtype_to_cutlass_type c_layout dtype d_layout None new_op D layout = CUTLASSGemmTemplate cutlass_layout d_layout new_op _dtype_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool Checking dtypes A B acc D here Empirically speaking CUTLASS x ops have same dtype C D X = input_nodes W = input_nodes accumulator_torch_dtype = cutlass_utils get_accumulator_dtype X get_dtype W get_dtype cutlass_utils dtype_match X get_dtype op A element cutlass_utils dtype_match W get_dtype op B element cutlass_utils dtype_match output_node get_layout dtype op D element cutlass_utils dtype_match accumulator_torch_dtype op accumulator_type False True classmethod global_filter_ops cls ops list cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - list cutlass_library gemm_op GemmOperation type ignore name-defined noqa F Filter ops without using information about torch op input nodes output node assert cutlass_utils try_import_cutlass cutlass_library library cutlass_lib type ignore Skip simt kernels ops = op op ops op tile_description math_instruction opcode_class = cutlass_lib OpcodeClass Simt only keep set row x column ops other layout we modify place filter_op after deepcopy ops = op op ops op A layout name == RowMajor op B layout name == ColumnMajor filter supported accumulator types ops = op op ops any dtype_match torch_dtype op accumulator_type torch_dtype ACCUMULATOR_DTYPES check dtypes A B supported ops = op op ops any dtype_match torch_dtype op A element torch_dtype XW_DTYPES any dtype_match torch_dtype op B element torch_dtype XW_DTYPES ops filter_op op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - cutlass_library gemm_op GemmOperation type ignore name-defined noqa F Helper method Determines whether given Cutlass GEMM op definition suitable current input output operation template supposed implement Takes memory layout dtype support EVT operations into account filters potentially problematic ops Returns None op suitable otherwise returns op used which might have been mutated op gemm_kind _get_supported_ops None X = input_nodes W = input_nodes Filter ops according shape match _shape_match op None Filter ops dtypes _dtype_match op None Filter ops alignment _alignment_match op log debug Skipping due alignment mismatch op s op configuration_name None only use stream k static shape op tile_scheduler name == StreamK static_shape = PythonWrapperCodegen statically_known_list_of_ints_or_none tuple X get_size + tuple W get_size static_shape None Update op op = copy deepcopy op set layouts X W set_layout op A X get_layout set_layout op B W get_layout Set output layout op D layout = CUTLASSGemmTemplate cutlass_layout output_node get_layout Filter ops alignments set alignments status = set_alignment X get_layout op A set_alignment W get_layout op B set_alignment output_node get_layout op D status log debug Skipping due alignment setting failure op s op configuration_name None inductor_cuda_config cutlass_tma_only _has_tma_epilogue op None Set epilogue TODO update epilogue functor according epilogues op element_epilogue = op accumulator_type use_fast_accum None is_op_fast_accum = fastaccum op configuration_name use_fast_accum ^ is_op_fast_accum None Set bias layout alignment status = _set_bias_layout_and_alignment op status log debug Skipping due bias layout alignment setting failure op s op configuration_name None Apply regex filters end when configuration name doesn t change anymore inductor_cuda_config cutlass_op_allowlist_regex re search inductor_cuda_config cutlass_op_allowlist_regex op configuration_name None inductor_cuda_config cutlass_op_denylist_regex None re search inductor_cuda_config cutlass_op_denylist_regex op configuration_name None op gen_ops - list tuple str cutlass_gemm_op GemmOperation type ignore name-defined noqa F Creates list Cutlass GemmOperation instances match operation template designed represent The matching carried out respect input output specifications operation No function arguments Returns List tuple str cutlass_gemm_op GemmOperation A list cutlass_name GemmOperation tuples compatible operation requirements template assert cutlass_utils try_import_cutlass cutlass_library gemm_operation cutlass_gemm_op cache_key filtered_ops_cache log debug Using cached ops s cache_key filtered_ops_cache cache_key dynamo_timed CUTLASSGemmTemplate maybe_fetch_ops maybe_ops = maybe_fetch_ops maybe_ops None log debug Cannot fetch ops cache generating ops scratch full_ops = cutlass_utils gen_ops ops = pytree tree_flatten full_ops log debug Using cached ops cache ops = maybe_ops ops = global_filter_ops ops res dict str cutlass_gemm_op GemmOperation = start_time = time time op ops changed need also change CUTLASS_OPERATION_KIND assert isinstance op cutlass_gemm_op GemmOperation filter_res = filter_op op filter_res None res get filter_res configuration_name None None res filter_res configuration_name = filter_res log info Got cutlass configs total number ops d Filtering took f seconds len res time time - start_time sorted_res = sorted res items ret_res = sorted_res inductor_cuda_config cutlass_max_profiling_configs len filtered_ops_cache filtered_ops_cache cache_key = ret_res log debug Not caching ops since filtered_ops_cache has reached size ret_res gemm_mode - str Returns Cutlass GEMM mode string current operation dependent whether op implements batched GEMM simple GEMM without batch dimension Returns str A string indicating Cutlass GEMM mode If output node has more than two dimensions cutlass gemm GemmUniversalMode kBatched returned otherwise cutlass gemm GemmUniversalMode kGemm returned sizes = output_node get_size len sizes cutlass gemm GemmUniversalMode kBatched cutlass gemm GemmUniversalMode kGemm render type ignore override kernel CUDATemplateKernel op cutlass_gemm_op GemmOperation = None type ignore name-defined noqa F template_buffer_node Optional CUDATemplateBuffer = None epilogue_nodes Optional list BaseSchedulerNode = None kwargs - str The primary entry point code rendering process used template Renders Cutlass based CUDA C++ code GEMM Kernel template designed implement including potentially fused epilogues Args kernel CUDATemplateKernel The kernel rendered op cutlass_gemm_op GemmOperation optional A GEMM operation required compatible input output definitions well possible epilogue Defaults None kwargs Additional keyword arguments Currently unused Returns str Cutlass based CUDA C++ code fragment string used current CUDATemplateKernel autotuning code Note All inputs their corresponding buffer addresses names take precedence over previously passed inputs template construction time However they should layout compatible assert cutlass_utils try_import_cutlass cutlass_library gemm_operation cutlass_gemm_op cutlass_library library cutlass_lib assert isinstance op cutlass_gemm_op GemmOperation op argument required has instance GemmOperation epilogue_nodes _has_tma_epilogue op raise NotImplementedError Non-TMA epilogue visitor tree supported Cutlass assert len input_nodes = output_node None X W = input_nodes input_nodes input_node input_nodes isinstance X layout FixedLayout input_node freeze_layout Y = output_node template_buffer_node None Y = template_buffer_node Bias extra_inputs extra_names = _get_extra_inputs_and_names op Define Kernel call signature Important This step also populates Kernel name node mapping data structures which required further below example template renderer inputs = X W Bias extra_inputs names = X W Bias extra_names + Y names_str = join names input_reorder None input_reorder = input_reorder input_reorder = None The layouts might have changed between autotuning call they FlexibleLayout we need adapt which might lead suboptimal performance op = fix_op_layout op X W Bias Y make op mutable without affecting others op = copy deepcopy op is_scaled_mm = len input_nodes Bias None is_scaled_mm assert Bias get_dtype == X get_dtype This might have been set void during filtering when assumption still there s no C operand op C element = op A element assert op C element == op D element f Expect C D have same dtype found op C element op D element argument_template epilogue_template = _get_template_args op should_swap_xw bool = False Bias None _has_tma_epilogue op op epilogue_schedule = cutlass_lib EpilogueScheduleType EpilogueTransposed should_swap_XW Bias TMA epilogue requires bias vector column major get best perf op = swap_XW op should_swap_xw = True name_to_buffer = node get_name node node input_nodes handle fake output buffer during lowering name_to_buffer Y get_name = Y type ignore assignment epilogue_nodes is_scaled_mm epilogue_nodes input_names output_names var_name_to_buffer_name evt_py_code = CutlassEVTCodegen ir_to_evt_python_code Y get_name epilogue_nodes V kernel removed_buffers TODO mlazos remove returning buffer metadata ir_to_evt_python code name buf V graph name_to_buffer &#124; V graph graph_inputs items name name_to_buffer name_to_buffer name = buf type ignore assignment D_output_name = var_name_to_buffer_name D D_output_buffer = name_to_buffer D_output_name Y = D_output_buffer type ignore assignment Interestingly I don t think rest layout matters here since we use properties Y buffer fill D s properties epilogue args This needed though because defines types expected epilogue args op D element = cutlass_utils torch_dtype_to_cutlass_type D_output_buffer get_dtype assert output_names There should least one write epilogue_inputs = name_to_buffer name name input_names outputs = name_to_buffer name name output_names Scaled MM we read two scale matrices optional bias write single output bias = None len input_nodes input_nodes bias_name = bias get_name bias None evt_read_names var_name_to_buffer_name evt_py_code = scaled_mm_evt input_nodes get_name scale_A input_nodes get_name scale_B bias_name Y get_name input_names = list evt_read_names output_names = We only need Y epilogue_inputs = input_nodes input_nodes bias epilogue_inputs append bias outputs = acc_dtype = cutlass_utils get_accumulator_dtype X get_dtype W get_dtype assert acc_dtype Could determine accumulator dtype evt_name evt_args evt_code evt_arg_renames = _render_evt op evt_py_code var_name_to_buffer_name name_to_buffer Y get_dtype acc_dtype inputs = X W Bias epilogue_inputs type ignore list-item Y extra_inputs input_names = evt_arg_renames get name name input_names output_names = evt_arg_renames get name name output_names names_str = join X W Bias input_names Y output_names extra_names evt_name = None outputs = Y evt_args = f ElementComputeEpilogue alpha ElementComputeEpilogue beta evt_code = kernel_call_signature = kernel def_kernel inputs=inputs type ignore arg-type outputs=outputs type ignore arg-type names_str=names_str input_reorder=input_reorder test_call_statement = test_call_statement kernel inputs names_str instance_definition instance_type = _define_gemm_instance op evt_name options = alpha alpha beta beta X X W W Y Y kernel_call_signature kernel_call_signature Bias Bias epilogue_template epilogue_template argument_template argument_template should_swap_xw should_swap_xw template kernel kernel instance_definition instance_definition instance_type instance_type input_reorder input_reorder epilogue_args evt_args test_call_statement test_call_statement op_conf_name op configuration_name epilogue_visitor_tree evt_code options update dict zip extra_names extra_inputs res = _template_from_string _get_template render options inductor_cuda_config generate_test_runner is_dynamic X W Y Bias test_runner_code = _template_from_string GEMM_STANDALONE_RUNNER_TEMPLATE render options res += \n\n + test_runner_code splice remove trailing spaces each line buf = IndentedBuffer buf splice res buf getvalue test_call_statement kernel input_nodes names_str str = - str Helper method render Cutlass CUDA C++ code required calling GEMM operation standalone test runner might also generated along rest code corresponding config enabled Returns C++ statement calls GEMM operation correct arguments _ __ arg_types = kernel args cpp_argdefs cutlass_utils DTYPE_TO_CUTLASS_TYPE arg_names = name strip name names_str strip split arg_names = _update_arg_names_for_test_call_statement arg_names input_nodes arguments = f arg_type arg_name _data get arg_type arg_name zip arg_types arg_names f kernel kernel_name join arguments M N K B lda ldb ldc ldd swizzle workspace_size_ptr uint _t workspace_data get noqa B _render_evt op GemmOperation evt_py_code str buffer_renames dict str str name_to_buffer dict str Buffer output_dtype torch dtype accumulator_dtype torch dtype - tuple str str str EVTArgRenames type ignore name-defined noqa F raise NotImplementedError _render_evt CUTLASSGemmTemplate implemented CUTLASS xGemmTemplate CUTLASSGemmTemplate CUTLASS x GEMM Template which used generate CUTLASS GEMM kernels including those which allow flexible fusions epilogues __init__ input_nodes list Buffer layout Layout alpha float beta float input_reorder Optional list int = None use_fast_accum Optional bool = None super __init__ input_nodes layout alpha beta input_reorder use_fast_accum staticmethod add_cutlass_gemm_choices choices list ChoiceCaller layout ir Layout input_nodes list Buffer alpha Union float int = beta Union float int = input_reorder Optional list int = None use_fast_accum Optional bool = None extra_kwargs - None template = CUTLASS xGemmTemplate input_nodes layout alpha beta input_reorder use_fast_accum template _add_cutlass_gemm_choices choices layout input_nodes alpha beta input_reorder extra_kwargs staticmethod functools lru_cache _get_supported_ops - list cutlass_library gemm_operation GemmOperation type ignore name-defined noqa F cutlass_library library cutlass_lib cutlass_lib GemmKind Universal x _get_template - str GEMM_TEMPLATE_CUTLASS_ X _get_template_args op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - tuple str Optional str GEMM_ARGS_CUTLASS_ X GEMM_ARGS_CUTLASS_ X_EPILOGUE staticmethod _has_tma_epilogue noqa F type ignore arg-type name-defined op cutlass_library gemm_op GemmOperation type ignore name-defined arg-type noqa F - bool type ignore name-defined Helper method Determine whether given Cutlass GEMM op has TMA Epilogue assert cutlass_utils try_import_cutlass cutlass_library library cutlass_lib result = False op gemm_kind == cutlass_lib GemmKind Universal x epilogue_schedule_str = str op epilogue_schedule split - result = epilogue_schedule_str lower startswith tma result staticmethod supports_epilogue_fusion op GemmOperation - bool CUTLASS xGemmTemplate _has_tma_epilogue op _are_inputs_layout_compatible layouts list Layout - bool Evaluates whether input layouts compatible General Matrix Multiply GEMM This function checks compatibility A B possibly C operand layouts General Matrix Multiply GEMM operation expressed alpha matmul A B + beta C It verifies requirements such matching data types minimum rank suitability broadcasting defined PyTorch operations like ` torch matmul ` ` torch aten mm ` ` addmm ` ` bmm ` ` baddbmm ` etc Args layouts List Layout List containing Layout objects representing input matrices A B possibly C Returns bool True layouts GEMM compatible otherwise False assert = len layouts = Check A B compatible A_layout B_layout = layouts len A_layout size False len B_layout size False A_size = list V graph sizevars size_hints A_layout size B_size = list V graph sizevars size_hints B_layout size len A_size A_size insert len B_size A_size insert Are batch dims broadcastable while len A_size len B_size A_size insert while len B_size len A_size B_size insert K = max A_size - B_size - M = A_size - N = B_size - K = A_size - A_size - = False K = B_size - B_size - = False check batch dim broadcastable i range len A_size - A_size i = B_size i A_size i = B_size i = False len layouts == C_layout = layouts C_size = V graph sizevars size_hint i i C_layout size while len C_size len A_size C_size insert check batch dims i range len A_size - bd = max A_size i B_size i bd = C_size i C_size i = False len C_size len A_size This may happen last elements C contiguous their multiplied size equals last dim size B M = C_size len A_size - C_size len A_size - = False remaining_size = i range len A_size - len C_size remaining_size = C_size i N = remaining_size remaining_size = False True assert len C_size == len A_size M = C_size - C_size - = False N = C_size - C_size - = False True _render_evt op GemmOperation evt_py_code str var_name_to_buffer_name dict str str name_to_buffer dict str Buffer output_dtype torch dtype accumulator_dtype torch dtype - tuple str str str EVTArgRenames cutlass_lib_extensions evt_extensions create_example_tensors trace acc_dtype = torch_dtype_to_cutlass_type accumulator_dtype output_dtype = torch_dtype_to_cutlass_type output_dtype examples = create_example_tensors var_name_to_buffer_name name_to_buffer type ignore arg-type V graph sizevars size_hint evt_name evt_args evt_code arg_renames = trace evt_py_code examples acc_dtype output_dtype op tile_description type ignore attr-defined op epilogue_schedule type ignore attr-defined k name_to_buffer v k v var_name_to_buffer_name items type ignore arg-type misc V graph sizevars size_hint evt_name evt_args evt_code arg_renames _shape_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool True _alignment_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool True _set_bias_layout_and_alignment op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool cutlass_library library cutlass_lib has_bias = len input_nodes == input_nodes None has_bias Bias = input_nodes bias dtype op C element = cutlass_utils torch_dtype_to_cutlass_type Bias get_layout dtype Bias layout bias_layout = CUTLASSGemmTemplate cutlass_layout Bias get_layout op C layout = bias_layout Bias alignment status = set_alignment Bias get_layout op C status False op C element = cutlass_lib DataType void True _define_gemm_instance op GemmOperation evt_name Optional str = None - tuple str str Defines renders Cutlass CUDA C++ code given GEMM operation instance This function uses Cutlass library generate key parts codegen process General Matrix Multiply forms core part number scientific applications so efficient adaptable implementation crucial Args op cutlass_library gemm_op GemmOperation This core GEMM operation we defining rendering Returns tuple str str A tuple where first part string constitutes defined GEMM operation C++ code render second part string specifies operation type assert cutlass_utils try_import_cutlass cutlass_library library cutlass_lib cutlass_lib_extensions gemm_operation_extensions gemm_extensions emitter = gemm_extensions EmitGemmUniversal xInstanceWithEVT evt_name=evt_name type ignore call-arg hasattr op epilogue_functor isinstance op epilogue_functor enum Enum op = copy deepcopy op op epilogue_functor = cutlass_lib EpilogueFunctor LinearCombination op_def = emitter emit op pattern = re compile r \s struct\s \s decl = line line op_def split \n struct line - match = pattern match decl match None raise RuntimeError Invalid Gemm config \n + op_def op_type = match groups op gemm_kind == cutlass_lib GemmKind Universal x op_def += f \n using op_type _device_type = cutlass gemm device GemmUniversalAdapter op_type \n op_type = f op_type _device_type op_def op_type _get_extra_inputs_and_names op cutlass_gemm_op GemmOperation = None type ignore name-defined noqa F - tuple Optional Buffer list Optional Buffer list str Bias = input_nodes len input_nodes == None inputs list Optional Buffer = names list str = Bias inputs names _update_arg_names_for_test_call_statement arg_names list str input_nodes list Buffer - list str input_nodes None del arg_names Reorder them Bias A B input_reorder None arg_names len input_reorder = arg_names i i input_reorder arg_names render_gemm_arguments argument_template str epilogue_template str should_swap_xw bool X IRNode W IRNode Bias IRNode Y IRNode alpha float beta float kernel CUDATemplateKernel epilogue_args - str Render Cutlass CUDA C++ code required passing arguments GEMM operation Args argument_template str Template GEMM operation arguments epilogue_template str Template epilogue arguments should_swap_xw bool Determines whether X W operands should swapped If True applies explicit transpose operation X W X IRNode The X input tensor W IRNode The W input tensor Bias IRNode The bias tensor Y IRNode The output tensor alpha float Scaling factor product inputs beta float Scaling factor output tensor kernel CUDATemplateKernel CUDA Template kernel operation epilogue_args any Additional arguments epilogue state Returns str A block CUDA C++ code string ready used arguments GEMM operation Note If ` should_swap_xw ` True transpose operation will applied X W Bias Y tensors This operation also implies M N dimensions Bias GEMM output swapped before function call options = alpha alpha beta beta X X W W Y Y Bias Bias template kernel kernel M M N N epilogue_args epilogue_args assert epilogue_template None should_swap_xw Swap clone_with_transposed_stride node IRNode - IRNode old_layout = node get_layout new_stride = list old_layout stride type ignore union-attr new_stride - new_stride - = new_stride - new_stride - assert old_layout device None new_layout = FixedLayout old_layout device old_layout dtype list old_layout size type ignore union-attr new_stride old_layout offset type ignore union-attr Buffer name=node get_name layout=new_layout new_X = clone_with_transposed_stride X new_W = clone_with_transposed_stride W new_Bias = clone_with_transposed_stride Bias new_Y = clone_with_transposed_stride Y options X options W options Bias options Y = new_W new_X new_Bias new_Y options M options N = N M epilogue_arguments = _template_from_string epilogue_template render options arguments = _template_from_string argument_template render epilogue_arguments=epilogue_arguments options arguments CUTLASS xGemmTemplate CUTLASSGemmTemplate __init__ input_nodes list Buffer layout Layout alpha float beta float input_reorder Optional list int = None super __init__ input_nodes layout alpha beta input_reorder staticmethod add_cutlass_gemm_choices choices list ChoiceCaller layout ir Layout input_nodes list Buffer alpha Union float int = beta Union float int = input_reorder Optional list int = None use_fast_accum Optional bool = False extra_kwargs - None template = CUTLASS xGemmTemplate input_nodes layout alpha beta input_reorder template _add_cutlass_gemm_choices choices layout input_nodes alpha beta input_reorder extra_kwargs staticmethod _get_supported_ops - list cutlass_library gemm_operation GemmOperation type ignore name-defined noqa F cutlass_library library cutlass_lib cutlass_lib GemmKind Universal cutlass_lib GemmKind Sparse staticmethod _has_tma_epilogue - bool False _get_template - str GEMM_TEMPLATE_CUTLASS_ X _get_template_args op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - tuple str Optional str cutlass_library library cutlass_lib op gemm_kind == cutlass_lib GemmKind Sparse GEMM_ARGS_SPARSE_CUTLASS_ X None GEMM_ARGS_CUTLASS_ X None _are_inputs_layout_compatible layouts list Layout - bool Evaluates whether input layouts compatible set operations supported Args layouts List Layout List containing Layout objects representing input matrices Returns bool True layouts GEMM compatible otherwise False assert len layouts == len layouts == Check A B compatible A_layout B_layout = layouts len A_layout size = False len B_layout size = False A_size = int i i A_layout size B_size = int i i B_layout size K = max A_size B_size K == A_size K == A_size K == B_size _shape_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool cutlass_library library cutlass_lib X W = input_nodes input_nodes op gemm_kind == cutlass_lib GemmKind Sparse X get_size == W get_size X get_size == W get_size _alignment_match op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool cutlass_library library cutlass_lib op gemm_kind = cutlass_lib GemmKind Sparse True SparseGemm CUTLASS has specific alignment check small k could make some choices throw kMisalignedOperand CUTLASS error when run see https github com NVIDIA cutlass blob e b b b caca c f d d cf dcae include cutlass gemm kernel sparse_gemm h#L -L noqa B So let s skip these choices would case X = input_nodes X get_size op tile_description tile_shape == _set_bias_layout_and_alignment op cutlass_library gemm_op GemmOperation type ignore name-defined noqa F - bool cutlass_library library cutlass_lib op gemm_kind == cutlass_lib GemmKind Sparse op C layout = op D layout True len input_nodes = input_nodes None Bias = input_nodes bias_layout = CUTLASSGemmTemplate cutlass_layout Bias get_layout bias_layout = op D layout For cutlass bias output layout must match False set_alignment Bias get_layout op C False op C layout = op D layout True _define_gemm_instance op GemmOperation evt_name Optional str = None - tuple str str Defines renders Cutlass CUDA C++ code given GEMM operation instance This function uses Cutlass library generate key parts codegen process General Matrix Multiply forms core part number scientific applications so efficient adaptable implementation crucial Args op cutlass_library gemm_op GemmOperation This core GEMM operation we defining rendering Returns tuple str str A tuple where first part string constitutes defined GEMM operation C++ code render second part string specifies operation type assert cutlass_utils try_import_cutlass cutlass_library gemm_operation cutlass_gemm_op cutlass_library library cutlass_lib op gemm_kind == cutlass_lib GemmKind Sparse emitter = cutlass_gemm_op EmitSparseGemmInstance emitter = cutlass_gemm_op EmitGemmInstance op_def = emitter emit op op_def = op_def replace cutlass gemm device Gemm cutlass gemm device GemmUniversal op gemm_kind = cutlass_lib GemmKind Sparse op_def = op_def replace false pattern = re compile r \s using\s \s= decl = op_def split \n match = pattern match decl match None raise RuntimeError Invalid Gemm config \n + op_def op_type = match groups op_def op_type _get_extra_inputs_and_names op cutlass_gemm_op GemmOperation = None type ignore name-defined noqa F - tuple Optional Buffer list Optional Buffer list str cutlass_library library cutlass_lib op gemm_kind == cutlass_lib GemmKind Sparse Bias = None Meta = input_nodes Bias = None len input_nodes == input_nodes Meta = None inputs = Meta names = Meta Bias inputs names _update_arg_names_for_test_call_statement arg_names list str input_nodes list Buffer - list str input_nodes None del arg_names input_nodes None del arg_names arg_names render_gemm_arguments instance_type str argument_template str epilogue_template str should_swap_xw bool X IRNode W IRNode Bias IRNode Meta IRNode Y IRNode alpha float beta float kernel CUDATemplateKernel epilogue_args - str Render Cutlass CUDA C++ code required passing arguments GEMM operation Args instance_type str GEMM instance type argument_template str Template GEMM operation arguments epilogue_template str Template epilogue arguments should_swap_xw bool Determines whether X W operands should swapped If True applies explicit transpose operation X W X IRNode The X input tensor W IRNode The W input tensor Bias IRNode The bias tensor Meta IRNode The meta tensor Y IRNode The output tensor alpha float Scaling factor product inputs beta float Scaling factor output tensor kernel CUDATemplateKernel CUDA Template kernel operation epilogue_args any Additional arguments epilogue state Returns str A block CUDA C++ code string ready used arguments GEMM operation Note If ` should_swap_xw ` True transpose operation will applied X W Bias Y tensors This operation also implies M N dimensions Bias GEMM output swapped before function call options = instance_type instance_type alpha alpha beta beta X X W W Y Y Bias Bias Meta Meta template kernel kernel M M N N epilogue_args epilogue_args epilogue_template None arguments = _template_from_string argument_template render split_k= options arguments epilogue_arguments = _template_from_string epilogue_template render options arguments = _template_from_string argument_template render epilogue_arguments=epilogue_arguments options arguments