Owner s module sparse copy torch torch nn nn torch nn functional F torch ao pruning _experimental activation_sparsifier activation_sparsifier ActivationSparsifier torch ao pruning sparsifier utils module_to_fqn torch testing _internal common_utils raise_on_run_directly skipIfTorchDynamo TestCase Model nn Module __init__ - None super __init__ conv = nn Conv d kernel_size= conv = nn Conv d kernel_size= identity = nn Identity max_pool = nn MaxPool d kernel_size= stride= linear = nn Linear identity = nn Identity linear = nn Linear forward x out = conv x out = conv out out = identity out out = max_pool out batch_size = x shape out = out reshape batch_size - out = F relu identity linear out out = linear out out TestActivationSparsifier TestCase _check_constructor activation_sparsifier model defaults sparse_config Helper function check model defaults sparse_config loaded correctly activation sparsifier sparsifier_defaults = activation_sparsifier defaults combined_defaults = defaults sparse_config sparse_config more keys populated activation sparsifier even though they may None assert len combined_defaults = len activation_sparsifier defaults key config sparsifier_defaults items all keys combined_defaults should present sparsifier defaults assert config == combined_defaults get key _check_register_layer activation_sparsifier defaults sparse_config layer_args_list Checks layers model correctly mapped s arguments Args activation_sparsifier sparsifier object activation sparsifier object being tested defaults Dict all default config except sparse_config sparse_config Dict default sparse config passed sparsifier layer_args_list list tuples Each entry list corresponds layer arguments First entry tuple corresponds all arguments other than sparse_config Second entry tuple corresponds sparse_config check args data_groups = activation_sparsifier data_groups assert len data_groups == len layer_args_list layer_args layer_args_list layer_arg sparse_config_layer = layer_args check sparse config sparse_config_actual = copy deepcopy sparse_config sparse_config_actual update sparse_config_layer name = module_to_fqn activation_sparsifier model layer_arg layer assert data_groups name sparse_config == sparse_config_actual assert rest other_config_actual = copy deepcopy defaults other_config_actual update layer_arg other_config_actual pop layer key value other_config_actual items assert key data_groups name assert value == data_groups name key get_mask should raise error assertRaises ValueError activation_sparsifier get_mask name=name _check_pre_forward_hook activation_sparsifier data_list Registering layer attaches pre-forward hook layer This function checks pre-forward hook works expected Specifically checks input aggregated correctly Basically asserts aggregate input activations same what computed sparsifier Args activation_sparsifier sparsifier object activation sparsifier object being tested data_list list torch tensors data input model attached sparsifier can only check first layer data_agg_actual = data_list model = activation_sparsifier model layer_name = module_to_fqn model model conv agg_fn = activation_sparsifier data_groups layer_name aggregate_fn i range len data_list data_agg_actual = agg_fn data_agg_actual data_list i assert data activation_sparsifier data_groups layer_name assert torch all activation_sparsifier data_groups layer_name data == data_agg_actual data_agg_actual _check_step activation_sparsifier data_agg_actual Checks step works expected Specifically checks mask computed correctly Args activation_sparsifier sparsifier object activation sparsifier object being tested data_agg_actual torch tensor aggregated torch tensor model = activation_sparsifier model layer_name = module_to_fqn model model conv assert layer_name None reduce_fn = activation_sparsifier data_groups layer_name reduce_fn data_reduce_actual = reduce_fn data_agg_actual mask_fn = activation_sparsifier data_groups layer_name mask_fn sparse_config = activation_sparsifier data_groups layer_name sparse_config mask_actual = mask_fn data_reduce_actual sparse_config mask_model = activation_sparsifier get_mask layer_name assert torch all mask_model == mask_actual config activation_sparsifier data_groups values assert data config _check_squash_mask activation_sparsifier data Makes sure squash_mask works usual Specifically checks sparsifier hook attached correctly This achieved only looking identity layers making sure output == layer input mask Args activation_sparsifier sparsifier object activation sparsifier object being tested data torch tensor dummy batched data create forward hook checking output == layer input mask check_output name mask = activation_sparsifier get_mask name features = activation_sparsifier data_groups name get features feature_dim = activation_sparsifier data_groups name get feature_dim hook module input output input_data = input features None assert torch all mask input_data == output feature_idx range len features feature = torch Tensor features feature_idx device=input_data device long inp_data_feature = torch index_select input_data feature_dim feature out_data_feature = torch index_select output feature_dim feature assert torch all mask feature_idx inp_data_feature == out_data_feature hook name config activation_sparsifier data_groups items identity name config layer register_forward_hook check_output name activation_sparsifier model data _check_state_dict sparsifier Checks loading restoring state_dict works expected Basically dumps state sparsifier loads other sparsifier checks all configuration line This function called various times workflow makes sure sparsifier can dumped restored any point time state_dict = sparsifier state_dict new_model = Model create empty new sparsifier sparsifier = ActivationSparsifier new_model assert sparsifier defaults = sparsifier defaults assert len sparsifier data_groups = len sparsifier data_groups sparsifier load_state_dict state_dict assert sparsifier defaults == sparsifier defaults name state sparsifier state items assert name sparsifier state mask = sparsifier state name mask mask = state mask mask None assert mask None assert type mask type mask isinstance mask list assert len mask == len mask idx range len mask assert torch all mask idx == mask idx assert torch all mask == mask make sure state dict stored torch sparse state state_dict state values mask = state mask mask None isinstance mask list idx range len mask assert mask idx is_sparse assert mask is_sparse dg dg = sparsifier data_groups sparsifier data_groups layer_name config dg items assert layer_name dg exclude hook layer config = key value key value config items key hook layer config = key value key value dg layer_name items key hook layer assert config == config skipIfTorchDynamo TorchDynamo fails unknown reason test_activation_sparsifier Simulates workflow activation sparsifier starting object creation till squash_mask The idea check everything works expected while workflow defining aggregate reduce mask functions agg_fn x y x + y reduce_fn x torch mean x dim= _vanilla_norm_sparsifier data sparsity_level r Similar data norm sparsifier block_shape = Simply flatten data sort mask out values less than threshold data_norm = torch abs data flatten _ sorted_idx = torch sort data_norm threshold_idx = round sparsity_level len sorted_idx sorted_idx = sorted_idx threshold_idx mask = torch ones_like data_norm mask scatter_ dim= index=sorted_idx value= mask = mask reshape data shape mask Creating default function sparse configs default sparse_config sparse_config = sparsity_level defaults = aggregate_fn agg_fn reduce_fn reduce_fn simulate workflow STEP make data activation sparsifier object model = Model create model activation_sparsifier = ActivationSparsifier model defaults sparse_config Test Constructor _check_constructor activation_sparsifier model defaults sparse_config STEP Register some layers register_layer _args = layer model conv mask_fn _vanilla_norm_sparsifier sparse_config_layer = sparsity_level register_layer _args = layer model linear features feature_dim mask_fn _vanilla_norm_sparsifier sparse_config_layer = sparsity_level register_layer _args = layer model identity mask_fn _vanilla_norm_sparsifier sparse_config_layer = sparsity_level register_layer _args = layer model identity features feature_dim mask_fn _vanilla_norm_sparsifier sparse_config_layer = sparsity_level layer_args_list = register_layer _args sparse_config_layer register_layer _args sparse_config_layer layer_args_list += register_layer _args sparse_config_layer register_layer _args sparse_config_layer Registering layer_args layer_args_list layer_arg sparse_config_layer = layer_args activation_sparsifier register_layer layer_arg sparse_config_layer check things registered correctly _check_register_layer activation_sparsifier defaults sparse_config layer_args_list check state_dict after registering before model forward _check_state_dict activation_sparsifier check forward pre hooks actually work some dummy data data_list = num_data_points = _ range num_data_points rand_data = torch randn activation_sparsifier model rand_data data_list append rand_data data_agg_actual = _check_pre_forward_hook activation_sparsifier data_list check state_dict before step _check_state_dict activation_sparsifier STEP sparsifier step activation_sparsifier step check state_dict after step before squash_mask _check_state_dict activation_sparsifier check_step _check_step activation_sparsifier data_agg_actual STEP squash mask activation_sparsifier squash_mask _check_squash_mask activation_sparsifier data_list check state_dict after squash_mask _check_state_dict activation_sparsifier __name__ == __main__ raise_on_run_directly test test_ao_sparsity py