Owner s oncall distributed checkpointing importlib json os torch torch distributed checkpoint dist_cp torch distributed dist torch distributed checkpoint quantized_hf_storage QuantizedHuggingFaceStorageReader torch distributed checkpoint state_dict_loader _load_state_dict_from_keys torch distributed device_mesh init_device_mesh torch distributed tensor distribute_tensor DTensor Replicate Shard zeros torch testing _internal common_utils instantiate_parametrized_tests run_tests TestCase torch testing _internal distributed _tensor common_dtensor DTensorTestBase skip_if_lt_x_gpu with_comms torch testing _internal distributed checkpoint_utils with_temp_dir CHECKPOINT_DIR = checkpoint MyTestModule torch nn Module __init__ - None super __init__ linear_ = torch nn Linear linear_ = torch nn Linear emb = torch nn EmbeddingBag TestSingleRankSaveLoad TestCase with_temp_dir test_save - None try safetensors torch load_file except ImportError print safetensors installed CHECKPOINT_DIR = temp_dir state_dict_to_save = MyTestModule state_dict dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR state_dict_loaded = load_file CHECKPOINT_DIR + model- -of- safetensors assertEqual sorted state_dict_to_save keys sorted state_dict_loaded keys key state_dict_to_save keys assertTrue torch equal state_dict_to_save key state_dict_loaded key with_temp_dir test_load - None try safetensors torch save_file except ImportError print safetensors installed CHECKPOINT_DIR = temp_dir state_dict_to_save = MyTestModule state_dict state_dict_to_load = MyTestModule state_dict save_file state_dict_to_save CHECKPOINT_DIR + model- -of- safetensors dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader path=CHECKPOINT_DIR assertEqual sorted state_dict_to_save keys sorted state_dict_to_load keys key state_dict_to_save keys assertTrue torch equal state_dict_to_save key state_dict_to_load key with_temp_dir test_load_into_empty_dict - None try safetensors torch save_file except ImportError print safetensors installed CHECKPOINT_DIR = temp_dir state_dict_to_save = MyTestModule state_dict save_file state_dict_to_save CHECKPOINT_DIR + model- -of- safetensors state_dict_loaded = _load_state_dict_from_keys storage_reader=dist_cp HuggingFaceStorageReader path=CHECKPOINT_DIR assertEqual sorted state_dict_to_save keys sorted state_dict_loaded keys key state_dict_to_save keys assertTrue torch equal state_dict_to_save key state_dict_loaded key with_temp_dir test_load_with_multiple_threads - None importlib util find_spec safetensors None print safetensors installed CHECKPOINT_DIR = temp_dir state_dict_to_save = MyTestModule state_dict state_dict_to_load = MyTestModule state_dict Create mapping split tensors across multiple files This will force multiple files created enabling multi-threading fqn_to_index_mapping = i fqn enumerate state_dict_to_save keys fqn_to_index_mapping fqn = i + Split across files Save using HuggingFaceStorageWriter multiple files dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR fqn_to_index_mapping=fqn_to_index_mapping dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader path=CHECKPOINT_DIR thread_count= assertEqual sorted state_dict_to_save keys sorted state_dict_to_load keys key state_dict_to_save keys assertTrue torch equal state_dict_to_save key state_dict_to_load key with_temp_dir test_quantized_checkpoint_loading - None Test end-to-end saving quantizaed checkpoint loading try safetensors torch save_file except ImportError print safetensors installed CHECKPOINT_DIR = temp_dir Create original unquantized tensors validate against original_tensors = linear weight torch randn dtype=torch float linear weight torch randn dtype=torch float embedding weight torch randn dtype=torch float Create quantized tensors scale tensors quantized_checkpoint = block_size = tensor_name original_tensor original_tensors items Simulate quantization scale down tensor quantization This simplified quantization - real scenarios would more complex rows cols = original_tensor shape Create scale tensor block-wise dequantization block_rows = rows + block_size - block_size block_cols = cols + block_size - block_size Create scale inverse tensor used dequantization scale_inv = torch ones block_rows block_cols dtype=torch float Create quantized version divide scale quantization quantized_tensor = original_tensor Simplified quantization Store quantized tensor its scale quantized_checkpoint tensor_name = quantized_tensor quantized_checkpoint f tensor_name _scale_inv = scale_inv Save quantized checkpoint safetensors file safetensors_file = os path join CHECKPOINT_DIR model safetensors save_file quantized_checkpoint safetensors_file Create model safetensors index json weight mapping weight_map = key quantized_checkpoint keys weight_map key = model safetensors index_data = metadata total_size sum t numel t element_size t quantized_checkpoint values weight_map weight_map index_file = os path join CHECKPOINT_DIR model safetensors index json open index_file w f json dump index_data f indent= Prepare state dict load into state_dict_to_load = tensor_name original_tensor original_tensors items state_dict_to_load tensor_name = torch zeros_like original_tensor Load using QuantizedHuggingFaceStorageReader dist_cp load state_dict=state_dict_to_load storage_reader=QuantizedHuggingFaceStorageReader path=CHECKPOINT_DIR target_dtype=torch float block_size=block_size thread_count= Validate loaded tensors match original tensors assertEqual sorted original_tensors keys sorted state_dict_to_load keys tensor_name original_tensors keys original = original_tensors tensor_name loaded = state_dict_to_load tensor_name Verify shapes match assertEqual original shape loaded shape f Shape mismatch tensor_name original shape vs loaded shape Verify dtypes match assertEqual original dtype loaded dtype f Dtype mismatch tensor_name original dtype vs loaded dtype Verify dequantized values match original values We expect exact match since we used simple x scaling torch testing assert_close loaded original rtol= e- atol= e- msg=f Value mismatch tensor tensor_name TestDistributedHFSafetensorsConsolidation DTensorTestBase with_comms with_temp_dir skip_if_lt_x_gpu test_consolidate_to_one_file - None importlib util find_spec safetensors None print safetensors installed safetensors global_tensor = torch arange dtype=torch float view mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape Create local tensor row-wise sharding rows_per_rank = global_tensor shape world_size start_row = rank rows_per_rank end_row = start_row + rows_per_rank local_tensor = global_tensor start_row end_row clone Create DTensor row-wise sharding dtensor = DTensor from_local local_tensor device_mesh=mesh_ d placements= Shard shape=global_tensor shape stride= global_tensor = torch arange dtype=torch float view checkpoint_dir = temp_dir state_dict_to_save = dtensor dtensor dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=checkpoint_dir save_distributed=True enable_consolidation=True dist barrier rank == file_path = os path join checkpoint_dir model- -of- safetensors loaded_dict = safetensors torch load_file file_path assertEqual loaded_dict keys dtensor assertTrue torch equal loaded_dict dtensor global_tensor dist barrier ONE_D_PLACEMENTS = Shard Replicate ONE_D_TO_ONE_D_PLACEMENTS = Replicate Shard Shard Replicate TWO_D_PLACEMENTS = Replicate Replicate Replicate Shard Shard Replicate Shard Shard TWO_D_TO_TWO_D_PLACEMENTS = p TWO_D_PLACEMENTS p TWO_D_PLACEMENTS p = p TWO_D_TO_TWO_D_PLACEMENTS append p p instantiate_parametrized_tests TestDTensorReshardPlacementChange DTensorTestBase Test DCP reshard DTensor placements changes without world_size change mesh_tensor change with_comms skip_if_lt_x_gpu with_temp_dir test_ d_to_ d_reshard_placement_change - None importlib util find_spec safetensors None print safetensors installed CHECKPOINT_DIR = temp_dir one_d_to_one_d_placements ONE_D_TO_ONE_D_PLACEMENTS original_placement new_placement = one_d_to_one_d_placements global_tensor = torch arange dtype=torch float view mesh_shape = world_size device_mesh = init_device_mesh device_type mesh_shape dtensor = distribute_tensor global_tensor device_mesh placements=original_placement state_dict_to_save = dtensor dtensor dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR save_distributed=True zero_dtensor = zeros device_mesh=device_mesh placements=new_placement state_dict_to_load = dtensor zero_dtensor dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader CHECKPOINT_DIR materialize whole tensor compare original global_tensor state_dict_to_load dtensor = state_dict_to_load dtensor redistribute device_mesh placements= Replicate assertEqual global_tensor state_dict_to_load dtensor to_local redistribute tensor back its original placement comparison state_dict_to_load dtensor = state_dict_to_load dtensor redistribute device_mesh placements=original_placement assertEqual state_dict_to_save dtensor to_local state_dict_to_load dtensor to_local with_comms skip_if_lt_x_gpu with_temp_dir test_ d_to_ d_reshard_placement_change - None importlib util find_spec safetensors None print safetensors installed CHECKPOINT_DIR = temp_dir two_d_to_two_d_placements TWO_D_TO_TWO_D_PLACEMENTS original_placement new_placement = two_d_to_two_d_placements global_tensor = torch arange dtype=torch float view mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape dtensor = distribute_tensor global_tensor mesh_ d placements=original_placement state_dict_to_save = dtensor dtensor dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR save_distributed=True planner=dist_cp DefaultSavePlanner zero_dtensor = zeros device_mesh=mesh_ d placements=new_placement state_dict_to_load = dtensor zero_dtensor dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader CHECKPOINT_DIR state_dict_to_load dtensor = state_dict_to_load dtensor redistribute mesh_ d placements= Replicate Replicate assertEqual global_tensor state_dict_to_load dtensor to_local state_dict_to_load dtensor = state_dict_to_load dtensor redistribute mesh_ d placements=original_placement assertEqual state_dict_to_save dtensor to_local state_dict_to_load dtensor to_local TestDTensorReshardMeshChange DTensorTestBase Test DCP reshard DTensor placements changes mesh_tensor change with_comms with_temp_dir skip_if_lt_x_gpu test_ d_to_ d_reshard_mesh_change - None importlib util find_spec safetensors None print safetensors installed CHECKPOINT_DIR = temp_dir placements_ d ONE_D_PLACEMENTS global_tensor = torch arange dtype=torch float view mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape dtensor = distribute_tensor global_tensor mesh_ d placements=placements_ d state_dict_to_save = dtensor dtensor dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR save_distributed=True placements_ d TWO_D_PLACEMENTS mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape zero_dtensor = zeros device_mesh=mesh_ d placements=placements_ d state_dict_to_load = dtensor zero_dtensor dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader CHECKPOINT_DIR planner=dist_cp DefaultLoadPlanner materialzie whole tensor compare original global_tensor state_dict_to_load dtensor = state_dict_to_load dtensor redistribute mesh_ d placements= Replicate Replicate assertEqual global_tensor state_dict_to_load dtensor to_local with_comms with_temp_dir skip_if_lt_x_gpu test_ d_to_ d_reshard_mesh_change - None importlib util find_spec safetensors None print safetensors installed CHECKPOINT_DIR = temp_dir placements_ d TWO_D_PLACEMENTS global_tensor = torch arange dtype=torch float view mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape dtensor = distribute_tensor global_tensor mesh_ d placements=placements_ d state_dict_to_save = dtensor dtensor dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp HuggingFaceStorageWriter path=CHECKPOINT_DIR save_distributed=True planner=dist_cp DefaultSavePlanner placements_ d ONE_D_PLACEMENTS mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape zero_dtensor = zeros device_mesh=mesh_ d placements=placements_ d state_dict_to_load = dtensor zero_dtensor dist_cp load state_dict=state_dict_to_load storage_reader=dist_cp HuggingFaceStorageReader CHECKPOINT_DIR planner=dist_cp DefaultLoadPlanner materialzie whole tensor compare original global_tensor state_dict_to_load dtensor = state_dict_to_load dtensor redistribute mesh_ d placements= Replicate assertEqual global_tensor state_dict_to_load dtensor to_local with_comms with_temp_dir skip_if_lt_x_gpu test_dtensor_checkpoint_resharding_with_empty_shard Test dtensor checkpoint resharding dtensor containing empty shards importlib util find_spec safetensors None print safetensors installed tensor = torch rand device_type mesh = init_device_mesh device_type world_size dtensor = distribute_tensor tensor mesh Shard ref_state_dict = dtensor dtensor dist_cp save state_dict=ref_state_dict storage_writer=dist_cp HuggingFaceStorageWriter path=self temp_dir save_distributed=True tensor = torch rand device_type mesh_ = init_device_mesh device_type world_size dtensor = distribute_tensor tensor mesh_ Shard Shard state_dict = dtensor dtensor dist_cp load state_dict=state_dict storage_reader=dist_cp HuggingFaceStorageReader temp_dir __name__ == __main__ run_tests