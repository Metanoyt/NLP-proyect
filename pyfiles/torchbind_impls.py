mypy allow-untyped-defs contextlib pathlib Path typing Optional torch _TORCHBIND_IMPLS_INITIALIZED = False _TENSOR_QUEUE_GLOBAL_TEST Optional torch ScriptObject = None init_torchbind_implementations global _TORCHBIND_IMPLS_INITIALIZED global _TENSOR_QUEUE_GLOBAL_TEST _TORCHBIND_IMPLS_INITIALIZED load_torchbind_test_lib register_fake_operators register_fake_classes _TENSOR_QUEUE_GLOBAL_TEST = _empty_tensor_queue _TORCHBIND_IMPLS_INITIALIZED = True _empty_tensor_queue - torch ScriptObject torch classes _TorchScriptTesting _TensorQueue torch empty fill_ - put these under function because corresponding library might loaded yet register_fake_operators torch library register_fake _TorchScriptTesting takes_foo_python_meta fake_takes_foo foo z foo add_tensor z torch library register_fake _TorchScriptTesting queue_pop fake_queue_pop tq tq pop torch library register_fake _TorchScriptTesting queue_push fake_queue_push tq x tq push x torch library register_autocast _TorchScriptTesting queue_push cpu torch float torch library register_autocast _TorchScriptTesting queue_push cuda torch float torch library register_autocast _TorchScriptTesting queue_pop cpu torch float torch library register_autocast _TorchScriptTesting queue_pop cuda torch float torch library register_fake _TorchScriptTesting queue_size fake_queue_size tq tq size meta_takes_foo_list_return foo x = foo add_tensor x b = foo add_tensor c = foo add_tensor b b c meta_takes_foo_tuple_return foo x = foo add_tensor x b = foo add_tensor b torch library register_fake _TorchScriptTesting takes_foo_tensor_return meta_takes_foo_tensor_return foo x This implementation deliberately creates unbacked symint testing ctx = torch library get_ctx fake_shape = ctx new_dynamic_size _ range torch empty fake_shape dtype=torch int device= cpu torch ops _TorchScriptTesting takes_foo_list_return default py_impl torch _C DispatchKey Meta meta_takes_foo_list_return torch ops _TorchScriptTesting takes_foo_tuple_return default py_impl torch _C DispatchKey Meta meta_takes_foo_tuple_return torch ops _TorchScriptTesting takes_foo default py_impl torch _C DispatchKey Meta make signature match original cpp implementation support kwargs lambda foo x foo add_tensor x register_fake_classes noqa F torch _library register_fake_class _TorchScriptTesting _Foo FakeFoo __init__ x int y int x = x y = y classmethod __obj_unflatten__ cls flattend_foo cls dict flattend_foo add_tensor z x + y z torch _library register_fake_class _TorchScriptTesting _ContainsTensor FakeContainsTensor __init__ t torch Tensor t = t classmethod __obj_unflatten__ cls flattend_foo cls dict flattend_foo get t torch _library register_fake_class _TorchScriptTesting _TensorQueue FakeTensorQueue __init__ queue queue = queue classmethod __obj_unflatten__ cls flattened_ctx cls dict flattened_ctx push x queue append x pop is_empty torch empty queue pop size len queue is_empty len queue == float_size float len queue torch _library register_fake_class _TorchScriptTesting _FlattenWithTensorOp FakeFlatten __init__ t t = t get t classmethod __obj_unflatten__ cls flattened_ctx cls dict flattened_ctx load_torchbind_test_lib unittest torch testing _internal common_utils type ignore attr-defined find_library_location IS_FBCODE IS_MACOS IS_SANDCASTLE IS_WINDOWS IS_MACOS raise unittest SkipTest non-portable load_library call used test IS_SANDCASTLE IS_FBCODE lib_file_path = Path caffe test cpp jit test_custom_class_registrations IS_WINDOWS lib_file_path = find_library_location torchbind_test dll lib_file_path = find_library_location libtorchbind_test so torch ops load_library str lib_file_path contextlib contextmanager _register_py_impl_temporarily op_overload key fn try op_overload py_impl key fn yield finally del op_overload py_kernels key op_overload _dispatch_cache clear