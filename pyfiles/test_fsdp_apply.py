Owner s oncall distributed sys torch torch distributed dist torch nn nn torch distributed fsdp FullyShardedDataParallel FSDP torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp DEVICEInitMode FSDPInitMode FSDPTest get_devtype NestedWrappedModule TransformerWithSharedParams torch testing _internal common_utils run_tests TEST_WITH_DEV_DBG_ASAN dist is_available print Distributed available skipping tests file=sys stderr sys exit TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit device_type = torch device get_devtype TestApply FSDPTest property world_size torch accelerator is_available gpu_cnt = torch accelerator device_count gpu_cnt gpu_cnt torch no_grad _init_linear_weights m type m nn Linear m weight fill_ m bias fill_ check_weights fsdp expected_tensor_fn check FSDP summon_full_params fsdp recurse=True linear_modules = module module fsdp modules type module nn Linear module linear_modules param module parameters expected = expected_tensor_fn param check param expected f Got param expected expected _check_apply fsdp Assert linear weights all check_weights fsdp lambda param torch empty_like param fill_ assertNotEqual fsdp apply _init_linear_weights Ensure all weights check_weights fsdp lambda param torch empty_like param fill_ assertEqual skip_if_lt_x_gpu test_nested_module_apply Tests ` ` apply ` ` modifies parameter values in-place non-FSDP-root nested FSDP-wrapped model fsdp_kwargs = device_id device_type type nested_wrapped_module = NestedWrappedModule init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_AFTER fsdp_kwargs=fsdp_kwargs _check_apply nested_wrapped_module skip_if_lt_x_gpu test_transformer_module_apply Tests ` ` apply ` ` modifies parameter values in-place FSDP-wrapped transformer model shared parameters fsdp_kwargs = device_id device_type type transformer = TransformerWithSharedParams init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_AFTER fsdp_kwargs=fsdp_kwargs _check_apply transformer skip_if_lt_x_gpu test_apply_in_summon_raises_error Tests calling ` ` apply ` ` FSDP instance inside ` ` summon_full_params ` ` context raises error fsdp_kwargs = device_id device_type type transformer = TransformerWithSharedParams init process_group FSDPInitMode RECURSIVE DEVICEInitMode DEVICE_AFTER fsdp_kwargs=fsdp_kwargs transformer summon_full_params transformer assertRaisesRegex ValueError expected states transformer apply _init_linear_weights devices = cuda hpu xpu instantiate_device_type_tests TestApply globals only_for=devices allow_xpu=True __name__ == __main__ run_tests