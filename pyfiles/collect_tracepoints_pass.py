mypy allow-untyped-defs __future__ annotations operator typing TYPE_CHECKING torch torch export exported_program ConstantArgument TensorArgument torch fx passes infra pass_base PassBase PassResult TYPE_CHECKING torch export exported_program ModuleCallSignature torch export graph_signature ExportGraphSignature __all__ = CollectTracepointsPass CollectTracepointsPass PassBase Performs constant folding constant propagation __init__ specs dict str ModuleCallSignature sig ExportGraphSignature - None super __init__ specs = specs sig = sig call gm torch fx GraphModule - PassResult &#124; None get_arg_spec arg - TensorArgument &#124; ConstantArgument isinstance arg torch fx Node isinstance arg meta get val torch Tensor TensorArgument name=arg name raise AssertionError Symint input implemented yet submodule call signature ConstantArgument name= value=arg module gm modules isinstance module torch fx GraphModule continue nn_module_stack = None node module graph nodes node op = call_function continue node target torch ops higher_order _export_tracepoint kind = node kwargs kind kind == module_call_outputs nn_module_stack = node meta nn_module_stack kind == module_call_inputs nn_module_stack = None raise AssertionError f Unknown tracepoint kind kind node meta nn_module_stack == nn_module_stack node meta nn_module_stack popitem nn_module_stack = None nn_module_stack = None node reversed module graph nodes node op = call_function continue node target torch ops higher_order _export_tracepoint kind = node kwargs kind kind == module_call_inputs nn_module_stack = node meta nn_module_stack kind == module_call_outputs nn_module_stack = None raise AssertionError f Unknown tracepoint kind kind node meta nn_module_stack == nn_module_stack node meta nn_module_stack popitem nn_module_stack = None copy_sig sig - ModuleCallSignature torch export exported_program ModuleCallSignature ModuleCallSignature inputs= outputs= in_spec=sig in_spec out_spec=sig out_spec forward_arg_names=None module gm modules isinstance module torch fx GraphModule continue node module graph nodes node op = call_function continue node target torch ops higher_order _export_tracepoint There s some subtlety worth noting Here fqn corresponds call name whereas path corresponds module name They necessarily same When submodule shared through different aliases there many _export_tracepoint markers there aliases since shared submodule wrapped once each alias path = node kwargs path fqn _ = next reversed node meta nn_module_stack values module_key = next reversed node meta nn_module_stack module_key suffix = module_key split - path = f path suffix call_fqn = f fqn suffix call_fqn specs specs call_fqn = copy_sig specs fqn fqn = call_fqn kind = node kwargs kind i arg enumerate node args We only update signature alias used call submodule Otherwise signatures all aliases would get conflated inputs outputs every call would recorded every other call well fqn == path kind == module_call_inputs specs path inputs append get_arg_spec arg kind == module_call_outputs specs path outputs append get_arg_spec arg raise AssertionError f Unknown tracepoint kind kind isinstance arg torch fx Node user node users assert user op == call_function assert user target operator getitem assert isinstance user args int user args == i user replace_all_uses_with arg sig replace_all_uses user name arg name break users = list node users user users assert len user users == gm graph erase_node user gm graph erase_node node PassResult gm True None