mypy allow-untyped-defs logging weakref typing TYPE_CHECKING torch torch autograd graph register_multi_grad_hook torch nn modules module register_module_forward_hook register_module_forward_pre_hook torch utils _pytree tree_flatten TYPE_CHECKING torch utils hooks RemovableHandle logger = logging getLogger __name__ __all__ = ModuleTracker ModuleTracker ` ` ModuleTracker ` ` context manager tracks nn Module hierarchy during execution so other system can query which Module currently being executed its backward being executed You can access ` ` parents ` ` attribute context manager get set all Modules currently being executed via their fqn fully qualified name also used key within state_dict You can access ` ` is_bw ` ` attribute know you currently running backward Note ` ` parents ` ` never empty always contains Global key The ` ` is_bw ` ` flag will remain ` ` True ` ` after forward until another Module executed If you need more accurate please submit issue requesting Adding map fqn module instance possible done yet please submit issue requesting you need Example usage code-block python mod = torch nn Linear ModuleTracker tracker Access anything during forward pass my_linear m m bias print f Current modules tracker parents torch mm m m t + bias torch nn functional linear = my_linear mod torch rand parents set str A Set containing fqn each module currently running their forward __init__ - None parents = Global _known_modules weakref WeakKeyDictionary = weakref WeakKeyDictionary _seen_modules weakref WeakSet = weakref WeakSet _has_callback = False _hooks list RemovableHandle = _maybe_set_engine_callback This assumes no concurrent calls backward _has_callback callback parents = Global _has_callback = False torch autograd Variable _execution_engine queue_callback callback _has_callback = True property is_bw A boolean marking currently running during backward pass torch _C _current_graph_task_id = - _get_mod_name mod mod _known_modules _known_modules mod = type mod __name__ mod_name = _known_modules mod mod _seen_modules name submod mod named_children _known_modules submod = f mod_name name _get_mod_name submod _seen_modules add mod mod_name _get_append_fn name is_bw fn args is_bw _maybe_set_engine_callback name parents logger info The module hierarchy tracking seems broken Module already entered s during s name backward is_bw forward parents add name fn _get_pop_fn name is_bw fn args name parents parents remove name logger info The Module hierarchy tracking confused we re exiting Module never entered s during s name backward is_bw forward fn _fw_pre_hook mod input name = _get_mod_name mod _get_append_fn name False args _ = tree_flatten input tensors = args isinstance torch Tensor requires_grad tensors _hooks append register_multi_grad_hook tensors _get_pop_fn name True _fw_post_hook mod input output name = _get_mod_name mod _get_pop_fn name False args _ = tree_flatten output tensors = args isinstance torch Tensor requires_grad tensors _hooks append register_multi_grad_hook tensors _get_append_fn name True __enter__ _fw_pre_handle = register_module_forward_pre_hook _fw_pre_hook _fw_post_handle = register_module_forward_hook _fw_post_hook __exit__ args _fw_pre_handle remove _fw_post_handle remove hook _hooks hook remove _hooks clear