Copyright c Meta Platforms Inc affiliates Owner s oncall distributed copy itertools pprint pformat typing NamedTuple torch torch distributed dist torch distributed device_mesh init_device_mesh torch distributed tensor DeviceMesh distribute_module distribute_tensor DTensor Partial Replicate Shard torch distributed tensor _ops utils is_tensor_partial normalize_dim torch distributed tensor debug CommDebugMode torch distributed tensor parallel ColwiseParallel parallelize_module RowwiseParallel SequenceParallel torch testing _internal common_utils run_tests torch testing _internal distributed _tensor common_dtensor create_local_tensor_test_class DTensorTestBase map_local_for_rank skip_unless_torch_gpu with_comms funcol = torch ops c d_functional DistMathOpsTest DTensorTestBase _check_module m m check_grad=False named_parameters = dict m named_parameters name param_m m named_parameters assertTrue name named_parameters param_m = named_parameters name check_grad param_m = param_m grad param_m = param_m grad isinstance param_m DTensor replicate = Replicate param_m = param_m redistribute device_mesh=param_m device_mesh placements=replicate to_local assertEqual param_m param_m linear_op_reductions op_str device_mesh = build_device_mesh shard_spec = Shard tensor = torch randn op_str any all Test bool tensor any all reduction ops Previously all had bug using sum reduction instead product tensor = tensor dtensor = distribute_tensor tensor device_mesh shard_spec op = getattr tensor op_str op_dt = getattr dtensor op_str keep_dim_or_not = True False None dim range tensor ndim keep_dim keep_dim_or_not args = dim keep_dim keep_dim None dim op_str max min min max tuple when dim specified dim_reduced_tensor _ = op args dt_reduced _ = op_dt args dim_reduced_tensor = op args dt_reduced = op_dt args dt_dim_reduced_tensor = dt_reduced full_tensor assertEqual dt_dim_reduced_tensor dim_reduced_tensor full_reduced_tensor = op dt_full_reduced = op_dt full_tensor assertEqual dt_full_reduced full_reduced_tensor with_comms test_linear_op_reductions op_str all sum prod max min any amax amin linear_op_reductions op_str with_comms skip_unless_torch_gpu test_mean linear_op_reductions mean TODO forward test can removed once test_softmax_with_bwd passes CPU with_comms test_softmax_fwd device_mesh = build_device_mesh x = torch rand device=self device_type dims = range used convert - actual dim softmax_dims = - shard_dims = - test_list = list itertools product softmax_dims shard_dims softmax_dim shard_dim test_list local_y = torch nn functional softmax x dim=softmax_dim dtype=torch float dist_x = distribute_tensor x device_mesh Shard shard_dim dist_y = torch nn functional softmax dist_x dim=softmax_dim dtype=torch float shard_dim = normalize_dim shard_dim dist_x ndim dims shard_dim == dims softmax_dim assertTrue dist_y placements is_replicate assertEqual dist_y to_local local_y assertTrue dist_y placements is_shard dim=shard_dim assertEqual dist_y full_tensor local_y TODO get test_softmax_with_bwd pass CPU DTensor s _softmax_backward_data produces wrong result CPU certain dimension fail_on_cpu_list = - - with_comms skip_unless_torch_gpu test_softmax_with_bwd device_mesh = build_device_mesh dims = range used convert - actual dim softmax_dims = - shard_dims = - test_list = list itertools product softmax_dims shard_dims params test_list softmax_dim shard_dim = params x = torch rand device=self device_type requires_grad=True assertTrue x requires_grad local_y = torch nn functional softmax x dim=softmax_dim dtype=torch float sum local_y backward dist_x = distribute_tensor x device_mesh Shard shard_dim assertTrue dist_x requires_grad dist_softmax = dist_x softmax dim=softmax_dim shard_dim = normalize_dim shard_dim dist_x ndim dims softmax_dim == dims shard_dim assertTrue dist_softmax placements is_replicate assertTrue dist_softmax placements is_shard dim=shard_dim dist_y = dist_softmax sum dims softmax_dim == dims shard_dim assertTrue dist_y placements is_replicate assertTrue dist_y placements is_partial dist_y = dist_y redistribute device_mesh Replicate assertEqual dist_y to_local local_y assertIsNone dist_x grad dist_y backward assertIsNotNone dist_x grad dims softmax_dim == dims shard_dim assertTrue dist_x grad placements is_replicate assertTrue dist_x grad placements is_shard dim=shard_dim assertEqual dist_x grad full_tensor x grad with_comms skip_unless_torch_gpu test_nll_loss_and_cross_entropy device_mesh = build_device_mesh comm_mode = CommDebugMode channel_size channel_dim = test_setup = channel_size calling aten nll_loss_forward channel_size calling aten nll_loss d_forward input_ndim input_size target_size test_setup x = torch rand input_size device=self device_type requires_grad=True target = torch randint channel_size target_size device=self device_type dist_target = distribute_tensor target device_mesh Replicate shard_dims = list range input_ndim reductions = none mean sum Compared nll_loss cross_entropy additionally calls log_softmax first Testing them together code can reused loss_functions = torch nn functional nll_loss torch nn functional cross_entropy shard_dim reduction loss_fn itertools product shard_dims reductions loss_functions dist_x = distribute_tensor x device_mesh Shard shard_dim y = loss_fn x target reduction=reduction reduction == none y sum backward y backward comm_mode dist_y = loss_fn dist_x dist_target reduction=reduction shard_dim == channel_dim assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor assertTrue dist_y placements is_replicate assertEqual dist_y to_local y assertEqual comm_mode get_total_counts reduction == none output_shard_dim = shard_dim shard_dim channel_dim shard_dim - assertTrue dist_y placements is_shard dim=output_shard_dim assertTrue dist_y placements is_partial assertEqual dist_y full_tensor y reduction == none dist_y sum backward dist_y backward shard_dim == channel_dim assertTrue dist_x grad placements is_replicate assertEqual dist_x grad to_local x grad assertTrue dist_x grad placements is_shard dim=shard_dim assertEqual dist_x grad full_tensor x grad x grad zero_ with_comms test_shard_math_ops mesh_shape = world_size mesh = DeviceMesh device_type torch arange world_size reshape mesh_shape global_tensor = torch ones double_shard_tensor = distribute_tensor global_tensor mesh Shard Shard fully_shard_tensor = distribute_tensor global_tensor mesh Shard Shard op torch add torch sub torch mul torch div op torch add torch sub torch mul torch div expect_rs = op global_tensor double_shard_full_tensor = op double_shard_tensor full_tensor assertEqual double_shard_full_tensor expect_rs fully_shard_full_tensor = op fully_shard_tensor full_tensor assertEqual fully_shard_full_tensor expect_rs with_comms test_layer_norm_fwd device_mesh = build_device_mesh NLP example pytorch docs https pytorch org docs stable generated torch nn LayerNorm html batch sentence_length embedding_dim = x = torch rand batch sentence_length embedding_dim device=self device_type norm_shape_idx_list = list range x ndim shard_dims = - elementwise_affine_list = False True Test RMSNorm well CUDA norm_types = torch nn LayerNorm device_type == cuda hasattr torch nn RMSNorm norm_types append torch nn RMSNorm test_config_list = list itertools product norm_types shard_dims norm_shape_idx_list elementwise_affine_list normalized shape torch Size object norm_type shard_dim norm_idx elementwise_affine test_config_list normalized_shape = x shape norm_idx layer_norm = norm_type normalized_shape elementwise_affine=elementwise_affine device=self device_type layer_norm_local = copy deepcopy layer_norm device_type _replicate_fn name module device_mesh name param module named_parameters RMSNorm only has weight LayerNorm has both weight bias name weight bias param_dist = torch nn Parameter distribute_tensor param device_mesh Replicate module register_parameter name param_dist layer_norm_dist = distribute_module layer_norm device_mesh _replicate_fn x_local = x x_dist = distribute_tensor x device_mesh Shard shard_dim y_local = layer_norm_local x_local make sure forward layer norm does introduce extra collectives comm_mode = CommDebugMode comm_mode y_dist = layer_norm_dist x_dist assertLessEqual comm_mode get_total_counts TODO This should f comm count= comm_mode get_total_counts norm_type= norm_type __name__ f shard_dim= shard_dim norm_shape= normalized_shape elem_affine= elementwise_affine torch distributed tensor _dtensor_spec TensorMeta dtensor_meta = y_dist _spec tensor_meta assert isinstance dtensor_meta TensorMeta make sure right shape sharding prop assertEqual y_local shape dtensor_meta shape assertEqual y_local y_dist full_tensor with_comms test_layer_norm_bwd device_mesh = build_device_mesh NLP example pytorch docs https pytorch org docs stable generated torch nn LayerNorm html batch sentence_length embedding_dim = norm_shape_idx_list = list range shard_dims = elementwise_affine_list = False True Test both LayerNorm RMSNorm CUDA norm_types = torch nn LayerNorm device_type == cuda hasattr torch nn RMSNorm norm_types append torch nn RMSNorm test_config_list = list itertools product norm_types shard_dims norm_shape_idx_list elementwise_affine_list normalized shape torch Size object norm_type shard_dim norm_idx elementwise_affine test_config_list x = torch rand batch sentence_length embedding_dim device=self device_type requires_grad=True normalized_shape = x shape norm_idx layer_norm = norm_type normalized_shape elementwise_affine=elementwise_affine device=self device_type layer_norm_local = copy deepcopy layer_norm device_type _replicate_fn name module device_mesh name param module named_parameters name weight bias param_dist = torch nn Parameter distribute_tensor param device_mesh Replicate module register_parameter name param_dist layer_norm_dist = distribute_module layer_norm device_mesh _replicate_fn elementwise_affine assertEqual layer_norm_local weight layer_norm_dist weight full_tensor RMSNorm doesn t have bias hasattr layer_norm_local bias assertEqual layer_norm_local bias layer_norm_dist bias full_tensor x_local = x detach clone requires_grad_ True x_dist = distribute_tensor x device_mesh Shard shard_dim assertEqual x_local x_dist full_tensor y_local = layer_norm_local x_local make sure backward layer norm does introduce extra collectives comm_mode = CommDebugMode comm_mode y_dist = layer_norm_dist x_dist y_dist sum backward expected_fwd_comm = shard_dim norm_idx assertEqual sum comm_mode comm_module_counts Global forward values expected_fwd_comm f comm count= comm_mode get_total_counts norm_type= norm_type __name__ f shard_dim= shard_dim norm_shape= normalized_shape elem_affine= elementwise_affine assertEqual y_local y_dist full_tensor backward step y_local sum backward expected_bwd_comm = shard_dim norm_idx assertEqual sum comm_mode comm_module_counts Global backward values expected_bwd_comm f comm count= comm_mode get_total_counts norm_type= norm_type __name__ f shard_dim= shard_dim norm_shape= normalized_shape elem_affine= elementwise_affine elementwise_affine input sharded any outer dimension gradient weight bias should Partial dim_map = x_dist _spec dim_map outer_dims = range norm_idx needs_reduction = any dim_map d = d outer_dims assertEqual is_tensor_partial layer_norm_dist weight grad _spec needs_reduction RMSNorm doesn t have bias hasattr layer_norm_dist bias assertEqual is_tensor_partial layer_norm_dist bias grad _spec needs_reduction assertEqual layer_norm_local weight grad layer_norm_dist weight grad full_tensor RMSNorm doesn t have bias hasattr layer_norm_local bias assertEqual layer_norm_local bias grad layer_norm_dist bias grad full_tensor assertEqual x_local grad x_dist grad full_tensor with_comms test_layer_norm_bwd_req_grad device_mesh = build_device_mesh batch seq_len embedding_dim vocab_size = Test both LayerNorm RMSNorm CUDA norm_types = torch nn LayerNorm device_type == cuda hasattr torch nn RMSNorm norm_types append torch nn RMSNorm build our subtest configurations filter out invalid ones SubTest NamedTuple norm_type type multidim_norm bool elementwise_affine bool emb_req_grad bool ln_req_grad bool out_req_grad bool subtest_fails = valid_filter cfg cfg ln_req_grad cfg elementwise_affine any cfg subtest_cfgs = list filter valid_filter SubTest norm_type cfg norm_type norm_types cfg itertools product False True subtest_cfg subtest_cfgs try norm_type multidim_norm elementwise_affine emb_req_grad ln_req_grad out_req_grad = subtest_cfg normalized_shape = seq_len embedding_dim multidim_norm embedding_dim configure our local parallelized models subtest LnTpBlock torch nn Module __init__ super __init__ preln_embeddings = torch nn Embedding vocab_size embedding_dim layer_norm = norm_type normalized_shape elementwise_affine=elementwise_affine postln_linear = torch nn Linear embedding_dim embedding_dim forward tokens h = preln_embeddings tokens h = layer_norm h output = postln_linear h output parallel_plan = preln_embeddings RowwiseParallel input_layouts=Replicate output_layouts=Shard layer_norm SequenceParallel postln_linear ColwiseParallel input_layouts=Shard output_layouts=Replicate model = LnTpBlock model_local = copy deepcopy model device=self device_type model_dist = parallelize_module model device_mesh parallel_plan req_grad_map = preln_embeddings emb_req_grad postln_linear out_req_grad layer_norm ln_req_grad apply relevant ` requires_grad ` mask subtest both models target_model model_local model_dist n p target_model named_parameters req_grad_map get n rpartition False p requires_grad_ False assert p requires_grad assert p requires_grad forward step both local distributed models x = torch randint vocab_size batch seq_len device=self device_type x_local = x detach clone output_local = model_local x_local CommDebugMode comm_mode output_dist = model_dist x assertEqual output_local output_dist all requires_grad patterns should have same forward comm counts expected_fwd_comm = funcol reduce_scatter_tensor funcol all_gather_into_tensor assertDictEqual comm_mode comm_module_counts Global forward expected_fwd_comm backward step output_local sum backward CommDebugMode comm_mode output_dist sum backward ensure gradients parameters remain equal between local distributed models _check_module model_local model_dist check_grad=True different requires_grad patterns will have different bwd comm counts out_req_grad any emb_req_grad ln_req_grad expected_bwd_comm = ln_req_grad any emb_req_grad multidim_norm expected_bwd_comm = funcol reduce_scatter_tensor multidim_norm expected_bwd_comm = funcol all_reduce expected_bwd_comm funcol all_gather_into_tensor = emb_req_grad expected_bwd_comm = funcol reduce_scatter_tensor funcol all_gather_into_tensor assertDictEqual comm_mode comm_module_counts Global backward expected_bwd_comm assertEqual output_local output_dist except Exception e subtest_fails subtest_cfg = e any subtest fails provide failed subtests report overall failure assert subtest_fails f len subtest_fails len subtest_cfgs subtests failed pformat subtest_fails with_comms test_topk device_mesh = build_device_mesh placement_combs = Shard Shard Shard Replicate comm_mode = CommDebugMode tensor = torch randn requires_grad=True global_topk = tensor topk dim= placement placement_combs dtensor = distribute_tensor tensor device_mesh placement comm_mode out_dt = dtensor topk dim= placement is_shard assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor out_full_values = out_dt values full_tensor assertEqual global_topk values out_full_values TODO support backward scatter global_topk values sum backward out_full_values sum backward with_comms test_shard _svd device_mesh = build_device_mesh torch manual_seed replicated_x = torch randn device=self device_type sharded_x = distribute_tensor replicated_x device_mesh Shard CommDebugMode comm_mode U S V = torch linalg svd sharded_x full_matrices=False ref_U ref_S ref_V = torch linalg svd replicated_x full_matrices=False assertEqual U to_local ref_U assertEqual S to_local ref_S assertEqual V to_local ref_V comm_counts = comm_mode get_comm_counts assertEqual len comm_counts assertEqual comm_counts funcol all_gather_into_tensor with_comms test_vector_norm device_mesh = build_device_mesh grad = torch randn sharded_grad = distribute_tensor grad device_mesh Shard non-sharded op out = torch ops aten linalg_vector_norm grad sharded op sharded_out = torch ops aten linalg_vector_norm sharded_grad assertEqual sharded_out full_tensor out with_comms test_vector_norm_partial device_mesh = build_device_mesh all_ranks = list range world_size local_grad = map_local_for_rank rank lambda rank torch tensor rank dtype=torch float full_grad = torch tensor sum all_ranks world_size dtype=torch float partial_grad = DTensor from_local local_grad device_mesh Partial full result out = torch ops aten linalg_vector_norm full_grad partial result partial_out = torch ops aten linalg_vector_norm partial_grad assertEqual partial_out full_tensor out with_comms test_foreach_norm device_mesh = build_device_mesh grad = torch randn grad = torch randn sharded_grad = distribute_tensor grad device_mesh Shard sharded_grad = distribute_tensor grad device_mesh Shard non-sharded op out = torch ops aten _foreach_norm grad grad sharded op sharded_out = torch ops aten _foreach_norm sharded_grad sharded_grad o so zip out sharded_out assertEqual so full_tensor o with_comms test_foreach_norm_partial device_mesh = build_device_mesh all_ranks = list range world_size local_grad = map_local_for_rank rank lambda rank torch tensor rank dtype=torch float local_grad = map_local_for_rank rank lambda rank torch tensor rank + dtype=torch float grad = torch tensor sum all_ranks world_size dtype=torch float grad = torch tensor sum all_ranks + world_size world_size dtype=torch float partial_grad = DTensor from_local local_grad device_mesh Partial partial_grad = DTensor from_local local_grad device_mesh Partial full result out = torch ops aten _foreach_norm grad grad partial result partial_out = torch ops aten _foreach_norm partial_grad partial_grad o po zip out partial_out assertEqual po full_tensor o with_comms test_foreach_norm_different_mesh mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= x y mesh_x = mesh_ d x mesh_y = mesh_ d y torch manual_seed grad = torch randn grad = torch randn replica_grad = DTensor from_local grad mesh_x Replicate replica_grad = DTensor from_local grad mesh_y Replicate could run sharded op without error out_tuple = torch ops aten _foreach_norm replica_grad replica_grad grad _norm = out_tuple grad _norm = out_tuple assertEqual grad _norm device_mesh mesh_x assertEqual grad _norm device_mesh mesh_y with_comms test_foreach_add_different_mesh mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= x y mesh_x = mesh_ d x mesh_y = mesh_ d y inp = torch ones inp = torch ones inp = torch ones inp = torch ones replica_inp = DTensor from_local inp mesh_x Shard replica_inp = DTensor from_local inp mesh_x Replicate replica_inp = DTensor from_local inp mesh_y Shard replica_inp = DTensor from_local inp mesh_y Replicate zipped foreach could run sharded op without error out_tuple = torch ops aten _foreach_add replica_inp replica_inp replica_inp replica_inp out out = out_tuple assertEqual out device_mesh mesh_x assertEqual out device_mesh mesh_y assertRaisesRegex RuntimeError Sharding propagation failed torch ops aten _foreach_add replica_inp replica_inp replica_inp replica_inp with_comms test_linalg_eigh A = torch randn dtype=torch float mesh = build_device_mesh dtensor_A = distribute_tensor A device_mesh=mesh placements= Replicate dtensor_A = dtensor_A + dtensor_A mT dtensor_L dtensor_Q = torch linalg eigh dtensor_A TODO we need convert A L Q local because we don t have sharding strategy registered aten dist default yet local_A local_L local_Q = dtensor_A to_local dtensor_L to_local dtensor_Q to_local distance = torch dist local_Q torch diag local_L local_Q mT local_A assertEqual distance item with_comms test_upsampling input = torch arange dtype=torch float view mesh = build_device_mesh input_dtensor = distribute_tensor input device_mesh=mesh placements= Shard upsample_m = torch nn UpsamplingBilinear d scale_factor= torch nn UpsamplingNearest d scale_factor= torch nn Upsample scale_factor= mode= bicubic m upsample_m result = m input dtensor_result = m input_dtensor assertEqual result dtensor_result full_tensor with_comms test_cumsum mesh = build_device_mesh comm_mode = CommDebugMode inp = torch rand device=self device_type shard_dim = input_dtensor = distribute_tensor inp device_mesh=mesh placements= Shard shard_dim cumsum_dims = dim cumsum_dims output = torch cumsum inp dim=dim comm_mode output_dtensor = torch cumsum input_dtensor dim=dim dim == shard_dim assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor assertTrue output_dtensor placements is_replicate assertEqual comm_mode get_total_counts assertTrue output_dtensor placements is_shard shard_dim assertEqual output_dtensor full_tensor output with_comms test_conj_complex_dtensor mesh = build_device_mesh comm_mode = CommDebugMode freqs_cis = torch randn dtype=torch complex requires_grad=False device=self device_type freqs_cis_dt = distribute_tensor freqs_cis device_mesh=mesh placements= Replicate local_result = freqs_cis conj + comm_mode dtensor_result = freqs_cis_dt conj + assertEqual comm_mode get_total_counts assertEqual local_result dtensor_result full_tensor with_comms test_rotary_embedding_complex_ops mesh = build_device_mesh comm_mode = CommDebugMode apply_rotary_emb xq freqs_cis xq_ = torch view_as_complex xq xq_out = torch view_as_real xq_ freqs_cis xq_out xq = torch randn requires_grad=True device=self device_type freqs_cis = torch randn dtype=torch complex requires_grad=False device=self device_type xq_dt = distribute_tensor xq device_mesh=mesh placements= Replicate freqs_cis_dt = distribute_tensor freqs_cis device_mesh=mesh placements= Replicate comm_mode xq_out_dt = apply_rotary_emb xq_dt freqs_cis_dt xq_out_dt sum backward assertEqual comm_mode get_total_counts dtensor_grad = xq_dt grad full_tensor xq grad = None xq_out = apply_rotary_emb xq freqs_cis xq_out sum backward assertEqual dtensor_grad xq grad with_comms test_histc TODO - nicer use parametrize here so its easy run one sub-test name its too slow sec per process-group init - switch MultiProcessContinuousTest device_mesh = build_device_mesh comm_mode = CommDebugMode tensor = torch randn requires_grad=True min_max_specified True False placement Shard Shard Shard Replicate min_ = tensor min item max_ = tensor max item global_bins = tensor histc min=min_ max=max_ min_max_specified tensor histc dtensor = distribute_tensor tensor device_mesh placement comm_mode out_dt = dtensor histc min=min_ max=max_ min_max_specified dtensor histc placement is_shard min_max_specified assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor assertEqual comm_mode get_total_counts out_full = out_dt full_tensor assertEqual global_bins out_full with_comms test_logsumexp mesh = build_device_mesh comm_mode = CommDebugMode inp = torch rand device=self device_type shard_dim = input_dtensor = distribute_tensor inp device_mesh=mesh placements= Shard shard_dim logsumexp_dims = dim logsumexp_dims output = torch logsumexp inp dim=dim comm_mode output_dtensor = torch logsumexp input_dtensor dim=dim dim == shard_dim assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor assertTrue output_dtensor placements is_replicate assertEqual comm_mode get_total_counts assertTrue output_dtensor placements is_shard shard_dim assertEqual output_dtensor full_tensor output with_comms test_partial_reduction_ops mesh = build_device_mesh rank = dist get_rank torch manual_seed rank local_tensor = torch rand dtype=torch float device=self device_type dt = DTensor from_local local_tensor device_mesh=mesh placements= Partial sum out_without_redistribute = torch norm dt dt = dt redistribute dt device_mesh placements= Replicate out_with_redistribute = torch norm dt assertEqual out_without_redistribute out_with_redistribute local_tensor = torch rand dtype=torch float device=self device_type dt = DTensor from_local local_tensor device_mesh=mesh placements= Partial sum out_without_redistribute = torch max dt dt = dt redistribute dt device_mesh placements= Replicate out_with_redistribute = torch max dt assertEqual out_without_redistribute out_with_redistribute local_tensor = torch rand dtype=torch float device=self device_type dt = DTensor from_local local_tensor device_mesh=mesh placements= Partial sum out_without_redistribute = torch min dt dt = dt redistribute dt device_mesh placements= Replicate out_with_redistribute = torch min dt assertEqual out_without_redistribute out_with_redistribute with_comms test_matching_partial_reduction_ops mesh = build_device_mesh rank = dist get_rank torch manual_seed rank local_tensor = torch rand dtype=torch float device=self device_type dt = DTensor from_local local_tensor device_mesh=mesh placements= Partial max out_without_redistribute = torch max dt dt = dt redistribute dt device_mesh placements= Replicate out_with_redistribute = torch max dt assertTrue out_without_redistribute placements is_partial assertTrue out_with_redistribute placements is_replicate assertEqual out_without_redistribute out_with_redistribute DistMathOpsTestWithLocalTensor = create_local_tensor_test_class DistMathOpsTest __name__ == __main__ run_tests