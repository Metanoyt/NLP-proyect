mypy allow-untyped-defs operator torch torch ao quantization backend_config BackendConfig BackendPatternConfig DTypeConfig ObservationType weighted_op_quint _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch quint weight_dtype=torch qint bias_dtype=torch float get_linear_configs linear_configs = observation_type = ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT dtype_configs = weighted_op_quint _dtype_config TODO need fix way we insert observers pattern should solved new fusion API reason doesn t work pattern bit complicated we don t have way specify which input pattern we would like observe pattern bias input weight \ &#124; \ &#124; t \ &#124; addmm we want observe weight weight there way convey information current pattern language right now original weight - t \ input - addmm observed no hack weight - t - observer \ input - observer - addmm target weight - observer - t \ input - observer - addmm root_node_getter node_pattern addmm bias act weight = node_pattern addmm linear_configs append BackendPatternConfig torch ops aten addmm default MatchAllNode MatchAllNode torch ops aten t default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_root_node_getter root_node_getter linear_configs append BackendPatternConfig torch ops aten addmm default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias linear decomposed ` t - mm ` bias present linear_configs append BackendPatternConfig torch ops aten mm default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight linear_configs get_conv_configs conv_configs = observation_type = ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT dtype_configs = weighted_op_quint _dtype_config conv_configs append BackendPatternConfig torch ops aten convolution default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias conv_configs append BackendPatternConfig torch ops aten convolution default torch ops aten relu default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias TODO remove when functionalization supported PT mode conv_configs append BackendPatternConfig torch ops aten convolution default torch ops aten relu_ default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias conv_configs get_pooling_configs backend_pattern_configs = observation_type = ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT dtype_configs = weighted_op_quint _dtype_config root_node_getter node_pattern _getitem maxpool _index = node_pattern maxpool backend_pattern_configs append BackendPatternConfig _set_pattern_complex_format operator getitem torch ops aten max_pool d_with_indices default set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_root_node_getter root_node_getter backend_pattern_configs get_relu_configs backend_pattern_configs = observation_type = ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT dtype_configs = weighted_op_quint _dtype_config backend_pattern_configs append BackendPatternConfig torch ops aten relu default set_observation_type observation_type noqa E set_dtype_configs dtype_configs backend_pattern_configs get_binary_op_configs binary_op_configs list BackendPatternConfig = dtype_configs = weighted_op_quint _dtype_config num_tensor_args_to_observation_type_mapping = TODO used right now since we have extra check prepare will need change NO_OBSERVER later after we implemented Tensor dtype inference properly ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT op_with_quantized_bop_scalar_variant torch ops aten add Tensor torch ops aten add_ Tensor bop_patterns = op_with_quantized_bop_scalar_variant torch ops aten relu default op_with_quantized_bop_scalar_variant TODO remove when functionalization supported pt _mode op_with_quantized_bop_scalar_variant torch ops aten relu_ default binary_op_configs extend BackendPatternConfig bop_pattern set_dtype_configs dtype_configs noqa E _set_num_tensor_args_to_observation_type num_tensor_args_to_observation_type_mapping bop_pattern bop_patterns binary_op_configs get_qnnpack_pt e_backend_config BackendConfig qnnpack_pytorch_ _export set_backend_pattern_configs get_linear_configs set_backend_pattern_configs get_binary_op_configs set_backend_pattern_configs get_conv_configs set_backend_pattern_configs get_pooling_configs set_backend_pattern_configs get_relu_configs