Owner s module mps importlib os sys numpy np torch torch testing FileCheck make_tensor torch testing _internal common_dtype get_all_dtypes torch testing _internal common_utils instantiate_parametrized_tests MACOS_VERSION parametrize MPS_UNSUPPORTED_TYPES = torch double torch cdouble + torch bfloat MACOS_VERSION MPS_DTYPES = t t get_all_dtypes t MPS_UNSUPPORTED_TYPES importlib import_module filelock pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir inductor test_torchinductor manual=fbcode caffe test inductor test_inductor-library check_model_gpu CommonTemplate TestCase TODO Remove file This tests basic MPS compile functionality instantiate_parametrized_tests MPSBasicTests TestCase is_dtype_supported = CommonTemplate is_dtype_supported common = check_model_gpu device = mps parametrize dtype MPS_DTYPES test_add dtype common lambda b + b make_tensor dtype=dtype device=self device make_tensor dtype=dtype device=self device check_lowp=False test_log common lambda x x log torch rand test_acos common lambda x x acos torch rand test_atanh common lambda x x atanh torch rand test_floor common lambda x x floor torch rand test_sign common lambda x x sign torch rand test_sliced_input common lambda x x sin + x cos torch rand test_where foo x rc = x abs sqrt rc x = - rc common foo torch rand parametrize dtype MPS_DTYPES test_cast dtype common lambda dtype torch rand test_broadcast common torch add torch rand torch rand test_inplace inc_ x x += x common inc_ torch rand test_rms_norm_nograd Regression test https github com pytorch pytorch issues fn x w torch no_grad torch nn functional rms_norm x x shape w common fn torch rand torch ones test_compile_numpy_scalar fn x y x y common fn torch rand np exp test_conv_transpose_channels_last fn x y torch nn functional conv_transpose d x y stride= padding= common fn torch rand memory_format=torch channels_last torch rand test_conv_train Regression test https github com pytorch pytorch issues fn x y torch nn functional conv d x y None common fn torch rand requires_grad=True torch rand check_gradient=True test_cholesky fn x torch linalg cholesky x upper=False torch linalg cholesky x upper=True common fn torch eye check_lowp=False test_reduced_max inductor test do validate max say K half elements can computed common torch max torch rand dtype=torch half check_lowp=False test_linalg_inv fn x torch linalg inv torch linalg cholesky x A = torch diag torch tensor dtype=torch float common fn A check_lowp=False MPSBasicTestsAOTI TestCase check_model m inp dynamic_shapes=None res = m inp ep = torch export export m inp dynamic_shapes=dynamic_shapes path = torch _inductor aoti_compile_and_package ep m = torch _inductor aoti_load_package path res = m inp assert torch allclose res res test_add_mps M torch nn Module forward x y x + y inp = torch ones device= mps torch ones device= mps m = M mps check_model m inp test_fallback_mps M torch nn Module forward x y torch nn functional linear x y inp = torch randn device= mps torch randn device= mps m = M mps check_model m inp test_c M torch nn Module __init__ - None super __init__ forward x torch cat tensors=torch split x dim= dim=- inp = torch randn device= mps m = M mps check_model m inp test_two_const Model torch nn Module __init__ - None super __init__ y = torch ones device= mps z = torch full device= mps forward x x + y + z inp = torch ones device= mps m = Model device= mps check_model m inp test_simple_dynamic Model torch nn Module __init__ - None super __init__ forward x y add_ = x + y torch nn functional relu input=add_ inplace=False x = torch randn device= mps y = torch randn device= mps inp = x y m = Model device= mps dim _x = torch export Dim dim _x min= max= dynamic_shapes = x dim _x y dim _x check_model m inp dynamic_shapes test_dynamic_cat Model torch nn Module __init__ - None super __init__ forward b torch cat b dim= = torch randn device= mps b = torch randn device= mps inp = b m = Model device= mps dim _a = torch export Dim dim _a min= max= dim _b = torch export Dim dim _b min= max= dynamic_shapes = dim _a b dim _b check_model m inp dynamic_shapes test_reuse_kernel Model torch nn Module __init__ - None super __init__ forward x y = torch sin x b = torch mm y c = torch sin b d = torch mm b c d example_inputs = torch randn device= mps torch randn device= mps model = Model ep = torch export export model example_inputs package_path = torch _export aot_compile ep module example_inputs target_str = aoti_torch_mps_get_kernel_function target_count = open os path splitext package_path + cpp cpp src_code = cpp read FileCheck check_count target_str target_count exactly=True run src_code __name__ == __main__ torch _dynamo test_case run_tests torch backends mps is_available run_tests needs= filelock