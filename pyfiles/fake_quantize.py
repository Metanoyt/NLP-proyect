flake noqa F r This file process migration ` torch ao quantization ` kept here compatibility while migration process ongoing If you adding new entry functionality please add ` torch ao quantization fake_quantize py ` while adding statement here torch ao quantization fake_quantize _is_fake_quant_script_module _is_per_channel _is_per_tensor _is_symmetric_quant default_fake_quant default_fixed_qparams_range_ _fake_quant default_fixed_qparams_range_neg _fake_quant default_fused_act_fake_quant default_fused_per_channel_wt_fake_quant default_fused_wt_fake_quant default_histogram_fake_quant default_per_channel_weight_fake_quant default_weight_fake_quant disable_fake_quant disable_observer enable_fake_quant enable_observer FakeQuantize FakeQuantizeBase FixedQParamsFakeQuantize FusedMovingAvgObsFakeQuantize