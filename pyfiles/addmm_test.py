operator_benchmark op_bench torch Microbenchmarks add_ matmul operator Supports both Caffe PyTorch Configs PT add operator addmm_long_configs = op_bench cross_product_configs M= N= K= device= cuda tags= long dtype= torch float torch bfloat torch float addmm_short_configs = op_bench config_list attr_names= M N K attrs= cross_product_configs= device cpu cuda dtype torch float tags= short Mircobenchmark addmm operator AddmmBenchmark op_bench TorchBenchmarkBase init M N K device dtype inputs = input_one torch rand M K device=device requires_grad=self auto_set dtype=dtype mat torch rand M N device=device requires_grad=self auto_set dtype=dtype mat torch rand N K device=device requires_grad=self auto_set dtype=dtype set_module_name addmm forward input_one mat mat torch addmm input_one mat mat op_bench generate_pt_test addmm_long_configs + addmm_long_configs AddmmBenchmark op_bench generate_pt_gradient_test addmm_long_configs + addmm_long_configs AddmmBenchmark Mircobenchmark addbmm operator AddbmmBenchmark op_bench TorchBenchmarkBase init B M N K device dtype inputs = input_one torch rand M N device=device requires_grad=self auto_set dtype=dtype batch torch rand B M K device=device requires_grad=self auto_set dtype=dtype batch torch rand B K N device=device requires_grad=self auto_set dtype=dtype set_module_name addbmm forward input_one batch batch torch addbmm input_one batch batch addbmm_long_configs = op_bench cross_product_configs B= M= N= K= device= cuda dtype= torch float torch bfloat torch float tags= long addbmm_short_configs = op_bench cross_product_configs B= M= N= K= device= cpu cuda dtype= torch float torch bfloat torch float tags= short op_bench generate_pt_test addbmm_long_configs + addbmm_short_configs AddbmmBenchmark op_bench generate_pt_gradient_test addbmm_long_configs + addbmm_short_configs AddbmmBenchmark __name__ == __main__ op_bench benchmark_runner main