mypy allow-untyped-defs Copyright c Meta Platforms Inc affiliates copy csv itertools logging re abc ABC abstractmethod collections Counter defaultdict collections abc Callable enum Enum functools lru_cache typing Any cast NamedTuple Optional Protocol Union torch torch distributed dist torch _dynamo OptimizedModule torch distributed fsdp FSDPModule UnshardHandle torch nn modules loss _Loss torch profiler record_function _utils generate_rank_to_stage_mapping generate_stage_to_rank_mapping microbatch merge_chunks split_args_kwargs_into_chunks TensorChunkSpec stage _PipelineStageBase __all__ = get_schedule_class PipelineScheduleSingle PipelineScheduleMulti Schedule F B ScheduleGPipe ScheduleInterleaved F B ScheduleLoopedBFS ScheduleInterleavedZeroBubble ScheduleZBVZeroBubble ScheduleDualPipeV logger = logging getLogger __name__ _ComputationType Enum TODO whc rename _ActType FORWARD = BACKWARD_INPUT = BACKWARD_WEIGHT = UNSHARD = RESHARD = SEND_F = RECV_F = SEND_B = RECV_B = FULL_BACKWARD = OVERLAP_F_B = __str__ str_map = _ComputationType FORWARD F _ComputationType BACKWARD_INPUT I _ComputationType BACKWARD_WEIGHT W _ComputationType UNSHARD UNSHARD _ComputationType RESHARD RESHARD _ComputationType SEND_F SEND_F _ComputationType RECV_F RECV_F _ComputationType SEND_B SEND_B _ComputationType RECV_B RECV_B _ComputationType FULL_BACKWARD B _ComputationType OVERLAP_F_B OVERLAP_F_B str_map staticmethod from_str action action == F _ComputationType FORWARD action == I _ComputationType BACKWARD_INPUT action == W _ComputationType BACKWARD_WEIGHT action == UNSHARD _ComputationType UNSHARD action == RESHARD _ComputationType RESHARD action == SEND_F _ComputationType SEND_F action == RECV_F _ComputationType RECV_F action == SEND_B _ComputationType SEND_B action == RECV_B _ComputationType RECV_B action == B _ComputationType FULL_BACKWARD action == OVERLAP_F_B _ComputationType OVERLAP_F_B raise RuntimeError f Invalid computation type action FORWARD = _ComputationType FORWARD BACKWARD_INPUT = _ComputationType BACKWARD_INPUT BACKWARD_WEIGHT = _ComputationType BACKWARD_WEIGHT UNSHARD = _ComputationType UNSHARD RESHARD = _ComputationType RESHARD SEND_F = _ComputationType SEND_F RECV_F = _ComputationType RECV_F SEND_B = _ComputationType SEND_B RECV_B = _ComputationType RECV_B FULL_BACKWARD = _ComputationType FULL_BACKWARD OVERLAP_F_B = _ComputationType OVERLAP_F_B Convenience shorthand compute actions only since they used simple schedule format F = FORWARD I = BACKWARD_INPUT W = BACKWARD_WEIGHT B = FULL_BACKWARD Helper parse action string like F into tuple stage_index computation_type microbatch_index _action_regex = re compile r \d+ F &#124; I &#124; B &#124; W &#124; UNSHARD &#124; RESHARD &#124; SEND_F &#124; RECV_F &#124; SEND_B &#124; RECV_B \d _Action NamedTuple stage_index int computation_type _ComputationType microbatch_index Optional int = None sub_actions Optional tuple _Action = None __str__ __repr__ __repr__ sub_actions None Use recursive repr sub_actions sub_action_reprs = repr sub_action sub_action sub_actions f join sub_action_reprs computation_type repr_str = str stage_index repr_str += str computation_type microbatch_index None repr_str += str microbatch_index repr_str property is_compute_op - bool computation_type FORWARD FULL_BACKWARD BACKWARD_INPUT BACKWARD_WEIGHT OVERLAP_F_B staticmethod from_str action_string str Reverse __repr__ String should formatted stage action type microbatch e g ` F ` ` UNSHARD ` ` SEND_F ` action_string = action_string strip action_string == None Check sub_actions format sub_action sub_action ComputationType action_string startswith action_string Find closing bracket separate sub_actions computation type bracket_end = action_string find sub_part = action_string bracket_end Remove get content before computation_type_part = action_string bracket_end + Get part after Parse sub_actions sub_actions = sub_part strip sub_str sub_part split sub_action = _Action from_str sub_str strip sub_action None sub_actions append sub_action For sub_actions format we create action just computation type The stage_index microbatch_index meaningful container action _Action stage_index=- Placeholder meaningful sub_actions container computation_type=_ComputationType from_str computation_type_part microbatch_index=None sub_actions=tuple sub_actions sub_actions None Handle regular single action format match = _action_regex match action_string stage_index computation_type microbatch_index = match groups _Action int stage_index _ComputationType from_str computation_type int microbatch_index len microbatch_index None action_string == None raise RuntimeError f Invalid action string action_string should formatted stage action type microbatch e g F lru_cache _get_profiler_function_name action _Action - str f PP str action _format_pipeline_order pipeline_order dict int list Optional _Action error_step_number Optional int = None - str Formats pipeline order timestep row x rank column grid actions returns formatted string If ` error_step_number ` passed additional label will added signify which step erroring don t mutate original pipeline_order = copy deepcopy pipeline_order Replace None rank pipeline_order i range len pipeline_order rank pipeline_order rank i None TODO make real None action prints empty string make mypy happy pipeline_order rank i = type ignore call-overload Calculate maximum number steps across all ranks num_steps = max len actions actions pipeline_order values step_labels = Step + str i zfill len str num_steps - i range num_steps Sorting dictionary keys retrieving values order rank_actions = pipeline_order get key num_steps key sorted pipeline_order Transpose list lists rows columns pyrefly ignore no-matching-overload transposed_actions = list itertools zip_longest rank_actions fillvalue= Generate column labels ranks num_ranks = len pipeline_order rank_labels = Rank + str i i range num_ranks Calculate maximum length each column considering labels max_lengths = max len str item item None item col col zip step_labels transposed_actions Format header row rank labels header_row = len step_labels + + join f label max_lengths i i label enumerate rank_labels Format each row its corresponding label formatted_rows = f label + join f str item max_lengths i i item enumerate row + -- ERROR HERE error_step_number None int label split == error_step_number label row zip step_labels transposed_actions Join rows into single string formatted_table = header_row + \n + \n join formatted_rows + \n formatted_table _PipelineSchedule ABC __init__ n_microbatches int loss_fn Optional Callable torch Tensor = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True From arguments _n_microbatches = n_microbatches _loss_fn = loss_fn See documentation ` PipelineScheduleSingle ` ` PipelineScheduleMulti ` scale_grads = scale_grads Chunking specification positional inputs default ` None ` _args_chunk_spec = args_chunk_spec Chunking specification keyword inputs default ` None ` _kwargs_chunk_spec = kwargs_chunk_spec _output_merge_spec = output_merge_spec args_chunk_spec kwargs_chunk_spec specify how chunk inputs They used convert batch microbatches ` step x ` See ` TensorChunkSpec ` helper methods creating them Derived _has_backward = _loss_fn None Holds losses each microbatch _internal_losses list torch Tensor = logger info Using s __class__ __name__ _maybe_compute_loss stage output target_mbs mb_index stage is_last _loss_fn None loss = _compute_loss output target_mbs mb_index type ignore index _internal_losses append loss _maybe_get_loss stage mb_index valid_index = = mb_index len _internal_losses stage is_last _loss_fn None valid_index _internal_losses mb_index len _internal_losses = valid_index raise RuntimeError f Loss microbatch mb_index available f Available losses microbatches _internal_losses None _update_losses stages losses Update losses those internal state stages list turn into list isinstance stages list stages = stages contains_last_stage = any stage is_last stage stages Return losses there container passed contains_last_stage losses None len _internal_losses = _n_microbatches raise RuntimeError f Expecting _n_microbatches losses got len _internal_losses Clean external container first losses clear Copy internal losses external container losses extend _internal_losses _internal_losses clear abstractmethod _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Run one iteration pipeline schedule list microbatches Will go through all microbatches according schedule implementation Args microbatches list microbatch args return_outputs whether outputs last stage raise NotImplementedError abstractmethod step args target=None losses Optional list = None return_outputs=True kwargs Run one iteration pipeline schedule whole-batch input Will chunk input into microbatches automatically go through microbatches according schedule implementation args positional arguments model non-pipeline case kwargs keyword arguments model non-pipeline case target target loss function losses list store losses each microbatch return_outputs whether outputs last stage raise NotImplementedError eval args target=None losses Optional list = None kwargs Run one iteration pipeline schedule whole-batch input Will chunk input into microbatches automatically go through microbatches calling forward only args positional arguments model non-pipeline case kwargs keyword arguments model non-pipeline case target target values loss function losses list store losses each microbatch Save original has_backward state original_has_backward = _has_backward try _has_backward = False step args target=target losses=losses kwargs finally Restore original state _has_backward = original_has_backward _check_inputs arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None - tuple list list Pre-process check inputs check_type_and_len mbs name str isinstance mbs list raise TypeError f name must list got type mbs len mbs = _n_microbatches raise ValueError f Expecting _n_microbatches name got len mbs arg_mbs None check_type_and_len arg_mbs arg_mbs arg_mbs = _n_microbatches kwarg_mbs None check_type_and_len kwarg_mbs kwarg_mbs kwarg_mbs = _n_microbatches target_mbs None check_type_and_len target_mbs target_mbs losses None isinstance losses list raise TypeError f losses must list got type losses arg_mbs kwarg_mbs _compute_loss output target _loss_fn output target type ignore misc _split_inputs args tuple Any kwargs Optional dict str Any = None Splits full-batch input into chunks i e microbatches returns chunks args kwargs args_split kwargs_split = split_args_kwargs_into_chunks args kwargs _n_microbatches _args_chunk_spec _kwargs_chunk_spec args_split kwargs_split Empty inputs e g when called middle stages Return list empty tuples dicts matching length chunks _n_microbatches _n_microbatches _merge_outputs output_chunks list Any - Any Merge output chunks back batch state If output_merge_spec None utility will merge output chunks dimension batch dim merge_chunks output_chunks _output_merge_spec _batch_p p p p_ops list dist P POp desc Optional str = None - list dist Work Simple wrapper over batch_isend_irecv torch distributed which just adds descriptive logger top len p p_ops == desc_str = f desc desc logger debug batch_p p s s desc_str p p_ops dist batch_isend_irecv p p_ops _sorted_batch_p p p p_ops list dist P POp desc Optional str = None - dict int list dist Work Sorts list P P ops peer rank then calls batch_isend_irecv Return dictionary works peer rank This function helps us avoid hangs case skip connections Arrange p p_ops peer rank int peer rank List list ops towards peer ops_by_peer dict int list dist P POp = defaultdict list work_by_peer dict int list dist Work = len p p_ops == work_by_peer Classify ops peer rank op p p_ops ops_by_peer op peer append op Call batch_isend_irecv per peer sorted order peers avoid hangs peer ops sorted ops_by_peer items work_by_peer peer = _batch_p p ops desc=desc work_by_peer _wait_batch_p p work list dist Work Waits list dist Work typically _batch_p p _sorted_batch_p p w work w wait PipelineScheduleSingle _PipelineSchedule Base single-stage schedules Implements ` step ` method Derived classes should implement ` _step_microbatches ` Gradients scaled num_microbatches depending ` scale_grads ` argument defaulting True This setting should match configuration your loss_fn which may either average losses scale_grads=True sum losses scale_grads=False __init__ stage _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True Init parent super __init__ n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads Self attributes _stage = stage _num_stages = stage num_stages _stage_forward_initialized = False _stage_backward_initialized = False n_microbatches _num_stages raise ValueError f Number microbatches n_microbatches must greater than \ equal number stages _num_stages pipeline_order Optional dict int list Optional _Action = _get_pipeline_order _initialize_stage args kwargs _stage_forward_initialized Prepare communication needed pipeline schedule execution This needed because during execution we always perform series batch P P ops The first call batched P P needs involve global group all_ops list dist P POp = all_ops extend _stage _get_init_p p_neighbors_ops _wait_batch_p p _batch_p p all_ops _stage _prepare_forward_infra _n_microbatches args kwargs _stage_forward_initialized = True _has_backward _stage_backward_initialized _stage _prepare_backward_infra _n_microbatches _stage_backward_initialized = True step args target=None losses Optional list = None return_outputs bool = True kwargs Run one iteration pipeline schedule whole-batch input Will chunk input into microbatches automatically go through microbatches according schedule implementation args positional arguments model non-pipeline case kwargs keyword arguments model non-pipeline case target target loss function losses list store losses each microbatch return_outputs whether outputs last stage _has_backward torch is_grad_enabled raise RuntimeError step requires gradients enabled backward computation should used under torch no_grad context Please call eval instead Set same has_backward flag stage object _stage has_backward = _has_backward Clean per iteration _stage clear_runtime_states Split inputs into microbatches args_split kwargs_split = _split_inputs args kwargs Split target into microbatches target None targets_split = list torch tensor_split target _n_microbatches targets_split = None Run microbatches _step_microbatches args_split kwargs_split targets_split losses return_outputs Stage post processing grad_scale_factor = _n_microbatches scale_grads _stage _post_backward grad_scale_factor Return merged results per original format _stage is_last return_outputs _merge_outputs _stage output_chunks None _get_pipeline_order - Optional dict int list Optional _Action Returns pipeline execution order schedule IR The returned IR dictionary mapping rank IDs lists actions Each action either _Action object representing computation perform None representing deliberate idle step The None values used represent pipeline bubbles where rank must wait dependencies other ranks before proceeding However during execution _PipelineScheduleRuntime these Nones skipped since relevant communication send recv will scheduled waited Returns A dictionary mapping rank - list actions None _ScheduleForwardOnly PipelineScheduleSingle The forward-only schedule Will go through all microbatches perform only forward pass _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Run one iteration pipeline schedule target_mbs None losses None raise RuntimeError Forward-only schedule does support loss computation arg_mbs kwarg_mbs = _check_inputs arg_mbs kwarg_mbs target_mbs losses _initialize_stage arg_mbs kwarg_mbs Delay send waits fwd_sends_to_wait list list dist Work = Run microbatches i range _n_microbatches record_function f Forward i ops = _stage get_fwd_recv_ops i works = _sorted_batch_p p ops desc= fwd_recv work works values _wait_batch_p p work _stage forward_one_chunk i arg_mbs i kwarg_mbs i type ignore index ops = _stage get_fwd_send_ops i works = _sorted_batch_p p ops desc= fwd_send fwd_sends_to_wait extend works values logger debug s Forwarded microbatch s _stage stage_index i Wait all forward sends finish This should have performance impact because time first backward arrives all forward sends should have been finished work fwd_sends_to_wait _wait_batch_p p work ScheduleGPipe PipelineScheduleSingle The GPipe schedule Will go through all microbatches fill-drain manner _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Run one iteration pipeline schedule list microbatches Will go through all microbatches according GPipe schedule Args microbatches list microbatch args return_outputs whether outputs last stage arg_mbs kwarg_mbs = _check_inputs arg_mbs kwarg_mbs target_mbs losses _initialize_stage arg_mbs kwarg_mbs Delay send waits fwd_sends_to_wait list list dist Work = Run microbatches i range _n_microbatches record_function f Forward i ops = _stage get_fwd_recv_ops i works = _sorted_batch_p p ops desc= fwd_recv work works values _wait_batch_p p work output = _stage forward_one_chunk i arg_mbs i kwarg_mbs i save_forward_output=return_outputs type ignore index ops = _stage get_fwd_send_ops i works = _sorted_batch_p p ops desc= fwd_send fwd_sends_to_wait extend works values logger debug s Forwarded microbatch s _stage stage_index i _maybe_compute_loss _stage output target_mbs i Wait all forward sends finish This should have performance impact because time first backward arrives all forward sends should have been finished work fwd_sends_to_wait _wait_batch_p p work Run backward Delay send waits bwd_sends_to_wait list list dist Work = i range _n_microbatches record_function f Backward i ops = _stage get_bwd_recv_ops i works = _sorted_batch_p p ops desc= bwd_recv work works values _wait_batch_p p work loss = _maybe_get_loss _stage i _stage backward_one_chunk i loss=loss last_backward=i == _n_microbatches - ops = _stage get_bwd_send_ops i works = _sorted_batch_p p ops desc= bwd_send bwd_sends_to_wait extend works values logger debug s Backwarded microbatch s _stage stage_index i Wait all backward sends finish work bwd_sends_to_wait _wait_batch_p p work Update losses there container passed _update_losses _stage losses _get_pipeline_order - Optional dict int list Optional _Action Returns pipeline order GPipe schedule See base method PipelineScheduleSingle details schedule IR format pipeline_order = pp_group_size = _num_stages rank range pp_group_size actions list Optional _Action = Initial delay based rank position warmup_delay = rank actions extend None warmup_delay Forward passes all microbatches mb_idx range _n_microbatches actions append _Action rank _ComputationType FORWARD mb_idx Wait period before backward passes can begin backward_delay = pp_group_size - - rank actions extend None backward_delay Backward passes all microbatches mb_idx range _n_microbatches actions append _Action rank _ComputationType FULL_BACKWARD mb_idx pipeline_order rank = actions pipeline_order Schedule F B PipelineScheduleSingle The F B schedule Will perform one forward one backward microbatches steady state _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Run one iteration pipeline schedule list microbatches Will go through all microbatches according F B schedule Args microbatches list microbatch args return_outputs whether outputs last stage arg_mbs kwarg_mbs = _check_inputs arg_mbs kwarg_mbs target_mbs losses _initialize_stage arg_mbs kwarg_mbs Last stage has warmup second-to-last warmups first stage ` num_stages ` warmups warmup_chunks = min _n_microbatches _num_stages - _stage stage_index Chunk counters fwd_mb_index = bwd_mb_index = Warmup phase send_work list dist Work = fwd_sends = _ range warmup_chunks Receive activations fwd_recvs = _stage get_fwd_recv_ops fwd_mb_index _wait_batch_p p _batch_p p fwd_recvs desc= fwd_recv Compute output = _stage forward_one_chunk fwd_mb_index arg_mbs fwd_mb_index kwarg_mbs fwd_mb_index save_forward_output=return_outputs type ignore index Clear previous chunk s forward sends hopefully they have well finished otherwise we heavily communication bound which case doesn t create lot benefit compute next chunk eagerly either _wait_batch_p p send_work Send activations fwd_sends = _stage get_fwd_send_ops fwd_mb_index fwd_mb_index = warmup_chunks - Safe fire send_work = _batch_p p fwd_sends desc= fwd_send otherwise The last forward send left fuse first B B F below Compute loss _maybe_compute_loss _stage output target_mbs fwd_mb_index fwd_mb_index += Now we should have send ops left over fused first B B F phase below B F phase while True Don t worry we have break inside We actually do B first ` B F ` name indicates so prepare its recv ops bwd_recvs = _stage get_bwd_recv_ops bwd_mb_index Now we need fire fwd_sends bwd_recvs together _wait_batch_p p _batch_p p fwd_sends + bwd_recvs desc= fwd_send_bwd_recv Backward one chunk loss = _maybe_get_loss _stage bwd_mb_index _stage backward_one_chunk bwd_mb_index loss=loss last_backward=bwd_mb_index == _n_microbatches - Get bwd send ops don t fire fused F below bwd_sends = _stage get_bwd_send_ops bwd_mb_index bwd_mb_index += fwd_mb_index == _n_microbatches We done B F so break some left-over bwd_sends break We prepare F ` B F ` fwd_recvs = _stage get_fwd_recv_ops fwd_mb_index Fuse bwd_sends above _wait_batch_p p _batch_p p bwd_sends + fwd_recvs desc= bwd_send_fwd_recv Now do fwd output = _stage forward_one_chunk fwd_mb_index arg_mbs fwd_mb_index kwarg_mbs fwd_mb_index save_forward_output=return_outputs type ignore index Compute loss _maybe_compute_loss _stage output target_mbs fwd_mb_index Get fwd send ops don t fire leave next iter wrap-around fwd_sends = _stage get_fwd_send_ops fwd_mb_index fwd_mb_index += Remember we still have some bwd_sends left over after break Now time fire send_work = _batch_p p bwd_sends desc= bwd_send Cooldown while bwd_mb_index _n_microbatches prepare bwd recv ops bwd_recvs = _stage get_bwd_recv_ops bwd_mb_index _wait_batch_p p _batch_p p bwd_recvs desc= bwd_recv Backward one chunk loss = _maybe_get_loss _stage bwd_mb_index _stage backward_one_chunk bwd_mb_index loss=loss last_backward=bwd_mb_index == _n_microbatches - Clear previous chunk s backward sends hopefully they have well finished _wait_batch_p p send_work Get bwd send ops fire bwd_sends = _stage get_bwd_send_ops bwd_mb_index send_work = _batch_p p bwd_sends desc= bwd_send bwd_mb_index += Wait last backward send finish _wait_batch_p p send_work Return losses there container passed _update_losses _stage losses _get_pipeline_order - Optional dict int list Optional _Action Returns pipeline order F B schedule See base method PipelineScheduleSingle details schedule IR format pipeline_order = pp_group_size = _num_stages rank range pp_group_size actions list Optional _Action = Warmup phase initial delay based rank actions extend None rank Initial forward passes before F B phase num_forward = pp_group_size - - rank forward_mb = i range num_forward actions append _Action rank _ComputationType FORWARD i forward_mb = i Wait backward ready wait_for_ f b = max pp_group_size - - rank actions extend None wait_for_ f b F B steady state phase backward_mb = remaining_forward = _n_microbatches - num_forward while remaining_forward One forward forward_mb += actions append _Action rank _ComputationType FORWARD forward_mb remaining_forward -= One backward actions append _Action rank _ComputationType FULL_BACKWARD backward_mb backward_mb += Cooldown phase remaining backward passes remaining_backward = _n_microbatches - backward_mb while remaining_backward Add None backward actions alternating pattern based distance last stage pp_group_size - rank actions append None Decrement wait counter only we still have backward passes do remaining_backward actions append _Action rank _ComputationType FULL_BACKWARD backward_mb backward_mb += remaining_backward -= If we re last stage just add backward actions without None actions append _Action rank _ComputationType FULL_BACKWARD backward_mb backward_mb += remaining_backward -= pipeline_order rank = actions pipeline_order _add_unshard_reshard compute_actions list Optional _Action max_active_stages int = - list _Action Given basic schedule involving only compute actions F B W OVERLAP_F_B add UNSHARD RESHARD actions FSDP UNSHARD refers fetching full contents FSDP-sharded layer requiring all-gather operation RESHARD does opposite releasing memory doing no communication We abandon timestep lock during lowering max_active_stages controls how many prefetches we allow It should measured mb tuneable practice stages probably thing we want account having one f one b active something prefetching next_stage_indices count int next_actions list Optional _Action - list int Remove duplicates same stage different microbatch find next count stages will do compute seen set int = set ret list int = next_actions None Handle OVERLAP_F_B actions checking their sub_actions computation_type == OVERLAP_F_B sub_actions None sub_action sub_actions sub_action stage_index seen seen add sub_action stage_index ret append sub_action stage_index len ret = count break Regular action stage_index seen seen add stage_index ret append stage_index len ret == count break ret active_stages set int = set fsdp_aware_actions list _Action = _unshard stage_index int active_stages add stage_index fsdp_aware_actions append _Action stage_index UNSHARD None _reshard stage_index int active_stages remove stage_index fsdp_aware_actions append _Action stage_index RESHARD None i action enumerate compute_actions action None continue We prefetch next N stages we ll see dropping existing stages make room next_n = next_stage_indices max_active_stages compute_actions i Fetch needs ordered correctly so don t use set fetch = list filter lambda s s active_stages next_n Unclear what best policy eviction we can maintain order so we do evict = list filter lambda s s next_n active_stages logger debug _add_unshard_reshard Step d active s fetch s evict s i active_stages fetch evict stage evict _reshard stage stage fetch _unshard stage fsdp_aware_actions append action Reshard all remaining active stages after processing all operations stage list active_stages _reshard stage fsdp_aware_actions _merge_bw compute_actions list Optional _Action - list _Action Given basic schedule involving only compute actions F I W merge adjacent I W ops into B ops note I = BACKWARD_INPUT W = BACKWARD_WEIGHT B = FULL_BACKWARD B refers running whole backward separating grad_input grad_weight which can more efficient some cases merged_actions = while compute_actions action = compute_actions pop action None continue Remove any None actions find next non-None action while len compute_actions compute_actions None compute_actions pop Get next action exists next_action = compute_actions len compute_actions None action computation_type == BACKWARD_INPUT next_action None next_action computation_type == BACKWARD_WEIGHT action stage_index == next_action stage_index action microbatch_index == next_action microbatch_index merged_actions append _Action action stage_index FULL_BACKWARD action microbatch_index compute_actions pop merged_actions append action merged_actions _add_send_recv compute_actions dict int list _Action stage_to_rank Callable int int num_stages int - dict int list _Action Transforms compute-only schedule into complete schedule communication actions For actions sub-actions OVERLAP_F_B we ensure all subactions have been computed communication ready comm_actions dict int list _Action = rank rank compute_actions prev_actions dict int set _Action = rank set rank compute_actions _has_comms action _Action - bool action computation_type == F action stage_index = num_stages - stage_to_rank action stage_index + = stage_to_rank action stage_index action computation_type BACKWARD_INPUT FULL_BACKWARD action stage_index = stage_to_rank action stage_index - = stage_to_rank action stage_index False _get_comms action _Action - tuple _Action _Action assert _has_comms action f action valid comm action stage_idx = action stage_index ctype = action computation_type mb_idx = action microbatch_index send = _Action stage_idx SEND_F ctype == F SEND_B mb_idx recv_stage_idx = stage_idx + ctype == F stage_idx - recv = _Action recv_stage_idx RECV_F ctype == F RECV_B mb_idx send recv _ready_to_schedule action Optional _Action prev_actions set _Action - bool We don t put our own recv ops schedule we let sender another rank put our recv ops place This helps ensure sane non-hanging ordering sends recvs But also means we might able schedule our next compute action yet action None True action computation_type == F action stage_index = _Action action stage_index RECV_F action microbatch_index prev_actions True _Action action stage_index - F action microbatch_index prev_actions True False action computation_type BACKWARD_INPUT FULL_BACKWARD action stage_index = num_stages - _Action action stage_index RECV_B action microbatch_index prev_actions True _Action action stage_index + BACKWARD_INPUT action microbatch_index prev_actions True _Action action stage_index + FULL_BACKWARD action microbatch_index prev_actions True False True while compute_actions progress = False go order ranks even dict keys aren t ordered rank sorted compute_actions assert len compute_actions rank f rank= len compute_actions rank = action = compute_actions rank handle case where parent action e g OVERLAP_F_B can comprised subactions action None action sub_actions None all_actions = action sub_actions all_actions = action all _ready_to_schedule prev_actions rank all_actions continue The action s dependencies satisfied so add schedule action None comm_actions rank append action all_actions prev_actions rank add _has_comms send recv = _get_comms TODO we can avoid send recv stages same rank should we avoid runtime here comm_actions rank append send prev_actions rank add send comm_actions stage_to_rank recv stage_index append recv prev_actions stage_to_rank recv stage_index add recv compute_actions rank pop len compute_actions rank == del compute_actions rank progress = True assert progress Malformed compute schedule can t schedule sends recvs comm_actions _validate_schedule actions dict int list Optional _Action pp_group_size int num_stages int num_microbatches int - dict int int assert len actions == pp_group_size f Schedule has incorrect number ranks - expected pp_group_size actual len actions rank range pp_group_size assert rank actions f Schedule missing actions rank rank We will count all actions per stage ensure they happen valid order e g F before B I before W given microbatch stage_actions dict int dict _ComputationType set = stage_id F set B set I set W set stage_id range num_stages stage_index_to_rank_mapping = _process_action action _Action rank int step int Process single action update stage_actions stage_index_to_rank_mapping s_id = action stage_index ctype = action computation_type mb_id = action microbatch_index ctype == F stage_actions s_id F add mb_id ctype == B mb_id stage_actions s_id F error_msg = f Rank rank step step Running Full Backward stage s_id f microbatch mb_id without first running Forward formatted_schedule = _format_pipeline_order actions error_step_number=step full_error_msg = f error_msg \n\nFull pipeline schedule \n formatted_schedule raise AssertionError full_error_msg stage_actions s_id B add mb_id ctype == I mb_id stage_actions s_id F error_msg = f Rank rank step step Running Backward Input stage s_id f microbatch mb_id without first running Forward formatted_schedule = _format_pipeline_order actions error_step_number=step full_error_msg = f error_msg \n\nFull pipeline schedule \n formatted_schedule raise AssertionError full_error_msg stage_actions s_id I add mb_id ctype == W mb_id stage_actions s_id I error_msg = f Rank rank step step Running Backward Weight stage s_id f microbatch mb_id without first running Backward Input formatted_schedule = _format_pipeline_order actions error_step_number=step full_error_msg = f error_msg \n\nFull pipeline schedule \n formatted_schedule raise AssertionError full_error_msg stage_actions s_id W add mb_id s_id stage_index_to_rank_mapping stage_index_to_rank_mapping s_id = rank existing_rank = stage_index_to_rank_mapping s_id assert rank == existing_rank f Rank rank step step Stage s_id assigned both rank rank rank existing_rank rank actions step action enumerate actions rank action None continue assert isinstance action _Action f Rank rank step step Got invalid action action expected instance _Action Check action has sub_actions action sub_actions None Process each sub_action instead main action sub_action action sub_actions _process_action sub_action rank step Process main action normally _process_action action rank step s_id stage_actions f_mb = len stage_actions s_id F b_mb = len stage_actions s_id B i_mb = len stage_actions s_id I w_mb = len stage_actions s_id W assert f_mb == num_microbatches f Got f_mb F microbatches stage s_id expected num_microbatches assert i_mb == w_mb f Invalid backward microbatches stage s_id I W must have equal counts \ got I= i_mb W= w_mb assert b_mb + i_mb + w_mb == num_microbatches f Invalid backward microbatches stage s_id expected num_microbatches total backwards \ got B= b_mb I= i_mb W= w_mb stage_index_to_rank_mapping PipelineScheduleMulti _PipelineSchedule Base multi-stage schedules Implements ` step ` method Gradients scaled num_microbatches depending ` scale_grads ` argument defaulting True This setting should match configuration your loss_fn which may either average losses scale_grads=True sum losses scale_grads=False __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None use_full_backward Optional bool = None scale_grads bool = True Init parent super __init__ n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads Self attributes _stages = stages _num_stages = stages num_stages pp_group_size = stages group_size rank = stages group_rank Set pipeline stage states stage_index_to_group_rank = generate_stage_to_rank_mapping pp_group_size _num_stages stage _stages stage stage_index_to_group_rank = stage_index_to_group_rank _stages_forward_initialized = False _stages_backward_initialized = False avoid putting reference inside lambda creates ref cycle has_loss bool = _loss_fn None _should_compute_loss = lambda stage stage is_last has_loss This will set during init derived schedules pipeline_order dict int list Optional _Action = use_full_backward None logger warning Deprecation warning use_full_backward no longer supported Simply stop passing everything should still work fine _initialize_stages args tuple Any kwargs _stages_forward_initialized Prepare communication needed pipeline schedule execution This needed because during execution we always perform series batch P P ops The first call batched P P needs involve global group all_ops list dist P POp = stage _stages all_ops extend stage _get_init_p p_neighbors_ops _wait_batch_p p _batch_p p all_ops may none value stage sends its output shapes next stage via P P real value stage next stage same device next_stage_args tuple Any = tuple stage _stages stage is_first next_stage_args = stage _prepare_forward_infra _n_microbatches args kwargs next_stage_args = stage _prepare_forward_infra _n_microbatches next_stage_args kwargs _stages_forward_initialized = True _has_backward _stages_backward_initialized stage _stages stage _prepare_backward_infra _n_microbatches _stages_backward_initialized = True _validate_and_set_stage_mapping actions dict int list Optional _Action - None Allocates stage index rank mapping which needed communication stage_index_to_group_rank = _validate_schedule actions pp_group_size _num_stages _n_microbatches stage _stages stage stage_index_to_group_rank = stage_index_to_group_rank _dump_csv filename Dump CSV representation schedule into file provided filename open filename w newline= csvfile writer = csv writer csvfile rank pipeline_order writer writerow pipeline_order rank _load_csv filename format= compute_only Load CSV representation schedule file provided filename This API will most likely get renamed refactored so marked internal now format must compute_only PipelineScheduleMulti assert format == compute_only open filename newline= csvfile reader = csv reader csvfile rank row enumerate reader pipeline_order rank = _Action from_str s s row Validates order pipeline actions infers stage_to_rank_mapping This will overwrite default stage_to_rank_mapping created constructor _validate_and_set_stage_mapping pipeline_order step args target=None losses Optional list = None return_outputs bool = True kwargs Run one iteration pipeline schedule whole-batch input Will chunk input into microbatches automatically go through microbatches according schedule implementation args positional arguments model non-pipeline case kwargs keyword arguments model non-pipeline case target target loss function losses list store losses each microbatch return_outputs whether outputs last stage _has_backward torch is_grad_enabled raise RuntimeError step requires gradients enabled backward computation should used under torch no_grad context Please call eval instead Set same has_backward flag stage object stage _stages stage has_backward = _has_backward Clean per iteration stage _stages stage clear_runtime_states Split inputs into microbatches args_split kwargs_split = _split_inputs args kwargs Split target into microbatches target None targets_split = list torch tensor_split target _n_microbatches targets_split = None Run microbatches _step_microbatches args_split kwargs_split targets_split losses return_outputs Stage post processing TODO remove section include part schedule IR stage _stages grad_scale_factor = _n_microbatches scale_grads stage _post_backward grad_scale_factor Return merged results per original format stage _stages stage is_last return_outputs _merge_outputs stage output_chunks Does contain last stage we do output chunks None _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Operate microbatches looped schedules multiple stages each rank TODO Does use sorted_batch_isend_irecv As result schedule does support models skip connections arg_mbs kwarg_mbs = _check_inputs arg_mbs kwarg_mbs target_mbs losses _initialize_stages arg_mbs kwarg_mbs Based plan Step created __init__ Perform communication based pipeline_order stage_index_to_stage dict int _PipelineStageBase = stage stage_index stage stage _stages determine prev_rank next_rank based which ranks next stages pipeline_order all_prev_ranks set int = set all_next_ranks set int = set stage_index stage_index_to_stage keys TODO assumption stages only communicate distances + - no skip connections stage_index all_prev_ranks add stage_index_to_group_rank stage_index - stage_index _num_stages - all_next_ranks add stage_index_to_group_rank stage_index + count either full_backward backward_weight together determine when sync DP grads backward_counter Counter int = Counter time_step action enumerate pipeline_order rank try ops list dist P POp = action None computation_type = action computation_type mb_index = action microbatch_index stage_index = action stage_index assert mb_index None All currently supported action types require valid microbatch_index computation_type == _ComputationType FORWARD perform forward computation stage = stage_index_to_stage stage_index output = stage forward_one_chunk mb_index arg_mbs mb_index kwarg_mbs mb_index save_forward_output=return_outputs _maybe_compute_loss stage output target_mbs mb_index ops extend stage get_fwd_send_ops mb_index computation_type == _ComputationType FULL_BACKWARD perform backward computation stage = stage_index_to_stage stage_index loss = _maybe_get_loss stage mb_index backward_counter stage_index += last_backward = backward_counter stage_index == _n_microbatches grad_scale_factor = _n_microbatches scale_grads stage backward_one_chunk mb_index loss=loss full_backward=True last_backward=last_backward last_backward stage scale_grads grad_scale_factor ops extend stage get_bwd_send_ops mb_index computation_type == _ComputationType BACKWARD_INPUT perform backward computation stage = stage_index_to_stage stage_index loss = _maybe_get_loss stage mb_index stage backward_one_chunk mb_index loss=loss full_backward=False last_backward=False ops extend stage get_bwd_send_ops mb_index computation_type == _ComputationType BACKWARD_WEIGHT perform weight update stage = stage_index_to_stage stage_index backward_counter stage_index += last_backward = backward_counter stage_index == _n_microbatches grad_scale_factor = _n_microbatches scale_grads stage backward_weight_one_chunk mb_index last_backward=last_backward last_backward stage scale_grads grad_scale_factor raise ValueError f Unknown computation type computation_type Look neighboring ranks current timestep determine whether current rank needs do any recv communication prev_rank all_prev_ranks prev_rank_ops = pipeline_order prev_rank prev_rank_action = None time_step len prev_rank_ops prev_rank_action = prev_rank_ops time_step prev_rank_action None computation_type = prev_rank_action computation_type mb_index = prev_rank_action microbatch_index stage_index = prev_rank_action stage_index assert mb_index None All currently supported action types require valid microbatch_index Only handle sends forward previous rank computation_type == _ComputationType FORWARD If last stage then receive fwd activations stage_index + stage_index_to_stage TODO We assuming stage will always receive stage- however necessarily true get_fwd_recv_ops stage = stage_index_to_stage stage_index + ops extend stage get_fwd_recv_ops mb_index computation_type FULL_BACKWARD BACKWARD_INPUT BACKWARD_WEIGHT Previous rank doing backward has no influence current rank forward recv pass raise ValueError f Unknown computation type computation_type next_rank all_next_ranks next_rank_ops = pipeline_order next_rank next_rank_action = None time_step len next_rank_ops next_rank_action = next_rank_ops time_step next_rank_action None computation_type = next_rank_action computation_type mb_index = next_rank_action microbatch_index stage_index = next_rank_action stage_index assert mb_index None All currently supported action types require valid microbatch_index Only handle receives backwards next rank computation_type FORWARD BACKWARD_WEIGHT Next rank doing forward weight update has no influence current rank backward recv pass computation_type BACKWARD_INPUT FULL_BACKWARD If first stage then receive bwd gradients stage_index - stage_index_to_stage TODO We assuming stage will always receive stage+ however necessarily true get_bwd_recv_ops stage = stage_index_to_stage stage_index - ops extend stage get_bwd_recv_ops mb_index raise ValueError f Unknown computation type computation_type do communication _wait_batch_p p _batch_p p ops except Exception e logger error noqa G Rank s pipeline schedule s caught following exception s \ time_step s when running action s rank __class__ __name__ str e time_step action logger error s _format_pipeline_order pipeline_order error_step_number=time_step raise e Return losses there container passed _update_losses _stages losses _PipelineContext __init__ schedule_ref _PipelineSchedule arg_mbs Optional list tuple = None kwarg_mbs Optional list dict = None target_mbs Optional list = None losses Optional list = None schedule_ref = schedule_ref arg_mbs = arg_mbs kwarg_mbs = kwarg_mbs target_mbs = target_mbs losses = losses _CustomFunctionProtocol Protocol __call__ action _Action ctx _PipelineContext - None _PipelineScheduleRuntime PipelineScheduleMulti Provides simple runtime requires schedule IR including specified communication operations Can instantiated directly creating _PipelineScheduleRuntime calling load_csv can subclassed subclass can responsible creating schedule IR __init__ args kwargs super __init__ args kwargs Action custom function mapping _comp_type_to_function_map dict _ComputationType Callable = count either full_backward backward_weight together determine when sync DP grads backward_counter Counter int = Counter recv ops indexed stage_idx mb_idx need waited before use bwd_recv_ops dict tuple int int list dist Work = fwd_recv_ops dict tuple int int list dist Work = we track which stages active when used FSDP wait unshard ops before computing stages unshard_ops dict int list UnshardHandle = defaultdict list unsharded_stages = set register_custom_function computation_type _ComputationType custom_function _CustomFunctionProtocol - None Register custom function executed specific computation type Args computation_type The computation type which register custom function custom_function The function execute when computation type encountered Must have signature stage _PipelineStageBase mb_index int args kwargs - None Ensure computation type valid computation_type FORWARD FULL_BACKWARD BACKWARD_INPUT BACKWARD_WEIGHT OVERLAP_F_B raise ValueError f Invalid computation type computation_type Only FORWARD FULL_BACKWARD \ BACKWARD_INPUT BACKWARD_WEIGHT OVERLAP_F_B supported Check computation_type already registered computation_type _comp_type_to_function_map logger warning Computation type s already registered Overwriting existing custom function computation_type _comp_type_to_function_map computation_type = custom_function _prepare_schedule_with_comms actions dict int list Optional _Action format str = compute_only Given in-memory representation simple compute-only schedule lower complex schedule including communication actions Stores schedule must called before running step_mo validate provided actions valid overrides default stage_index_to_group_rank super _validate_and_set_stage_mapping actions pipeline_order_with_comms dict int list _Action = format == compute_comms rank actions pipeline_order_with_comms rank = action actions rank assert action None pipeline_order_with_comms rank append action TODO what level validation should we offer compute+comms schedule format == compute_only Validate schedule does have comms already added rank action_list actions items i action enumerate action_list action None action is_compute_op raise ValueError f Expected compute-only schedule found communication action f action rank rank position i f Communication actions e g SEND_F RECV_F etc f should present when format= compute_only Perform schedule lowering rank actions pipeline_order_with_comms rank = _add_unshard_reshard actions rank pipeline_order_with_comms = _add_send_recv pipeline_order_with_comms stage_to_rank=lambda s stage_index_to_group_rank s num_stages=self _num_stages raise NotImplementedError f format= implemented _load_csv filename str format str = compute_only Loads csv simple format then lowers include communication actions format must either compute_only compute_comms If compute_only lowering passes will automatically run generate compute_comms schedule format == compute_only will populate pipeline_order super _load_csv filename will populate pipeline_order_with_comms _prepare_schedule_with_comms pipeline_order format == compute_comms actions = open filename newline= csvfile reader = csv reader csvfile rank row enumerate reader actions rank = _Action from_str s s row _prepare_schedule_with_comms actions format=format raise NotImplementedError f format= implemented _dump_csv filename str format str = compute_comms Dump CSV representation schedule into file provided filename format == compute_only assert pipeline_order None Compute only schedule must available open filename w newline= csvfile writer = csv writer csvfile rank pipeline_order writer writerow pipeline_order rank format == compute_comms assert pipeline_order_with_comms None Must initialize compute_comms schedule before dump_csv open filename w newline= csvfile writer = csv writer csvfile rank pipeline_order_with_comms writer writerow pipeline_order_with_comms rank _simulate _simulate_comms_compute pipeline_order_with_comms lambda s stage_index_to_group_rank s _num_stages _assert_unsharded stage _PipelineStageBase If unshard active ` stage_idx ` wait mark ` stage_idx ` unshared stage_uses_fsdp = isinstance stage submod FSDPModule stage_uses_fsdp stage_idx = stage stage_index stage_idx unshard_ops op unshard_ops stage_idx op wait del unshard_ops stage_idx unsharded_stages add stage_idx assert stage_idx unsharded_stages f Attempted compute sharded stage_idx= _step_microbatches arg_mbs Optional list = None kwarg_mbs Optional list = None target_mbs Optional list = None losses Optional list = None return_outputs bool = True Operate microbatches looped schedules multiple stages each rank TODO Does use sorted_batch_isend_irecv As result schedule does support models skip connections arg_mbs kwarg_mbs = _check_inputs arg_mbs kwarg_mbs target_mbs losses _initialize_stages arg_mbs kwarg_mbs Based plan Step created __init__ Perform communication based pipeline_order stage_index_to_stage dict int _PipelineStageBase = stage stage_index stage stage _stages assert pipeline_order_with_comms None Must call _prepare_schedule_with_comms before calling _step_microbatches send ops should waited before step exists mainly hygiene send_ops list list dist Work = _perform_action action _Action - None comp_type = action computation_type mb_index int = action microbatch_index action microbatch_index None - assert mb_index = comp_type UNSHARD RESHARD f action= missing mb_index stage_idx = action stage_index stage = stage_index_to_stage stage_idx stage_uses_fsdp = isinstance stage submod FSDPModule see Note V-schedule special case is_next_stage_on_this_rank = stage_idx + stage_index_to_stage is_prev_stage_on_this_rank = stage_idx - stage_index_to_stage logger debug _PipelineScheduleRuntime running time_step d action s time_step action TODO whc s actually safe use _batch_p p here uncommon case model has skip-connections since we do want batch up ops between more than pair ranks _sorted_batch_p p would safe use instead However I wondering I should avoid calling batched operators all case there only one operator per batch I could iterate through fwd_send_ops one one run them comp_type == SEND_F send_ops append _batch_p p stage get_fwd_send_ops mb_index comp_type == SEND_B send_ops append _batch_p p stage get_bwd_send_ops mb_index comp_type == RECV_F assert stage_idx mb_index fwd_recv_ops f Recv twice stage_idx= mb_index= without executing forward fwd_recv_ops stage_idx mb_index = _batch_p p stage get_fwd_recv_ops mb_index comp_type == RECV_B assert stage_idx mb_index bwd_recv_ops f Recv twice stage_idx= mb_index= without executing backward bwd_recv_ops stage_idx mb_index = _batch_p p stage get_bwd_recv_ops mb_index comp_type == UNSHARD stage_uses_fsdp assert stage_idx unsharded_stages stage_idx unshard_ops f Unsharding same stage_idx= twice submodule stage submod modules isinstance submodule FSDPModule continue handle = cast UnshardHandle submodule unshard async_op=True unshard_ops stage_idx append handle comp_type == RESHARD stage_uses_fsdp assert stage_idx unsharded_stages f Resharding stage_idx= without unsharding assert stage_idx unshard_ops f Resharding stage_idx= before finishing unshard submodule stage submod modules isinstance submodule FSDPModule continue submodule reshard unsharded_stages remove stage_idx comp_type == FORWARD _assert_unsharded stage stage is_first no recv op expected V-schedule special case see Note V-schedule special case is_prev_stage_on_this_rank assert stage_idx mb_index fwd_recv_ops f Computing action= before receiving input _wait_batch_p p fwd_recv_ops pop stage_idx mb_index output = stage forward_one_chunk mb_index arg_mbs mb_index type ignore index kwarg_mbs mb_index type ignore index save_forward_output=return_outputs _maybe_compute_loss stage output target_mbs mb_index SEND RECV op avoided special case adjacent stages same rank see Note V-schedule special case is_next_stage_on_this_rank stage_index_to_stage stage_idx + set_local_fwd_input output mb_index comp_type == FULL_BACKWARD _assert_unsharded stage stage is_last no recv op expected V-schedule special case see Note V-schedule special case is_next_stage_on_this_rank assert stage_idx mb_index bwd_recv_ops f Attempted run compute action= before receiving input _wait_batch_p p bwd_recv_ops pop stage_idx mb_index loss = _maybe_get_loss stage mb_index backward_counter stage_idx += last_backward = backward_counter stage_idx == _n_microbatches stage backward_one_chunk mb_index loss=loss full_backward=True last_backward=last_backward SEND RECV op avoided special case adjacent stages same rank see Note V-schedule special case is_prev_stage_on_this_rank stage_index_to_stage stage_idx - set_local_bwd_input stage get_local_bwd_output mb_index mb_index comp_type == BACKWARD_INPUT _assert_unsharded stage stage is_last is_next_stage_on_this_rank assert stage_idx mb_index bwd_recv_ops f Attempted run compute action= before receiving input _wait_batch_p p bwd_recv_ops pop stage_idx mb_index loss = _maybe_get_loss stage mb_index stage backward_one_chunk mb_index loss=loss full_backward=False last_backward=False SEND RECV op avoided special case adjacent stages same rank see Note V-schedule special case is_prev_stage_on_this_rank stage_index_to_stage stage_idx - set_local_bwd_input stage get_local_bwd_output mb_index mb_index comp_type == BACKWARD_WEIGHT _assert_unsharded stage backward_counter stage_idx += last_backward = backward_counter stage_idx == _n_microbatches stage backward_weight_one_chunk mb_index last_backward=last_backward raise ValueError f action= unknown unsupported count either full_backward backward_weight together determine when sync DP grads backward_counter clear time_step action enumerate pipeline_order_with_comms rank try record_function _get_profiler_function_name action action computation_type _comp_type_to_function_map ctx = _PipelineContext arg_mbs kwarg_mbs target_mbs losses _comp_type_to_function_map action computation_type action ctx action computation_type == OVERLAP_F_B assert action sub_actions None sub_actions must set sub_a action sub_actions _perform_action sub_a _perform_action action except Exception e logger error _PipelineScheduleRuntime caught exception step s when running action s Full Schedule time_step action TODO whc what best practice printing multiline log logger will split into multiple log lines makes hard read too wide print _format_pipeline_order pipeline_order_with_comms type ignore arg-type error_step_number=time_step raise e Mostly these operations should have finished long ago there isn t obvious time when wait them while send_ops _wait_batch_p p send_ops pop assert len unshard_ops == Unused unshard operations Return losses there container passed _update_losses _stages losses ScheduleLoopedBFS _PipelineScheduleRuntime Breadth-First Pipeline Parallelism See https arxiv org abs details Similar Interleaved F B Looped BFS supports multiple stages per rank What different when microbatches ready multiple local stages Loops BFS will prioritizes earlier stage running all available microbatches once __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Union Callable _Loss = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True super __init__ stages=stages n_microbatches=n_microbatches loss_fn=loss_fn output_merge_spec=output_merge_spec scale_grads=scale_grads Create pipeline_order all ranks do calculation This will used keep track current state entire pipeline pipeline_order rank = Action computation_type microbatch_index stage_index pipeline_order dict int list Optional _Action = ======================================================================== rank range pp_group_size rank_ops = _calculate_single_rank_operations rank pipeline_order rank = rank_ops Initialize pipeline order communication necessary run _PipelineScheduleRuntime _prepare_schedule_with_comms pipeline_order _calculate_single_rank_operations rank n_local_stages = len _stages stage_indices = range rank pp_group_size n_local_stages pp_group_size Store list operations used rank Pre-padding rank starts no-ops based warmup rank_ops list Optional _Action = None _ range rank stage_index stage_indices rank_ops extend _Action stage_index _ComputationType FORWARD mb_index mb_index range _n_microbatches wait first backward trickle up which every hop away post_warmup_ops = pp_group_size - - rank rank_ops extend None post_warmup_ops stage_index reversed stage_indices rank_ops extend _Action stage_index _ComputationType FULL_BACKWARD mb_index mb_index reversed range _n_microbatches rank_ops _get_ f b_rank_ops n_local_stages pp_group_size warmup_ops fwd_bwd_ops cooldown_ops rank forward_stage_index backward_stage_index num_ f b_microbatches= enable_zero_bubble=False All stages start handling microbatch fwd_stage_mb_index dict int int = defaultdict int bwd_stage_mb_index dict int int = defaultdict int weight_stage_mb_index dict int int = defaultdict int Store list operations used rank Pre-padding rank starts no-ops based warmup rank_ops list Optional _Action = None _ range rank These used calculate number slots fill no-ops account delay warmup when we want wait backward trickle back up start f b align all ranks Formula pre-padding + warmup_ops + post_warmup_ops = earliest time step first backward post_warmup_ops = earliest time step first backward - warmup_ops + pre-padding earliest time step first backward = local_stages group_size + group_size - - rank warmup_ops = calculated above post_warmup_ops = n_local_stages pp_group_size + pp_group_size - - rank - warmup_ops + rank enable_zero_bubble post_warmup_ops = pp_group_size - rank - total_ops = warmup_ops + fwd_bwd_ops + cooldown_ops backward_op_ids = weight_op_count = FULL_BACKWARD_OR_BACKWARD_INPUT = BACKWARD_INPUT enable_zero_bubble FULL_BACKWARD op range total_ops Warmup phase op warmup_ops fwd_stage_index = forward_stage_index op This will assign current microbatch index update well fwd_stage_mb_index fwd_stage_index = mb_index = fwd_stage_mb_index fwd_stage_index + rank_ops append _Action fwd_stage_index _ComputationType FORWARD mb_index op == warmup_ops - This last step warmup phase so we need wait backward trickle back up rank_ops extend None post_warmup_ops F B Phase forward backward warmup_ops = op warmup_ops + fwd_bwd_ops fwd_stage_index = forward_stage_index op fwd_stage_mb_index fwd_stage_index = fwd_mb_index = fwd_stage_mb_index fwd_stage_index + rank_ops append _Action fwd_stage_index _ComputationType FORWARD fwd_mb_index bwd_stage_index = backward_stage_index op bwd_stage_mb_index bwd_stage_index = bwd_mb_index = bwd_stage_mb_index bwd_stage_index + rank_ops append _Action bwd_stage_index FULL_BACKWARD_OR_BACKWARD_INPUT bwd_mb_index backward_op_ids append op enable_zero_bubble op - warmup_ops = num_ f b_microbatches weight_stage_index = backward_stage_index backward_op_ids weight_op_count weight_stage_mb_index weight_stage_index = weight_mb_index = weight_stage_mb_index weight_stage_index + rank_ops append _Action weight_stage_index _ComputationType BACKWARD_WEIGHT weight_mb_index weight_op_count += Cooldown phase During cooldown phase we need steps align f b happening other ranks TODO we don t need always append after all f b finished we can stop appending None enable_zero_bubble rank_ops append None bwd_stage_index = backward_stage_index op bwd_stage_mb_index bwd_stage_index = bwd_mb_index = bwd_stage_mb_index bwd_stage_index + rank_ops append _Action bwd_stage_index FULL_BACKWARD_OR_BACKWARD_INPUT bwd_mb_index backward_op_ids append op enable_zero_bubble op - warmup_ops = num_ f b_microbatches weight_stage_index = backward_stage_index backward_op_ids weight_op_count weight_stage_mb_index weight_stage_index = weight_mb_index = weight_stage_mb_index weight_stage_index + rank_ops append _Action weight_stage_index _ComputationType BACKWARD_WEIGHT weight_mb_index weight_op_count += while enable_zero_bubble weight_op_count len backward_op_ids weight_stage_index = backward_stage_index backward_op_ids weight_op_count weight_stage_mb_index weight_stage_index = weight_mb_index = weight_stage_mb_index weight_stage_index + rank_ops append _Action weight_stage_index _ComputationType BACKWARD_WEIGHT weight_mb_index weight_op_count += rank_ops ScheduleInterleaved F B _PipelineScheduleRuntime The Interleaved F B schedule See https arxiv org pdf details Will perform one forward one backward microbatches steady state supports multiple stages per rank When microbatches ready multiple local stages Interleaved F B prioritizes earlier microbatch also called depth first This schedule mostly similar original paper It differs being relaxing requirement num_microbatch pp_size == Using flex_pp schedule we will have num_rounds = max n_microbatches pp_group_size works long n_microbatches num_rounds As few examples support pp_group_size = n_microbatches = We will have num_rounds = n_microbatches pp_group_size = n_microbatches = We will have num_rounds = n_microbatches __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True pp_group_size = stages group_size super __init__ stages=stages n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads n_local_stages = len stages rank = stages group_rank number_of_rounds = max n_microbatches pp_group_size microbatches_per_round = n_microbatches number_of_rounds n_microbatches number_of_rounds = raise ValueError Interleaved F B requires number microbatches f multiple number rounds number_of_rounds f got n_microbatches Create pipeline_order all ranks do calculation This will used keep track current state entire pipeline pipeline_order rank = Action computation_type microbatch_index stage_index pipeline_order dict int list Optional _Action = rank range pp_group_size rank_ops = _calculate_single_rank_operations rank pipeline_order rank = rank_ops Initialize pipeline order communication necessary run _PipelineScheduleRuntime _prepare_schedule_with_comms pipeline_order _calculate_single_rank_operations rank - list Optional _Action get_rank_warmup_ops rank Warms up operations last stage warmups_ops_last_stage = n_local_stages - microbatches_per_round Increment warmup operations each hop away last stage multiply_factor = warmup_ops = warmups_ops_last_stage + multiply_factor pp_group_size - - rank We cannot have more warmup operations than there number microbatches so cap there min warmup_ops _n_microbatches n_local_stages warmup_ops = get_rank_warmup_ops rank microbatch_ops = n_local_stages _n_microbatches fwd_bwd_ops should encompass remaining forwards fwd_bwd_ops = microbatch_ops - warmup_ops cooldown_ops should encompass remaining backwards cooldown_ops = microbatch_ops - fwd_bwd_ops total ops encompass both forward backward ops total_ops = warmup_ops + fwd_bwd_ops + cooldown_ops warmup_ops + fwd_bwd_ops + cooldown_ops == microbatch_ops logger debug rank s warmup_ops s f b s cooldown_ops s total_ops s rank warmup_ops fwd_bwd_ops cooldown_ops total_ops Calculates stage index based step pp_group_size forward_stage_index step Get local index n_local_stages- local_index = step microbatches_per_round n_local_stages local_index pp_group_size + rank backward_stage_index step local_index = n_local_stages - - step - warmup_ops microbatches_per_round n_local_stages local_index pp_group_size + rank _get_ f b_rank_ops n_local_stages pp_group_size warmup_ops fwd_bwd_ops cooldown_ops rank forward_stage_index backward_stage_index ScheduleInterleavedZeroBubble _PipelineScheduleRuntime The Interleaved Zero Bubble schedule See https arxiv org pdf details Will perform one forward one backward inputs microbatches steady state supports multiple stages per rank Uses backward weights fill pipeline bubble In particular implementing ZB P schedule paper __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True TODO we dont support input weight backward split torch compile _check_torch_compile_compatibility stages __class__ __name__ pp_group_size = stages group_size super __init__ stages=stages n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads n_local_stages = len stages rank = stages group_rank number_of_rounds = max n_microbatches pp_group_size microbatches_per_round = n_microbatches number_of_rounds n_microbatches number_of_rounds = raise ValueError Zero bubble requires number microbatches f multiple number rounds number_of_rounds f got n_microbatches Create pipeline_order all ranks do calculation This will used keep track current state entire pipeline pipeline_order rank = Action computation_type microbatch_index stage_index pipeline_order dict int list Optional _Action = rank range pp_group_size rank_ops = _calculate_single_rank_operations rank pipeline_order rank = rank_ops This function add bubbles generated schedule based dependencies actions Note ZB P schedule will require bubbles manually added only useful when n_microbatches = microbatches_per_round pipeline_order = _add_bubbles_to_actions n_local_stages pp_group_size Initialize pipeline order communication necessary run _PipelineScheduleRuntime _prepare_schedule_with_comms pipeline_order _calculate_single_rank_operations rank - list Optional _Action get_rank_warmup_ops rank Warms up operations last stage warmups_ops_last_stage = n_local_stages - microbatches_per_round Increment warmup operations each hop away last stage multiply_factor = warmup_ops = warmups_ops_last_stage + multiply_factor pp_group_size - - rank We cannot have more warmup operations than there number microbatches so cap there min warmup_ops _n_microbatches n_local_stages warmup_ops = get_rank_warmup_ops rank microbatch_ops = n_local_stages _n_microbatches fwd_bwd_ops should encompass remaining forwards fwd_bwd_ops = microbatch_ops - warmup_ops cooldown_ops should encompass remaining backwards cooldown_ops = microbatch_ops - fwd_bwd_ops total ops encompass both forward backward ops total_ops = warmup_ops + fwd_bwd_ops + cooldown_ops warmup_ops + fwd_bwd_ops + cooldown_ops == microbatch_ops logger debug rank s warmup_ops s f b s cooldown_ops s total_ops s rank warmup_ops fwd_bwd_ops cooldown_ops total_ops Calculates stage index based step pp_group_size forward_stage_index step Get local index n_local_stages- local_index = step microbatches_per_round n_local_stages local_index pp_group_size + rank backward_stage_index step local_index = n_local_stages - - step - warmup_ops microbatches_per_round n_local_stages local_index pp_group_size + rank num_ f b_microbatches = rank _get_ f b_rank_ops n_local_stages pp_group_size warmup_ops fwd_bwd_ops cooldown_ops rank forward_stage_index backward_stage_index num_ f b_microbatches enable_zero_bubble=True _add_bubbles_to_actions num_stages_global actions = pipeline_order need_bubble stage op microbatch num_stages_global seen_ops op == _ComputationType FORWARD stage = stage - op microbatch seen_ops True op == _ComputationType FULL_BACKWARD stage == num_stages_global - stage _ComputationType FORWARD microbatch seen_ops stage + op microbatch seen_ops False seen_ops set tuple int _ComputationType int = set result dict int list Optional _Action = next_pointer dict int int = bubbles_added dict int int = total_bubbles_added = rank range pp_group_size result rank = next_pointer rank = bubbles_added rank = while True should_stop = True temp_seen_ops set tuple int _ComputationType int = set rank range pp_group_size timestamp = next_pointer rank timestamp = len actions rank continue should_stop = False actions rank timestamp None temp_action = actions rank timestamp assert temp_action None stage_index op microbatch _ = temp_action need_bubble stage_index op microbatch num_stages_global seen_ops result rank append actions rank timestamp microbatch None temp_seen_ops add stage_index op microbatch next_pointer rank += result rank append None bubbles_added rank += next_pointer rank += result rank append None seen_ops update temp_seen_ops should_stop break total_bubbles_added logger warning Non zero bubbles added total_bubbles_added= s bubbles_added= s total_bubbles_added bubbles_added result ScheduleZBVZeroBubble _PipelineScheduleRuntime The Zero Bubble schedule ZBV variant See https arxiv org pdf Section details This schedules requires exactly two stages per rank This schedule will perform one forward one backward inputs microbatches steady state supports multiple stages per rank Uses backward respect weights fill pipeline bubble This ZB-V schedule would have zero bubble property only time forward == time backward input == time backward weights In practice likely true real models so alternatively greedy scheduler could implemented unequal unbalanced time __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True TODO we dont support input weight backward split torch compile _check_torch_compile_compatibility stages __class__ __name__ pp_group_size = stages group_size super __init__ stages=stages n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads stage_index_to_group_rank = generate_stage_to_rank_mapping pp_group_size _num_stages style= v stage _stages stage stage_index_to_group_rank = stage_index_to_group_rank n_local_stages = len stages n_local_stages = raise ValueError ZBV requires exactly stages per rank got f n_local_stages rank = stages group_rank num_stages = stages num_stages Create pipeline_order all ranks do calculation This will used keep track current state entire pipeline pipeline_order rank = Action computation_type microbatch_index stage_index pipeline_order dict int list Optional _Action = rank range pp_group_size rank_ops = _calculate_single_rank_operations rank pipeline_order rank = rank_ops Initialize pipeline order communication necessary run _PipelineScheduleRuntime _prepare_schedule_with_comms pipeline_order _calculate_single_rank_operations rank - list Optional _Action max pp_group_size - ensure number microbatches least large number microbatches needed fully utilize pipeline n_micro = max pp_group_size - _n_microbatches rank_ops list Optional _Action = None _ range rank Forward backward action counts stage chunk chunk f _cnt f _cnt b _cnt b _cnt = warm-up phase warmup_n = pp_group_size - rank - stage_id_chunk = rank stage_id_chunk = num_stages - - rank _ range warmup_n rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += warmup_n = rank _ range warmup_n rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += warmup_n = pp_group_size - rank _ range warmup_n rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=b _cnt b _cnt += stable phase while f _cnt f _cnt f _cnt n_micro f _cnt n_micro rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=b _cnt b _cnt += rank_ops append _Action stage_id_chunk computation_type=F microbatch_index=f _cnt f _cnt += rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=b _cnt b _cnt += cool-down phase w _cnt w _cnt = b _cnt b _cnt cooldown_n = rank _ range cooldown_n rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt b _cnt += rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt b _cnt += cooldown_n = pp_group_size - rank _ range cooldown_n rank_ops append _Action stage_id_chunk computation_type=I microbatch_index=b _cnt b _cnt += rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=w _cnt w _cnt += while w _cnt b _cnt rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=w _cnt w _cnt += while w _cnt b _cnt rank_ops append _Action stage_id_chunk computation_type=W microbatch_index=w _cnt w _cnt += assert w _cnt == b _cnt b _cnt == f _cnt assert w _cnt == b _cnt b _cnt == f _cnt We use max n_micro computation above so we may need remove redundant microbatches rank_ops = action action None action microbatch_index None action microbatch_index _n_microbatches None action rank_ops rank_ops ScheduleDualPipeV _PipelineScheduleRuntime The DualPipeV schedule A more efficient schedule variant based DualPipe schedule introduced DeepSeek https arxiv org pdf Based open sourced code https github com deepseek-ai DualPipe __init__ stages list _PipelineStageBase n_microbatches int loss_fn Optional Callable = None args_chunk_spec Optional tuple TensorChunkSpec = None kwargs_chunk_spec Optional dict str TensorChunkSpec = None output_merge_spec Optional Union dict str Any tuple Any = None scale_grads bool = True TODO we dont support input weight backward split torch compile _check_torch_compile_compatibility stages __class__ __name__ pp_group_size = stages group_size super __init__ stages=stages n_microbatches=n_microbatches loss_fn=loss_fn args_chunk_spec=args_chunk_spec kwargs_chunk_spec=kwargs_chunk_spec output_merge_spec=output_merge_spec scale_grads=scale_grads stage_index_to_group_rank = generate_stage_to_rank_mapping pp_group_size _num_stages style= v stage _stages stage stage_index_to_group_rank = stage_index_to_group_rank n_local_stages = len stages n_local_stages = raise ValueError ZBV requires exactly stages per rank got f n_local_stages n_microbatches _num_stages raise ValueError DualPipeV requires least many microbatches stages got f n_microbatches microbatches _num_stages stages rank = stages group_rank num_stages = stages num_stages Create pipeline_order all ranks do calculation This will used keep track current state entire pipeline pipeline_order rank = Action computation_type microbatch_index stage_index pipeline_order dict int list Optional _Action = rank range pp_group_size rank_ops = _calculate_single_rank_operations rank pipeline_order rank = rank_ops Initialize pipeline order communication necessary run _PipelineScheduleRuntime _prepare_schedule_with_comms pipeline_order _calculate_single_rank_operations rank - list Optional _Action actions list Optional _Action = counters dict tuple int _ComputationType int = stage_index computation_type - mb_index weight_queue = Queue stage_index mb_index pending weight actions num_ranks = pp_group_size num_chunks = _n_microbatches rank_to_stages = generate_rank_to_stage_mapping num_ranks num_ranks style= v stage _index stage _index = rank_to_stages rank increment_backward_counts stage_index int Helper method increment BACKWARD_INPUT BACKWARD_WEIGHT counters when FULL_BACKWARD used input_key = stage_index BACKWARD_INPUT weight_key = stage_index BACKWARD_WEIGHT counters input_key = counters get input_key + counters weight_key = counters get weight_key + add_overlap_f_b actions list forward_stage int backward_stage int Helper method add overlapped forward+backward action which tracks microbatch index Create new overlapped forward+backward action sub_actions forward_key = forward_stage FORWARD backward_key = backward_stage BACKWARD_INPUT forward_mb = counters get forward_key backward_mb = counters get backward_key sub_actions = _Action forward_stage FORWARD forward_mb _Action backward_stage FULL_BACKWARD backward_mb actions append _Action - OVERLAP_F_B None sub_actions Update counters sub_actions counters forward_key = forward_mb + increment_backward_counts backward_stage add_action actions list stage_index int computation_type _ComputationType Regular single action FULL_BACKWARD we only use BACKWARD_INPUT counter key = stage_index computation_type computation_type = FULL_BACKWARD stage_index BACKWARD_INPUT mb_index = counters get key actions append _Action stage_index computation_type mb_index If FULL_BACKWARD used just increment separate BACKWARD_INPUT BACKWARD_WEIGHT counters computation_type == FULL_BACKWARD increment_backward_counts stage_index If BACKWARD_INPUT updated add corresponding weight action queue computation_type == BACKWARD_INPUT Add weight action queue later processing weight_queue append stage_index mb_index counters key = mb_index + add_weight_action_if_pending actions list Helper method add weight action queue weight_queue No pending weight actions skip Pop oldest weight action queue actual_stage_index weight_mb_index = weight_queue pop actions append _Action actual_stage_index BACKWARD_WEIGHT weight_mb_index Update counter actual stage processed weight_key = actual_stage_index BACKWARD_WEIGHT counters weight_key = counters get weight_key + Step F step_ = num_ranks - rank - _ range step_ add_action actions stage _index FORWARD Step F F step_ = rank + _ range step_ add_action actions stage _index FORWARD add_action actions stage _index FORWARD Step I W F Use zero bubble step_ = num_ranks - rank - _ range step_ add_action actions stage _index BACKWARD_INPUT add_weight_action_if_pending actions add_action actions stage _index FORWARD Step Main step F B -F B combined overlapped forward+backward step_ = num_chunks - num_ranks + rank + i range step_ i == rank == num_ranks - NOTE We don t overlap these two chunks further reduce bubble size add_action actions stage _index FORWARD add_action actions stage _index FULL_BACKWARD add_overlap_f_b actions forward_stage=stage _index backward_stage=stage _index add_overlap_f_b actions forward_stage=stage _index backward_stage=stage _index Step B -F B step_ = num_ranks - rank - _ range step_ add_action actions stage _index FULL_BACKWARD add_overlap_f_b actions forward_stage=stage _index backward_stage=stage _index Step B B The second half chunks use zero bubble step_ = rank + enable_zb = False i range step_ i == step_ rank == enable_zb = True comp_type = BACKWARD_INPUT enable_zb FULL_BACKWARD add_action actions stage _index comp_type i == step_ rank == enable_zb = True comp_type = BACKWARD_INPUT enable_zb FULL_BACKWARD add_action actions stage _index comp_type Step W B step_ = num_ranks - rank - _ range step_ add_weight_action_if_pending actions comp_type = BACKWARD_INPUT enable_zb FULL_BACKWARD add_action actions stage _index comp_type Step W step_ = rank + _ range step_ add_weight_action_if_pending actions actions get_schedule_class schedule_name str Maps schedule name case insensitive its corresponding object Args schedule_name str The name schedule schedule_map = F B Schedule F B Interleaved F B ScheduleInterleaved F B GPipe ScheduleGPipe LoopedBFS ScheduleLoopedBFS InterleavedZeroBubble ScheduleInterleavedZeroBubble PipelineScheduleSingle PipelineScheduleSingle PipelineScheduleMulti PipelineScheduleMulti ZBVZeroBubble ScheduleZBVZeroBubble DualPipeV ScheduleDualPipeV lowercase_keys = k lower k k schedule_map keys lowercase_schedule_name = schedule_name lower lowercase_schedule_name lowercase_keys raise ValueError f Unknown schedule name schedule_name The valid options list schedule_map keys schedule_map lowercase_keys lowercase_schedule_name _simulate_comms_compute pipeline_order stage_to_rank Callable int int num_stages int This function dry-run simulates actions schedule perspective all ranks flags any deadlocks caused missing misordered communications It also simulates any bubbles time where rank can execute any action due waiting unmet dependencies The total number simulator steps can used metric unit tests involving IR optimization passes reordering merging IR can reduce number simulated steps The simulation high-fidelity does model overlapping compute communication cuda streams Future work may enhance model compute time comms overlap even memory pipeline_order = rank pipeline_order rank None rank sorted pipeline_order _schedule dict int list _Action &#124; None = rank rank sorted pipeline_order _prev_ops_rank dict int set _Action = rank set rank _schedule add_to_schedule rank int action Optional _Action _schedule rank append action action None _prev_ops_rank rank add action _ready_to_schedule action Optional _Action - bool action None True stage_idx = action stage_index prev_ops = _prev_ops_rank stage_to_rank stage_idx action computation_type == F action stage_index == True _Action action stage_index RECV_F action microbatch_index prev_ops True _Action action stage_index - F action microbatch_index prev_ops True False action computation_type BACKWARD_INPUT FULL_BACKWARD action stage_index == num_stages - True _Action action stage_index RECV_B action microbatch_index prev_ops True _Action action stage_index + BACKWARD_INPUT action microbatch_index prev_ops True _Action action stage_index + FULL_BACKWARD action microbatch_index prev_ops True False action computation_type == BACKWARD_WEIGHT True action computation_type == SEND_F expected_f = _Action action stage_index F action microbatch_index expected_f prev_ops action computation_type == RECV_F peer_stage_idx = stage_idx - expected_send = _Action peer_stage_idx SEND_F action microbatch_index expected_send _prev_ops_rank stage_to_rank peer_stage_idx action computation_type == SEND_B expected_b = _Action action stage_index BACKWARD_INPUT action microbatch_index expected_bw = _Action action stage_index FULL_BACKWARD action microbatch_index expected_b prev_ops expected_bw prev_ops action computation_type == RECV_B peer_stage_idx = stage_idx + expected_send = _Action peer_stage_idx SEND_B action microbatch_index expected_send _prev_ops_rank stage_to_rank peer_stage_idx raise ValueError f Unsupported action type action while pipeline_order progress = False rank sorted pipeline_order len pipeline_order rank == continue action = pipeline_order rank _ready_to_schedule action action None add_to_schedule rank action pipeline_order rank pop progress = True add_to_schedule rank None i sorted pipeline_order reverse=True len pipeline_order i == del pipeline_order i hacky do second pass replace any none timestep real action got unblocked one later ranks rank sorted pipeline_order len pipeline_order rank == continue _schedule rank - None continue action = pipeline_order rank _ready_to_schedule action action None _schedule rank - = action _prev_ops_rank rank add action pipeline_order rank pop i sorted pipeline_order reverse=True len pipeline_order i == del pipeline_order i progress print WIP comms schedule \n _format_pipeline_order _schedule rank pipeline_order print f rank= next action= pipeline_order rank raise ValueError Schedule progressing _schedule _dump_chrometrace schedule filename This function dumps schedule IR into chrometrace format so can visualized It currently very basic only serves graphical alternative dumping schedule IR text As future work we may extend include more accurate heuristics durations let users input durations add flow events let UI show connection between sends recvs model cuda streams comm compute separate streams chrometrace view events = rank sorted schedule timestep action enumerate schedule rank action None continue events append name str action cat computation action computation_type F B W communication ph X pid rank tid rank ts timestep dur json open filename w f json dump traceEvents events f _check_torch_compile_compatibility stages list _PipelineStageBase schedule_name str Check schedule compatible torch compile Args stages List pipeline stages check schedule_name Name schedule error message Raises RuntimeError If any stage uses torch compile stage stages isinstance stage submod torch nn Module continue module stage submod modules isinstance module OptimizedModule raise RuntimeError f The schedule_name schedule supported stage modules have used torch compile f Found OptimizedModule type module __name__