Owner s module type promotion functools wraps itertools unittest torch torch testing _internal common_utils TestCase run_tests load_tests make_tensor TEST_NUMPY set_default_dtype torch_to_numpy_dtype_dict numpy_to_torch_dtype_dict skipIfTorchDynamo torch testing _internal common_device_type instantiate_device_type_tests onlyNativeDeviceTypes dtypes onlyCPU expectedFailureMeta skipMeta torch testing _internal common_dtype all_types_and_complex_and get_all_math_dtypes floating_types get_all_dtypes float_to_corresponding_complex_type_map numpy np operator load_tests torch testing _internal common_utils used automatically filter tests sharding sandcastle This line silences flake warnings load_tests = load_tests noqa PLW Not thread-safe decorator runs decorated test once default dtype being torch float again default dtype being torch double float_double_default_dtype fn wraps fn wrapped_fn args kwargs set_default_dtype torch float fn args kwargs set_default_dtype torch double fn args kwargs wrapped_fn TestTypePromotion TestCase In-place operations don t promote ` int+float - float ` ` int add_ float ` rejected error Promoting inplace would require re-allocating copying memory tensor data since element size could change https github com pytorch pytorch issues float_double_default_dtype test_inplace device int_tensor = torch ones dtype=torch int device=device assertRaisesRegex RuntimeError can t cast lambda int_tensor add_ expected = torch ones dtype=torch int device=device long_tensor = torch ones dtype=torch int device=device int_tensor add_ long_tensor int_tensor add_ three = expected + assertEqual int_tensor three assertEqual int_tensor dtype torch int bool_tensor = torch tensor dtype=torch bool device=device uint _tensor = torch tensor dtype=torch uint device=device We treat bool separate category which means uint cannot cast bool assertRaisesRegex RuntimeError can t cast lambda bool_tensor add_ uint _tensor We allow demotion signed unsigned unlike numpy because We don t want performance penalty inspecting scalar values We don t want signed considered distinct category promotion rules We don t want signed separate category because uint _tensor + would result long_tensor which what we want int _tensor = torch tensor dtype=torch int device=device uint _tensor = int _tensor float_double_default_dtype test_unsigned device dont_promote = torch ones dtype=torch uint device=device + assertEqual dont_promote dtype torch uint some basic examples float_double_default_dtype test_int_promotion device = torch ones dtype=torch int device=device b = torch ones dtype=torch int device=device c = + b assertEqual c b + b assertEqual c dtype torch int float_double_default_dtype test_float_promotion device test_promotion dtype_float dtype_double = torch ones dtype=dtype_float device=device b = torch ones dtype=dtype_double device=device c = + b assertEqual c b + b assertEqual c dtype dtype_double c = b + assertEqual c b + b assertEqual c dtype dtype_double test_promotion torch float torch double float_double_default_dtype test_complex_promotion device test_promotion dtype_float dtype_double = torch ones dtype=dtype_float device=device b = torch ones dtype=dtype_double device=device c = + b assertEqual c b + b assertEqual c dtype dtype_double c = b + assertEqual c b + b assertEqual c dtype dtype_double test_promotion torch complex torch complex = torch randn dtype=torch complex device=device assertEqual dtype torch complex wrapped number other = torch tensor dtype=torch double device=device assertEqual + other dtype torch complex make_scalar_tensor dtype make_tensor dtype=dtype device=device make_ d_tensor dtype make_tensor dtype=dtype device=device complex_scalar_tensor_test s t As per type promotion rules Complex Scalar Float Tensor - Complex Tensor Value type Float Tensor Complex Scalar Integral Tensor - Complex Tensor Value type Complex Scalar t dtype is_floating_point defaults complex bfloat expected_dtype = float_to_corresponding_complex_type_map get t dtype torch complex integral tensor isinstance s torch Tensor expected_dtype = s dtype expected_dtype = float_to_corresponding_complex_type_map torch get_default_dtype assertEqual s t dtype expected_dtype assertEqual t s dtype expected_dtype assertEqual torch result_type s t expected_dtype assertEqual torch result_type t s expected_dtype torch device device type = xla chalf supported XLA s = make_scalar_tensor dtype=torch chalf Same Value type t = make_ d_tensor dtype=torch half -D Tensor X -D Tensor complex_scalar_tensor_test s t Python Scalar X -D Tensor complex_scalar_tensor_test s item t Higher Value Type t = make_ d_tensor dtype=torch float complex_scalar_tensor_test s t complex_scalar_tensor_test s item t Special Case t = make_ d_tensor dtype=torch bfloat complex_scalar_tensor_test s t complex_scalar_tensor_test s item t Integral Tensor t = make_ d_tensor dtype=torch long complex_scalar_tensor_test s t complex_scalar_tensor_test s item t CFloat Scalar s = make_scalar_tensor dtype=torch cfloat Lower Value type than CFloat t = make_ d_tensor dtype=torch half complex_scalar_tensor_test s t complex_scalar_tensor_test s item t Higher Value type than CFloat t = make_ d_tensor dtype=torch double complex_scalar_tensor_test s t complex_scalar_tensor_test s item t Integral Tensor t = make_ d_tensor dtype=torch long -D Tensor X -D Tensor complex_scalar_tensor_test s t Python Scalar X -D Tensor complex_scalar_tensor_test s item t CDouble Scalar s = make_scalar_tensor dtype=torch cdouble Lower Value type than CDouble t = make_ d_tensor dtype=torch float complex_scalar_tensor_test s t complex_scalar_tensor_test s item t Special Case t = make_ d_tensor dtype=torch bfloat complex_scalar_tensor_test s t complex_scalar_tensor_test s item t float_double_default_dtype test_complex_scalar_mult_tensor_promotion device = j torch ones device=device = + j b = torch tensor j j device=device assertEqual b assertEqual dtype b dtype float_double_default_dtype test_add_wrapped device = torch ones dtype=torch int device=device b = c = + b assertEqual c + assertEqual c dtype torch int float_double_default_dtype test_int_to_float device = torch ones dtype=torch int device=device b = torch ones dtype=torch float device=device c = + b assertEqual c dtype torch float some examples https github com pytorch pytorch issues float_double_default_dtype test_from_issue device = torch rand dtype=torch float device=device u = torch tensor dtype=torch uint device=device assertEqual dtype torch float assertEqual u + dtype torch uint assertEqual u + dtype torch uint integer overflow wrapped number other = torch tensor dtype=torch double device=device assertEqual u + dtype torch get_default_dtype assertEqual u + other dtype torch double adding -dim tensor float doesn t promote double unless first type integral assertEqual + other dtype torch float float_double_default_dtype test_half device half = torch tensor dtype=torch float device=device assertEqual half + dtype torch float assertEqual half + dtype torch float inf default_tensor = torch tensor device=device assertEqual half + default_tensor dtype torch get_default_dtype test_bfloat device scalar bf = torch tensor dtype=torch bfloat device=device scalar bf + inf assertEqual bf + scalar dtype torch bfloat assertEqual scalar + bf bf + scalar scalar complex complex - complex - assertEqual bf + scalar dtype torch cfloat assertEqual bf + scalar scalar + bf tensor dtype all_types_and_complex_and torch half torch bfloat torch bool t = torch tensor dtype=dtype device=device assertEqual bf + t t + bf dtype torch float torch float torch float torch cfloat torch cdouble Handles bfloat x float - float promotion expected_dtype = dtype dtype = torch half torch float dtype torch chalf expected_dtype = torch cfloat dtype torch bool torch uint torch int torch int torch int torch int torch bfloat expected_dtype = torch bfloat raise AssertionError f Missing dtype dtype tested assertEqual torch promote_types dtype torch bfloat expected_dtype assertEqual torch promote_types torch bfloat dtype expected_dtype assertEqual bf + t dtype expected_dtype onlyNativeDeviceTypes test_complex_half device scalar chalf = torch tensor dtype=torch chalf device=device scalar chalf + inf assertEqual chalf scalar dtype torch chalf assertEqual scalar chalf chalf scalar scalar complex complex - complex - assertEqual chalf scalar dtype torch chalf assertEqual chalf scalar scalar chalf tensor dtypes = all_types_and_complex_and torch chalf torch half torch bfloat torch bool dtype dtypes t = torch tensor dtype=dtype device=device assertEqual chalf t t chalf dtype torch float torch chalf expected_dtype = torch chalf dtype torch float torch double torch bfloat expected_dtype = torch cdouble dtype torch double torch cfloat dtype torch cfloat torch cdouble expected_dtype = dtype dtype torch bool torch uint torch int torch int torch int torch int expected_dtype = torch chalf raise AssertionError f Missing dtype dtype tested assertEqual torch promote_types dtype torch chalf expected_dtype assertEqual torch promote_types torch chalf dtype expected_dtype assertEqual chalf t dtype expected_dtype float_double_default_dtype test_alternate_result device x = torch tensor dtype=torch float device=device o = torch tensor dtype=torch long device=device assertRaisesRegex RuntimeError can t cast lambda torch add x x out=o d = torch tensor dtype=torch double device=device torch add x x out=d assertEqual d dtype torch double x = x torch double assertEqual x + x d float_double_default_dtype test_mixed_type_backward device f = torch ones dtype=torch float requires_grad=True device=device ten = torch tensor dtype=torch double device=device tens = f ten s = tens + sum s backward expected = f grad torch double assertEqual tens expected If we don t convert returned grad_input actual input type we get error like RuntimeError Function SubBackward returned invalid gradient index - expected type \ torch FloatTensor got torch DoubleTensor f_dtypes = torch float torch double device_type == cuda f_dtypes = f_dtypes + torch half i_dtypes = torch int torch long func torch add torch sub torch rsub torch mul torch div dtype dtype itertools product f_dtypes f_dtypes + i_dtypes x = torch ones requires_grad=True dtype=dtype device=device y = torch ones dtype=dtype device=device func x y sum backward _get_test_tensor device dtype remove_zeros=False shape = dtype == torch bool tensor = torch randint int remove_zeros shape device=device dtype=dtype dtype is_floating_point dtype is_complex _th_normal_ supported CPUType Half so simpler create convert tensor = torch randn shape device=device tensor = tensor dtype remove_zeros tensor torch abs tensor = tensor = torch randint - dtype is_signed shape device=device dtype=dtype remove_zeros tensor tensor == = tensor verifies torch op first second same torch op first common_dtype second common_dtype cases where should hold float_double_default_dtype test_many_promotions device Can also include half CPU cases where will promoted supported dtype dtypes = get_all_math_dtypes cuda dtypes = get_all_math_dtypes device ops = torch add torch sub torch mul torch div torch rsub dt dt itertools product dtypes dtypes op non_contiguous itertools product ops True False common_dtype = torch promote_types dt dt common_dtype == torch half device_type == cpu continue op == torch sub common_dtype = torch bool Subtraction ` - ` operator bool tensor supported continue first = _get_test_tensor device dt second = _get_test_tensor device dt op == torch div test ops non-contiguous tensors non_contiguous first = first transpose second = second transpose assertNotEqual first stride second stride msg= some non-contiguous issues could missed tensors have same strides assertEqual first is_contiguous non_contiguous assertEqual second is_contiguous non_contiguous result = op first second expected = op first common_dtype second common_dtype assertEqual result dtype expected dtype msg=f op __name__ dt dt assertEqual result expected msg=f op __name__ dt dt float_double_default_dtype test_non_promoting_ops device x = torch ones dtype=torch double device=device assertRaises RuntimeError torch lerp x torch ones dtype=torch float device=device float_double_default_dtype test_alpha_mismatch device x = torch ones dtype=torch int device=device err = alpha must assertRaisesRegex RuntimeError err lambda torch add x x alpha= x = x torch bool assertRaisesRegex RuntimeError err lambda torch add x x alpha= assertEqual x + x torch add x x alpha=True float_double_default_dtype test_booleans device onedim = torch tensor True device=device assertEqual onedim + onedim onedim assertEqual onedim + True onedim assertEqual torch add True True True assertEqual torch add False False False assertEqual torch add False True True assertRaisesRegex RuntimeError Boolean alpha only supported lambda torch add alpha=True assertEqual torch add torch tensor True device=device torch tensor True device=device True torch tensor True device=device skipIfTorchDynamo Not TorchDynamo suitable test float_double_default_dtype test_create_bool_tensors device expected = torch tensor dtype=torch int device=device assertEqual torch arange False True device=device expected assertEqual torch arange True device=device expected expected = torch tensor dtype=torch get_default_dtype device=device assertEqual torch arange False True device=device expected expected = torch ones dtype=torch int device=device assertEqual torch arange False False device=device expected bool_tensor_lin = torch linspace False True steps= device=device int_tensor_lin = torch linspace steps= device=device assertEqual bool_tensor_lin int_tensor_lin bool_tensor_log = torch linspace False True steps= device=device int_tensor_log = torch linspace steps= device=device assertEqual bool_tensor_log int_tensor_log seems like odd behavior ints also create float tensors numpy doesn t have function assertEqual torch scalar_tensor False device=device torch tensor device=device dtypes itertools product all_types_and_complex_and torch half torch bfloat torch bool all_types_and_complex_and torch half torch bfloat torch bool test_result_type device dtypes Test result_type tensor vs tensor scalar vs scalar _get_dtype x Get dtype x x tensor If x scalar get its corresponding dtype tensor torch is_tensor x x dtype isinstance x bool torch bool isinstance x int torch int isinstance x float torch float isinstance x complex torch complex raise AssertionError f Unknown type x tensor against tensor a_tensor = torch tensor device=device dtype=dtypes a_single_tensor = torch tensor device=device dtype=dtypes a_scalar = a_single_tensor item b_tensor = torch tensor device=device dtype=dtypes b_single_tensor = torch tensor device=device dtype=dtypes b_scalar = b_single_tensor item combo = a_tensor a_single_tensor a_scalar b_tensor b_single_tensor b_scalar b itertools product combo dtype_a = _get_dtype dtype_b = _get_dtype b try result = + b except RuntimeError assertRaises RuntimeError torch promote_types dtype_a dtype_b assertRaises RuntimeError torch result_type b dtype_res = _get_dtype result a_scalar b b_scalar dtype_a == torch bool dtype_b == torch bool special case Python True + True integer assertEqual dtype_res torch int f == b == b assertEqual dtype_res torch result_type b f == b == b a_scalar b b_scalar Python internal type determination good enough case continue any b b b zip combo b belong same assertEqual dtype_res torch promote_types dtype_a dtype_b f == b == b Spot check some result type tensor against scalar including single-element tensor float_double_default_dtype test_result_type_tensor_vs_scalar device _test_spot b res_dtype assertEqual torch result_type b res_dtype assertEqual torch result_type b res_dtype _test_spot torch tensor dtype=torch half device=device torch tensor dtype=torch long device=device torch half _test_spot torch tensor dtype=torch float device=device torch tensor dtype=torch double device=device torch double _test_spot torch tensor dtype=torch int device=device torch int _test_spot torch tensor device=device torch get_default_dtype _test_spot torch tensor dtype=torch long device=device torch tensor dtype=torch int device=device torch int _test_spot torch tensor dtype=torch float device=device torch float _test_spot torch tensor dtype=torch complex device=device torch tensor dtype=torch complex device=device torch complex _test_spot torch tensor dtype=torch complex device=device torch tensor dtype=torch complex device=device torch complex _test_spot torch tensor dtype=torch bool device=device torch get_default_dtype float_double_default_dtype test_can_cast device assertTrue torch can_cast torch double torch float assertFalse torch can_cast torch float torch int float_double_default_dtype test_comparison_ops_with_type_promotion device value_for_type = torch uint torch int torch int torch int torch int torch float torch float torch float torch complex torch complex comparison_ops = dict name= lt out_op=lambda x y d torch lt x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch lt x y compare_op=operator lt dict name= le out_op=lambda x y d torch le x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch le x y compare_op=operator le dict name= gt out_op=lambda x y d torch gt x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch gt x y compare_op=operator gt dict name= ge out_op=lambda x y d torch ge x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch ge x y compare_op=operator ge dict name= eq out_op=lambda x y d torch eq x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch eq x y compare_op=operator eq dict name= ne out_op=lambda x y d torch ne x y out=torch empty dtype=torch bool device=d ret_op=lambda x y torch ne x y compare_op=operator ne op comparison_ops dt get_all_math_dtypes device dt get_all_math_dtypes device dt is_complex dt is_complex op name == eq op name == ne continue val = value_for_type dt val = value_for_type dt t = torch tensor val dtype=dt device=device t = torch tensor val dtype=dt device=device expected = torch tensor op compare_op val val dtype=torch bool out_res = op out_op t t device assertEqual out_res expected assertTrue out_res dtype == torch bool assertTrue t dtype == dt assertTrue t dtype == dt out_res = op ret_op t t assertEqual out_res expected assertTrue out_res dtype == torch bool assertTrue t dtype == dt assertTrue t dtype == dt test comparing zero dim tensor another zero dim tensor has type promotion behavior t = torch tensor val dtype=dt device=device t = torch tensor val dtype=dt device=device expected = torch tensor op compare_op val val dtype=torch bool out_res = op out_op t t device assertEqual out_res expected assertTrue out_res dtype == torch bool assertTrue t dtype == dt assertTrue t dtype == dt out_res = op ret_op t t assertEqual out_res expected assertTrue out_res dtype == torch bool assertTrue t dtype == dt assertTrue t dtype == dt XLA tests fail assertRaises complex dtypes onlyNativeDeviceTypes test_complex_assertraises device comparison_ops = dict name= lt compare_op=operator lt dict name= le compare_op=operator le dict name= gt compare_op=operator gt dict name= ge compare_op=operator ge dict name= eq compare_op=operator eq dict name= ne compare_op=operator ne op comparison_ops is_cuda = torch device device type == cuda dtypes = get_all_dtypes include_half=is_cuda include_bfloat =False include_bool=False include_complex =True dt dt itertools product dtypes dtypes dt is_complex dt is_complex op name == eq op name == ne u = torch tensor dtype=dt device=device v = torch tensor dtype=dt device=device assertRaises RuntimeError lambda torch tensor op compare_op u v dtype=torch bool float_double_default_dtype test_lt_with_type_promotion device dt get_all_math_dtypes device x = torch tensor dtype=dt device=device expected = torch tensor True dtype=torch bool device=device dt is_complex continue actual = x assertTrue actual expected assertTrue actual dtype == torch bool actual = x torch tensor device=device assertTrue actual expected assertTrue actual dtype == torch bool x = torch tensor dtype=dt device=device expected = torch tensor True dtype=torch bool device=device actual = x assertTrue actual expected assertTrue actual dtype == torch bool actual = x torch tensor device=device assertTrue actual expected assertTrue actual dtype == torch bool float_double_default_dtype test_promote_types device assertEqual torch promote_types torch float torch int torch float assertEqual torch promote_types torch float torch double torch double assertEqual torch promote_types torch int torch uint torch int assertRaisesRegex RuntimeError Promotion Float Types supported assertEqual torch promote_types torch float _e m torch float torch float assertRaisesRegex RuntimeError Promotion Float Types supported assertEqual torch promote_types torch float torch float _e m fn torch float float_double_default_dtype test_promote_self device dtype all_types_and_complex_and torch half torch bfloat torch chalf torch bool torch float _e m torch float _e m fn assertEqual torch promote_types dtype dtype dtype expectedFailureMeta float_double_default_dtype test_indexing_fail device https github com pytorch pytorch issues = torch ones dtype=torch double device=device b = torch zeros dtype=torch int device=device assertRaises RuntimeError = b unsqueeze - float_double_default_dtype test_indexing device x = torch ones dtype=torch double device=device y = torch zeros dtype=torch double device=device x = y unsqueeze - expected = torch tensor dtype=torch double device=device assertEqual x expected https github com pytorch pytorch issues tmp = torch ones dtype=torch float device=device mask = torch ones dtype=torch uint device=device result = tmp + mask expected = torch full dtype=torch float device=device fill_ assertEqual result expected float_double_default_dtype test_transpose device https github com pytorch pytorch issues = torch tensor True True False True device=device assertEqual t == t == False noqa E dtypes torch bool torch uint torch int torch int torch int torch int float_double_default_dtype test_div_promotion device dtype op torch div torch true_divide dividend = torch randn device=device dtype divisor = torch arange device=device dtype Tests tensor tensor division casting_result = dividend torch get_default_dtype divisor torch get_default_dtype assertEqual casting_result op dividend divisor Tests tensor scalar division casting_result = dividend torch get_default_dtype assertEqual casting_result op dividend onlyNativeDeviceTypes dtypes torch float torch double torch bool torch uint torch int torch int torch int torch int test_div_promotion_out device dtype op torch div torch true_divide dividend = torch randn device=device dtype divisor = torch arange device=device dtype Tests requests integer quotient fail dtype is_floating_point integral_quotient = torch empty device=device dtype=dtype assertRaises RuntimeError op dividend divisor out=integral_quotient assertRaises RuntimeError op dividend out=integral_quotient Tests requests floating quotient succeed floating_quotient = torch empty device=device dtype=dtype div_result = dividend divisor assertEqual div_result op dividend divisor out=floating_quotient assertEqual dividend op dividend out=floating_quotient dtypes torch float torch double torch bool torch uint torch int torch int torch int torch int test_div_promotion_inplace device dtype op torch Tensor div_ torch Tensor true_divide_ dividend = torch randn device=device dtype divisor = torch arange device=device dtype Tests requests integer quotient fail dtype is_floating_point assertRaises RuntimeError op dividend divisor assertRaises RuntimeError op dividend Tests requests floating quotient succeed div_result = dividend clone div_ divisor assertEqual div_result op dividend clone divisor assertEqual dividend clone div_ op dividend clone _test_sparse_op_input_tensors device dtype coalesced zeros=True t = _get_test_tensor device dtype zeros zeros dtype = torch bool ensure sparsity Bool should already have sufficient sparsity mask = _get_test_tensor device torch bool t = t mask coalesced s = t to_sparse s = t to_sparse indices = torch cat s indices s indices values = torch cat s values s values s = torch sparse_coo_tensor indices=indices values=values size=s size dtype=dtype device=device t = s to_dense assertEqual s is_coalesced coalesced assertEqual s dtype dtype assertEqual t dtype s dtype t s _get_precision dtype coalesced dtype == torch half coalesced very low precision uncoalesced float sparse tensors since ops like s + s to_dense will add four low-precision floating point values e- dtype == torch half e- uses default None _test_sparse_op op_name inplace dtype dtype device coalesced dtype is_complex dtype is_complex suffix = _ inplace err = f coalesced coalesced uncoalesced op_name + suffix dtype dtype op t t suf=None suf = suffix suf None suf getattr t op_name + suf t add_sub = op_name == add op_name == sub dense sparse = _test_sparse_op_input_tensors device dtype coalesced dense sparse = _test_sparse_op_input_tensors device dtype coalesced op_name = div common_dtype = torch result_type dense dense device_type == cpu common_dtype == torch half assertRaises RuntimeError lambda op s d Skip inplace tests would fail due inability cast output type Some these would also raise errors due being supported op inplace torch can_cast common_dtype dtype assertRaises RuntimeError lambda op dense sparse assertRaises RuntimeError lambda op sparse sparse assertRaises RuntimeError lambda op sparse dense expected = op dense clone dense precision = _get_precision expected dtype coalesced rtol = None precision None test_tensors = expected dense sparse dense sparse e d s d s = x clone x test_tensors inplace test_tensors Test op sparse sparse op_name = div sparse = op s s assertEqual sparse dtype e dtype assertEqual e sparse to_dense atol=precision rtol=rtol msg=err sparse division only supports division scalar assertRaises RuntimeError lambda op s s to_dense Test op dense sparse add_sub op_name == mul inplace e d s d s = x clone x test_tensors dense_sparse = op d s dense_sparse = dense_sparse to_dense dense_sparse is_sparse dense_sparse assertEqual e dense_sparse atol=precision rtol=rtol msg=err sparse division only supports division scalar mul Didn t find kernel dispatch operator aten _nnz assertRaises RuntimeError lambda op d s Test op sparse dense supported all ops mul add sparse dense supported Use add dense sparse instead sparse division only supports division scalar op_name = mul assertRaises RuntimeError lambda op s d No type promotions inplace operations hence suf= op s d suf= Test op sparse scalar add_sub device_type == cpu dtype == torch half inplace e d s d s = x clone x test_tensors scalar = d view d numel item sparse = op s scalar dense_scalar = op d scalar assertEqual sparse dtype dense_scalar dtype assertEqual dense_scalar sparse to_dense atol=precision rtol=rtol msg=err add sparse dense supported Use add dense sparse instead mul_cpu div_cpu implemented Half assertRaises RuntimeError lambda op s d view d numel item _run_all_tests_for_sparse_op op_name device dtypes dtype dtype itertools product dtypes dtypes inplace coalesced itertools product True False True False _test_sparse_op op_name inplace dtype dtype device coalesced onlyNativeDeviceTypes test_sparse_add device _run_all_tests_for_sparse_op add device dtypes=get_all_math_dtypes device onlyNativeDeviceTypes test_sparse_mul device _run_all_tests_for_sparse_op mul device dtypes=get_all_math_dtypes device onlyNativeDeviceTypes test_sparse_div device _run_all_tests_for_sparse_op div device dtypes= torch float torch float torch complex torch complex onlyNativeDeviceTypes test_sparse_sub device _run_all_tests_for_sparse_op sub device dtypes=get_all_math_dtypes device onlyNativeDeviceTypes dtypes torch bool torch short torch uint torch int torch long float_double_default_dtype test_sparse_div_promotion device dtype op torch div torch true_divide dividend = torch randn device=device dtype dividend_sparse = dividend to_sparse casting_result = dividend torch get_default_dtype assertEqual casting_result op dividend_sparse to_dense onlyNativeDeviceTypes dtypes torch int torch uint torch int torch int torch int test_integer_addcdiv_deprecated device dtype t = torch tensor device=device dtype=dtype assertRaisesRegex RuntimeError ^Integer division +is no longer supported + torch addcdiv t t t assertRaisesRegex RuntimeError ^Integer division +is no longer supported + torch addcdiv t t t out=t assertRaisesRegex RuntimeError ^Integer division +is no longer supported+ t addcdiv_ t t unittest skipIf TEST_NUMPY NumPy found float_double_default_dtype onlyCPU NB skip uint PyTorch doesn t implement promotion them dtypes list itertools product set numpy_to_torch_dtype_dict values - torch uint torch uint torch uint set numpy_to_torch_dtype_dict values - torch uint torch uint torch uint test_numpy_array_binary_ufunc_promotion device dtypes operator np_type = torch_to_numpy_dtype_dict dtypes torch_type = dtypes t = torch tensor device=device dtype=torch_type = np array dtype=np_type a_as_t = torch from_numpy device=device np_first True False op operator add torch add Acquires results binary ufunc type promotion try actual = op t np_first op t except Exception e actual = e try expected = op a_as_t t np_first op t a_as_t except Exception e expected = e same_result = type expected type actual expected == actual Note An undesired failure opposed expected failure both expected we know test will fail undesirable PyTorch working properly test would fail This test affected three issues see below will cause undesired failures It detects when these issues will occur updates bool accordingly undesired_failure = False A NumPy array first argument plus operator any argument torch add working intended See https github com pytorch pytorch issues np_first op operator add undesired_failure = True op torch add undesired_failure = True Expects same result undesired_failure false different result otherwise Note These cases prettyprint failing inputs make debugging test failures easier undesired_failure same_result msg = f Failure actual == expected torch type torch_type f NumPy type np_type np_first np_first default type f torch get_default_dtype fail msg undesired_failure same_result msg = f Failure actual = expected torch type torch_type f NumPy type np_type np_first np_first default type f torch get_default_dtype fail msg onlyNativeDeviceTypes test_cat_different_dtypes device dtypes = all_types_and_complex_and torch half torch bool x_dtype y_dtype itertools product dtypes dtypes x_vals y_vals = x = torch tensor x_vals device=device dtype=x_dtype y = torch tensor y_vals device=device dtype=y_dtype x_dtype torch bool x_vals = y_dtype torch bool y_vals = res_dtype = torch result_type x y expected_res = torch tensor x_vals + y_vals device=device dtype=res_dtype res = torch cat x y assertEqual res expected_res exact_dtype=True cat full empty tensor y = torch tensor device=device dtype=y_dtype res_dtype = torch result_type x y expected_res = torch tensor x_vals + device=device dtype=res_dtype res = torch cat x y assertEqual res expected_res exact_dtype=True onlyNativeDeviceTypes test_cat_out_different_dtypes device dtypes = all_types_and_complex_and torch half x_dtype y_dtype out_dtype itertools product dtypes dtypes dtypes out = torch zeros device=device dtype=out_dtype x = torch tensor device=device dtype=x_dtype y = torch tensor device=device dtype=y_dtype expected_out = torch tensor device=device dtype=out_dtype x_dtype is_floating_point y_dtype is_floating_point out_dtype is_floating_point out_dtype is_complex x_dtype is_complex y_dtype is_complex out_dtype is_complex This combinations do support type conversion different out type assertRaises TypeError torch cat x y out=out torch cat x y out=out assertEqual out expected_out exact_dtype=True Verifies unary ops require matching out types onlyNativeDeviceTypes dtypes itertools product torch int torch float torch float torch complex torch complex torch int torch float torch float torch complex torch complex test_unary_op_out_casting device dtypes t = torch tensor dtype=dtypes device=device out = torch empty dtype=dtypes device=device ops = torch neg torch floor torch ceil float_and_int_only_ops = torch floor torch ceil real_only_ops = torch floor torch ceil op ops dtypes dtypes assertRaises RuntimeError op t out=out op real_only_ops dtypes is_complex assertRaises RuntimeError op t out=out op float_and_int_only_ops dtypes is_floating_point dtypes is_complex dtypes == torch int dtypes == torch int device = meta assertRaises RuntimeError op t out=out assertEqual op t out=out op t assertEqual op t out=out out Verifies out= argument doesn t affect computation out = op op out=out produce same result onlyNativeDeviceTypes skipMeta test_computation_ignores_out device t = torch tensor dtype=torch float device=device out = torch empty dtype=torch float device=device result = torch add t t out=out assertEqual result t + t exact_dtype=False assertNotEqual result t double + t exact_dtype=False = torch tensor dtype=torch float device=device b = torch tensor dtype=torch float device=device result = torch true_divide b out=out assertEqual result b exact_dtype=False assertNotEqual result double exact_dtype=False = torch tensor dtype=torch uint device=device b = torch tensor dtype=torch uint device=device result = torch sub b out=out assertEqual result - b exact_dtype=False assertNotEqual result double - b exact_dtype=False onlyNativeDeviceTypes dtypes itertools product torch bool torch int torch float torch double repeat= test_clamp_type_promotion device dtypes dtype dtype dtype = dtypes S = make_tensor size dtype dtype == torch bool torch randint size dtype=dtype device=device dtype == torch int torch randint size dtype=dtype device=device torch randn size dtype=dtype device=device min_t = make_tensor S dtype max_t = make_tensor S dtype mins = min_t min_t min_t item maxs = max_t max_t max_t item inp = make_tensor S dtype min_v max_v itertools product mins maxs type max_v type min_v continue isinstance min_v torch Tensor min_v ndim == max_v ndim == continue d tensors go scalar overload s tested separately expected_type inp max min arg arg = max min isinstance max torch Tensor max ndim == first do maybe dimensional boundary arg arg = min max exp_type = torch result_type inp arg inp_new = torch empty_like inp dtype=exp_type torch result_type inp_new arg exp_type = expected_type inp min_v max_v exp_type = torch bool actual = torch clamp inp min_v max_v inps = x exp_type isinstance x torch Tensor x x inp min_v max_v expected = torch clamp inps inps inps assertEqual actual expected inp dtype floating_types exp_type == inp dtype actual = torch clamp_ inp min_v max_v assertEqual actual expected exact_dtype=False val mins expected_type inp val torch result_type inp val exp_type = expected_type inp val exp_type = torch bool actual = torch clamp_min inp val inps = x exp_type isinstance x torch Tensor x x inp val expected = torch clamp_min inps inps assertEqual actual dtype exp_type assertEqual actual expected inp dtype == exp_type actual = torch clamp_min_ inp val assertEqual actual expected actual = torch clamp_max inp val expected = torch clamp_max inps inps assertEqual actual expected inp dtype floating_types exp_type == inp dtype actual = torch clamp_max_ inp val assertEqual actual expected exact_dtype=False onlyNativeDeviceTypes test_ternary_out_promotion device op torch addcdiv torch addcmul dtype torch float torch cfloat prom_dtype = torch float dtype torch float torch cdouble dtype torch cfloat dtype x = torch rand device=device dtype=dtype y = torch empty device=device dtype=dtype y_promo = torch empty device=device dtype=prom_dtype op x x x out=y op x x x out=y_promo assertEqual y y_promo dtype=dtype instantiate_device_type_tests TestTypePromotion globals __name__ == __main__ run_tests