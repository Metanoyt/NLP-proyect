Owner s module inductor unittest torch torch _inductor config torch _inductor test_case run_tests TestCase torch testing _internal common_cuda TEST_CUDA MatMulModule torch nn Module __init__ super __init__ matrix = torch nn Parameter torch eye requires_grad=True forward x torch matmul x matrix torch add performs better than torch mm got chosen during tuning matmul_cpu torch Tensor b torch Tensor out torch Tensor - None torch add b out=out matmul_dup torch Tensor b torch Tensor out torch Tensor - None torch add b out=out matmul_cuda torch Tensor b torch Tensor out torch Tensor - None torch add b out=out TestInductorExternalCallable TestCase classmethod setUpClass cls super setUpClass cls _saved_config = config save_config tearDown super tearDown config load_config _saved_config test_matmul_cpu I + I == I I x = torch eye opt_fn = torch compile MatMulModule options= max_autotune True external_matmul matmul_cpu opt_fn_golden = torch compile MatMulModule options= max_autotune True torch testing assert_close opt_fn x opt_fn_golden x msg=f torch compile external_matmul = matmul_cpu failed test_matmul_dup I + I == I I x = torch eye This should only register first external call opt_fn = torch compile MatMulModule options= max_autotune True external_matmul matmul_dup matmul_dup opt_fn_golden = torch compile MatMulModule options= max_autotune True torch testing assert_close opt_fn x opt_fn_golden x msg=f torch compile external_matmul = matmul_dup failed unittest skipIf TEST_CUDA CUDA found unittest skipIf torch cuda is_available torch cuda get_device_capability Triton does support device capability test_matmul_cuda device = torch device cuda x = torch eye device=device opt_fn = torch compile MatMulModule device options= max_autotune True external_matmul matmul_cuda opt_fn_golden = torch compile MatMulModule device options= max_autotune True torch testing assert_close opt_fn x opt_fn_golden x msg=f torch compile external_matmul = matmul_cuda failed __name__ == __main__ run_tests