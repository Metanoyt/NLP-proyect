mypy allow-untyped-defs logging typing Optional torch torch _export error InternalError torch ao quantization pt e utils _filter_sym_size_users _find_q_dq_node_for_user _is_valid_annotation torch ao quantization quantizer QuantizationSpecBase torch fx passes infra pass_base PassBase PassResult logger = logging getLogger __name__ logger setLevel logging ERROR __all__ = PortNodeMetaForQDQ _METADATA_TO_PORT = stack_trace quantization_tag _QUANTIZE_OPS = torch ops quantized_decomposed quantize_per_tensor default torch ops quantized_decomposed quantize_per_tensor tensor torch ops quantized_decomposed quantize_per_channel default torch ops pt e_quant quantize_affine _DEQUANTIZE_OPS = torch ops quantized_decomposed dequantize_per_tensor default torch ops quantized_decomposed dequantize_per_tensor tensor torch ops quantized_decomposed dequantize_per_channel default torch ops pt e_quant dequantize_affine _CHOOSE_QPARAMS_OPS = torch ops quantized_decomposed choose_qparams tensor torch ops quantized_decomposed choose_qparams_symmetric tensor torch ops pt e_quant choose_qparams_affine _add_metadata to_node torch fx Node from_node torch fx Node - None from_meta = from_node meta meta_name _METADATA_TO_PORT meta_name from_meta to_node meta meta_name = from_meta meta_name _has_quant_annotation node torch fx Node - bool quantization_annotation node meta _find_choose_qparams_node node torch fx Node - Optional torch fx Node BFS look choose qparams collections deque queue = deque list node users keys while len queue n = queue popleft n op == output continue n op == call_function n target _CHOOSE_QPARAMS_OPS n k n users keys queue append k None _port_metadata_for_input_quant_nodes input_node torch fx Node node torch fx Node qspec Optional QuantizationSpecBase qspec None is_dynamic_quant = getattr qspec is_dynamic None is_dynamic_quant None is_dynamic_quant True choose_qparams_node = _find_choose_qparams_node input_node choose_qparams_node None raise ValueError f No chose qparams node found node choose_qparam_users = _filter_sym_size_users choose_qparams_node len choose_qparam_users = raise InternalError f Expecting exactly two user choose_qparams_node scale_node = choose_qparam_users pop dynamic_q_node = next iter scale_node users keys dynamic_q_node_users = _filter_sym_size_users dynamic_q_node len dynamic_q_node_users raise InternalError f Expecting single user dynamic_q_node dynamic_dq_node = dynamic_q_node_users pop _add_metadata choose_qparams_node node _add_metadata dynamic_q_node node _add_metadata dynamic_dq_node node q_node dq_node = _find_q_dq_node_for_user input_node node q_node None dq_node None add metadata all node between q_node get_attr node q_node can traced back get_attr node q_to_get_attr_nodes = q_node q_node_input = q_node args while isinstance q_node_input torch fx Node q_node_input op == call_function q_node_input target torch ops aten flatten using_ints torch ops aten permute default torch ops aten permute_copy default torch ops aten slice_copy Tensor torch ops aten squeeze dim torch ops aten squeeze_copy dim torch ops aten transpose Dimname torch ops aten transpose int torch ops aten transpose_ torch ops aten view_copy default torch ops aten view default torch ops aten _mkldnn_transpose q_to_get_attr_nodes append q_node_input q_node_input = q_node_input args isinstance q_node_input torch fx Node q_node_input op == get_attr n q_to_get_attr_nodes _add_metadata n q_node_input _add_metadata dq_node node _port_metadata_for_output_quant_nodes node torch fx Node qspec Optional QuantizationSpecBase qspec None node_users = _filter_sym_size_users node len node users == len node_users = logger warning f Expecting node have single user noqa G q_node = node_users pop q_node op = call_function q_node target _QUANTIZE_OPS logger warning f Expecting node user quantized op got q_node noqa G noqa G _add_metadata q_node node PortNodeMetaForQDQ PassBase Port metadata nodes added quantization flow For static quant these - quantizer_per_tensor default dequantize_per_tensor default - quantizer_per_channel default dequantize_per_channel default For dynamic quant these - choose_qparams tensor - quantizer_per_tensor tensor dequantize_per_tensor tensor - quantizer_per_channel default dequantize_per_channel default Rules porting metadata - Metadata ported - nn_module_stack - stack_trace - quantization_tag - Metadata NOT ported - Everything - Rules - Statically quantized patterns - Dequantize nodes inputs quantized inherit metadata consumer node - Quantize nodes outputs inherit metadata producer node - Example - Original Conv - AvgPool - Linear - Quantized Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - Linear - Q - DQ - Inner brackets specify which nodes Q DQ inherit metadata - Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - Linear - Q - DQ - Note first Q last DQ do inherit metadata any nodes - Example - Original Conv - AvgPool - Linear - AvgPool quantized - Quantized Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - Linear - Q - DQ - Inner brackets specify which nodes Q DQ inherit metadata - Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - Linear - Q - DQ - Note DQ Q nodes around AvgPool do inherit metadata AvgPool because AvgPool supposed quantized Metadata porting relies quantization_annotation nodes case AvgPool node conclude node pattern supposed quantized And subsequently decide preceding Q any should inherit metadata AvgPool - Dynamically quantized patterns - Input dynamically quantized have choose_qparams quantize dequantize nodes - For example below linear dynamically quantized while rest statically - Original Conv - AvgPool - Linear - Quantized Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - choose_params - Q - DQ - Linear - Quantized Q- DQ - Conv - Q - DQ - AvgPool - Q - DQ - choose_params - Q - DQ - Linear - Note first Q does inherit metadata any nodes NB - The best place porting metadata during observer conversion q dq This because precisely knows which quantization spec converted q dq thus where metadata should ported However since FX PT E quant workflow common code-base hurts readability quite bit Doing via separate pass helps readability code Once we able refactor PT E quant code pass should like integrated refactored variant convert step call graph_module torch fx GraphModule - PassResult node graph_module graph nodes annotation = node meta get quantization_annotation None _is_valid_annotation annotation input_qspec_map = node meta quantization_annotation input_qspec_map output_qspec = node meta quantization_annotation output_qspec input_node qspec input_qspec_map items _port_metadata_for_input_quant_nodes input_node node qspec _port_metadata_for_output_quant_nodes node output_qspec PassResult graph_module True