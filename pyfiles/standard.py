Default set benchmarks Parser notes ` parse_stmts ` - Width left Python column MUST characters - The column separator &#124; &#124; Whitespace matters ` GroupedVariants ` - ` Setup ` ` Global_Setup ` case insensitive reserved keywords populate ` setup ` ` global_setup ` every generated benchmark - To set label succeeding block add ` YOUR_LABEL ` Python ` YOUR_LABEL ` C++ mypy ignore-errors core api GroupedModules GroupedStmts GroupedVariants core types FlatIntermediateDefinition core utils flatten parse_stmts definitions setup Setup BENCHMARKS FlatIntermediateDefinition = flatten Empty no allocation GroupedStmts r torch empty r torch empty allocation GroupedStmts r torch empty r torch empty overloads GroupedVariants cpp_block=r Setup auto options_empty = c TensorOptions auto options_full = c TensorOptions dtype kFloat device kCPU auto optional_float = std make_optional kFloat TensorOptions overload empty options_empty empty options_full empty kFloat implicit conversion Faithful overload empty std nullopt std nullopt std nullopt std nullopt std nullopt empty kFloat std nullopt std nullopt std nullopt std nullopt empty optional_float std nullopt std nullopt std nullopt std nullopt Pointwise Math GroupedVariants parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- setup &#124; setup torch manual_seed _ _ &#124; torch manual_seed x = torch rand &#124; auto x = torch rand y_float = torch ones &#124; auto y_float = torch ones y_vector = torch ones &#124; auto y_vector = torch ones y_int = torch ones &#124; auto y_int = torch ones kInt dtype=torch int &#124; &#124; add &#124; add x += &#124; x += x += y_float &#124; x += y_float x += y_vector &#124; x += y_vector x += y_int &#124; x += y_int x + y_float &#124; x + y_float torch add x y_float &#124; torch add x y_float torch add x y_float out=x &#124; torch add_out out= x x y_float &#124; multiply &#124; multiply x = &#124; x = x = y_float &#124; x = y_float x = y_vector &#124; x = y_vector x = y_int &#124; x = y_int x y_float &#124; x y_float torch mul x y_float &#124; torch mul x y_float torch mul x y_float out=x &#124; torch mul_out out= x x y_float &#124; equality &#124; equality x == y_float &#124; x == y_float x == &#124; x == Data movement GroupedVariants parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- setup &#124; setup x = torch ones &#124; auto x = torch ones y = torch ones &#124; auto y = torch ones x_t = x t &#124; auto x_t = x t &#124; contiguous trivial &#124; contiguous trivial x contiguous &#124; x contiguous &#124; contiguous non-trivial &#124; contiguous non-trivial x_t contiguous &#124; x_t contiguous &#124; clone &#124; clone x clone &#124; x clone &#124; copy_ &#124; copy_ x copy_ y &#124; x copy_ y &#124; zero_ &#124; zero_ x zero_ &#124; x zero_ &#124; RNG &#124; RNG x uniform_ &#124; x uniform_ Reduction GroupedVariants parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- setup &#124; setup x = torch ones &#124; auto x = torch ones &#124; max &#124; max x max &#124; x max &#124; sum &#124; sum x sum &#124; x sum &#124; variance &#124; variance x var &#124; x var Indexing GroupedVariants parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- setup &#124; setup &#124; using namespace torch indexing torch manual_seed _ _ &#124; torch manual_seed &#124; x = torch randn &#124; auto x = torch randn y = torch randn &#124; auto y = torch randn &#124; Tensor-Scalar &#124; Tensor-Scalar x = &#124; x index_put_ x = &#124; x index_put_ x = &#124; x index_put_ &#124; Tensor-Scalar Advanced &#124; Tensor-Scalar Advanced x = &#124; x index_put_ x = &#124; x index_put_ Slice None None None x None = &#124; x index_put_ None x False = &#124; x index_put_ false x True = &#124; x index_put_ true &#124; Tensor-Tensor &#124; Tensor-Tensor x = y &#124; x index_put_ y index x = y &#124; x index_put_ y index x = y &#124; x index_put_ y index &#124; Tensor-Tensor Advanced &#124; Tensor-Tensor Advanced x = y &#124; x index_put_ y index x = y &#124; x index_put_ Slice None None None y index Slice None None None x None = y None &#124; x index_put_ None y index None x False = y False &#124; x index_put_ false y index false x True = y True &#124; x index_put_ true y index true Metadata views GroupedVariants parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- setup &#124; setup x = torch ones &#124; auto x = torch ones &#124; size &#124; size x size &#124; x sizes &#124; stride &#124; stride x stride &#124; x stride &#124; as_strided &#124; as_strided torch as_strided x &#124; torch as_strided x &#124; select &#124; select x select &#124; x select &#124; unsqueeze &#124; unsqueeze x unsqueeze &#124; x unsqueeze &#124; view &#124; view x view - &#124; x view - &#124; transpose &#124; transpose x t &#124; x t &#124; reshape &#124; reshape x reshape &#124; x reshape nn Modules py_constructor split GroupedModules f model = torch nn py_constructor f auto model = torch nn cpp_constructor setup=setup value signature= f x - y torchscript=torchscript setup torchscript py_constructor cpp_constructor Setup TRIVIAL_ D True BatchNorm d Setup TRIVIAL_ D True GroupNorm Setup TRIVIAL_ D True LayerNorm LayerNorm torch nn LayerNormOptions Setup TRIVIAL_ D True Conv d Setup TRIVIAL_ D True Conv d Setup TRIVIAL_ D True MaxPool d Setup TRIVIAL_ D True ReLU Setup TRIVIAL_ D True Sigmoid Setup TRIVIAL_ D True Linear TODO LSTM can t TorchScript d Setup TRIVIAL_ D False LSTM training simple GroupedStmts parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- = torch nn functional relu x w &#124; auto = torch nn functional relu x w y = w &#124; auto y = w Setup TRAINING value num_threads= signature=r f x w w - y torchscript=True autograd=True ensemble GroupedStmts parse_stmts r Python &#124; C++ ---------------------------------------- &#124; ---------------------------------------- = torch nn functional gelu x w &#124; auto = torch nn functional gelu x w = torch nn functional prelu y w &#124; auto = torch nn functional prelu y w z = torch nn functional normalize &#124; auto z = torch nn functional normalize torch cat &#124; torch cat p= dim= &#124; torch nn functional NormalizeFuncOptions p dim dot w &#124; dot w Setup TRAINING value num_threads= signature=r f x y w w w - z torchscript=True autograd=True InferenceMode GroupedVariants In general mixed input scenario less common so its perf can less important than pure inference tensor inputs cpp_block=r Setup auto s = torch ones Normal Tensor c InferenceMode guard auto x = torch ones Inference Tensor View torch Tensor y = x view Inplace torch Tensor y = x mul_ x Mixed torch Tensor y = x + s