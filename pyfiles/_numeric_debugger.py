copy logging collections abc Callable Sequence dataclasses dataclass typing Optional torch torch ao ns fx utils compute_sqnr torch ao quantization pt e graph_utils bfs_trace_with_node_process torch export ExportedProgram torch fx GraphModule Node torch nn functional F NUMERIC_DEBUG_HANDLE_KEY = numeric_debug_handle CUSTOM_KEY = custom log = logging getLogger __name__ generate_numeric_debug_handle ep ExportedProgram - None Attach numeric_debug_handle_id all nodes graph module given ExportedProgram like conv d squeeze conv d etc except placeholder Notice nodes like getattr out scope since they graph The graph nodes input exported program modified inplace Here s example using debug handle quantize flow ep = export_for_training eager_model example_inputs generate_numeric_debug_handle ep m = ep module quantizer = XNNPACKQuantizer m = prepare_pt e m quantizer m = convert_pt e m Sanity check input data type isinstance ep ExportedProgram raise ValueError f Expected ep ExportedProgram got type ExportedProgram unique_id = _find_max_id node torch fx Node - None nonlocal unique_id unique_id = max unique_id node meta get CUSTOM_KEY get NUMERIC_DEBUG_HANDLE_KEY _assign_debug_handle node torch fx Node - None nonlocal unique_id CUSTOM_KEY node meta node meta CUSTOM_KEY = NUMERIC_DEBUG_HANDLE_KEY node meta CUSTOM_KEY node meta CUSTOM_KEY NUMERIC_DEBUG_HANDLE_KEY = unique_id unique_id += Find max ID exists graph first case part graph has already been annotated This way we guarantee there no duplicate handle IDs bfs_trace_with_node_process ep _find_max_id unique_id += Assign debug handles all nodes graph don t have one based max ID found previous step bfs_trace_with_node_process ep _assign_debug_handle _detach x object - object detached object = None isinstance x torch Tensor detached = x detach isinstance x list tuple detached = type x _detach e e x isinstance x dict detached = k _detach e k e x items detached = x detached _tensor_shape_equals x object y object - bool isinstance x torch Tensor isinstance y torch Tensor x shape == y shape isinstance x list tuple isinstance y list tuple all _tensor_shape_equals e e e e zip x y isinstance x dict isinstance y dict all_equal = True k x all_equal = all_equal k y _tensor_shape_equals x k y k all_equal log debug Comparing non Tensors s s they must equal x y type x type y x == y _loss_fn loss Callable torch Tensor torch Tensor torch Tensor x object y object - object The returned loss will have same structure ` x ` ` y ` e g both Tensor we ll Tensor both list we ll list Tensors both dict we ll dict same key value being loss between two Tensors isinstance x torch Tensor isinstance y torch Tensor loss x torch float y torch float isinstance x list tuple isinstance y list tuple type x _loss_fn loss e e e e zip x y isinstance x dict isinstance y dict k _loss_fn loss e y k k e x items None OutputLogger torch nn Module Base capturing output values nodes GraphModule only captures Tensor output currently we can extend work other types inputs later needed Mark impure so calls will removed during DCE _is_impure = True __init__ debug_handle int node_name Optional str = None nn_module_stack Optional object = None - None super __init__ node_name = node_name nn_module_stack = nn_module_stack debug_handle = debug_handle stats list object = forward x object - object stats append _detach x x __extra_repr__ - str f debug_handle= debug_handle node_name= node_name nn_module_stack= nn_module_stack num_stats= len stats _insert_logger model GraphModule node Node debug_handle int - Node For given node adds OutputLogger observes output node all its users use OutputLogger output instead The OutputLogger will contain debug_handle which can used compare graphs after transforms avoid circular dep torch ao quantization fx utils get_new_attr_name_with_prefix add logger after node model graph inserting_after node get_new_attr_name = get_new_attr_name_with_prefix f node name _logger logger_name = get_new_attr_name model setattr model logger_name OutputLogger debug_handle node name node meta get nn_module_stack logger_node = model graph call_module logger_name node orig_users = list node users keys user_node orig_users user_node logger_node continue user_node replace_input_with node logger_node logger_node prepare_for_propagation_comparison model GraphModule - GraphModule Add output loggers node has numeric_debug_handle Args model GraphModule original model Returns model output loggers all nodes has numeric_debug_handle_id don t change original model model = copy deepcopy model n model graph nodes CUSTOM_KEY n meta NUMERIC_DEBUG_HANDLE_KEY n meta CUSTOM_KEY continue numeric_debug_handle = n meta CUSTOM_KEY NUMERIC_DEBUG_HANDLE_KEY _insert_logger model n numeric_debug_handle model recompile model dataclass frozen=True QuantizationComparisonResult actual torch Tensor ref torch Tensor property mse_loss - object loss F mse_loss property sqnr - object loss compute_sqnr loss loss_function Callable torch Tensor torch Tensor torch Tensor - object _loss_fn loss_function actual ref __repr__ - str Don t include tensors themselves they quite large print out f QuantizationComparisonResult mse_loss= mse_loss sqnr= sqnr __post_init__ - None isinstance actual torch Tensor list tuple dict raise ValueError f ` actual ` value must Tensor list tuple dict got actual isinstance ref torch Tensor list tuple dict raise ValueError f ` ref ` value must Tensor list tuple dict got ref _tensor_shape_equals ref actual raise ValueError f Cannot compare tensors different shapes ref= ref vs actual= actual dataclass frozen=True NodeAccuracySummary handle int actual_node_name str actual_module_stack str ref_node_name str ref_module_stack str results Sequence QuantizationComparisonResult _module_stack_to_str module_stack object - str Simplifies stack mod mod foo mod foo mod foo linear mod foo linear isinstance module_stack dict str module_stack module_values_list = list module_stack values len module_values_list owning_module = module_values_list - str owning_module str module_stack extract_results_from_loggers model GraphModule - dict int tuple Optional str object list object For given model extract tensors stats related information each debug handle The reason we have list object instead Tensor because output node may Tensor could nested list tuple dict well Returns A dict keyed debug_handle id values list object recorded loggers Results maps debug handle tensor list each model being compared handles dict int tuple Optional str object list object = _name module model named_children isinstance module OutputLogger len module stats handles module debug_handle = module node_name module nn_module_stack module stats handles compare_results ref_results dict int tuple Optional str object list torch Tensor actual_results dict int tuple Optional str object list torch Tensor - dict int NodeAccuracySummary Given two dict mapping ` debug_handle_id ` int list tensors map ` debug_handle_id ` ` NodeAccuracySummary ` contains comparison information like SQNR MSE etc Args ref_results Dict int Tuple str object List torch Tensor reference results each debug_handle_id actual_results Dict int Tuple str object List torch Tensor actual results each debug_handle_id Returns Dict int NodeAccuracySummary comparisons = debug_handle ref_name ref_stack ref_stats ref_results items debug_handle actual_results log debug Cannot compare handle s because wasn t found transformed model debug_handle continue actual_name actual_stack actual_stats = actual_results debug_handle try results = QuantizationComparisonResult actual=a ref=b b zip actual_stats ref_stats except Exception e Add extra information exception QuantizationComparisonResult shapes didn t match include handle node names raise ValueError f For numeric_debug_handle= debug_handle ref node ref_name actual node actual_name e comparisons debug_handle = NodeAccuracySummary handle=debug_handle actual_node_name=actual_name actual_module_stack=_module_stack_to_str actual_stack ref_node_name=ref_name ref_module_stack=_module_stack_to_str ref_stack results=results comparisons