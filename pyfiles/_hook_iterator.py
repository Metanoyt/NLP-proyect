mypy allow-untyped-defs functools inspect enum Enum torch _SnapshotState Enum r These snapshotting-related states IterDataPipes can ` NotStarted ` - allows you restore snapshot create iterator reset ` Restored ` - cannot restore again allows you create iterator without resetting DataPipe ` Iterating ` - can restore will reset you create new iterator NotStarted = Restored = Iterating = _simplify_obj_name obj - str Simplify display strings objects purpose rendering within DataPipe error messages inspect isfunction obj obj __name__ repr obj _strip_datapipe_from_name name str - str name replace IterDataPipe replace MapDataPipe _generate_input_args_string obj Generate string input arguments object signature = inspect signature obj __class__ input_param_names = set signature parameters keys result = name value inspect getmembers obj name input_param_names result append name _simplify_obj_name value join f name = value name value result _generate_iterdatapipe_msg datapipe simplify_dp_name bool = False output_string = f datapipe __class__ __name__ _generate_input_args_string datapipe simplify_dp_name output_string = _strip_datapipe_from_name output_string output_string _gen_invalid_iterdatapipe_msg datapipe This iterator has been invalidated because another iterator has been created f same IterDataPipe _generate_iterdatapipe_msg datapipe \n This may caused multiple references same IterDataPipe We recommend using ` fork ` necessary _feedback_msg = \nFor feedback regarding single iterator per IterDataPipe constraint feel free comment issue https github com pytorch data issues _check_iterator_valid datapipe iterator_id next_method_exists=False - None r Given instance DataPipe iterator ID check IDs match raises exception In case ChildDataPipe ID gets compared one stored ` main_datapipe ` well next_method_exists This case where ` IterDataPipe ` has both ` __iter__ ` ` __next__ ` The ` _valid_iterator_id ` should either never set ` None ` set most one iterator ` ` Otherwise means there multiple iterators datapipe _valid_iterator_id None datapipe _valid_iterator_id = extra_msg = \nNote exception raised inside your IterDataPipe s ` __next__ ` method raise RuntimeError _gen_invalid_iterdatapipe_msg datapipe + extra_msg + _feedback_msg hasattr datapipe _is_child_datapipe datapipe _is_child_datapipe True hasattr datapipe _check_valid_iterator_id datapipe _check_valid_iterator_id iterator_id raise RuntimeError This iterator has been invalidated because new iterator has been created f one ChildDataPipes f _generate_iterdatapipe_msg datapipe main_datapipe + _feedback_msg raise RuntimeError ChildDataPipe must have method ` _check_valid_iterator_id ` datapipe _valid_iterator_id = iterator_id raise RuntimeError _gen_invalid_iterdatapipe_msg datapipe + _feedback_msg _set_datapipe_valid_iterator_id datapipe Given DataPipe updates its valid iterator ID reset DataPipe hasattr datapipe _is_child_datapipe datapipe _is_child_datapipe True hasattr datapipe _set_main_datapipe_valid_iterator_id datapipe _set_main_datapipe_valid_iterator_id reset called within method when appropriate raise RuntimeError ChildDataPipe must have method ` _set_main_datapipe_valid_iterator_id ` datapipe _valid_iterator_id None datapipe _valid_iterator_id = datapipe _valid_iterator_id += datapipe reset datapipe _valid_iterator_id hook_iterator namespace r Define hook applied all ` __iter__ ` metaclass ` _DataPipeMeta ` This done purpose profiling checking iterator still valid profiler_record_fn_context datapipe hasattr datapipe _profile_name datapipe _profile_name = _generate_iterdatapipe_msg datapipe simplify_dp_name=True torch autograd profiler record_function datapipe _profile_name IteratorDecorator r Wrap iterator modifying its ` __next__ ` method This decorator applied DataPipes which ` __iter__ ` method NOT generator function Those ` __iter__ ` method commonly returns ` ` necessarily __init__ iterator datapipe iterator_id has_next_method iterator = iterator datapipe = datapipe iterator_id = iterator_id _profiler_enabled = torch autograd _profiler_enabled Check ` __iter__ ` returns ` ` ` DataPipe ` has ` __next__ ` self_and_has_next_method = iterator datapipe has_next_method __iter__ _get_next Return next logic related iterator validity profiler incrementation samples yielded _check_iterator_valid datapipe iterator_id result = next iterator self_and_has_next_method datapipe _number_of_samples_yielded += result __next__ TODO Add try-except in-place reduce traceback Exception See https github com pytorch data issues _profiler_enabled profiler_record_fn_context datapipe _get_next Decided against using ` contextlib nullcontext ` performance reasons _get_next __getattr__ name getattr iterator name func = namespace __iter__ ` ` __iter__ ` ` IterDataPipe generator function inspect isgeneratorfunction func functools wraps func wrap_generator args kwargs gen = func args kwargs datapipe = args datapipe _fast_forward_iterator = datapipe _fast_forward_iterator datapipe _fast_forward_iterator = None datapipe _snapshot_state = _SnapshotState Iterating while True try yield next except StopIteration iterator_id = _set_datapipe_valid_iterator_id datapipe This ID tied each created iterator _profiler_enabled = torch autograd _profiler_enabled try _profiler_enabled profiler_record_fn_context datapipe response = gen send None response = gen send None while True datapipe _number_of_samples_yielded += request = yield response Pass through here every time ` __next__ ` called _profiler_enabled profiler_record_fn_context datapipe _check_iterator_valid datapipe iterator_id response = gen send request Decided against using ` contextlib nullcontext ` performance reasons _check_iterator_valid datapipe iterator_id response = gen send request except StopIteration except Exception e TODO Simplify traceback message skip over ` response = gen send None ` Part https github com pytorch data issues datapipe = args msg = thrown __iter__ single_iterator_msg = single iterator per IterDataPipe constraint hasattr e args __len__ full_msg = f msg datapipe __class__ __name__ _generate_input_args_string datapipe len e args == isinstance e args str If exception message doesn t exist e args = f \nThis exception full_msg msg e args single_iterator_msg e args e args = e args + f \nThis exception full_msg + e args raise namespace __iter__ = wrap_generator ` ` __iter__ ` ` IterDataPipe NOT generator function IterDataPipe iterator both ` ` __iter__ ` ` ` ` __next__ ` ` And ` ` __iter__ ` ` may may ` ` __next__ namespace If ` __next__ ` exists put wrapper around next_func = namespace __next__ functools wraps next_func wrap_next args kwargs datapipe = args torch autograd _profiler_enabled profiler_record_fn_context datapipe result = next_func args kwargs result = next_func args kwargs datapipe _number_of_samples_yielded += result namespace __next__ = wrap_next Note ` __next__ ` ` __iter__ ` do something completely unrelated It may cause issue user will violating iterator protocol Potential issue Valid iterator ID may update checked properly The number samples yielded will miscounted Regardless ` __next__ ` exists ` __iter__ ` needs wrapper track number valid iterators functools wraps func wrap_iter args kwargs iter_ret = func args kwargs datapipe = args datapipe _snapshot_state = _SnapshotState Iterating datapipe _fast_forward_iterator iter_ret = datapipe _fast_forward_iterator datapipe _fast_forward_iterator = None iter_ret iterator_id = _set_datapipe_valid_iterator_id datapipe This ID tied each created iterator IteratorDecorator iter_ret datapipe iterator_id __next__ namespace namespace __iter__ = wrap_iter