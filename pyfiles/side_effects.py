Side effect tracking management TorchDynamo s compilation system This module provides infrastructure tracking managing side effects occur during symbolic execution including - Tracking mutations objects attributes variables - Managing context changes cell variables global namespace modifications - Handling aliasing object identity preservation - Managing stack frame state local variable changes - Tracking function calls side effects Key classes - SideEffects Main container tracking all side effects during execution - MutableSideEffects Specialization mutable object tracking - AttributeMutation ValueMutation Track specific types mutations - Various specialized side effect classes different scenarios The side effect system ensures mutations performed during symbolic execution properly replayed during runtime maintaining correctness compiled code while enabling optimizations where safe collections contextlib inspect warnings weakref collections abc Generator MutableMapping types CellType typing Any Optional TYPE_CHECKING torch nn torch _dynamo variables misc AutogradFunctionContextVariable graph_break_hints utils variables bytecode_transformation bytecode_from_template create_call_function create_call_method create_instruction codegen PyCodegen exc SideEffectsError unimplemented_v source GlobalSource LocalCellSource LocalSource Source utils is_frozen_dataclass nn_module_new object_new variables base AttributeMutation AttributeMutationExisting AttributeMutationNew is_side_effect_safe ValueMutationExisting ValueMutationNew VariableTracker variables user_defined FrozenDataClassVariable TYPE_CHECKING torch _dynamo output_graph OutputGraph torch _dynamo symbolic_convert InstructionTranslatorBase torch _dynamo variables lists ListVariable _manual_dict_setitem dict_from dict Any Any dict_to dict Any Any mro_index int - None Carefully calls dict OrderedDict ` clear ` ` __setitem__ ` We have careful because we don t want trigger user defined object setitem clear The mro_index used find dict OrderedDict mro dict_class = type dict_to __mro__ mro_index dict_class clear dict_to type ignore attr-defined k v dict_from items dict_class __setitem__ dict_to k v type ignore index _manual_list_update list_from list Any list_to list Any - None list clear list_to list extend list_to list_from SideEffects Maintain records mutations provide methods apply them during code generation Handles tracking applying side effects during PyTorch Dynamo compilation maintaining Python semantics managing mutations attribute modifications other side effects occur during program execution Key responsibilities - Tracks mutations Python objects lists dictionaries need applied after FX graph run - Manages attribute modifications deletions - Handles tensor hooks backward pass state - Tracks cell variable mutations global variable changes - Ensures correct ordering application side effects after graph execution This ensures optimized code behaves identically original Python code respect object mutations other side effects id_to_variable dict int VariableTracker store_attr_mutations dict VariableTracker dict str VariableTracker keepalive list Any __init__ output_graph OutputGraph id_to_variable Optional dict int VariableTracker = None store_attr_mutations Optional dict VariableTracker dict str VariableTracker = None keepalive Optional list Any = None save_for_backward Optional list tuple AutogradFunctionContextVariable list VariableTracker = None tensor_hooks Optional dict int tuple variables TensorVariable VariableTracker variables RemovableHandleVariable str = None - None super __init__ output_graph_weakref = weakref ref output_graph id_to_variable = id_to_variable store_attr_mutations = store_attr_mutations keepalive = keepalive save_for_backward = save_for_backward tensor_hooks = tensor_hooks Used MappingProxyVariable graph break case any mutated dict _has_existing_dict_mutation = False Track Compiled Autograd final callbacks must called end Compiled Autograd backward graph Only applicable graph created Dynamo tracing Compiled Autograd ca_final_callbacks_var Optional ListVariable = None Tracks VariableTracker objects whose mutations can skipped For normal mutated variables Dynamo generates code replay reconstruct mutations after graph execution However variables set have their mutations ignored - mutations happen during execution don t need replayed generated code Used temporary mutations contexts like torch func functional_call where module parameters buffers modified later restored ignore_mutation_on_these_variables set VariableTracker = set ignore_mutations_on var VariableTracker - None Mutations variable will executed tracked typically used temporary mutations later restored ignore_mutation_on_these_variables add var stop_ignoring_mutations_on var VariableTracker - None Remove variable skip mutation set restoring normal mutation tracking var ignore_mutation_on_these_variables ignore_mutation_on_these_variables remove var __eq__ other object - bool assert isinstance other SideEffects NB do NOT test keepalive id_to_variable == other id_to_variable store_attr_mutations == other store_attr_mutations save_for_backward == other save_for_backward tensor_hooks == other tensor_hooks diff other SideEffects - Optional str id_to_variable = other id_to_variable sk_itv = id_to_variable keys ok_itv = other id_to_variable keys sk_itv = ok_itv f id_to_variable keys sk_itv = ok_itv Feel free augment more fancy diffing logic needed debugging id_to_variable unknown diff store_attr_mutations = other store_attr_mutations sk_sam = store_attr_mutations keys ok_sam = other store_attr_mutations keys sk_sam = ok_sam f store_attr_mutations keys sk_sam = ok_sam store_attr_mutations unknown diff save_for_backward = other save_for_backward save_for_backward tensor_hooks = other tensor_hooks tensor_hooks None clone - SideEffects Create shallow copy ref = output_graph_weakref assert ref None __class__ output_graph=ref id_to_variable=dict id_to_variable store_attr_mutations= k dict v k v store_attr_mutations items keepalive=list keepalive save_for_backward=self save_for_backward tensor_hooks=self tensor_hooks __contains__ item Any - bool id item id_to_variable __getitem__ item Any - VariableTracker id_to_variable id item should_allow_side_effects_under_checkpoint - bool output_graph = output_graph_weakref bool output_graph output_graph current_tx output current_tracer under_activation_checkpoint output_graph current_tx output current_tracer allow_side_effects_under_checkpoint torch _dynamo config skip_fwd_side_effects_in_bwd_under_checkpoint should_allow_externally_visible_side_effects_in_subtracer - bool output_graph = output_graph_weakref bool output_graph output_graph current_tx output current_tracer unsafe_allow_externally_visible_side_effects is_reconstructing_generator - bool output_graph = output_graph_weakref bool output_graph output_graph current_tx output current_tracer is_reconstructing_generator check_allowed_side_effect item VariableTracker - bool torch _dynamo variables misc AutogradFunctionContextVariable People do things like dim = dim inside autograd Function These benign isinstance item AutogradFunctionContextVariable True should_allow_externally_visible_side_effects_in_subtracer True should_allow_side_effects_under_checkpoint True is_reconstructing_generator This missing case where one mutates tensor See test_generator py test_reconstruct_generator_tensor_mutation raise SideEffectsError Cannot reconstruct generator variable mutations Dynamo needs fully exhaust generator which may cause unintended variable modifications assert item mutation_type None is_side_effect_safe item mutation_type TODO plumb HOP information here unimplemented_v gb_type= HigherOrderOperator Mutating variable current scope SideEffects context= explanation= This supported hints= False store_attr item VariableTracker name str value VariableTracker - None assert is_attribute_mutation item check_allowed_side_effect item item store_attr_mutations store_attr_mutations item = store_attr_mutations item name = value load_attr item VariableTracker name str deleted_ok bool = False check bool = False - VariableTracker check assert is_attribute_mutation item result = store_attr_mutations item name deleted_ok isinstance result variables DeletedVariable unimplemented_v gb_type= Attempted read deleted variable context=f item item name name explanation= hints= graph_break_hints USER_ERROR result store_cell cellvar VariableTracker value VariableTracker - None cellvar is_immutable unimplemented_v gb_type= Write immutable cell context=f cellvar cellvar value value explanation= Dynamo doesn t support writing immutable sourceless cell variables hints= graph_break_hints DIFFICULT assert isinstance cellvar variables CellVariable assert isinstance value variables VariableTracker store_attr cellvar cell_contents value load_cell cellvar VariableTracker - VariableTracker assert isinstance cellvar variables CellVariable has_pending_mutation_of_attr cellvar cell_contents load_attr cellvar cell_contents check=False cellvar pre_existing_contents cellvar pre_existing_contents unimplemented_v gb_type= Read uninitialized cell context=str cellvar explanation= Attempted read cell variable has been populated yet hints= graph_break_hints USER_ERROR load_global gvar VariableTracker name str - VariableTracker assert isinstance gvar variables VariableTracker load_attr gvar name store_global gvar VariableTracker name str value VariableTracker - None assert isinstance gvar variables VariableTracker assert isinstance value variables VariableTracker store_attr gvar name value staticmethod cls_supports_mutation_side_effects cls type - bool inspect getattr_static cls __getattribute__ None object __getattribute__ dict __getattribute__ set __getattribute__ frozenset __getattribute__ int __getattribute__ str __getattribute__ list __getattribute__ tuple __getattribute__ BaseException __getattribute__ is_attribute_mutation item VariableTracker - bool isinstance item mutation_type AttributeMutation has_pending_mutation item VariableTracker - bool is_attribute_mutation item bool store_attr_mutations get item has_pending_mutation_of_attr item VariableTracker name str - bool is_attribute_mutation item name store_attr_mutations get item is_modified item VariableTracker - bool item is_immutable False isinstance item mutation_type AttributeMutationNew ValueMutationNew True isinstance item variables UserDefinedObjectVariable Checks underlying dict tuple vt has been modified item store_attr_mutations item is_underlying_vt_modified is_attribute_mutation item item store_attr_mutations assert item mutation_type None item mutation_type is_modified type ignore attr-defined _track_obj item Any variable VariableTracker mutation_type_cls type = ValueMutationExisting - VariableTracker Start tracking existing new variable mutation id item id_to_variable raise AssertionError f variable already tracked mutation This could because you using VariableBuilder construct variable tracker f Source new object variable source f Source previously tracked object id_to_variable id item source variable mutation_type = mutation_type_cls id_to_variable id item = variable keepalive append item variable track_mutable = _track_obj track_object_existing item Any variable VariableTracker - VariableTracker _track_obj item variable mutation_type_cls=AttributeMutationExisting track_object_new cls_source Source user_cls Any variable_cls Any options dict str Any - VariableTracker user_cls torch autograd function FunctionCtx warnings catch_warnings record=True obj = torch autograd Function obj = object_new user_cls variable = variable_cls obj mutation_type=AttributeMutationNew cls_source options id_to_variable id obj = variable keepalive append obj variable get_variable_cls user_cls type - type torch overrides TorchFunctionMode variables ctx_manager GenericContextWrappingVariable variables torch_function TorchFunctionModeVariable variables user_defined is_forbidden_context_manager variable_cls type variables UserDefinedObjectVariable = variables UserDefinedObjectVariable issubclass user_cls TorchFunctionMode TorchFunctionModeVariable is_supported_torch_function_mode user_cls variable_cls = TorchFunctionModeVariable hasattr user_cls __enter__ hasattr user_cls __exit__ is_forbidden_context_manager user_cls variable_cls = GenericContextWrappingVariable issubclass user_cls torch nn Module variable_cls = variables UnspecializedNNModuleVariable issubclass user_cls dict collections OrderedDict variable_cls = variables UserDefinedDictVariable issubclass user_cls set frozenset variable_cls = variables UserDefinedSetVariable issubclass user_cls tuple variable_cls = variables UserDefinedTupleVariable issubclass user_cls list variable_cls = variables UserDefinedListVariable issubclass user_cls MutableMapping variable_cls = variables MutableMappingVariable is_frozen_dataclass user_cls variable_cls = FrozenDataClassVariable issubclass user_cls BaseException variable_cls = variables UserDefinedExceptionObjectVariable assert issubclass variable_cls variables UserDefinedObjectVariable variable_cls get_example_value base_cls_vt VariableTracker cls_vt VariableTracker init_args list VariableTracker - Any user_cls = cls_vt value type ignore attr-defined issubclass user_cls torch nn Module TODO anijain - Is possible remove specialization obj = nn_module_new user_cls isinstance base_cls_vt variables BuiltinVariable base_cls = base_cls_vt fn isinstance base_cls_vt variables UserDefinedClassVariable base_cls = base_cls_vt value raise RuntimeError f Unexpected base_cls_vt base_cls_vt assert variables UserDefinedClassVariable is_supported_new_method base_cls __new__ TODO anijain - Consider adding get_example_value method each VT get example value all args As we expand scope other __new__ methods we might need call __new__ init_args like functools partial init_args = arg get_example_value arg init_args obj = base_cls __new__ user_cls init_args obj = base_cls __new__ user_cls obj track_new_user_defined_object base_cls_vt VariableTracker cls_vt VariableTracker init_args list VariableTracker - VariableTracker Creates UserDefinedObjectVariable its subclass variable tracker mark attribute mutation tracking Also records variable trackers call __new__ method reconstruction Roughly reconstruction looks like base_cls_vt __new__ user_cls init_args cls_source = cls_vt source user_cls = cls_vt value type ignore attr-defined variable_cls = get_variable_cls user_cls obj = get_example_value base_cls_vt cls_vt init_args variable = variable_cls obj cls_source=cls_vt source base_cls_vt=base_cls_vt init_args=init_args mutation_type=AttributeMutationNew cls_source id_to_variable id obj = variable keepalive append obj variable track_cell_new - VariableTracker obj = object variable = variables CellVariable mutation_type=AttributeMutationNew id_to_variable id obj = variable keepalive append obj variable track_cell_existing source Optional Source cell CellType contents VariableTracker - VariableTracker variable = variables CellVariable We don t support mutation cell without source because we need source properly codegen mutations mutation_type=None source None AttributeMutationExisting pre_existing_contents=contents source=source id_to_variable id cell = variable keepalive append cell variable track_global_existing source Source item Any - VariableTracker variable = variables NewGlobalVariable mutation_type=AttributeMutationExisting source=source id_to_variable id item = variable keepalive append item variable track_save_for_backward ctx VariableTracker args list VariableTracker - None assert isinstance ctx variables AutogradFunctionContextVariable save_for_backward append ctx args track_runahead_tensor_and_symvar_side_effects other SideEffects - None In higher order ops we want keep track tensors seen speculate_subgraph so we don t lift them again new input other speculate_subgraph root tracer other_item other keepalive other_id = id other_item other_variable = other id_to_variable other_id other_id id_to_variable isinstance other_variable variables TensorVariable variables SymNodeVariable track_object_existing other_item other_variable prune_dead_object_new tx InstructionTranslatorBase - None Avoid VT cycles e g recursive function visited set VariableTracker = set live_new_objects set VariableTracker = set visit var VariableTracker - None var visited visited add var Object may have been mutated store mutation isinstance var mutation_type AttributeMutationNew live_new_objects add var It s possible we have mutated value variable another one The new value store_attr_mutations Also recurse through new value detect alive AttributeMutationNew var store_attr_mutations VariableTracker visit visit noqa F store_attr_mutations var is_live var VariableTracker - bool isinstance var mutation_type AttributeMutationNew var live_new_objects True pre_existing_vars = var var id_to_variable values isinstance var mutation_type AttributeMutationNew The only live side effects come returns tx stack any intermediates during graph break tx symbolic_locals mutation pre-existing variables Recursively visit Variables see any them have been mutated init_live_vars = gather stack symbolic_locals all tx s up chain cur_tx Optional InstructionTranslatorBase = tx while cur_tx None init_live_vars extend cur_tx stack cur_tx symbolic_locals cur_tx parent None non-root tx es also keep cells freevars alive so they get codegen d properly TODO see we could prune dead cells - cell pruning information needs forwarded resume function creation well assert cur_tx post_prune_cell_and_freevars None init_live_vars append cur_tx post_prune_cell_and_freevars cur_tx = cur_tx parent VariableTracker visit visit TODO track all possible sources init_live_vars + pre_existing_vars tx output backward_state tensor_hooks Manually release self-referential function which indirectly captures certain ` VariableTracker ` affects parts PT test logic sensitive when certain objects get released del visit NB cell variable handling tricky cell variables must stay alive any NestedUserFunctionVariable live visit -ing NestedUserFunctionVariable visits closures field which we will see we need keep any mutations cell variables alive id_to_variable = k v k v id_to_variable items is_live v store_attr_mutations = k v k v store_attr_mutations items is_live k mutation var VariableTracker - None var ignore_mutation_on_these_variables check_allowed_side_effect var isinstance var mutation_type ValueMutationExisting var mutation_type is_modified = True var source isinstance var variables ConstDictVariable isinstance var variables SetVariable _has_existing_dict_mutation = True has_existing_dict_mutation - bool _has_existing_dict_mutation _get_modified_vars - list VariableTracker var var id_to_variable values is_modified var codegen_save_tempvars cg PyCodegen - None We must codegen modified VT their source default so mutation aliasing properly accounted Since newly constructed objects don t have source we manually codegen their construction store them newly assigned local source Note ` ValueMutationNew ` isn t tracked SideEffects var _get_modified_vars isinstance var mutation_type AttributeMutationNew assert var source None continue isinstance var variables CellVariable Cells created root frame created either ` MAKE_CELL ` them being ` co_cellvars ` so we only emit ` make_cell ` non-root-frame cells here TODO generalize so we never need call ` make_cell ` var local_name None cg add_push_null lambda cg load_import_from utils __name__ make_cell cg extend_output create_call_function False cg add_cache var var source = LocalSource cg tempvars var type ignore attr-defined var source None pyrefly ignore bad-assignment var source = LocalCellSource var local_name isinstance var variables TensorVariable NOTE historical reasons we never assigned local sources newly constructed tensor object so we keep way They always loaded output fx graph so one can think having OutputGraphSource codegen purposes However tensor subclass objects different because reconstruction logic ` PyCodegen ` loads data tensor graph output then calls ` as_subclass ` meaning we must assign source ensure we only reconstruct one subclass instance isinstance var variables torch_function TensorWithTFOverrideVariable Don t codegen temp source assigned st pass cg var allow_cache=False cg add_cache var ` add_cache ` generates STORE consumes TOS we never cleared TODO move call into ` add_cache ` cg clear_tos var source = LocalSource cg tempvars var isinstance var variables AutogradFunctionContextVariable unimplemented_v gb_type= AutogradFunctionContextVariable escaped Dynamo-traced region context= explanation= We cannot reconstruct torch autograd Function s context object hints= Reconstruct bytecode base_cls __new__ user_cls args isinstance var variables UserDefinedObjectVariable load_new_method - None pyrefly ignore missing-attribute assert var base_cls_vt None cg var base_cls_vt type ignore attr-defined cg extend_output cg create_load_attr __new__ cg add_push_null load_new_method cg add_push_null lambda cg load_import_from utils __name__ object_new assert var mutation_type cls_source None cg var mutation_type cls_source Generate args __new__ method arg var init_args type ignore attr-defined cg arg Call __new__ method cg extend_output create_call_function + len var init_args False type ignore attr-defined cg add_cache var var source = LocalSource cg tempvars var ctx args save_for_backward cg ctx source cg load_method save_for_backward arg args cg arg cg extend_output create_call_method len args create_instruction POP_TOP register_hook tensor variables TensorVariable hook VariableTracker handle variables RemovableHandleVariable name str - None assert isinstance tensor variables TensorVariable assert isinstance hook variables VariableTracker assert isinstance handle variables RemovableHandleVariable handle is_mutable assert hasattr torch Tensor name idx = len tensor_hooks keys duplicate index possible because remove_hook while idx tensor_hooks idx += tensor_hooks idx = tensor hook handle name assert handle idx handle idx = idx remove_hook idx int - None del tensor_hooks idx codegen_hooks cg PyCodegen - None tensor hook handle name tensor_hooks values Note On tensor register_hook register_hook tensor AKA backward hooks have slightly nuanced differences how they implemented when comes hooks objects sources inputs params vs objects without sources intermediaries For tensors source we bypass direct inclusion register_hook calls graph Instead these tracked stashed global variable enabling their association tensors residuals During dynamo s frame creation these hooks invoked seamlessly known reconstructible fetch-able tensors Because source indicates knowledge object outside torch compile region because we running residuals firmly before backward can run sound invoke ` register_hook ` known tensor For tensors without source we support limited subset hooks Global functions only compiled_autograd must enabled we will graph break Handling Handle When user retains register_hook result handle we intercept STORE_FAST operation record user-designated local variable name This ensures reconstructed bytecode retains name If no handle defined we simply pop generated value keep stack intact Dynamo Tensor Hooks Workflow - Functions passed register_hook lifted globally - For tensors sources - In side_effects phase codegen we iterate over tensors hooks - Generate tensor - Issue register_hook call tensor linking globally stored function - Incorporate handle one established eager phase - For tensors without sources - We don t generate any instructions registering hook - Handles intermediary hooks NYI - We produce call function utilizes trace_wrapped higher order op closing over - We then manually insert call function above into graph - The handle s exact user-specified name user_code_variable_name discerned associated during STORE_FAST assert tensor source Hooks non input tensors NYI - should get here gen_fn - None cg tensor cg extend_output cg create_load_attr name cg add_push_null gen_fn cg hook cg extend_output create_call_function False Adding handle cache means RemovableHandleVariable reconstruct will associated value register_hook This consumes top stack cg add_cache handle get_ca_final_callbacks_var - variables ListVariable variables base ValueMutationNew ca_final_callbacks_var None ca_final_callbacks_var = variables ListVariable mutation_type=ValueMutationNew ca_final_callbacks_var codegen_update_mutated cg PyCodegen - None suffixes = var _get_modified_vars isinstance var variables ListVariable old = new cg var allow_cache=False Don t codegen via source cg var source type ignore attr-defined cg extend_output cg create_load_const None cg create_load_const None create_instruction BUILD_SLICE arg= suffixes append create_instruction STORE_SUBSCR isinstance var variables lists DequeVariable For limited maxlen order operations matter side effect we currently don t track order so no support isinstance var maxlen variables ConstantVariable var maxlen value None unimplemented_v gb_type= Side effect existing deque limited maxlen context= explanation= This supported hints= Don t use deque ` maxlen ` specified old extend new runs last cg var source cg load_method extend cg var allow_cache=False Don t codegen via source suffixes append create_call_method create_instruction POP_TOP old clear runs first cg var source cg load_method clear suffixes append create_call_method create_instruction POP_TOP isinstance var variables ConstDictVariable Reconstruct works follow Skip codegen there no new items codegen each pair key value create new dictionary pairs key values above clear original dictionary + only key removed input dict update original dictionary dict created var has_new_items cg var source type ignore attr-defined cg load_method update cg var allow_cache=False Don t codegen via source var should_reconstruct_all cg var source type ignore attr-defined cg load_method clear suffixes append create_call_method update create_instruction POP_TOP var should_reconstruct_all clear will appear before update suffixes applied reverse order suffixes append create_call_method clear create_instruction POP_TOP isinstance var variables torch_function TorchFunctionModeStackVariable Needed finally block stack restoration cg add_push_null lambda cg load_import_from utils __name__ get_torch_function_mode_stack cg call_function False name = variables torch_function get_prev_stack_var_name cg code_options co_varnames += name cg append_output create_instruction STORE_FAST argval=name cg add_push_null lambda cg load_import_from utils __name__ set_torch_function_mode_stack cg foreach var symbolic_stack cg append_output create_instruction BUILD_LIST arg=len var symbolic_stack cg call_function False cg append_output create_instruction POP_TOP isinstance var variables CellVariable var local_name None Emit more readable performant bytecode TODO generalize cells created during inlining var store_attr_mutations contents_var = load_cell var cg contents_var suffixes append cg create_store_deref var local_name is_attribute_mutation var isinstance var variables UserDefinedDictVariable pyrefly ignore bad-argument-type is_modified var _dict_vt Do dict related update manually here The store_attr mutations will applied later varname_map = name _manual_dict_setitem __code__ co_varnames varname_map name = cg tx output new_var try mro_index = type var value __mro__ index collections OrderedDict except ValueError mro_index = type var value __mro__ index dict cg extend_output create_instruction LOAD_CONST argval=mro_index create_instruction STORE_FAST argval=varname_map mro_index cg var source type ignore attr-defined cg extend_output create_instruction STORE_FAST argval=varname_map dict_to pyrefly ignore bad-argument-type cg var _dict_vt allow_cache=False Don t codegen via source cg extend_output create_instruction STORE_FAST argval=varname_map dict_from dict_update_insts = bytecode_from_template _manual_dict_setitem varname_map=varname_map suffixes append dict_update_insts create_instruction POP_TOP isinstance var variables UserDefinedListVariable pyrefly ignore bad-argument-type is_modified var _list_vt Update list updated items Be careful calling list methods overridden methods varname_map = name _manual_list_update __code__ co_varnames varname_map name = cg tx output new_var cg var source type ignore attr-defined cg extend_output create_instruction STORE_FAST argval=varname_map list_to pyrefly ignore bad-argument-type cg var _list_vt allow_cache=False Don t codegen via source cg extend_output create_instruction STORE_FAST argval=varname_map list_from list_update_insts = bytecode_from_template _manual_list_update varname_map=varname_map suffixes append list_update_insts create_instruction POP_TOP Applying mutations involves two steps Push all reconstructed objects onto stack Call STORE_ATTR apply mutations Dynamo must ensure mutations applied same order original program Therefore two reverse operations occur below The first reverse operation concerns ` suffixes ` We apply suffixes reverse order due way Python handles stack In Step we push all reconstructed objects onto stack item top stack refers last attribute mutation order If fixed will apply mutations attributes reverse order To account reversal we iterate through mutable attributes reverse order name value reversed store_attr_mutations get var items isinstance var variables NewGlobalVariable cg tx output update_co_names name cg value assert isinstance var source GlobalSource type ignore attr-defined suffixes append create_instruction STORE_GLOBAL argval=name isinstance value variables DeletedVariable isinstance var mutation_type AttributeMutationExisting hasattr getattr var value None name cg tx output update_co_names name cg var source suffixes append create_instruction DELETE_ATTR argval=name isinstance var variables UserDefinedObjectVariable var should_skip_descriptor_setter name cg add_push_null lambda cg load_import_from utils __name__ object_setattr_ignore_descriptor cg var source type ignore attr-defined cg variables ConstantVariable name cg value suffixes append create_call_function False create_instruction POP_TOP isinstance var variables UserDefinedObjectVariable var needs_slow_setattr __setattr__ defined object so call object __setattr__ directly cg load_import_from builtins object cg load_method __setattr__ cg var source type ignore attr-defined cg variables ConstantVariable name cg value suffixes append create_call_method create_instruction POP_TOP cg tx output update_co_names name cg value cg var suffixes append create_instruction STORE_ATTR argval=name isinstance var variables ListIteratorVariable _ range var index cg add_push_null lambda cg load_import_from utils __name__ iter_next cg var source type ignore attr-defined cg call_function False cg pop_top isinstance var variables RandomVariable set correct random seed state gen_fn - None cg var source type ignore attr-defined cg load_attr setstate cg add_push_null gen_fn cg var wrap_state var random getstate suffixes append create_call_function False setstate create_instruction POP_TOP raise AssertionError type var do all actual mutations very end handle dependencies suffix reversed suffixes cg extend_output suffix is_empty - bool any map is_modified id_to_variable values tensor_hooks save_for_backward tensor_hooks clear - None keepalive clear id_to_variable clear contextlib contextmanager allow_side_effects_under_checkpoint tx InstructionTranslatorBase - Generator None None None assert tx output current_tracer under_activation_checkpoint orig_val = tx output current_tracer allow_side_effects_under_checkpoint try tx output current_tracer allow_side_effects_under_checkpoint = True yield finally tx output current_tracer allow_side_effects_under_checkpoint = orig_val contextlib contextmanager allow_externally_visible_side_effects_in_subtracer tx InstructionTranslatorBase - Generator None None None orig_val = tx output current_tracer unsafe_allow_externally_visible_side_effects try tx output current_tracer unsafe_allow_externally_visible_side_effects = True yield finally tx output current_tracer unsafe_allow_externally_visible_side_effects = orig_val contextlib contextmanager disallow_side_effects_in_generator tx InstructionTranslatorBase - Generator None None None orig_val = tx output current_tracer is_reconstructing_generator try tx output current_tracer is_reconstructing_generator = True yield finally tx output current_tracer is_reconstructing_generator = orig_val