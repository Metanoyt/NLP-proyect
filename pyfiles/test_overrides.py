Owner s module __torch_function__ sys torch numpy np inspect functools pprint pickle collections unittest os torch testing _internal common_utils TestCase run_tests TEST_WITH_CROSSREF torch overrides handle_torch_function has_torch_function get_ignored_functions get_overridable_functions get_testing_overrides resolve_name is_tensor_method_or_property TorchFunctionMode _get_current_function_mode _get_current_function_mode_stack BaseTorchFunctionMode torch utils _mode_utils all_same_mode torch utils _pytree tree_map Tensor = torch Tensor os getenv ATEN_CPU_CAPABILITY default avx This test supported ARM print Skipping due failing when cuda build runs non cuda machine + see https github com pytorch pytorch pull example sys exit The functions below simulate pure-python torch functions torch functional namespace We use examples local file rather than any real examples implemented Python since future those examples might get reimplemented C++ speed This fake torch function allows us verify dispatch rules work same torch function implemented C++ Python foo b c=None A function multiple arguments optional argument has_torch_function b c handle_torch_function foo b c b c=c c + b + c + b bar A function one argument has_torch_function handle_torch_function bar baz b A function multiple arguments has_torch_function b handle_torch_function baz b b + b quux Used test errors raised user implementations get propagated has_torch_function handle_torch_function quux HANDLED_FUNCTIONS_DIAGONAL dispatch table DiagonalTensor __torch_function__ uses determine which override function call given torch API function The keys dictionary function names torch API values function implementations Implementations added HANDLED_FUNCTION_DIAGONAL decorating python function implements_diagonal See overrides immediately below definition DiagonalTensor usage examples HANDLED_FUNCTIONS_DIAGONAL = implements_diagonal torch_function Register torch function override DiagonalTensor This decorator takes function torch API parameter Applying decorator function adds function registered override torch function passed parameter decorator See DiagonalTensor __torch_function__ runtime dispatch implementation decorated functions immediately below DiagonalTensor usage examples functools wraps torch_function decorator func HANDLED_FUNCTIONS_DIAGONAL torch_function = func func decorator DiagonalTensor A __torch_function__ specific diagonal representation This has limited utility mostly useful verifying dispatch mechanism works expected It based ` DiagonalArray example ` _ NumPy documentation Note does inherit ` ` torch tensor ` ` interaction pytorch dispatch system happens via ` ` __torch_function__ ` ` protocol ` ` DiagonalTensor ` ` represents D tensor N rows columns has diagonal entries set value all other entries set zero The main functionality ` ` DiagonalTensor ` ` provide more compact string representation diagonal tensor than base tensor d = DiagonalTensor d DiagonalTensor N= value= d tensor tensor Note simplify testing matrix multiplication ` ` DiagonalTensor ` ` returns torch mm d d _DiagonalArray example https numpy org devdocs user basics dispatch html This defined attribute so SubDiagonalTensor below which subclasses DiagonalTensor can reuse DiagonalTensor s __torch_function__ implementation handled_functions = HANDLED_FUNCTIONS_DIAGONAL __init__ N value _N = N _i = value __repr__ f DiagonalTensor N= _N value= _i __array__ _i np eye _N tensor _i torch eye _N classmethod __torch_function__ cls func types args= kwargs=None kwargs None kwargs = func cls handled_functions NotImplemented cls handled_functions func args kwargs __eq__ other type other type _N == other _N _i == other _i implements_diagonal torch mean mean mat float mat _i mat _N implements_diagonal torch mm diagonal_mm mat mat implements_diagonal torch div diagonal_div input other out=None - implements_diagonal torch add add mat mat raise ValueError implements_diagonal foo diagonal_foo b c=None - implements_diagonal bar diagonal_bar - implements_diagonal quux diagonal_quux raise ValueError The dispatch table SubTensor s __torch_function__ implementation HANDLED_FUNCTIONS_SUB = implements_sub torch_function Register torch function override SubTensor functools wraps torch_function decorator func HANDLED_FUNCTIONS_SUB torch_function = func func decorator SubTensor torch Tensor A subclass torch Tensor use testing __torch_function__ dispatch This has property matrix multiplication returns zero s = SubTensor torch mm s s t = torch tensor torch mm s t torch mm t s torch mm t t tensor This useful testing semantics overriding torch functions working correctly classmethod __torch_function__ cls func types args= kwargs=None kwargs None kwargs = func HANDLED_FUNCTIONS_SUB NotImplemented HANDLED_FUNCTIONS_SUB func args kwargs SubTensor torch Tensor pass SubSubTensor SubTensor pass SubTensor torch Tensor pass implements_sub torch mean sub_mean mat implements_sub torch mm sub_mm mat mat - implements_sub bar sub_bar mat implements_sub torch div sub_div input other out=None NotImplemented The dispatch table SubDiagonalTensor s __torch_function__ implementation HANDLED_FUNCTIONS_SUB_DIAGONAL = implements_sub_diagonal torch_function Register torch function override SubDiagonalTensor functools wraps torch_function decorator func HANDLED_FUNCTIONS_SUB_DIAGONAL torch_function = func func decorator SubDiagonalTensor DiagonalTensor A subclass ` ` DiagonalTensor ` ` test custom dispatch This tests semantics defining ` ` __torch_function__ ` ` subclass another defines ` ` __torch_function__ ` ` The only difference compared superclass provides slightly different repr well custom implementations ` ` mean ` ` ` ` mm ` ` scaling mean factor returning ` ` mm ` ` instead ` ` DiagonalTensor ` ` does handled_functions = HANDLED_FUNCTIONS_SUB_DIAGONAL __repr__ f SubDiagonalTensor N= _N value= _i implements_sub_diagonal torch mean sub_diagonal_mean mat float mat _i mat _N implements_sub_diagonal bar sub_diagonal_bar mat implements_sub_diagonal torch mm sub_diagonal_mm mat mat implements_sub_diagonal torch div sub_diagonal_div input other out=None NotImplemented implements_sub_diagonal foo sub_diagonal_foo b c=None NotImplemented The dispatch table SubDiagonalTensor s __torch_function__ implementation HANDLED_FUNCTIONS_TENSOR_LIKE = Note _triggered wrapper Dict wraps implementations get_testing_overrides into another function _triggered slot flag The triggered flag set when implementation called WRAPPED_TRIGGERED_IMPLS = triggered_wrapper f functools wraps f wrapped args kwargs wrapped _triggered = True f args kwargs wrapped _triggered = False wrapped implements_tensor_like torch_function Register torch function override TensorLike functools wraps torch_function decorator func HANDLED_FUNCTIONS_TENSOR_LIKE torch_function = func func decorator generate_tensor_like_torch_implementations untested_funcs = testing_overrides = get_testing_overrides test test_cpp_api_parity py monkeypatches torch nn have new function sample_functional Depending what order you run pytest collection may trigger error here This hack fix problem A more proper fix make tested check test its own make sure monkeypatch only installed span relevant test deleted afterwards testing_ignore = sample_functional autocast namespace funcs get_overridable_functions items func funcs func testing_overrides func __name__ testing_ignore untested_funcs append f namespace func __name__ msg = The following functions tested __torch_function__ support please ensure there entry dict returned torch overrides get_testing_overrides function __torch_function__ override does make sense add entry tuple returned torch _overrides get_ignored_functions \n\n assert len untested_funcs == msg format pprint pformat untested_funcs func override testing_overrides items decorate overrides implements_tensor_like s torch Tensor method wrapped = triggered_wrapper override See note _triggered wrapper WRAPPED_TRIGGERED_IMPLS func = wrapped is_tensor_method_or_property func implements_sub func wrapped implements_tensor_like func wrapped generate_tensor_like_torch_implementations TensorLike A overrides full torch API This used explicitly test full torch tensor API can overridden defines __torch_function__ classmethod __torch_function__ cls func types args= kwargs=None kwargs None kwargs = func HANDLED_FUNCTIONS_TENSOR_LIKE NotImplemented In case _torch_function_ should override TensorLike objects HANDLED_FUNCTIONS_TENSOR_LIKE func args kwargs TestTorchFunctionOverride TestCase test_dtype_override MyDtype __torch_function__ args kwargs assertEqual torch empty view MyDtype test_mean_semantics Test function one argument can overridden t = DiagonalTensor t = SubTensor t = SubDiagonalTensor assertEqual torch mean t assertEqual bar t - assertEqual torch mean t assertEqual bar t assertEqual torch mean t assertEqual bar t test_has_torch_function_non_sequence assertRaisesRegex TypeError expected sequence has_torch_function object test_mm_semantics Test function multiple arguments can overridden t = DiagonalTensor t = torch eye t = SubTensor t = SubDiagonalTensor only DiagonalTensor so should always get DiagonalTensor result assertEqual torch mm t t tensor DiagonalTensor always DiagonalTensor result assertEqual torch mm t t assertEqual torch mm t t only SubTensor so should always get SubTensor result assertEqual torch mm t t - tensor SubTensor so should always get SubTensor result assertEqual torch mm t t - assertEqual torch mm t t - DiagonalTensor SubTensor unrelated classes so result depends which argument appears first assertEqual torch mm t t - assertEqual torch mm t t SubDiagonalTensor should take precedence over DiagonalTensor should behave otherwise same DiagonalTensor assertEqual torch mm t t assertEqual torch mm t t assertEqual torch mm t t assertEqual torch mm t t assertEqual torch mm t t assertEqual torch mm t t - assertEqual torch mm t t test_precedence_semantics Test semantics __torch_function__ functions take multiple arguments For functions take multiple arguments appropriate __torch_function__ implementation call determined examining types arguments The precedence order left-to-right argument list except subclasses always checked before superclasses The first result calling implementations precedence order NotImplemented returned user If all implementations NotImplemented TypeError raised All cases tested functions implemented C++ either foo baz which python functions defined above instrumented obey same dispatch rules functions torch functional DiagonalTensor has valid override SubDiagonal has override returns NotImplemented so we should call DiagonalTensor implementation returning - t = DiagonalTensor t = SubDiagonalTensor assertEqual torch div t t - assertEqual torch div t t - assertEqual foo t t - assertEqual foo t t - SubTensor has implementation returns NotImplemented well so should behave exactly like SubDiagonalTensor test above t = SubTensor assertEqual torch div t t - assertEqual torch div t t - assertEqual foo t t - assertEqual foo t t - div between SubTensor SubDiagonalTensor should raise TypeError since both have implementation explicitly returns NotImplemented assertRaises TypeError torch div t t assertRaises TypeError torch div t t assertRaises TypeError foo t t assertRaises TypeError foo t t none DiagonalTensor SubdiagonalTensor SubTensor have mul baz implementation so all ops should raise TypeError assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError torch mul t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t assertRaises TypeError baz t t test_user_implementation_raises Test errors raised user implementations propagate correctly t = DiagonalTensor t = DiagonalTensor assertRaises ValueError torch add t t assertRaises ValueError quux t test_tensor_subclass_propagation test exercises functionality described docs source notes extending rst#subclassing-torchtensor t = torch tensor t = torch tensor s = SubTensor s = SubTensor ss = SubSubTensor ss = SubSubTensor sn = SubTensor sn = SubTensor Check leaf subclass kept regardless order assertTrue isinstance s + t SubTensor assertTrue isinstance t + s SubTensor assertTrue isinstance s + s SubTensor Check indexing subclass kept assertTrue isinstance s SubTensor Check case subclass subclass assertTrue isinstance ss + ss SubSubTensor assertTrue isinstance ss + s SubSubTensor assertTrue isinstance s + ss SubSubTensor assertTrue isinstance ss + ss SubSubTensor assertTrue isinstance ss + t SubSubTensor assertTrue isinstance t + ss SubSubTensor assertTrue isinstance ss SubSubTensor Make sure unrelated trees merged assertRaises TypeError s + sn assertRaises TypeError sn + s test_base https github com szagoruyko pytorchviz issues DummyTensor torch Tensor pass = torch ones c = DummyTensor assertTrue c _is_view assertTrue c _base test_grad Previously Tensor-like objects did subclass Tensor did get wrapped into unary tuples before being passed into handle_torch_function contradiction how Tensor-likes handled NB asserts arguments get normalized into tuple before entering torch function handler could go other way beware https github com pytorch pytorch issues Dummy classmethod __torch_function__ cls func types args= kwargs=None inputs outputs = args assertEqual inputs x assertEqual outputs x - x = Dummy assertEqual torch autograd grad x x - test_pow_rpow NothingImplemented torch Tensor classmethod __torch_function__ cls func types args= kwargs=None NotImplemented RPowOnly torch Tensor classmethod __torch_function__ cls func types args= kwargs=None func torch Tensor __rpow__ - NotImplemented assertEqual NothingImplemented RPowOnly - test_torch_function_in_lists Test __torch_function__ called objects inside lists IntLike Object can used int lists __init__ value value = value torch_function_called = False __torch_function__ func types args= kwargs=None torch_function_called = True Return result makes operation succeed func __name__ == pad For pad input shape adjusted args func __name__ == layer_norm For layer_norm normalized tensor torch ones_like args func __name__ == tensordot For tensordot appropriate shape torch tensor Fallback torch tensor Test F pad which takes int list torch nn functional F x = torch randn obj = IntLike pad takes left right top bottom padding _ = F pad x obj assertTrue obj torch_function_called torch_function should called object int list Test multiple objects list obj = IntLike obj = IntLike _ = F pad x obj obj assertTrue obj torch_function_called obj torch_function_called torch_function should called least one object test_torch_function_in_float_lists Test __torch_function__ called objects inside float lists FloatLike Object can used float lists __init__ value value = float value torch_function_called = False __torch_function__ func types args= kwargs=None torch_function_called = True Return appropriate result func __name__ == layer_norm torch ones_like args torch tensor torch nn functional F x = torch randn obj = FloatLike layer_norm takes normalized_shape int float list _ = F layer_norm x obj assertTrue obj torch_function_called torch_function should called object float list test_torch_function_in_scalar_lists Test __torch_function__ called scalar objects inside lists ScalarLike Object can used scalar lists __init__ value value = value torch_function_called = False __torch_function__ func types args= kwargs=None torch_function_called = True Return scalar tensor torch tensor value __float__ float value __int__ int value Test function takes scalar lists Using torch as_tensor which can take scalar lists obj = ScalarLike obj = ScalarLike Create tensor scalar list containing torch function objects Use different operation should trigger torch_function _ = torch stack obj obj assertTrue obj torch_function_called obj torch_function_called torch_function should called scalar objects list test_torch_function_precedence_in_lists Test precedence when multiple torch function objects list call_order = HighPriority __torch_function__ func types args= kwargs=None call_order append high Delegate lower priority NotImplemented LowPriority __torch_function__ func types args= kwargs=None call_order append low Return valid result func __name__ == pad args torch tensor torch nn functional F x = torch randn high = HighPriority low = LowPriority Test both objects list call_order clear _ = F pad x high low High priority should called first assertEqual call_order high Higher priority torch_function should called first assertEqual call_order low Lower priority torch_function should called after NotImplemented test_torch_function_mixed_lists Test lists mix regular values torch function objects CountingInt call_count = __init__ value value = value classmethod reset cls cls call_count = __torch_function__ func types args= kwargs=None CountingInt call_count += Return valid result func __name__ == pad args torch tensor __index__ value torch nn functional F x = torch randn obj = CountingInt CountingInt reset Mix regular ints torch function object _ = F pad x obj assertEqual CountingInt call_count torch_function should called exactly once mixed list test_torch_function_empty_lists Test empty lists work correctly This should work without calling any torch_function x = torch randn Single element tensor Functions accept empty lists should still work torch stack empty list tensors would fail empty size lists should work result = x view Empty list means scalar assertEqual result shape torch Size Empty list should work size arguments test_torch_function_not_first_in_list Test torch_function called even when object first list IntLikeNotFirst Object torch_function won t first list __init__ value value = value torch_function_called = False __torch_function__ func types args= kwargs=None torch_function_called = True Return input tensor pad args __index__ value torch nn functional F x = torch randn Test torch_function object second item obj_second = IntLikeNotFirst _ = F pad x obj_second assertTrue obj_second torch_function_called torch_function should called when object second list Test torch_function object third item obj_third = IntLikeNotFirst _ = F pad x obj_third assertTrue obj_third torch_function_called torch_function should called when object third list Test torch_function object last item obj_last = IntLikeNotFirst _ = F pad x obj_last assertTrue obj_last torch_function_called torch_function should called when object last list test_torch_function_nested_tuple_getitem Test torch_function called getitem TF objects inside nested tuples called_functions = TorchFunctionObj Object torch_function tracks which functions called __init__ value value = value __torch_function__ func types args= kwargs=None called_functions append func __name__ For getitem tensor unchanged func __name__ == __getitem__ args Return simple result other functions torch tensor __index__ value Create tensor index x = torch randn Create torch function objects - these will INSIDE nested structure tf_obj = TorchFunctionObj tf_obj = TorchFunctionObj Clear called functions list called_functions clear Test tuple tuple where TF objects only INSIDE The outer structure regular tuples inner elements have __torch_function__ This tests recursive detection logic added recent commit x tf_obj tf_obj Assert torch_function called assertTrue len called_functions torch_function should called TF objects inside nested tuples Assert getitem called size assertIn __getitem__ called_functions getitem should called tuple indexing torch function objects inside assertNotIn size called_functions size should called - we should use getitem convert advanced indexing generate_tensor_like_override_tests cls torch testing _internal generated annotated_fn_args annotated_args test_generator func override If func corresponds torch Tensor method property is_tensor_method_or_property func Generate instance using SubTensor instance_gen SubTensor Otherwise TensorLike instance_gen TensorLike FIXME The following code does support kwonly args without defaults The fix easy one just needs save these args when generating variable annotated_args The problem one does so one finds number functions have problematic signatures native_functions yaml Fixing these would BC breaking so hence terrible hack https github com pytorch pytorch issues kwargs = hasattr func __name__ linalg_solve_triangular func __name__ kwargs = upper True func_args = is_method = is_tensor_method_or_property func _simple_type_parser func arg_name arg_type Guess valid input aten function based type argument arg_type == Tensor instance_gen arg_type == TensorList arg_type == ITensorListRef instance_gen instance_gen arg_type == c List std optional Tensor instance_gen instance_gen arg_type == IntArrayRef arg_type == SymIntArrayRef size = arg get size size == size arg_type == Scalar arg_type == bool False arg_type == Dimname arg_type == DimnameList arg_type startswith int arg_type Stream torch Stream arg_type startswith float arg_type == double arg_type Generator MemoryFormat TensorOptions None arg_type == ScalarType torch float arg_type == c string_view arg_type std string_view std string_view arg_type == SymInt TODO generate actual SymbolicInt raise RuntimeError f Unsupported argument type arg_type arg_name function func Special case doesn t have schema takes list func torch sym_sum func_args append TensorLike TensorLike func annotated_args arg annotated_args func Guess valid input aten function based type argument t = arg simple_type t = t removesuffix t == Tensor is_method arg name == See Note properties __get__ func = func __get__ instance_gen continue arg_to_add = _simple_type_parser func arg name t is_kwarg_only arg arg is_kwarg_only == str True kwargs arg name = arg_to_add func_args append arg_to_add args = inspect getfullargspec override try func_args = inspect getfullargspec func Remove annotations argspec func_args = type func_args func_args annotations None func_args = args raise RuntimeError f Override func doesn t match its argspec \n + f Original inspect signature func \n + f Override inspect signature override except TypeError pass nargs = len args args args defaults None nargs -= len args defaults func_args = instance_gen _ range nargs args varargs None func_args += instance_gen instance_gen test ret = func func_args kwargs ret None certain protocols e g ` __weakref__ ` ` __setitem__ ` This currently best check doesn t work example Tensor __add__ because redirects Tensor add See note _triggered wrapper is_method ret None assertTrue WRAPPED_TRIGGERED_IMPLS func _triggered assertEqual ret - test func override get_testing_overrides items test_method = test_generator func override func __name__ == __get__ Note properties __get__ __get__ part descriptor protocol https docs python org howto descriptor html This used properties form torch Tensor property method __get__ In case we get property name two ways This case properties defined C module = getattr func __self__ __qualname__ None This one properties defined Python module None module = Tensor + func __self__ fget __name__ Unfortunately I couldn t find way unify these two cases there no way general descriptors is_tensor_method_or_property func module = Tensor module = func __module__ module name = test_ _ format module replace _ func __name__ name = f test_ func __name__ test_method __name__ = name setattr cls name test_method generate_tensor_like_override_tests TestTorchFunctionOverride Wrapper Basic data container knows how unwrap itself __init__ data __dict__ _data = data __dict__ used_attrs = set __dict__ used_calls = set __getattr__ name name __dict__ __dict__ name used_attrs add name val = getattr _data name If s method isinstance val torch device callable val c = getattr type _data name Don t append args classmethod staticmethod c val lambda kw wrap __torch_function__ c Wrapper args=a kwargs=kw Otherwise append args lambda kw wrap __torch_function__ c Wrapper args= + kwargs=kw wrap val __setattr__ name value name __dict__ __dict__ name = value used_attrs add name setattr _data name unwrap value __setitem__ key value _data unwrap key = unwrap value __getitem__ key wrap _data unwrap key classmethod __torch_function__ cls func types args= kwargs=None kwargs None kwargs = Find instance arguments args_of_this_cls = args isinstance cls args_of_this_cls append isinstance collections abc Sequence args_of_this_cls extend el el isinstance el cls assert len args_of_this_cls args_of_this_cls used_calls add func args = unwrap tuple args kwargs = k unwrap v k v kwargs items wrap func args kwargs __add__ other __torch_function__ torch add Wrapper other __mul__ other __torch_function__ torch mul Wrapper other __sub__ other __torch_function__ torch sub Wrapper other __truediv__ other __torch_function__ torch true_divide Wrapper other __floordiv__ other __torch_function__ torch floor_divide Wrapper other __ge__ other __torch_function__ torch ge Wrapper other __gt__ other __torch_function__ torch gt Wrapper other __lt__ other __torch_function__ torch lt Wrapper other __le__ other __torch_function__ torch le Wrapper other __eq__ other __torch_function__ torch eq Wrapper other __ne__ other __torch_function__ torch ne Wrapper other __bool__ __torch_function__ torch Tensor __bool__ Wrapper __int__ __torch_function__ torch Tensor __int__ Wrapper __len__ len _data unwrap inputs necessary unwrap v type v tuple list type v unwrap vi vi v v _data isinstance v Wrapper v wrap inputs necessary wrap v type v tuple list type v wrap vi vi v Wrapper v isinstance v torch Tensor v TestEinsumOverride TestCase Regression test gh- test_wrapper x = Wrapper torch randn y = Wrapper torch randn assertEqual torch einsum i j- ij x y _data torch ger x y _data old einsum interface ` operands ` list = Wrapper torch randn b = Wrapper torch randn c = Wrapper torch randn assertEqual torch einsum ik jkl il- ij b c _data torch nn functional bilinear c b _data TestGradCheckOverride TestCase Test wrappers work gradcheck test_gradcheck torch testing _internal common_utils gradcheck gradgradcheck run_test fast_mode = wrap torch tensor dtype=torch double b = wrap torch tensor dtype=torch double requires_grad = True b requires_grad = True gradcheck torch add b raise_exception=False check_batched_grad=False fast_mode=fast_mode gradgradcheck torch add b raise_exception=False check_batched_grad=False fast_mode=fast_mode total_used_attrs = used_attrs union b used_attrs total_used_calls = used_calls union b used_calls These attributes functions below may change gradcheck implementation changes It s best aim attributes may commonly present other Tensor-likes expected_used_attrs = data dtype is_floating_point is_sparse layout new_zeros numel requires_grad requires_grad_ size stride fast_mode expected_used_attrs add is_complex expected_used_attrs add device assertEqual expected_used_attrs total_used_attrs expected_used_calls = torch Tensor new_zeros torch Tensor size torch Tensor is_floating_point torch Tensor numel torch Tensor stride torch Tensor requires_grad_ torch autograd grad torch add fast_mode expected_used_calls add torch Tensor is_complex assertEqual expected_used_calls total_used_calls run_test fast_mode=True run_test fast_mode=False TestNamedTuple TestCase Regression test gh- test_max x = torch tensor xs = x as_subclass SubTensor r = torch max x dim= rs = torch max xs dim= assertEqual type r type rs assertEqual r rs TestGradNewOnesOverride TestCase Regression test gh- test_newones t = torch tensor as_subclass SubTensor n = t new_ones assertEqual type n SubTensor TestPickle TestCase Regression test gh- test_pickle t = torch tensor as_subclass SubTensor t abcd = e t = pickle loads pickle dumps t assertIs type t SubTensor assertEqual t abcd e TestBroadcastAllOverride TestCase test gh- test_broadcast_all torch distributions utils broadcast_all = torch tensor a_w = Wrapper b = torch tensor b_w = Wrapper b c = torch tensor o_ = broadcast_all a_w b_w assertTrue isinstance o_ Wrapper assertTrue isinstance o_ Wrapper assertEqual o_ _data assertEqual o_ _data c o_ = broadcast_all a_w b assertTrue isinstance o_ Wrapper assertTrue isinstance o_ Wrapper assertEqual o_ _data assertEqual o_ _data c TestWrapTorchFunction TestCase test_wrap_torch_function A classmethod __torch_function__ cls func types args kwargs - dispatcher torch overrides wrap_torch_function dispatcher f assertEqual f A - TestIndexing TestCase Regression tests gh- test_getitem A classmethod __torch_function__ cls func types args kwargs=None - t = torch tensor assertEqual t A - assertEqual t torch tensor test_getitem_subclass A torch Tensor classmethod __torch_function__ cls func types args kwargs=None - t = torch tensor assertEqual t A - assertEqual t A - assertEqual t torch tensor test_setitem triggered = set A classmethod __torch_function__ cls func types args kwargs=None triggered add func - t = torch tensor t A = t A = assertIn Tensor __setitem__ triggered assertEqual t torch tensor test_setitem_val triggered = set A classmethod __torch_function__ cls func types args kwargs=None triggered add func - t = torch tensor t = A assertIn Tensor __setitem__ triggered assertEqual t torch tensor test_setitem_subclass triggered = set A torch Tensor classmethod __torch_function__ cls func types args kwargs=None triggered add func - t = torch tensor t A = t A = assertIn Tensor __setitem__ triggered assertEqual t torch tensor TestIterator TestCase Regression test gh- test_iterator t = torch tensor as_subclass SubTensor = iter t assertIs type next SubTensor assertIs type next SubTensor assertIs type next SubTensor TestRNN TestCase Regression test gh- test_rnn model = torch nn RNN input = Wrapper torch randn model input TestDisabledTorchFunction TestCase Regression test gh- test_parameter_does_not_prevent_dispatch MyTensor classmethod __torch_function__ cls func types args= kwargs=None called t = MyTensor t = torch nn Parameter torch rand assertEqual torch add t t called inp = torch rand assertEqual torch nn functional linear inp t t called assertEqual torch nn functional linear inp t t called TestResolveName TestCase test_resolve_name cs get_overridable_functions values c cs assertEqual eval torch overrides resolve_name c c msg=f c torch overrides resolve_name c TestTorchFunctionWarning TestCase test_torch_function_standalone_class StandaloneTorchFunctionClass classmethod __torch_function__ cls func types args= kwargs=None Return simple tensor testing torch tensor = StandaloneTorchFunctionClass Test torch_function works without warnings result = torch nn functional dropout result = torch abs assertEqual result torch tensor assertEqual result torch tensor test_torch_function_tensor_subclass TensorSubclassTorchFunctionClass torch Tensor classmethod __torch_function__ cls func types args= kwargs=None Return simple tensor testing torch tensor b = TensorSubclassTorchFunctionClass Test torch_function works without warnings result = torch nn functional dropout b result = torch abs b assertEqual result torch tensor assertEqual result torch tensor TestDisabledUserWarnings TestCase test_no_implicit_user_warning_for_deprecated_functions assertNotWarn get_ignored_functions assertNotWarn get_testing_overrides assertNotWarn get_overridable_functions assertNotWarn lambda resolve_name torch Tensor add assertNotWarn lambda is_tensor_method_or_property torch Tensor add unittest skipIf TEST_WITH_CROSSREF run crossref TestTorchFunctionMode TestCase test_basic A TorchFunctionMode __torch_function__ args kwargs - NB factory functions get overridden too x = torch randn A assertEqual torch randn - assertEqual torch add x x - assertEqual torch split None - python side assertEqual bar x - test_factory_override A TorchFunctionMode __torch_function__ args kwargs - A assertEqual torch tensor - assertEqual torch sparse_coo_tensor - assertEqual torch sparse_csr_tensor - assertEqual torch sparse_coo_tensor check_invariants=False - assertEqual torch sparse_csr_tensor check_invariants=False - assertEqual torch as_tensor - test_modes_handle_first A TorchFunctionMode __torch_function__ args kwargs - x = SubTensor A assertEqual torch neg x - assertEqual torch mean x - assertEqual torch mm x x - assertEqual bar x - test_modes_return_notimplemented MyMode TorchFunctionMode __torch_function__ args kwargs NotImplemented x = SubTensor MyMode assertEqual torch mean x assertEqual torch mm x x - assertEqual bar x assertRaisesRegex TypeError r SubTensor lambda assertEqual torch max x x test_with_mode ErrorA RuntimeError pass A TorchFunctionMode __torch_function__ args kwargs raise ErrorA assertRaises ErrorA A torch empty test_with_mode_created_separately ErrorA RuntimeError pass A TorchFunctionMode __torch_function__ args kwargs raise ErrorA x = A assertRaises ErrorA x torch empty test_with_nested_modes out = A TorchFunctionMode __init__ msg msg = msg __torch_function__ func _ args= kwargs=None kwargs None kwargs = out append msg func args kwargs A layer A layer torch empty assertEqual out layer layer test_nested_same_mode out = A TorchFunctionMode __init__ msg msg = msg __torch_function__ func _ args= kwargs=None kwargs None kwargs = out append msg func args kwargs A layer torch empty assertEqual out layer layer test_error_using_class_method_on_mode A TorchFunctionMode classmethod __torch_function__ cls func _ args= kwargs=None func args kwargs x = torch tensor assertRaisesRegex RuntimeError classmethod supported please make plain method A x + x test_restacking_with_ancestor A TorchFunctionMode pass A A x pass x pass test_get_cur_mode A TorchFunctionMode __torch_dispatch__ func types args= kwargs=None pass A mode assertEqual _get_current_function_mode mode mode A mode assertEqual _get_current_function_mode mode test_get_mode_stack A TorchFunctionMode __torch_dispatch__ func types args= kwargs=None pass assertEqual _get_current_function_mode_stack A mode assertEqual _get_current_function_mode_stack mode mode A mode assertEqual _get_current_function_mode_stack mode mode test_all_same_mode A TorchFunctionMode pass x = A y = A assertTrue all_same_mode x x x assertFalse all_same_mode x None assertFalse all_same_mode x y test_nested_modes_with_python_has_torch_function called = A TorchFunctionMode __torch_function__ func types args= kwargs=None called append A kwargs = kwargs None kwargs func args kwargs B TorchFunctionMode __torch_function__ func types args= kwargs=None called append B kwargs = kwargs None kwargs func args kwargs x = torch randn A B y = bar x assertEqual y x assertEqual called B A test_reentrant_mode_idiom log = A TorchFunctionMode __torch_function__ func types args= kwargs=None kwargs None kwargs = log append func func torch sub input other = args assert kwargs torch add input other alpha=- func args kwargs x = torch randn y = torch randn A torch sub x y add hits torch function again assertEqual log torch sub torch add test_nn_parse_to This failed because parser thinks function called s actually called _parse_to called = False A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called = True func args kwargs A torch _C _nn _parse_to cpu assertTrue called test_getitem_call This failed because parser thinks function called s actually called _parse_to called = False A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called = True func args kwargs = torch zeros b = torch tensor A b assertTrue called test_distributions_bernoulli This failed because improper use has_torch_function when is_tensor_like should have been used instead inside broadcasting logic called distributions Bernoulli doesn t matter per se called = False A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called = True func args kwargs A torch distributions Bernoulli assertTrue called test_mode_notimplemented_loop Default tensor subclass implementation disables torch function when we redispatch mode we must treat objects eligible called = A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called += The first time we call mode sees active type doesn t know how deal The second time we re instructed treat tensor so we keep going I m entirely clear subclasses disappearing types correct way do any t torch Tensor t types NotImplemented func args kwargs B torch Tensor pass b = B A r = torch neg b assertIs type r B assertEqual called called = A r = bar b assertIs type r B assertEqual called test_disable_subclass_not_mode called = False A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called = True func args kwargs B torch Tensor pass x = B torch randn A torch _C DisableTorchFunctionSubclass assertNotIsInstance torch sum x B assertTrue called test_disable_subclass_mode called = False A TorchFunctionMode __torch_function__ func types args= kwargs=None nonlocal called kwargs None kwargs = called = True func args kwargs B torch Tensor pass x = B torch randn A torch _C DisableTorchFunction assertNotIsInstance torch sum x B assertFalse called test_disable_enable_subclass A torch Tensor pass x = A torch randn torch _C DisableTorchFunctionSubclass g = torch _C _EnableTorchFunction try assertIsInstance torch sum x A finally del g test_disable_enable_torch_function_ctx A torch Tensor pass x = A torch randn torch _C DisableTorchFunction torch overrides _enable_torch_function assertIsInstance torch sum x A test_torch_function_all_disabled_api torch _C _is_torch_function_all_disabled state = _is_torch_function_all_disabled assertFalse state torch _C DisableTorchFunction state = _is_torch_function_all_disabled assertTrue state state = _is_torch_function_all_disabled assertFalse state torch _C DisableTorchFunctionSubclass state = _is_torch_function_all_disabled assertFalse state test_subclass_hash DiagTensor torch Tensor __init__ diag _diag = diag classmethod __torch_function__ cls func types args= kwargs=None kwargs = kwargs get_full_matrices t isinstance t DiagTensor torch diag_embed t _diag t func tree_map get_full_matrices args tree_map get_full_matrices kwargs d = torch rand = DiagTensor d assertEqual + torch diag_embed d + If hash function returning same value would fail inside ` Tensor __eq__ ` If __hash__ going through torch_function implementation above would wrong would compute hash temporary Tensor thus ensuring uniqueness hash we rely Tensors s = set s add s add DiagTensor d test_custom_device_type CustomDeviceContext TorchFunctionMode __torch_function__ func types args= kwargs=None kwargs = kwargs func == torch device args isinstance args int args = xla args isinstance kwargs get device int kwargs device = f xla kwargs get device func args kwargs CustomDeviceContext d_args = torch device assertEqual d_args type xla assertEqual d_args index d_kwargs = torch device device= assertEqual d_kwargs type xla assertEqual d_kwargs index test_device_context_semantics torch _C _len_torch_function_stack torch utils _device DeviceContext try torch set_default_device cuda get_stack torch _C _get_function_stack_at i i range _len_torch_function_stack base_mode = BaseTorchFunctionMode base_mode torch set_default_device cpu stack = get_stack assertIsInstance stack DeviceContext assertEqual stack device torch device cpu stack = get_stack assertIsInstance stack DeviceContext assertEqual stack device torch device cpu finally torch set_default_device None __name__ == __main__ run_tests