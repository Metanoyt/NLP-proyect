__future__ annotations math os subprocess pathlib Path typing TYPE_CHECKING tools stats import_test_stats get_disabled_tests tools testing test_run ShardedTest TestRun try torch testing _internal common_cuda SM OrLater torch testing _internal common_utils TEST_CUDA except ImportError TEST_CUDA = False SM OrLater = False TYPE_CHECKING collections abc Callable Sequence REPO_ROOT = Path __file__ resolve parents IS_MEM_LEAK_CHECK = os getenv PYTORCH_TEST_CUDA_MEM_LEAK_CHECK == BUILD_ENVIRONMENT = os getenv BUILD_ENVIRONMENT NUM_PROCS_FOR_SHARDING_CALC must remain consistent across all shards job ensure sharding consistent NUM_PROCS actual number procs used run tests If they equal only consequence should unequal shards IS_ROCM = os path exists opt rocm NUM_PROCS = IS_MEM_LEAK_CHECK TEST_CUDA SM OrLater NUM_PROCS_FOR_SHARDING_CALC = NUM_PROCS IS_ROCM IS_MEM_LEAK_CHECK THRESHOLD = minutes See Note ROCm parallel CI testing Special logic ROCm GHA runners query number GPUs available torch version hip available check ROCm self-hosted runner Must check ROCm runner another way We look opt rocm directory IS_ROCM IS_MEM_LEAK_CHECK try This same logic used GHA health check see github templates common yml j lines = subprocess check_output rocminfo encoding= ascii strip split \n count = line lines gfx line count += assert count there must least GPU Limiting GPUs PROCS NUM_PROCS = min count except subprocess CalledProcessError The safe default ROCm GHA runners run tests serially NUM_PROCS = ShardJob __init__ - None serial list ShardedTest = parallel list ShardedTest = get_total_time - float Default value which substitute test has no time procs = _ range NUM_PROCS_FOR_SHARDING_CALC test parallel min_index = procs index min procs procs min_index += test get_time time = max procs + sum test get_time test serial time convert_to_tuple - tuple float list ShardedTest get_total_time serial + parallel get_with_pytest_shard tests Sequence TestRun test_file_times dict str float test_class_times dict str dict str float &#124; None - list ShardedTest sharded_tests list ShardedTest = test tests duration = get_duration test test_file_times test_class_times duration duration THRESHOLD num_shards = math ceil duration THRESHOLD i range num_shards sharded_tests append ShardedTest test i + num_shards duration num_shards sharded_tests append ShardedTest test duration sharded_tests get_duration test TestRun test_file_times dict str float test_class_times dict str dict str float - float &#124; None Calculate time TestRun based given test_file_times test_class_times Returns None time unknown file_duration = test_file_times get test test_file None test is_full_file file_duration get_duration_for_classes test_file str test_classes frozenset str - float &#124; None duration float = test_class test_classes class_duration = test_class_times get test_file get test_class None class_duration None None duration += class_duration duration included = test included excluded = test excluded included_classes_duration = get_duration_for_classes test test_file included excluded_classes_duration = get_duration_for_classes test test_file excluded included_classes_duration None excluded_classes_duration None Didn t get time all classes so time unknown None included included_classes_duration assert excluded f TestRun test full file doesn t have included excluded classes file_duration None None file_duration - excluded_classes_duration shard sharded_jobs list ShardJob pytest_sharded_tests Sequence ShardedTest estimated_time_limit float &#124; None = None serial bool = False - None Modifies sharded_jobs place len sharded_jobs == assert len pytest_sharded_tests == No shards provided there tests shard round_robin_index = _get_min_sharded_job sharded_jobs list ShardJob test ShardedTest - ShardJob test time None nonlocal round_robin_index job = sharded_jobs round_robin_index len sharded_jobs round_robin_index += job min sharded_jobs key=lambda j j get_total_time _shard_serial tests Sequence ShardedTest sharded_jobs list ShardJob - None assert estimated_time_limit None Estimated time limit must provided new_sharded_jobs = sharded_jobs test tests len sharded_jobs sharded_jobs - get_total_time estimated_time_limit new_sharded_jobs = sharded_jobs - min_sharded_job = _get_min_sharded_job new_sharded_jobs test min_sharded_job serial append test _shard_parallel tests Sequence ShardedTest sharded_jobs list ShardJob - None test tests min_sharded_job = _get_min_sharded_job sharded_jobs test min_sharded_job parallel append test serial _shard_serial pytest_sharded_tests sharded_jobs _shard_parallel pytest_sharded_tests sharded_jobs calculate_shards num_shards int tests Sequence TestRun test_file_times dict str float test_class_times dict str dict str float &#124; None must_serial Callable str bool &#124; None = None sort_by_time bool = True - list tuple float list ShardedTest must_serial = must_serial lambda x True test_class_times = test_class_times Divide tests into pytest shards sort_by_time known_tests = x x tests get_duration x test_file_times test_class_times None unknown_tests = x x tests x known_tests pytest_sharded_tests = sorted get_with_pytest_shard known_tests test_file_times test_class_times key=lambda j j get_time reverse=True + get_with_pytest_shard unknown_tests test_file_times test_class_times pytest_sharded_tests = get_with_pytest_shard tests test_file_times test_class_times del tests serial_tests = test test pytest_sharded_tests must_serial test name parallel_tests = test test pytest_sharded_tests test serial_tests serial_time = sum test get_time test serial_tests parallel_time = sum test get_time test parallel_tests total_time = serial_time + parallel_time NUM_PROCS_FOR_SHARDING_CALC estimated_time_per_shard = total_time num_shards Separate serial tests parallel tests much possible maximize parallelism putting all serial tests first num_serial_shards shards The estimated_time_limit estimated time should take least filled serial shard Ex we have min serial tests min parallel tests shards procs per machine we would expect each machine take min should aim serial shards shards taking min shard taking min The estimated time limit would min This ensures first few shard contains many serial tests possible few parallel tests possible The least filled last example rd shard may contain lot both serial parallel tests estimated_time_limit = estimated_time_per_shard = estimated_time_limit = serial_time estimated_time_per_shard estimated_time_limit = estimated_time_limit = estimated_time_per_shard total_time == num_serial_shards = num_shards num_serial_shards = max math ceil serial_time total_time num_shards sharded_jobs = ShardJob _ range num_shards shard sharded_jobs=sharded_jobs num_serial_shards pytest_sharded_tests=serial_tests estimated_time_limit=estimated_time_limit serial=True shard sharded_jobs=sharded_jobs pytest_sharded_tests=parallel_tests serial=False job convert_to_tuple job sharded_jobs get_test_case_configs dirpath str - None get_disabled_tests dirpath=dirpath