Owner s module cuda multiprocessing os sys unittest unittest mock patch torch NOTE Each tests module need run brand new process ensure CUDA uninitialized prior test initiation patch dict os environ PYTORCH_NVML_BASED_CUDA_CHECK Before executing desired tests we need disable CUDA initialization fork_handler additions would otherwise triggered ` torch testing _internal common_utils ` module torch testing _internal common_utils instantiate_parametrized_tests IS_JETSON IS_WINDOWS NoTest parametrize run_tests TestCase NOTE Because ` remove_device_and_dtype_suffixes ` initializes CUDA context triggered via ` torch testing _internal common_device_type ` which imports ` torch testing _internal common_cuda ` we need bypass method here which should irrelevant parameterized tests module torch testing _internal common_utils remove_device_and_dtype_suffixes = lambda x x TEST_CUDA = torch cuda is_available TEST_CUDA print CUDA available skipping tests file=sys stderr TestCase = NoTest type ignore misc assignment noqa F torch testing _internal common_utils markDynamoStrictTest TestExtendedCUDAIsAvail TestCase SUBPROCESS_REMINDER_MSG = \n REMINDER Tests defined test_cuda_nvml_based_avail py must run process where there CUDA Driver API has been initialized Before further debugging ensure you either using run_test py have added -- subprocess run each test different subprocess setUp super setUp torch cuda _cached_device_count = None clear lru_cache method before our test staticmethod in_bad_fork_test - bool _ = torch cuda is_available torch cuda _is_in_bad_fork These tests validate behavior activation weaker NVML-based user-requested ` torch cuda is_available ` assessment The NVML-based assessment should attempted when ` PYTORCH_NVML_BASED_CUDA_CHECK ` set reverting default CUDA Runtime API check otherwise If NVML-based assessment attempted fails CUDA Runtime API check should executed unittest skipIf IS_WINDOWS Needs fork parametrize nvml_avail True False parametrize avoid_init None test_cuda_is_available avoid_init nvml_avail IS_JETSON nvml_avail avoid_init == skipTest Not working Jetson patch_env = PYTORCH_NVML_BASED_CUDA_CHECK avoid_init avoid_init patch dict os environ patch_env nvml_avail _ = torch cuda is_available patch object torch cuda _device_count_nvml return_value=- _ = torch cuda is_available multiprocessing get_context fork Pool pool in_bad_fork = pool apply TestExtendedCUDAIsAvail in_bad_fork_test os getenv PYTORCH_NVML_BASED_CUDA_CHECK == nvml_avail assertFalse in_bad_fork TestExtendedCUDAIsAvail SUBPROCESS_REMINDER_MSG assert in_bad_fork torch testing _internal common_utils markDynamoStrictTest TestVisibleDeviceParses TestCase test_env_var_parsing _parse_visible_devices val torch cuda _parse_visible_devices _pvd patch dict os environ CUDA_VISIBLE_DEVICES val clear=True _pvd rest string ignored assertEqual _parse_visible_devices gpu ampere Negatives abort parsing assertEqual _parse_visible_devices - Double mention ordinal returns empty set assertEqual _parse_visible_devices Unary pluses minuses assertEqual _parse_visible_devices + - Random string used empty set assertEqual _parse_visible_devices one two Random string used separator assertEqual _parse_visible_devices two one GPU ids parsed assertEqual _parse_visible_devices GPU- e d e GPU- e d e Ordinals included GPUid set assertEqual _parse_visible_devices GPU- GPU- MIG ids parsed assertEqual _parse_visible_devices MIG- c dc MIG- c dc test_partial_uuid_resolver torch cuda _transform_uuid_to_ordinals uuids = GPU- a-aa - ff - aa -c d f f GPU- e d e -a - fdd- e - fdbd GPU-e e-c c- -b - caeb e GPU-eee dfbc- f- ad - ff -dc b d GPU-bbcd - - e -c - cc d e GPU- ea - d - d-cc -f fdece bd GPU-e c - f- b- ec - f ccf e GPU- c e d- c a-d ed-fe - b ad assertEqual _transform_uuid_to_ordinals GPU- e d e uuids assertEqual _transform_uuid_to_ordinals GPU-e GPU- e d e uuids assertEqual _transform_uuid_to_ordinals GPU- e d e GPU- GPU- uuids First invalid UUID aborts parsing assertEqual _transform_uuid_to_ordinals GPU- GPU- e d e uuids assertEqual _transform_uuid_to_ordinals GPU- e d e GPU- GPU- uuids First ambiguous UUID aborts parsing assertEqual _transform_uuid_to_ordinals GPU- e d e GPU-e GPU- uuids Duplicate UUIDs result empty set assertEqual _transform_uuid_to_ordinals GPU- e d e GPU- GPU- e uuids test_ordinal_parse_visible_devices _device_count_nvml val torch cuda _device_count_nvml _dc patch dict os environ CUDA_VISIBLE_DEVICES val clear=True _dc patch object torch cuda _raw_device_count_nvml return_value= assertEqual _device_count_nvml Ordinal out bounds aborts parsing assertEqual _device_count_nvml instantiate_parametrized_tests TestExtendedCUDAIsAvail __name__ == __main__ run_tests