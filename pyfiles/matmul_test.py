operator_benchmark op_bench torch Microbenchmarks MatMul operator Configs PT Matmul operator mm_short_configs = op_bench config_list attr_names= M N K trans_a trans_b attrs= True False True False False True cross_product_configs= device cpu cuda tags= short mm_long_configs = op_bench cross_product_configs M= N= K= trans_a= False True trans_b= True False device= cuda dtype= torch float torch bfloat torch float tags= long MatMulBenchmark op_bench TorchBenchmarkBase init M N K trans_a trans_b device dtype=torch float Create tensors without requires_grad first then set separately This avoids creating graph leaves cannot deep copied trans_a input_one = torch rand M N device=device dtype=dtype input_one = torch rand N M device=device dtype=dtype t trans_b input_two = torch rand N K device=device dtype=dtype input_two = torch rand K N device=device dtype=dtype t Set requires_grad after tensor creation avoid graph leaf issues auto_set input_one requires_grad_ True auto_set input_two requires_grad_ True inputs = input_one input_one input_two input_two set_module_name matmul forward input_one input_two torch matmul input_one input_two op_bench generate_pt_test mm_long_configs + mm_short_configs MatMulBenchmark op_bench generate_pt_gradient_test mm_long_configs MatMulBenchmark __name__ == __main__ op_bench benchmark_runner main