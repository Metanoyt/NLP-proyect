Owner s module inductor math os sys torch torch _inductor codegen triton TritonScheduling torch _inductor test_case TestCase InductorTestCase torch _inductor test_operators realize torch _inductor utils fresh_cache is_big_gpu run_and_get_code torch testing FileCheck torch testing _internal common_utils slowTest torch testing _internal inductor_utils get_func_call GPU_TYPE HAS_CPU HAS_GPU_AND_TRITON IS_BIG_GPU Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir contextlib unittest inductor test_torchinductor manual=fbcode caffe test inductor test_inductor-library check_model check_model_gpu copy_tests skip_if_cpp_wrapper torch _inductor config torch _inductor scheduler Scheduler TestCase InductorTestCase classmethod setUpClass cls super setUpClass cls _stack = contextlib ExitStack cls _stack enter_context config patch benchmark_kernel True benchmark_fusion True classmethod tearDownClass cls cls _stack close super tearDownClass BenchmarkFusionTestTemplate test_softmax f x torch nn functional softmax x dim=- common f torch rand slowTest test_resnet try torchvision except ImportError skipTest TorchVision available model = torchvision models resnet model eval batch_size = inputs = torch randn batch_size common model inputs atol= e- rtol= e- test_register_spills The test can potentially trigger register spills old_benchmark_fn = Scheduler benchmark_fused_nodes new_benchmark_fn scheduler nodes We override Scheduler benchmark_fused_nodes latency there no register spills Without we may able test code path handling register spilling because before register start spilling related fusion may have already been skipped due longer lantency ms path = old_benchmark_fn scheduler nodes math isinf ms ms = ms path Disable dynamic_scale_rblock make easier trigger register spilling unittest mock patch object Scheduler benchmark_fused_nodes new_benchmark_fn config patch dynamic_scale_rblock False S = f inputs inputs = list inputs outputs = out = torch zeros S device=self device x inputs x = x x = x + x = x sum dim=- outputs append x out = out + x outputs out N = int os environ get NINP inputs = torch randn S device=self device _ range N opt_f = torch compile f opt_f inputs test_foreach_kernel Benchmark fusion should skip benchmarking kernels involves foreach kernel now Without skipping logic ` codegen_node_schedule ` may fail = torch randn device=self device b = torch randn device=self device f b b = torch _foreach_abs b + b + common f b unittest skipIf IS_BIG_GPU Skipping triton backend only since big GPU enough SM config patch max_autotune_gemm_backends= TRITON test_avoid_register_spilling device = GPU_TYPE raise unittest SkipTest GPU only torch nn functional gelu foo m inp curr = m inp tmps = _ range curr = gelu curr t tmps curr = curr + t tmps append curr curr m = torch nn Linear bias=True half GPU_TYPE inp = torch rand half GPU_TYPE torch no_grad foo_c = torch compile mode= max-autotune-no-cudagraphs foo _ out_code = run_and_get_code foo_c m inp occasionally CI will make one kernel just skip case out_code count triton_ = should multiple triton invocations FileCheck check async_compile wait check_count run exactly=True run out_code config patch benchmark_fusion False epilogue_fusion False torch no_grad torch _dynamo reset foo_c = torch compile mode= max-autotune-no-cudagraphs foo _ out_code = run_and_get_code foo_c m inp c out_code out_code FileCheck check async_compile wait check DeviceGuard check_count f empty_strided_ GPU_TYPE exactly=True check_regex buf - = buf - del buf - check run c test_tield_kernel_fusion f x y = realize x + x t y + x = torch randn device=self device common f x HAS_GPU_AND_TRITON BenchmarkFusionGpuTest TestCase common = check_model_gpu device = GPU_TYPE copy_tests BenchmarkFusionTestTemplate BenchmarkFusionGpuTest GPU_TYPE BenchmarkingTest TestCase unittest skipIf getattr torch GPU_TYPE device_count The test need least devices skip_if_cpp_wrapper This tests triton scheduling directly test_benchmark_on_non_zero_device hit_count = getattr torch GPU_TYPE device f GPU_TYPE torch compile relu x realize x relu + x x = torch randn int e device=f GPU_TYPE orig_benchmark_codegened_module = TritonScheduling benchmark_codegened_module benchmark_codegened_module args kwargs nonlocal hit_count hit_count += ms path = orig_benchmark_codegened_module args kwargs assertTrue ms ms path unittest mock patch object TritonScheduling benchmark_codegened_module benchmark_codegened_module relu x assertTrue hit_count BenchmarkMultiTemplateFusionGpuTest InductorTestCase classmethod setUpClass cls super setUpClass cls _stack = contextlib ExitStack cls _stack enter_context config patch benchmark_kernel True benchmark_fusion True benchmark_epilogue_fusion True classmethod tearDownClass cls cls _stack close super tearDownClass setUp super setUp is_big_gpu skipTest Need big GPU run max_autotune=True _equivalent_output_code_impl size first_dim=None activation=True foo m inp = m inp activation torch nn functional relu foo_c = torch compile mode= max-autotune-no-cudagraphs foo first_dim = first_dim first_dim None size m = torch nn Linear size size bias=True half GPU_TYPE inp = torch rand first_dim size half GPU_TYPE torch no_grad res code = run_and_get_code foo_c m inp torch _dynamo reset config patch benchmark_epilogue_fusion=False foo_c = torch compile mode= max-autotune-no-cudagraphs foo torch no_grad res code = run_and_get_code foo_c m inp assertEqual res res atol= e- rtol= code code fresh_cache config patch max_autotune_gemm_backends= TRITON test_equivalent_template_code code code = _equivalent_output_code_impl out_code code code FileCheck check get_func_call check_count empty_strided exactly=True check triton_tem_fused_addmm_relu_t_ check_count reset config cpp_wrapper del exactly=True check config cpp_wrapper run out_code fresh_cache config patch max_autotune_gemm_backends= ATEN test_equivalent_extern_code torch _dynamo reset code code = _equivalent_output_code_impl False out_code code code FileCheck check get_func_call check_count empty_strided exactly=True check config cpp_wrapper extern_kernels check_count reset config cpp_wrapper del exactly=True check config cpp_wrapper run out_code test_changed_layout cat addmm planning will change layout - make sure propagated fn torch Tensor b torch Tensor c torch Tensor torch cat torch addmm b c torch addmm b c args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE expected = fn args actual = torch compile fn mode= max-autotune args assertEqual expected actual torch _dynamo reset HAS_CPU torch backends mps is_available BenchmarkFusionCpuTest TestCase common = check_model device = cpu copy_tests BenchmarkFusionTestTemplate BenchmarkFusionCpuTest cpu __name__ == __main__ torch _inductor test_case run_tests HAS_CPU HAS_GPU_AND_TRITON run_tests