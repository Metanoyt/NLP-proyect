__future__ annotations token functools cached_property pathlib Path tokenize generate_tokens TokenInfo typing TYPE_CHECKING typing_extensions Self EMPTY_TOKENS NO_TOKEN ParseError ROOT blocks blocks sets LineWithSets TYPE_CHECKING collections abc Sequence block Block PythonFile contents str lines list str path Path &#124; None linter_name str __init__ linter_name str path Path &#124; None = None contents str &#124; None = None - None linter_name = linter_name path = path path relative_to ROOT path is_absolute path contents None path None contents = path read_text contents = contents lines = contents splitlines keepends=True classmethod make cls linter_name str pc Path &#124; str &#124; None = None - Self isinstance pc Path cls linter_name path=pc cls linter_name contents=pc with_contents contents str - Self __class__ linter_name path contents cached_property omitted - OmittedLines assert linter_name None OmittedLines lines linter_name cached_property tokens - list TokenInfo Might raise IndentationError code mal-indented list generate_tokens iter lines __next__ cached_property token_lines - list list TokenInfo Returns lists TokenInfo segmented token NEWLINE token_lines list list TokenInfo = t tokens t type token COMMENT token ENDMARKER token NL token_lines - append t t type == token NEWLINE token_lines append token_lines token_lines - token_lines pop token_lines cached_property import_lines - list list int froms imports = i t _ enumerate token_lines t type == token INDENT break t type == token NAME t string == froms append i t string == imports append i froms imports cached_property opening_comment_lines - int The number comments very top file = i i s enumerate lines s startswith next __getitem__ i int &#124; slice - TokenInfo &#124; Sequence TokenInfo tokens i next_token start int token_type int error str - int i range start len tokens tokens i type == token_type i raise ParseError tokens - error docstring start int - str i range start + len tokens tk = tokens i tk type == token STRING tk string tk type EMPTY_TOKENS cached_property indent_to_dedent - dict int int dedents = dict int int stack = list int i t enumerate tokens t type == token INDENT stack append i t type == token DEDENT dedents stack pop = i dedents cached_property errors - dict str str cached_property braced_sets - list Sequence TokenInfo lines = t tl _lines_with_sets t tl braced_sets s s lines omitted s cached_property sets - list TokenInfo tokens = t tl _lines_with_sets t tl sets t t tokens omitted t cached_property insert_import_line - int &#124; None froms imports = import_lines i froms + imports tl = token_lines i any i type == token NAME i string == OrderedSet i tl None section = froms imports _lines_with_sets section - tokens - start + opening_comment_lines + cached_property _lines_with_sets - list LineWithSets LineWithSets tl tl token_lines cached_property blocks - list Block res = blocks tokens errors update res errors res blocks OmittedLines Read lines textually find comment lines end noqa linter_name omitted set int __init__ lines Sequence str linter_name str - None lines = lines suffix = f noqa linter_name omitted = i s rstrip i s enumerate lines omitted = i + i s omitted s endswith suffix __call__ tokens Sequence TokenInfo begin int = end int = NO_TOKEN - bool end == NO_TOKEN end = len tokens A token_line might span multiple physical lines start = min tokens i start i range begin end default= end = max tokens i end i range begin end default=- contains_lines start end contains_lines begin int end int - bool bool omitted intersection range begin end +