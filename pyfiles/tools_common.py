mypy allow-untyped-defs collections operator collections abc Mapping dataclasses dataclass typing Any Optional Union torch torch fx torch fx _compatibility compatibility torch fx node _get_qualified_name __all__ = get_acc_ops_name get_node_target is_node_output_tensor FxNetAccFusionsFinder legalize_graph Tensors = Union tuple torch Tensor list torch Tensor TensorOrTensors = Union torch Tensor Tensors NodeList = list torch fx Node NodeSet = set torch fx Node Names = list str CALLABLE_NODE_OPS = call_module call_function call_method compatibility is_backward_compatible=False get_acc_ops_name k isinstance k str k k __module__ acc_ops k __module__ f acc_ops k __name__ module = k __module__ replace torch _ops torch ops WAR bug how torch ops assigns module f module module k __name__ compatibility is_backward_compatible=False get_node_target submodules Mapping str torch nn Module node torch fx Node - str Given ` node ` returns its target typename For call_method node node target which name method being called This could potential lead conflict should okay because normally s tensor For call_function node typename node target For call_module node typename module node target point If seeing _VariableFunctionsClass target name string will replaced torch e g _VariableFunctionsClass relu would become torch relu assert node op CALLABLE_NODE_OPS Expect op types + join CALLABLE_NODE_OPS + f found node op node op == call_module assert isinstance node target str submod = submodules node target submod_type = getattr submod _base_class_origin type submod get_acc_ops_name submod_type node op == call_function target Any = node target f acc_ops target __name__ target __module__ None acc_ops target __module__ _get_qualified_name target assert isinstance node target str node target compatibility is_backward_compatible=False is_node_output_tensor node torch fx Node - bool Checks node output produces Tensor NOTE This requires run ` ShapeProp ` containing fx graph before calling function This because works checking ` type ` metadata node This metadata produced ` ShapeProp ` type_ = node meta get type None type_ None issubclass type_ torch Tensor compatibility is_backward_compatible=False FxNetAccFusionsFinder Finds groups connected ACC nodes pass non-tensor data between each other Such groups called fusion groups __init__ module torch fx GraphModule acc_nodes NodeSet module = module nodes = list module graph nodes acc_nodes = acc_nodes dataclass FusionGroup The smallest idx nodes fusion group after topological sorting all nodes model top_node_idx int Nodes fusion group nodes NodeSet Inputs fusion group inputs NodeSet Nodes fusion group haven t been processed yet nodes_need_process NodeSet add_node node Add node fusion group node nodes nodes_need_process add node nodes add node inputs discard node inputs update n n node all_input_nodes n op CALLABLE_NODE_OPS n nodes recursive_add_node fusion_group FxNetAccFusionsFinder FusionGroup inputs Union NodeSet NodeList visited Optional NodeSet = None Start inputs going reverse topological order If any upstream node fusion group add all nodes path fusion group arg inputs skip node already seen visited None arg visited continue visited add arg Skip placeholder get_attr because they won t fusion group arg op CALLABLE_NODE_OPS continue If node has smaller idx s already upstream node fusion group We don t need check anymore nodes index arg fusion_group top_node_idx continue If node fusion group True arg fusion_group nodes True Check upstream nodes node any them fusion group we ll add node fusion group True recursive_add_node fusion_group arg all_input_nodes visited fusion_group add_node arg True False __call__ - dict torch fx Node NodeSet result dict torch fx Node NodeSet = acc_nodes = list acc_nodes node acc_nodes node result continue node op CALLABLE_NODE_OPS continue tensor_meta node meta continue node acc_nodes continue fusion_group FxNetAccFusionsFinder FusionGroup = FusionGroup top_node_idx=self nodes index node nodes= node inputs=set node all_input_nodes nodes_need_process= node while fusion_group nodes_need_process node = fusion_group nodes_need_process pop recursive_add_node fusion_group fusion_group inputs visited=set Optionally add downstream nodes tensor_meta node meta user node users user op CALLABLE_NODE_OPS continue user fusion_group nodes continue fusion_group add_node user recursive_add_node fusion_group fusion_group inputs visited=set Add some upstream nodes arg node all_input_nodes arg op CALLABLE_NODE_OPS continue tensor_meta arg meta continue arg fusion_group nodes continue fusion_group add_node arg fusion_group top_node_idx = min fusion_group top_node_idx nodes index arg recursive_add_node fusion_group fusion_group inputs visited=set set fusion_group nodes = acc_nodes acc_nodes -= fusion_group nodes n fusion_group nodes result n = fusion_group nodes result compatibility is_backward_compatible=False legalize_graph gm torch fx GraphModule - torch fx GraphModule Replace graph given GraphModule one contains same nodes original topologically sorted order This used merge_matmul transformation below which disturbs topologically sorted order its input GraphModule so order restored before further transformation Arguments gm The graph module topologically sort It modified in-place Returns The graph module in-place sorted These operators used making runtime assertions before any data-dependent operators occur We want prioritize sorting these ensure these assertions appear before any data-dependent operations graph PRIORITIZED_OPS = operator add operator mul operator sub operator floordiv operator truediv operator mod operator le operator lt operator ge operator gt operator eq operator ne torch ops aten sym_constrain_range default torch ops aten sym_constrain_range_for_size default torch ops aten _assert_async msg torch ops aten scalar_tensor default torch ops aten _assert_scalar default indeg = dict fromkeys gm graph nodes new_graph = torch fx Graph Track how many unfulfilled dependencies each node has node gm graph nodes user node users indeg user += queue collections deque = collections deque Add all nodes no dependencies queue node gm graph nodes indeg node == queue append node env dict torch fx Node torch fx Node = Pop nodes queue add nodes have had all their dependencies fulfilled while len queue cur = queue popleft env cur = new_graph node_copy cur lambda x env x user cur users indeg user -= indeg user == user op == call_function user target PRIORITIZED_OPS queue appendleft user queue append user If new graph s size large old one then there must cycle i e some node s dependencies satisfied len new_graph nodes len gm graph nodes raise RuntimeError f Input graph has cycles unable add node node indeg indeg node = new_graph _codegen = gm graph _codegen gm graph = new_graph gm