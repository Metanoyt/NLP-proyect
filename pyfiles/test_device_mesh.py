Copyright c Meta Platforms Inc affiliates Owner s oncall distributed os unittest datetime timedelta torch torch distributed dist torch distributed _functional_collectives funcol torch _C _distributed_c d Backend C dBackend torch _subclasses fake_tensor FakeTensorMode torch distributed _mesh_layout _MeshLayout _Layout torch distributed device_mesh _mesh_resources DeviceMesh init_device_mesh torch distributed distributed_c d _get_default_group _world get_global_rank get_world_size init_process_group is_initialized new_group ProcessGroup torch distributed tensor DTensor torch distributed tensor _collective_utils mesh_broadcast mesh_scatter unpad_tensor torch distributed tensor placement_types _Partial Shard torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_utils run_tests TEST_XPU TestCase torch testing _internal distributed _tensor common_dtensor DTensorTestBase with_comms torch testing _internal distributed fake_pg FakeProcessGroup FakeStore torch utils _typing_utils not_none device_type = acc type acc = torch accelerator current_accelerator cpu device_count = torch accelerator device_count try torch _C _distributed_c d ProcessGroupNCCL _NCCL_AVAILABLE = True except ImportError _NCCL_AVAILABLE = False _set_env_var addr= localhost port= world_size= rank= local_rank=- os environ MASTER_ADDR = addr os environ MASTER_PORT = port os environ WORLD_SIZE = f world_size os environ RANK = f rank local_rank = - os environ LOCAL_RANK = f local_rank unittest skipIf TEST_XPU XPU does support gloo backend DeviceMeshTestGlooBackend DTensorTestBase property backend gloo with_comms test_device_mesh_reuse_default_group mesh = init_device_mesh device_type world_size mesh_group = mesh get_group default_group = _get_default_group torch cuda is_available assertNotEqual mesh_group default_group assertEqual get_world_size mesh_group get_world_size default_group assertEqual mesh_group default_group DeviceMeshSetDeviceTest DTensorTestBase property world_size skip_if_lt_x_gpu test_manual_set_device mesh_tensor = torch arange reshape assertTrue is_initialized Set device each process before DeviceMesh constructor device different than default world rank torch accelerator set_device_index rank + world_size _set_env_var world_size=self world_size rank=self rank DeviceMesh device_type mesh_tensor assertTrue is_initialized check device set correct device respect previous set_device calls assertEqual torch accelerator current_device_idx rank + world_size destroy_pg skip_if_lt_x_gpu test_auto_set_device_from_local_rank mesh_tensor = torch arange reshape assertTrue is_initialized set local rank different than default world rank DeviceMesh should respect LOCAL_RANK env var s set local_rank = rank + world_size _set_env_var world_size=self world_size rank=self rank local_rank=local_rank DeviceMesh device_type mesh_tensor assertTrue is_initialized check device set correct device respect LOCAL_RANK env var assertEqual torch accelerator current_device_idx local_rank destroy_pg skip_if_lt_x_gpu test_auto_set_device_from_heuristic mesh_tensor = torch arange reshape assertTrue is_initialized _set_env_var world_size=self world_size rank=self rank assertWarnsRegex UserWarning It seems like you did set select default device DeviceMesh device_type mesh_tensor assertTrue is_initialized check device set correct device assertEqual torch accelerator current_device_idx rank destroy_pg DeviceMeshTest DTensorTestBase property world_size skip_if_lt_x_gpu test_init_process_group mesh_tensor = torch arange reshape assertTrue is_initialized _set_env_var world_size=self world_size rank=self rank DeviceMesh device_type mesh_tensor assertTrue is_initialized destroy_pg rank with_comms skip_if_lt_x_gpu test_assert_invalid_mesh_tensor mesh = torch arange world_size rank assertRaises ValueError DeviceMesh device_type mesh with_comms test_ d_mesh_non_eager_init_subgroup mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape assertEqual mesh_ d get_group bound_device_id None assertEqual mesh_ d get_group bound_device_id None TODO need refactor other tests file test both eager_init=True eager_init=False scenarios with_comms eager_init=True test_ d_mesh_eager_init_subgroup mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape when eager init used subgroup created nccl comm split there would bound_device_id immediately assigned subgroup backend == nccl curr_device = torch cuda current_device assertEqual mesh_ d get_group bound_device_id index curr_device assertEqual mesh_ d get_group bound_device_id index curr_device with_comms test_get_group_and_get_all_groups mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp assertEqual mesh_ d get_group mesh_ d get_group dp assertEqual mesh_ d get_group mesh_ d get_group tp assertEqual mesh_ d get_group dp dp_mesh get_group assertEqual mesh_ d get_group tp tp_mesh get_group groups = mesh_ d get_all_groups assertEqual len groups assertTrue tp_mesh get_group groups assertTrue dp_mesh get_group groups with_comms test_get_local_rank_raises_exception mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= dp tp assertRaisesRegex RuntimeError Optional kwarg ` mesh_dim ` needs specified when device_mesh ndim mesh_ d get_local_rank with_comms test_get_local_rank mesh_shape = world_size mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= dp tp assertEqual mesh_ d get_local_rank dp mesh_ d get_local_rank assertEqual mesh_ d get_local_rank tp mesh_ d get_local_rank dp_mesh = mesh_ d dp tp_mesh = mesh_ d tp assertEqual dp_mesh get_local_rank mesh_ d get_local_rank dp assertEqual tp_mesh get_local_rank mesh_ d get_local_rank tp Verify flattened mesh local rank correctness flattened_mesh = mesh_ d dp tp _flatten assertEqual flattened_mesh get_local_rank rank with_comms test_device_mesh_ d mesh_tensor = torch arange reshape construct device mesh device_type mesh = DeviceMesh device_type mesh_tensor check all dim groups dim_to_subgroups = mesh get_all_groups expected_ranks_by_dim = dim dim_group enumerate dim_to_subgroups assertTrue dim dim_ranks = expected_ranks_by_dim dim dim_group_size = get_world_size dim_group assertIsInstance dim_group ProcessGroup assertEqual dim_group_size global_ranks = get_global_rank dim_group i i range dim_group_size current_rank_expected_group_ranks = dim_ranks rank dim_ranks dim_ranks assertEqual global_ranks current_rank_expected_group_ranks with_comms test_device_mesh_init_backend mesh = DeviceMesh device_type torch arange _init_backend=False _rank= assertRaisesRegex RuntimeError process groups initialized mesh get_group coordinates should always been populated when init_backend False whenever we call init_backend we should make sure default pg already created assertEqual mesh get_coordinate test_fake_pg_device_mesh fake_store = FakeStore init_process_group fake store=fake_store rank= world_size=self world_size device_type = torch accelerator current_accelerator type torch accelerator is_available cpu mesh = DeviceMesh device_type torch arange world_size local_tensor = torch randn global_tensor = funcol all_gather_tensor local_tensor gather_dim= group= mesh wait assertEqual global_tensor shape world_size with_comms test_from_group_with_global_pg Simple test check ` from_group ` mesh pg vs directly initializing via ` init_device_mesh ` ref_global_mesh = init_device_mesh device_type world_size mesh_pg = ref_global_mesh get_group global_mesh = DeviceMesh from_group mesh_pg device_type assertEqual ref_global_mesh global_mesh assertEqual ref_global_mesh _dim_group_names global_mesh _dim_group_names assertEqual ref_global_mesh _coordinate_on_dim global_mesh _coordinate_on_dim Check when ` mesh ` passed well global_mesh = DeviceMesh from_group mesh_pg device_type mesh=torch arange world_size assertEqual ref_global_mesh global_mesh assertEqual ref_global_mesh _dim_group_names global_mesh _dim_group_names assertEqual ref_global_mesh _coordinate_on_dim global_mesh _coordinate_on_dim with_comms test_from_group_with_invalid_mesh global_pg = _get_default_group global_pg_size = global_pg size assert global_pg_size == Test assumes global world size invalid_mesh = D mesh when we need D regex = r Invalid mesh \ \ \ \ \ \ ProcessGroup ranks \ \ assertRaisesRegex ValueError regex DeviceMesh from_group global_pg device_type invalid_mesh mesh_dim_names= dim dim device_mesh = init_device_mesh device_type groups = device_mesh get_all_groups invalid_mesh = D mesh when we need D regex = r Expects mesh ndim equal number ProcessGroups got mesh \ \ ProcessGroups assertRaisesRegex ValueError regex DeviceMesh from_group groups device_type invalid_mesh mesh_dim_names= dim dim test_raises_invalid_device_type assertRaisesRegex RuntimeError Device type index supported test init_device_mesh invalid device type contains GPU index mesh_shape = world_size init_device_mesh f device_type mesh_shape=mesh_shape mesh_dim_names= dp tp with_comms test_get_root_mesh_multiple_independent_meshes regression test issue when creating multiple independent device meshes slicing them get_root_mesh should correct parent mesh each submesh mesh = init_device_mesh device_type mesh_dim_names= dp tp mesh _dp = mesh dp mesh _tp = mesh tp mesh = init_device_mesh device_type mesh_dim_names= dim dim mesh _dim = mesh dim mesh _dim = mesh dim assertEqual _mesh_resources get_root_mesh mesh _dp mesh assertEqual _mesh_resources get_root_mesh mesh _tp mesh assertEqual _mesh_resources get_root_mesh mesh _dim mesh assertEqual _mesh_resources get_root_mesh mesh _dim mesh assertNotEqual _mesh_resources get_root_mesh mesh _dp mesh assertNotEqual _mesh_resources get_root_mesh mesh _tp mesh DeviceMeshTestNDim DTensorTestBase property world_size with_comms test_device_mesh_nd construct device mesh device_type mesh_tensor = torch arange reshape mesh = DeviceMesh device_type mesh_tensor check all dim groups dim_to_subgroups = mesh get_all_groups dim dim_group enumerate dim_to_subgroups assertTrue dim mesh_tensor ndim dim_ranks = mesh_tensor swapdims - dim reshape - dim_group_size = get_world_size dim_group assertIsInstance dim_group ProcessGroup assertEqual dim_group_size global_ranks = get_global_rank dim_group i i range dim_group_size ranks dim_ranks rank ranks assertEqual global_ranks ranks tolist with_comms test_device_mesh_hash mesh_tensor_ d = torch arange reshape mesh = DeviceMesh device_type mesh_tensor_ d mesh = DeviceMesh device_type mesh_tensor_ d assertEqual hash mesh hash mesh mesh_tensor_ d = torch arange reshape mesh = DeviceMesh device_type mesh_tensor_ d assertNotEqual hash mesh hash mesh assertNotEqual hash mesh hash mesh with_comms test_get_local_rank_ d If we have D mesh we want apply dp pp tp mesh_dim_names = dp pp tp mesh tensor would mesh_ d_tensor = mesh_shape = mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names= dp pp tp tp_rank_ tp_rank_ tp_rank = mesh_ d get_local_rank tp expected_tp_rank = rank assertEqual tp_rank expected_tp_rank pp_rank_ pp_rank_ pp_rank = mesh_ d get_local_rank pp expected_pp_rank = rank = assertEqual pp_rank expected_pp_rank dp_rank_ dp_rank_ dp_rank = mesh_ d get_local_rank dp expected_dp_rank = rank assertEqual dp_rank expected_dp_rank with_comms test_device_mesh_parent_child_hash mesh_ d = init_device_mesh device_type world_size mesh_dim_names= DP TP mesh_group_ = torch arange world_size mesh_group_ = torch arange world_size world_size ep_mesh_ = DeviceMesh device_type mesh_group_ ep_mesh_ = DeviceMesh device_type mesh_group_ ep_mesh = ep_mesh_ rank world_size ep_mesh_ ep_mesh considered different mesh_ d TP assertEqual mesh_ d TP mesh flatten tolist ep_mesh mesh flatten tolist assertEqual mesh_ d TP _layout ep_mesh _layout assertEqual mesh_ d TP mesh shape ep_mesh mesh shape assertEqual mesh_ d TP device_type ep_mesh device_type assertNotEqual mesh_ d TP mesh_dim_names ep_mesh mesh_dim_names assertEqual mesh_ d TP _thread_id ep_mesh _thread_id assertNotEqual hash mesh_ d TP hash ep_mesh assertNotEqual mesh_ d TP ep_mesh another_mesh_ = DeviceMesh device_type mesh_group_ another_mesh_ = DeviceMesh device_type mesh_group_ another_mesh = another_mesh_ rank world_size another_mesh_ another_mesh considered same ep_mesh assertEqual ep_mesh _flatten_rank_map another_mesh _flatten_rank_map assertEqual ep_mesh _layout another_mesh _layout assertEqual ep_mesh mesh shape another_mesh mesh shape assertEqual ep_mesh device_type another_mesh device_type assertEqual ep_mesh mesh_dim_names another_mesh mesh_dim_names assertEqual ep_mesh _thread_id another_mesh _thread_id assertEqual hash ep_mesh hash another_mesh assertEqual ep_mesh another_mesh with_comms test_from_group_with_mesh_shape_ d Tests ` ` from_group ` ` when passing ` ` mesh_shape ` ` D Consider following D scenario we need create D HSDP mesh - dp_replicate dp_shard tp mesh mesh_shape = mesh_dim_names = dp_replicate dp_shard tp ref_mesh = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names dp_shard_group = ref_mesh dp_shard get_group dp_replicate_group = ref_mesh dp_replicate get_group dp_mesh = DeviceMesh from_group dp_replicate_group dp_shard_group device_type mesh=ref_mesh mesh ref_mesh get_local_rank mesh_dim= tp mesh_dim_names= dp_replicate dp_shard ref_mesh_dp_dim_group_names = ref_mesh _dim_group_names assertEqual ref_mesh_dp_dim_group_names dp_mesh _dim_group_names Cannot check directly mesh equality since parent meshes same since ref s parent mesh D assertEqual dp_mesh dp_replicate mesh ref_mesh dp_replicate mesh assertEqual dp_mesh dp_replicate _dim_group_names ref_mesh dp_replicate _dim_group_names assertEqual dp_mesh dp_shard mesh ref_mesh dp_shard mesh assertEqual dp_mesh dp_shard _dim_group_names ref_mesh dp_shard _dim_group_names with_comms test_from_group_with_mesh_shape_ d Tests ` ` from_group ` ` when passing ` ` mesh_shape ` ` D Consider following scenario where process group has been created we need create D HSDP mesh later program mesh_shape = mesh_dim_names = dp_replicate dp_shard ref_mesh = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names Create shard groups e g assign correct shard group each rank shard_rank_lists = list range world_size list range world_size world_size shard_groups = new_group shard_rank_lists new_group shard_rank_lists current_shard_group = shard_groups rank shard_rank_lists shard_groups Create replicate groups example assign correct replicate group each rank current_replicate_group = None shard_factor = len shard_rank_lists i range world_size replicate_group_ranks = list range i world_size shard_factor replicate_group = new_group replicate_group_ranks rank replicate_group_ranks current_replicate_group = replicate_group dp_mesh = DeviceMesh from_group not_none current_replicate_group current_shard_group device_type mesh=ref_mesh mesh mesh_dim_names= dp_replicate dp_shard mesh_dim_group ref_mesh_dim_group zip dp_mesh get_all_groups ref_mesh get_all_groups mesh_dim_group_ranks = dist get_process_group_ranks mesh_dim_group ref_mesh_dim_group_ranks = dist get_process_group_ranks ref_mesh_dim_group assertEqual mesh_dim_group_ranks ref_mesh_dim_group_ranks check both d mesh submeshes exactly same assertEqual dp_mesh ref_mesh assertEqual dp_mesh dp_replicate ref_mesh dp_replicate assertEqual dp_mesh dp_shard ref_mesh dp_shard InitDeviceMeshTest DTensorTestBase property world_size with_comms test_init_device_mesh mesh_shape = mesh_dim_names = DP TP ref_mesh = DeviceMesh device_type torch arange view mesh_shape mesh_dim_names=mesh_dim_names test init_device_mesh mesh_dim_names mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names assertEqual mesh_ d ref_mesh assertEqual mesh_ d mesh_dim_names mesh_dim_names with_comms test_raises_duplicate_mesh_dim_names assertRaisesRegex RuntimeError Each mesh_dim_name must unique init_device_mesh device_type mesh_dim_names= dp dp with_comms test_raises_mesh_shape_mesh_dim_names_mismatch assertRaisesRegex RuntimeError mesh_shape mesh_dim_names should have same length init_device_mesh device_type mesh_dim_names= dp tp _test_backend_override_argument_dict_with_idx_and_backend opts = FakeProcessGroup Options opts fake_option = mesh = init_device_mesh device_type mesh_dim_names= dp tp cp backend_override= fake fake opts get_opts mesh DeviceMesh dim_idx int - C dBackend Options mesh get_group dim_idx _get_backend torch device f device_type rank options Fake pg only have BackendType BackendType CUSTOM assertEqual mesh get_group _get_backend_name custom assertNotEqual mesh get_group _get_backend_name custom assertEqual mesh get_group _get_backend_name custom assertIsNone get_opts mesh assertEqual get_opts mesh fake_option dp_tp_mesh = mesh dp tp _flatten dp_cp_mesh = mesh dp cp _flatten backend_override= fake tp_cp_mesh = mesh tp cp _flatten backend_override= fake opts assertNotEqual dp_tp_mesh get_group _get_backend_name custom assertEqual dp_cp_mesh get_group _get_backend_name custom assertEqual tp_cp_mesh get_group _get_backend_name custom assertIsNone get_opts dp_cp_mesh assertEqual get_opts tp_cp_mesh fake_option with_comms test_backend_override_argument_dict_with_idx_and_backend_lazy _test_backend_override_argument_dict_with_idx_and_backend with_comms eager_init=True test_backend_override_argument_dict_with_idx_and_backend_eager _test_backend_override_argument_dict_with_idx_and_backend with_comms backend= fake test_backend_override_argument_dict_with_name_and_options opts = FakeProcessGroup Options opts fake_option = mesh = init_device_mesh device_type mesh_dim_names= dp tp cp backend_override= tp opts get_opts mesh DeviceMesh dim_idx int - C dBackend Options mesh get_group dim_idx _get_backend torch device f device_type rank options assertIsNone get_opts mesh assertEqual get_opts mesh fake_option assertIsNone get_opts mesh dp_tp_mesh = mesh dp tp _flatten dp_cp_mesh = mesh dp cp _flatten backend_override=opts assertIsNone get_opts dp_tp_mesh assertEqual get_opts dp_cp_mesh fake_option with_comms test_backend_override_argument_errors assertRaisesRegex RuntimeError Found redundant dim index name dp backend_override init_device_mesh device_type mesh_dim_names= dp tp backend_override= dp foo bar assertRaisesRegex RuntimeError r Found invalid keys backend_override got \ cp \ init_device_mesh device_type mesh_dim_names= dp tp backend_override= cp foo assertRaisesRegex RuntimeError r Found invalid keys backend_override got \ \ init_device_mesh device_type mesh_dim_names= dp tp backend_override= bar TestDeviceMeshGetItem DTensorTestBase property world_size with_comms test_raises_no_mesh_dim_found assertRaisesRegex RuntimeError Cannot slice DeviceMesh without mesh_dim_names mesh = init_device_mesh device_type mesh DP with_comms test_raises_invalid_mesh_dim_name child_mesh_dim_name = PP assertRaisesRegex KeyError Invalid mesh_dim_name mesh_dim_names = DP TP mesh = init_device_mesh device_type mesh_dim_names=mesh_dim_names mesh child_mesh_dim_name with_comms test_get_item_ d mesh_shape = mesh_dim_names = DP TP mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names pg_ranks_by_dim_name = mesh_dim_name mesh_dim_names mesh_dim = mesh_dim_names index mesh_dim_name pg_ranks_by_dim_name mesh_dim_name = mesh_ d mesh swapdims - mesh_dim reshape - mesh_ d mesh size mesh_dim tp_mesh = mesh_ d TP tp_group_idx = rank assertEqual tp_mesh mesh pg_ranks_by_dim_name TP tp_group_idx dp_group_idx = rank assertEqual mesh_ d DP mesh pg_ranks_by_dim_name DP dp_group_idx with_comms test_get_item_ d mesh = init_device_mesh device_type mesh_dim_names= dp Make sure slicing out D mesh D mesh works dp_mesh = mesh dp assertEqual dp_mesh mesh assertRaisesRegex KeyError Invalid mesh_dim_name dp_mesh = mesh dim with_comms test_get_item_ d mesh_shape = mesh_dim_names = Replicate Shard TP mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names tp_group = tp_group_idx = int rank assertEqual mesh_ d TP mesh tolist tp_group tp_group_idx shard_group = shard_group_idx = rank + rank assertEqual mesh_ d Shard mesh tolist shard_group shard_group_idx replicate_group = replicate_group_idx = rank assertEqual mesh_ d Replicate mesh tolist replicate_group replicate_group_idx We support both UX nD slicing mesh_ d Replicate Shard mesh_ d Replicate Shard hsdp_mesh_ = mesh_ d Replicate Shard hsdp_mesh_ = mesh_ d Replicate Shard hsdp_group = hsdp_group_idx = rank assertEqual hsdp_mesh_ mesh tolist hsdp_group hsdp_group_idx assertEqual hsdp_mesh_ mesh tolist hsdp_group hsdp_group_idx assertEqual hsdp_mesh_ hsdp_mesh_ Test slicing out D mesh sub- D mesh shard_mesh = hsdp_mesh_ Shard assertEqual shard_mesh mesh tolist shard_group shard_group_idx replicate_mesh = hsdp_mesh_ Replicate assertEqual replicate_mesh mesh tolist replicate_group replicate_group_idx with_comms test_cache_and_reuse_submesh_slice_result mesh = init_device_mesh device_type mesh_dim_names= dp tp ref_pg_count = _world group_count When we call dp slice second time should create any new pg As we just using cached result so pg count should same assertEqual ref_pg_count _world group_count When we call tp slice should create new pg tp slice would just reuse parent mesh pg mesh tp assertEqual _world group_count ref_pg_count with_comms test_get_item_ d_noncontiguous_slicing mesh_shape = mesh_dim_names = dp pp cp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names Slice order simply decides which mesh_dim sits which mesh_dim For dp_cp_mesh cp mesh innermost dimension dp_cp_mesh = mesh_ d dp cp expected_mesh_tensor = torch tensor dtype=torch int rank torch tensor dtype=torch int dp_local_rank = dp_cp_mesh get_local_rank dp assertEqual dp_cp_mesh mesh expected_mesh_tensor cp_mesh = mesh_ d cp Check current dp_local_rank whether cp mesh tensor same assertEqual dp_cp_mesh mesh dp_local_rank cp_mesh mesh assertRaisesRegex KeyError Invalid mesh_dim_names mesh_ d cp dp with_comms test_flatten_mesh_ d mesh_shape = mesh_dim_names = default mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names mesh_ d _flatten with_comms test_flatten_mesh_ d mesh_shape = mesh_dim_names = dp cp tp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names Test flatten into existing mesh_dim_name inside mesh assertRaisesRegex ValueError already exists submesh DeviceMesh mesh_ d _flatten dp Test flatten contiguous dims dp_cp_mesh = mesh_ d dp cp flattened_dp_cp_mesh = dp_cp_mesh _flatten assertEqual dp_cp_mesh mesh flatten flattened_dp_cp_mesh mesh assertEqual flattened_dp_cp_mesh mesh_dim_names dp_cp assertEqual flattened_dp_cp_mesh get_group group_desc mesh_dp_cp root_mesh = dp_cp_mesh _get_root_mesh assertEqual root_mesh mesh_ d flatten_mesh_layout = root_mesh _flatten_mapping dp_cp _layout assertEqual flatten_mesh_layout flattened_dp_cp_mesh _layout assertEqual flattened_dp_cp_mesh _layout global_ranks ref_pg_count = _world group_count Calling flatten again should create new pg flattened_dp_cp_mesh_ = dp_cp_mesh _flatten assertEqual flattened_dp_cp_mesh flattened_dp_cp_mesh_ assertEqual ref_pg_count _world group_count Test flatten non-contiguous dims dp_tp_mesh = mesh_ d dp tp flattened_dp_tp_mesh = dp_tp_mesh _flatten assertEqual dp_tp_mesh mesh flatten flattened_dp_tp_mesh mesh assertEqual flattened_dp_tp_mesh mesh_dim_names dp_tp root_mesh = dp_tp_mesh _get_root_mesh assertEqual root_mesh mesh_ d flatten_mesh_root_layout = root_mesh _flatten_mapping dp_tp _layout assertEqual flatten_mesh_root_layout flattened_dp_tp_mesh _layout assertEqual flattened_dp_tp_mesh _layout global_ranks assertRaisesRegex NotImplementedError Currently only allows slicing out contiguous flattened dim mesh_ d dp_tp cp Test flatten flattened mesh_dim_name cp_tp_mesh = mesh_ d cp tp cp_tp_mesh _flatten dummy assertEqual mesh_ d dummy mesh_dim_names dummy Test flatten into existing mesh_dim_name inside mesh assertRaisesRegex ValueError dp already exists submesh DeviceMesh mesh_ d _flatten dp assertRaisesRegex ValueError Flatten mesh mesh_dim_name dp_tp has been created before mesh_ d cp tp _flatten dp_tp with_comms eager_init=True test_flatten_mesh_ d mesh_shape = mesh_dim_names = dp_replicate dp_shard cp tp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names flatten HSDP CP into one mesh dp_cp_mesh = mesh_ d mesh_dim_names _flatten dp_cp check flattened mesh integrity assertEqual mesh_ d dp_cp mesh flatten dp_cp_mesh mesh check flattened mesh dim names correct assertEqual dp_cp_mesh mesh_dim_names dp_cp check flattened mesh dependency assertEqual dp_cp_mesh _get_root_mesh mesh_ d with_comms test_unflatten_mesh_ d mesh_shape = mesh_dim_names = dp tp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names unflatten_mesh = mesh_ d _unflatten dp_shard dp_replicate assertEqual unflatten_mesh mesh_dim_names dp_shard dp_replicate tp assertEqual mesh_ d tp mesh unflatten_mesh tp mesh assertEqual mesh_ d tp get_group unflatten_mesh tp get_group Not supporting slicing out unflatten dim name root mesh assertRaises KeyError assertEqual mesh_ d dp_shard mesh unflatten_mesh dp_shard mesh with_comms test_unflatten_mesh_ d Test unflatten dummy world mesh which case we need Expert Parallelism EP global_mesh = init_device_mesh device_type mesh_dim_names= world non_ep_mesh = global_mesh _unflatten dp cp tp ep_mesh = global_mesh _unflatten dp ep ep_tp assertEqual non_ep_mesh cp mesh ep_mesh ep mesh assertEqual non_ep_mesh tp mesh ep_mesh ep_tp mesh mesh_ d = global_mesh _unflatten dp cp tp unflatten_mesh = mesh_ d _unflatten dp_shard dp_replicate assertEqual unflatten_mesh mesh_dim_names dp_shard dp_replicate cp tp assertEqual mesh_ d tp mesh unflatten_mesh tp mesh assertEqual mesh_ d tp get_group unflatten_mesh tp get_group assertEqual mesh_ d cp mesh unflatten_mesh cp mesh assertEqual mesh_ d cp get_group unflatten_mesh cp get_group Test unflatten backend override set _NCCL_AVAILABLE opts = dist ProcessGroupNCCL Options opts _timeout = timedelta seconds= mesh_ d = global_mesh _unflatten pp spmd backend_override= pp fake spmd nccl opts opts = dist ProcessGroupNCCL Options opts _timeout = timedelta seconds= mesh_ d = mesh_ d _unflatten dp cp tp backend_override= dp nccl cp nccl tp nccl opts assertEqual mesh_ d pp get_group _get_backend_name custom spmd_pg = mesh_ d spmd get_group assertEqual spmd_pg _get_backend_name nccl w = spmd_pg allreduce torch rand cuda rank assertTrue spmd_pg _get_backend torch device f cuda rank _verify_work_timeout w timedelta seconds= w wait tp_pg = mesh_ d tp get_group assertEqual tp_pg _get_backend_name nccl w = tp_pg allreduce torch rand cuda rank assertTrue tp_pg _get_backend torch device f cuda rank _verify_work_timeout w timedelta seconds= w wait with_comms test_concatenate_ d mesh_shape = mesh_dim_names = dp tp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names concatenated_mesh = DeviceMesh _concatenate mesh_ d dp mesh_ d tp assertEqual concatenated_mesh mesh mesh_ d mesh assertEqual concatenated_mesh get_group dp mesh_ d get_group dp assertEqual concatenated_mesh get_group tp mesh_ d get_group tp with_comms test_concatenate_ d mesh_shape = mesh_dim_names = pp dp tp mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names concatenated_mesh = DeviceMesh _concatenate mesh_ d dp mesh_ d tp dp_tp_mesh = mesh_ d dp tp assertEqual concatenated_mesh mesh dp_tp_mesh mesh assertEqual concatenated_mesh get_group dp dp_tp_mesh get_group dp assertEqual concatenated_mesh get_group tp dp_tp_mesh get_group tp assertEqual mesh_ d DeviceMesh _concatenate mesh_ d pp dp mesh_ d tp with_comms test_reconstruct_mesh_with_flatten_dim mesh_ d = init_device_mesh device_type mesh_dim_names= replicate shard cp shard_cp_mesh = mesh_ d shard cp _flatten hsdp_mesh = mesh_ d replicate shard_cp expected_mesh_tensor = torch tensor dtype=torch int assertEqual hsdp_mesh mesh expected_mesh_tensor assertEqual shard_cp_mesh get_group mesh_ d shard_cp get_group assertEqual shard_cp_mesh get_group mesh_ d get_group mesh_dim= shard_cp mesh_ d = init_device_mesh device_type mesh_dim_names= dp cp tp dp_cp_mesh = mesh_ d dp cp _flatten spmd_mesh = mesh_ d dp_cp tp expected_mesh_tensor = torch tensor dtype=torch int assertEqual spmd_mesh mesh expected_mesh_tensor assertEqual dp_cp_mesh get_group mesh_ d dp_cp get_group assertEqual dp_cp_mesh get_group mesh_ d get_group mesh_dim= dp_cp TestMeshEnv DTensorTestBase property world_size with_comms test_get_root_mesh mesh_ d = init_device_mesh device_type mesh_dim_names= dp cp tp dp_cp_mesh = mesh_ d dp cp dp_tp_mesh = mesh_ d dp tp cp_tp_mesh = mesh_ d cp tp dp_mesh = mesh_ d dp cp_mesh = mesh_ d cp tp_mesh = mesh_ d tp Test BC case still working assertEqual _mesh_resources get_root_mesh dp_cp_mesh mesh_ d assertEqual _mesh_resources get_root_mesh dp_tp_mesh mesh_ d assertEqual _mesh_resources get_root_mesh cp_tp_mesh mesh_ d assertEqual _mesh_resources get_root_mesh dp_mesh mesh_ d assertEqual _mesh_resources get_root_mesh cp_mesh mesh_ d assertEqual _mesh_resources get_root_mesh tp_mesh mesh_ d assertEqual dp_cp_mesh _get_root_mesh mesh_ d assertEqual dp_tp_mesh _get_root_mesh mesh_ d assertEqual cp_tp_mesh _get_root_mesh mesh_ d assertEqual dp_mesh _get_root_mesh mesh_ d assertEqual cp_mesh _get_root_mesh mesh_ d assertEqual tp_mesh _get_root_mesh mesh_ d with_comms test_get_root_mesh_dim_exist mesh_shape = world_size mesh_dim_names = DP TP mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names assertEqual mesh_ d DP _get_root_mesh_dim assertEqual mesh_ d TP _get_root_mesh_dim with_comms test_get_root_mesh_dim_not_exist mesh_shape = world_size mesh = init_device_mesh device_type mesh_shape assertEqual mesh _get_root_mesh_dim None with_comms test_get_mesh_dim_by_name mesh_shape = world_size mesh_dim_names = DP TP mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names assertEqual mesh_ d _get_mesh_dim_by_name DP assertEqual mesh_ d _get_mesh_dim_by_name TP with_comms test_get_all_submeshes mesh_ d = init_device_mesh device_type mesh_dim_names= replicate shard all_submeshes = mesh_ d _get_all_submeshes replicate assertEqual len all_submeshes assertEqual all submesh mesh numel == submesh all_submeshes True with_comms test_mesh_slice_fake_tensor_mode mesh_shape = world_size mesh_dim_names = DP TP mesh_ d = init_device_mesh device_type mesh_shape mesh_dim_names=mesh_dim_names FakeTensorMode mesh_ d DP mesh_ d TP mesh_ d DP TP DeviceMeshCollectiveTest DTensorTestBase property world_size with_comms test_broadcast_ d mesh = DeviceMesh device_type torch arange world_size local_tensor = torch ones device=self device_type rank mesh_broadcast local_tensor mesh mesh_dim= assertEqual local_tensor torch zeros with_comms test_scatter_ d mesh = DeviceMesh device_type torch arange world_size scatter_tensor_shape = scatter_dim range len scatter_tensor_shape shard_placement = Shard scatter_dim scatter_tensor_shape scatter_dim = world_size make random seed same across rank torch manual_seed global_tensor = torch randn scatter_tensor_shape device=self device_type splitted_list _ = shard_placement _split_tensor global_tensor mesh size with_padding=True contiguous=True recv_tensor = torch empty_like splitted_list mesh get_rank scatter dim would generate non-contiguous tensor verify works mesh_scatter recv_tensor splitted_list mesh mesh_dim= assertEqual recv_tensor splitted_list mesh get_rank with_comms test_scatter_uneven device_mesh = DeviceMesh device_type list range world_size my_rank = device_mesh get_rank tensor_to_split = torch randn device_mesh size + device_mesh size + device=self device_type shard_dim range tensor_to_split ndim shard_placement = Shard shard_dim tensor_to_scatter = tensor_to_split clone tensor_splitted_list = list torch chunk tensor_to_split world_size dim=shard_dim _ range world_size - len tensor_splitted_list tensor_splitted_list append torch tensor device=self device_type padded_tensor_list pad_sizes = shard_placement _split_tensor tensor_to_scatter device_mesh size with_padding=True contiguous=True scattered_tensor = torch empty_like padded_tensor_list my_rank mesh_scatter scattered_tensor padded_tensor_list device_mesh mesh_dim= pad_sizes my_rank = scattered_tensor = unpad_tensor scattered_tensor shard_dim pad_sizes my_rank scattered_tensor numel == We need check numel instead size tensor after unpadding since size could after unpadding assertEqual scattered_tensor numel tensor_splitted_list my_rank numel assertEqual scattered_tensor size tensor_splitted_list my_rank size assertEqual scattered_tensor tensor_splitted_list my_rank with_comms test_all_gather_uneven device_mesh = DeviceMesh device_type list range world_size my_rank = device_mesh get_rank tensor_to_split = torch ones device_mesh size + device_mesh size + device=self device_type shard_dim range tensor_to_split ndim shard_placement = Shard shard_dim tensor_padded_list pad_sizes = shard_placement _split_tensor tensor_to_split device_mesh size with_padding=True contiguous=True local_tensor = tensor_padded_list my_rank big_tensor = funcol all_gather_tensor local_tensor gather_dim=shard_dim group= device_mesh big_tensor_chunks = list torch chunk big_tensor device_mesh size dim=shard_dim unpadded_list = unpad_tensor big_tensor shard_dim pad_sizes i pad_sizes i big_tensor i big_tensor enumerate big_tensor_chunks all_gathered_tensor = torch cat unpadded_list dim=shard_dim assertEqual all_gathered_tensor size tensor_to_split size assertEqual all_gathered_tensor tensor_to_split with_comms test_reduce_scatter_contiguous device_mesh = DeviceMesh device_type list range world_size my_rank = device_mesh get_rank Init tensor step = world_size total_elem = step tensor = torch arange total_elem view step - device=self device_type tensor = tensor my_rank + Get non-contiguous tensor slicing tensor_to_reduce = tensor tensor_contiguous = tensor_to_reduce clone contiguous Partial Shard trigger reduce_scatter tensor_to_reduce = DTensor from_local tensor_to_reduce device_mesh _Partial tensor_contiguous = DTensor from_local tensor_contiguous device_mesh _Partial new_tensor = tensor_to_reduce redistribute device_mesh Shard new_tensor_contiguous = tensor_contiguous redistribute device_mesh Shard The output contiguous non-contiguous tensors same value should same reducescatter value new_tensor_local = new_tensor _local_tensor new_tensor_contiguous_local = new_tensor_contiguous _local_tensor assertEqual new_tensor_local new_tensor_contiguous_local assertEqual list new_tensor_local size Check reduce numerical value sum_base = + world_size world_size first_elem = my_rank sum_base step expected_tensor = torch tensor first_elem first_elem + sum_base dtype=new_tensor_local dtype device=self device_type assertEqual new_tensor_local expected_tensor with_comms test_reduce_scatter_uneven device_mesh = DeviceMesh device_type list range world_size my_rank = device_mesh get_rank tensor_to_split = torch ones device_mesh size + device_mesh size + device=self device_type rank shard_dim range tensor_to_split ndim shard_placement = Shard shard_dim tensor_to_scatter = tensor_to_split clone tensor_splitted_list = list torch chunk tensor_to_split world_size dim=shard_dim _ range world_size - len tensor_splitted_list tensor_splitted_list append torch tensor device=self device_type padded_tensor_list pad_sizes = shard_placement _split_tensor tensor_to_scatter device_mesh size with_padding=True contiguous=True tensor_to_reduce = torch cat padded_tensor_list shard_dim res_num = + world_size - world_size scattered_tensor = funcol reduce_scatter_tensor tensor_to_reduce reduceOp= sum scatter_dim=shard_dim group= device_mesh unpad scattered_tensor pad_sizes my_rank scattered_tensor = unpad_tensor scattered_tensor shard_dim pad_sizes my_rank scattered_tensor numel == We need check numel instead size tensor after unpadding since size could after unpadding assertEqual scattered_tensor numel tensor_splitted_list my_rank numel assertEqual scattered_tensor size tensor_splitted_list my_rank size assertEqual scattered_tensor torch ones_like tensor_splitted_list my_rank res_num with_comms test_broadcast_nd mesh_tensor = torch arange reshape mesh = DeviceMesh device_type mesh_tensor local_tensor = torch ones device=self device_type rank check all dim groups dim_to_subgroups = mesh get_all_groups dim dim_group enumerate dim_to_subgroups dim_group_size = get_world_size dim_group global_ranks = get_global_rank dim_group i i range dim_group_size cloned_local_tensor = local_tensor clone mesh_broadcast cloned_local_tensor mesh mesh_dim=dim res_num = global_ranks assertEqual cloned_local_tensor torch ones res_num with_comms test_scatter_nd mesh_tensor = torch arange reshape mesh = DeviceMesh device_type mesh_tensor check all dim groups dim_to_subgroups = mesh get_all_groups dim dim_group enumerate dim_to_subgroups dim_group_size = get_world_size dim_group global_ranks = get_global_rank dim_group i i range dim_group_size scattered_tensors = torch ones device=self device_type global_rank global_rank global_ranks received_tensor = torch empty_like scattered_tensors mesh get_coordinate dim mesh_scatter received_tensor scattered_tensors mesh mesh_dim=dim assertEqual received_tensor torch ones rank CuTeLayoutTest TestCase test_coalesce - l = _Layout l = l coalesce assertEqual list l sizes_and_strides - l = _Layout l = l coalesce assertEqual list l sizes_and_strides test_coalesce_non_coalescible stays as-is ≠ l = _Layout l = l coalesce assertEqual list l sizes_and_strides test_complement_n_group_layout complement = together form pg_layout = _Layout outer = pg_layout complement world_size= assertEqual list outer sizes_and_strides assertEqual pg_layout all_ranks_from_zero groups = o + i i pg_layout all_ranks_from_zero o outer all_ranks_from_zero assertEqual groups assertEqual pg_layout global_ranks complement = together form outer = pg_layout complement world_size= assertEqual list outer sizes_and_strides assertEqual outer all_ranks_from_zero assertEqual pg_layout global_ranks Complement under world_size= → complement pg_layout = _Layout assertEqual pg_layout all_ranks_from_zero outer = pg_layout complement world_size= assertEqual list outer sizes_and_strides assertEqual outer all_ranks_from_zero assertEqual pg_layout global_ranks Test layout_to_global_ranks layout_to_all_ranks_from_zero pg_layout = _Layout assertEqual pg_layout all_ranks_from_zero assertEqual pg_layout global_ranks outer = pg_layout complement world_size= assertEqual list outer sizes_and_strides Test when stride monotonically decreasing complement layout same one sorted its stride pg_layout_r = _Layout outer = pg_layout_r complement world_size= assertEqual list outer sizes_and_strides assertEqual pg_layout_r global_ranks Test just all_ranks_from_zero global_ranks pg_layout = _Layout assertEqual pg_layout all_ranks_from_zero assertEqual pg_layout global_ranks test_composition = l = → o l = orig_l = _Layout right_l = _Layout composed_layout = orig_l composition right_l assertEqual list composed_layout sizes_and_strides assertEqual composed_layout global_ranks = l = → o l = orig_l = _Layout right_l = _Layout composed_layout = orig_l composition right_l assertEqual list composed_layout sizes_and_strides assertEqual composed_layout global_ranks = l = → o l = This mimic un-flatten D mesh D mesh right_l = _Layout composed_layout = orig_l composition right_l assertEqual list composed_layout sizes_and_strides assertEqual composed_layout global_ranks assertEqual composed_layout global_ranks Error case orig_l = _Layout assertRaises AssertionError right_l = _Layout orig_l composition right_l test_check_non_overlap Test check_non_overlap method various layout configurations Test Valid layout - no overlap sizes= strides= - stride span so no overlap layout = _Layout assertTrue layout check_non_overlap Test Invalid layout - overlap due stride previous span sizes= strides= - stride span causes overlap layout = _Layout assertFalse layout check_non_overlap Test Invalid layout - duplicate strides sizes= strides= - same stride causes overlap layout = _Layout assertFalse layout check_non_overlap Test Valid layout - single dimension layout = _Layout assertTrue layout check_non_overlap Test Valid layout - exact boundary case sizes= strides= - stride == span valid layout = _Layout assertTrue layout check_non_overlap Test Valid layout - multi-dimensional proper spacing layout = _Layout assertTrue layout check_non_overlap Test Valid layout - stride ordered layout = _Layout assertTrue layout check_non_overlap Test Valid layout - Interleaved no overlap layout = _Layout assertTrue layout check_non_overlap test_remap_to_tensor Test remap_to_tensor method various scenarios Test Consecutive ranks full world - should logical groups directly original_mesh = torch tensor dtype=torch int layout = _Layout row-major x result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected Test Non-consecutive ranks - should map actual ranks original_mesh = torch tensor dtype=torch int layout = _Layout result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected Test D layout consecutive ranks original_mesh = torch tensor dtype=torch int layout = _Layout result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected Test Complex strided layout non-consecutive ranks original_mesh = torch tensor dtype=torch int layout = _Layout result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected Test Tensor Cute representation D mesh original_mesh = torch tensor dtype=torch int layout = _Layout column-major style result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected Test Layout different stride pattern original_mesh = torch tensor dtype=torch int layout = _Layout column-major style result = layout remap_to_tensor original_mesh expected = torch tensor dtype=torch int assertEqual result expected __name__ == __main__ run_tests