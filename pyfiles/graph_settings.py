mypy allow-untyped-defs inspect warnings typing Any Optional typing_extensions deprecated torch torch utils data datapipes iter sharding _ShardingIterDataPipe SHARDING_PRIORITIES torch utils data graph DataPipe DataPipeGraph traverse_dps __all__ = apply_random_seed apply_sharding apply_shuffle_seed apply_shuffle_settings get_all_graph_pipes get_all_graph_pipes graph DataPipeGraph - list DataPipe _get_all_graph_pipes_helper graph set _get_all_graph_pipes_helper graph DataPipeGraph id_cache set int - list DataPipe results list DataPipe = dp_id datapipe sub_graph graph items dp_id id_cache continue id_cache add dp_id results append datapipe results extend _get_all_graph_pipes_helper sub_graph id_cache results _is_sharding_datapipe datapipe DataPipe - bool isinstance datapipe _ShardingIterDataPipe hasattr datapipe apply_sharding inspect ismethod datapipe apply_sharding apply_sharding datapipe DataPipe num_of_instances int instance_id int sharding_group=SHARDING_PRIORITIES DEFAULT - DataPipe r Apply dynamic sharding over ` ` sharding_filter ` ` DataPipe has method ` ` apply_sharding ` ` RuntimeError will raised when multiple ` ` sharding_filter ` ` presented same branch graph = traverse_dps datapipe _helper graph prev_applied=None dp sub_graph graph values applied = None _is_sharding_datapipe dp prev_applied None raise RuntimeError Sharding twice single pipeline likely unintended will cause data loss f Sharding already applied prev_applied while trying apply dp For BC only provide sharding_group accepted sig = inspect signature dp apply_sharding len sig parameters dp apply_sharding num_of_instances instance_id dp apply_sharding num_of_instances instance_id sharding_group=sharding_group applied = dp applied None applied = prev_applied _helper sub_graph applied _helper graph datapipe _is_shuffle_datapipe datapipe DataPipe - bool hasattr datapipe set_shuffle hasattr datapipe set_seed inspect ismethod datapipe set_shuffle inspect ismethod datapipe set_seed apply_shuffle_settings datapipe DataPipe shuffle Optional bool = None - DataPipe r Traverse graph ` ` DataPipes ` ` find set shuffle attribute Apply method each ` DataPipe ` has APIs ` ` set_shuffle ` ` ` ` set_seed ` ` Args datapipe DataPipe needs set shuffle attribute shuffle Shuffle option default ` ` None ` ` no-op graph shuffle None datapipe graph = traverse_dps datapipe all_pipes = get_all_graph_pipes graph shufflers = pipe pipe all_pipes _is_shuffle_datapipe pipe shufflers shuffle warnings warn ` shuffle=True ` set datapipe does contain ` Shuffler ` Adding one end Be aware default buffer size might sufficient your task stacklevel= datapipe = datapipe shuffle shufflers = datapipe shuffler shufflers shuffler set_shuffle shuffle datapipe deprecated ` apply_shuffle_seed ` deprecated since will removed future releases Please use ` apply_random_seed ` instead category=FutureWarning apply_shuffle_seed datapipe DataPipe rng Any - DataPipe apply_random_seed datapipe rng _is_random_datapipe datapipe DataPipe - bool hasattr datapipe set_seed inspect ismethod datapipe set_seed apply_random_seed datapipe DataPipe rng torch Generator - DataPipe r Traverse graph ` ` DataPipes ` ` find random ` ` DataPipe ` ` API ` ` set_seed ` ` Then set random seed based provided RNG those ` ` DataPipe ` ` Args datapipe DataPipe needs set randomness rng Random number generator generate random seeds graph = traverse_dps datapipe all_pipes = get_all_graph_pipes graph Using set track id DataPipe prevent setting randomness per DataPipe more than once And ` id ` used case unhashable DataPipe cache = set random_datapipes = pipe all_pipes id pipe cache continue _is_random_datapipe pipe random_datapipes append pipe cache add id pipe pipe random_datapipes random_seed = int torch empty dtype=torch int random_ generator=rng item pipe set_seed random_seed datapipe