mypy allow-untyped-defs functools partial typing Optional torch torch nn functional F expanded_weights_impl implements_per_sample_grads expanded_weights_utils forward_helper set_grad_sample_if_exists standard_kwargs unpack_expanded_weight_or_tensor implements_per_sample_grads F instance_norm InstanceNormPerSampleGrad torch autograd Function staticmethod pyrefly ignore bad-override forward ctx kwarg_names _ expanded_args_and_kwargs instance_norm = partial torch instance_norm cudnn_enabled=True expanded_args expanded_kwargs = standard_kwargs kwarg_names expanded_args_and_kwargs output = forward_helper instance_norm expanded_args expanded_kwargs ctx input = expanded_args ctx running_mean ctx running_var = expanded_kwargs running_mean expanded_kwargs running_var ctx weight ctx bias ctx eps = expanded_kwargs weight expanded_kwargs bias expanded_kwargs eps output staticmethod pyrefly ignore bad-override backward ctx grad_output input running_mean running_var = ctx input ctx running_mean ctx running_var weight bias eps = ctx weight ctx bias ctx eps results list Optional torch Tensor = results append None kwarg names results append None op reference input requires_grad b = input shape c = input shape new_shape = b c input shape weight_ = unpack_expanded_weight_or_tensor weight lambda orig_weight orig_weight repeat b running_mean_ = running_mean repeat b running_mean None None running_var_ = running_var repeat b running_var None None input_reshaped = input contiguous view new_shape grad_output_reshaped = grad_output contiguous view new_shape mean = torch mean input_reshaped + tuple range input dim False var = torch var input_reshaped + tuple range input dim keepdim=False unbiased=False rstd = torch sqrt var + eps must use native batch norm since supports all inputs This may have used cuda openmi during forward didn t save metadata so we don t know during backward res = torch ops aten native_batch_norm_backward grad_output_reshaped input_reshaped weight_ running_mean_ running_var_ mean rstd True eps True False False results append res reshape input shape results append None weight bias don t compute batched gradients no other arguments differentiable saved forward results = results + None set grad_sample field weight bias per sample gradients set_grad_sample_if_exists weight lambda _ torch einsum ni - ni F instance_norm input eps=eps grad_output set_grad_sample_if_exists bias lambda _ torch einsum ni - ni grad_output tuple results