Owner s module dynamo io logging warnings unittest mock patch torch torch _dynamo torch _dynamo test_case torch _dynamo testing torch _dynamo testing same torch _dynamo utils counters torch testing _internal common_utils instantiate_parametrized_tests parametrize logger = logging getLogger __name__ logger_test = logging getLogger test f_info x x = x + x logger info moo x = x x x f_isEnabledFor x x = x + x logger isEnabledFor logging INFO logger info moo x = x x x instantiate_parametrized_tests IgnoreLogsTests torch _dynamo test_case TestCase parametrize ignore_method fn should_ignore_logger None f_info False logger_test info f_info False None f_isEnabledFor False logger_test isEnabledFor f_isEnabledFor False logger info f_info True logging Logger info f_info True logger isEnabledFor f_isEnabledFor True logging Logger isEnabledFor f_isEnabledFor True test_ignore_logger ignore_method fn should_ignore_logger counters clear x = torch randn orig_out = fn x torch _dynamo config patch ignore_logger_methods= ignore_method opt_f = torch compile backend= eager fn assertLogs logger level= INFO captured logger info call logger info avoid error opt_out = opt_f x printed_output = entry split entry captured output assertTrue same orig_out opt_out should_ignore_logger assertNotIn moo printed_output assertEqual len counters graph_break assertIn moo printed_output assertEqual len counters graph_break ReorderLogsTests torch _dynamo test_case TestCase test_dont_reorder_print f x x = x + x print moo x = x x x counters clear x = torch randn opt_f = torch compile backend= eager f patch sys stdout new_callable=io StringIO mock_stdout opt_out = opt_f x printed_output = mock_stdout getvalue strip orig_out = f x assertTrue same orig_out opt_out assertEqual printed_output moo assertEqual len counters graph_break torch _dynamo config patch reorderable_logging_functions= print test_reorder_print f x print moo x = x + x print x x = x x print x = x + x x x x = torch ones opt_f = torch compile backend= eager fullgraph=True f patch sys stdout new_callable=io StringIO mock_stdout opt_out = opt_f x printed_output = mock_stdout getvalue strip orig_out = f x assertEqual printed_output f moo\n torch ones \n assertTrue same orig_out opt_out torch _dynamo config patch reorderable_logging_functions= warnings warn test_reorder_warnings warnings f x x = x + x warnings warn moo x = x x warnings warn f x x = x + x x x = torch ones opt_f = torch compile backend= eager fullgraph=True f warnings catch_warnings record=True w opt_out = opt_f x warning_messages = str i message i w orig_out = f x assertTrue same orig_out opt_out assertIn moo warning_messages torch _dynamo config patch reorderable_logging_functions= print test_reorder_print_graph_break f x x = x + x print f res x x = x x torch _dynamo graph_break x = x + x print x x = torch ones opt_f = torch compile backend= eager f patch sys stdout new_callable=io StringIO mock_stdout opt_out = opt_f x printed_output = mock_stdout getvalue strip orig_out = f x assertEqual printed_output f res torch ones \n assertTrue same orig_out opt_out test_reorder_custom_log_fn custom_logs = custom_log s str torch _dynamo graph_break custom_logs append s f x custom_log moo x = x + x custom_log f x x + x x = torch ones counters clear torch _dynamo config patch reorderable_logging_functions= custom_log opt_f = torch compile backend= eager f opt_f x assertEqual sum counters graph_break values assertEqual custom_logs moo assertEqual custom_logs f torch ones torch _dynamo config patch reorderable_logging_functions= print test_constant_mutation f x alist = x alist append x + print alist - alist sum item graph break res = alist pop print alist - res sum item graph break res inputs = torch tensor counters clear opt_f = torch compile backend= eager f patch sys stdout new_callable=io StringIO mock_stdout opt_out = opt_f inputs printed_output = mock_stdout getvalue strip orig_out = f inputs assertEqual printed_output tensor \ntensor assertTrue same orig_out opt_out graph_break_key = counters graph_break keys assertEqual len graph_break_key assertExpectedInline next iter graph_break_key \ Unsupported Tensor item call capture_scalar_outputs=False Explanation Dynamo does support tracing ` Tensor item ` config capture_scalar_outputs=False Hint Set ` torch _dynamo config capture_scalar_outputs = True ` ` export TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS= ` include these operations captured graph Developer debug context call_method TensorVariable item For more details about graph break please visit https meta-pytorch github io compile-graph-break-site gb gb html noqa B __name__ == __main__ torch _dynamo test_case run_tests run_tests