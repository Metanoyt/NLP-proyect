mypy allow-untyped-defs functools typing Union sympy torch _inductor config torch _inductor codegen simd IterationRangesRoot prefix_is_reduction torch _inductor codegen triton triton_compute_type TritonCSEVariable TritonKernel torch _inductor runtime triton_heuristics SplitScanGrid torch utils _ordered_set OrderedSet torch utils _sympy functions CeilDiv utils sympy_product TritonSplitScanKernel TritonKernel Generates triton kernel supports ops scan calls while also splitting reduction dimension over multiple triton programs For kernel loop numels will always take form ` ` xdim rdim ` ` grid has shape ` ` CeilDiv rdim RBLOCK xdim ` ` Communication between blocks occurs within global memory workspace buffer which must zero-filled before launching kernel Note generation ` ` ops reduction ` ` supported For details communication strategy see https research nvidia com publication - _single-pass-parallel-prefix-scan-decoupled-look-back __init__ tiling dict str sympy Expr pid_cache=None fixed_config=None kwargs - None assert pid_cache None supported assert fixed_config None supported super __init__ tiling kwargs no_x_dim = True should_use_persistent_reduction - bool False should_use_cooperative_reduction - bool False initialize_range_tree pid_cache prefixes = y x r _ assert len numels = len prefixes z dimension supported split scan active_prefixes = prefixes len prefixes - len numels grid_dims = r _ x y prefix active_prefixes numel = numels prefix tensor_dim = prefix_is_reduction prefix None grid_dim = grid_dims prefix range_trees append IterationRangesRoot f prefix index numel prefix grid_dim type ignore arg-type pid_cache=pid_cache is_loop=False tensor_dim=tensor_dim grid_dim=grid_dim has_zdim=False reduction dtype src_dtype reduction_type value raise NotImplementedError NYI TritonSplitDimKernel reductions scan dtypes combine_fn values Perform associative scan values triton language tl dtype = dtypes value = values compute_type = triton_compute_type dtype compute_type_triton = getattr tl compute_type element_nbits = compute_type_triton primitive_bitwidth scratch_type = tl uint element_nbits = tl uint scratch_type_triton = getattr tl scratch_type scratch_elems_per_block = element_nbits == scratch_nbytes_per_block = scratch_elems_per_block scratch_type_triton primitive_bitwidth cse_load = functools partial cse generate loads dtype=dtype cse_compute = functools partial cse generate compute assert len numels == Unexpected tiling min_rblock = config triton min_split_scan_rblock reduction_numel = sympy_product numel prefix numel numels items prefix_is_reduction prefix pointwise_numel = sympy_product numel prefix numel numels items prefix_is_reduction prefix max_blocks = pointwise_numel CeilDiv reduction_numel min_rblock nbytes = scratch_nbytes_per_block max_blocks scratch_base Union str TritonCSEVariable scratch_base _ offset = args workspace nelem=nbytes zero_fill=True offset = scratch_base = cse_load f scratch_base + index_to_str offset shape= runtime_rblocks = cse_load f tl num_programs range_trees - index shape= scratch_base = cse_load f scratch_base tl pointer_type scratch_type + xoffset f scratch_elems_per_block runtime_rblocks shape= masks = OrderedSet f tree prefix mask tree range_trees filter_masks masks assert _load_mask ops scan supported inside ops masked value = cse_compute f value compute_type dtype=dtype shape=value shape value = cse_compute f tl broadcast_to value dense_size_str dtype=dtype shape=self dense_size_list combine_helper_fn = _lift_helper combine_fn value dtype dim = triton_tensor_ndim - assert dim == shape = list dense_size_list del shape dim block_sum = cse_compute f tl reduce value dim combine_helper_fn dtype=dtype shape=shape exclusive_prefix = cse newvar dtype=dtype shape=shape element_nbits == compute splice f exclusive_prefix = triton_helpers exclusive_scan_decoupled_lookback_ scratch_base block_sum iteration_ranges_get_pid range_trees - combine_helper_fn strip=True assert element_nbits = value_as_uint_dtype = f tl uint element_nbits compute splice f exclusive_prefix = triton_helpers exclusive_scan_decoupled_lookback scratch_base block_sum iteration_ranges_get_pid range_trees - combine_helper_fn DTYPE_VALUE_AS_UINT= value_as_uint_dtype DTYPE_PACK= scratch_type strip=True Compute final cumsum block_scan = cse_compute f tl associative_scan value dim combine_helper_fn dtype=dtype shape=shape combined_result = cse_compute f combine_helper_fn exclusive_prefix block_scan dtype=dtype shape=shape cse_compute f tl where roffset == block_scan combined_result dtype=dtype shape=block_scan shape _get_heuristic split_scan _get_grid_type - type SplitScanGrid SplitScanGrid