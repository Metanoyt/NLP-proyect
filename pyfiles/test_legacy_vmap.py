Owner s module vmap ruff noqa F functools itertools types warnings torch torch nn functional F torch Tensor torch _vmap_internals vmap torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_utils run_tests skipIfTorchDynamo TestCase FALLBACK_REGEX = r There performance drop EnableVmapFallbackWarnings __enter__ prev_state = torch _C _debug_only_are_vmap_fallback_warnings_enabled torch _C _debug_only_display_vmap_fallback_warnings True __exit__ ignored torch _C _debug_only_display_vmap_fallback_warnings prev_state TestVmapAPILegacy TestCase test_non_tensor_output_raises assertRaisesRegex ValueError got type float output = vmap lambda x torch ones multiple_outputs x x assertRaisesRegex ValueError got type int vmap multiple_outputs torch ones test_different_map_dim_size_raises x = torch randn y = torch randn expected_msg = Expected all tensors have same size mapped dimension assertRaisesRegex ValueError expected_msg vmap torch mul x y assertRaisesRegex ValueError expected_msg vmap lambda z z + z in_dims= x y assertRaisesRegex ValueError expected_msg vmap lambda z z x + z y in_dims= x y x x y y test_func_with_no_inputs expected_msg = got no inputs foo torch randn bar x torch randn assertRaisesRegex ValueError expected_msg vmap foo assertRaisesRegex ValueError expected_msg vmap bar test_constant_function output = vmap lambda x torch tensor torch ones assertEqual output torch tensor test_single_input x = torch randn square x x x output = vmap square x assertEqual output x x test_multiple_inputs x = torch randn y = torch randn output = vmap torch mul x y assertEqual output x y test_multiple_outputs foo x x x x x x x = torch randn outputs = vmap foo x assertEqual outputs x x assertEqual outputs x x x test_multiple_outputs_error_cases This same thing returns_tuple_of_tensors x x x returns_tuple_of_tensors x x x returns_list_of_two_tensors x x x returns_list_of_one_tensor x x x = torch randn should throw vmap returns_tuple_of_tensors x jax supports these we don t yet msg = must only Tensors got type list assertRaisesRegex ValueError msg vmap returns_list_of_two_tensors x assertRaisesRegex ValueError msg vmap returns_list_of_one_tensor x test_nested_with_same_map_dim x = torch randn y = torch randn output = vmap vmap torch mul x y assertEqual output x y output = vmap vmap vmap torch mul x y assertEqual output x y test_nested_with_different_map_dim x = torch randn y = torch randn output = vmap lambda x vmap lambda y x y y x assertEqual output shape assertEqual output x view y z = torch randn output = vmap lambda x vmap lambda y vmap lambda z x y z z y x assertEqual output shape assertEqual output x view y view z test_noop_in_inner_vmap x = torch randn y = torch randn output = vmap lambda x vmap lambda y x y x assertEqual output x view expand test_unsupported_op_err_msg Unsupported view op tensor = torch randn msg = r Batching rule implemented aten + r fallback path doesn t work out= view ops assertRaisesRegex RuntimeError msg vmap torch ravel tensor out_op x y torch abs x out=y assertRaisesRegex RuntimeError msg vmap out_op tensor tensor tensor = torch randn The fallback doesn t support TensorList assertRaisesRegex RuntimeError Batching rule implemented vmap lambda t torch atleast_ d t tensor Don t support non-tensor returns This limitation vmap functions don t tensors must special cased assertRaisesRegex RuntimeError Batching rule implemented vmap torch Tensor item tensor test_nonzero_out_dims Basic test tensor = torch randn result = vmap lambda x x out_dims= tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr Test batch dimension gets permuted dim tensor = torch randn result = vmap lambda x x out_dims= tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr negative out_dim tensor = torch randn result = vmap lambda x x out_dims=- tensor assertEqual result tensor permute assertEqual result data_ptr tensor data_ptr check out_dims works ALL outputs tensor = torch randn other = torch randn result = vmap lambda x y x y out_dims= tensor other assertEqual result tensor permute other permute use out_dims maximum vmap-able tensor dims dims ndims = shape = + ndims - expected_shape = + ndims - tensor = torch randn shape result = vmap lambda x x out_dims= tensor assertEqual result shape expected_shape test something identity function foo x y x x y x y y x = torch randn y = torch randn result = vmap foo out_dims= x y assertEqual result x permute x y permute x y y permute test_multiple_out_dims foo x x x bar x y x x x x y x = torch randn y = torch randn result = vmap foo out_dims= x assertEqual result x x permute result = vmap bar out_dims= - x y expected = x permute x x permute x y permute assertEqual result expected test_nested_out_dims y = torch randn Inner vmap has non-zero out_dim result = vmap lambda y vmap lambda x x out_dims= y y assertEqual result shape assertEqual result y permute all vmaps have non-zero out_dim result = vmap lambda y vmap lambda x x out_dims= y out_dims= y assertEqual result shape assertEqual result y permute throwing some negative out_dims result = vmap lambda y vmap lambda x x out_dims=- y out_dims=- y assertEqual result shape assertEqual result y permute testing fn isn t identity x = torch randn y = torch randn result = vmap lambda y vmap lambda x x y out_dims= x out_dims=- y assertEqual result shape assertEqual result y view x permute test_out_dims_edge_case foo x x Test we accept out_dims= function one output tensor = torch randn expected = vmap foo out_dims= tensor result = vmap foo out_dims= tensor assertEqual result expected test_out_dims_must_be_int_or_tuple_of_int_err_msg msg = ` out_dims ` must int tuple int tensor = torch randn assertRaisesRegex ValueError msg vmap lambda x x out_dims= lol tensor assertRaisesRegex ValueError msg vmap lambda x x out_dims= lol tensor assertRaisesRegex ValueError msg vmap lambda x x out_dims=None tensor assertRaisesRegex ValueError msg vmap lambda x x out_dims= None tensor test_out_dims_and_num_outputs_mismatch_err_msg msg = ` out_dims ` must have one dim per output x = torch randn Too many out_dims assertRaisesRegex ValueError msg vmap lambda x x out_dims= x assertRaisesRegex ValueError msg vmap lambda x x x x out_dims= x Too few out_dims assertRaisesRegex ValueError msg vmap lambda x x x out_dims= x assertRaisesRegex ValueError msg vmap lambda x x x x out_dims= x test_out_dim_out_of_bounds_err_msg TODO rzou This error message isn t great It comes straight maybe_wrap_dim Consider doing try-catch- add some context error message future C++ msg = Dimension out range x = torch randn assertRaisesRegex IndexError msg vmap lambda x x out_dims= x assertRaisesRegex IndexError msg vmap lambda x x out_dims=- x test_non_zero_in_dims tensor = torch randn Implicit out_dims = vmap will move batch dim front output = vmap lambda x x tensor assertEqual output tensor permute assertEqual output data_ptr tensor data_ptr x = torch randn y = torch randn output = vmap torch mul x y assertEqual output x y t output = vmap torch mul x y assertEqual output x t y test_none_in_dims x = torch randn y = torch randn None in_dim Tensor means we don t map over output = vmap torch mul None x y assertEqual output shape assertEqual output x view y None in_dim non-tensor arguments output = vmap torch mul None x assertEqual output x test_nested_non_default_in_dims x = torch rand y = torch rand result = vmap vmap vmap torch mul x y assertEqual result x permute y permute test_non_default_in_dims_out_dims x = torch randn Same in_dim out_dim vmap over identity result = vmap lambda x x in_dims= out_dims= x assertEqual result x assertEqual result data_ptr x data_ptr Different in_dim out_dim vmap over identity result = vmap lambda x x in_dims= out_dims= x assertEqual result shape assertEqual result x transpose assertEqual result data_ptr x data_ptr foo x x Same in_dim out_dim vmap over operation result = vmap foo in_dims= out_dims= x assertEqual result x Different in_dim out_dim vmap over operation result = vmap foo in_dims= out_dims= x assertEqual result shape assertEqual result x transpose Basic nested test result = vmap vmap foo x assertEqual result x test_accepts_nested_inputs B = x = torch randn y = torch randn Single layer nesting out = vmap lambda z z + z x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z + z in_dims= x y assertEqual out x + y out = vmap lambda z z x + z y x x y y assertEqual out x + y out = vmap lambda z z x + z y in_dims= x x y y assertEqual out x + y out = vmap lambda z z x + z y in_dims= x y x x y y assertEqual out x + y Multiple layers nesting out_fn = vmap lambda z z x + z x + z y + z y out = out_fn x x x y y y assertEqual out x + x + y + y test_in_dims_wrong_type_err_msg x = torch randn y = torch randn msg = r expected ` in_dims ` int \ potentially nested\ tuple assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap torch mul set x y assertRaisesRegex ValueError msg vmap torch mul lol x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y The following should throw vmap torch mul x y test_not_enough_in_dims_err_msg x = torch randn y = torch randn msg = r in_dims compatible structure ` inputs ` assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap torch mul x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y The following should throw vmap torch mul x y test_integer_in_dim_but_not_tensor_input_err_msg foo xy xy xy bar x yz x yz yz x = torch randn y = torch randn following errors jax will always errors msg = Got in_dim= input input type assertRaisesRegex ValueError msg vmap torch sum x assertRaisesRegex ValueError msg vmap torch sum x assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x The following should throw vmap torch sum None x test_in_dim_not_in_tensor_err_msg foo x x x x = torch randn y = torch randn msg = r Got in_dim=- \w some input input Tensor dimensionality \w assertRaisesRegex ValueError msg vmap foo torch randn assertRaisesRegex ValueError msg vmap foo in_dims= torch randn assertRaisesRegex ValueError msg vmap foo in_dims= - x assertRaisesRegex ValueError msg vmap foo in_dims= y assertRaisesRegex ValueError msg vmap lambda z z + z in_dims= x y following should throw vmap foo in_dims= torch randn vmap foo in_dims= torch randn test_fallback_does_not_warn_by_default NB One day we will implement batching rule torch atan If when we do test should replaced test fallback path another operator avoid bitrot op = torch atan x = torch randn y = torch randn warnings catch_warnings record=True wa result = vmap op x y The single warning here vmap experimental warning warning vmap fallback path assertEqual len wa test_fallback_warns_when_warnings_are_enabled NB One day we will implement batching rule torch atan If when we do test should replaced test fallback path another operator avoid bitrot op = torch atan x = torch randn y = torch randn warnings catch_warnings record=True wa EnableVmapFallbackWarnings result = vmap op x y assertEqual len wa assertRegex str wa - message FALLBACK_REGEX _assert_uses_vmap_fallback vmap_args inputs warnings catch_warnings record=True wa EnableVmapFallbackWarnings result = vmap vmap_args inputs assertEqual len wa assertRegex str wa - message FALLBACK_REGEX test_fallback_zero_dim NB One day we will implement batching rule torch atan If when we do test should replaced test fallback path another operator avoid bitrot op = torch atan x = torch randn y = torch randn _assert_uses_vmap_fallback op x y B B = x = torch randn B y = torch randn msg = The fallback path does support vmap over dims size assertRaisesRegex RuntimeError msg vmap op None x y assertRaisesRegex RuntimeError msg vmap op None y x assertRaisesRegex RuntimeError msg vmap op x x x = torch randn B B y = torch randn B assertRaisesRegex RuntimeError msg vmap op None x y assertRaisesRegex RuntimeError msg vmap op None y x assertRaisesRegex RuntimeError msg vmap op x x test_fallback_atan NB One day we will implement batching rule torch atan If when we do test should replaced test fallback path another operator avoid bitrot op = torch atan x = torch randn y = torch randn _assert_uses_vmap_fallback op x y fallback torch atan x = torch randn y = torch randn result = vmap op x y assertEqual result op x permute y fallback torch atan nested vmap x = torch randn y = torch randn result = vmap vmap op x y assertEqual result op x permute y big batch size total x = torch randn y = torch randn result = vmap vmap vmap op x y assertEqual result op x y view test_fallback_masked_fill NB One day we will implement batching rule masked_fill If when we do test should replaced test fallback path another operator avoid bitrot run_test batch_size B = batch_size x = torch randn B dim = index = torch tensor values = torch randn B _assert_uses_vmap_fallback torch index_add None None x dim index values result = vmap torch index_add None None x dim index values expected = torch index_add x dim + index values view B assertEqual result expected run_test batch_size= run_test batch_size= test_fallback_multiple_returns NB One day we will implement batching rule torch var_mean If when we do test should replaced test fallback path another operator avoid bitrot B B B = tensor = torch randn B _assert_uses_vmap_fallback torch var_mean tensor fallback correctness torch var_mean result = vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected nested vmap tensor = torch randn B B result = vmap vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected big batch size nested vmap tensor = torch randn B B B result = vmap vmap vmap torch var_mean tensor expected = torch var_mean tensor dim= assertEqual result expected test_inplace_fallback_unary Test in-place fallback in-place method takes no additional Tensor arguments This simplest case fallback NB One day we will implement batching rule acos_ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor acos_ B B B = x = torch randn B _assert_uses_vmap_fallback op x Single vmap x_orig = torch rand B x = x_orig clone result = vmap op x assertTrue result x assertEqual result x_orig acos Single vmap + different out_dim produces view x_orig = torch rand B x = x_orig clone result = vmap op out_dims= x assertTrue result _base x assertEqual result x_orig t acos Nested vmap x_orig = torch randn B B x = x_orig clone result = vmap vmap op x assertTrue result x assertEqual result x_orig acos Nested vmap large batch size x_orig = torch randn B B B x = x_orig clone result = vmap vmap vmap op x assertTrue result x assertEqual result x_orig acos test_inplace_fallback_nary_same_levels NB One day we will implement batching rule atan _ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor atan _ outplace_op = torch atan x = torch randn y = torch randn _assert_uses_vmap_fallback op x y Single vmap B = x_orig = torch randn B x = x_orig clone y = torch randn B vmap op x y assertEqual x outplace_op x_orig y movedim Nested vmap B B = x_orig = torch randn B B x = x_orig clone y = torch randn B B vmap vmap op x y assertEqual x outplace_op x_orig y movedim big batch size total B B B = x_orig = torch randn B B B x = x_orig clone y = torch randn B B B result = vmap vmap vmap op x y assertEqual x outplace_op x_orig y view B B B test_inplace_fallback_nary_different_levels NB One day we will implement batching rule atan _ If when we do test should replaced test fallback path another operator avoid bitrot op = Tensor atan _ outplace_op = torch atan B B B = x = torch rand B y = torch rand _assert_uses_vmap_fallback op None x y op left right All levels right found left x_orig = torch rand B x = x_orig clone y = torch rand vmap op in_dims= None x y assertEqual x outplace_op x_orig y x_orig = torch rand B B x = x_orig clone y = torch rand B vmap vmap op in_dims= None x y assertEqual x outplace_op x_orig y view B op left right Some levels right found left msg = r vmap aten atan _\ \ extra_args\ possible x = torch rand y = torch rand B assertRaisesRegex RuntimeError msg vmap op in_dims= None x y x = torch rand B y = torch rand B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None in_dims= None x y x = torch rand B y = torch rand B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None in_dims= None x y x = torch rand B y = torch rand B B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= None x y test_backward_unsupported_interaction x = torch randn requires_grad=True y = torch randn grad = torch randn_like x err_msg = r backward\ \ called inside torch vmap backward_on_vmapped_tensor x x sum backward assertRaisesRegex RuntimeError err_msg vmap backward_on_vmapped_tensor x backward_with_vmapped_grad x grad x backward grad assertRaisesRegex RuntimeError err_msg vmap backward_with_vmapped_grad x grad completely_unrelated_backward y x sum backward assertRaisesRegex RuntimeError err_msg vmap completely_unrelated_backward y test_grad_unsupported_interaction input_tensor = torch randn requires_grad=True err_msg = autograd grad called inside torch vmap captured = torch randn requires_grad=True output_to_grad_is_vmapped input_tensor output = captured input_tensor sum torch autograd grad output captured assertRaisesRegex RuntimeError err_msg vmap output_to_grad_is_vmapped input_tensor output = input_tensor sum input_to_grad_is_vmapped input_tensor torch autograd grad output input_tensor assertRaisesRegex RuntimeError err_msg vmap input_to_grad_is_vmapped input_tensor test_batched_gradient_basic N = x = torch randn N requires_grad=True y = torch randn N vjp_mul v torch autograd grad x y x grad_outputs= v batched_v = torch eye N jacobian = vmap vjp_mul batched_v assertEqual jacobian torch diagflat y test_functools_partial x = torch randn y = torch randn result = vmap functools partial torch mul x y assertEqual result x y test_nn_module tensor = torch randn model = torch nn Linear bias=False result = vmap model tensor assertEqual result model tensor test_fallback_with_undefined_grad B = x = torch randn requires_grad=True weight = torch randn v = torch randn B get_vjp v result = torch nn functional conv d x weight grad_x = torch autograd grad result x v grad_x Runs vmap get_vjp v which should error out The backward formula convolution returns undefined Tensor grad_bias because original bias does exist In future we ll probably add batching rule convolution backward When happens we should modify test use different op create use dummy operator avoid bitrot _assert_uses_vmap_fallback get_vjp v slice_inputs inputs bdims i result = inp bdim zip inputs bdims bdim None result append inp result append inp select bdim i tuple result reference_vmap op inputs in_dims= out_dims= isinstance in_dims int in_dims = in_dims len inputs bdim_sizes = inp size dim inp dim zip inputs in_dims dim None assert all bdim_size == bdim_sizes bdim_size bdim_sizes bdim_size = bdim_sizes results = tuple op slice_inputs inputs in_dims i i range bdim_size assert len results op_has_single_return = isinstance results tuple op_has_single_return assert all isinstance result torch Tensor result results isinstance out_dims int out_dims = out_dims torch stack results dim=out_dims assert all isinstance result tuple result results num_returns = len results assert all len result == num_returns result results isinstance out_dims int out_dims = out_dims num_returns tuple torch stack result_shards out_dim result_shards out_dim zip zip results out_dims TensorFactory staticmethod rand size device= cpu dtype=torch float torch rand size device=device dtype=dtype staticmethod randn size device= cpu dtype=torch float torch randn size device=device dtype=dtype staticmethod randp size device= cpu dtype=torch float torch rand size device=device dtype=dtype + Tests vmap op in_dims out_dims inputs comparing output slow sequential map+stack fallback check_view Test first returned output view first input check_propagates_grad Test operation propagates gradients _vmap_test op inputs in_dims= out_dims= check_view=False check_propagates_grad=True result = vmap op in_dims out_dims inputs reference_result = reference_vmap op inputs in_dims out_dims assertEqual result reference_result op_has_single_return = isinstance result tuple check_view result_as_tuple = result op_has_single_return result output result_as_tuple input _base = inputs inputs _base None inputs _base assertTrue output _base input _base msg= result view first input check_propagates_grad Assuming input floating-point tensor Check vmap operation propagates requires_grad flag zeroth output Some vmap operators implemented way assumes they composite respect autograd If operator ever changed composite respect autograd then following check should fail inputs_clone = list inputs inputs_clone = inputs clone requires_grad_ result = vmap op in_dims out_dims inputs_clone result_as_tuple = result op_has_single_return result assertTrue result requires_grad should_allow_vmap_fallback_usage fn getattr fn _allow_vmap_fallback_usage False allowVmapFallbackUsage fn fn _allow_vmap_fallback_usage = True fn All tests TestVmapBaseLegacy check slow vmap fallback never invoked This so we can incrementally add batching rules operators replace slow vmap fallback path said operators To skip check please use allowVmapFallbackUsage decorator NB Don t add tests TestVmapBaseLegacy directly unless you want them run every subclass TestVmapBaseLegacy Add them e g TestVmapOperators NB TestVmapBaseLegacy nested This prevents test runners picking up running Namespace TestVmapBaseLegacy TestCase __init__ method_name= runTest super __init__ method_name test_method = getattr method_name None test_method None should_allow_vmap_fallback_usage test_method setattr method_name _wrap_method_with_vmap_fallback_check test_method _wrap_method_with_vmap_fallback_check method msg = Expected test invoke vmap fallback path i e all operators being tested test should have batching rules implemented If you intentionally testing something do fallback path use allowVmapFallbackUsage Otherwise please make sure batching rules implemented operator s being tested functools wraps method wrapper args kwargs warnings catch_warnings record=True wa warnings simplefilter always EnableVmapFallbackWarnings method args kwargs captured_warning wa assertNotRegex str captured_warning message FALLBACK_REGEX msg types MethodType wrapper allowVmapFallbackUsage test_vmap_fallback_check_ok One day we ll implement batching rule torch var_mean When happens please change example use operator doesn t have batching rule implemented op_using_fallback = torch var_mean vmap op_using_fallback torch rand test_vmap_fallback_check _wrap_method_with_vmap_fallback_check no_fallback pass One day we ll implement batching rule torch var_mean When happens please change example use operator doesn t have batching rule implemented op_using_fallback = torch var_mean _wrap_method_with_vmap_fallback_check uses_fallback vmap op_using_fallback torch rand no_fallback assertRaises AssertionError uses_fallback TestVmapOperatorsLegacy Namespace TestVmapBaseLegacy _vmap_test args kwargs _vmap_test args kwargs _vmap_view_test args kwargs _vmap_test args kwargs check_view=True _test_unary op getter device args kwargs test = functools partial _vmap_test args kwargs B B = Single vmap various in_dims out_dims test op getter B device test op getter B device in_dims= test op getter B device in_dims= out_dims= Doubly nested vmap test vmap op getter B B device test vmap op getter B B device in_dims= test vmap op in_dims= getter B B device in_dims= out_dims= test_unary_pointwise_ops cases = torch abs TensorFactory randn torch acos TensorFactory rand torch asin TensorFactory rand torch atan TensorFactory rand torch ceil TensorFactory randn torch cos TensorFactory rand torch cosh TensorFactory rand torch digamma TensorFactory rand torch exp TensorFactory randn torch expm TensorFactory randn torch floor TensorFactory randn torch frac TensorFactory randn torch lgamma TensorFactory rand torch log TensorFactory randp torch log TensorFactory randp torch log p TensorFactory randp torch log TensorFactory randp torch neg TensorFactory randn torch reciprocal TensorFactory randp torch relu TensorFactory randn torch round TensorFactory randn torch rsqrt TensorFactory randp torch sigmoid TensorFactory randn torch sign TensorFactory randn torch sin TensorFactory rand torch sinh TensorFactory rand torch sqrt TensorFactory rand torch tan TensorFactory rand torch tanh TensorFactory rand torch trunc TensorFactory randn op getter cases _test_unary op getter cpu test_clone Some basic tests _test_unary lambda x x clone TensorFactory randn cpu _test_unary lambda x x clone memory_format=torch preserve_format TensorFactory randn cpu _test_unary lambda x x clone memory_format=torch contiguous_format TensorFactory randn cpu Test per-examples contiguous when using torch contiguous_format clone_contiguous x x clone memory_format=torch contiguous_format B B = x = torch randn B y = vmap clone_contiguous in_dims= out_dims= x assertTrue y movedim is_contiguous assertTrue y is_contiguous x = torch randn B B y = vmap vmap clone_contiguous in_dims= in_dims= x assertTrue y is_contiguous assertTrue y is_contiguous msg = r only supported memory_format torch preserve_format torch contiguous_format assertRaisesRegex RuntimeError msg vmap lambda x x clone memory_format=torch channels_last torch randn B assertRaisesRegex RuntimeError msg vmap lambda x x clone memory_format=torch channels_last_ d torch randn B test_binary_pointwise_ops get_number getter getter item make_case op input_getter=TensorFactory randn op input_getter cases = Basic arithmetic make_case torch add make_case lambda x y x + y make_case torch sub make_case lambda x y x - y make_case torch mul make_case lambda x y x y make_case torch div input_getter=TensorFactory randp make_case lambda x y x y input_getter=TensorFactory randp make_case torch pow input_getter=TensorFactory randp make_case lambda x y x y input_getter=TensorFactory randp test = _vmap_test op getter cases device = cpu B B = Single vmap op Tensor Tensor test op getter B device getter B device test op getter B device getter B device test op getter B device getter B device in_dims= test op getter B device getter B device in_dims= out_dims= test op getter B device getter device in_dims= None test op getter device getter B device in_dims= None Nested vmap op Tensor Tensor test vmap op getter B B device getter B B device test vmap op in_dims= None getter B device getter B device in_dims= None Python number overload op Tensor Number vice-versa number = get_number getter _test_unary lambda t op t number getter device number = get_number getter _test_unary lambda t op number t getter device Type promotion op Logical Scalar Tensor Logical Scalar Tensor test op getter B device getter B device dtype=torch double test op getter B device dtype=torch double getter B device test op getter B device getter B device Type promotion op Tensor Logical Scalar Tensor vice-versa test op getter B device getter B device torch double test op getter B device torch double getter B device torch cuda is_available continue TODO rzou fix following Test cross-device scalars number = get_number getter _test_unary lambda t op t number getter device= cuda _test_unary lambda t op number t getter device= cuda _test_unary lambda t op t torch tensor number getter device= cuda test_as_strided _test sizes strides offset tensor lambd result = vmap lambda t t as_strided sizes strides offset tensor expected = vmap lambd tensor assertTrue result _base expected _base assertEqual result expected single vmap test B = tensors = contiguous torch randn B non-contiguous torch randn B transpose non-zero storage offset torch randn B non-contiguous strides zero storage offset torch randn B non-contiguous strides non-zero storage offset torch randn B x tensors S S = x stride offset = x storage_offset Broadcast _test S S offset x lambda x x expand transpose _test S S offset x lambda x x transpose select _test S offset + S x lambda x x Nested vmap test B = x = torch randn B B S S = x stride result = vmap vmap lambda t t as_strided S S in_dims= x expected = vmap vmap lambda t t expand in_dims= x assertTrue result _base expected _base assertEqual result expected Check mal-formatted size strides doesn t crash assertRaisesRegex RuntimeError size stride must have same length x = torch randn B transpose vmap lambda x x as_strided x Sanity check we require batch dims front tensor memory layout msg = batch dims being vmapped over front tensor assertRaisesRegex RuntimeError msg x = torch randn B transpose vmap lambda x x as_strided B x assertRaisesRegex RuntimeError msg x = torch randn B B movedim vmap vmap lambda x x as_strided B B x All Sanity check b c cases check xs i as_strided sizes strides offset + xs i offset - xs offset doesn t index memory out bounds xs i This condition important correctness as_strided batching rule see NOTE When will as_strided_batching_rule fail Sanity check The maximum indexable location xs i as_strided sizes strides offset + xs i offset - xs offset less than equal maximum indexable location xs i msg = This supported inside vmap assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x assertRaisesRegex RuntimeError msg x = torch randn B B vmap vmap lambda x x as_strided x Sanity check b The min indexable location xs i as_strided sizes strides offset + xs i offset - xs offset greater than equal min indexable location xs i assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided B - x Sanity check c xs i zero-dim tensor xs i as_strided sizes strides offset + xs i offset - xs offset assertRaisesRegex RuntimeError msg x = torch randn B vmap lambda x x as_strided x test_bmm op = torch bmm test = _vmap_test B B = shape mismatch msg = Shape mismatch assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_cat test = _vmap_test B B = Quick hack b c vmap can t accept list tensors argument get_op dim op tensors torch cat tensors dim=dim op test get_op torch rand B torch rand B test get_op torch rand torch rand B in_dims= None test get_op torch rand torch rand B in_dims= None test get_op - torch rand torch rand B in_dims= None test vmap get_op in_dims= None torch rand B torch rand B in_dims= None test vmap get_op in_dims= torch rand B torch rand B B in_dims= None test_conj op = torch conj run_test dtype get shape torch randn shape dtype=dtype B B = test = _vmap_test Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= correctness tests run_test torch float run_test torch cfloat check torch conj non-complex tensor returns same tensor real_tensor = torch randn result = vmap op real_tensor assertEqual result data_ptr real_tensor data_ptr test_contiguous op = Tensor contiguous _test_unary op TensorFactory randn cpu check contiguous returns original tensor per-examples already contiguous B = x = torch randn B x = x movedim result = vmap Tensor contiguous in_dims= out_dims= x assertTrue result x msg = NYI querying is_contiguous inside vmap memory_format tensor = torch randn B assertRaisesRegex RuntimeError msg vmap functools partial op memory_format=torch channels_last tensor assertRaisesRegex RuntimeError msg vmap functools partial op memory_format=torch channels_last_ d tensor test_stride B = x = torch randn B foo x assert x stride == x vmap foo x x = torch randn B movedim bar x assert x stride == B x vmap bar x test_chunk test = _vmap_view_test op = torch chunk B B B = tests torch split split_size int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_clamp clamp_cases = lambda t t clamp min=- TensorFactory randn lambda t t clamp max= TensorFactory randn lambda t t clamp min=- max= TensorFactory randn lambda t t clamp_min min=- TensorFactory randn lambda t t clamp_max max= TensorFactory randn op getter clamp_cases _test_unary op getter cpu test_comparison_ops test = functools partial _vmap_test check_propagates_grad=False getter = TensorFactory randn B B = ops = torch eq lambda x y x == y torch gt lambda x y x y torch ge lambda x y x = y torch le lambda x y x = y torch lt lambda x y x y torch ne lambda x y x = y op ops Single vmap op Tensor Tensor test op getter B getter B test op getter B getter B test op getter B getter B in_dims= test op getter B getter B in_dims= out_dims= test op getter B getter in_dims= None test op getter getter B in_dims= None Nested vmap op Tensor Tensor test vmap op getter B B getter B B test vmap op in_dims= None getter B getter B in_dims= None test number inputs number = getter item _test_unary lambda t op t number getter cpu check_propagates_grad=False test_diagonal tensor = torch randn test = _vmap_view_test op = torch diagonal test op tensor in_dims= None None None test op tensor - in_dims= None None None test op tensor in_dims= None None None test op tensor - - in_dims= None None None out_dims= test vmap lambda t op t - tensor in_dims= out_dims= test vmap vmap lambda t op t in_dims= in_dims= tensor in_dims= out_dims= test_dot op = torch dot test = _vmap_test B B = shape mismatch msg = Shape mismatch assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_expand_as op = torch Tensor expand_as test = _vmap_view_test B B B = test op torch rand B torch rand B test op torch rand B torch rand in_dims= None test op torch rand torch rand B in_dims= None test vmap op torch rand B B torch rand B B test vmap op torch rand B B torch rand B B in_dims= test vmap op torch rand B B torch rand B in_dims= None test vmap vmap op torch rand B B B torch rand B B B test_fill_and_zero_inplace test = functools partial _vmap_test check_propagates_grad=False B B = ops = lambda t t fill_ lambda t t fill_ torch tensor lambda t t zero_ op ops Single vmap various in_dims out_dims test op TensorFactory randn B test op TensorFactory randn B in_dims= test op TensorFactory randn B in_dims= out_dims= Doubly nested vmap test vmap op TensorFactory randn B B test vmap op TensorFactory randn B B in_dims= test vmap op in_dims= TensorFactory randn B B in_dims= out_dims= test when value batched tensor fill_ operator B B = test Tensor fill_ TensorFactory randn B B TensorFactory randn B assertRaisesRegex RuntimeError r output shape + doesn t match broadcast shape Runtime Error thrown when tensor being written isn t being vmapped over vmap Tensor fill_ None TensorFactory randn B B TensorFactory randn B _test_complex_views op dtypes test = _vmap_view_test run_test op dtype get shape torch randn shape dtype=dtype B B = Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= dtype dtypes run_test op dtype test_real _test_complex_views torch real dtypes= torch cfloat torch cdouble test_imag _test_complex_views torch imag dtypes= torch cfloat torch cdouble test_view_as_real _test_complex_views torch view_as_real dtypes= torch cfloat torch cdouble test_view_as_complex run_test dtype get shape torch randn shape dtype=dtype op = torch view_as_complex test = _vmap_view_test B B = Single vmap various in_dims out_dims test op get B test op get B in_dims= test op get B in_dims= out_dims= Doubly nested vmap test vmap op get B B test vmap op get B B in_dims= test vmap op in_dims= get B B in_dims= out_dims= Interesting case Batch dim directly before dim size test op get B in_dims= test vmap op in_dims= get B B in_dims= Interesting case Batch dim end tensor success cases view_as_complex requires dim size have stride order view function properly test op get B transpose in_dims= test vmap op in_dims= get B B movedim test vmap op in_dims= get B B movedim Interesting case Batch dim end tensor failure cases msg = Tensor must have last dimension stride assertRaisesRegex RuntimeError msg vmap op in_dims= get B assertRaisesRegex RuntimeError msg vmap vmap op in_dims= in_dims= get B B Invalid input no dimension size msg = Input tensor must have one more dimensions assertRaisesRegex RuntimeError msg vmap op get B assertRaisesRegex RuntimeError msg vmap vmap op get B B Invalid input Batch dim has size logical last dim does have size msg = Tensor must have last dimension size assertRaisesRegex RuntimeError msg vmap op in_dims= get dtype torch float torch double run_test dtype test_is_complex ctensor = torch randn dtype=torch cfloat tensor = torch randn foo x x is_complex torch tensor torch tensor assertEqual vmap foo ctensor torch tensor assertEqual vmap foo tensor torch tensor test_is_floating_point float_tensor = torch tensor long_tensor = torch tensor foo x x is_floating_point torch tensor torch tensor assertEqual vmap foo float_tensor torch tensor assertEqual vmap foo long_tensor torch tensor test_is_contiguous foo x x is_contiguous torch tensor torch tensor B B = Single batch dim contig = torch randn B assertEqual vmap foo contig torch ones B noncontig = torch randn B assertEqual vmap foo in_dims= noncontig torch zeros B noncontig = torch randn B movedim assertEqual vmap foo noncontig torch zeros B noncontig = torch randn B assertEqual vmap foo in_dims= noncontig torch zeros B Multiple batch dims contig = torch randn B B assertEqual vmap vmap foo contig torch ones B B contig = torch randn B B assertEqual vmap vmap foo in_dims= contig torch ones B B contig = torch randn B B movedim assertEqual vmap vmap foo contig torch ones B B noncontig = torch randn B B assertEqual vmap vmap foo in_dims= noncontig torch zeros B B is_contiguous empty tensor True bar x assert x is_contiguous x vmap bar torch randn B vmap bar in_dims= torch randn B vmap bar torch randn B mT is_contiguous other memory formats baz x memory_format x is_contiguous memory_format=memory_format x msg = NYI querying is_contiguous inside vmap memory_format tensor = torch randn B assertRaisesRegex RuntimeError msg vmap functools partial baz memory_format=torch channels_last tensor assertRaisesRegex RuntimeError msg vmap functools partial baz memory_format=torch channels_last_ d tensor test_movedim op = torch movedim test = _vmap_view_test B B B = movedim tensor int int variant test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap op in_dims= None None in_dims= None None torch rand B B B in_dims= None None movedim tensor intlist intlist variant test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap op in_dims= None None in_dims= None None torch rand B B B in_dims= None None test_mm op = torch mm test = _vmap_test B B = shape mismatch msg = Shape mismatch assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_mv op = torch mv test = _vmap_test B B = shape mismatch msg = Shape mismatch assertRaisesRegex RuntimeError msg vmap op torch randn B torch randn B assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn B torch randn assertRaisesRegex RuntimeError msg vmap op in_dims= None torch randn torch randn B left arg vmapped test op torch rand B torch rand in_dims= None test vmap op in_dims= None torch rand B B torch rand in_dims= None right arg vmapped test op torch rand torch rand B in_dims= None test vmap op in_dims= None torch rand torch rand B B in_dims= None both args vmapped test op torch rand B torch rand B test vmap op torch rand B B torch rand B B in_dims= test vmap op in_dims= None torch rand B torch rand B in_dims= None test_narrow op = torch narrow test = _vmap_view_test B B B = test op torch rand B - in_dims= None None None test op torch rand B in_dims= None None None test vmap op in_dims= None None None torch rand B B in_dims= None None None test vmap vmap op in_dims= None None None in_dims= None None None torch rand B B B - in_dims= None None None test_new_empty Empty non-deterministic so we just check shape output tensor what we expect vmap fallback isn t used op = Tensor new_empty B B = result = vmap lambda x op x torch randn B assertEqual result shape B result = vmap lambda x op x torch randn B assertEqual result shape B result = vmap vmap lambda x op x torch randn B B assertEqual result shape B B test_new_empty_strided Empty non-deterministic so we just check size shape output what we expect vmap fallback isn t used B B = _test_single_vmap size stride B x = torch randn B result = vmap lambda x x new_empty_strided size stride x S = torch empty_strided size stride storage size assertEqual result shape B + size assertEqual result stride S + stride _test_double_vmap size stride B B x = torch randn B B result = vmap vmap lambda x x new_empty_strided size stride x S = torch empty_strided size stride storage size assertEqual result shape B B + size assertEqual result stride B S S + stride x = torch randn B B result = vmap vmap lambda x x new_empty_strided size stride in_dims= x S = x new_empty_strided size stride storage size assertEqual result shape B B + size assertEqual result stride B S S + stride contiguous case _test_single_vmap B _test_double_vmap B B expanded _test_single_vmap B _test_double_vmap B B some these cases pretty strange just verifying empty_strided allows them then BatchedTensor new_empty_strided can well shape strides _test_single_vmap shape strides B _test_double_vmap shape strides B B test_new_zeros op = Tensor new_zeros test = functools partial _vmap_test check_propagates_grad=False B B = test lambda x op x torch rand B test lambda x op x torch rand B test vmap lambda x op x torch rand B B test_select op = torch select test = _vmap_view_test B B B = test op torch rand B in_dims= None None test op torch rand B in_dims= None None test vmap lambda t op t torch rand B B in_dims= test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_stack test = _vmap_test B B = Quick hack b c vmap can t accept list tensors argument get_op dim op tensors torch stack tensors dim=dim op test get_op torch rand B torch rand B test get_op torch rand torch rand B in_dims= None test get_op torch rand torch rand B in_dims= None test get_op - torch rand torch rand B in_dims= None test vmap get_op in_dims= None torch rand B torch rand B in_dims= None test vmap get_op in_dims= torch rand B torch rand B B in_dims= None test_slice test = _vmap_view_test B B B = test lambda t t torch rand B test lambda t t torch rand B in_dims= test vmap lambda t t in_dims= torch rand B B in_dims= test vmap vmap lambda t t in_dims= in_dims= torch rand B B B in_dims= test_squeeze test = _vmap_view_test op = torch squeeze B B = test op torch rand B test op torch rand B test op torch rand B in_dims= test op torch rand B test op torch rand B test vmap op torch rand B B test vmap op torch rand B B in_dims= test_sum_dim test = _vmap_test B B = Single vmap various in_dims out_dims test lambda x x sum torch randn B test lambda x x sum torch randn B test lambda x x sum torch randn B test lambda x x sum - torch randn B test lambda x x sum torch randn B test lambda x x sum - torch randn B in_dims= test lambda x x sum torch randn B in_dims= out_dims= Doubly nested vmap test vmap lambda x x sum torch randn B B test vmap lambda x x sum torch randn B B test vmap lambda x x sum - torch randn B B test vmap lambda x x sum - torch randn B B in_dims= test vmap lambda x x sum in_dims= torch randn B B in_dims= out_dims= test_reshape test = _vmap_test B B B = op = torch reshape test op torch rand B in_dims= None check_view=True test op torch rand B in_dims= None check_view=False test vmap lambda t t reshape - torch rand B B check_view=True test vmap vmap lambda t t reshape - in_dims= in_dims= torch rand B B B in_dims= check_view=False test_reshape_as test = _vmap_test B B B = op = torch Tensor reshape_as test op torch rand B torch rand B check_view=True test op torch rand torch rand B in_dims= None check_view=True test op torch rand B torch rand in_dims= None check_view=True test op torch rand B torch rand in_dims= None check_view=False test vmap op torch rand B B torch randn B B check_view=True test vmap vmap op in_dims= None in_dims= None torch rand B B B torch rand B in_dims= check_view=False test_result_type scalar_tensor_with_dtype op wrapped args kwargs dtype = op args kwargs torch ones dtype=dtype wrapped test = _vmap_test op = scalar_tensor_with_dtype torch result_type B = test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch tensor torch randn B check_propagates_grad=False test lambda x op x torch tensor dtype=torch double torch randn B check_propagates_grad=False test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch randn B check_propagates_grad=False test lambda x op x torch tensor torch randn B check_propagates_grad=False test lambda x op x torch tensor dtype=torch double torch randn B check_propagates_grad=False test op torch randn B torch randn B dtype=torch float check_propagates_grad=False test op torch randn B torch randint B dtype=torch int check_propagates_grad=False skipIfTorchDynamo too slow test_tensor_split test = _vmap_view_test op = torch tensor_split B B B = tests torch tensor_split indices_or_sections int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= tests torch tensor_split indices_or_sections List int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= test_split test = _vmap_view_test op = torch split B B B = tests torch split split_size int dim test op torch rand B - in_dims= None None test op torch rand B in_dims= None None test vmap op in_dims= None None torch rand B B in_dims= None None test vmap vmap lambda t op t in_dims= torch rand B B B in_dims= tests torch split split_size List int dim test op torch rand B - in_dims= None None test op torch rand B + in_dims= None None test vmap op in_dims= None None torch rand B B + in_dims= None None test vmap vmap lambda t op t + in_dims= torch rand B B B in_dims= test_trace op = torch trace test = _vmap_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_transpose op = torch transpose test = _vmap_view_test B B B = test lambda x op x torch rand B test lambda x op x - - torch rand B test lambda x op x torch rand B test lambda x op x torch rand B in_dims= test vmap lambda x op x torch rand B B in_dims= test vmap vmap lambda x op x in_dims= torch rand B B B in_dims= Special case scalar tensor dim dim itertools product - - x = torch rand B result = vmap lambda x op x dim dim x assertTrue result x test_t op = torch t test = _vmap_view_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_T_numpy op t t T test = _vmap_view_test B B B = test op torch rand B test op torch rand B in_dims= test vmap op torch rand B B in_dims= test vmap op torch rand B B in_dims= test vmap vmap op in_dims= torch rand B B B in_dims= test_to test = _vmap_test B B = test lambda t t cpu torch rand B test lambda t t torch double torch rand B test lambda t o t o torch rand B torch randn B dtype=torch float test lambda t o t o torch rand B torch randn B dtype=torch float in_dims= None test vmap lambda t t torch double torch rand B B also test some casting methods test lambda t t double torch rand B test lambda t t float torch rand B test lambda t t int torch rand B check_propagates_grad=False test lambda t t long torch rand B check_propagates_grad=False test_unfold op = torch Tensor unfold test = _vmap_view_test B B B = test op torch rand B in_dims= None None None test op torch rand B in_dims= None None None test vmap op in_dims= None None None torch rand B B in_dims= None None None test vmap vmap op in_dims= None None None in_dims= None None None torch rand B B B - in_dims= None None None test_unbind test = _vmap_view_test op = torch unbind B B B = test op torch rand B - in_dims= None test op torch rand B test op torch rand B in_dims= None test vmap op in_dims= None torch rand B B in_dims= None test vmap vmap lambda t op t dim= in_dims= torch rand B B B in_dims= test_view test = _vmap_view_test B B B = op = torch Tensor view We should error out view would produce incorrect result assertRaises RuntimeError vmap op in_dims= None torch rand B test op torch rand B in_dims= None test op torch rand B in_dims= None test vmap lambda t t view - torch rand B B test vmap vmap lambda t t reshape - in_dims= torch rand B B B in_dims= test_view_as test = _vmap_view_test B B B = op = torch Tensor view_as We should error out view would produce incorrect result assertRaises RuntimeError vmap op in_dims= torch rand B torch rand B test op torch rand B torch rand B test op torch rand torch rand B in_dims= None test op torch rand B torch rand in_dims= None test op torch rand B torch rand in_dims= None test vmap op torch rand B B torch randn B B test vmap vmap op in_dims= None in_dims= None torch rand B B B torch rand B in_dims= test_no_random_op_support B = captured = torch rand random_ops = out-of-place BatchedTensor torch bernoulli torch rand B lambda t torch bernoulli t p= torch rand B lambda t torch multinomial t torch rand B torch normal torch randn B torch randn B lambda t torch normal t torch randn B lambda t torch normal t torch randn B torch poisson torch rand B torch rand_like torch rand B torch randn_like torch rand B lambda t torch randint_like t torch rand B lambda t torch randint_like t torch rand B out-of-place captured tensor lambda t torch bernoulli captured torch rand B lambda t torch bernoulli captured p= torch rand B lambda t torch multinomial captured torch rand B lambda t torch normal captured captured torch randn B lambda t torch normal captured torch randn B lambda t torch normal captured torch randn B lambda t torch poisson captured torch rand B lambda t torch rand_like captured torch rand B lambda t torch randn_like captured torch rand B lambda t torch randint_like captured torch rand B lambda t torch randint_like captured torch rand B in-place BatchedTensor lambda t t bernoulli_ torch randn B lambda t t cauchy_ torch randn B lambda t t exponential_ torch randn B lambda t t geometric_ torch randn B lambda t t log_normal_ torch randn B lambda t t normal_ torch randn B lambda t t random_ torch randn B lambda t t random_ torch randn B lambda t t random_ torch randn B lambda t t uniform_ torch randn B in-place captured tensor lambda t captured bernoulli_ torch randn B lambda t captured cauchy_ torch randn B lambda t captured exponential_ torch randn B lambda t captured geometric_ torch randn B lambda t captured log_normal_ torch randn B lambda t captured normal_ torch randn B lambda t captured random_ torch randn B lambda t captured random_ torch randn B lambda t captured random_ torch randn B lambda t captured uniform_ torch randn B factory functions lambda t torch rand torch randn B lambda t torch randn torch randn B lambda t torch randint torch randn B lambda t torch randperm torch randn B op args random_ops assertRaisesRegex RuntimeError vmap We do yet support calling random operations vmap op args construct_v output batch_size torch randn batch_size output shape dtype=output dtype device=output device as_tuple x isinstance x tuple x isinstance x list tuple x x differentiable args tuple arg arg as_tuple args isinstance arg torch Tensor arg requires_grad _get_rand_no_zeros args kwargs requires_grad = kwargs get requires_grad False kwargs_without_requires_grad = kwargs copy kwargs_without_requires_grad requires_grad = False result = torch rand args kwargs_without_requires_grad result clamp_min_ requires_grad_ requires_grad TestVmapBatchedGradientLegacy Namespace TestVmapBaseLegacy _vmap_test args kwargs _vmap_test args kwargs Tests batched gradient computation outputs = op args kwargs comparing sequential map+stack fallback output_process_fn function maps outputs part should differentiated batch_size batch dim size batched grad _batched_grad_test op args kwargs=None output_process_fn=lambda x x batch_size= kwargs None kwargs = outputs = op args kwargs outputs = differentiable output_process_fn outputs batched_vectors = tuple construct_v out batch_size out outputs vector_jacobian_product vectors torch autograd grad outputs differentiable args vectors retain_graph=True _vmap_test vector_jacobian_product batched_vectors check_propagates_grad=False Tests batched second grad computation outputs = op args kwargs comparing sequential map+stack fallback output_process_fn function maps outputs part should differentiated batch_size batch dim size batched grad NB we only test computing batched gradients second gradient computation One specific use case does computing hessian matrix scalar-valued function useful Bayesian Logistic Regression It might useful have test computes batched first gradients then uses those compute batched second gradients future _batched_grad_grad_test op args kwargs=None output_process_fn=lambda x x batch_size= kwargs None kwargs = outputs = op args kwargs outputs = differentiable output_process_fn outputs ones = tuple torch ones_like out out outputs Same thing summing together all outputs calling backward first_grads = torch autograd grad outputs differentiable args ones create_graph=True first_grads = differentiable first_grads assertNotEqual len first_grads None first grads depend input batched_vectors = tuple construct_v grad batch_size grad first_grads vector_hessian_product vectors outputs = torch autograd grad first_grads differentiable args vectors retain_graph=True allow_unused=True outputs = tuple out out outputs out None assert len outputs outputs _vmap_test vector_hessian_product batched_vectors check_propagates_grad=False _test_arithmetic op device test_grad_grad=True x = torch randn requires_grad=True device=device y = _get_rand_no_zeros device=device requires_grad=True scalar = _batched_grad_test op x y _batched_grad_test op scalar y _batched_grad_test op x scalar test_grad_grad _batched_grad_grad_test op x y test_add device _test_arithmetic torch add device test_grad_grad=False _test_arithmetic lambda x y x + y device test_grad_grad=False test_sub device _test_arithmetic torch sub device test_grad_grad=False _test_arithmetic lambda x y x - y device test_grad_grad=False test_mul device _test_arithmetic torch mul device _test_arithmetic lambda x y x y device test_div device _test_arithmetic torch div device _test_arithmetic lambda x y x y device allowVmapFallbackUsage test_binary_cross_entropy device x = torch sigmoid torch randn device=device requires_grad=True target = torch rand device=device op = functools partial F binary_cross_entropy target=target _batched_grad_test op x _batched_grad_grad_test op x test_expand device x = torch randn device=device requires_grad=True op x x expand _batched_grad_test op x allowVmapFallbackUsage test_index device x = torch randn requires_grad=True device=device index = torch tensor device=device op x y = x x y index _batched_grad_test op x _batched_grad_grad_test op x test_lgamma device x = torch randn requires_grad=True device=device _batched_grad_test Tensor lgamma x _batched_grad_grad_test Tensor lgamma x test_log device x = _get_rand_no_zeros device=device requires_grad=True _batched_grad_test torch log x _batched_grad_grad_test torch log x test_logsumexp device x = _get_rand_no_zeros device=device requires_grad=True op x torch logsumexp x - _batched_grad_test op x _batched_grad_grad_test op x test_log p device x = _get_rand_no_zeros device=device requires_grad=True _batched_grad_test torch log p x _batched_grad_grad_test torch log p x allowVmapFallbackUsage test_max device x = torch randn requires_grad=True device=device _batched_grad_test torch max x allowVmapFallbackUsage test_median device x = torch randn requires_grad=True device=device _batched_grad_test torch median x allowVmapFallbackUsage test_min device x = torch randn requires_grad=True device=device _batched_grad_test torch min x test_permute device x = torch randn requires_grad=True device=device op x x permute _batched_grad_test op x test_reshape device x = torch randn requires_grad=True device=device op x x reshape _batched_grad_test op x test_sigmoid device x = torch randn requires_grad=True device=device _batched_grad_test Tensor sigmoid x _batched_grad_grad_test Tensor sigmoid x test_stack device x = torch randn device=device requires_grad=True y = torch randn device=device requires_grad=True op x y torch stack x y _batched_grad_test op x y test_select device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x x _batched_grad_test lambda x x select x _batched_grad_test lambda x x select - x test_slice device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x x _batched_grad_test lambda x x x _batched_grad_test lambda x x x test_trace device x = torch randn device=device requires_grad=True _batched_grad_test Tensor trace x test_threshold device x = torch randn device=device requires_grad=True _batched_grad_test lambda x F threshold x x allowVmapFallbackUsage test_inplace_on_view device leaf = torch randn requires_grad=True func leaf Make sure function non-trivially twice differentiable base = leaf leaf view = base view cos_ view _batched_grad_test func leaf _batched_grad_grad_test func leaf allowVmapFallbackUsage test_inplace_manyview device leaf = torch randn requires_grad=True func leaf Make sure function non-trivially twice differentiable base = leaf leaf view = base transpose view = view view = view diagonal view = view view cos_ view _batched_grad_test func leaf _batched_grad_grad_test func leaf test_diagonal device x = torch randn device=device requires_grad=True _batched_grad_test lambda x x diagonal x x = torch randn device=device requires_grad=True _batched_grad_test lambda x x diagonal - - x allowVmapFallbackUsage test_unrelated_output device B = x = torch randn requires_grad=True y = torch randn requires_grad=True gy = torch randn B requires_grad=True vjp v res = torch autograd grad y x v allow_unused=True torch zeros_like x res None res result = vmap vjp gy assertEqual result torch zeros B x shape device=device allowVmapFallbackUsage test_unrelated_output_multiple_grad device B = x = torch randn requires_grad=True y = torch randn requires_grad=True gy = torch randn B requires_grad=True vjp v res = torch autograd grad y x v allow_unused=True torch zeros_like x res None res _ = vjp gy result = vmap vjp gy assertEqual result torch zeros B x shape device=device instantiate_device_type_tests TestVmapBatchedGradientLegacy globals None __name__ == __main__ run_tests