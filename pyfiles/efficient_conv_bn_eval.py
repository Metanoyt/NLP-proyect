mypy allow-untyped-defs torch torch nn nn torch _dynamo utils counters torch _inductor config inductor_config torch func functional_call pattern_matcher CallFunctionVarArgs CallModuleVarArgs Match register_graph_pattern pre_grad efficient_conv_bn_eval_pass efficient_conv_bn_eval bn nn modules batchnorm _BatchNorm conv nn modules conv _ConvNd x torch Tensor Implementation based https arxiv org abs Efficient ConvBN Blocks Transfer Learning Beyond It leverages associative law between convolution affine transform i e normalize weight conv feature = normalize weight conv feature It works Eval mode ConvBN blocks during validation can used training well only one sets ` bn training=False ` It reduces memory footprint computation cost cost slightly reduced numerical stability Args bn nn modules batchnorm _BatchNorm BatchNorm module conv nn modules conv _ConvNd conv module x torch Tensor Input feature map assert bn running_var None assert bn running_mean None These lines code designed deal various cases like bn without affine transform conv without bias weight_on_the_fly = conv weight conv bias None bias_on_the_fly = conv bias bias_on_the_fly = torch zeros_like bn running_var bn weight None bn_weight = bn weight bn_weight = torch ones_like bn running_var bn bias None bn_bias = bn bias bn_bias = torch zeros_like bn running_var shape C_out Conv d target_shape = - + conv weight ndim - isinstance conv nn modules conv _ConvTransposeNd transposed conv C_out dimension should index target_shape = target_shape target_shape weight_coeff = torch rsqrt bn running_var + bn eps reshape target_shape shape C_out Conv d coefff_on_the_fly = bn_weight view_as weight_coeff weight_coeff shape C_out C_in k k Conv d weight_on_the_fly = weight_on_the_fly coefff_on_the_fly shape C_out Conv d bias_on_the_fly = bn_bias + coefff_on_the_fly flatten bias_on_the_fly - bn running_mean input = x params = weight weight_on_the_fly bias bias_on_the_fly output = functional_call conv params input output efficient_conv_bn_eval_decomposed bn_weight bn_bias bn_running_mean bn_running_var bn_eps conv torch _ops OpOverload conv_weight conv_bias x conv_remainging_args Implementation based https arxiv org abs Efficient ConvBN Blocks Transfer Learning Beyond It leverages associative law between convolution affine transform i e normalize weight conv feature = normalize weight conv feature It works Eval mode ConvBN blocks during validation can used training well only one sets ` bn training=False ` It reduces memory footprint computation cost cost slightly reduced numerical stability Args assert bn_running_var None These lines code designed deal various cases like bn without affine transform conv without bias weight_on_the_fly = conv_weight conv_bias None bias_on_the_fly = conv_bias bias_on_the_fly = torch zeros_like bn_running_var bn_weight None bn_weight = torch ones_like bn_running_var bn_bias None bn_bias = torch zeros_like bn_running_var shape C_out Conv d target_shape = - + conv_weight ndim - conv_transpose conv __str__ transposed conv C_out dimension should index target_shape = target_shape target_shape weight_coeff = torch rsqrt bn_running_var + bn_eps reshape target_shape shape C_out Conv d coefff_on_the_fly = bn_weight view_as weight_coeff weight_coeff shape C_out C_in k k Conv d weight_on_the_fly = weight_on_the_fly coefff_on_the_fly shape C_out Conv d bias_on_the_fly = bn_bias + coefff_on_the_fly flatten bias_on_the_fly - bn_running_mean input = x conv input weight_on_the_fly bias_on_the_fly + conv_remainging_args register_graph_pattern CallFunctionVarArgs torch nn functional batch_norm pyrefly ignore bad-argument-type pass_dict=efficient_conv_bn_eval_pass extra_check=lambda match inductor_config freezing inductor_config efficient_conv_bn_eval_fx_passes efficient_conv_bn_eval_graph_transform_inlined match Match args kwargs bn_node = match nodes graph = match graph assert len bn_node args == We can only use efficient conv-bn eval mode track_running_stats bn_node args ` training ` bn_node args - Check input Conv input_node = bn_node args input_node op = call_function type ignore union-attr input_fn = input_node target type ignore arg-type union-attr supported_convs = torch _C _nn linear torch conv d torch conv d torch conv d torch conv_transpose d torch conv_transpose d torch conv_transpose d any input_fn cls cls supported_convs conv_node = input_node Output conv used other nodes cannot optimize len conv_node users type ignore union-attr counters inductor efficient_conv_bn_eval += graph inserting_before bn_node prepare args fused function bn_running_mean = bn_node args bn_running_var = bn_node args bn_weight = bn_node args bn_bias = bn_node args bn_eps = bn_node args assert len conv_node args = type ignore union-attr conv_input = conv_node args type ignore union-attr conv_weight = conv_node args type ignore union-attr conv_bias = conv_node args len conv_node args = None type ignore union-attr conv_remainging_args = conv_node args type ignore union-attr args = bn_weight bn_bias bn_running_mean bn_running_var bn_eps conv_node target type ignore union-attr conv_weight conv_bias conv_input conv_remainging_args create new node new_node = graph create_node op= call_function target=efficient_conv_bn_eval_decomposed args=args type ignore arg-type name= efficient_conv_bn_eval node replaces original conv + bn therefore should replace uses bn_node bn_node replace_all_uses_with new_node take care deletion order delete bn_node first then conv_node graph erase_node bn_node graph erase_node conv_node type ignore arg-type register_graph_pattern CallFunctionVarArgs torch ops aten batch_norm default pyrefly ignore bad-argument-type pass_dict=efficient_conv_bn_eval_pass extra_check=lambda match inductor_config freezing inductor_config efficient_conv_bn_eval_fx_passes efficient_conv_bn_eval_graph_transform_decomposed match Match args kwargs bn_node = match nodes graph = match graph assert len bn_node args == We can only use efficient conv-bn eval mode track_running_stats bn_node args ` training ` bn_node args - Check input Conv input_node = bn_node args input_node op = call_function type ignore union-attr input_fn = input_node target type ignore arg-type union-attr supported_convs = torch ops aten linear default torch ops aten conv d default torch ops aten conv d default torch ops aten conv d default torch ops aten conv_transpose d default torch ops aten conv_transpose d input torch ops aten conv_transpose d input any input_fn cls cls supported_convs conv_node = input_node Output conv used other nodes cannot optimize len conv_node users type ignore union-attr counters inductor efficient_conv_bn_eval += graph inserting_before bn_node prepare args fused function bn_weight = bn_node args bn_bias = bn_node args bn_running_mean = bn_node args bn_running_var = bn_node args bn_eps = bn_node args assert len conv_node args = type ignore union-attr conv_input = conv_node args type ignore union-attr conv_weight = conv_node args type ignore union-attr conv_bias = conv_node args len conv_node args = None type ignore union-attr conv_remainging_args = conv_node args type ignore union-attr args = bn_weight bn_bias bn_running_mean bn_running_var bn_eps conv_node target type ignore union-attr conv_weight conv_bias conv_input conv_remainging_args create new node new_node = graph create_node op= call_function target=efficient_conv_bn_eval_decomposed args=args type ignore arg-type name= efficient_conv_bn_eval node replaces original conv + bn therefore should replace uses bn_node bn_node replace_all_uses_with new_node take care deletion order delete bn_node first then conv_node graph erase_node bn_node graph erase_node conv_node type ignore arg-type register_graph_pattern CallModuleVarArgs nn modules batchnorm _BatchNorm nn BatchNorm d nn BatchNorm d nn BatchNorm d nn SyncBatchNorm pyrefly ignore bad-argument-type pass_dict=efficient_conv_bn_eval_pass extra_check=lambda match inductor_config freezing inductor_config efficient_conv_bn_eval_fx_passes efficient_conv_bn_eval_graph_transform match Match args kwargs We matched BN node bn_node = match nodes graph = match graph gm = graph owning_module bn_mod = getattr gm bn_node target type ignore arg-type We can only use efficient conv-bn eval mode track_running_stats bn_mod track_running_stats bn_mod training Check input Conv bn_node args input_node = bn_node args input_node = bn_node kwargs input input_node op = call_module type ignore union-attr hasattr gm input_node target type ignore arg-type union-attr input_mod = getattr gm input_node target type ignore arg-type union-attr supported_convs = nn Linear nn Conv d nn Conv d nn Conv d nn ConvTranspose d nn ConvTranspose d nn ConvTranspose d any isinstance input_mod cls cls supported_convs conv_node = input_node Output conv used other nodes cannot optimize len conv_node users type ignore union-attr Find pair conv bn computation nodes optimize counters inductor efficient_conv_bn_eval += graph inserting_before conv_node type ignore arg-type create ` get_attr ` node access modules note we directly call ` create_node ` fill ` name ` argument ` graph get_attr ` ` graph call_function ` does allow ` name ` argument conv_get_node = graph create_node op= get_attr target=conv_node target type ignore union-attr name= get_conv bn_get_node = graph create_node op= get_attr target=bn_node target name= get_bn conv_node args type ignore union-attr conv_input = conv_node args type ignore union-attr conv_input = conv_node kwargs input type ignore union-attr prepare args fused function args = bn_get_node conv_get_node conv_input create new node new_node = graph create_node op= call_function target=efficient_conv_bn_eval args=args name= efficient_conv_bn_eval node replaces original conv + bn therefore should replace uses bn_node bn_node replace_all_uses_with new_node take care deletion order delete bn_node first then conv_node graph erase_node bn_node graph erase_node conv_node type ignore arg-type