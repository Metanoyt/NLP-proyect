json logging os pathlib Path typing Any Callable Optional unittest mock torch torch _export torch _inductor utils is_cpu_device runtime runtime_utils cache_dir log = logging getLogger __name__ aoti_eager_cache_dir namespace str device str - Path Path cache_dir aoti_eager namespace device aoti_eager_op_conf_lock op_func_name_with_overload str - Any Avoid circular torch _inductor codecache get_lock_dir LOCK_TIMEOUT torch utils _filelock FileLock op_conf_lock_file = f op_func_name_with_overload lock lock_dir = get_lock_dir FileLock os path join lock_dir op_conf_lock_file timeout=LOCK_TIMEOUT load_aoti_eager_cache ns str op_func_name_with_overload str device_type str - list Optional dict str Any device_kernel_cache = aoti_eager_cache_dir ns device_type op_conf = device_kernel_cache f op_func_name_with_overload json op_conf exists try aoti_eager_op_conf_lock op_func_name_with_overload open op_conf f json_data = json load f item json_data Get absolution path kernel library kernel_lib_abs_path = device_kernel_cache item kernel_path item kernel_path = kernel_lib_abs_path as_posix Check kernel library exists kernel_lib_abs_path exists metadata item meta_info metadata get is_dynamic raise NotImplementedError Only support static shape now device_type metadata metadata device_type == cpu metadata device_index = - dtype_key dtype dtype_value dtype_key metadata metadata dtype_key = getattr torch metadata dtype_key split - layout_value metadata metadata layout_value = getattr torch metadata layout_value split - memory_format_value metadata metadata memory_format_value = getattr torch metadata memory_format_value split - json_data except Exception e err_msg = f Failed load aoti eager cache e log exception err_msg supported_builtin_dtype_torch_dtype - dict type torch dtype int torch int float torch float bool torch bool supported_scalar_types - tuple type type_to_torch_dtype = supported_builtin_dtype_torch_dtype tuple type_to_torch_dtype keys extract_tensor_metadata dynamic bool input torch Tensor - dict str Any metadata dict str Any = metadata is_dynamic = dynamic assert isinstance input torch Tensor metadata device_type = f input device type is_cpu_device input metadata device_index = - metadata device_index = input device index metadata dtype = f input dtype metadata sizes = list input size metadata strides = list input stride metadata requires_grad = input requires_grad metadata dispatch_key_set = torch _C _dispatch_keys input raw_repr metadata extract_tensor_list_metadata dynamic bool input list torch Tensor - dict str Any metadata_list = item input assert isinstance item torch Tensor metadata_list append extract_tensor_metadata dynamic item metadata dict str Any = metadata tensor_list = metadata_list metadata extract_scalar_metadata device_type str input Any - dict str Any assert isinstance input supported_scalar_types metadata dict str Any = metadata is_dynamic = False Scalar tensor metadata device_type = device_type metadata device_index = - device_type == cpu type_to_torch_dtype = supported_builtin_dtype_torch_dtype metadata dtype = f type_to_torch_dtype type input metadata scalar_value = input metadata extract_string_metadata input str - dict str Any assert isinstance input str metadata dict str Any = metadata string_value = input metadata extract_dtype_metadata input torch dtype - dict str Any assert isinstance input torch dtype metadata dict str Any = metadata dtype_value = f input metadata extract_device_metadata input torch device - dict str Any assert isinstance input torch device metadata dict str Any = metadata device_type_value = f input type metadata device_index_value = input index metadata extract_layout_metadata input torch layout - dict str Any assert isinstance input torch layout metadata dict str Any = metadata layout_value = f input metadata aoti_compile_with_persistent_cache ns str op_func_name_with_overload str device_type str dynamic bool f Callable Any args tuple Any kwargs dict str Any dynamic_shapes Optional dict str Any = None options Optional dict str Any = None remove_runtime_assertions bool = False disable_constraint_solver bool = False - str Compile given function persistent cache AOTI eager mode assert dynamic Only support static shape now flattened_inputs = list args + list kwargs values all isinstance input supported_scalar_types torch Tensor list str torch dtype torch device torch layout input flattened_inputs err_msg = f Unsupported input types flattened_inputs log exception err_msg raise NotImplementedError err_msg input flattened_inputs isinstance input list all isinstance item torch Tensor item input err_msg = f _impl_with_aoti_compile encounters unsupported input types flattened_inputs log exception err_msg raise NotImplementedError err_msg persistent_cache = aoti_eager_cache_dir ns device_type persistent_cache exists persistent_cache mkdir parents=True persistent_cache_lib = persistent_cache lib persistent_cache_lib exists persistent_cache_lib mkdir mock patch dict os environ TORCHINDUCTOR_CACHE_DIR persistent_cache_lib absolute as_posix try kernel_lib_path = torch _export aot_compile f args kwargs dynamic_shapes=dynamic_shapes remove_runtime_assertions=remove_runtime_assertions disable_constraint_solver=disable_constraint_solver Some operations may have non-Tensor parameters like int float bool These non-Tensor parameters will input graph Therefore we do need keep same signature same_signature=False assert isinstance kernel_lib_path str kernel_metadata_items = idx input enumerate flattened_inputs isinstance input torch Tensor metadata = extract_tensor_metadata dynamic input isinstance input list assert all isinstance item torch Tensor item input metadata = extract_tensor_list_metadata dynamic input isinstance input supported_scalar_types metadata = extract_scalar_metadata device_type input isinstance input str metadata = extract_string_metadata input isinstance input torch dtype metadata = extract_dtype_metadata input isinstance input torch device metadata = extract_device_metadata input isinstance input torch layout metadata = extract_layout_metadata input raise NotImplementedError f Unsupported input type type input metadata arg_order = idx kernel_metadata_items append metadata kernel_meta_info dict str Any = kernel_meta_info meta_info = kernel_metadata_items kernel_meta_info kernel_path = Path kernel_lib_path relative_to persistent_cache as_posix json_data = update_json = True op_conf = persistent_cache f op_func_name_with_overload json mode = r op_conf exists w aoti_eager_op_conf_lock op_func_name_with_overload open op_conf mode op_conf_file try json_data = json load op_conf_file except Exception json_data = assert isinstance json_data list item json_data assert isinstance item dict Same kernel meta info already exists json file item meta_info == kernel_metadata_items update_json = False break update_json json_data append kernel_meta_info open op_conf w op_conf_file json dump json_data op_conf_file indent= kernel_lib_path except Exception e err_msg = f Failed compile op_func_name_with_overload e log exception err_msg