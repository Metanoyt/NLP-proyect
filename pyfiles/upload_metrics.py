__future__ annotations datetime inspect os time uuid datetime timezone typing Any warnings warn boto optional dependency If s installed we ll just emit metrics Keeping logic here so callers don t have worry about EMIT_METRICS = False try tools stats upload_stats_lib upload_to_s EMIT_METRICS = True except ImportError e print f Unable boto Will emitting metrics Reason e EnvVarMetric name str env_var str required bool = True Used cast value env_var correct type defaults str type_conversion_fn Any = None __init__ name str env_var str required bool = True type_conversion_fn Any = None - None name = name env_var = env_var required = required type_conversion_fn = type_conversion_fn value - Any value = os environ get env_var Github CI will set some env vars empty string DEFAULT_ENVVAR_VALUES = None value DEFAULT_ENVVAR_VALUES required None raise ValueError f Missing name Please set env_var environment variable pass value type_conversion_fn type_conversion_fn value value global_metrics dict str Any = add_global_metric metric_name str metric_value Any - None Adds stats should emitted every metric current process If emit_metrics method specifies metric same name will overwrite value global_metrics metric_name = metric_value emit_metric metric_name str metrics dict str Any - None Upload metric DynamoDB there HUD backend database Even EMIT_METRICS set False function will still run code validate shape metrics skipping just upload Parameters metric_name Name metric Every unique metric should have different name emitted just once per run attempt Metrics namespaced their module function emitted them metrics The actual data record Some default values populated environment variables which must set metrics emitted If they re set function becomes noop metrics None raise ValueError You didn t ask upload any metrics Merge given metrics global metrics overwriting any duplicates given metrics metrics = global_metrics metrics We use these env vars determine basic info about workflow run By using env vars we don t have pass info around every function It also helps ensure we only emit metrics during CI env_var_metrics = EnvVarMetric repo GITHUB_REPOSITORY EnvVarMetric workflow GITHUB_WORKFLOW EnvVarMetric build_environment BUILD_ENVIRONMENT required=False EnvVarMetric job GITHUB_JOB EnvVarMetric test_config TEST_CONFIG required=False EnvVarMetric pr_number PR_NUMBER required=False type_conversion_fn=int EnvVarMetric run_id GITHUB_RUN_ID type_conversion_fn=int EnvVarMetric run_number GITHUB_RUN_NUMBER type_conversion_fn=int EnvVarMetric run_attempt GITHUB_RUN_ATTEMPT type_conversion_fn=int EnvVarMetric job_id JOB_ID type_conversion_fn=int EnvVarMetric job_name JOB_NAME Use info about function invoked one namespace way filter metrics calling_frame = inspect currentframe f_back type ignore union-attr calling_frame_info = inspect getframeinfo calling_frame type ignore arg-type calling_file = os path basename calling_frame_info filename calling_module = inspect getmodule calling_frame __name__ type ignore union-attr calling_function = calling_frame_info function try default_metrics = metric_name metric_name calling_file calling_file calling_module calling_module calling_function calling_function timestamp datetime datetime now timezone utc strftime Y- m- d H M S f m name m value m env_var_metrics m value except ValueError e warn f Not emitting metrics metric_name e Prefix key metric name timestamp derisk chance uuid name collision s _key = f metric_name _ int time time _ uuid uuid hex EMIT_METRICS try upload_to_s bucket_name= ossci-raw-job-status key=f ossci_uploaded_metrics s _key docs= default_metrics info metrics except Exception e We don t want fail job we can t upload metric We still raise ValueErrors outside try block since those indicate improperly configured metrics warn f Error uploading metric metric_name DynamoDB e print f Not emitting metrics metric_name Boto wasn t imported