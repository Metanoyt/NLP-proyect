mypy allow-untyped-defs base copy copyreg dataclasses heapq inspect io json keyword logging math operator re traceback typing collections namedtuple OrderedDict collections abc Callable Iterable Iterator Sequence contextlib contextmanager dataclasses dataclass field enum Enum typing Annotated Any cast final Optional Union sympy torch torch export exported_program ep torch _export non_strict_utils _enable_graph_inputs_of_type_nn_module torch _export verifier load_verifier torch _subclasses fake_tensor FakeTensor FakeTensorMode torch fx _symbolic_trace _ConstantAttributeType torch fx experimental symbolic_shapes torch utils _pytree pytree torch utils _pytree treespec_dumps treespec_loads torch utils _sympy numbers int_oo torch utils _sympy symbol prefix_str SymT torch utils _sympy value_ranges ValueRanges torch utils _traceback CapturedTraceback torch utils _triton has_triton utils remove_proxy_from_state_dict schema type ignore attr-defined Argument ArgumentKind BufferMutationSpec ComplexValue ConstantValue CustomObjArgument Device ExportedProgram GradientToParameterSpec GradientToUserInputSpec Graph GraphArgument GraphModule GraphSignature InputSpec InputToBufferSpec InputToConstantInputSpec InputToCustomObjSpec InputTokenSpec InputToParameterSpec InputToTensorConstantSpec Layout LossOutputSpec MemoryFormat ModuleCallEntry ModuleCallSignature NamedArgument NamedTupleDef Node OptionalTensorArgument OutputSpec OutputTokenSpec ParameterMutationSpec RangeConstraint ScalarType SCHEMA_VERSION SchemaVersion SymBool SymBoolArgument SymExpr SymExprHint SymFloat SymFloatArgument SymInt SymIntArgument TensorArgument TensorMeta TokenArgument TREESPEC_VERSION UserInputMutationSpec UserInputSpec UserOutputSpec union _Union __all__ = serialize GraphModuleSerializer ExportedProgramSerializer GraphModuleDeserializer ExportedProgramDeserializer log = logging getLogger __name__ SerializeError RuntimeError pass _reverse_map d dict Any Enum v value k k v d items MetaType = Union FakeTensor int torch SymInt float torch SymFloat bool torch SymBool ep CustomObjArgument DEFAULT_PICKLE_PROTOCOL = ST_DELIMITER = _TORCH_TO_SERIALIZE_DTYPE = torch uint ScalarType BYTE torch int ScalarType CHAR torch uint ScalarType UINT torch int ScalarType SHORT torch int ScalarType INT torch int ScalarType LONG torch float ScalarType HALF torch float ScalarType FLOAT torch float ScalarType DOUBLE torch complex ScalarType COMPLEXHALF torch complex ScalarType COMPLEXFLOAT torch complex ScalarType COMPLEXDOUBLE torch bool ScalarType BOOL torch bfloat ScalarType BFLOAT torch float _e m fn ScalarType FLOAT E M FN torch float _e m ScalarType FLOAT E M torch float _e m fnuz ScalarType FLOAT E M FNUZ torch float _e m fnuz ScalarType FLOAT E M FNUZ _SERIALIZE_TO_TORCH_DTYPE = _reverse_map _TORCH_TO_SERIALIZE_DTYPE type ignore arg-type _TORCH_TO_SERIALIZE_LAYOUT = torch sparse_coo Layout SparseCoo torch sparse_csr Layout SparseCsr torch sparse_csc Layout SparseCsc torch sparse_bsr Layout SparseBsr torch sparse_bsc Layout SparseBsc torch _mkldnn Layout _mkldnn type ignore attr-defined torch strided Layout Strided _SERIALIZE_TO_TORCH_LAYOUT = _reverse_map _TORCH_TO_SERIALIZE_LAYOUT type ignore arg-type _TORCH_TO_SERIALIZE_MEMORY_FORMAT = torch contiguous_format MemoryFormat ContiguousFormat torch channels_last MemoryFormat ChannelsLast torch channels_last_ d MemoryFormat ChannelsLast d torch preserve_format MemoryFormat PreserveFormat _SERIALIZE_TO_TORCH_MEMORY_FORMAT = _reverse_map _TORCH_TO_SERIALIZE_MEMORY_FORMAT type ignore arg-type _SYM_OPS = operator eq operator ne operator le operator ge operator lt operator gt operator neg operator pos operator and_ operator or_ math trunc torch sym_not operator mul operator add operator sub operator floordiv operator mod operator pow torch sym_int torch sym_float torch sym_ite torch sym_max torch sym_min torch sym_sqrt operator truediv operator and_ assert any isinstance op torch _ops OpOverload op _SYM_OPS dataclass SerializedArtifact exported_program bytes state_dict bytes constants bytes example_inputs bytes dataclass _SerializedProgram exported_program ExportedProgram state_dict bytes constants bytes example_inputs bytes LazyMap dict Dictionary deferred instantiation node metadata values Purpose avoid creation symbolic-shape tensors before relevant shape guards parsed __init__ map = evaluated = set __setitem__ k v map k = v __getitem__ k out = map k k evaluated out evaluated add k map k = out map k __repr__ map __repr__ deserialize_device d Device - torch device d index None torch device type=d type type ignore call-overload torch device type=d type index=d index deserialize_size sizes Sequence SymInt - tuple int sym_int_size sizes assert sym_int_size type == as_int f Only as_int supported got sym_int_size type tuple sym_int_size as_int sym_int_size sizes deserialize_stride strides Sequence SymInt - tuple int sym_int_stride strides assert sym_int_stride type == as_int f Only as_int supported got sym_int_stride type tuple sym_int_stride as_int sym_int_stride strides deserialize_scalar_type st ScalarType - torch dtype _SERIALIZE_TO_TORCH_DTYPE st deserialize_storage_offset offset SymInt - int assert offset type == as_int f Only as_int supported got offset type offset as_int _print_sympy s Union torch SymInt torch SymBool torch SymFloat sympy Expr isinstance s torch SymInt torch SymBool torch SymFloat s = s node expr sympy printing repr srepr s serialize_sym_int s Union int torch SymInt - SymInt isinstance s torch SymInt sympy Symbol int symbolic_shapes is_concrete_int s SymInt create as_int=int s assert isinstance s torch SymInt sympy Symbol s node hint None SymInt create as_expr=SymExpr _print_sympy s SymInt create as_expr=SymExpr _print_sympy s hint=SymExprHint create as_int=s node hint raise SerializeError f SymInt should either symbol int got ` s ` type ` type s ` serialize_sym_float s Union float torch SymFloat - SymFloat isinstance s torch SymFloat sympy Symbol float symbolic_shapes is_concrete_float s SymFloat create as_float=float s assert isinstance s torch SymFloat sympy Symbol s node hint None SymFloat create as_expr=SymExpr _print_sympy s SymFloat create as_expr=SymExpr _print_sympy s hint=SymExprHint create as_float=s node hint raise SerializeError f SymFloat should either symbol float got ` s ` type ` type s ` serialize_sym_bool s Union bool torch SymBool - SymBool isinstance s torch SymBool bool symbolic_shapes is_concrete_bool s SymBool create as_bool=bool s SymBool create as_expr=SymExpr expr_str=_print_sympy s raise SerializeError f SymBool should either symbol bool got ` s ` type ` type s ` serialize_tensor_meta t torch Tensor - TensorMeta Extract TensorMeta describing ` t ` TensorMeta dtype=_TORCH_TO_SERIALIZE_DTYPE t dtype sizes= serialize_sym_int s s t shape requires_grad=t requires_grad device=Device type=t device type index=t device index strides= serialize_sym_int s s t stride storage_offset=serialize_sym_int t storage_offset layout=_TORCH_TO_SERIALIZE_LAYOUT t layout _CURRENT_DESERIALIZER Optional GraphModuleDeserializer = None _reduce_fake_tensor fake_tensor FakeTensor is_parameter = isinstance fake_tensor torch nn Parameter tensor_meta = serialize_tensor_meta fake_tensor tensor_meta_bytes = json dumps _dataclass_to_dict tensor_meta cls=EnumEncoder encode utf- _reconstruct_fake_tensor tensor_meta_bytes is_parameter _reconstruct_fake_tensor serialized_tensor_meta bytes is_parameter bool - FakeTensor Deserialize bytes into TensorMeta json_tensor_meta = json loads serialized_tensor_meta decode utf- tensor_meta = _dict_to_dataclass TensorMeta json_tensor_meta Find current fake mode assert _CURRENT_DESERIALIZER None Need access current deserializer state fake_tensor = _CURRENT_DESERIALIZER deserialize_tensor_meta tensor_meta is_parameter fake_tensor = torch nn Parameter fake_tensor type ignore assignment pyrefly ignore bad-return fake_tensor serialize_torch_artifact artifact Optional Any pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - bytes artifact None b assert FakeTensor copyreg dispatch_table Refusing stomp existing FakeTensor reducer try copyreg pickle FakeTensor _reduce_fake_tensor buffer = io BytesIO This workaround backend s tensor deserialization problem unpickleTensor always create tensor device where originally saved This behavior bad multi-gpu training we wish directly load tensor designated device For now we simply move tensor cpu before saving TODO should fixed deserialization instead torch save artifact buffer pickle_protocol=pickle_protocol buffer getvalue finally del copyreg dispatch_table FakeTensor deserialize_torch_artifact serialized Union dict str Any tuple Any bytes isinstance serialized dict tuple serialized len serialized == buffer = io BytesIO serialized buffer seek weights_only=False we want load custom objects here e g ScriptObject artifact = torch load buffer weights_only=False assert isinstance artifact tuple dict artifact _sympy_int_to_int val sympy Expr adjust str - Optional int Convert simple sympy Integers into concrete int val sympy oo int_oo None val -sympy oo -int_oo None isinstance val sympy Integer int val TODO Remove adjustment when Ed gets rid fractional ranges log warning Export constraints cannot non-integer expressions Found type s value s We will attempt s value type val val adjust adjust == floor math floor val adjust == ceil math ceil val raise RuntimeError f Got invalid adjustment adjust _int_to_sympy_int val Optional int default - sympy Expr Convert concrete int into simple sympy Integers val None default val -int_oo int_oo val val == math inf int_oo val == -math inf -int_oo sympy Integer val _symbol_index sym sympy Symbol sym_type SymT int str sym len prefix_str sym_type serialize_range_constraints range_constraints dict sympy Symbol ValueRanges - dict str RangeConstraint str k RangeConstraint _sympy_int_to_int v lower ceil type ignore arg-type _sympy_int_to_int v upper floor type ignore arg-type k v range_constraints items _get_schema_from_target target isinstance target torch _ops OpOverload target _schema type target _serialization_registry _serialization_registry type target op_schema target raise RuntimeError f Cannot find schema type target dataclass GraphState inputs list Argument = field default_factory=list outputs list Argument = field default_factory=list nodes list Node = field default_factory=list tensor_values dict str TensorMeta = field default_factory=dict sym_int_values dict str SymInt = field default_factory=dict sym_bool_values dict str SymBool = field default_factory=dict sym_float_values dict str SymFloat = field default_factory=dict is_single_tensor_return bool = False custom_obj_values dict str CustomObjArgument = field default_factory=dict Final type __new__ metacls name bases classdict b bases isinstance b Final raise TypeError f type b __name__ acceptable base type type __new__ metacls name bases dict classdict is_metadata_matched config entry_metadata metadata_attrs = num_cpu_threads num_warps num_stages num_ctas attr metadata_attrs hasattr config attr hasattr entry_metadata attr getattr config attr = getattr entry_metadata attr False True get_triton_kernel_and_cache_entry node torch fx Node assert node target torch _higher_order_ops triton_kernel_wrap triton_kernel_wrapper_functional assert has_triton triton required serialize triton kernels triton runtime autotuner Autotuner triton runtime jit JITFunction assert isinstance node kwargs kernel_idx int kernel = torch _higher_order_ops triton_kernel_wrap kernel_side_table get_kernel node kwargs kernel_idx For Autotuner we need look underlying JITFunction s cache since Autotuner itself doesn t have cache is_autotuner = isinstance kernel Autotuner actual_kernel = kernel fn is_autotuner kernel hasattr actual_kernel device_caches caches = actual_kernel device_caches assert len caches keys == cache = next iter caches values hasattr actual_kernel cache old path still used cpu triton builds caches = actual_kernel cache assert len caches keys == cache = next iter caches values raise AssertionError f kernel caches found kernel actual_kernel __name__ len cache keys == actual_kernel next iter cache values has_constexprs = isinstance actual_kernel JITFunction hasattr actual_kernel constexprs len actual_kernel constexprs has_constexprs constexpr_vals = constexpr_idx actual_kernel constexprs constexpr_idx len actual_kernel arg_names param_name = actual_kernel arg_names constexpr_idx kwargs_dict = node kwargs get kwargs isinstance kwargs_dict dict param_name kwargs_dict constexpr_vals param_name = kwargs_dict param_name expected_values = constexpr_vals actual_kernel arg_names idx idx actual_kernel constexprs actual_kernel arg_names idx constexpr_vals matching_entries = sig_key cache_entry cache items constexpr_matches = re findall r \ constexpr \s ^ + \ sig_key constexpr_matches constexpr_values = match constexpr_matches match True False constexpr_values append match == True match e match E match constexpr_values append float match constexpr_values append int match constexpr_values == expected_values matching_entries append sig_key cache_entry matching_entries = list cache items len matching_entries == raise AssertionError f couldn t find kernel cache entry metadata matching autotuner configs kernel actual_kernel __name__ f Available cache keys list cache keys len matching_entries == actual_kernel matching_entries is_autotuner sig_key cache_entry matching_entries entry_metadata = cache_entry metadata config kernel configs is_metadata_matched config entry_metadata actual_kernel cache_entry raise AssertionError f Multiple cache entries found autotuned kernel actual_kernel __name__ f same constexpr values has_constexprs no constexpr f couldn t disambiguate using configs raise AssertionError f Multiple cache entries found non-autotuned kernel actual_kernel __name__ f same constexpr values has_constexprs no constexpr f This should happen Available cache keys key key _ matching_entries final GraphModuleSerializer metaclass=Final __init__ graph_signature ep ExportGraphSignature module_call_graph list ep ModuleCallEntry graph_state = GraphState graph_signature = graph_signature module_call_graph = module_call_graph custom_objs dict str torch _C ScriptObject = duplicate_getitem_nodes dict str str = treespec_namedtuple_fields dict str NamedTupleDef = contextmanager save_graph_state saved = graph_state graph_state = GraphState try yield finally graph_state = saved handle_placeholder node torch fx Node assert node op == placeholder val = node meta val log debug handle_placeholder s s node name val isinstance val torch Tensor graph_input = Argument create as_tensor=self serialize_tensor_output node name val isinstance val torch SymInt graph_input = Argument create as_sym_int=self serialize_sym_int_output node name val isinstance val torch SymFloat raise AssertionError SymFloat graph input implemented yet isinstance val int bool str float type None graph_input = serialize_input val isinstance val ep CustomObjArgument class_fqn = val class_fqn graph_input = Argument create as_custom_obj=CustomObjArgument name=node name class_fqn=class_fqn graph_state custom_obj_values node name = serialize_script_obj_meta val raise AssertionError f Unimplemented graph input type node meta val graph_state inputs append graph_input handle_output node torch fx Node assert node op == output assert len node args == FX Node s args should have one arg node_args = node args log debug handle_output s s node name node_args isinstance node_args torch fx Node For singleton tensor returns graph_state is_single_tensor_return = True graph_state outputs = serialize_input node_args assert isinstance node_args tuple list graph_state outputs = serialize_input arg arg node_args serialize_operator target - str isinstance target str target target __module__ startswith torch _ops TODO zhxchen Maybe provide function name helper FX From torch fx node _get_qualified_name module = target __module__ replace torch _ops torch ops f module target __name__ TODO zhxchen Don t catch all here f target __module__ target __name__ handle_call_function node torch fx Node assert node op == call_function meta_val = node meta get val log debug handle_call_function s s s s - s node name node target node args node kwargs meta_val getitem has been handled producer node skip here node target operator getitem node target _SYM_OPS meta_val None isinstance meta_val torch SymInt torch SymBool torch SymFloat assert len node kwargs == ex_node = Node target=self serialize_operator node target inputs=self serialize_sym_op_inputs node target node args outputs= serialize_output node name meta_val metadata=self serialize_metadata node isinstance node target torch _ops OpOverload ex_node = Node target=self serialize_operator node target inputs=self serialize_inputs node target node args node kwargs outputs=self serialize_outputs node TODO create new tensor_values here meta might have faketensor info metadata=self serialize_metadata node isinstance node target torch _ops HigherOrderOperator _is_hop_single_tensor_return node - bool assert isinstance node target torch _ops HigherOrderOperator HOP schema always available so we look node meta val meta_val = node meta get val None meta_val None isinstance meta_val torch Tensor Special handle serialization aoti_call_delegate node target torch _higher_order_ops aoti_call_delegate serializable_args = list node args AOTI lowered module serializable serialize aoti_path instead lowered_module_name str = node args name type ignore assignment no-untyped-def union-attr assert hasattr node graph owning_module lowered_module_name lowered_module = getattr node graph owning_module lowered_module_name type ignore no-untyped-def serializable_args = lowered_module aoti_path AOTI compiled graph module node args stateful will fail verifier check Skip serializing original_gm workaround serializable_args = None serializable_weight_nodes = serializable_args None isinstance serializable_args Iterable weight_node serializable_args skip passing custom obj into weight arg hack The schema weight input list Tensors Downstream runtime actively consuming weighs arg anything meaningful isinstance weight_node torch fx Node isinstance weight_node meta get val None ep CustomObjArgument continue serializable_weight_nodes append weight_node serializable_args = serializable_weight_nodes serialize_tensor_list_output node meta_val = node meta get val None tensor_args = idx meta enumerate meta_val name = _output_node_name_at_index node idx tensor_args append serialize_tensor_output name meta Argument create as_tensors=tensor_args ex_node = Node target=self serialize_operator node target inputs=self serialize_hoo_inputs serializable_args node kwargs outputs=serialize_tensor_list_output node metadata=self serialize_metadata node is_hop_single_tensor_return=False node target torch _higher_order_ops triton_kernel_wrap triton_kernel_wrapper_functional kernel kernel_cache_entry = get_triton_kernel_and_cache_entry node kernel_cache_metadata = kernel_cache_entry metadata meta_val = node meta val assert isinstance meta_val dict output_keys = meta_val keys output_indices = constexpr_keys = p name p kernel params p is_constexpr found_constexpr = False args_new = i = assert isinstance node kwargs kwargs dict k v node kwargs kwargs items don t serialize constexpr since they will embedded into binary don t need passed around attributes k constexpr_keys found_constexpr = True continue assert found_constexpr non-constexpr args found after constexpr arg s k output_keys output_indices append i args_new += v type ignore assignment i += assert isinstance node kwargs grid list kernel_name_with_hash = f kernel fn __name__ _ kernel_cache_metadata hash kwargs_new = name kernel_name_with_hash grid node kwargs grid output_indices output_indices num_warps kernel_cache_metadata num_warps hasattr kernel_cache_metadata num_cpu_threads kwargs_new num_cpu_threads = kernel_cache_metadata num_cpu_threads hasattr kernel_cache_metadata shared kwargs_new shared_memory_bytes = kernel_cache_metadata shared ex_node = Node target=self serialize_operator node target inputs=self serialize_hoo_inputs args_new kwargs_new outputs=self serialize_hoo_outputs node metadata=self serialize_metadata node is_hop_single_tensor_return=_is_hop_single_tensor_return node ex_node = Node target=self serialize_operator node target inputs=self serialize_hoo_inputs node args node kwargs outputs=self serialize_hoo_outputs node metadata=self serialize_metadata node is_hop_single_tensor_return=_is_hop_single_tensor_return node type node target _serialization_registry Sanity check unhandled serialization assert type node target _serialization_registry f type node target supported export serialization handler = _serialization_registry type node target namespace = handler namespace op_name = handler to_op_name node target assert isinstance namespace str isinstance op_name str assert namespace op_name ex_node = Node target=f namespace op_name inputs=self serialize_inputs node target node args node kwargs outputs=self serialize_outputs node metadata=self serialize_metadata node raise SerializeError f Serializing node target supported graph_state nodes append ex_node handle_get_attr node log debug handle_get_attr s node name _output_node_at_index node index - Optional torch fx Node user_node = None user node users assert user target operator getitem f user getitem node index == user args user_node None user_node = user We want deduplicate getitem nodes trying index same index duplicate_getitem_nodes user name = user_node name user_node _output_node_name_at_index node index - str user_node = _output_node_at_index node index user_node None f node name _unused_ index user_node name serialize_metadata node torch fx Node - dict str str ret = stack_trace = node meta get stack_trace ret stack_trace = stack_trace nn_module_stack = node meta get nn_module_stack export_nn_module_stack val assert isinstance val tuple len val == path ty = val assert isinstance path str assert isinstance ty str path + + ty Serialize key orig_path type_str nn_module_list = f k export_nn_module_stack v k v nn_module_stack items ret nn_module_stack = ST_DELIMITER join nn_module_list source_fn_st = node meta get source_fn_stack source_fn_list = f source_fn serialize_operator source_fn source_fn source_fn_st ret source_fn_stack = ST_DELIMITER join source_fn_list torch_fn = node meta get torch_fn ret torch_fn = ST_DELIMITER join list torch_fn custom = node meta get custom try ret custom = json dumps custom except Exception e raise SerializeError f Failed serialize custom metadata node node name error e e ret serialize_script_obj_meta script_obj_meta ep CustomObjArgument - CustomObjArgument log debug serialize_script_obj_meta s script_obj_meta CustomObjArgument name=script_obj_meta name class_fqn=script_obj_meta class_fqn serialize_sym_op_inputs op args - list NamedArgument isinstance op torch _ops OpOverload args_names = arg name arg op _schema arguments assert op _SYM_OPS args_names = list inspect signature op parameters keys serialized_args = args_name arg zip args_names args serialized_args append NamedArgument name=args_name arg=self serialize_input arg kind=ArgumentKind POSITIONAL serialized_args serialize_inputs target Any torch _ops OpOverload other custom operator types args kwargs=None - list NamedArgument schema = None serialized_args = isinstance target torch _higher_order_ops torchbind CallTorchBind obj = args method = args schema = target schema obj method assert isinstance target torch _ops OpOverload _registered_extension_types schema = _get_schema_from_target target assert schema None kwargs = kwargs i schema_arg enumerate schema arguments schema_arg name kwargs serialized_args append NamedArgument name=schema_arg name arg=self serialize_input kwargs schema_arg name schema_arg type kind=ArgumentKind KEYWORD schema_arg kwarg_only i len args serialized_args append NamedArgument name=schema_arg name arg=self serialize_input args i schema_arg type kind=ArgumentKind POSITIONAL We intentionally don t serialize missing arguments default values pass serialized_args serialize_hoo_inputs args kwargs - list NamedArgument For serializing HOO inputs since HOOs do have schema inputs = NamedArgument name= arg=self serialize_input kind=ArgumentKind POSITIONAL args inputs extend NamedArgument name=name arg=self serialize_input kind=ArgumentKind KEYWORD name kwargs items inputs is_inductor_sym_int_arg arg - bool This special branch handling SymInt args inductor s ExternalFallbackNode For regular FX graph SymInt arg should fx Node should verified is_sym_int_arg type arg int isinstance arg torch SymInt is_sym_int_arg arg - bool type arg int isinstance arg torch fx Node arg name graph_state sym_int_values is_sym_float_arg arg - bool isinstance arg float isinstance arg torch fx Node arg name graph_state sym_float_values is_sym_bool_arg arg - bool isinstance arg bool isinstance arg torch fx Node arg name graph_state sym_bool_values should torch _C JitType annotation busted serialize_input arg arg_type Optional Any = None - Argument torch _inductor ir inductor_ir inductor_tensor_buffers = inductor_ir Buffer inductor_ir ReinterpretView isinstance arg torch fx Node arg op == get_attr assert isinstance arg target str attr = getattr arg graph owning_module arg target isinstance attr torch Tensor raise SerializeError getattr nodes containing tensors should appear graph isinstance attr torch fx GraphModule save_graph_state graph = serialize_graph attr Argument create as_graph=GraphArgument name=arg target graph=graph type attr __name__ == LoweredBackendModule Special handling executorch_call_delegate HOP It s first argument LoweredBackendModule which we serialize name backend id lowered module module_name = getattr attr module_name None backend_id = getattr attr backend_id None assert module_name None module_name should None assert backend_id None backend_id should None Argument create as_string=f module_name - backend_id raise SerializeError f Unsupported getattr attribute arg target type type attr is_sym_int_arg arg Argument create as_sym_int=SymIntArgument create as_name=arg name is_sym_float_arg arg Argument create as_sym_float=SymFloatArgument create as_name=arg name is_sym_bool_arg arg Argument create as_sym_bool=SymBoolArgument create as_name=arg name isinstance arg meta val ep CustomObjArgument Argument create as_custom_obj=CustomObjArgument name=arg name class_fqn=arg meta val class_fqn arg name duplicate_getitem_nodes dedup_name = duplicate_getitem_nodes arg name Argument create as_tensor=TensorArgument name=dedup_name Argument create as_tensor=TensorArgument name=arg name isinstance arg inductor_tensor_buffers Other branches arguments fx node This special branch handling buffers representing tensor arguments inductor s ExternalFallbackNode export_extern_kernel_node using function serialize arguments arg_name = arg get_name assert arg_name None Buffer must have valid name Argument create as_tensor=TensorArgument name=arg_name isinstance arg inductor_ir TorchBindObject This special branch handling TorchBindObject inductor s ExternalFallbackNode export_extern_kernel_node using function serialize arguments arg_name = arg get_name assert arg_name None Buffer must have valid name arg_val = arg get_real_obj class_fqn = arg_val _type qualified_name custom_objs arg_name = arg_val Argument create as_custom_obj=CustomObjArgument arg_name class_fqn isinstance arg torch SymInt This special branch handling SymInt args inductor s ExternalFallbackNode For regular FX graph SymInt arg should fx Node is_sym_int_arg arg being true Argument create as_sym_int=SymIntArgument create as_name=str arg isinstance arg torch SymFloat This special branch handling SymFloat args inductor s ExternalFallbackNode For regular FX graph SymInt arg should fx Node is_sym_float_arg arg being true Argument create as_sym_float=SymFloatArgument create as_name=str arg type arg bool Argument create as_bool=arg type arg str Argument create as_string=arg type arg int Argument create as_int=arg type arg float Argument create as_float=arg type arg complex Argument create as_complex=ComplexValue real=arg real imag=arg imag arg None Argument create as_none=True isinstance arg list tuple len arg == arg_type None isinstance arg_type torch OptionalType arg_type = arg_type getElementType type ignore assignment assert isinstance arg_type torch ListType elem_type = arg_type getElementType isinstance elem_type torch OptionalType elem_type = elem_type getElementType isinstance elem_type torch BoolType Argument create as_bools= isinstance elem_type torch IntType Argument create as_ints= isinstance elem_type torch FloatType Argument create as_floats= isinstance elem_type torch StringType Argument create as_strings= isinstance elem_type torch TensorType Argument create as_tensors= I believe empty symint lists default ints please file issue case raise SerializeError f Empty list type elem_type nyi We could serialize default tensor list This needed HOO case log warning Unsure how serialize given empty list we don t know what type argument Serializing tensor list default Argument create as_tensors= all type bool arg Argument create as_bools=list arg all type int arg Argument create as_ints=list arg all type float arg Argument create as_floats=list arg all type str arg Argument create as_strings=list arg all is_inductor_sym_int_arg arg This special branch handling SymInt args inductor s ExternalFallbackNode For regular FX graph SymInt arg should fx Node values = arg isinstance torch SymInt values append SymIntArgument create as_name=str type int values append SymIntArgument create as_int=a Argument create as_sym_ints=values all isinstance torch SymFloat arg Argument create as_sym_floats= SymFloatArgument create as_name=str arg all is_sym_int_arg arg list sym_ints values = arg isinstance torch fx Node values append SymIntArgument create as_name=a name type int values append SymIntArgument create as_int=a Argument create as_sym_ints=values all is_sym_float_arg arg list sym_float values = arg isinstance torch fx Node values append SymFloatArgument create as_name=a name isinstance float values append SymFloatArgument create as_float=a Argument create as_sym_floats=values all is_sym_bool_arg arg list sym_bools values = arg isinstance torch fx Node values append SymBoolArgument create as_name=a name isinstance bool values append SymBoolArgument create as_bool=a Argument create as_sym_bools=values all isinstance torch fx Node arg list tensors arguments = arg op == get_attr raise SerializeError getattr nodes containing tensors should appear graph arguments append TensorArgument name=a name Argument create as_tensors=arguments all isinstance torch fx Node type None arg list optional tensors serialize_optional_tensor_args None OptionalTensorArgument create as_none=True isinstance torch fx Node OptionalTensorArgument create as_tensor=TensorArgument name=a name raise SerializeError f Unsupported list tuple argument Argument create as_optional_tensors=list map serialize_optional_tensor_args arg all isinstance inductor_tensor_buffers arg list inductor buffers Argument create as_tensors= TensorArgument name=a get_name arg all isinstance inductor_tensor_buffers type None arg list inductor buffers optional tensors serialize_optional_tensor_args None OptionalTensorArgument create as_none=True isinstance inductor_tensor_buffers OptionalTensorArgument create as_tensor=TensorArgument name=a get_name raise SerializeError f Unsupported list tuple argument Argument create as_optional_tensors=list map serialize_optional_tensor_args arg raise SerializeError f Unsupported list tuple argument type type arg isinstance arg torch dtype Argument create as_scalar_type=_TORCH_TO_SERIALIZE_DTYPE arg isinstance arg torch device Argument create as_device=Device type=arg type index=arg index isinstance arg torch memory_format Argument create as_memory_format=_TORCH_TO_SERIALIZE_MEMORY_FORMAT arg isinstance arg torch layout Argument create as_layout=_TORCH_TO_SERIALIZE_LAYOUT arg isinstance arg torch _C ScriptObject arg _has_method __getstate__ type ignore attr-defined arg _has_method __setstate__ type ignore attr-defined raise SerializeError f Unable serialize custom arg Please define serialization methods via def_pickle Custom objects through torchind serializable pickle through implementing def_pickle function This should result object containing __getstate__ __setstate__ serialize deserialize function custom_obj_name = f _custom_obj_ len custom_objs custom_objs custom_obj_name = arg class_fqn = arg _type qualified_name type ignore attr-defined Argument create as_custom_obj=CustomObjArgument custom_obj_name class_fqn isinstance arg torch _ops OpOverload torch _ops HigherOrderOperator Argument create as_operator=self serialize_operator arg raise SerializeError f Unsupported argument type type arg schema arg_type arg_type serialize_tensor_output name meta_val - TensorArgument assert name graph_state tensor_values graph_state tensor_values name = serialize_tensor_meta meta_val TensorArgument name=name serialize_sym_int_output name meta_val - SymIntArgument assert name graph_state sym_int_values graph_state sym_int_values name = serialize_sym_int meta_val SymIntArgument create as_name=name serialize_sym_float_output name meta_val - SymFloatArgument assert name graph_state sym_float_values graph_state sym_float_values name = serialize_sym_float meta_val SymFloatArgument create as_name=name serialize_sym_bool_output name meta_val - SymIntArgument assert name graph_state sym_bool_values graph_state sym_bool_values name = serialize_sym_bool meta_val SymBoolArgument create as_name=name serialize_input_spec spec ep InputSpec - InputSpec log debug serialize_input_spec s spec spec kind == ep InputKind USER_INPUT isinstance spec arg ep ConstantArgument type spec arg value int constant_spec = ConstantValue create as_int=spec arg value type spec arg value bool constant_spec = ConstantValue create as_bool=spec arg value type spec arg value str constant_spec = ConstantValue create as_string=spec arg value type spec arg value float constant_spec = ConstantValue create as_float=spec arg value spec arg value None constant_spec = ConstantValue create as_none=True raise SerializeError f Unhandled constant input spec arg value serialize InputSpec create constant_input=InputToConstantInputSpec name=spec arg name value=constant_spec InputSpec create user_input=UserInputSpec arg=self serialize_argument_spec spec arg spec kind == ep InputKind PARAMETER assert spec target None assert isinstance spec arg ep TensorArgument InputSpec create parameter=InputToParameterSpec arg=TensorArgument name=spec arg name parameter_name=spec target spec kind == ep InputKind BUFFER assert spec target None assert isinstance spec arg ep TensorArgument assert spec persistent None InputSpec create buffer=InputToBufferSpec arg=TensorArgument name=spec arg name buffer_name=spec target persistent=spec persistent spec kind == ep InputKind CONSTANT_TENSOR assert spec target None assert isinstance spec arg ep TensorArgument InputSpec create tensor_constant=InputToTensorConstantSpec arg=TensorArgument name=spec arg name tensor_constant_name=spec target spec kind == ep InputKind CUSTOM_OBJ assert spec target None assert isinstance spec arg ep CustomObjArgument InputSpec create custom_obj=InputToCustomObjSpec arg=CustomObjArgument name=spec arg name class_fqn=spec arg class_fqn custom_obj_name=spec target spec kind == ep InputKind TOKEN assert isinstance spec arg ep TokenArgument InputSpec create token=InputTokenSpec arg=TokenArgument name=spec arg name raise AssertionError f Unknown argument kind spec serialize_output_spec spec ep OutputSpec - OutputSpec log debug serialize_output_spec s spec spec kind == ep OutputKind USER_OUTPUT OutputSpec create user_output=UserOutputSpec arg=self serialize_argument_spec spec arg spec kind == ep OutputKind LOSS_OUTPUT assert isinstance spec arg ep TensorArgument OutputSpec create loss_output=LossOutputSpec arg=TensorArgument name=spec arg name spec kind == ep OutputKind BUFFER_MUTATION assert spec target None assert isinstance spec arg ep TensorArgument OutputSpec create buffer_mutation=BufferMutationSpec arg=TensorArgument name=spec arg name buffer_name=spec target spec kind == ep OutputKind PARAMETER_MUTATION assert spec target None assert isinstance spec arg ep TensorArgument OutputSpec create parameter_mutation=ParameterMutationSpec arg=TensorArgument name=spec arg name parameter_name=spec target spec kind == ep OutputKind GRADIENT_TO_PARAMETER assert spec target None assert isinstance spec arg ep TensorArgument OutputSpec create gradient_to_parameter=GradientToParameterSpec arg=TensorArgument name=spec arg name parameter_name=spec target spec kind == ep OutputKind GRADIENT_TO_USER_INPUT assert spec target None assert isinstance spec arg ep TensorArgument OutputSpec create gradient_to_user_input=GradientToUserInputSpec arg=TensorArgument name=spec arg name user_input_name=spec target spec kind == ep OutputKind USER_INPUT_MUTATION assert spec target None assert isinstance spec arg ep TensorArgument OutputSpec create user_input_mutation=UserInputMutationSpec arg=TensorArgument name=spec arg name user_input_name=spec target spec kind == ep OutputKind TOKEN assert isinstance spec arg ep TokenArgument OutputSpec create token=OutputTokenSpec arg=TokenArgument name=spec arg name raise AssertionError f Unknown argument kind spec serialize_signature sig ep ExportGraphSignature - GraphSignature log debug \n serialize_signature GraphSignature input_specs= serialize_input_spec s s sig input_specs output_specs= serialize_output_spec s s sig output_specs serialize_argument_spec x ep ArgumentSpec - Argument isinstance x ep TensorArgument Argument create as_tensor=TensorArgument name=x name isinstance x ep SymIntArgument Argument create as_sym_int=SymIntArgument create as_name=x name isinstance x ep SymFloatArgument Argument create as_sym_float=SymFloatArgument create as_name=x name isinstance x ep ConstantArgument serialize_input x value isinstance x ep CustomObjArgument Argument create as_custom_obj=CustomObjArgument name=x name class_fqn=x class_fqn raise AssertionError TODO serialize_treespec treespec pytree TreeSpec - str We want additionally save all field names namedtuples case users want check treespec types equivalent store_namedtuple_fields ts pytree TreeSpec - None ts type None ts type namedtuple pytree is_namedtuple_class ts type serialized_type_name = pytree SUPPORTED_SERIALIZED_TYPES ts context serialized_type_name serialized_type_name treespec_namedtuple_fields field_names = treespec_namedtuple_fields serialized_type_name field_names field_names = ts context _fields raise SerializeError f The given TreeSpec s namedtuple type ts context f found have field names ts context _fields f somehow previously found have field names field_names treespec_namedtuple_fields serialized_type_name = NamedTupleDef field_names=ts context _fields child ts children store_namedtuple_fields child serialized_treespec = treespec_dumps treespec TREESPEC_VERSION store_namedtuple_fields treespec serialized_treespec serialize_module_call_signature module_call_signature ep ModuleCallSignature - ModuleCallSignature log debug serialize_module_call_signature s module_call_signature ModuleCallSignature inputs= serialize_argument_spec x x module_call_signature inputs outputs= serialize_argument_spec x x module_call_signature outputs in_spec=self serialize_treespec module_call_signature in_spec out_spec=self serialize_treespec module_call_signature out_spec forward_arg_names=names names = module_call_signature forward_arg_names None serialize_module_call_graph module_call_graph list ep ModuleCallEntry - list ModuleCallEntry log debug \n serialize_module_call_graph ModuleCallEntry fqn=entry fqn signature= serialize_module_call_signature entry signature entry signature None entry module_call_graph serialize_outputs node torch fx Node - list Argument For given node dataclass representing its output values NOTE Multiple outputs We handle aggregates differently than FX For FX looks like x = call_function multiple_return element = call_function getitem x foo = call_function use_output element We do want intermediate ` getitem ` call so our serialized thing looks like element element element = call_function multiple_return foo = call_function use_output element We want names consistent across these two schemes so we can mostly reuse names coming FX This function computes mapping FX representation our representation preserving names _is_single_tensor_list_return target Any - bool schema = _get_schema_from_target target returns = schema returns len returns = False return_type = returns real_type isinstance return_type torch ListType isinstance return_type getElementType torch TensorType assert node op == call_function isinstance node target torch _ops OpOverload _registered_extension_types schema = _get_schema_from_target node target returns = schema returns len returns == meta_val = node meta val Check single value _is_single_tensor_list_return node target e g - Tensor tensor_args = idx meta enumerate meta_val name = _output_node_name_at_index node idx tensor_args append serialize_tensor_output name meta Argument create as_tensors=tensor_args len returns == serialize_output node name meta_val There two possibilities point - This operator returns tuple Tensors e g - Tensor Tensor - This operator returns tuple mixed Tensor Tensors e g - Tensor Tensor Either way start gathering list TensorArguments correct names For consistent naming FX consult downstream ` getitem ` node make sure our outputs have same name output_arguments = idx meta return_schema enumerate zip meta_val returns meta None assert isinstance return_schema real_type torch OptionalType torch TensorType When type annotated Tensor type op can also undefined Tensor which will implicitly converted None Python output_arguments append Argument create as_none=True isinstance meta FakeTensor assert isinstance return_schema real_type torch OptionalType torch TensorType name = _output_node_name_at_index node idx output_arguments append serialize_output name meta isinstance meta list List Tensor type assert isinstance return_schema real_type torch ListType isinstance return_schema real_type getElementType torch TensorType user_node = _output_node_at_index node idx assert user_node None args = i m enumerate meta m None continue sub_user_node_name = _output_node_name_at_index user_node i args append serialize_tensor_output sub_user_node_name m output_arguments append Argument create as_tensors=args isinstance meta int SymInt float SymFloat user_node_name = _output_node_name_at_index node idx output_arguments append serialize_output user_node_name meta raise ValueError f Unhandled output type type meta node node format_node output_arguments serialize_hoo_outputs node torch fx Node - list Argument For serializing HOO outputs since HOOs do have schema meta_val = node meta val isinstance meta_val tuple outputs = i element_meta_val enumerate meta_val user_node = _output_node_at_index node i isinstance element_meta_val list e g - Tensor assert user_node None tensors = j m enumerate element_meta_val isinstance m torch Tensor raise SerializeError f Serialize list output type type m nyi name = _output_node_name_at_index user_node j tensors append serialize_tensor_output name m outputs append Argument create as_tensors=tensors name = user_node name user_node None f node name _unused_ i outputs append serialize_output name element_meta_val outputs isinstance meta_val dict tensor_args = use dict key idx idx meta meta_val items isinstance meta torch Tensor raise SerializeError f Serialize list output type type meta nyi name = _output_node_name_at_index node idx tensor_args append serialize_tensor_output name meta Argument create as_tensors=tensor_args serialize_output node name meta_val serialize_output name str meta_val Any - Argument Check single value meta_val None Argument create as_none=True isinstance meta_val torch Tensor e g - Tensor Argument create as_tensor=self serialize_tensor_output name meta_val isinstance meta_val bool torch SymBool e g - SymBool Argument create as_sym_bool=self serialize_sym_bool_output name meta_val isinstance meta_val int torch SymInt e g - SymInt assert isinstance meta_val bool Argument create as_sym_int=self serialize_sym_int_output name meta_val isinstance meta_val float torch SymFloat e g - SymFloat Argument create as_sym_float=self serialize_sym_float_output name meta_val list outputs should ve been handled earlier raise SerializeError f Unable serialize output meta_val _handle_getitem_users node torch fx Node - list TensorArgument meta_val = node meta val idx_to_name = user node users assert user target operator getitem f User node user node incorrect idx_to_name user args = user name idx _ enumerate meta_val FX does emit getitem node any outputs unused However we need name them so number outputs will correctly match schema Just assign dummy name idx idx_to_name idx_to_name idx = f node name _unused_ idx arg_list = i element_meta_val enumerate meta_val arg_list append serialize_tensor_output idx_to_name i element_meta_val arg_list serialize_graph graph_module torch fx GraphModule - Graph assert isinstance graph_module torch fx GraphModule log debug serialize_graph \n\n s graph_module print_readable print_output=False node graph_module graph nodes try getattr f handle_ node op node except Exception e raise SerializeError f Failed serializing node node graph node format_node \n Original exception traceback format_exc e Graph inputs=self graph_state inputs nodes=self graph_state nodes tensor_values=self graph_state tensor_values sym_int_values=self graph_state sym_int_values sym_float_values=self graph_state sym_float_values sym_bool_values=self graph_state sym_bool_values custom_obj_values=self graph_state custom_obj_values outputs=self graph_state outputs is_single_tensor_return=self graph_state is_single_tensor_return serialize_graph_module_metadata meta dict str Any ret = custom = meta get custom log debug \n serialize_graph_module_metadata s custom try ret custom = json dumps custom except Exception e raise SerializeError f Failed serialize custom metadata graph error e e ret serialize graph_module torch fx GraphModule - GraphModule log debug \n serialize graph = serialize_graph graph_module GraphModule graph=graph signature=self serialize_signature graph_signature module_call_graph=self serialize_module_call_graph module_call_graph metadata=self serialize_graph_module_metadata graph_module meta treespec_namedtuple_fields=self treespec_namedtuple_fields final ExportedProgramSerializer metaclass=Final __init__ opset_version Optional dict str int = None pickle_protocol int = DEFAULT_PICKLE_PROTOCOL opset_version dict str int = opset_version opset_version update opset_version aten opset_version opset_version aten = torch _C _get_max_operator_version pickle_protocol = pickle_protocol serialize exported_program ep ExportedProgram - _SerializedProgram Args exported_program Exported Program serialize exported_program validate gm_serializer = GraphModuleSerializer exported_program graph_signature exported_program module_call_graph serialized_graph_module = gm_serializer serialize exported_program graph_module serialized_range_constraints = serialize_range_constraints exported_program range_constraints TODO Directly serialize exported_program constants once CustomClassHolders get stored ExportedProgram rather than graph constants dict str Any = gm_serializer custom_objs copy n t exported_program constants items assert n constants constants n = t serialized_ep = ExportedProgram graph_module=serialized_graph_module opset_version=self opset_version range_constraints=serialized_range_constraints schema_version=SchemaVersion major=SCHEMA_VERSION minor=SCHEMA_VERSION verifiers= v dialect v exported_program verifiers torch_version=torch __version__ guards_code=exported_program _guards_code Test canonical form well defined canonicalize serialized_ep set constants keys Proxy cannot dumped so we remove them new_state_dict = remove_proxy_from_state_dict exported_program state_dict in_place=False _SerializedProgram serialized_ep serialize_torch_artifact new_state_dict pickle_protocol serialize_torch_artifact constants pickle_protocol serialize_torch_artifact exported_program example_inputs pickle_protocol final GraphModuleDeserializer metaclass=Final dataclasses dataclass Result graph_module torch fx GraphModule signature ep ExportGraphSignature module_call_graph list ep ModuleCallEntry names_to_symbols dict str sympy Symbol state_dict dict str Union torch Tensor torch nn Parameter constants dict str _ConstantAttributeType example_inputs Optional tuple tuple torch Tensor dict str Any __init__ - None serialized_name_to_node dict str torch fx Node = serialized_name_to_meta LazyMap = LazyMap str - MetaType graph = torch fx Graph module = torch nn Module contextmanager save_graph_module - Iterator None saved = graph module serialized_name_to_node serialized_name_to_meta unbacked_symbols graph = torch fx Graph module = torch nn Module serialized_name_to_node = serialized_name_to_meta = LazyMap unbacked_symbols set sympy Symbol = set try yield finally graph module serialized_name_to_node serialized_name_to_meta unbacked_symbols = saved deserialize_extension_operator serialized_target str namespace op_name = serialized_target split namespace = namespace starting handler = _deserialization_registry namespace handler from_op_name op_name deserialize_operator serialized_target str serialized_target startswith _operator TODO zhxchen Follow up module = operator serialized_target_names = serialized_target split serialized_target startswith torch module = torch type ignore misc serialized_target_names = serialized_target split serialized_target startswith math module = math type ignore misc serialized_target_names = serialized_target split serialized_target startswith deserialize_extension_operator serialized_target TODO zhxchen Don t catch all here serialized_target target = module name serialized_target_names hasattr target name serialized_target target = getattr target name target _parse_sym_expr expr_str str hint Optional Union int bool float = None - sympy Expr Parses does bottom-up processing sympy Expr nodes populating ShapeEnv caching symbols needed _process_sym_expr sym sympy Expr hint Optional Union int bool float = None - sympy Expr sym is_Integer sym is_Float sym is_Boolean base case sym recursive case important use str expr _print_sympy str expr key symbol_name_to_range expr_str = str sym arg sym args _parse_sym_expr arg symbol caching expr_str symbol_name_to_symbol sym = symbol_name_to_symbol expr_str symbol_name_to_symbol expr_str = sym isinstance sym sympy Symbol symbolic_shapes symbol_is_type sym SymT UNBACKED_INT SymT UNBACKED_FLOAT unbacked_symbols add sym hints hint None sym shape_env var_to_val shape_env add_var_to_val sym hint type ignore arg-type ValueRanges vr = symbol_name_to_range get expr_str shape_env constrain_symbol_range sym compiler_min=vr lower type ignore arg-type compiler_max=vr upper type ignore arg-type ShapeEnv meta isinstance sym sympy Symbol shape_env var_to_stack sym = CapturedTraceback extract skip= sym expr = sympy sympify expr_str locals= sympy_functions symbol_name_to_symbol _process_sym_expr expr hint deserialize_sym_int s SymInt - Union int torch SymInt val = s value s type == as_expr val hint None hint = None assert val hint type == as_int hint = val hint value sym = _parse_sym_expr val expr_str hint shape_env create_symintnode sym hint=hint s type == as_int assert type val int val raise SerializeError f SymInt has invalid field type s type value s value deserialize_sym_float s SymFloat - Union float torch SymFloat val = s value s type == as_expr hint = val hint as_float val hint None sym = _parse_sym_expr val expr_str hint shape_env create_symfloatnode sym hint=hint s type == as_float assert isinstance val float val raise SerializeError f SymFloat has invalid field type s type value s value deserialize_sym_bool s SymBool - Union bool torch SymBool val = s value s type == as_expr expr = _parse_sym_expr val expr_str shape_env create_symboolnode expr s type == as_bool assert isinstance val bool val raise SerializeError f SymBool has invalid field type s type value s value deserialize_tensor_meta tensor_meta TensorMeta - FakeTensor fake_tensor_mode cast FakeTensor torch empty_strided tuple deserialize_sym_int val val tensor_meta sizes type ignore misc tuple deserialize_sym_int val val tensor_meta strides type ignore misc device=deserialize_device tensor_meta device dtype=_SERIALIZE_TO_TORCH_DTYPE tensor_meta dtype requires_grad=tensor_meta requires_grad deserialize_script_obj_meta script_obj_meta CustomObjArgument - ep CustomObjArgument ep CustomObjArgument name=script_obj_meta name class_fqn=script_obj_meta class_fqn deserialize_graph_output output - Optional Union torch fx Node int output type == as_tensor serialized_name_to_node output as_tensor name output type == as_sym_int serialized_name_to_node output as_sym_int as_name output type == as_sym_bool serialized_name_to_node output as_sym_bool as_name output type == as_sym_float serialized_name_to_node output as_sym_float as_name output type == as_int output as_int output type == as_float output as_float output type == as_bool output as_bool output type == as_none None raise SerializeError f Unable deserialize output node output deserialize_graph serialized_graph Graph - torch fx Graph log debug \n deserialize_graph Handle tensor metas name tensor_value serialized_graph tensor_values items log debug deserialize_tensor_meta s input s name tensor_value serialized_name_to_meta name = lambda v=tensor_value deserialize_tensor_meta v name sym_int_value serialized_graph sym_int_values items log debug deserialize_sym_int s input s name sym_int_value serialized_name_to_meta name = lambda v=sym_int_value deserialize_sym_int v name sym_float_value serialized_graph sym_float_values items log debug deserialize_sym_float s input s name sym_float_value serialized_name_to_meta name = lambda v=sym_float_value deserialize_sym_float v name sym_bool_value serialized_graph sym_bool_values items log debug deserialize_sym_bool s input s name sym_bool_value serialized_name_to_meta name = lambda v=sym_bool_value deserialize_sym_bool v name script_obj_meta serialized_graph custom_obj_values items log debug deserialize_script_obj_meta s script_obj_meta serialized_name_to_meta name = lambda v=script_obj_meta deserialize_script_obj_meta v log debug \n deserialize graph nodes Inputs convert placeholder nodes FX i input_ enumerate serialized_graph inputs log debug deserialize input s input_ input_ type as_tensor as_custom_obj node_name = input_ value name placeholder_node = graph placeholder node_name FX might declare name illegal e g some nn Modules use input forward arguments we will overwrite placeholder_node name = node_name sync_fx_node node_name placeholder_node input_ type == as_sym_int input_ value type == as_name node_name = input_ value as_name placeholder_node = graph placeholder node_name FX might declare name illegal e g some nn Modules use input forward arguments we will overwrite placeholder_node name = node_name sync_fx_node node_name placeholder_node raise SerializeError f Deserializing constant symint input_ value input input_ type as_int as_float as_bool as_none as_string node_name = signature input_specs i arg name f arg i placeholder_node = graph placeholder node_name placeholder_node meta val = deserialize_input input_ raise SerializeError f Invalid input type input_ Nodes convert call_function nodes serialized_node serialized_graph nodes try target = deserialize_operator serialized_node target deserialize_node serialized_node target except Exception e raise SerializeError f Failed deserializing node serialized_node \n Original exception traceback format_exc e Outputs convert single ` output ` node outputs = output serialized_graph outputs log debug deserialize output s output outputs append deserialize_graph_output output serialized_graph is_single_tensor_return assert len outputs == outputs = outputs type ignore assignment outputs = tuple outputs type ignore assignment output_node = graph output outputs serialized_graph is_single_tensor_return output_node meta val = output_node args meta val output_node meta val = tuple arg meta val isinstance arg torch fx Node arg arg output_node args recompute unbacked bindings node graph nodes val = node meta get val None unbacked_bindings = symbolic_shapes _free_unbacked_symbols_with_path val shape_env=self shape_env pending=self unbacked_symbols simplify=True node meta unbacked_bindings = unbacked_bindings assert len unbacked_symbols == graph deserialize_node serialized_node Node target Callable - None _is_single_tensor_return target - bool schema = _get_schema_from_target target returns = schema returns len returns == isinstance returns real_type torch TensorType target _SYM_OPS target == torch ops aten item default can produce either SymInt SymBool name = serialized_node outputs value as_name args = deserialize_sym_op_inputs serialized_node inputs fx_node = graph create_node call_function target args name deserialize_sym_op_outputs serialized_node fx_node target torch _higher_order_ops triton_kernel_wrap triton_kernel_wrapper_functional raise SerializeError deserialize nyi torch _higher_order_ops triton_kernel_wrap triton_kernel_wrapper_functional isinstance target torch _ops HigherOrderOperator args kwargs = deserialize_hoo_inputs serialized_node inputs metadata = deserialize_metadata serialized_node metadata x args kwargs values isinstance x torch fx Node x op == get_attr means we have deserialized graph argument unfortunately schema does include metadata so we reuse metadata HOP call such arguments x meta update metadata If serialized HOP node has length= outputs type ` as_tensor ` ` There could two cases The HOP node returns single tensor The HOP node returns tuple containing single tensor We distinguish ` is_single_tensor_return ` field schema Node For BC getattr will True ` is_single_tensor_return ` doesn t exist This because prior adding ` is_single_tensor_return ` only could happen we handle type ` as_tensors ` name = serialized_node outputs as_tensor name len serialized_node outputs == hasattr serialized_node outputs as_tensor getattr serialized_node is_hop_single_tensor_return True None fx_node = graph create_node call_function target args kwargs name deserialize_outputs serialized_node fx_node fx_node meta update metadata isinstance target torch _ops OpOverload _registered_extension_types For convenience node returns single tensor name newly-created node after This ensures these tensor values have names consistent serialized name = serialized_node outputs as_tensor name _is_single_tensor_return target None FX will generate name us args kwargs = deserialize_inputs target serialized_node fx_node = graph create_node call_function target args kwargs name deserialize_outputs serialized_node fx_node _additional_msg = f We failed resolve target operator + If s custom op custom triton op usually because custom op registered + when deserializing Please custom op register before deserializing + Otherwise please file issue github isinstance target str raise SerializeError _additional_msg + f Unsupported target type node serialized_node type target fx_node meta update deserialize_metadata serialized_node metadata log debug deserialize_node s s s s - s fx_node name fx_node target fx_node args fx_node kwargs fx_node meta get val handle ShapeEnv asserts target torch ops aten _assert_scalar default isinstance arg = fx_node args bool expr = arg meta val type ignore union-attr isinstance expr torch SymBool shape_env guard_or_defer_runtime_assert expr node expr fx_node target torch ops aten sym_constrain_range_for_size default sym = fx_node args meta val type ignore union-attr isinstance sym torch SymInt shape_env _constrain_range_for_size sym node expr handle nn_module_stack serialization throws away empty dicts fx_node op placeholder output nn_module_stack fx_node meta fx_node meta nn_module_stack = deserialize_input_spec i InputSpec - ep InputSpec log debug deserialize_input_spec s i i type == user_input ep InputSpec kind=ep InputKind USER_INPUT arg=self deserialize_argument_spec i user_input arg target=None i type == parameter ep InputSpec kind=ep InputKind PARAMETER arg=ep TensorArgument name=i parameter arg name target=i parameter parameter_name i type == buffer ep InputSpec kind=ep InputKind BUFFER arg=ep TensorArgument name=i buffer arg name target=i buffer buffer_name persistent=i buffer persistent i type == tensor_constant ep InputSpec kind=ep InputKind CONSTANT_TENSOR arg=ep TensorArgument name=i tensor_constant arg name target=i tensor_constant tensor_constant_name i type == custom_obj ep InputSpec kind=ep InputKind CUSTOM_OBJ arg=ep CustomObjArgument name=i custom_obj arg name class_fqn=i custom_obj arg class_fqn target=i custom_obj custom_obj_name i type == token ep InputSpec kind=ep InputKind TOKEN arg=ep TokenArgument name=i token arg name target=None i type == constant_input ep InputSpec kind=ep InputKind USER_INPUT arg=ep ConstantArgument name=i constant_input name value=self deserialize_constant_input i constant_input value target=None raise AssertionError f Unknown input spec i deserialize_output_spec o OutputSpec - ep OutputSpec log debug deserialize_output_spec s o o type == user_output ep OutputSpec kind=ep OutputKind USER_OUTPUT arg=self deserialize_argument_spec o user_output arg target=None o type == loss_output ep OutputSpec kind=ep OutputKind LOSS_OUTPUT arg=ep TensorArgument name=o loss_output arg name target=None o type == buffer_mutation ep OutputSpec kind=ep OutputKind BUFFER_MUTATION arg=ep TensorArgument name=o buffer_mutation arg name target=o buffer_mutation buffer_name o type == parameter_mutation ep OutputSpec kind=ep OutputKind PARAMETER_MUTATION arg=ep TensorArgument name=o parameter_mutation arg name target=o parameter_mutation parameter_name o type == gradient_to_parameter ep OutputSpec kind=ep OutputKind GRADIENT_TO_PARAMETER arg=ep TensorArgument name=o gradient_to_parameter arg name target=o gradient_to_parameter parameter_name o type == gradient_to_user_input ep OutputSpec kind=ep OutputKind GRADIENT_TO_USER_INPUT arg=ep TensorArgument name=o gradient_to_user_input arg name target=o gradient_to_user_input user_input_name o type == user_input_mutation ep OutputSpec kind=ep OutputKind USER_INPUT_MUTATION arg=ep TensorArgument name=o user_input_mutation arg name target=o user_input_mutation user_input_name o type == token ep OutputSpec kind=ep OutputKind TOKEN arg=ep TokenArgument name=o token arg name target=None raise AssertionError f Unknown output spec o deserialize_signature sig GraphSignature - ep ExportGraphSignature log debug \n deserialize_signature ep ExportGraphSignature input_specs= deserialize_input_spec i i sig input_specs output_specs= deserialize_output_spec o o sig output_specs deserialize serialized_graph_module GraphModule serialized_state_dict Union dict str torch Tensor bytes constants Union dict str Any bytes example_inputs Optional Union tuple tuple torch Tensor dict str Any bytes = None symbol_name_to_range Optional dict str symbolic_shapes ValueRanges = None - Result global _CURRENT_DESERIALIZER assert _CURRENT_DESERIALIZER None _CURRENT_DESERIALIZER = try log debug \n deserialize shape_env = symbolic_shapes ShapeEnv assume_static_by_default=True fake_tensor_mode = FakeTensorMode allow_fallback_kernels=False allow_non_fake_inputs=True shape_env=self shape_env sympy_functions = all torch utils _sympy functions should go here TODO avik find better way keep collection sync e g ` exec torch utils _sympy functions ` would work long public API module complete FloorDiv torch utils _sympy functions FloorDiv ModularIndexing torch utils _sympy functions ModularIndexing Where torch utils _sympy functions Where PythonMod torch utils _sympy functions PythonMod Mod torch utils _sympy functions Mod CleanDiv torch utils _sympy functions CleanDiv CeilToInt torch utils _sympy functions CeilToInt FloorToInt torch utils _sympy functions FloorToInt CeilDiv torch utils _sympy functions CeilDiv LShift torch utils _sympy functions LShift RShift torch utils _sympy functions RShift PowByNatural torch utils _sympy functions PowByNatural FloatPow torch utils _sympy functions FloatPow FloatTrueDiv torch utils _sympy functions FloatTrueDiv IntTrueDiv torch utils _sympy functions IntTrueDiv IsNonOverlappingAndDenseIndicator torch utils _sympy functions IsNonOverlappingAndDenseIndicator TruncToFloat torch utils _sympy functions TruncToFloat TruncToInt torch utils _sympy functions TruncToInt RoundToInt torch utils _sympy functions RoundToInt RoundDecimal torch utils _sympy functions RoundDecimal ToFloat torch utils _sympy functions ToFloat Identity torch utils _sympy functions Identity symbol_name_to_symbol dict str sympy Symbol = constants = deserialize_torch_artifact constants signature = deserialize_signature serialized_graph_module signature deserialization does analysis checks so we create fake range constraints restore original range constraints afterwards symbol_name_to_range = we also need bump unbacked sym float int counters shape env accommodate unbacked symbols exported program unbacked_symbols = set count_unbacked_symfloat count_unbacked_symint = - - unbacked_symfloat_prefix unbacked_symint_prefix = prefix_str t t SymT UNBACKED_FLOAT SymT UNBACKED_INT symbol_name_to_range k vr symbol_name_to_range items lower = vr lower symbol_name_to_range k = symbolic_shapes ValueRanges _int_to_sympy_int lower -int_oo vr upper k startswith unbacked_symfloat_prefix i = int k len unbacked_symfloat_prefix count_unbacked_symfloat = max count_unbacked_symfloat i k startswith unbacked_symint_prefix i = int k len unbacked_symint_prefix count_unbacked_symint = max count_unbacked_symint i TODO pianpwk we can clean up unused symbols range_constraints then logic can just handled unbacked_symbols alone _ range count_unbacked_symfloat + shape_env unbacked_symfloat_counter += _ range count_unbacked_symint + shape_env unbacked_symint_counter += example_inputs None len example_inputs example_inputs = deserialize_torch_artifact example_inputs example_inputs = None deserialize_graph serialized_graph_module graph _enable_graph_inputs_of_type_nn_module example_inputs module_call_graph = deserialize_module_call_graph serialized_graph_module module_call_graph graph_module = ep _create_graph_module_for_export module graph meta = custom = serialized_graph_module metadata get custom meta custom = json loads custom hasattr serialized_graph_module treespec_namedtuple_fields meta treespec_namedtuple_fields = type_ fields serialized_graph_module treespec_namedtuple_fields items meta treespec_namedtuple_fields type_ = fields field_names graph_module meta = meta GraphModuleDeserializer Result graph_module=graph_module signature=self signature module_call_graph=module_call_graph names_to_symbols=self symbol_name_to_symbol state_dict=deserialize_torch_artifact serialized_state_dict constants=self constants example_inputs=self example_inputs finally _CURRENT_DESERIALIZER = None sync_fx_node name str fx_node torch fx Node name serialized_name_to_node raise SerializeError f Node name has already been deserialized before overwrite name fx_node name = name serialized_name_to_node name = fx_node assert val fx_node meta fx_node meta val = serialized_name_to_meta name deserialize_sym_op_inputs inputs tuple deserialize_input input arg input inputs deserialize_inputs target serialized_node Node schema_args = _get_schema_from_target target arguments argument_kinds = input name input kind input serialized_node inputs actual_args = input name deserialize_input input arg input serialized_node inputs args = kwargs OrderedDict str Any = OrderedDict schema_arg schema_args schema_arg name actual_args arg = actual_args schema_arg name kind = argument_kinds schema_arg name kind == ArgumentKind POSITIONAL args append arg continue kind == ArgumentKind KEYWORD keyword iskeyword schema_arg name kwargs schema_arg name = arg continue If there s no ArgumentKind found fallback old cases is_positional = schema_arg has_default_value schema_arg kwarg_only is_positional args append actual_args schema_arg name keyword iskeyword schema_arg name assert schema_arg kwarg_only len kwargs kwargs = OrderedDict args extend list kwargs values args append actual_args schema_arg name schema_arg name actual_args kwargs schema_arg name = actual_args schema_arg name tuple args kwargs deserialize_hoo_inputs inputs list NamedArgument For deserializing HOO inputs since HOOs do have schema args = kwargs = input_ inputs input_ name = kwargs input_ name = deserialize_input input_ arg args append deserialize_input input_ arg tuple args kwargs deserialize_input inp Argument - Any value = inp value typ_ = inp type typ_ == as_none None should converted None encoded bool serialized Convert serialized object torch equivalent None typ_ == as_tensor serialized_name_to_node inp as_tensor name typ_ == as_scalar_type _SERIALIZE_TO_TORCH_DTYPE inp as_scalar_type typ_ == as_memory_format _SERIALIZE_TO_TORCH_MEMORY_FORMAT inp as_memory_format typ_ == as_layout _SERIALIZE_TO_TORCH_LAYOUT inp as_layout typ_ == as_graph assert isinstance value GraphArgument save_graph_module deserialize_graph value graph submodule = ep _create_graph_module_for_export module graph module register_module value name submodule graph create_node get_attr value name name=value name typ_ == as_device deserialize_device inp as_device typ_ == as_int inp as_int typ_ == as_float inp as_float typ_ == as_bool inp as_bool typ_ == as_string inp as_string typ_ == as_complex complex inp as_complex real inp as_complex imag typ_ == as_sym_int deserialize_sym_argument inp as_sym_int typ_ == as_sym_float deserialize_sym_argument inp as_sym_float typ_ == as_sym_bool deserialize_sym_argument inp as_sym_bool isinstance value list len value == typ_ == as_tensors result = serialized_name_to_node arg name arg value result typ_ as_ints as_floats as_bools as_strings convert serialized python types List python list list value typ_ as_sym_ints as_sym_bools as_sym_floats deserialize_sym_argument arg arg value typ_ == as_optional_tensors deserialize_optional_tensor_args type == as_none None type == as_tensor serialized_name_to_node value name raise SerializeError f Unhandled argument inp list map deserialize_optional_tensor_args value raise SerializeError f Unhandled argument inp typ_ == as_custom_obj inp as_custom_obj name serialized_name_to_node Custom object has been lifted input serialized_name_to_node inp as_custom_obj name constants inp as_custom_obj name typ_ == as_operator deserialize_operator inp as_operator raise SerializeError f Unhandled argument inp deserialize_constant_input inp ConstantValue - Any inp type == as_int int inp as_int inp type == as_float float inp as_float inp type == as_string str inp as_string inp type == as_bool bool inp as_bool inp type == as_none None raise SerializeError f Unhandled constant argument inp deserialize deserialize_sym_argument sym_arg isinstance sym_arg SymIntArgument sym_arg type == as_int sym_arg as_int sym_arg type == as_name serialized_name_to_node sym_arg as_name isinstance sym_arg SymFloatArgument sym_arg type == as_float sym_arg as_float sym_arg type == as_name serialized_name_to_node sym_arg as_name isinstance sym_arg SymBoolArgument sym_arg type == as_bool sym_arg as_bool sym_arg type == as_name serialized_name_to_node sym_arg as_name raise SerializeError f Unknown symbolic argument type sym_arg deserialize_sym_op_outputs serialized_node Node fx_node torch fx Node sync_fx_node serialized_node outputs value as_name fx_node deserialize_outputs serialized_node Node fx_node torch fx Node Check single value len serialized_node outputs == len serialized_node outputs == torch ops higher_order serialized_node target getattr serialized_node is_hop_single_tensor_return True serialized_node outputs type = as_none _deserialize_hop_with_single_return serialized_node fx_node meta_val list Any = arg = None serialized_node outputs type == as_tensor arg = serialized_node outputs as_tensor isinstance serialized_node outputs value SymIntArgument SymBoolArgument SymFloatArgument arg = serialized_node outputs value deserialized_metadata = deserialize_metadata serialized_node metadata assert arg None pyrefly ignore bad-argument-type generate_getitem meta_val fx_node arg deserialized_metadata fx_node meta val = tuple meta_val serialized_name_to_node fx_node name = fx_node _deserialize_hop_with_single_return serialized_node fx_node len serialized_node outputs == serialized_node outputs type == as_tensor sync_fx_node serialized_node outputs as_tensor name fx_node len serialized_node outputs == isinstance serialized_node outputs value SymIntArgument SymBoolArgument SymFloatArgument sync_fx_node serialized_node outputs value as_name fx_node len serialized_node outputs == serialized_node outputs type == as_none manually rename node unused name avoid naming conflicts fx_node meta val = None fx_node _rename f graph _target_to_str fx_node target _unused deserialize_multiple_outputs serialized_node fx_node generate_getitem meta_val fx_node torch fx Node arg Union TensorArgument SymIntArgument SymFloatArgument idx int deserialized_metadata dict str Any isinstance arg TensorArgument name = arg name isinstance arg SymIntArgument name = arg as_name isinstance arg SymFloatArgument name = arg as_name raise AssertionError f generate_getitem got unknown argument type type arg individual_output = graph create_node call_function operator getitem fx_node idx name=name sync_fx_node name individual_output meta_val append serialized_name_to_meta name The derived ` getitem ` nodes should have same stacktrace original ` fx_node ` individual_output meta update deserialized_metadata generate_getitems meta_val fx_node torch fx Node args deserialized_metadata dict str Any idx arg enumerate args isinstance arg TensorArgument SymIntArgument SymFloatArgument generate_getitem meta_val fx_node arg idx deserialized_metadata continue assert isinstance arg Argument arg type as_tensor as_sym_int as_sym_float generate_getitem meta_val fx_node arg value idx deserialized_metadata arg type as_tensors as_sym_ints as_sym_floats as_ints as_floats as_strings as_bools as_sym_bools list_output = graph create_node call_function operator getitem fx_node idx meta_val append generate_getitems meta_val - list_output arg value deserialized_metadata list_output meta update deserialized_metadata list_output meta val = meta_val - arg type == as_none individual_output = graph create_node call_function operator getitem fx_node idx name= as_none meta_val append None individual_output meta val = None individual_output meta update deserialized_metadata raise NotImplementedError f Unimplemented node output type arg deserialize_multiple_outputs serialized_node Node fx_node torch fx Node - None deserialized_metadata = deserialize_metadata serialized_node metadata Convert multiple types FX format In FX each node only returns one value So order represent multiple values we have emit ` getitem ` node each value This performs inverse mapping ` serialize_outputs ` call serialization see NOTE Multiple outputs meta_val list Any = len serialized_node outputs == assert isinstance serialized_node outputs value list assert isinstance serialized_node outputs value TensorArgument generate_getitems meta_val fx_node serialized_node outputs as_tensors deserialized_metadata generate_getitems meta_val fx_node serialized_node outputs deserialized_metadata also update metaval ` fx_node ` list meta fx_node meta val = tuple meta_val serialized_name_to_node fx_node name = fx_node deserialize_metadata metadata dict str str - dict str Any ret dict str Any = stack_trace = metadata get stack_trace ret stack_trace = stack_trace deserialize_meta_func serialized_target str module = None serialized_target startswith torch nn module = torch nn serialized_target_names = serialized_target split serialized_target startswith torch module = torch serialized_target_names = serialized_target split deserialize_operator serialized_target target = module name serialized_target_names hasattr target name serialized_target target = getattr target name target nn_module_stack_str = metadata get nn_module_stack Originally serialized key orig_path type_str import_nn_module_stack key path ty key path ty Helper function split string commas accounting nested parentheses brackets metadata_split metadata out = start n = b = end c enumerate metadata c n += c b n -= c == n == out append metadata start end start = end + out append metadata start assert len out == out nn_module_stack = dict import_nn_module_stack metadata_split item item nn_module_stack_str split ST_DELIMITER ret nn_module_stack = nn_module_stack source_fn_st_str = metadata get source_fn_stack Originally serializes fx_node_name op_str source_fn_st = source_fn_str source_fn_st_str split ST_DELIMITER name target_str = source_fn_str split source_fn_st append name deserialize_meta_func target_str ret source_fn_stack = source_fn_st torch_fn_str = metadata get torch_fn ret torch_fn = tuple torch_fn_str split ST_DELIMITER custom_str = metadata get custom ret custom = json loads custom_str ret deserialize_argument_spec x Argument - ep ArgumentSpec log debug deserialize_argument_spec s x x type == as_tensor ep TensorArgument name=x as_tensor name x type == as_sym_int ep SymIntArgument name=x as_sym_int as_name x type == as_sym_float ep SymFloatArgument name=x as_sym_float as_name x type == as_custom_obj ep ConstantArgument name=x as_custom_obj name value=self deserialize_input x ep ConstantArgument name= value=self deserialize_input x deserialize_module_call_signature module_call_signature ModuleCallSignature - ep ModuleCallSignature ep ModuleCallSignature inputs= deserialize_argument_spec x x module_call_signature inputs outputs= deserialize_argument_spec x x module_call_signature outputs in_spec=treespec_loads module_call_signature in_spec out_spec=treespec_loads module_call_signature out_spec forward_arg_names=names names = module_call_signature forward_arg_names None deserialize_module_call_graph module_call_graph list ModuleCallEntry - list ep ModuleCallEntry log debug \n deserialize_module_call_graph ep ModuleCallEntry fqn=entry fqn signature= deserialize_module_call_signature entry signature entry signature None entry module_call_graph final ExportedProgramDeserializer metaclass=Final __init__ expected_opset_version Optional dict str int = None expected_opset_version dict str int = expected_opset_version expected_opset_version update expected_opset_version aten expected_opset_version expected_opset_version aten = torch _C _get_max_operator_version deserialize_range_constraints symbol_name_to_range dict str symbolic_shapes ValueRanges symbol_name_to_symbol dict str sympy Symbol - dict sympy Symbol ValueRanges log debug \n deserialize_range_constraints range_constraints = k v symbol_name_to_range items symbol = symbol_name_to_symbol get k log debug deserialize_range_constraints s - s k v range_constraints symbol = v type ignore arg-type log warning Symbol s did appear graph deserialized k range_constraints deserialize exported_program ExportedProgram state_dict Union dict str torch Tensor bytes constants Union dict str torch Tensor bytes example_inputs Optional Union tuple tuple torch Tensor dict str Any bytes = None _unsafe_skip_version_check=False - ep ExportedProgram assert isinstance exported_program ExportedProgram version = exported_program schema_version TODO zhxchen blocked thrift schema refactor version major = SCHEMA_VERSION version major == version minor == _unsafe_skip_version_check raise SerializeError f Serialized schema version exported_program schema_version f does match our current schema version SCHEMA_VERSION symbol_name_to_range = k symbolic_shapes ValueRanges _int_to_sympy_int v min_val -int_oo _int_to_sympy_int v max_val int_oo k v exported_program range_constraints items res = GraphModuleDeserializer deserialize exported_program graph_module state_dict constants example_inputs symbol_name_to_range range_constraints = deserialize_range_constraints symbol_name_to_range res names_to_symbols result = ep ExportedProgram root=res graph_module graph=res graph_module graph graph_signature=res signature state_dict=res state_dict type ignore arg-type range_constraints=range_constraints module_call_graph=res module_call_graph example_inputs=res example_inputs constants=res constants verifiers= load_verifier v v exported_program verifiers result _guards_code = exported_program guards_code log debug \n deserialize s result result EnumEncoder json JSONEncoder default obj isinstance obj Enum obj value isinstance obj bytes base b encode obj decode utf- super default obj _dataclass_to_dict obj isinstance obj _Union obj type _dataclass_to_dict obj value dataclasses is_dataclass obj f name _dataclass_to_dict getattr obj f name f dataclasses fields obj isinstance obj list _dataclass_to_dict x x obj isinstance obj tuple tuple _dataclass_to_dict x x obj isinstance obj dict k _dataclass_to_dict v k v obj items isinstance obj float obj == math inf Infinity obj == -math inf -Infinity math isnan obj NaN obj obj _to_json_bytes obj Any - bytes json dumps _dataclass_to_dict obj cls=EnumEncoder allow_nan=False encode utf- serialize exported_program ep ExportedProgram opset_version Optional dict str int = None pickle_protocol int = DEFAULT_PICKLE_PROTOCOL - SerializedArtifact _enable_graph_inputs_of_type_nn_module exported_program example_inputs serialized_program = ExportedProgramSerializer opset_version pickle_protocol serialize exported_program assert isinstance serialized_program exported_program ExportedProgram json_bytes = _to_json_bytes serialized_program exported_program artifact = SerializedArtifact json_bytes serialized_program state_dict serialized_program constants serialized_program example_inputs artifact _dict_to_dataclass cls data assert isinstance cls str f Unresolved type cls typing get_origin cls Annotated _dict_to_dataclass cls __origin__ data typing get_origin cls == typing Union type None typing get_args cls data None None ty_args = typing get_args cls assert len ty_args == _dict_to_dataclass ty_args data isinstance cls type issubclass cls _Union assert isinstance data dict assert len data == _type = next iter data keys _value = next iter data values assert isinstance _type str field_type = cls __annotations__ _type pyrefly ignore missing-attribute cls create _type _dict_to_dataclass field_type _value dataclasses is_dataclass cls fields = type_hints = typing get_type_hints cls For forward compatibility consideration we ignore all keys showing up dataclass definition f dataclasses fields cls name = f name name data continue new_field_obj = _dict_to_dataclass type_hints name data name fields name = new_field_obj cls fields type ignore operator isinstance data list len data == data d_type = typing get_args cls _dict_to_dataclass d_type d d data isinstance data dict v_type = typing get_args cls k _dict_to_dataclass v_type v k v data items cls float float data data _bytes_to_dataclass cls Any artifact_bytes bytes - Any artifact_str = artifact_bytes decode utf- artifact_dict = json loads artifact_str artifact_dataclass = _dict_to_dataclass cls artifact_dict artifact_dataclass deserialize artifact SerializedArtifact expected_opset_version Optional dict str int = None _unsafe_skip_version_check=False - ep ExportedProgram assert isinstance artifact exported_program bytes serialized_exported_program = _bytes_to_dataclass ExportedProgram artifact exported_program ExportedProgramDeserializer expected_opset_version deserialize serialized_exported_program artifact state_dict artifact constants artifact example_inputs _unsafe_skip_version_check=_unsafe_skip_version_check _canonicalize_graph sorted_inputs sorted_outputs graph constants - tuple Graph dict str str _get_argument Argument type == as_none None type == as_tensor as_tensor type == as_tensors as_tensors type == as_int None type == as_ints None type == as_float None type == as_floats None type == as_string None type == as_strings None type == as_complex None type == as_sym_int as_sym_int type == as_sym_ints as_sym_ints type == as_sym_float as_sym_float type == as_sym_floats as_sym_floats type == as_scalar_type None type == as_memory_format None type == as_layout None type == as_device None type == as_bool None type == as_bools None type == as_sym_bool as_sym_bool type == as_sym_bools as_sym_bools type == as_graph None type == as_optional_tensors as_optional_tensors type == as_custom_obj as_custom_obj type == as_operator None raise AssertionError f Unknown input type ExportedProgram Stage Reorder named items for_args f assert isinstance Argument pytree tree_map f _get_argument sort_nodes nodes dataclass Edges outs list int ins int graph_inputs set str = set def_table dict str int = edges dict int Edges = candidates list tuple str list tuple str list int int = rank dict str int = ret list Node = get_name - Optional str None None isinstance TensorArgument name isinstance SymIntArgument SymBoolArgument SymFloatArgument type == as_name as_name type as_int as_bool as_float None raise AssertionError f Unknown argument type isinstance OptionalTensorArgument type == as_tensor as_tensor name type == as_none None raise AssertionError f Unknown optional tensor type isinstance CustomObjArgument name raise AssertionError f Unknown argument type i sorted_inputs add_input s = get_name graph_inputs add s for_args add_input i idx node enumerate nodes add_def s = get_name assert s def_table def_table s = idx o node outputs for_args add_def o edges idx = Edges idx user enumerate nodes add_edge s = get_name s constants s def_table assert s graph_inputs src = def_table s edges src outs append idx edges idx ins += i user inputs for_args add_edge i arg add_rank s = get_name assert s rank rank s = len rank get_rank s = get_name s s constants rank s - i sorted_inputs for_args add_rank i add_candidate idx int get_ranks i ranks = for_args lambda x ranks append get_rank x i ranks node = nodes idx args_rank = name get_ranks arg node inputs heapq heappush candidates node target args_rank idx idx e edges items e ins == add_candidate idx while len candidates _ _ idx = heapq heappop candidates node = nodes idx o node outputs for_args add_rank o ret append node assert idx edges user edges idx outs e = edges user assert e ins e ins -= e ins == add_candidate user edges idx outs clear ret sorted_nodes = sort_nodes graph nodes assert len sorted_nodes == len graph nodes Stage Rename nodes name_table dict str str = rename_def _rename arg_name values new_name = f _ len name_table assert arg_name name_table name_table arg_name = new_name assert arg_name values values new_name = values pop arg_name new_name None isinstance TensorArgument name = _rename name graph tensor_values isinstance SymIntArgument type == as_name as_name = _rename as_name graph sym_int_values isinstance SymFloatArgument type == as_name as_name = _rename as_name graph sym_float_values isinstance SymBoolArgument type == as_name as_name = _rename as_name graph sym_bool_values isinstance CustomObjArgument name = _rename name graph custom_obj_values raise AssertionError f Unknown argument type replace_use None isinstance TensorArgument name = name_table get name name isinstance SymIntArgument SymFloatArgument type == as_name as_name = name_table get as_name as_name isinstance SymBoolArgument type == as_name as_name = name_table get as_name as_name isinstance OptionalTensorArgument type == as_tensor as_tensor name = name_table get as_tensor name as_tensor name isinstance CustomObjArgument name = name_table get name name raise AssertionError f Unknown argument type i sorted_inputs for_args rename_def i n sorted_nodes o n outputs for_args rename_def o n sorted_nodes i n inputs for_args replace_use i arg o sorted_outputs for_args replace_use o Stage Remove unstable fields n sorted_nodes n metadata clear Stage Aggregate values pyrefly ignore no-matching-overload sorted_tensor_values = dict sorted graph tensor_values items key=operator itemgetter pyrefly ignore no-matching-overload sorted_sym_int_values = dict sorted graph sym_int_values items key=operator itemgetter pyrefly ignore no-matching-overload sorted_sym_float_values = dict sorted graph sym_float_values items key=operator itemgetter pyrefly ignore no-matching-overload sorted_sym_bool_values = dict sorted graph sym_bool_values items key=operator itemgetter pyrefly ignore no-matching-overload sorted_custom_obj_values = dict sorted graph custom_obj_values items key=operator itemgetter Stage Recurse subgraphs counter = node sorted_nodes i node inputs = i arg type == as_graph as_graph graph _ = _canonicalize_graph as_graph graph inputs as_graph graph outputs as_graph graph constants as_graph name = f _g counter counter += graph = Graph inputs=sorted_inputs outputs=sorted_outputs nodes=sorted_nodes tensor_values=sorted_tensor_values sym_int_values=sorted_sym_int_values sym_float_values=sorted_sym_float_values sym_bool_values=sorted_sym_bool_values is_single_tensor_return=graph is_single_tensor_return custom_obj_values=sorted_custom_obj_values graph name_table canonicalize ep ExportedProgram constants Optional set str = None - ExportedProgram Normalize serialized ExportedProgram so different eager program which shares same semantics can get single representation disk This function canonicalizes ExportedProgram Sorting nodes topological order Rename nodes have unique names Remove unstable fields Aggregate above program fields Recurse subgraphs Args ep ExportedProgram The ExportedProgram canonicalize constants Optional set str Set constants names Returns ExportedProgram The canonicalized exported program ep = copy deepcopy ep pyrefly ignore annotation-mismatch constants set str = constants set opset_version = dict sorted ep opset_version items key=operator itemgetter range_constraints = dict sorted ep range_constraints items key=operator itemgetter guards_code = sorted ep guards_code module_call_graph = sorted ep graph_module module_call_graph key=lambda x x fqn signature = ep graph_module signature graph = ep graph_module graph assert len graph inputs == len signature input_specs assert len graph outputs == len signature output_specs rank_input inp - tuple int Optional str int idx _arg spec = inp assert isinstance spec InputSpec spec type == user_input None idx spec type == parameter spec parameter parameter_name idx spec type == buffer spec buffer buffer_name idx spec type == tensor_constant spec tensor_constant tensor_constant_name idx spec type == custom_obj spec custom_obj custom_obj_name idx spec type == token None idx spec type == constant_input spec constant_input name idx raise AssertionError f Unknown input type spec rank_output out - tuple int Optional str int idx _arg spec = out assert isinstance spec OutputSpec spec type == user_output None idx spec type == loss_output None idx spec type == parameter_mutation spec parameter_mutation parameter_name idx spec type == buffer_mutation spec buffer_mutation buffer_name idx spec type == gradient_to_parameter spec gradient_to_parameter parameter_name idx spec type == gradient_to_user_input None idx spec type == user_input_mutation None idx spec type == token None idx raise AssertionError f Unknown output type spec sorted_ins = sorted enumerate zip graph inputs signature input_specs key=rank_input len sorted_ins sorted_inputs input_specs = zip i idx i sorted_ins type ignore assignment sorted_inputs = input_specs = sorted_outs = sorted enumerate zip graph outputs signature output_specs key=rank_output sorted_outputs output_specs = zip i idx i sorted_outs type ignore assignment sorted_graph replace_table = _canonicalize_graph sorted_inputs sorted_outputs graph constants replace_input spec assert isinstance spec InputSpec spec type == user_input arg = spec user_input arg arg type == as_tensor t = arg as_tensor t name = replace_table t name arg type == as_sym_int s = arg as_sym_int s type == as_name s as_name = replace_table s as_name s type == as_int pass raise AssertionError f Unknown sym_int type s arg type == as_sym_float f = arg as_sym_float f type == as_name f as_name = replace_table f as_name f type == as_float pass raise AssertionError f Unknown sym_float type f arg type as_none as_bool as_int as_float as_string as_custom_obj raise AssertionError f Unknown input type arg spec type == parameter t = spec parameter arg t name = replace_table t name spec type == buffer t = spec buffer arg t name = replace_table t name spec type == tensor_constant t = spec tensor_constant arg t name = replace_table t name spec type == custom_obj t_custom_obj = spec custom_obj arg t_custom_obj name = replace_table t_custom_obj name spec type == token tok = spec token arg tok name = replace_table tok name spec type == constant_input raise AssertionError f Unknown input type spec replace_output out assert isinstance spec OutputSpec spec type == user_output arg = spec user_output arg arg type == as_tensor t = arg as_tensor t name = replace_table t name arg type == as_sym_int s = arg as_sym_int s type == as_name s as_name = replace_table s as_name s type == as_int pass raise AssertionError f Unknown sym_int type s arg type == as_sym_float f = arg as_sym_float f type == as_name f as_name = replace_table f as_name f type == as_float pass raise AssertionError f Unknown sym_float type f arg type as_none as_bool as_int as_float as_string raise AssertionError f Unknown input type arg spec type == loss_output t = spec loss_output arg t name = replace_table t name spec type == buffer_mutation t = spec buffer_mutation arg t name = replace_table t name spec type == parameter_mutation t = spec parameter_mutation arg t name = replace_table t name spec type == gradient_to_parameter t = spec gradient_to_parameter arg t name = replace_table t name spec type == gradient_to_user_input g = spec gradient_to_user_input g arg name = replace_table g arg name g user_input_name = replace_table g user_input_name spec type == user_input_mutation u = spec user_input_mutation u arg name = replace_table u arg name u user_input_name = replace_table u user_input_name spec type == token tok = spec token arg tok name = replace_table tok name raise AssertionError f Unknown output type spec spec input_specs replace_input spec spec output_specs replace_output spec ExportedProgram graph_module=GraphModule graph=sorted_graph signature=GraphSignature input_specs=list input_specs output_specs=list output_specs module_call_graph=module_call_graph opset_version=opset_version range_constraints=range_constraints schema_version=ep schema_version verifiers=ep verifiers torch_version=ep torch_version guards_code=guards_code ExtensionHandler Base handling extension operators classmethod namespace cls - str raise NotImplementedError f cls __class__ namespace must implemented classmethod to_op_name cls op - str raise NotImplementedError f cls __class__ op_name must implemented classmethod from_op_name cls name str raise NotImplementedError f cls __class__ op_name must implemented classmethod op_schema cls op - torch FunctionSchema raise NotImplementedError f cls __class__ op_schema must implemented register_extension op_type type Any extension_handler type ExtensionHandler Register custom de serialization method node non-standard type assert issubclass extension_handler ExtensionHandler f Expected ExtensionHandler got extension_handler assert op_type _serialization_registry f op_type already registered assert isinstance op_type type Maybe good idea enforce first assert op_type __module__ startswith torch op_type __module__ startswith builtins assert extension_handler namespace _deserialization_registry _serialization_registry op_type = extension_handler _deserialization_registry extension_handler namespace = extension_handler _registered_extension_types tuple _serialization_registry keys Registry store all custom serialization implementations The registry maps operation its serialization function callable their own namespace avoid conflicts Serialization Op type -- custom handler De-serialization Namespace -- custom handler _serialization_registry dict type Any type ExtensionHandler = _deserialization_registry dict str type ExtensionHandler =