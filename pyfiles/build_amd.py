usr bin env python argparse os sys pathlib Path NOTE ` tools amd_build build_amd py ` could symlink The behavior ` symlink ` different ` symlink parent ` Use ` pardir ` three times rather than using ` path parents ` REPO_ROOT = Path __file__ absolute os path pardir os path pardir os path pardir resolve sys path append str REPO_ROOT torch utils hipify hipify_python type ignore parser = argparse ArgumentParser description= Top-level script HIPifying filling most common parameters parser add_argument -- out-of-place-only action= store_true help= Whether only run hipify out-of-place source files parser add_argument -- project-directory type=str default= help= The root project required=False parser add_argument -- output-directory type=str default= help= The directory store hipified project required=False parser add_argument -- extra-include-dir type=str default= nargs= + help= The list extra directories caffe hipify required=False args = parser parse_args NOTE ` tools amd_build build_amd py ` could symlink amd_build_dir = os path dirname os path realpath __file__ proj_dir = os path dirname os path dirname amd_build_dir args project_directory proj_dir = args project_directory out_dir = proj_dir args output_directory out_dir = args output_directory includes = caffe operators caffe sgd caffe image caffe transforms caffe video caffe distributed caffe queue caffe contrib aten binaries caffe _test caffe core caffe db caffe utils caffe contrib gloo caffe contrib nccl c cuda c cuda test CMakeLists txt modules third_party nvfuser PyTorch paths Keep synchronized is_pytorch_file hipify_python py aten src ATen cuda aten src ATen native cuda aten src ATen native cudnn aten src ATen native quantized cudnn aten src ATen native nested cuda aten src ATen native sparse cuda aten src ATen native quantized cuda aten src ATen native transformers cuda attention_backward cu aten src ATen native transformers cuda attention cu aten src ATen native transformers cuda sdp_utils cpp aten src ATen native transformers cuda sdp_utils h aten src ATen native transformers cuda mem_eff_attention debug_utils h aten src ATen native transformers cuda mem_eff_attention gemm_kernel_utils h aten src ATen native transformers cuda mem_eff_attention pytorch_utils h aten src THC aten src ATen test CMakeLists txt isn t processed default there few we do want handle so explicitly specify them aten src THC CMakeLists txt torch tools autograd templates python_variable_methods cpp torch csrc stable includes = os path join proj_dir include include includes new_dir args extra_include_dir abs_new_dir = os path join proj_dir new_dir os path exists abs_new_dir abs_new_dir = os path join abs_new_dir includes append abs_new_dir ignores = caffe operators depthwise_ x _conv_op_cudnn cu caffe operators pool_op_cudnn cu hip These files compatible both cuda hip aten src ATen core Correct path generate HIPConfig h CUDAConfig h - amd_build HIPConfig h - cmake HIPConfig h aten src ATen cuda CUDAConfig h third_party nvfuser csrc codegen cpp third_party nvfuser runtime block_reduction cu third_party nvfuser runtime block_sync_atomic cu third_party nvfuser runtime block_sync_default_rocm cu third_party nvfuser runtime broadcast cu third_party nvfuser runtime grid_reduction cu third_party nvfuser runtime helpers cu torch csrc jit codegen fuser cuda resource_strings h torch csrc jit tensorexpr ir_printer cpp torch csrc jit ir ir h generated files we shouldn t frob torch lib tmp_install torch include ignores = os path join proj_dir ignore ignore ignores Check compiler hip-clang This used useful function now we can safely always assume hip-clang Leaving function here avoids bc-linter errors is_hip_clang - bool True TODO Remove once following submodules updated hip_platform_files = third_party fbgemm fbgemm_gpu CMakeLists txt third_party fbgemm fbgemm_gpu cmake Hip cmake third_party fbgemm fbgemm_gpu codegen embedding_backward_dense_host cpp third_party fbgemm fbgemm_gpu codegen embedding_backward_split_host_template cpp third_party fbgemm fbgemm_gpu codegen embedding_backward_split_template cu third_party fbgemm fbgemm_gpu codegen embedding_forward_quantized_split_lookup cu third_party fbgemm fbgemm_gpu include fbgemm_gpu utils cuda_prelude cuh third_party fbgemm fbgemm_gpu include fbgemm_gpu utils stochastic_rounding cuh third_party fbgemm fbgemm_gpu include fbgemm_gpu utils vec cuh third_party fbgemm fbgemm_gpu include fbgemm_gpu utils weight_row cuh third_party fbgemm fbgemm_gpu include fbgemm_gpu sparse_ops cuh third_party fbgemm fbgemm_gpu src jagged_tensor_ops cu third_party fbgemm fbgemm_gpu src quantize_ops cu third_party fbgemm fbgemm_gpu src sparse_ops cu third_party fbgemm fbgemm_gpu src split_embeddings_cache_cuda cu third_party fbgemm fbgemm_gpu src topology_utils cpp third_party fbgemm src EmbeddingSpMDM cc third_party gloo cmake Dependencies cmake third_party gloo gloo cuda cu third_party kineto libkineto CMakeLists txt third_party nvfuser CMakeLists txt third_party tensorpipe cmake Hip cmake remove_hcc line str - str line = line replace HIP_PLATFORM_HCC HIP_PLATFORM_AMD line = line replace HIP_HCC_FLAGS HIP_CLANG_FLAGS line hip_platform_file hip_platform_files do_write = False os path exists hip_platform_file open hip_platform_file sources lines = sources readlines newlines = remove_hcc line line lines lines == newlines print f hip_platform_file skipped open hip_platform_file w sources line newlines sources write line print f hip_platform_file updated NOTE fbgemm sources needing hipify fbgemm its own project its own build system pytorch uses fbgemm submodule acquire some gpu source files compiles only those sources instead using fbgemm s own build system One source files refers header file result running hipify fbgemm uses slightly different hipify settings than pytorch fbgemm normally hipifies renames tuning_cache cuh tuning_cache_hip cuh pytorch s settings hipify puts into its own hip directory After hipify runs below added fbgemm file we move its expected location NOTE Internal meta builds using buck don t need step so conditionally disable buck_build = os environ get FBCODE_BUILD_TOOL == buck extra_files = torch _inductor codegen cuda device_op_overrides py torch _inductor codegen cpp_wrapper_cpu py torch _inductor codegen cpp_wrapper_gpu py torch _inductor codegen wrapper py fbgemm_dir = REPO_ROOT third_party fbgemm fbgemm_gpu experimental gen_ai src quantize common include fbgemm_gpu quantize buck_build fbgemm_original = fbgemm_dir tuning_cache cuh extra_files append fbgemm_original as_posix hipify_python hipify project_directory=proj_dir output_directory=out_dir includes=includes ignores=ignores extra_files=extra_files out_of_place_only=args out_of_place_only hip_clang_launch=is_hip_clang buck_build fbgemm_move_src = fbgemm_dir hip tuning_cache cuh fbgemm_move_dst = fbgemm_dir tuning_cache_hip cuh only update file changes doesn t exist do_write = True src_lines = None open fbgemm_move_src src src_lines = src readlines os path exists fbgemm_move_dst dst_lines = None open fbgemm_move_dst dst dst_lines = dst readlines src_lines == dst_lines print f fbgemm_move_dst skipped do_write = False do_write open fbgemm_move_dst w dst line src_lines dst write line print f fbgemm_move_dst updated