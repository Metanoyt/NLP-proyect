Owner s oncall jit ruff noqa F gc os sys unittest typing NamedTuple torch torch testing FileCheck torch testing _internal common_cuda TEST_MULTIGPU torch testing _internal common_utils NoTest raise_on_run_directly skipCUDANonDefaultStreamIf TEST_CUDA torch testing _internal jit_utils JitTestCase Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir If GPU available then do run tests TEST_CUDA print CUDA available skipping tests file=sys stderr JitTestCase = NoTest noqa F TEST_LARGE_TENSOR = TEST_CUDA If GPU available then initialize cuda context check there memory available allocate LARGE Tensors TEST_CUDA torch ones cuda initialize cuda context TEST_LARGE_TENSOR = torch cuda get_device_properties total_memory = e TestCUDA JitTestCase A suite tests CUDA API TorchScript tearDown gc collect torch cuda empty_cache super tearDown unittest skipIf TEST_MULTIGPU detected only one GPU test_cuda_synchronize Test device synchronization torch jit script test_device_synchronize prev_current_device_index = torch cuda current_device torch cuda synchronize torch cuda synchronize cuda torch cuda synchronize cuda torch cuda synchronize torch cuda synchronize torch device cuda after_current_device_index = torch cuda current_device Check current device index same device index before synchronizing device prev_current_device_index == after_current_device_index torch jit script test_multi_device_synchronize torch cuda synchronize torch device cuda prev_current_device_index = torch cuda current_device torch cuda synchronize after_current_device_index = torch cuda current_device Check current device index same device index before synchronizing device prev_current_device_index == after_current_device_index assertTrue test_device_synchronize FileCheck check cuda synchronize run test_device_synchronize graph assertTrue test_multi_device_synchronize FileCheck check cuda synchronize run test_multi_device_synchronize graph test_stream_args Test stream creation default arguments torch jit script stream_default_args - bool s = torch cuda Stream s device_index == torch cuda current_device torch jit script stream_default_args_for_device - bool s = torch cuda Stream priority= s device_index == torch cuda current_device torch jit script stream_default_args_for_priority - bool d = torch device cuda s = torch cuda Stream d s device_index == torch jit script stream_args_all - bool d = torch device cuda s = torch cuda Stream d s device_index == assertTrue stream_default_args assertTrue stream_default_args_for_device assertTrue stream_default_args_for_priority assertTrue stream_args_all test_event_args Test Event creation default arguments torch jit script event_default_args - bool e = torch cuda Event e None assertTrue event_default_args unittest skipIf TEST_MULTIGPU detected only one GPU test_current_stream Test current stream device check stream device index matches device ID torch jit script fn device_index = torch cuda current_device device = torch device cuda + str device_index s = torch cuda current_stream device s = torch cuda current_stream torch device cuda s = torch cuda current_stream torch device cuda s device_index s device_index s device_index d d d = fn By default current device ID assertEqual d assertEqual d assertEqual d assertEqual d d Test current_stream API passing device ID argument check stream device index matches device ID torch jit script fn_with_device_index_args device_index = torch cuda current_device s = torch cuda current_stream device_index s = torch cuda current_stream s = torch cuda current_stream s device_index s device_index s device_index d d d = fn_with_device_index_args By default current device ID assertEqual d assertEqual d assertEqual d assertEqual d d unittest skipIf TEST_MULTIGPU detected only one GPU unittest skipIf TEST_LARGE_TENSOR enough memory skipCUDANonDefaultStreamIf True test_streams_and_events Test default_stream API passing device ID argument check stream device index matches device ID torch jit script test_default_streams_with_device_index_args s = torch cuda default_stream s = torch cuda default_stream s device_index s device_index d d = test_default_streams_with_device_index_args assertEqual d assertEqual d This test checks default stream ID set device torch jit script test_default_streams s = torch cuda default_stream torch device cuda s = torch cuda default_stream torch device cuda d = torch device cuda Check current stream id default id same current device The current device id default s = torch cuda current_stream torch device cuda check_s = s id == s id check_d = torch cuda current_device == s device_index Set current device d check stream has been set default stream d torch cuda device d s = torch cuda current_stream d check_s = s id == s id check_d = torch cuda current_device == s device_index Check current device reset is_device_d = torch cuda current_device == s device_index s device_index s device_index check_s check_s check_d check_d is_device_d d d check_s check_s check_d check_d is_device_d = test_default_streams assertEqual d assertEqual d assertTrue check_s assertTrue check_s assertTrue check_d assertTrue check_d assertTrue is_device_d This test checks Stream Context manager no op when stream none ` torch cuda stream ` torch jit script test_set_none_stream device_index = torch cuda current_device device = torch device cuda + str device_index current_stream = torch cuda current_stream device default_stream = torch cuda default_stream device When stream none check operation no-op torch cuda stream None cur_device_index = torch cuda current_device is_device_index_same = cur_device_index == device_index is_current_stream_same = torch cuda current_stream device id == current_stream id is_default_stream_same = torch cuda default_stream device id == default_stream id Check device index current stream default streams have changed are_streams_same = is_device_index_same is_current_stream_same is_default_stream_same are_streams_same assertTrue test_set_none_stream This test checks Device Context manager no op when device none ` torch cuda device ` torch jit script test_set_device_none device_index = torch cuda current_device When device none check operation no-op torch cuda device None Check current device same is_device_same = torch cuda current_device == device_index is_device_same assertTrue test_set_device_none Check CUDA JIT stream created current_device torch jit script test_simple_stream device_index = torch cuda current_device s = torch cuda Stream device_index == s device_index assertTrue test_simple_stream Could create Stream Class used store results test test_get_stream Result NamedTuple t torch Tensor t torch Tensor is_current_and_default_stream_same bool is_default_and_user_stream_not_same bool is_stream_set bool is_stream_reset bool default_stream_query bool default_stream_id int user_stream_id int The test aims checking different stream properties torch jit script test_get_stream device_index = torch cuda current_device device = torch device cuda + str device_index current_stream = torch cuda current_stream device default_stream = torch cuda default_stream device user_stream = torch cuda Stream Check current default streams same device is_current_and_default_stream_same = current_stream id == default_stream id Check user stream default stream same device is_default_and_user_stream_not_same = default_stream id = user_stream id torch cuda stream user_stream is_stream_set = torch cuda current_stream device id == user_stream id Check stream reset current_stream is_stream_reset = torch cuda current_stream device id == current_stream id tensor = torch rand device= cuda tensor = torch mm tensor tensor cuda default_stream synchronize default_stream_query = default_stream query Capture all results Result res = Result tensor tensor is_current_and_default_stream_same is_default_and_user_stream_not_same is_stream_set is_stream_reset default_stream_query default_stream id user_stream id res result = test_get_stream assertEqual torch matmul result t result t result t assertTrue result is_current_and_default_stream_same assertTrue result is_default_and_user_stream_not_same assertTrue result is_stream_set assertTrue result is_stream_reset assertTrue result default_stream_query assertEqual result default_stream_id Check default stream ID always assertNotEqual result user_stream_id Check user stream always non zero Test stream context manager This test checks stream switched user stream using stream context manager torch jit script test_stream_context device_index = torch cuda current_device device = torch device cuda + str device_index current_stream = torch cuda current_stream device user_stream = torch cuda Stream A = torch rand device= cuda torch cuda stream user_stream check = torch cuda current_stream device id == user_stream id B = torch mm A A cuda Wait B computed user_stream synchronize Check stream has been reset current device is_stream_reset = torch cuda current_stream device id == current_stream id A B check is_stream_reset A B is_stream_set is_stream_reset = test_stream_context assertEqual torch matmul A A B assertTrue is_stream_set Error Current stream set user stream assertTrue is_stream_reset Error The stream restored previous stream Test multiple nested streams Check operations computed expected streams This test has been adapted eager mode tests available test test_cuda py torch jit script test_multiple_stream prev_device_index = torch cuda current_device device = torch device cuda + str prev_device_index prev_current_stream = torch cuda current_stream device d = torch device cuda d = torch device cuda s = torch cuda Stream d s = torch cuda Stream d A = torch rand device= cuda B = torch rand device= cuda torch cuda stream s C = torch mm A A cuda Check stream device have been set s is_stream_s = torch cuda current_stream d id == s id is_device_s = torch cuda current_device == s device_index torch cuda stream s Check stream device have been set s is_stream_s = torch cuda current_stream d id == s id is_device_s = torch cuda current_device == s device_index D = torch mm B B cuda Check stream device have been set s is_stream_s _after = torch cuda current_stream d id == s id is_device_s _after = torch cuda current_device == s device_index Wait D computed s synchronize Wait C computed S s synchronize Check stream device has been restored previous stream device is_device_current = torch cuda current_device == prev_device_index is_stream_current = torch cuda current_stream device id == prev_current_stream id check_stream = is_stream_s is_stream_s is_stream_s _after is_stream_current check_device = is_device_s is_device_s is_device_s _after is_device_current A B C D check_stream check_device A B C D check_stream check_device = test_multiple_stream assertEqual torch matmul A A C assertEqual torch matmul B B D assertTrue check_stream assertTrue check_device Test multiple streams waiting each other operations completed torch jit script test_data_dependency_between_streams device_index = torch cuda current_device device = torch device cuda + str device_index prev_current_stream = torch cuda current_stream device d = torch device cuda s = torch cuda Stream d s = torch cuda Stream d event = torch cuda Event False False False A = torch rand device= cuda torch cuda stream s is_stream_s = torch cuda current_stream device id == s id B = torch mm A A cuda s record_event event Check current_stream reset is_current_stream_ = torch cuda current_stream device id == prev_current_stream id Wait ops s computed s wait_event event torch cuda stream s is_stream_s = torch cuda current_stream device id == s id C = torch mm B B cuda Wait C computed s synchronize Check current_stream reset is_current_stream_ = torch cuda current_stream device id == prev_current_stream id check_stream = is_current_stream_ is_current_stream_ is_stream_s is_stream_s A B C check_stream A B C check_stream = test_data_dependency_between_streams assertEqual torch matmul A A B assertEqual torch matmul B B C assertTrue check_stream Test simple CUDA event Test CUDA event created successfully torch jit script test_simple_event e = torch cuda Event True False False e None assertTrue test_simple_event Could create CUDA Event Record CUDA event operation torch mm current stream then test elapsed time greater than This test also adaption eager mode CUDA tests available test test_cuda py torch jit script test_event device_index = torch cuda current_device device = torch device cuda + str device_index stream = torch cuda current_stream device event = torch cuda Event True False False is_true_event_query = event query start_event = torch cuda Event True False False stream record_event start_event tensor = torch rand device= cuda tensor = torch mm tensor tensor cuda stream record_event event event synchronize is_again_true_event_query = event query is_true_event_query is_again_true_event_query - start_event elapsed_time event assertGreater test_event Check stream synchronization when large tensor multiplication computed stream The stream query should true once synchronization done torch jit script test_stream_synchronize - float device_index = torch cuda current_device s = torch cuda Stream e_tik = torch cuda Event True False False e_tok = torch cuda Event True False False e_tik record s tensor = torch rand device= cuda torch cuda stream s tensor = torch mm tensor tensor cuda s synchronize e_tok record s e_tok synchronize s query - necessary check e_tik e_tok elapsed_time would throw exception otherwise e_tik elapsed_time e_tok assertGreater test_stream_synchronize Test event synchronization event records stream doing large tensor multiplication Check elapsed time greater than stream query evaluates true torch jit script test_event_synchronize - float s = torch cuda Stream e_tik = torch cuda Event True False False e_tok = torch cuda Event True False False e_tik record s tensor = torch rand device= cuda torch cuda stream s tensor = torch mm tensor tensor cuda s record_event e_tok e_tok synchronize s synchronize s query - necessary check e_tik e_tok elapsed_time would throw exception otherwise e_tik elapsed_time e_tok assertGreater test_event_synchronize Test event wait Check event waits all operations stream done Check synchronizations query streams events This test adapted eager mode tests CUDA Please refer test test_cuda py torch jit script test_event_wait - float device_index = torch cuda current_device device = torch device cuda + str device_index s = torch cuda current_stream device s = torch cuda Stream e_tik = torch cuda Event True True False e_tok = torch cuda Event True True False e_tik record s tensor = torch rand device= cuda torch cuda stream s tensor = torch mm tensor tensor cuda e_sync = torch cuda Event True False False e_sync record torch cuda current_stream device e_sync wait s torch cuda stream s tensor = torch rand device= cuda tensor = torch mm tensor tensor cuda s synchronize e_tok record torch cuda current_stream device e_tok synchronize s synchronize s query s query e_sync query - necessary check e_tik e_tok elapsed_time would throw exception otherwise e_tik elapsed_time e_tok assertGreater test_event_wait Test stream wait_event Checks stream waits event torch jit script test_wait_event d = torch device cuda torch cuda device d s = torch cuda current_stream d tensor = torch rand device= cuda tensor = torch mm tensor tensor cuda e = torch cuda Event False False False s record_event e s = torch cuda current_stream torch device cuda s wait_event e s synchronize e query s query s query assertTrue test_wait_event Test scripted module cuda streams can saved loaded executed test_save_load Model torch nn Module forward s = torch cuda Stream = torch rand device= cuda b = torch rand device= cuda torch cuda stream s is_stream_s = torch cuda current_stream s device id == s id c = torch cat b cuda s synchronize is_stream_s b c model = Model Script model save script_model = torch jit script model is_stream_s b c = script_model Verify output correct assertTrue is_stream_s assertEqual torch cat b c Save load scripted model load_model = getExportImportCopy script_model is_stream_s a_load b_load c_load = load_model assertTrue is_stream_s assertEqual torch cat a_load b_load c_load Make sure cuda _exchange_device doesn t get DCE ed unittest skipIf TEST_CUDA Cuda available test__exchange_device_op fn device int tensor torch cuda _exchange_device device tensor cos relu fn_s = torch jit script fn Just check graph don t run Otherwise we d need run test multi-gpu CI runner which overkill g = fn_s graph FileCheck check cuda _exchange_device run g torch _C _jit_pass_inline g FileCheck check cuda _exchange_device run g Make sure cuda _maybe_exchange_device doesn t get DCE ed unittest skipIf TEST_CUDA Cuda available test__maybe_exchange_device_op fn device int tensor torch cuda _maybe_exchange_device device tensor cos relu fn_s = torch jit script fn Just check graph don t run Otherwise we d need run test multi-gpu CI runner which overkill g = fn_s graph FileCheck check cuda _maybe_exchange_device run g torch _C _jit_pass_inline g FileCheck check cuda _maybe_exchange_device run g __name__ == __main__ raise_on_run_directly test test_jit py