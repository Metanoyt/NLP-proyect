Owner s module dynamo module higher order operators dataclasses dataclass torch torch _dynamo test_case torch utils _pytree pytree torch _dynamo testing AotEagerAndRecordGraphs EagerAndRecordGraphs normalize_gm torch _higher_order_ops flat_apply flat_apply func_to_graphable is_graphable to_graphable distance b norm norm typ == l torch sqrt x - b x pow + y - b y pow norm typ == l x - b x abs + y - b y abs dataclass frozen=True Norm typ str pytree register_constant Norm dataclass Point x torch Tensor y torch Tensor pytree register_dataclass Point FlatApplyTests torch _dynamo test_case TestCase test_simple tensor = torch tensor = Point tensor tensor b = Point tensor tensor norm = Norm l args = b kwargs = norm norm empty_list func_spec = func_to_graphable distance assertEqual empty_list flat_args in_spec = to_graphable args kwargs arg flat_args assertTrue is_graphable arg Test flat_apply returns same thing original function result = flat_apply func_spec in_spec flat_args assertEqual result distance args kwargs test_non_tensor_output tensor = torch tensor = Point tensor tensor b = Point tensor tensor args = b kwargs = f b x + b x + y + + b y empty_list func_spec = func_to_graphable f assertEqual empty_list flat_args in_spec = to_graphable args kwargs arg flat_args assertTrue is_graphable arg Test flat_apply returns same thing original function result = flat_apply func_spec in_spec flat_args assertEqual result f args kwargs test_nonstrict_trace_dynamo_graph Point x torch Tensor y torch Tensor __init__ x y x = x y = y PointTensor p Point t torch Tensor __init__ p t p = p t = t torch utils _pytree register_pytree_node PointTensor lambda pt pt p pt t lambda pt _ PointTensor pt pt torch utils _pytree register_pytree_node Point lambda p p x p y lambda xy _ Point xy xy trace_point p torch _dynamo graph_break p x p y torch _dynamo nonstrict_trace trace_point_tensor pt torch _dynamo graph_break pt t + trace_point pt p backend = EagerAndRecordGraphs torch compile fullgraph=True backend=backend fn x y p = Point x y t = x + y pt = PointTensor p t res = trace_point_tensor pt res fn torch randn torch randn assertExpectedInline normalize_gm backend graphs print_readable print_output=False \ GraphModule torch nn Module forward L_x_ f L_y_ f l_x_ = L_x_ l_y_ = L_y_ t f = l_x_ + l_y_ trace_point_tensor_spec torch utils _pytree TreeSpec = trace_point_tensor_spec trace_point_tensor_input_spec torch utils _pytree TreeSpec = trace_point_tensor_input_spec res f = torch ops higher_order flat_apply trace_point_tensor_spec trace_point_tensor_input_spec l_x_ l_y_ t trace_point_tensor_spec = trace_point_tensor_input_spec = l_x_ = l_y_ = t = None res NOQA B test_nonstrict_trace_captured_tensor_post_aot_graph cst = torch ones torch _dynamo nonstrict_trace trace_me x y torch _dynamo graph_break x y + cst backend = AotEagerAndRecordGraphs torch compile fullgraph=True backend=backend fn x y trace_me x y fn torch randn torch randn assertExpectedInline normalize_gm backend fw_graphs print_readable print_output=False \ lambda torch nn Module forward arg _ f arg _ f mul f = torch ops aten mul Tensor arg _ arg _ arg _ = arg _ = None _tensor_constant f = _tensor_constant add f = torch ops aten add Tensor mul _tensor_constant mul = _tensor_constant = None add NOQA B __name__ == __main__ torch _dynamo test_case run_tests run_tests