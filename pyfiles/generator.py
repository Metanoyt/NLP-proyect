__future__ annotations json logging math typing TYPE_CHECKING torchgen api cpp cpp torchgen context native_function_manager torchgen model Argument BackendIndex BaseTy BaseType FunctionSchema NativeFunctionsGroup NativeFunctionsViewGroup OptionalType SelfArgument TensorOptionsArguments Type torchgen static_runtime config TYPE_CHECKING collections abc Sequence logger logging Logger = logging getLogger has_alias arguments Sequence Argument &#124; SelfArgument &#124; TensorOptionsArguments - bool arg arguments annotation = getattr arg annotation None annotation continue alias_set = getattr annotation alias_set alias_set True False BLOCKED_OPS = frozenset non cpu ops sparse_sampled_addmm hspmm linalg_svdvals sparse ops sspaddmm coalesce _indices indices _values values crow_indices col_indices deprecated ops floor_divide ger buggy ops conj_physical P binary_cross_entropy P arccosh uncommon ops cholesky lu_solve linalg_cholesky linalg_householder_product linalg_ldl_solve _compute_linear_combination training related ops _make_dual cannot call directly _fw_primal no documentation _index_reduce TODO these ones got added recently need manual inspection _new_zeros_with_same_feature_meta _conj_physical binary_cross_entropy_with_logits bincount conv_tbc copy _copy_from _copy_from_and_resize count_nonzero cudnn_affine_grid_generator cudnn_affine_grid_generator_backward cudnn_grid_sampler diag_embed embedding embedding_dense_backward _embedding_bag_dense_backward _embedding_bag_per_sample_weights_backward grid_sampler_ d _grid_sampler_ d_cpu_fallback grid_sampler_ d isnan mkldnn_linear median nanmedian _sparse_sparse_matmul batch_norm_backward_elemt _euclidean_dist pixel_shuffle pixel_unshuffle channel_shuffle _reshape_nested_backward relu prelu celu slice_scatter select_scatter diagonal_scatter sum _mkldnn_transpose _nested_tensor_from_mask _nested_from_padded _nested_tensor_size _nested_from_padded_and_nested_example _standard_gamma_grad _dirichlet_grad native_norm _sparse_softmax _sparse_softmax_backward_data _sparse_log_softmax _sparse_log_softmax_backward_data zero _sparse_addmm sparse_mask _sparse_mask_projection _to_dense _coalesce _coalesced copy_sparse_to_sparse to_sparse to_sparse_csr to_sparse_csc to_mkldnn quantize_per_tensor_dynamic quantize_per_channel q_per_channel_scales q_per_channel_zero_points int_repr _make_per_channel_quantized_tensor set lift lift_fresh lift_fresh_copy masked_scatter _masked_softmax _masked_softmax_backward put index_reduce trace _cholesky_solve_helper dist max _torch_cuda_cu_linker_symbol_op glu_jvp glu_backward_jvp hardswish_backward rrelu_with_noise_backward mkldnn_adaptive_avg_pool d_backward _adaptive_avg_pool d_backward _adaptive_avg_pool d_backward isinf linalg_lu_solve linalg_vecdot linalg_matrix_exp linalg_eigvalsh _test_warn_in_autograd _test_autograd_multiple_dispatch_view _test_autograd_multiple_dispatch_view_copy _segment_reduce _segment_reduce_backward _fw_primal_copy _make_dual_copy view_as_real_copy view_as_complex_copy _conj_copy _neg_view_copy diagonal_copy detach_copy squeeze_copy t_copy unsqueeze_copy _indices_copy _values_copy indices_copy values_copy crow_indices_copy col_indices_copy ccol_indices ccol_indices_copy row_indices row_indices_copy unfold_copy alias_copy _triton_multi_head_attention special_airy_ai special_bessel_j special_bessel_j special_bessel_y special_bessel_y special_chebyshev_polynomial_t special_chebyshev_polynomial_u special_chebyshev_polynomial_v special_chebyshev_polynomial_w special_hermite_polynomial_h special_hermite_polynomial_he special_laguerre_polynomial_l special_legendre_polynomial_p special_modified_bessel_i special_modified_bessel_i special_modified_bessel_k special_modified_bessel_k special_scaled_modified_bessel_k special_scaled_modified_bessel_k special_shifted_chebyshev_polynomial_t special_shifted_chebyshev_polynomial_u special_shifted_chebyshev_polynomial_v special_shifted_chebyshev_polynomial_w special_spherical_bessel_j _foobar _nested_tensor_strides _nested_tensor_storage_offsets _nested_get_values no CPU backend _nested_get_values_copy no CPU backend _nested_view_from_jagged testing needs patched _nested_view_from_jagged_copy testing needs patched _nested_view_from_buffer testing needs patched _nested_view_from_buffer_copy testing needs patched _int_mm testing needs patched _to_sparse_csc testing needs patched _to_sparse_csr testing needs patched segment_reduce testing needs patched is_supported g NativeFunctionsGroup &#124; NativeFunctionsViewGroup - bool base_op_name = func = None isinstance g NativeFunctionsViewGroup base_op_name = g view root_name func = g view func base_op_name = g out func name name base func = g out func config is_hand_written g logger info HAND WRITTEN s base_op_name False base_op_name BLOCKED_OPS logger info BLOCKED s base_op_name False arg func schema_order_arguments maybe_method = ivalue_type_conversion_method arg type maybe_method Type converting unsupported yet logger info NOT SUPPORTED TYPE CONVERTING s func False isinstance g NativeFunctionsViewGroup TODO stop doing type tests converting C++ then testing string just test dang thing directly Tensor = cpp returns_type func returns symint=False cpp_type Returns non-Tensor value logger info NON-TENSOR RET TYPE s str func False True For out variant ops we need check arguments its functional func arg g functional func schema_order_arguments maybe_method = ivalue_type_conversion_method arg type maybe_method Type converting unsupported yet logger info NOT SUPPORTED TYPE CONVERTING s g functional func False g structured In case unstructured op we check has out variant implementation The out variant implementation satisfies minimum requirement has output tensor last parameter hasattr g out str func endswith Tensor out - Tensor str func name endswith out False TODO stop type testing converting C++ Tensor = cpp returns_type func returns symint=False cpp_type logger info NON_TENSOR RET TYPE s func False has_alias func arguments non_out This op may create alias inputs logger info INPUTS ALIAS s base_op_name False True ivalue_type_conversion_method arg_type BaseType &#124; OptionalType &#124; Type - tuple bool str &#124; None Return method call expression ` c ivalue convert its contained value expected value ` arg_type ` type For example ` arg_type ` == BaseTy Tensor function returns toTensor so can appended ivalue s variable name get value expected type type_conversion_methods = BaseTy Tensor True toTensor False toOptional Tensor BaseTy int False toInt False toOptional int _t BaseTy bool False toBool False toOptional bool BaseTy Scalar False toScalar False toOptional Scalar BaseTy ScalarType False toScalarType False toOptional ScalarType BaseTy str False toStringView False toOptional c string_view False toOptional std string_view base_ty_object = None isinstance arg_type BaseType base_ty_object = arg_type name isinstance arg_type OptionalType isinstance arg_type elem BaseType ListType currently unsupported None base_ty_object = arg_type elem name None base_ty_object type_conversion_methods None methods = type_conversion_methods base_ty_object isinstance arg_type BaseType methods methods should_use_int_tensor_ops_ = frozenset bitwise_not bitwise_and bitwise_or bitwise_xor bitwise_left_shift bitwise_right_shift gcd lcm scatter gather _convert_indices_from_coo_to_csr _convert_indices_from_csr_to_coo should_use_complex_tensor_ops_ = frozenset view_as_real imag _conj should_use_int_tensor op_name str - bool op_name should_use_int_tensor_ops_ should_use_complex_tensor op_name str - bool op_name should_use_complex_tensor_ops_ test_tensor_dim_ops_ _ = frozenset addmv index_add _convert_indices_from_coo_to_csr _convert_indices_from_csr_to_coo nll_loss_backward dot vdot outer ger test_tensor_dim_ops_ _ = frozenset addmm mm nuclear_norm diag _addmm_activation matrix_H t test_tensor_dim op_name str - int op_name test_tensor_dim_ops_ _ op_name test_tensor_dim_ops_ _ test_tensor_shapes_string = view_as_complex test_tensor_shape_json dict str str = json loads test_tensor_shapes_string test_tensor_shape op_name str - str op_name test_tensor_shape_json test_tensor_shape_json op_name test_value_expression arg_type BaseType &#124; OptionalType &#124; Type index int op_name str - str tensor_size_ex = test_tensor_shape op_name tensor_size_ex == num_tensors = index == num_dim = test_tensor_dim op_name size_per_dim = math ceil num_tensors float num_dim size_per_dim += size_per_dim tensor_size_ex = format join f size_per_dim num_dim should_use_int_tensor op_name tensor_expression = f randint tensor_size_ex kInt should_use_complex_tensor op_name tensor_expression = f randn tensor_size_ex kComplexFloat tensor_expression = f rand tensor_size_ex value_expressions = BaseTy Tensor tensor_expression BaseTy int BaseTy bool false BaseTy Scalar BaseTy ScalarType ScalarType Float BaseTy str floor base_ty_object = None isinstance arg_type BaseType base_ty_object = arg_type name assert isinstance arg_type OptionalType isinstance arg_type elem BaseType base_ty_object = arg_type elem name assert base_ty_object value_expressions expected type value_expression = value_expressions base_ty_object value_expression generate_test_value_definitions schema FunctionSchema index int - str assert schema is_out_fn schema_name = schema name name base arg_map = arg schema schema_order_arguments test_value_exp = test_value_expression arg type index schema_name arg_map arg name = test_value_exp config override_test_values arg_map schema_name index arg_populations = arg_name arg_value arg_map items arg_populations append f auto arg_name index = arg_value \n join arg_populations + generate_test_value_names schema FunctionSchema index int - str assert schema is_out_fn join f arg name index arg schema schema_order_arguments generate_test_ir_arguments_base_ty_to_type_str_ = BaseTy Tensor Tensor BaseTy int int BaseTy float float BaseTy str str BaseTy Scalar int BaseTy ScalarType int BaseTy bool bool generate_test_ir_arguments schema FunctionSchema - list tuple str str &#124; None ir_argument arg Argument - tuple str str &#124; None t = arg type add_optional = False isinstance t OptionalType t = t elem add_optional = True assert isinstance t BaseType type_str = None t name generate_test_ir_arguments_base_ty_to_type_str_ type_str = generate_test_ir_arguments_base_ty_to_type_str_ t name type_str add_optional type_str = f type_str + arg name type_str ir_argument arg arg schema schema_order_arguments generate_arg_extraction schema FunctionSchema - str arg_populations = i arg enumerate schema schema_order_arguments maybe_method = ivalue_type_conversion_method arg type assert maybe_method is_reference type_conversion_method = maybe_method reference = is_reference arg_populations append f const auto reference arg name = p_node- Input i type_conversion_method \n join arg_populations + get_kernel_name g NativeFunctionsGroup backend_index BackendIndex - str kernel = backend_index get_kernel g functional g structured kernel None cpp name g functional func kernel kernel get_out_kernel_name g NativeFunctionsGroup backend_index BackendIndex - str kernel = backend_index get_kernel g out g structured kernel None cpp name g out func kernel kernel generate_non_out_variant_call g NativeFunctionsGroup backend_index BackendIndex - str schema = g functional func assert schema is_out_fn kernel_name = get_kernel_name g backend_index arg_names = arg name arg schema schema_order_arguments namespace_name = cpu g structured native f namespace_name kernel_name join arg_names generate_call_to_view_ops g NativeFunctionsViewGroup backend_index BackendIndex - str schema = g view func kernel_name = cpp name schema kernel = backend_index get_kernel g view kernel kernel_name = kernel kernel arg_names = arg name arg schema schema_order_arguments namespace_name = native f namespace_name kernel_name join arg_names generate_out_variant_call g NativeFunctionsGroup backend_index BackendIndex - str schema = g out func assert schema is_out_fn arg_names = kernel_name = get_out_kernel_name g backend_index g structured structured op starts output tensor argument arg_names = out_arg name out_arg schema arguments out arg_names = arg schema arguments non_out isinstance arg SelfArgument arg_names append arg argument name assert isinstance arg Argument arg_names append arg name g structured assert len schema arguments out == arg_names append schema arguments out name cpp_arg_names = join arg_names namespace_name = cpu g structured native f namespace_name kernel_name cpp_arg_names no_memory_resize_ops = frozenset isin Scalar_Tensor index_add dot vdot nuclear_norm histc l _loss multi_margin_loss multilabel_margin_loss nll_loss nll_loss d prod should_check_resize schema FunctionSchema - bool schema_str = str schema type_variant_op_name = schema_str schema_str find type_variant_op_name no_memory_resize_ops op_name_from_group g NativeFunctionsGroup - str g functional func name name base GenOpDispatcher out_variant groups Sequence NativeFunctionsGroup backend_index BackendIndex - str groups generated_type_variants = g groups native_function_manager g assert is_supported g assert isinstance g NativeFunctionsGroup generated_type_variant = out_variant_op_generator g backend_index generated_type_variants append generated_type_variant op_name = op_name_from_group groups body = \n join generated_type_variants generated = f REGISTER_OPERATOR_FUNCTOR aten op_name aten_ op_name Node n - SROperator body LogAndDumpSchema n nullptr generated view groups Sequence NativeFunctionsViewGroup backend_index BackendIndex - str groups generated_type_variants = g groups native_function_manager g assert is_supported g assert isinstance g NativeFunctionsViewGroup generated_type_variant = view_op_generator g backend_index generated_type_variants append generated_type_variant op_name = config func_name_base_str groups body = \n join generated_type_variants generated = f REGISTER_NATIVE_OPERATOR_FUNCTOR aten op_name aten_ op_name Node n - SROperator body LogAndDumpSchema n nullptr generated out_variant_op_generator g NativeFunctionsGroup backend_index BackendIndex - str functional = g functional schema = str functional func populated_argument = generate_arg_extraction g functional func functional_variant_call = generate_non_out_variant_call g backend_index assert len g out func arguments out == out_variable_name = str g out func arguments out name out_variant_call = generate_out_variant_call g backend_index generated = f n- matches torch schema aten schema ProcessedNode p_node populated_argument p_node- Output isNone p_node- Output = functional_variant_call auto out_variable_name = p_node- Output toTensor fastResizeToZero out_variable_name out_variant_call generated view_op_generator g NativeFunctionsViewGroup backend_index BackendIndex - str schema = str g view func populated_argument = generate_arg_extraction g view func functional_variant_call = generate_call_to_view_ops g backend_index generated = f n- matches torch schema aten schema ProcessedNode p_node populated_argument p_node- Output = functional_variant_call generated GenOpTestCase out_variant groups Sequence NativeFunctionsGroup - str groups generated_type_variants = g groups native_function_manager g assert is_supported g assert isinstance g NativeFunctionsGroup generated_type_variant = out_variant_op_test_case_generator g generated_type_variants append generated_type_variant \n join generated_type_variants view groups Sequence NativeFunctionsViewGroup - str groups generated_type_variants = g groups native_function_manager g assert is_supported g assert isinstance g NativeFunctionsViewGroup generated_type_variant = view_op_test_case_generator g generated_type_variants append generated_type_variant \n join generated_type_variants out_variant_op_test_case_generator g NativeFunctionsGroup - str schema = g functional func schema_str = str schema assert schema_str find type_variant_op_name = schema_str schema_str find replace _ op_name = op_name_from_group g assert type_variant_op_name startswith op_name arg_types = generate_test_ir_arguments schema arg_declarations = join arg_name arg_type None f arg_name arg_type arg_name arg_type arg_types arg_names = join arg_name arg_name _ arg_types assert len schema returns == isinstance schema returns type BaseType schema returns type name BaseTy Tensor test_value_definitions = generate_test_value_definitions schema test_value_names = generate_test_value_names schema test_value_definitions = generate_test_value_definitions schema test_value_names = generate_test_value_names schema check_resize = true should_check_resize schema false generated = f TEST StaticRuntime autogen_ type_variant_op_name const std string script = R IR graph arg_declarations bias None = prim Constant ret = aten op_name arg_names cloned = aten clone ret bias cloned IR test_value_definitions std vector IValue args test_value_names testStaticRuntime script args use_allclose= false use_equalnan= false check_resize= check_resize test_value_definitions std vector IValue args test_value_names testStaticRuntime script args args use_allclose= false use_equalnan= false check_resize= check_resize generated view_op_test_case_generator g NativeFunctionsViewGroup - str schema = g view func schema_str = str schema assert schema_str find type_variant_op_name = schema_str schema_str find replace _ op_name = g view root_name assert type_variant_op_name startswith op_name arg_types = generate_test_ir_arguments schema arg_declarations = join arg_name arg_type None f arg_name arg_type arg_name arg_type arg_types arg_names = join arg_name arg_name _ arg_types assert len schema returns == isinstance schema returns type BaseType schema returns type name BaseTy Tensor test_value_definitions = generate_test_value_definitions schema test_value_names = generate_test_value_names schema generated = f TEST StaticRuntime autogen_ type_variant_op_name const std string script = R IR graph arg_declarations bias None = prim Constant ret = aten op_name arg_names cloned = aten clone ret bias cloned IR test_value_definitions std vector IValue args test_value_names testStaticRuntime script args generated