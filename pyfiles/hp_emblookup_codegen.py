mypy allow-untyped-defs argparse sys sizeof = float Half BFloat uint _t unroll uf IndexType InType OutType use_weights isa fused use_offsets compute regid InType use_weights isa prefetch code = InType == float code append f vop regid d = _mm _fmadd_ps vwgt _mm _loadu_ps ip + regid d vop regid d InType == Half code append f vop regid d = _mm _fmadd_ps \n vwgt \n _mm _cvtph_ps \n f _mm_loadu_si reinterpret_cast const __m i ip + regid d \n f vop regid d InType == BFloat code append f vop regid d = _mm _fmadd_ps \n vwgt \n _mm _castsi _ps _mm _slli_epi \n _mm _cvtepu _epi _mm_loadu_si \n f reinterpret_cast const __m i ip + regid d \n \n f vop regid d InType == uint _t code append f vop regid d = _mm _fmadd_ps \n vwgt \n _mm _cvtepi _ps _mm _cvtepu _epi \n f _mm_loadl_epi reinterpret_cast const __m i ip + regid d \n f _mm _add_ps vop regid d vbio raise AssertionError prefetch code append _mm_prefetch \n f reinterpret_cast const char ip_next_T regid d _MM_HINT_T code append f skip unnecessary prefetch ip_next_T regid d code code = code append unrolling + str uf + times use_offsets code append + IndexType + rangeIndex = rangeIndex output_size ++rangeIndex code append + IndexType + rangeIndex = rangeIndex output_size ++rangeIndex code append + OutType + op = out rangeIndex block_size i range uf j = i code append __m vop + str j + = _mm _setzero_ps inner loop use_offsets code append dataInd = offsets rangeIndex - offsets \n + false \n + code append \ int _t end_offset = offsets rangeIndex + int _t length = end_offset - offsets rangeIndex code append + int _t + start = dataInd dataInd end_offset - offsets \n ++dataInd code append dataInd + lengths rangeIndex index_size \n + false \n + code append + IndexType + start = dataInd dataInd start + lengths rangeIndex \n ++dataInd code append const + IndexType + idx = indices dataInd code append idx &#124; &#124; idx = data_size \n + false \n + InType == uint _t code append + OutType + wgt = f code append weights code append wgt = weights IS_WEIGHT_POSITIONAL dataInd - start dataInd code append fused code append const float scale_bias = reinterpret_cast const float \n input idx fused_block_size + block_size code append + OutType + bio = wgt scale_bias code append wgt = wgt scale_bias code append bio = wgt scale_bias idx + code append wgt = wgt scale_bias idx code append __m vbio = _mm _set _ps bio code append + OutType + wgt = f code append weights code append wgt = weights IS_WEIGHT_POSITIONAL dataInd - start dataInd code append code append __m vwgt = _mm _set _ps wgt code append f const InType ip = input idx fused_block_size code append f const IndexType next_T = dataInd index_size - prefdist_T \n NOLINTNEXTLINE cppcoreguidelines-narrowing-conversions bugprone-narrowing-conversions \n dataInd + prefdist_T \n NOLINTNEXTLINE cppcoreguidelines-narrowing-conversions bugprone-narrowing-conversions \n dataInd code append const + IndexType + idx_pref_T = indices next_T code append idx_pref_T &#124; &#124; idx_pref_T = data_size \n + false \n + code append f const InType ip_next_T = input idx_pref_T fused_block_size i range uf j = i cachelinesize = byteoffset = sizeof InType j prefetch = byteoffset cachelinesize == code extend compute j InType use_weights isa prefetch code append use_offsets code append normalize_by_lengths &#124; &#124; length == code append normalize_by_lengths &#124; &#124; lengths rangeIndex == i range uf j = i code append _mm _storeu_ps op + str j + vop + str j + code append inv length use_offsets code append __m vlen_inv = _mm _set _ps f length code append __m vlen_inv = _mm _set _ps f lengths rangeIndex i range uf j = i code append _mm _storeu_ps op + str j + _mm _mul_ps + vop + str j + vlen_inv code append code append code generic IndexType InType OutType use_weights isa fused use_offsets compute InType use_weights isa code = InType == float code append _mm _storeu_ps \n op j \n _mm _fmadd_ps \n vwgt _mm _loadu_ps ip j _mm _loadu_ps op j InType == Half code append _mm _storeu_ps \n op j \n _mm _fmadd_ps \n vwgt \n _mm _cvtph_ps _mm_loadu_si \n reinterpret_cast const __m i ip j \n _mm _loadu_ps op j InType == BFloat code append _mm _storeu_ps \n op j \n _mm _fmadd_ps \n vwgt \n _mm _castsi _ps _mm _slli_epi \n _mm _cvtepu _epi _mm_loadu_si \n reinterpret_cast const __m i ip j \n \n _mm _loadu_ps op j InType == uint _t code append _mm _storeu_ps \n op j \n _mm _fmadd_ps \n vwgt \n _mm _cvtepi _ps _mm _cvtepu _epi _mm_loadl_epi \n reinterpret_cast const __m i ip j \n _mm _add_ps _mm _loadu_ps op j vbio raise AssertionError code append _mm_prefetch \n reinterpret_cast const char ip_next_T j _MM_HINT_T code code = InType == Half code append alignas Half vtmp = InType == BFloat code append alignas BFloat vtmp = use_offsets code append + IndexType + rangeIndex = rangeIndex output_size ++rangeIndex code append + IndexType + rangeIndex = rangeIndex output_size ++rangeIndex code append + OutType + op = out rangeIndex block_size initialize code append int _t j = code append j + = block_size j += code append _mm _storeu_ps op + j _mm _setzero_ps code append code append j block_size j++ code append op j = f code append inner loop use_offsets code append dataInd = offsets rangeIndex - offsets \n + false \n + code append \ int _t end_offset = offsets rangeIndex + int _t length = end_offset - offsets rangeIndex code append + int _t + start = dataInd dataInd end_offset - offsets \n ++dataInd code append dataInd + lengths rangeIndex index_size \n + false \n + code append + IndexType + start = dataInd dataInd start + lengths rangeIndex \n ++dataInd code append const + IndexType + idx = indices dataInd code append idx &#124; &#124; idx = data_size \n + false \n + InType == uint _t code append + OutType + wgt = f code append weights code append wgt = weights IS_WEIGHT_POSITIONAL dataInd - start dataInd code append fused code append const float scale_bias = reinterpret_cast const float \n input idx fused_block_size + block_size code append + OutType + bio = wgt scale_bias code append wgt = wgt scale_bias code append + OutType + bio = wgt scale_bias idx + code append wgt = wgt scale_bias idx code append __m vbio = _mm _set _ps bio code append + OutType + wgt = f code append weights code append wgt = weights IS_WEIGHT_POSITIONAL dataInd - start dataInd code append code append __m vwgt = _mm _set _ps wgt code append f const InType ip = input idx fused_block_size code append f const IndexType next_T = dataInd index_size - prefdist_T \n NOLINTNEXTLINE cppcoreguidelines-narrowing-conversions bugprone-narrowing-conversions \n dataInd + prefdist_T \n NOLINTNEXTLINE cppcoreguidelines-narrowing-conversions bugprone-narrowing-conversions \n dataInd code append const + IndexType + idx_pref_T = indices next_T code append idx_pref_T &#124; &#124; idx_pref_T = data_size \n + false \n + code append f const InType ip_next_T = input idx_pref_T fused_block_size compute store main loop code append j = code append j + = block_size j += code extend compute InType use_weights isa code append leftover code append j block_size j++ InType == float code append op j = std fma wgt ip j op j InType == Half code append vtmp = ip j code append __m vtmp =\n _mm _cvtph_ps reinterpret_cast const __m i vtmp code append op j = std fma wgt float vtmp op j InType == BFloat code append vtmp = ip j code append __m vtmp = _mm _castsi _ps _mm _slli_epi \n _mm _cvtepu _epi reinterpret_cast const __m i vtmp \n code append op j = std fma wgt float vtmp op j InType == uint _t code append op j = std fma wgt float ip j bio + op j raise AssertionError code append code append use_offsets code append normalize_by_lengths length code append float len_inv = f length code append normalize_by_lengths lengths rangeIndex code append float len_inv = f lengths rangeIndex code append __m vlen_inv = _mm _set _ps len_inv code append j = code append j + = block_size j += code append _mm _storeu_ps \n op j _mm _mul_ps _mm _loadu_ps op j vlen_inv code append code append j block_size j++ code append op j = len_inv op j code append code append code append code start main code parser = argparse ArgumentParser parser add_argument -f -- filename help= file name parser add_argument -- fused action= store_true parser add_argument -- use-offsets action= store_true opts = parser parse_args opts filename filename = opts filename opts fused opts use_offsets filename = embedding_lookup_fused_ bit_rowwise_idx_avx cc filename = embedding_lookup_fused_ bit_rowwise_avx cc opts use_offsets filename = embedding_lookup_idx_avx cc filename = embedding_lookup_avx cc options = int _t int float float float float int _t int _t float float float float int _t int half Half float float int _t int _t half Half float float int _t int bfloat BFloat float float int _t int _t bfloat BFloat float float int _t int uint _t uint _t float float int _t int _t uint _t uint _t float float code = includes code append -------------------------- code append ATTENTION code append THIS CODE IS AUTOGENERATED code append f BY sys argv code append DO NOT MODIFY code append -------------------------- \n code append #include c util Half h code append #include c util BFloat h code append #include immintrin h code append namespace caffe \n o options IndexTypeName IndexType InTypeName InType OutTypeName OutType = o prefix = Fused BitRowwise opts fused code append template bool IS_WEIGHT_POSITIONAL opts use_offsets fn_base = f prefix EmbeddingLookupIdx_ IndexTypeName _ InTypeName _ OutTypeName fn_base = f prefix EmbeddingLookup_ IndexTypeName _ InTypeName _ OutTypeName suffix = __avx _fma fn = static bool + fn_base + suffix code append fn + args = args append const int _t block_size args append const int _t output_size args append const int _t index_size args append const int _t data_size args append const + InType + input args append const + IndexType + indices opts use_offsets args append const + IndexType + offsets args append const int lengths args append const float weights opts fused args append const float scale_bias args append bool normalize_by_lengths args append + OutType + out code += args code append const + IndexType + prefdist_T = code append NOLINTNEXTLINE cppcoreguidelines-narrowing-conversions bugprone-narrowing-conversions block_size number elements fused_block_size size entire row including scale bias offset = sizeof InType opts fused code append f const IndexType fused_block_size = block_size + offset opts use_offsets code append int _t dataInd = code append + IndexType + dataInd = code append printf \ calling + fn + \\n\ code append block_size == code += unroll IndexType InType OutType True AVX opts fused opts use_offsets code append block_size == code += unroll IndexType InType OutType True AVX opts fused opts use_offsets code append block_size == code += unroll IndexType InType OutType True AVX opts fused opts use_offsets code append block_size == code += unroll IndexType InType OutType True AVX opts fused opts use_offsets code append code append generic code code append NOLINTNEXTLINE modernize-avoid-c-arrays cppcoreguidelines-avoid-magic-numbers cppcoreguidelines-avoid-c-arrays code += generic IndexType InType OutType True AVX opts fused opts use_offsets code append code append dataInd == index_size code append is_weight_positional false true code append bool + fn_base + _ + is_weight_positional + suffix + code += args Resolve Lint warnings Limit characters one line extra_space = \n ret_string = + fn_base + suffix + + is_weight_positional + len ret_string = code append ret_string code append + fn_base + suffix + + extra_space + is_weight_positional + code append block_size code append output_size code append index_size code append data_size code append input code append indices opts use_offsets code append offsets code append lengths code append weights opts fused code append scale_bias code append normalize_by_lengths code append out code append code append code append namespace caffe open filename w encoding= utf fout c code print c file = fout fout write c + \n print Created + filename