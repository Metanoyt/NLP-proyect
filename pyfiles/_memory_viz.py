mypy allow-untyped-defs base io json operator os pickle subprocess sys warnings functools lru_cache itertools groupby typing Any cache = lru_cache None __all__ = format_flamegraph segments memory compare _frame_fmt f full_filename=False i = f line fname = f filename full_filename fname = fname split - func = f name f fname i func cache _frame_filter name filename omit_functions = unwind unwind CapturedTraceback gather gather_with_cpp _start __libc_start_main PyEval_ PyObject_ PyFunction_ omit_filenames = core boxing Register Redispatch pythonrun c Modules main c Objects call c Objects methodobject c pycore_ceval h ceval c cpython abstract h omit_functions name False omit_filenames filename False True _frames_fmt frames full_filename=False reverse=False reverse frames = reversed frames _frame_fmt f full_filename f frames _frame_filter f name f filename _block_extra_legacy b history b frames = b history get frames real_size = b history real_size real_size = b get requested_size b size frames = frames real_size _block_extra b frames b old snapshot format made more complicated get frames allocated size _block_extra_legacy b b frames b requested_size format_flamegraph flamegraph_lines flamegraph_script=None flamegraph_script None cache_dir = os path expanduser ~ cache os makedirs cache_dir exist_ok=True flamegraph_script = f cache_dir flamegraph pl os path exists flamegraph_script tempfile urllib request print f Downloading flamegraph pl flamegraph_script tempfile NamedTemporaryFile mode= wb suffix= pl f urllib request urlretrieve https raw githubusercontent com brendangregg FlameGraph master flamegraph pl f name try os chmod f name o os rename f name flamegraph_script except OSError noqa B E Ok skip file will removed tempfile pass args = flamegraph_script -- countname bytes p = subprocess Popen args stdin=subprocess PIPE stdout=subprocess PIPE encoding= utf- assert p stdin None assert p stdout None p stdin write flamegraph_lines p stdin close result = p stdout read p stdout close p wait assert p wait == result _write_blocks f prefix blocks frames_fragment frames frames non-python join _frames_fmt frames reverse=True b blocks history b frames accounted_for_size = _block_extra b f write f prefix b state frames_fragment frames accounted_for_size \n accounted_for_size = h b history sz = h real_size accounted_for_size += sz frames h frames = h frames f write f prefix b state frames_fragment frames sz \n f write f prefix b state no-context sz \n gaps = b size - accounted_for_size gaps f write f prefix b state gaps gaps \n segments snapshot format_flamegraph=format_flamegraph f = io StringIO seg snapshot segments prefix = f stream_ seg stream seg_ seg address _write_blocks f prefix seg blocks format_flamegraph f getvalue memory snapshot format_flamegraph=format_flamegraph f = io StringIO seg snapshot segments prefix = f stream_ seg stream _write_blocks f prefix seg blocks format_flamegraph f getvalue compare before after format_flamegraph=format_flamegraph _seg_key seg seg address seg total_size _seg_info seg f stream_ seg stream seg_ seg address f = io StringIO before_segs = _seg_key seg seg before after_segs = _seg_key seg seg after print f only_before = _ before_segs - after_segs print f only_after = _ after_segs - before_segs seg before _seg_key seg after_segs _write_blocks f f only_before _seg_info seg seg blocks seg after _seg_key seg before_segs _write_blocks f f only_after _seg_info seg seg blocks format_flamegraph f getvalue _format_size num https stackoverflow com questions get-human-readable-version-of-file-size unit Ki Mi Gi Ti Pi Ei Zi abs num f num f unit B num = f num f YiB Bytes __init__ value value = value __add__ rhs Bytes value + rhs __repr__ _format_size value calc_active seg sum b size b seg blocks b state == active_allocated _report_free free_external free_internal total = free_external + free_internal suffix = total = pct = free_internal total suffix = f pct f internal f Bytes total suffix PAGE_SIZE = legend = f \ Legend - segment allocator ^ -- page Bytes PAGE_SIZE memory segment a-z pages filled single block s content page completely free page completely full multiple blocks - page partially full tensors multiple blocks == full X internal - free memory X free because we rounded size allocation segsum data r Visually reports how allocator has filled its segments This printout can help debug fragmentation issues since free fragments will appear gaps printout The amount free space reported each segment We distinguish between internal free memory which occurs because allocator rounds allocation size external free memory which gaps between allocations segment Args data snapshot dictionary created _snapshot out = io StringIO out write f Summary segments = Bytes PAGE_SIZE size\n total_reserved = total_allocated = free_external = free_internal = seg sorted data segments key=lambda x x total_size calc_active x total_reserved += seg total_size seg_free_external = seg_free_internal = seg_allocated = all_ranges = boffset = b seg blocks active = b state == active_allocated active _ allocated_size = _block_extra b all_ranges append boffset allocated_size True seg_allocated += allocated_size seg_free_internal += b size - allocated_size seg_free_external += b size boffset += b size total_allocated += seg_allocated free_external += seg_free_external free_internal += seg_free_internal nseg = seg total_size - PAGE_SIZE + occupied = _ range nseg frac = _ range nseg active_size = i start_ size active enumerate all_ranges active_size += size finish_ = start_ + size start = start_ PAGE_SIZE finish = finish_ - PAGE_SIZE + m = chr ord active A + i j range start finish s = max start_ j PAGE_SIZE e = min finish_ j + PAGE_SIZE frac j += e - s PAGE_SIZE occupied j = occupied j = int frac j occupied j = m stream = seg stream == f stream_ seg stream body = join occupied assert seg_free_external + seg_free_internal + seg_allocated == seg total_size stream = f stream_ seg stream seg stream = seg total_size = PAGE_SIZE out write f body Bytes seg total_size allocated f _report_free seg_free_external seg_free_internal free stream \n out write f segments len data segments \n out write f total_reserved Bytes total_reserved \n out write f total_allocated Bytes total_allocated \n out write f total_free _report_free free_external free_internal \n out write legend assert free_internal + free_external + total_allocated == total_reserved out getvalue trace data out = io StringIO format entries segment_intervals list = segment_addr_to_name = allocation_addr_to_name = free_names list = next_name = _name nonlocal next_name free_names free_names pop r m = next_name next_name next_name += f chr ord + m r == r find_segment addr name saddr size segment_intervals addr = saddr addr saddr + size name saddr i seg enumerate data segments saddr = seg address size = seg allocated_size addr = saddr addr saddr + size f seg_ i saddr None None count = out write f len entries entries\n total_reserved = seg data segments total_reserved += seg total_size count e enumerate entries e action == alloc addr size = e addr e size n = _name seg_name seg_addr = find_segment addr seg_name None seg_name = MEM offset = addr offset = addr - seg_addr out write f n = seg_name offset Bytes size \n allocation_addr_to_name addr = n size count count += size e action == free_requested addr size = e addr e size name _ _ = allocation_addr_to_name get addr addr None None out write f del name Bytes size \n e action == free_completed addr size = e addr e size count -= size name _ _ = allocation_addr_to_name get addr addr None None out write f free completed name Bytes size \n name allocation_addr_to_name free_names append name del allocation_addr_to_name name e action == segment_alloc addr size = e addr e size name = _name out write f name = cudaMalloc addr Bytes size \n segment_intervals append name addr size segment_addr_to_name addr = name e action == segment_free addr size = e addr e size name = segment_addr_to_name get addr addr out write f cudaFree name Bytes size \n name segment_addr_to_name free_names append name del segment_addr_to_name name e action == oom size = e size free = e device_free out write f raise OutOfMemoryError Bytes size requested Bytes free free CUDA\n out write f e \n out write f TOTAL MEM Bytes count i d enumerate data device_traces d out write f Device i ---------------- \n format d out getvalue _memory_viz_template = r DOCTYPE html html head head body script type= module add_local_files https cdn jsdelivr net gh pytorch pytorch main torch utils viz MemoryViz js const local_files = $ SNAPSHOT add_local_files local_files $ VIZ_KIND script body _format_viz data viz_kind device device None warnings warn device argument deprecated plots now contain all device FutureWarning stacklevel= buffer = pickle dumps data buffer += b \x - len buffer Encode buffer base encoded_buffer = base b encode buffer decode utf- json_format = json dumps name snapshot pickle base encoded_buffer _memory_viz_template replace $ VIZ_KIND repr viz_kind replace $ SNAPSHOT json_format filter_alloc_free_pairs data dev_id range len data device_traces set indexes trace events alloc-free pairs filterSet = set map addr index alloc event allocMap = set addrs free_requested events freeRequested = set idx event enumerate data device_traces dev_id event action == alloc allocMap event addr = idx event action == free_requested freeRequested add event addr allocMap get event addr None filterSet add idx filterSet add allocMap event addr allocMap pop event addr event action == free_completed event addr freeRequested freeRequested remove event addr filterSet add idx print f free_completed without free_requested event Remove events whose index filterSet filterSet Create new list excluding events indices filterSet data device_traces dev_id = event idx event enumerate data device_traces dev_id idx filterSet data trace_plot data device=None plot_segments=False filter_freed=False Generate visualization over time memory usage recorded trace html file Args data Memory snapshot generated torch cuda memory _snapshot device torch device optional Generate trace device needed multiple devices have allocations plot_segments bool optional Plots memory returned cudaMalloc rather than individual allocations Defaults False filter_freed bool optional Filter out alloc-free paired events only plot allocations freed yet Defaults False plot all trace events Returns str HTML visualization filter_freed data = filter_alloc_free_pairs data _format_viz data Active Memory Timeline plot_segments Active Cached Memory Timeline device _profile_to_snapshot profile torch torch _C _profiler _EventType torch profiler _memory_profiler Action TensorKey memory_profile = profile _memory_profile allocation_stacks = event memory_profile _op_tree sorted_nodes event tag == _EventType Allocation parent = event parent python_parents = while parent parent tag _EventType PyCall _EventType PyCCall python_parents append parent parent = parent parent key = TensorKey from_allocation event extra_fields Corner case If allocation doesn t have ID can t prove used Tensor key will None I should add some way identify these I just haven t yet key event extra_fields alloc_size allocation_stacks key = python_parents device_count = torch cuda device_count snapshot dict str list Any = device_traces _ range device_count + segments device device address None total_size stream blocks device range device_count + to_device device device type == cuda device index device_count allocate size tensor_key version during_trace=True device = to_device tensor_key device addr = tensor_key storage ptr seg = snapshot segments device type ignore index seg address None seg address addr seg address = addr seg total_size = max seg total_size addr + size record max addr now we will make size later category = memory_profile _categories get tensor_key version category = category name lower category None unknown stack = allocation_stacks get tensor_key stack = filename none line name p name p stack r = action alloc addr addr size size stream frames stack category category during_trace snapshot device_traces device append r r free alloc device e free_requested free_completed snapshot device_traces device append action e addr alloc addr size alloc size stream frames alloc frames kv_to_elem = create device trace _time action tensor_key version size memory_profile timeline isinstance tensor_key TensorKey continue action == Action CREATE kv_to_elem tensor_key version = allocate size tensor_key version action == Action DESTROY free kv_to_elem pop tensor_key version to_device tensor_key device action == Action INCREMENT_VERSION free kv_to_elem pop tensor_key version to_device tensor_key device kv_to_elem tensor_key version + = allocate size tensor_key version + action == Action PREEXISTING kv_to_elem tensor_key version = allocate size tensor_key version during_trace=False create final snapshot state blocks_at_end = to_device tensor_key device event addr event size event frames tensor_key version event kv_to_elem items device blocks groupby sorted blocks_at_end key=operator itemgetter seg = snapshot segments device type ignore index last_addr = seg address _ addr size frames blocks last_addr addr seg blocks append size addr - last_addr state inactive seg blocks append size size state active_allocated requested_size size frames frames last_addr = addr + size last_addr seg total_size seg blocks append size seg total_size - last_addr state inactive snapshot segments = seg seg snapshot segments seg blocks type ignore attr-defined seg snapshot segments type ignore attr-defined name-defined no-redef seg total_size -= seg address seg blocks seg blocks append size seg total_size state inactive snapshot profile_plot profile device=None Generate visualization over time memory usage recorded kineto memory profiling html file Args profile profile generated ` torch profiler profile profile_memory=True ` device torch device optional Generate trace device needed multiple devices have allocations Returns str HTML visualization snapshot = _profile_to_snapshot profile _format_viz snapshot Active Memory Timeline device segment_plot data Any device=None _format_viz data Allocator State History device __name__ == __main__ os path thedir = os path realpath os path dirname __file__ thedir sys path otherwise we find cuda random py random sys path remove thedir argparse fn_name = torch cuda memory _snapshot pickled = f pickled memory statistics fn_name parser = argparse ArgumentParser description=f Visualize memory dumps produced fn_name subparsers = parser add_subparsers dest= action _output p p add_argument -o -- output default= output svg help= flamegraph svg default output svg description = Prints overall allocation statistics visualization how allocators segments currently filled stats_a = subparsers add_parser stats description=description stats_a add_argument input help=pickled description = Prints buffer most recent allocation events embedded snapshot Pythonic style trace_a = subparsers add_parser trace description=description trace_a add_argument input help=pickled description = Generate flamegraph visualizes what memory stored each allocator segment aka block segments_a = subparsers add_parser segments description=description segments_a add_argument input help=pickled _output segments_a description = Generate flamegraph program locations contributing CUDA memory usage memory_a = subparsers add_parser memory description=description memory_a add_argument input help=pickled _output memory_a description = Generate flamegraph shows segments aka blocks have been added removed between two different memorys snapshots compare_a = subparsers add_parser compare description=description compare_a add_argument before help=pickled compare_a add_argument after help=pickled _output compare_a plots = trace_plot Generate visualization over time memory usage recorded trace html file segment_plot Visualize how allocations packed into allocator segments each point trace html file cmd description plots trace_plot_a = subparsers add_parser cmd description=description trace_plot_a add_argument input help=pickled help = visualize trace device default chooses only device trace info errors trace_plot_a add_argument -d -- device type=int default=None help=help help = path save visualization default output html trace_plot_a add_argument -o -- output default= output html help=help cmd == trace_plot help = visualize change segments rather than individual allocations trace_plot_a add_argument -s -- segments action= store_true help=help help = filter out allocation-free pairs only visualize allocations freed yet useful reduce number events large traces debugging OOM trace_plot_a add_argument -f -- filter_freed action= store_true help=help args = parser parse_args _read name name == - f = sys stdin buffer f = open name rb data = pickle load f isinstance data list segments only data = segments data traces data _write name data open name w f f write data args action == segments data = _read args input _write args output segments data args action == memory data = _read args input _write args output memory data args action == stats data = _read args input print segsum data args action == trace data = _read args input print trace data args action == compare before = _read args before after = _read args after _write args output compare before after args action == trace_plot data = _read args input _write args output trace_plot data device=args device plot_segments=args segments filter_freed=args filter_freed args action == segment_plot data = _read args input _write args output segment_plot data device=args device