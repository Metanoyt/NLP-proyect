Owner s oncall mobile torch torch ao nn quantized nnq torch nn nn torch utils bundled_inputs torch ao quantization default_qconfig float_qparams_weight_only_qconfig graph mode quantization based fx torch ao quantization quantize_fx convert_fx prepare_fx torch testing _internal common_quantization LinearModelWithSubmodule NodeSpec ns QuantizationLiteTestCase TestLiteFuseFx QuantizationLiteTestCase Tests caffe test quantization fx test_quantize_fx py test_embedding M torch nn Module __init__ - None super __init__ emb = torch nn Embedding num_embeddings= embedding_dim= forward indices emb indices model = M eval indices = torch randint low= high= size= ns call_module nnq Embedding configs = float_qparams_weight_only_qconfig ns call_module nnq Embedding None ns call_module nn Embedding default_qconfig ns call_module nn Embedding qconfig _ configs qconfig_dict = qconfig m = prepare_fx model qconfig_dict example_inputs=torch randint low= high= size= m = convert_fx m _compare_script_and_mobile m input=indices test_conv d M torch nn Module __init__ - None super __init__ conv = nn Conv d conv = nn Conv d forward x x = conv x x = conv x x m = M eval qconfig_dict = default_qconfig module_name conv None m = prepare_fx m qconfig_dict example_inputs=torch randn data = torch randn m = convert_fx m first conv quantized second conv quantized _compare_script_and_mobile m input=data test_submodule test quantizing complete module submodule linear layer configs = module_name subm None module_name fc None config configs model = LinearModelWithSubmodule eval qconfig_dict = torch ao quantization get_default_qconfig qnnpack config model = prepare_fx model qconfig_dict example_inputs=torch randn quant = convert_fx model x = torch randn _compare_script_and_mobile quant input=x __name__ == __main__ run_tests noqa F