mypy allow-untyped-defs copy collections abc Callable typing Any Optional Union torch torch ao quantization experimental adaround_fake_quantize AdaroundFakeQuantizer torch ao quantization experimental adaround_loss AdaptiveRoundingLoss torch ao quantization observer MinMaxObserver torch nn functional F torch nn parallel DataParallel torch utils data DataLoader TensorDataset AdaptiveRoundingOptimizer __init__ model Union torch nn Module torch nn DataParallel callback Callable Union torch nn Module torch nn DataParallel Any Optional torch nn Module None forward_hook_wrapper Callable list torch Tensor Callable data Any observer type torch ao quantization observer ObserverBase = MinMaxObserver max_iter= dtype torch dtype = torch qint quant_min=- quant_max= qscheme torch qscheme = torch per_tensor_symmetric batch_size int = feed_forward_wrapper Optional torch nn Module = None torch cuda is_available model = model cuda torch cuda device_count model = torch nn DataParallel model model = model q_model = copy deepcopy model device = torch device cuda torch cuda is_available None callback = callback forward_hook_wrapper = forward_hook_wrapper TODO rather than having data list type we better pass iterator instead list data = data batch_size = min batch_size len data max_iter = max_iter adaptive_round_loss_fn = AdaptiveRoundingLoss max_iter=self max_iter warm_start= dtype = dtype observer = observer quant_min = quant_min quant_max = quant_max qscheme = qscheme feed_forward_wrapper = feed_forward_wrapper run_adaround - torch nn Module layer_list list tuple str torch nn Module torch nn Module = name module q_module zip model named_modules q_model modules isinstance module torch nn ReLU Disable all inplace operations module inplace = False isinstance q_module torch nn ReLU Disable all inplace operations q_module inplace = False isinstance module torch nn Conv d torch nn Linear Knowing activation ahead-of-time would helpful asymmetric formulation But challenging eager mode graph module layer_list append name module q_module print f Total number layers len layer_list noqa G name module q_module layer_list print f Kick start adaptive rounding name module module noqa G optimize_adaptive_rounding module q_module None q_model module isinstance q_model DataParallel q_model get_data_inp_out module torch nn Module q_module torch nn Module data list Any - tuple list torch Tensor list torch Tensor list torch Tensor fp_out list torch Tensor = q_input list torch Tensor = fp_input list torch Tensor = fp _fetcher list torch Tensor = quant_fetcher list torch Tensor = handler = module register_forward_hook forward_hook_wrapper fp _fetcher handler = q_module register_forward_hook forward_hook_wrapper quant_fetcher torch cuda is_available Somehow we need move model continuously Otherwise model will lowered CPU mysteriously model = model cuda q_model = q_model cuda data_ data torch no_grad callback model data_ feed_forward_wrapper callback q_model data_ feed_forward_wrapper fp _output = fp _fetcher quant_input = quant_fetcher fp_out append fp _output q_input append quant_input fp_input append fp _fetcher handler remove handler remove q_input fp_out fp_input torch no_grad feed_forward x weight module isinstance module torch nn Conv d out = torch nn functional conv d x weight stride=module stride padding=module padding dilation=module dilation groups=module groups isinstance module torch nn Linear out = torch nn functional linear x weight bias=module bias raise NotImplementedError out _compute_and_display_local_losses ada_quantizer AdaroundFakeQuantizer q_module torch nn Module q_inp torch Tensor fp_out torch Tensor torch no_grad ada_quantizer use_soft_rounding = False q_w_hard_round = ada_quantizer q_module weight out_hard_quant = feed_forward q_inp q_w_hard_round q_module ada_quantizer use_soft_rounding = True q_w_soft_round = ada_quantizer q_module weight out_soft_quant = feed_forward q_inp q_w_soft_round q_module soft_quant_loss = F mse_loss out_soft_quant fp_out hard_quant_loss = F mse_loss out_hard_quant fp_out print f soft quant loss soft_quant_loss item hard quant loss hard_quant_loss item noqa G optimize_adaptive_rounding module torch nn Module q_module torch nn Module activation Optional Callable torch Tensor torch Tensor = None - None ada_quantizer = AdaroundFakeQuantizer dtype=self dtype observer=self observer qscheme=self qscheme quant_min=self quant_min quant_max=self quant_max reduce_range=False ada_quantizer enable_observer ada_quantizer q_module weight ada_quantizer disable_observer ada_quantizer enable_fake_quant optimizer = torch optim Adam ada_quantizer V inp out fp_in = get_data_inp_out module q_module data print ==================== Before adaround ==================== torch abs out - module fp_in sum item = raise AssertionError In-placed activation detected please do use activation in-placed Stack tensors each list into single tensor Assuming inp out your lists tensors inp_tensor = torch vstack inp out_tensor = torch vstack out dataset = TensorDataset inp_tensor out_tensor dataloader = DataLoader dataset batch_size=self batch_size shuffle=True _compute_and_display_local_losses ada_quantizer q_module inp out global_idx = one_iter = len out batch_size iteration range max_iter one_iter reconstruction_loss = regularization_loss = torch tensor q_inp fp_out dataloader optimizer zero_grad q_weight = ada_quantizer q_module weight isinstance module torch nn Conv d q_out = torch nn functional conv d type ignore call-overload misc q_inp q_weight bias=q_module bias stride=q_module stride padding=q_module padding dilation=q_module dilation groups=q_module groups isinstance q_module torch nn Linear q_out = torch nn functional linear q_inp q_weight bias=q_module bias raise NotImplementedError regularization_loss reconstruction_loss = adaptive_round_loss_fn fp_out q_out ada_quantizer V curr_iter=global_idx loss = regularization_loss + reconstruction_loss loss backward optimizer step global_idx += global_idx = max_iter break global_idx = max_iter break iteration == print f glob iter global_idx regularization_loss regularization_loss item noqa G f reconstruction_loss reconstruction_loss item noqa G print ==================== After adaround ==================== _compute_and_display_local_losses ada_quantizer q_module inp out ada_quantizer use_soft_rounding = True ada_quantizer V requires_grad = False ada_quantizer = ada_quantizer eval q_weight = ada_quantizer q_module weight At end optimization we need copy adarounded weight back original module q_module weight data copy_ q_weight type ignore operator Eager mode requires observer set weight_fake_quant parsed q_module weight_fake_quant = ada_quantizer activation_post_process