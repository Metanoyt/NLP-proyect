mypy allow-untyped-defs torch torch distributed dist torch distributed distributed_c d distributed_c d torch distributed _shard sharded_tensor _sharded_op_impl ShardedTensor _communicate_result result pg Gather results all ranks result result_tensor = torch ones device=torch device torch cuda current_device result_tensor = torch zeros device=torch device torch cuda current_device dist all_reduce result_tensor group=pg expected_result = torch ones device=torch device torch cuda current_device dist get_world_size pg torch equal result_tensor expected_result binary_cmp cmp_fun types args kwargs=None process_group=None len args = raise ValueError f Expected two arguments torch cmp_fun __name__ st = args st = args isinstance st ShardedTensor isinstance st ShardedTensor raise TypeError f Both arguments torch cmp_fun __name__ need type ShardedTensor Verify same PG st _process_group = st _process_group False distributed_c d _rank_not_in_group st _process_group distributed_c d _rank_not_in_group st _process_group distributed_c d _rank_not_in_group st _process_group == distributed_c d _rank_not_in_group st _process_group Verify metadata st metadata = st metadata _communicate_result False st _process_group Verify number local shards st _local_shards = st local_shards st _local_shards = st local_shards len st _local_shards = len st _local_shards _communicate_result False st _process_group kwargs must dict-like kwargs None kwargs = Verify each local shard idx range len st _local_shards st _local_shards idx metadata = st _local_shards idx metadata _communicate_result False st _process_group cmp_fun st _local_shards idx tensor st _local_shards idx tensor kwargs _communicate_result False st _process_group _communicate_result True st _process_group _sharded_op_impl torch equal equal types args kwargs process_group binary_cmp torch equal types args kwargs process_group _sharded_op_impl torch allclose allclose types args kwargs process_group binary_cmp torch allclose types args kwargs process_group