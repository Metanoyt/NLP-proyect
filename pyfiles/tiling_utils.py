dataclasses itertools collections Counter defaultdict typing Callable Literal Optional overload TYPE_CHECKING TypeVar Union sympy torch torch _inductor config torch _inductor dependencies index_vars_no_squeeze torch _inductor utils sympy_product sympy_subs torch utils _ordered_set OrderedSet torch utils _sympy functions Identity torch utils _sympy solve try_solve torch utils _sympy symbol symbol_is_type SymT virtualized V T = TypeVar T U = TypeVar U Split = tuple sympy Expr VarsAndRanges = tuple list sympy Symbol list sympy Expr loop_tiling_log = torch _logging getArtifactLogger __name__ loop_tiling torch utils _sympy functions FloorDiv ModularIndexing TYPE_CHECKING torch _inductor scheduler FusedSchedulerNode SchedulerNode solve_for_zero expr sympy Expr - Optional sympy Expr Given expr single free symbol solve constant relation would make expression expr is_constant None isinstance expr FloorDiv None assert len expr free_symbols == free_symbol = next iter expr free_symbols isinstance expr ModularIndexing out = try_solve sympy Eq expr args expr args free_symbol out = try_solve sympy Eq expr free_symbol out out is_constant None out solve_for_tiling expr sympy Expr - Optional sympy Expr Giving expr single free symbol try find tiling would make expression coalesced respect symbol Tiling expression ` x ` ` y ` means expression will now indexed both original x x y So we looking multiplicative factor will make x + y - x y == To simplify things sympy we ll try just x y == check x x len expr free_symbols == None free_symbol = next iter expr free_symbols _solve_simple_expr expr sympy Expr - Optional sympy Expr assert expr has ModularIndexing expr has FloorDiv len expr free_symbols = None out = try_solve sympy Eq expr free_symbol out out is_constant None out Sympy solving very limited ModularIndexing FloorDiv good otherwise expr has ModularIndexing expr has FloorDiv _solve_simple_expr expr required_values = eq_ _expressions = very piecemeal solution ModularIndexing FloorDiv involved Look terms we ll try make then other terms we ll try make Expand needed arg sympy Add make_args expr Try make mul terms isinstance arg sympy Mul seen = False TODO - only need one these solvable zero mul_arg arg args out = solve_for_zero mul_arg out None continue assert out is_constant seen = True required_values append out seen None eq_ _expressions append arg eq_ _expressions None eq_ _expr = sum eq_ _expressions indexing_div_rep x sympy Expr y sympy Expr z Optional sympy Expr = None - sympy Expr x y For purposes tiling coalesced access approximate ModularIndexing FloorDiv then check later pyrefly ignore missing-attribute eq_ _expr_simplified = eq_ _expr replace ModularIndexing indexing_div_rep replace FloorDiv indexing_div_rep out = _solve_simple_expr eq_ _expr_simplified since we approximated FloorDiv ModularIndexing double check here out sympy_subs eq_ _expr free_symbol out = None required_values append out len OrderedSet required_values == required_values None find_coalesced_var index sympy Expr var_ranges dict sympy Expr int - Optional sympy Expr Try find symbol which coalesces index top_level_terms = sympy Add make_args index v var_ranges v top_level_terms v Approximate analysis evaluating variables dict sympy Symbol int = v index free_symbols v var_ranges variables v = variables v = get_hint v zero_index = sympy_subs index variables v var_ranges keys variables v = try new_val = sympy_subs index variables except ZeroDivisionError loop_tiling_log info zero division error s s index variables continue new_val - zero_index == variables v = some more complex expressions - will coalesced - sympy_subs index variables - new_val == v variables v = None dataclasses dataclass frozen=True FusedNormalizedReadsWrites Normalized reads writes nodes same FusedSchedulerNode index_vars OrderedSet sympy Symbol reduce_vars OrderedSet sympy Symbol reads dict sympy Expr OrderedSet str writes dict sympy Expr OrderedSet str var_ranges dict sympy Symbol int overload get_pw_red_splits n SchedulerNode pointwise_numel sympy Expr red_numel sympy Expr none_if_not_divisible Literal True - Optional tuple VarsAndRanges VarsAndRanges overload get_pw_red_splits n SchedulerNode pointwise_numel sympy Expr red_numel sympy Expr none_if_not_divisible Literal False = False - tuple VarsAndRanges VarsAndRanges get_pw_red_splits n SchedulerNode pointwise_numel sympy Expr red_numel sympy Expr none_if_not_divisible bool = False - Optional tuple VarsAndRanges VarsAndRanges n is_reduction sympy_product n _body sizes == pointwise_numel n _body iter_vars n _body sizes n _body reduce_vars n _body sizes type ignore return-value assert sympy_product n _body sizes == pointwise_numel red_numel type ignore operator i = len n _body sizes - prod = while i = prod = n _body sizes i prod == red_numel break i -= i = pw_splits = n _body sizes i iter_vars = n _body iter_vars i red_splits = n _body sizes i red_vars = n _body iter_vars i iter_vars pw_splits red_vars red_splits type ignore return-value none_if_not_divisible None n _body iter_vars n _body sizes n _body reduce_vars n _body sizes type ignore return-value NodeSplitGetter Finds Pointwise Reduction Split compatible all nodes SchedulerNode __init__ node Union FusedSchedulerNode SchedulerNode node = node pointwise_numel sympy Expr = node group red_numel sympy Expr = node group pw_split_options dict int OrderedSet Split = defaultdict OrderedSet reduction_split Split = all_node_sizes OrderedSet tuple Split Split = OrderedSet fused_group = node group n reversed node get_nodes isinstance n torch _inductor scheduler SchedulerNode continue we can t split pw ranges into pw red split dont add split option do make sure we check size splittable maybe_splits = get_pw_red_splits n pointwise_numel red_numel none_if_not_divisible=True maybe_splits None all_node_sizes add n _body sizes continue _ n_pw_splits _ n_red_splits = maybe_splits fill reduction size n_pw_splits n_red_splits = torch _inductor codegen simd SIMDKernel prepare_split_iteration_lengths fused_group n_pw_splits n_red_splits red_numel pw_split_options len n_pw_splits add tuple n_pw_splits initially we just going do single reduction split since reduction tiling off default even we miss reduction split we can recover split var analysis TODO earlier version code tried iteratively try maximum number split vars iterating over both pointwise reduction worth complexity yet n_red_splits = reduction_split = sympy_product n_red_splits n_size = tuple n_pw_splits tuple n_red_splits all_node_sizes add n_size seen_pw_splits OrderedSet Split = OrderedSet get_node_splits - tuple Split Split Get compatible pointwise reduction split node len all_node_sizes == next iter all_node_sizes max_pw_split = max pw_split_options keys pw_split_len range max_pw_split - pw_split pw_split_options pw_split_len out = try_split pw_split reduction_split out combine dims next round pw_split pw_split_options pw_split_len i range len pw_split - new_split = tuple pw_split i + sympy_product pw_split i i + + pw_split i + pw_split_options len new_split add new_split whatever reason we couldn t split above default split pointwise_numel red_numel try_split pw Split red Split - Optional tuple Split Split See split compatible potentially returning longer split than input torch _inductor codegen simd CantSplit SIMDKernel pw seen_pw_splits None seen_pw_splits add pw n_pw n_red all_node_sizes try groups = pw + red lengths = n_pw n_red splits getters = SIMDKernel _split_iteration_ranges groups lengths except CantSplit None assert len getters == pw_group_splits = splits len pw we had divide variable into two do split then lets try larger induced split e g splitting into will split first var into produce overall split flattened_pw_splits = tuple itertools chain from_iterable pw_group_splits flattened_pw_splits = pw out = try_split flattened_pw_splits red out pw red apply_var_mapping iter_vars list sympy Symbol red_vars list sympy Symbol norm_pw_vars list sympy Symbol norm_red_vars list sympy Symbol new_ranges list list sympy Expr return_getters_groups list list Callable list sympy Expr sympy Expr - dict sympy Symbol sympy Expr Maps original variables expressions using normalized variables output split_iteration_range new_ranges return_getters_groups new_ranges flattened list ranges corresponding new pw red vars example taking pw vars range normalized range new_ranges would There return_getter callable each input iter_var red_vars you flatten out all ranges create variable each index then applying flattening vars callables return_getters_groups gives you mapping input vars - flattened vars From there we can compute output normalized variables For instance corresponding flat vars v v will v + v Create flattened iteration variables num_vars = sum len s s new_ranges flat_vars = sympy symbols f v_ num_vars count = len iter_vars == len red_vars == assert len new_ranges == len norm_pw_vars + norm_red_vars apply_groups = group return_getters_groups apply_groups append g flat_vars g group iter_vars_to_flat_vars = i group var_group enumerate zip apply_groups iter_vars red_vars strict=True node has sizes p fused node p r reduction var gets filled split_iteration_range len group = len var_group assert i == assert len var_group == continue iter_vars_to_flat_vars update v g g v zip group var_group count = flat_vars_to_new_vars = new_range new_var zip new_ranges norm_pw_vars + norm_red_vars strict=True range_vars = _ range len new_range range_vars append flat_vars count count += prod = i range len new_range - - - flat_vars_to_new_vars range_vars i = new_var prod prod = new_range i prod k sympy_subs v flat_vars_to_new_vars k v iter_vars_to_flat_vars items extract_normalized_read_writes node Union FusedSchedulerNode SchedulerNode - Optional FusedNormalizedReadsWrites Extracts index variables reduce variables read write expressions variable ranges fused node reads dict sympy Expr OrderedSet str = defaultdict OrderedSet writes dict sympy Expr OrderedSet str = defaultdict OrderedSet all_output_names = node get_buffer_names op_names = node get_operation_names outputs OrderedSet str = OrderedSet removed_buffers OrderedSet str = OrderedSet buf_name all_output_names V graph scheduler can_buffer_be_removed_through_fusion buf_name op_names removed_buffers add buf_name outputs add buf_name inputs = OrderedSet dep name dep node read_writes reads dep name removed_buffers pointwise_numel sympy Expr = node group red_numel sympy Expr = node group TODO - few dynamic shapes issues resolve any isinstance var sympy Expr var is_constant var pointwise_numel red_numel None pw_splits red_splits = NodeSplitGetter node get_node_splits lets use different prefix ` n ` distinguish norm_pw_vars norm_red_vars ranges = index_vars_no_squeeze pw_splits red_splits prefix= n n list node get_nodes isinstance n torch _inductor scheduler SchedulerNode continue body = n _body TODO - handled well indirect loads will coalesced need account analysis body indirect_vars None n_reads dict sympy Expr OrderedSet str = defaultdict OrderedSet n_writes dict sympy Expr OrderedSet str = defaultdict OrderedSet TODO - will names all inputs outputs accurately reflect mutation do I need remap mutation_real_name inp inputs expr body get_all_read_expr inp n_reads expr add inp out outputs expr body get_all_write_expr out n_writes expr add out n_reads n_writes continue iter_vars n_pw_splits red_vars n_red_splits = get_pw_red_splits n pointwise_numel red_numel groups = pw_splits + red_splits lengths = n_pw_splits n_red_splits lengths = torch _inductor codegen simd SIMDKernel prepare_split_iteration_lengths groups lengths red_numel new_ranges return_getters_groups = torch _inductor codegen simd SIMDKernel _split_iteration_ranges groups lengths var_map = apply_var_mapping iter_vars red_vars norm_pw_vars norm_red_vars new_ranges return_getters_groups We create Identity sympy Functions prevent expansion int unwrap tiling analysis remove_identity expr sympy Expr - sympy Expr expr replace Identity lambda x x n_reads_new = sympy_subs remove_identity read var_map v read v n_reads items n_writes_new = sympy_subs remove_identity write var_map v write v n_writes items expr buf_names n_reads_new items reads expr &#124; = buf_names expr buf_names n_writes_new items writes expr &#124; = buf_names reads = V graph sizevars simplify_with_ranges r ranges v r v reads items writes = V graph sizevars simplify_with_ranges w ranges v w v writes items fused_out = FusedNormalizedReadsWrites norm_pw_vars type ignore arg-type norm_red_vars type ignore arg-type reads writes ranges loop_tiling_log info Normalized Fused reads s fused_out fused_out get_score addr sympy Expr var_ranges dict sympy Symbol int - int Score addr according its approximate size TODO - deduplicate candidate_tilings var_sizes = v addr free_symbols v_size = var_ranges get v TODO - reason about indirect vars symbol_is_type v SymT INDIRECT v_size None var_sizes append v_size virtualized V V graph sizevars atomically_apply_size_hint sympy_product var_sizes fallback=config unbacked_symint_fallback get_hint v Union sympy Expr int - int isinstance v int v V graph sizevars size_hint v fallback=config unbacked_symint_fallback dataclasses dataclass frozen=True VarTiling Tiling var ` tiling_factor ` yields additional coalesced mem accesses ` benefit_score ` var sympy Symbol tiling_factor int score int dataclasses dataclass frozen=True CoalesceVarAnalysis Var - Memory Score - strictly amount memory because we multiply writes x TODO separate into dataclass olds mem dtype is_write coalesced_by_var dict sympy Expr int norm_read_writes FusedNormalizedReadsWrites suggested_split Optional VarTiling = None analyze_memory_coalescing fused_node Union FusedSchedulerNode SchedulerNode - Optional CoalesceVarAnalysis Find variables coalesce reads writes score total size If uncoalesced memory expressions found look additionally tiling variables which will coalesce memory accesses For instance - following expression p Tiling p will make expression coalesced norm_read_writes = extract_normalized_read_writes fused_node norm_read_writes None None reads = norm_read_writes reads writes = norm_read_writes writes var_ranges = norm_read_writes var_ranges coalesced_by_var dict sympy Symbol int = Counter uncoalesced_addrs dict sympy Expr int = Counter is_read memory_expr buf_names itertools chain True item item reads items False item item writes items skip memory deps indirect vars - todo better handling indirect_expr = bool memory_expr free_symbols - norm_read_writes var_ranges keys indirect_expr continue size = get_score memory_expr var_ranges size == continue maybe_coalesced_var = find_coalesced_var memory_expr var_ranges byte_multipler = buf_name buf_names buf = V graph try_get_buffer buf_name byte_multipler += buf dtype itemsize coalesced writes more important byte_multipler = is_read maybe_coalesced_var coalesced_by_var maybe_coalesced_var += size byte_multipler uncoalesced_addrs memory_expr += size byte_multipler uncoalesced_addrs CoalesceVarAnalysis coalesced_by_var=coalesced_by_var norm_read_writes=norm_read_writes map var - tiling - total_score tiling_scores dict sympy Expr dict int int = defaultdict Counter uncoalesced_expr addr_score uncoalesced_addrs items expr_subs = dict fromkeys uncoalesced_expr free_symbols v uncoalesced_expr free_symbols skip non iter reduce var variables v var_ranges continue skip small addrs addr_score == continue del expr_subs v single_var_expr = sympy_subs uncoalesced_expr expr_subs expr_subs v = tiling_factor = solve_for_tiling single_var_expr tiling_factor None tiling_factor is_constant tiling_factor is_integer continue tiling_factor = int tiling_factor V graph sizevars statically_known_lt tiling_factor var_ranges v continue TODO - var middle such n n n n can can split beyond range MIN_TILING_BLOCK = all V graph sizevars statically_known_lt MIN_TILING_BLOCK block block tiling_factor var_ranges v tiling_factor continue tiling_scores v tiling_factor += addr_score len tiling_scores == CoalesceVarAnalysis coalesced_by_var=coalesced_by_var norm_read_writes=norm_read_writes best_tiling Optional tuple sympy Expr int = None best_tiling_score = var tiling_counter tiling_scores items tile tile_score tiling_counter items tile_score best_tiling_score best_tiling = var tile best_tiling_score = tile_score best_tiling None CoalesceVarAnalysis coalesced_by_var=coalesced_by_var norm_read_writes=norm_read_writes TODO - strictly pointwise fusions we can consider just swizzling var var we going tile does coalesce significant portion global reads TODO - could also prefer index var splits reduction better tested CoalesceVarAnalysis coalesced_by_var=coalesced_by_var norm_read_writes=norm_read_writes suggested_split=VarTiling best_tiling best_tiling best_tiling_score