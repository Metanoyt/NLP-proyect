mypy allow-untyped-defs torch torch utils _pytree tree_map tree_flatten tree_unflatten module_tracker ModuleTracker typing Any Optional Union TypeVar collections abc Callable collections abc Iterator typing_extensions ParamSpec collections defaultdict torch utils _python_dispatch TorchDispatchMode math prod functools wraps warnings __all__ = FlopCounterMode register_flop_formula _T = TypeVar _T _P = ParamSpec _P aten = torch ops aten get_shape i isinstance i torch Tensor i shape i flop_registry dict Any Any = shape_wrapper f wraps f nf args out_val=None kwargs args kwargs out_shape = tree_map get_shape args kwargs out_val f args out_shape=out_shape kwargs nf register_flop_formula targets get_raw=False - Callable Callable _P _T Callable _P _T register_fun flop_formula Callable _P _T - Callable _P _T get_raw flop_formula = shape_wrapper flop_formula register target isinstance target torch _ops OpOverloadPacket raise ValueError f register_flop_formula targets expected each target f OpOverloadPacket i e torch ops mylib foo got f target which type type target target flop_registry raise RuntimeError f duplicate registrations target flop_registry target = flop_formula To handle allowing multiple aten_ops once torch utils _pytree tree_map_ register targets flop_formula register_fun register_flop_formula aten mm mm_flop a_shape b_shape args out_shape=None kwargs - int Count flops matmul Inputs should list length Inputs contains shapes two matrices m k = a_shape k n = b_shape k = k raise AssertionError f matmul inner dimensions must match k == k got k k NB chilli Should k - technically FLOPs m n k register_flop_formula aten addmm addmm_flop self_shape a_shape b_shape out_shape=None kwargs - int Count flops addmm mm_flop a_shape b_shape register_flop_formula aten bmm bmm_flop a_shape b_shape out_shape=None kwargs - int Count flops bmm operation Inputs should list length Inputs contains shapes two tensor b m k = a_shape b k n = b_shape b = b raise AssertionError f bmm batch dimensions must match b == b got b b k = k raise AssertionError f bmm inner dimensions must match k == k got k k NB chilli Should k - technically FLOPs flop = b m n k flop register_flop_formula aten baddbmm baddbmm_flop self_shape a_shape b_shape out_shape=None kwargs - int Count flops baddbmm operation Inputs should list length Inputs contains shapes three tensors bmm_flop a_shape b_shape register_flop_formula aten _scaled_mm _scaled_mm_flop a_shape b_shape scale_a_shape scale_b_shape bias_shape=None scale_result_shape=None out_dtype=None use_fast_accum=False out_shape=None kwargs - int Count flops _scaled_mm mm_flop a_shape b_shape conv_flop_count x_shape list int w_shape list int out_shape list int transposed bool = False - int Count flops convolution Note only multiplication counted Computation bias ignored Flops transposed convolution calculated flops = x_shape prod w_shape batch_size Args x_shape list int The input shape before convolution w_shape list int The filter shape out_shape list int The output shape after convolution transposed bool convolution transposed Returns int number flops batch_size = x_shape conv_shape = x_shape transposed out_shape c_out c_in filter_size = w_shape General idea here regular conv each point output spatial dimension we convolve filter something hence ` prod conv_shape prod filter_size ` ops Then gets multiplied batch_size cross product input weight channels For transpose s each point output spatial dimension each point input spatial dimension NB chilli I don t think properly accounts padding think NB chilli Should c_in - technically FLOPs flop = prod conv_shape prod filter_size batch_size c_out c_in flop register_flop_formula aten convolution aten _convolution aten cudnn_convolution aten _slow_conv d_forward conv_flop x_shape w_shape _bias _stride _padding _dilation transposed args out_shape=None kwargs - int Count flops convolution pyrefly ignore bad-argument-type conv_flop_count x_shape w_shape out_shape transposed=transposed register_flop_formula aten convolution_backward conv_backward_flop grad_out_shape x_shape w_shape _bias _stride _padding _dilation transposed _output_padding _groups output_mask out_shape - int t shape shape shape + list shape flop_count = Let s say we have regular D conv A B C inp i j weight = conv Ai + Bj Bi + Cj out And reminder transposed conv above = Ai Aj + Bi Bj + Ci Cj transposed conv out For backwards conv we now have D E grad_out A B C inp i j weight grad_inp conv_transpose grad_out weight Let s first compute grad_inp To do so we can simply look all multiplications each element inp involved For example A only involved first element output thus only depends upon D grad_out C only involved last element output thus only depends upon E grad_out Di Dj + Ei Ej grad_inp Note corresponds below conv_transpose This gives us output_mask branch which grad_inp D E inp grad_out i j weight = conv_transpose Di Dj + Ei Ej out grad_inp I leave fact grad_inp transposed conv just conv grad_out weight exercise reader grad_weight conv inp grad_out To compute grad_weight we again look terms output which reminder = Ai + Bj Bi + Cj out = D E grad_out If we manually compute gradient weights we see s AD + BE BD + CE grad_weight This corresponds below conv A B C inp D E weight grad_out = conv AD + BE BD + CE out grad_weight grad_weight transposed conv conv grad_out inp As reminder terms output transposed conv = Ai Aj + Bi Bj + Ci Cj transposed conv out = D E F G grad_out Manually computing gradient weights we see s AD + BE + CF AE + BF + CG grad_weight This corresponds below conv D E F G inp grad_out A B C weight inp = conv AD + BE + CF AE + BF + CG out grad_weight For full backwards formula there also some details involving transpose batch channel dimensions groups I skip those sake brevity they re pretty similar matmul backwards Check conv backwards decomposition conv forwards grad_inp conv_transpose grad_out weight output_mask grad_input_shape = get_shape out_shape flop_count += conv_flop_count grad_out_shape w_shape grad_input_shape transposed output_mask grad_weight_shape = get_shape out_shape transposed grad_weight transposed conv conv grad_out inp flop_count += conv_flop_count t grad_out_shape t x_shape t grad_weight_shape transposed=False grad_weight conv inp grad_out flop_count += conv_flop_count t x_shape t grad_out_shape t grad_weight_shape transposed=False flop_count sdpa_flop_count query_shape key_shape value_shape Count flops self-attention NB We can assume value_shape == key_shape b h s_q d_q = query_shape _b _h s_k _d = key_shape _b _h _s d_v = value_shape b == _b == _b h == _h == _h d_q == _d s_k == _s d_q == _d raise AssertionError sdpa_flop_count query key value shapes incompatible total_flops = q b h s_q d_q k b h d_q s_k - scores b h s_q s_k total_flops += bmm_flop b h s_q d_q b h d_q s_k scores b h s_q s_k v b h s_k d_v - out b h s_q d_v total_flops += bmm_flop b h s_q s_k b h s_k d_v total_flops register_flop_formula aten _scaled_dot_product_efficient_attention aten _scaled_dot_product_flash_attention aten _scaled_dot_product_cudnn_attention sdpa_flop query_shape key_shape value_shape args out_shape=None kwargs - int Count flops self-attention NB We aren t accounting causal attention here sdpa_flop_count query_shape key_shape value_shape _offsets_to_lengths offsets max_len If offsets tensor fake then we don t know actual lengths In case we can just assume worst case each batch has max length torch _subclasses fake_tensor FakeTensor torch _subclasses functional_tensor FunctionalTensor isinstance offsets FakeTensor FunctionalTensor offsets device type = meta offsets diff tolist max_len offsets size - _unpack_flash_attention_nested_shapes query key value grad_out=None cum_seq_q cum_seq_k max_q max_k - Iterator tuple tuple int tuple int tuple int Optional tuple int Given inputs flash_attention_ forward &#124; backward kernel will handle behavior NestedTensor inputs effectively unbinding NestedTensor yielding shapes each batch element In case isn t NestedTensor kernel then just yields original shapes cum_seq_q None This means we should dealing Nested Jagged Tensor query The inputs will have shape sum sequence len heads dimension In comparison non-Nested inputs have shape batch heads sequence len dimension To deal we convert shape batch heads max_seq_len dimension So flops calculation case overestimate actual flops len key shape = raise AssertionError sdpa_flop_count expected key shape -dimensional len value shape = raise AssertionError sdpa_flop_count expected value shape -dimensional grad_out None grad_out shape = query shape raise AssertionError sdpa_flop_count grad_out shape must match query shape when provided _ h_q d_q = query shape _ h_k d_k = key shape _ h_v d_v = value shape cum_seq_q None raise AssertionError sdpa_flop_count cum_seq_q must None cum_seq_k None raise AssertionError sdpa_flop_count cum_seq_k must None cum_seq_q shape = cum_seq_k shape raise AssertionError sdpa_flop_count cum_seq_q cum_seq_k must have same shape seq_q_lengths = _offsets_to_lengths cum_seq_q max_q seq_k_lengths = _offsets_to_lengths cum_seq_k max_k seq_q_len seq_k_len zip seq_q_lengths seq_k_lengths strict=True new_query_shape = h_q seq_q_len d_q new_key_shape = h_k seq_k_len d_k new_value_shape = h_v seq_k_len d_v new_grad_out_shape = new_query_shape grad_out None None yield new_query_shape new_key_shape new_value_shape new_grad_out_shape yield query shape key shape value shape grad_out shape grad_out None None _unpack_efficient_attention_nested_shapes query key value grad_out=None cu_seqlens_q cu_seqlens_k max_seqlen_q max_seqlen_k - Iterator tuple tuple int tuple int tuple int Optional tuple int Given inputs efficient_attention_ forward &#124; backward kernel will handle behavior NestedTensor inputs effectively unbinding NestedTensor yielding shapes each batch element In case isn t NestedTensor kernel then just yields original shapes cu_seqlens_q None Unlike flash_attention_forward we get D tensor instead D tensor efficient attention This means we should dealing Nested Jagged Tensor query The inputs will have shape sum sequence len heads dimension In comparison non-Nested inputs have shape batch heads sequence len dimension To deal we convert shape batch heads max_seq_len dimension So flops calculation case overestimate actual flops len key shape = raise AssertionError _unpack_efficient_attention_nested_shapes expected key shape -dimensional len value shape = raise AssertionError _unpack_efficient_attention_nested_shapes expected value shape -dimensional grad_out None grad_out shape = query shape raise AssertionError _unpack_efficient_attention_nested_shapes grad_out shape must match query shape when provided _ _ h_q d_q = query shape _ _ h_k d_k = key shape _ _ h_v d_v = value shape cu_seqlens_q None raise AssertionError _unpack_efficient_attention_nested_shapes cu_seqlens_q must None cu_seqlens_k None raise AssertionError _unpack_efficient_attention_nested_shapes cu_seqlens_k must None cu_seqlens_q shape = cu_seqlens_k shape raise AssertionError _unpack_efficient_attention_nested_shapes cu_seqlens_q cu_seqlens_k must have same shape seqlens_q = _offsets_to_lengths cu_seqlens_q max_seqlen_q seqlens_k = _offsets_to_lengths cu_seqlens_k max_seqlen_k len_q len_k zip seqlens_q seqlens_k strict=True new_query_shape = h_q len_q d_q new_key_shape = h_k len_k d_k new_value_shape = h_v len_k d_v new_grad_out_shape = new_query_shape grad_out None None yield new_query_shape new_key_shape new_value_shape new_grad_out_shape yield query shape key shape value shape grad_out shape grad_out None None register_flop_formula aten _flash_attention_forward get_raw=True _flash_attention_forward_flop query key value cum_seq_q cum_seq_k max_q max_k args out_shape=None kwargs - int Count flops self-attention NB We aren t accounting causal attention here case nested tensor we unpack individual batch elements then sum flops per batch element sizes = _unpack_flash_attention_nested_shapes query=query key=key value=value cum_seq_q=cum_seq_q cum_seq_k=cum_seq_k max_q=max_q max_k=max_k sum sdpa_flop_count query_shape key_shape value_shape query_shape key_shape value_shape _ sizes register_flop_formula aten _efficient_attention_forward get_raw=True _efficient_attention_forward_flop query key value bias cu_seqlens_q cu_seqlens_k max_seqlen_q max_seqlen_k args kwargs - int Count flops self-attention NB We aren t accounting causal attention here case nested tensor we unpack individual batch elements then sum flops per batch element sizes = _unpack_efficient_attention_nested_shapes query=query key=key value=value cu_seqlens_q=cu_seqlens_q cu_seqlens_k=cu_seqlens_k max_seqlen_q=max_seqlen_q max_seqlen_k=max_seqlen_k sum sdpa_flop_count query_shape key_shape value_shape query_shape key_shape value_shape _ sizes sdpa_backward_flop_count grad_out_shape query_shape key_shape value_shape total_flops = b h s_q d_q = query_shape _b _h s_k _d = key_shape _b _h _s d_v = value_shape _b _h _s _d = grad_out_shape b == _b == _b == _b h == _h == _h == _h d_q == _d raise AssertionError sdpa_backward_flop_count batch heads dimension mismatch among tensors d_v == _d s_k == _s s_q == _s raise AssertionError sdpa_backward_flop_count grad_out value key query shapes incompatible total_flops = Step We recompute scores matrix q b h s_q d_q k b h d_q s_k - scores b h s_q s_k total_flops += bmm_flop b h s_q d_q b h d_q s_k Step We propagate gradients through score v operation gradOut b h s_q d_v v b h d_v s_k - gradScores b h s_q s_k total_flops += bmm_flop b h s_q d_v b h d_v s_k scores b h s_k s_q gradOut b h s_q d_v - gradV b h s_k d_v total_flops += bmm_flop b h s_k s_q b h s_q d_v Step We propagate th gradients through k v operation gradScores b h s_q s_k k b h s_k d_q - gradQ b h s_q d_q total_flops += bmm_flop b h s_q s_k b h s_k d_q q b h d_q s_q gradScores b h s_q s_k - gradK b h d_q s_k total_flops += bmm_flop b h d_q s_q b h s_q s_k total_flops register_flop_formula aten _scaled_dot_product_efficient_attention_backward aten _scaled_dot_product_flash_attention_backward aten _scaled_dot_product_cudnn_attention_backward sdpa_backward_flop grad_out_shape query_shape key_shape value_shape args out_shape=None kwargs - int Count flops self-attention backward sdpa_backward_flop_count grad_out_shape query_shape key_shape value_shape register_flop_formula aten _flash_attention_backward get_raw=True _flash_attention_backward_flop grad_out query key value out named _out_shape avoid kwarg collision out_shape created wrapper logsumexp cum_seq_q cum_seq_k max_q max_k args kwargs - int case nested tensor we unpack individual batch elements then sum flops per batch element shapes = _unpack_flash_attention_nested_shapes query=query key=key value=value grad_out=grad_out cum_seq_q=cum_seq_q cum_seq_k=cum_seq_k max_q=max_q max_k=max_k sum sdpa_backward_flop_count grad_out_shape query_shape key_shape value_shape query_shape key_shape value_shape grad_out_shape shapes register_flop_formula aten _efficient_attention_backward get_raw=True _efficient_attention_backward_flop grad_out query key value bias out named _out avoid kwarg collision out created wrapper cu_seqlens_q cu_seqlens_k max_seqlen_q max_seqlen_k args kwargs - int case nested tensor we unpack individual batch elements then sum flops per batch element shapes = _unpack_efficient_attention_nested_shapes query=query key=key value=value grad_out=grad_out cu_seqlens_q=cu_seqlens_q cu_seqlens_k=cu_seqlens_k max_seqlen_q=max_seqlen_q max_seqlen_k=max_seqlen_k sum sdpa_backward_flop_count grad_out_shape query_shape key_shape value_shape query_shape key_shape value_shape grad_out_shape shapes flop_registry = aten mm mm_flop aten addmm addmm_flop aten bmm bmm_flop aten baddbmm baddbmm_flop aten _scaled_mm _scaled_mm_flop aten convolution conv_flop aten _convolution conv_flop aten cudnn_convolution conv_flop aten _slow_conv d_forward conv_flop aten convolution_backward conv_backward_flop aten _scaled_dot_product_efficient_attention sdpa_flop aten _scaled_dot_product_flash_attention sdpa_flop aten _scaled_dot_product_cudnn_attention sdpa_flop aten _scaled_dot_product_efficient_attention_backward sdpa_backward_flop aten _scaled_dot_product_flash_attention_backward sdpa_backward_flop aten _scaled_dot_product_cudnn_attention_backward sdpa_backward_flop aten _flash_attention_forward _flash_attention_forward_flop aten _efficient_attention_forward _efficient_attention_forward_flop aten _flash_attention_backward _flash_attention_backward_flop aten _efficient_attention_backward _efficient_attention_backward_flop normalize_tuple x isinstance x tuple x x Define suffixes different orders magnitude suffixes = K M B T Thanks BingChat get_suffix_str number Find index appropriate suffix based number digits some additional overflow i e B should displayed M B index = max min len suffixes - len str number - suffixes index convert_num_with_suffix number suffix index = suffixes index suffix Divide number ^index format two decimal places value = f number index f Return value suffix string value + suffixes index convert_to_percent_str num denom denom == f num denom _pytreeify_preserve_structure f wraps f nf args flat_args spec = tree_flatten args out = f flat_args tree_unflatten out spec nf FlopCounterMode ` ` FlopCounterMode ` ` context manager counts number flops within its context It does using ` ` TorchDispatchMode ` ` It also supports hierarchical output passing module list modules FlopCounterMode construction If you do need hierarchical output you do need use module Example usage code-block python mod = FlopCounterMode mod flop_counter mod sum backward __init__ mods Optional Union torch nn Module list torch nn Module = None depth int = display bool = True custom_mapping Optional dict Any Any = None super __init__ flop_counts dict str dict Any int = defaultdict lambda defaultdict int depth = depth display = display mode Optional _FlopCounterMode = None custom_mapping None custom_mapping = mods None warnings warn mods argument needed anymore you can stop passing stacklevel= flop_registry = flop_registry k v getattr v _get_raw False shape_wrapper v k v custom_mapping items mod_tracker = ModuleTracker get_total_flops - int sum flop_counts Global values get_flop_counts - dict str dict Any int Return flop counts dictionary dictionaries The outer dictionary keyed module name inner dictionary keyed operation name Returns Dict str Dict Any int The flop counts dictionary k dict v k v flop_counts items get_table depth=None depth None depth = depth depth None depth = tabulate tabulate PRESERVE_WHITESPACE = True header = Module FLOP Total values = global_flops = get_total_flops global_suffix = get_suffix_str global_flops is_global_subsumed = False process_mod mod_name depth nonlocal is_global_subsumed total_flops = sum flop_counts mod_name values is_global_subsumed &#124; = total_flops = global_flops padding = depth values = values append padding + mod_name convert_num_with_suffix total_flops global_suffix convert_to_percent_str total_flops global_flops k v flop_counts mod_name items values append padding + - + str k convert_num_with_suffix v global_suffix convert_to_percent_str v global_flops values mod sorted flop_counts keys mod == Global continue mod_depth = mod count + mod_depth depth continue cur_values = process_mod mod mod_depth - values extend cur_values We do bit messing around here only output Global value there any FLOPs there aren t already fully contained module Global flop_counts is_global_subsumed value values value = + value values = process_mod Global + values len values == values = Global tabulate tabulate values headers=header colalign= left right right NB This context manager NOT reentrant __enter__ flop_counts clear mod_tracker __enter__ mode = _FlopCounterMode mode __enter__ __exit__ args mode None raise AssertionError Internal error FlopCounter __exit__ called mode None b = mode __exit__ args mode = None break cycles mod_tracker __exit__ display print get_table depth b _count_flops func_packet out args kwargs func_packet flop_registry flop_count_func = flop_registry func_packet flop_count = flop_count_func args kwargs out_val=out type ignore operator par set mod_tracker parents flop_counts par func_packet += flop_count out _FlopCounterMode TorchDispatchMode supports_higher_order_operators = True __init__ counter FlopCounterMode counter = counter _execute_with_isolated_flop_counting branch_fn operands Execute branch function capture its FLOP counts without affecting counter flop_counts Args branch_fn The branch function execute operands Arguments pass branch function Returns Tuple result flop_counts where result branch output flop_counts copy FLOP counts after execution copy checkpointed_flop_counts = copy copy counter flop_counts result = branch_fn operands flop_counts = copy copy counter flop_counts counter flop_counts = checkpointed_flop_counts result flop_counts _handle_higher_order_ops func types args kwargs func torch ops higher_order cond NotImplemented The flop counter cond counts upper bound flops For example matmul executed times true branch only time false branch flop counter will record larger number flops i e times func torch ops higher_order cond pred true_branch false_branch operands = args Step Count flops true branch false branch separately true_out true_flop_counts = _execute_with_isolated_flop_counting true_branch operands true_out NotImplemented NotImplemented false_out false_flop_counts = _execute_with_isolated_flop_counting false_branch operands false_out NotImplemented NotImplemented Step merge flop counts all_mod_keys = set true_flop_counts keys &#124; set false_flop_counts keys merged_flop_counts = outer_key all_mod_keys true_func_counts = true_flop_counts outer_key false_func_counts = false_flop_counts outer_key merged_func_counts = all_func_keys = set true_func_counts keys &#124; set false_func_counts keys func_key all_func_keys true_val = true_func_counts get func_key false_val = false_func_counts get func_key merged_func_counts func_key = max true_val false_val merged_flop_counts outer_key = merged_func_counts Step update counter merged counts outer_key inner_dict merged_flop_counts items counter flop_counts outer_key update inner_dict It doesn t matter which one we since true_fn false_fn output same structure true_out __torch_dispatch__ func types args= kwargs=None kwargs = kwargs kwargs Skip ops non-standard dispatch_sizes_strides_policy such NJT func torch ops aten sym_is_contiguous default torch ops aten is_contiguous default torch ops aten is_contiguous memory_format torch ops aten is_strides_like_format default torch ops aten is_non_overlapping_and_dense default torch ops aten size default torch ops aten sym_size default torch ops aten stride default torch ops aten sym_stride default torch ops aten storage_offset default torch ops aten sym_storage_offset default torch ops aten numel default torch ops aten sym_numel default torch ops aten dim default torch ops prim layout default NotImplemented isinstance func torch _ops HigherOrderOperator _handle_higher_order_ops func types args kwargs If we don t have func flop_registry see can decompose func counter flop_registry func torch ops prim device default r = func decompose args kwargs r NotImplemented r no further decomposition execute count flops out = func args kwargs counter _count_flops func _overloadpacket out args kwargs