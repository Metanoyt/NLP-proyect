Owner s module onnx os unittest collections OrderedDict collections abc Mapping onnx_test_common parameterized PIL pytorch_test_common test_models torchvision pytorch_test_common skipIfUnsupportedMinOpsetVersion skipScriptTest torchvision ops torchvision models detection faster_rcnn image_list keypoint_rcnn mask_rcnn roi_heads rpn transform torch torch nn torch testing _internal common_utils exportTest model inputs rtol= e- atol= e- opset_versions=None acceptable_error_percentage=None opset_versions = opset_versions opset_versions opset_version opset_versions opset_version = opset_version onnx_shape_inference = True onnx_test_common run_model_test model input_args=inputs rtol=rtol atol=atol acceptable_error_percentage=acceptable_error_percentage is_script_test_enabled opset_version script_model = torch jit script model onnx_test_common run_model_test script_model input_args=inputs rtol=rtol atol=atol acceptable_error_percentage=acceptable_error_percentage TestModels = type TestModels pytorch_test_common ExportTestCase dict test_models TestModels __dict__ is_script_test_enabled=False is_script=False exportTest=exportTest model tests scripting new JIT APIs shape inference TestModels_new_jit_API = type TestModels_new_jit_API pytorch_test_common ExportTestCase dict TestModels __dict__ exportTest=exportTest is_script_test_enabled=True is_script=True onnx_shape_inference=True _get_image rel_path str size tuple int int - torch Tensor data_dir = os path join os path dirname __file__ assets path = os path join data_dir rel_path split image = PIL Image open path convert RGB resize size PIL Image BILINEAR torchvision transforms ToTensor image _get_test_images - tuple list torch Tensor list torch Tensor _get_image grace_hopper_ x jpg _get_image rgb_pytorch png _get_features images s s = images shape - features = torch rand s s torch rand s s torch rand s s torch rand s s torch rand s s features = OrderedDict features features _init_test_generalized_rcnn_transform min_size = max_size = image_mean = image_std = transform GeneralizedRCNNTransform min_size max_size image_mean image_std _init_test_rpn anchor_sizes = aspect_ratios = len anchor_sizes rpn_anchor_generator = rpn AnchorGenerator anchor_sizes aspect_ratios out_channels = rpn_head = rpn RPNHead out_channels rpn_anchor_generator num_anchors_per_location rpn_fg_iou_thresh = rpn_bg_iou_thresh = rpn_batch_size_per_image = rpn_positive_fraction = rpn_pre_nms_top_n = dict training= testing= rpn_post_nms_top_n = dict training= testing= rpn_nms_thresh = rpn_score_thresh = rpn RegionProposalNetwork rpn_anchor_generator rpn_head rpn_fg_iou_thresh rpn_bg_iou_thresh rpn_batch_size_per_image rpn_positive_fraction rpn_pre_nms_top_n rpn_post_nms_top_n rpn_nms_thresh score_thresh=rpn_score_thresh _init_test_roi_heads_faster_rcnn out_channels = num_classes = box_fg_iou_thresh = box_bg_iou_thresh = box_batch_size_per_image = box_positive_fraction = bbox_reg_weights = None box_score_thresh = box_nms_thresh = box_detections_per_img = box_roi_pool = ops MultiScaleRoIAlign featmap_names= output_size= sampling_ratio= resolution = box_roi_pool output_size representation_size = box_head = faster_rcnn TwoMLPHead out_channels resolution representation_size representation_size = box_predictor = faster_rcnn FastRCNNPredictor representation_size num_classes roi_heads RoIHeads box_roi_pool box_head box_predictor box_fg_iou_thresh box_bg_iou_thresh box_batch_size_per_image box_positive_fraction bbox_reg_weights box_score_thresh box_nms_thresh box_detections_per_img parameterized parameterized_class is_script True False class_name_func=onnx_test_common parameterize_class_name TestModelsONNXRuntime onnx_test_common _TestONNXRuntime skipIfUnsupportedMinOpsetVersion skipScriptTest Faster RCNN model scriptable test_faster_rcnn model = faster_rcnn fasterrcnn_resnet _fpn pretrained=False pretrained_backbone=True min_size= max_size= model eval x = torch randn requires_grad=True x = torch randn requires_grad=True run_test model x x rtol= e- atol= e- run_test model x x input_names= images_tensors output_names= outputs dynamic_axes= images_tensors outputs rtol= e- atol= e- dummy_image = torch ones images test_images = _get_test_images run_test model images additional_test_inputs= images test_images dummy_image input_names= images_tensors output_names= outputs dynamic_axes= images_tensors outputs rtol= e- atol= e- run_test model dummy_image additional_test_inputs= dummy_image images input_names= images_tensors output_names= outputs dynamic_axes= images_tensors outputs rtol= e- atol= e- unittest skip Failing after ONNX skipIfUnsupportedMinOpsetVersion skipScriptTest test_mask_rcnn model = mask_rcnn maskrcnn_resnet _fpn pretrained=False pretrained_backbone=True min_size= max_size= images test_images = _get_test_images run_test model images rtol= e- atol= e- run_test model images input_names= images_tensors output_names= boxes labels scores masks dynamic_axes= images_tensors boxes labels scores masks rtol= e- atol= e- dummy_image = torch ones run_test model images additional_test_inputs= images test_images dummy_image input_names= images_tensors output_names= boxes labels scores masks dynamic_axes= images_tensors boxes labels scores masks rtol= e- atol= e- run_test model dummy_image additional_test_inputs= dummy_image images input_names= images_tensors output_names= boxes labels scores masks dynamic_axes= images_tensors boxes labels scores masks rtol= e- atol= e- unittest skip Failing see https github com pytorch pytorch issues skipIfUnsupportedMinOpsetVersion skipScriptTest test_keypoint_rcnn model = keypoint_rcnn keypointrcnn_resnet _fpn pretrained=False pretrained_backbone=False min_size= max_size= images test_images = _get_test_images run_test model images rtol= e- atol= e- run_test model images input_names= images_tensors output_names= outputs outputs outputs outputs dynamic_axes= images_tensors rtol= e- atol= e- dummy_images = torch ones run_test model images additional_test_inputs= images test_images dummy_images input_names= images_tensors output_names= outputs outputs outputs outputs dynamic_axes= images_tensors rtol= e- atol= e- run_test model dummy_images additional_test_inputs= dummy_images test_images input_names= images_tensors output_names= outputs outputs outputs outputs dynamic_axes= images_tensors rtol= e- atol= e- skipIfUnsupportedMinOpsetVersion skipScriptTest test_roi_heads RoIHeadsModule torch nn Module __init__ - None super __init__ transform = _init_test_generalized_rcnn_transform rpn = _init_test_rpn roi_heads = _init_test_roi_heads_faster_rcnn forward images features Mapping str torch Tensor original_image_sizes = img shape - img shape - img images images_m = image_list ImageList images i shape - i shape - i images proposals _ = rpn images_m features detections _ = roi_heads features proposals images_m image_sizes detections = transform postprocess detections images_m image_sizes original_image_sizes detections images = torch rand features = _get_features images images = torch rand test_features = _get_features images model = RoIHeadsModule model eval model images features run_test model images features input_names= input input input input input input dynamic_axes= input input input input input input additional_test_inputs= images features images test_features skipScriptTest TODO skipIfUnsupportedMinOpsetVersion test_transformer_encoder MyModule torch nn Module __init__ ninp nhead nhid dropout nlayers super __init__ encoder_layers = nn TransformerEncoderLayer ninp nhead nhid dropout transformer_encoder = nn TransformerEncoder encoder_layers nlayers forward input transformer_encoder input x = torch rand run_test MyModule x atol= e- skipScriptTest test_mobilenet_v model = torchvision models quantization mobilenet_v _large pretrained=False dummy_input = torch randn run_test model dummy_input skipIfUnsupportedMinOpsetVersion skipScriptTest test_shufflenet_v _dynamic_axes model = torchvision models shufflenet_v _x _ weights=None dummy_input = torch randn requires_grad=True test_inputs = torch randn requires_grad=True run_test model dummy_input additional_test_inputs= dummy_input test_inputs input_names= input_images output_names= outputs dynamic_axes= input_images batch_size output batch_size rtol= e- atol= e- __name__ == __main__ common_utils run_tests