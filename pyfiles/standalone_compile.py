__future__ annotations copy logging os pickle shutil abc ABC abstractmethod contextlib AbstractContextManager nullcontext typing Any Callable Literal Optional TYPE_CHECKING torch fx torch _dynamo aot_compile_types BundledAOTAutogradSerializableCallable torch _dynamo utils dynamo_timed torch _inductor cpp_builder normalize_path_separator torch _inductor cudagraph_utils BoxedDeviceIndex torch _inductor runtime cache_dir_utils temporary_cache_dir torch _inductor utils BoxedBool InputType torch _subclasses FakeTensorMode torch fx experimental symbolic_shapes ShapeEnv config TYPE_CHECKING collections abc Sequence torch compiler _cache CacheInfo torch fx GraphModule log = logging getLogger __name__ CompiledArtifact ABC CompiledArtifact represents inductor cache artifacts can invoked order avoid repeated compilation CompiledArtifact can obtained calling standalone_compile gm example_inputs create fresh CompiledArtifact GraphModule example inputs Later CompiledArtifact can saved disk either binary unpacked into provided folder via CompiledArtifact save function CompiledArtifact load provides way create CompiledArtifact binary unpacked data Finally CompiledArtifact can invoked via __call__ method execute cached artifact __init__ compiled_fn Callable Any artifacts Optional tuple bytes CacheInfo _compiled_fn = compiled_fn _artifacts = artifacts abstractmethod __call__ args Any - Any abstractmethod save path str format Literal binary unpacked = binary - None staticmethod load path str format Literal binary unpacked = binary - CompiledArtifact format == unpacked If format unpacked must CacheCompiledArtifact CacheCompiledArtifact load path=path format=format assert format == binary open path rb file torch utils _appending_byte_serializer BytesReader codecache torch_key result_bytes = file read reader = BytesReader result_bytes header = reader read_bytes header == AOTCompiledArtifact AOT_HEADER assert reader read_bytes == torch_key artifact = reader read_bytes assert reader is_finished AOTCompiledArtifact deserialize artifact Otherwise s CacheCompiledArtifact format header == CacheCompiledArtifact CACHE_HEADER assert reader read_bytes == torch_key key = reader read_str artifact_bytes = reader read_bytes assert reader is_finished torch compiler load_cache_artifacts artifact_bytes CacheCompiledArtifact _load_impl nullcontext key raise RuntimeError Invalid header expected CacheCompiledArtifact AOTCompiledArtifact got + header decode utf- CacheCompiledArtifact CompiledArtifact CompiledArtifact depends torch compiler save_cache_artifacts CACHE_HEADER = bytes CacheCompiledArtifact utf- __init__ compiled_fn Callable Any artifacts Optional tuple bytes CacheInfo _compiled_fn = compiled_fn _artifacts = artifacts __call__ args Any - Any _compiled_fn args save path str format Literal binary unpacked = binary - None dynamo_timed CompiledArtifact save _artifacts None raise RuntimeError CompiledArtifact save failed save since there s no artifact save artifact_bytes cache_info = _artifacts assert len cache_info aot_autograd_artifacts == cache_info key = cache_info aot_autograd_artifacts format == binary can t assert file since might exist yet assert os path isdir path torch utils _appending_byte_serializer BytesWriter codecache torch_key writer = BytesWriter writer write_bytes CacheCompiledArtifact CACHE_HEADER writer write_bytes torch_key writer write_str key writer write_bytes artifact_bytes torch _inductor codecache write_atomic write_atomic path writer to_bytes assert format == unpacked os path exists path assert os path isdir path shutil rmtree path ignore_errors=True codecache FxGraphCache temporary_cache_dir path This function unpacks cache artifacts disk loaded_cache_info = torch compiler load_cache_artifacts artifact_bytes assert loaded_cache_info None Now write all output_code artifacts disk so they can inspected modified key loaded_cache_info inductor_artifacts subdir = FxGraphCache _get_tmp_dir_for_key key assert os path exists subdir path sorted os listdir subdir open os path join subdir path rb f graph = pickle load f output_file = graph write_to_disk log info Output code written s output_file staticmethod _load_impl cache_dir_ctx AbstractContextManager Any key str - CompiledArtifact cache_dir_ctx config patch unsafe_skip_cache_dynamic_shape_guards=True torch _functorch config patch strict_autograd_cache=True torch _functorch _aot_autograd autograd_cache AOTAutogradCache result = AOTAutogradCache _lookup key local=True remote=False args= cache_info= aot_config=None assert result None entry _ = result compile_fx _CompileFxKwargs fx_config = _CompileFxKwargs cudagraphs=BoxedBool False boxed_forward_device_index=BoxedDeviceIndex context = torch _guards TracingContext FakeTensorMode shape_env=ShapeEnv torch _guards tracing context compiled_fn = entry wrap_post_compile entry sanitized_aot_config fx_config CacheCompiledArtifact lambda args compiled_fn list args None staticmethod _prepare_load path str format Literal binary unpacked = binary - tuple str AbstractContextManager Any Do format specific prep loads context manager key path = normalize_path_separator path dynamo_timed CompiledArtifact load format == binary can t assert file since might exist yet assert os path isdir path open path rb file artifacts = file read torch utils _appending_byte_serializer BytesReader codecache torch_key reader = BytesReader artifacts assert reader read_bytes == torch_key key = reader read_str artifact_bytes = reader read_bytes assert reader is_finished torch compiler load_cache_artifacts artifact_bytes key nullcontext assert format == unpacked assert os path isdir path autograd_cache_dir = os path join path aotautograd assert os path isdir autograd_cache_dir files = list os listdir autograd_cache_dir assert len files == key = files cache_dir_ctx = temporary_cache_dir path key cache_dir_ctx staticmethod load path str format Literal binary unpacked = binary - CompiledArtifact key cache_dir_ctx = CacheCompiledArtifact _prepare_load path=path format=format CacheCompiledArtifact _load_impl cache_dir_ctx key AOTCompiledArtifact CompiledArtifact Similar CompiledArtifact object single bundled precompiled function This object always serializable callable function This object essentially wrapper BundledAOTAutogradSerializableCallable which used torch _dynamo aot_compile AOT Precompilation AOT_HEADER = bytes AOTCompiledArtifact utf- __init__ compiled_fn Callable Any inner_fn = BundledAOTAutogradSerializableCallable compiled_fn _artifacts = None We don t need artifacts inner object handles everything staticmethod from_bundled_callable bundled_fn BundledAOTAutogradSerializableCallable - AOTCompiledArtifact AOTCompiledArtifact bundled_fn compiled_fn __call__ args Any - Any inner_fn args save path str format Literal binary unpacked = binary - None format == unpacked raise RuntimeError AOTCompiledArtifact does support unpacked format yet result_bytes = serialize torch utils _appending_byte_serializer BytesWriter codecache torch_key writer = BytesWriter writer write_bytes AOTCompiledArtifact AOT_HEADER writer write_bytes torch_key writer write_bytes result_bytes torch _inductor codecache write_atomic Save sentinel file indicate AOT write_atomic path writer to_bytes serialize - bytes BundledAOTAutogradSerializableCallable serialize_compile_artifacts inner_fn staticmethod deserialize result_bytes bytes - AOTCompiledArtifact deserialized = BundledAOTAutogradSerializableCallable deserialize_compile_artifacts result_bytes assert isinstance deserialized BundledAOTAutogradSerializableCallable AOTCompiledArtifact from_bundled_callable deserialized staticmethod load path str format Literal binary unpacked = binary - CompiledArtifact format == unpacked raise RuntimeError AOTCompiledArtifact does support unpacked format yet open path rb file torch utils _appending_byte_serializer BytesReader codecache torch_key result_bytes = file read reader = BytesReader result_bytes header = reader read_bytes assert header == AOTCompiledArtifact AOT_HEADER assert reader read_bytes == torch_key artifact = reader read_bytes assert reader is_finished AOTCompiledArtifact deserialize artifact standalone_compile gm GraphModule example_inputs Sequence InputType dynamic_shapes Any options Any aot bool = False AOT mode which uses BundledAOTAutogradCache - CompiledArtifact Implementation torch inductor standalone_compile torch compiler _cache CacheArtifactManager compile_fx compile_fx ignore_shape_env = False dynamic_shapes == from_example_inputs fake_mode = FakeTensorMode shape_env=ShapeEnv tells compile_fx ignore shape_envs ambient context graph_module ignore_shape_env = True dynamic_shapes == from_tracing_context Reuse fake_mode TracingContext NB The TracingContext only exists we re currently torch compile backend context = torch _guards TracingContext get assert context fake_mode None fake_mode = context fake_mode dynamic_shapes == from_graph fake_mode = FakeTensorMode shape_env=ShapeEnv Strategy find FakeTensor graph output grab its FakeTensorMode The graph passed standalone_compile must Inductor-approved graph which means there least one Tensor output output node contains flat list Tensors last_node = next iter reversed gm graph nodes assert last_node op == output assert len last_node args == handle_node node torch fx Node - None nonlocal fake_mode example_value node meta maybe_tensor = node meta example_value isinstance maybe_tensor torch _subclasses fake_tensor FakeTensor fake_mode = maybe_tensor fake_mode If gm came Dynamo then last_node args always list even single-Tensor returns It s possible get into situation where last_node args Node list This happens you call split_module graph We allow case since common isinstance last_node args torch fx Node handle_node last_node args node last_node args handle_node node raise ValueError f standalone_compile got unsupported ` dynamic_shapes ` value dynamic_shapes= dynamic_shapes context = torch _guards TracingContext fake_mode torch _guards tracing context CacheArtifactManager with_fresh_cache config patch triton autotune_at_compile_time True torch _functorch config patch bundled_autograd_cache aot compile_fx can mutate gm gm = copy deepcopy gm compiled_fn = compile_fx gm example_inputs ignore_shape_env=ignore_shape_env options assert callable compiled_fn aot hasattr compiled_fn serialize raise RuntimeError Compiled function should have serialize method when aot=True AOTCompiledArtifact compiled_fn artifacts = torch compiler save_cache_artifacts artifacts None log warning standalone_compile artifact generation failed cannot save Run TORCH_LOGS=+torch _inductor codecache identify problem CacheCompiledArtifact compiled_fn artifacts