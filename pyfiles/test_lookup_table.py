Owner s module inductor re unittest functools partial typing Any Optional Union unittest mock patch torch torch nn nn torch _inductor config inductor_config torch _inductor choices InductorChoices torch _inductor kernel_inputs MMKernelInputs torch _inductor lookup_table choices LookupTableChoices torch _inductor select_algorithm add_preprocessing_fn clear_preprocessing_fns ExternKernelCaller TritonTemplateCaller torch _inductor test_case run_tests TestCase torch _inductor utils fresh_cache get_num_sms TMA_DESCRIPTOR_SIZE torch _inductor virtualized V torch testing _internal common_utils instantiate_parametrized_tests parametrize TEST_WITH_ROCM torch testing _internal inductor_utils HAS_CPU HAS_CUDA_AND_TRITON HAS_GPU torch utils _triton has_triton_stable_tma_api has_triton_tma_device MockTensorNode Mock input node wraps real tensor testing __init__ tensor torch Tensor tensor = tensor get_device - torch device tensor device get_dtype - torch dtype tensor dtype get_size - tuple int tuple tensor shape get_stride - tuple int tuple tensor stride MockMMKernelInputs MMKernelInputs Mock MMKernelInputs subclasses real uses real tensors __init__ tensors list torch Tensor scalars Optional dict str Union float int = None mat _idx int = - mat _idx int = - Initialize real tensors creating mock nodes base mock_nodes = MockTensorNode t t tensors super __init__ mock_nodes scalars mat _idx=mat _idx mat _idx=mat _idx tensors = tensors Keep reference original tensors shapes_hinted - tuple tuple int Delegate symbolic since real tensors already have int shapes shapes_symbolic strides_hinted - tuple tuple int Delegate symbolic since real tensors already have int strides strides_symbolic pyre-ignore mnk_hinted - tuple int int int Delegate symbolic since real tensors already have int dimensions mnk_symbolic pyre-ignore property device_type - Optional str tensors device type BaseLookupTableTest TestCase Base lookup table tests common setup utilities setUp super setUp original_table = inductor_config lookup_table table original_max_autotune = getattr inductor_config max_autotune False inductor_config max_autotune = True Set lookup table choices handler V set_choices_handler LookupTableChoices tearDown inductor_config lookup_table table = original_table inductor_config max_autotune = original_max_autotune Restore original choices handler V set_choices_handler InductorChoices super tearDown create_mock_mm_kernel_inputs shapes Optional list tuple int = None device torch device = torch device cuda dtype torch dtype = torch float scalars Optional dict str Union float int = None - MockMMKernelInputs Create MockMMKernelInputs real tensors shapes None shapes = Default MM shapes tensors = shape shapes Create real tensor specified shape device dtype tensor = torch randn shape device=device dtype=dtype tensors append tensor MockMMKernelInputs tensors scalars create_lookup_key method kernel_inputs Create lookup key using LookupTableChoices choices = LookupTableChoices choices make_lookup_key kernel_inputs method create_config template_id kwargs Create backend configuration template_id field config = template_id template_id Add minimal defaults based template type template_id == triton config update BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M template_id == tma config update BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M template_id == decompose_k config update k config update kwargs config unittest skipIf HAS_CUDA_AND_TRITON CUDA available instantiate_parametrized_tests TestLookupTable BaseLookupTableTest Consolidated tests lookup table functionality test_lookup_mismatch Test mismatch scenario lookup table kernel_inputs = create_mock_mm_kernel_inputs lookup_table_data = create_lookup_key mm kernel_inputs create_config triton patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices looking addmm created entry mm - should mismatch key empty result result = test_choices lookup_template_configs kernel_inputs addmm triton assertEqual result test_successful_lookup_with_template_filtering Test successful lookup filters configs template_id kernel_inputs = create_mock_mm_kernel_inputs config_list = create_config triton BLOCK_M= BLOCK_N= create_config triton BLOCK_M= BLOCK_N= create_config tma BLOCK_M= BLOCK_N= create_config decompose_k k_split= lookup_table_data = create_lookup_key mm kernel_inputs config_list patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices Test triton template filtering result = test_choices lookup_template_configs kernel_inputs mm triton assert result None Result should None assertEqual len result triton config result triton assertNotIn template_id config assertIn BLOCK_M config Test tma template filtering result = test_choices lookup_template_configs kernel_inputs mm tma assert result None Result should None assertEqual len result tma assertNotIn template_id result tma assertEqual result tma BLOCK_M Test decompose_k template filtering result = test_choices lookup_template_configs kernel_inputs mm decompose_k assert result None Result should None assertEqual len result decompose_k assertNotIn template_id result decompose_k assertEqual result decompose_k k_split test_empty_table Test when template lookup table empty kernel_inputs = create_mock_mm_kernel_inputs patch object inductor_config lookup_table table test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton assertEqual result test_validation_error Test validation error invalid config kernel_inputs = create_mock_mm_kernel_inputs invalid_config = BLOCK_M missing template_id lookup_table_data = create_lookup_key mm kernel_inputs invalid_config patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices assertRaises ValueError cm test_choices lookup_template_configs kernel_inputs mm triton assertIn missing required template_id field str cm exception test_cpu_input_returns_empty Test CPU tensor input returns empty dict Create kernel inputs CPU tensors kernel_inputs = create_mock_mm_kernel_inputs device=torch device cpu lookup_table_data = create_lookup_key mm kernel_inputs create_config triton patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton assertEqual result Should empty dict CPU test_multiple_calls_work Test calling lookup functions multiple times works correctly kernel_inputs = create_mock_mm_kernel_inputs config_list = create_config triton BLOCK_M= create_config tma BLOCK_M= lookup_table_data = create_lookup_key mm kernel_inputs config_list patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices First calls result = test_choices lookup_template_configs kernel_inputs mm triton result = test_choices lookup_template_configs kernel_inputs mm tma assert result None Result should None assert result None Result should None assertEqual len result triton assertEqual len result tma Second calls should work same result = test_choices lookup_template_configs kernel_inputs mm triton result = test_choices lookup_template_configs kernel_inputs mm tma assert result None Result should None assert result None Result should None assertEqual len result triton assertEqual len result tma test_batch_lookup_mixed_entries Test batch lookup where some templates have entries others don t kernel_inputs = create_mock_mm_kernel_inputs config_list = create_config triton BLOCK_M= create_config tma BLOCK_M= No decompose_k config lookup table lookup_table_data = create_lookup_key mm kernel_inputs config_list patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices Test batch lookup mixed results result = test_choices lookup_template_configs kernel_inputs mm triton tma decompose_k assert result None Result should None Should have entries triton tma decompose_k assertIn triton result assertIn tma result assertNotIn decompose_k result assertEqual len result triton assertEqual len result tma assertEqual result triton BLOCK_M assertEqual result tma BLOCK_M parametrize config_hash template_hash expected_kept Hash matching config kept hash hash True Hash mismatch config filtered hash hash False Config without hash config kept None hash True Template without hash config kept hash None True Both None config kept None None True test_template_hash_checking config_hash template_hash expected_kept Test template hash validation behavior kernel_inputs = create_mock_mm_kernel_inputs config = create_config triton BLOCK_M= BLOCK_N= config_hash None config template_hash = config_hash template_hash_map = triton template_hash template_hash None lookup_table_data = create_lookup_key mm kernel_inputs config patch object inductor_config lookup_table table lookup_table_data patch object inductor_config lookup_table check_src_hash True test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton template_hash_map expected_kept assert result None Result should None assertIn triton result assertEqual len result triton template_hash should removed returned config assertNotIn template_hash result triton Config filtered out due hash mismatch assertEqual result test_template_hash_checking_disabled Test hash checking skipped when config flag disabled kernel_inputs = create_mock_mm_kernel_inputs Create config mismatching hash config = create_config triton BLOCK_M= template_hash= hash Provide different template hash would normally cause filtering template_hash_map = triton hash lookup_table_data = create_lookup_key mm kernel_inputs config patch object inductor_config lookup_table table lookup_table_data patch object inductor_config lookup_table check_src_hash False test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton template_hash_map Should keep config even mismatching hash since checking disabled assert result None Result should None assertIn triton result assertEqual len result triton template_hash should still removed returned config assertNotIn template_hash result triton test_template_hash_mixed_scenarios Test mixed hash scenarios multiple configs kernel_inputs = create_mock_mm_kernel_inputs config_list = create_config triton BLOCK_M= template_hash= correct_hash Should kept create_config triton BLOCK_M= template_hash= wrong_hash Should filtered create_config triton BLOCK_M= No hash should kept template_hash_map = triton correct_hash lookup_table_data = create_lookup_key mm kernel_inputs config_list patch object inductor_config lookup_table table lookup_table_data patch object inductor_config lookup_table check_src_hash True test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton template_hash_map assert result None Result should None assertIn triton result Should keep configs one correct hash one without hash assertEqual len result triton Check kept configs have expected BLOCK_M values kept_block_ms = config BLOCK_M config result triton assertIn kept_block_ms Config correct hash assertIn kept_block_ms Config without hash assertNotIn kept_block_ms Config wrong hash should filtered template_hash should removed returned configs config result triton assertNotIn template_hash config parametrize config_hash description definitely_malformed_hash_ #$ malformed hash non-string hash empty string hash None missing hash field test_hash_checking_disabled_edge_cases config_hash description Test configs kept when hash checking disabled regardless hash validity kernel_inputs = create_mock_mm_kernel_inputs Create config potentially problematic hash config = create_config triton BLOCK_M= config_hash None config template_hash = config_hash If config_hash None don t add template_hash field all Provide valid template hash would normally used comparison template_hash_map = triton valid_template_hash_abc lookup_table_data = create_lookup_key mm kernel_inputs config patch object inductor_config lookup_table table lookup_table_data patch object inductor_config lookup_table check_src_hash False test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton template_hash_map Should keep config regardless hash validity since checking disabled assert result None f Result should None description assertIn triton result f Should have triton result description assertEqual len result triton f Should have config description template_hash should removed returned config assertNotIn template_hash result triton f template_hash should removed result description Other config fields should preserved assertEqual result triton BLOCK_M f BLOCK_M should preserved description parametrize table_has_device_key lookup_device_matches expected_found Device-specific key table same device - found True True True Device-specific key table different device - found True False False Device-agnostic key table same device - found False True True Device-agnostic key table different device - found device-agnostic False False True test_device_key_lookup_scenarios table_has_device_key lookup_device_matches expected_found Test lookup behavior device-specific vs device-agnostic keys Create kernel inputs device_ our reference device kernel_inputs_device = create_mock_mm_kernel_inputs Create config config = create_config triton BLOCK_M= Create test choices generating table key TableKeyChoices LookupTableChoices staticmethod _get_device_key device device type = cuda None device_ Always device_ table key generation table_key_choices = TableKeyChoices Generate table key based whether should include device table_has_device_key table_key = table_key_choices make_lookup_key kernel_inputs_device mm include_device=True table_key = table_key_choices make_lookup_key kernel_inputs_device mm include_device=False lookup_table_data = table_key config Create test choices actual lookup different device behavior lookup_device_matches TestChoices LookupTableChoices staticmethod _get_device_key device device type = cuda None device_ TestChoices LookupTableChoices staticmethod _get_device_key device device type = cuda None device_ patch object inductor_config lookup_table table lookup_table_data test_choices = TestChoices result = test_choices lookup_template_configs kernel_inputs_device mm triton expected_found assert result None f Result should None when expected_found= expected_found assertIn triton result Should have triton result when found assertEqual len result triton Should have exactly config assertEqual result triton BLOCK_M Config should preserved assertEqual result f Should empty dict when expected_found= expected_found test_device_key_priority Test device-specific keys take priority over device-agnostic keys kernel_inputs = create_mock_mm_kernel_inputs Create two different configs device_specific_config = create_config triton BLOCK_M= Different BLOCK_M device_agnostic_config = create_config triton BLOCK_M= Create test choices instance generate keys key_choices = LookupTableChoices Create both key types same inputs device_key = key_choices make_lookup_key kernel_inputs mm include_device=True device_agnostic_key = key_choices make_lookup_key kernel_inputs mm include_device=False Put both table lookup_table_data = device_key device_specific_config device_agnostic_key device_agnostic_config patch object inductor_config lookup_table table lookup_table_data test_choices = LookupTableChoices result = test_choices lookup_template_configs kernel_inputs mm triton Should get device-specific config BLOCK_M= device-agnostic BLOCK_M= assert result None Result should None assertIn triton result assertEqual len result triton assertEqual result triton BLOCK_M Should use device-specific config when both exist test_make_lookup_key_variants Test make_lookup_key_variants helper function kernel_inputs = create_mock_mm_kernel_inputs test_choices = LookupTableChoices device_key device_agnostic_key = test_choices make_lookup_key_variants kernel_inputs mm Both should strings assertIsInstance device_key str assertIsInstance device_agnostic_key str Device key should longer contains device info assertGreater len device_key len device_agnostic_key Device-agnostic key should contained device key substring after device part assertIn device_agnostic_key split +mm device_key UnifiedModel nn Module Unified model different matrix operations __init__ operation= mm super __init__ operation = operation forward args operation == mm torch mm args args operation == addmm torch addmm args args args operation == bmm torch bmm args args operation == mm_plus_mm torch mm args args + torch mm args args raise ValueError f Unsupported operation operation verify_choice_names choices list Any pattern str expected_count int = Verify choices match expected pattern count len choices = expected_count raise ValueError f Expected expected_count choices got len choices choice choices re search pattern choice name raise ValueError f Choice name choice name doesn t match pattern pattern choices BaseE ELookupTableTest BaseLookupTableTest Base E E lookup table tests setUp torch _dynamo reset clear_preprocessing_fns device = torch device cuda dev_key = LookupTableChoices _get_device_key device original_lookup_table = inductor_config lookup_table table Set lookup table choices handler V set_choices_handler LookupTableChoices tearDown inductor_config lookup_table table = original_lookup_table Restore original choices handler V set_choices_handler InductorChoices clear_preprocessing_fns create_tensors operation b= m= n= k= Create test tensors operations configurable dimensions operation mm addmm mm_plus_mm A = torch randn m k device=self device dtype=torch float B = torch randn k n device=self device dtype=torch float operation == mm A B operation == addmm torch randn m n device=self device dtype=torch float A B operation == mm_plus_mm A B torch randn m k device=self device dtype=torch float torch randn k n device=self device dtype=torch float operation == bmm torch randn b m k device=self device dtype=torch float torch randn b k n device=self device dtype=torch float raise ValueError f Unsupported operation operation setup_lookup_table operation tensors configs Setup lookup table configuration scalars = operation addmm baddbmm scalars beta = scalars alpha = mock_kernel_inputs = MockMMKernelInputs tensors scalars flat_key = create_lookup_key operation mock_kernel_inputs inductor_config lookup_table table = flat_key configs run_model operation tensors config_patches=None Run compiled model configuration config = max_autotune_gemm True test_configs max_mm_configs config_patches config update config_patches model = UnifiedModel operation inductor_config patch config compiled_model = torch compile model device compiled_model tensors create_basic_config template_id Create basic configuration template configs = torch _inductor kernel mm mm_template uid BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M torch _inductor kernel mm_plus_mm mm_plus_mm_template uid BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M torch _inductor kernel bmm bmm_template uid BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M torch _inductor kernel mm persistent_tma_mm_template uid BLOCK_M BLOCK_N BLOCK_K num_stages num_warps EVEN_K True USE_FAST_ACCUM False ACC_TYPE tl float GROUP_M A_ROW_MAJOR True B_ROW_MAJOR True NUM_SMS get_num_sms TMA_SIZE TMA_DESCRIPTOR_SIZE TMA_EXPERIMENTAL_API has_triton_stable_tma_api torch _inductor kernel mm aten_bias_addmm uid torch _inductor kernel mm decompose_k_subgraph_template uid k_split template_id template_id configs get template_id _create_simple_matmul_model Create simple matmul model recording tests SimpleMatmul nn Module forward b torch mm b SimpleMatmul _create_test_inputs device= cuda Create test inputs matmul torch randn device=device dtype=torch float torch randn device=device dtype=torch float unittest skipIf TEST_WITH_ROCM ROCm doesn t support lookup table unittest skipIf HAS_CUDA_AND_TRITON CUDA available instantiate_parametrized_tests TestLookupTableE E BaseE ELookupTableTest E E tests lookup table functionality parametrize max_autotune True False fresh_cache test_no_lookup_table_entry_autotune_modes max_autotune Test when there s no lookup table entry different autotune modes tensors = create_tensors mm Setup lookup table different key force no match setup_lookup_table mm torch randn device=self device torch randn device=self device Inline validation function validate_choices choices max_autotune assert len choices f Max-autotune should have choices got len choices assert any isinstance c ExternKernelCaller c choices Should have ExternKernelCaller assert any isinstance c TritonTemplateCaller c choices Should have TritonTemplateCaller assert len choices == f No max-autotune should have choice got len choices assert isinstance choices ExternKernelCaller f Should ExternKernelCaller got type choices choices add_preprocessing_fn validate_choices run_model mm tensors max_autotune_gemm max_autotune max_autotune max_autotune parametrize operation mm addmm bmm mm_plus_mm fresh_cache test_valid_lookup_table_entry operation Test when there s valid entry operation k = operation == mm_plus_mm tensors = create_tensors operation k=k Map operation actual template UID template_mapping = mm torch _inductor kernel mm mm_template uid addmm torch _inductor kernel mm mm_template uid bmm torch _inductor kernel bmm bmm_template uid mm_plus_mm torch _inductor kernel mm_plus_mm mm_plus_mm_template uid template_id = template_mapping operation config = create_basic_config template_id setup_lookup_table operation tensors config add_preprocessing_fn partial verify_choice_names pattern= triton_ expected_count= run_model operation tensors unittest skipIf has_triton_tma_device Need TMA support parametrize operation mm addmm fresh_cache test_tma_lookup_table_entry operation Test TMA template entry tensors = create_tensors operation config = create_basic_config torch _inductor kernel mm persistent_tma_mm_template uid setup_lookup_table operation tensors config add_preprocessing_fn partial verify_choice_names pattern= triton_mm_persistent_tma_ expected_count= run_model operation tensors triton enable_persistent_tma_matmul True fresh_cache test_decompose_k_lookup_table_entry Test decompose_k template entry tensors = create_tensors mm m= n= k= config = create_basic_config torch _inductor kernel mm decompose_k_subgraph_template uid setup_lookup_table mm tensors config add_preprocessing_fn partial verify_choice_names pattern= decompose_k &#124; bmm_dtype expected_count= run_model mm tensors fresh_cache test_bias_addmm_lookup_table_entry Test bias_addmm template entry Create bias stride == bias_addmm eligibility bias_unexpanded = torch randn device=self device dtype=torch float expanded_bias = bias_unexpanded expand tensors = expanded_bias torch randn device=self device dtype=torch float torch randn device=self device dtype=torch float config = create_basic_config torch _inductor kernel mm aten_bias_addmm uid setup_lookup_table addmm tensors config add_preprocessing_fn partial verify_choice_names pattern= bias_addmm expected_count= Run original unexpanded bias inductor_config patch max_autotune_gemm True triton autotune_cublasLt True model = UnifiedModel addmm compiled_model = torch compile model device mode= max-autotune compiled_model bias_unexpanded tensors tensors unittest skipIf has_triton_tma_device Need TMA support fresh_cache test_multiple_configs_same_template Test multiple configurations same template tensors = create_tensors mm config = create_basic_config torch _inductor kernel mm persistent_tma_mm_template uid config update BLOCK_M BLOCK_N num_warps config = create_basic_config torch _inductor kernel mm persistent_tma_mm_template uid config update BLOCK_M BLOCK_N num_warps setup_lookup_table mm tensors config config add_preprocessing_fn partial verify_choice_names pattern= triton_mm_persistent_tma_ expected_count= run_model mm tensors triton enable_persistent_tma_matmul True unittest skipIf has_triton_tma_device Need TMA support fresh_cache test_mixed_template_configs Test mixing different template types tensors = create_tensors mm triton_config = create_basic_config torch _inductor kernel mm mm_template uid triton_config update BLOCK_M num_warps tma_config = create_basic_config torch _inductor kernel mm persistent_tma_mm_template uid tma_config update BLOCK_M num_warps setup_lookup_table mm tensors triton_config tma_config add_preprocessing_fn partial verify_choice_names pattern= triton_ expected_count= run_model mm tensors triton enable_persistent_tma_matmul True fresh_cache test_template_hash_filtering_e e Test end-to-end template hash filtering real MM operation tensors = create_tensors mm Get actual src_hash template actual_hash = torch _inductor kernel mm mm_template src_hash Create configs - one correct hash one wrong hash correct_config = create_basic_config torch _inductor kernel mm mm_template uid correct_config update BLOCK_M template_hash actual_hash Use actual hash wrong_config = create_basic_config torch _inductor kernel mm mm_template uid wrong_config update BLOCK_M template_hash definitely_wrong_hash_ Wrong hash setup_lookup_table mm tensors correct_config wrong_config Should only get choice since wrong hash config gets filtered add_preprocessing_fn partial verify_choice_names pattern= triton_ expected_count= Ensure hash checking enabled patch object inductor_config lookup_table check_src_hash True run_model mm tensors __name__ == __main__ torch _inductor utils is_big_gpu HAS_GPU HAS_CPU is_big_gpu run_tests