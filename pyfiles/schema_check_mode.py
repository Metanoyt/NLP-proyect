mypy ignore-errors collections namedtuple copy deepcopy itertools combinations torch torch fx operator_schemas normalize_function torch utils _pytree pytree torch utils _python_dispatch TorchDispatchMode torch utils _pytree tree_map Named Tuples used within SchemaCheckMode Mutation = namedtuple Mutation op_name arg_name Aliasing = namedtuple Aliasing op_name arg_name output_number Simplified naming C++ classes SchemaArgument = torch _C _SchemaArgument SchemaArgType = torch _C _SchemaArgType SchemaInfo = torch _C _SchemaInfo This TorchDispatchMode Subclass used verify op schemas This TorchDispatchMode Scubclass currently - Records called ops - Checks mutations all inputs - Checks aliasing all inputs move these functions here avoid numpy dependency testing _internal common_utils py is_iterable_of_tensors iterable Tensor itself iterable so we check first isinstance iterable torch Tensor False try len iterable == False t iter iterable isinstance t torch Tensor False except TypeError False True clone_inputs args inputs = arg args isinstance arg torch Tensor inputs append arg detach clone is_iterable_of_tensors arg inputs append t detach clone t arg inputs append arg inputs SchemaCheckMode TorchDispatchMode __init__ - None Information recorded testing purposes For example - incorrect schemas - overly conservative schemas ops = mutated = aliasing = reset_cache ops clear mutated clear aliasing clear display_ops print ops sep= __torch_dispatch__ func types args= kwargs=None bitwise_equal lhs rhs lhs is_quantized TODO This only OK can t have NaN quantized idk actually true torch equal lhs rhs torch allclose lhs rhs equal_nan=True has_mutated before after md are_tensors = type before torch Tensor type after torch Tensor are_tensors before layout = torch sparse_csr after layout = torch sparse_csr before size == after size bitwise_equal before after md == after stride md == after _typed_storage _cdata False has_aliased lhs rhs try torch _C _overlaps lhs rhs except Exception exception str exception startswith Cannot inspect value type False raise exception standardize_name name name name = input unwrap e isinstance e torch Tensor type e torch Tensor try e elem except AttributeError e e parse_metadata e isinstance e torch Tensor type e torch Tensor try current = e elem deepcopy current stride current _typed_storage _cdata except AttributeError None Sparse CSR tensors do have strides storage e layout = torch sparse_csr deepcopy e stride e _typed_storage _cdata None ops append func _schema name Clone process arguments outputs pre_arguments = normalize_function func args kwargs normalize_to_only_use_kwargs=True kwargs c_p_args = dict zip pre_arguments keys clone_inputs pre_arguments values cloned_arguments = name tree_map unwrap c_p_args get name name c_p_args cloned_metadata = name parse_metadata pytree tree_leaves pre_arguments get name name pre_arguments out = func args kwargs arguments = name tree_map unwrap pre_arguments get name name pre_arguments tuple_out = out isinstance out tuple out tuple_out = tree_map unwrap tuple_out schema_info = SchemaInfo func _schema schema_info add_argument_values pre_arguments Process arguments outputs i range len func _schema arguments arg = func _schema arguments i name = standardize_name arg name arguments get name None before = cloned_arguments get name md = cloned_metadata get name after = arguments get name j range len tuple_out aten _unsafe_view intended have incorrect aliasing notation hence unsafe unsafe_ops = aten _unsafe_view aten unsafe_split has_aliased tuple_out j after func _schema name unsafe_ops schema_info may_contain_alias SchemaArgument SchemaArgType output j SchemaArgument SchemaArgType input i raise RuntimeError f Argument name defined alias output aliasing aliasing append Aliasing func _schema name name f output_ j after tuple_out j isinstance after torch Tensor Only mutable ops e g add_ add out allowed directly inputs schema_info is_mutable SchemaArgument SchemaArgType input i func torch ops aten lift default torch ops aten lift_fresh default raise RuntimeError f \ Dispatcher operators below autograd allowed directly inputs However we found ` outputs str j name any has_mutated b c b c zip pytree tree_leaves before pytree tree_leaves after md schema_info is_mutable SchemaArgument SchemaArgType input i raise RuntimeError f Argument name defined mutable mutated mutated append Mutation func _schema name name Aliasing between outputs i j combinations range len func _schema returns has_aliased tuple_out i tuple_out j schema_info may_contain_alias SchemaArgument SchemaArgType output i SchemaArgument SchemaArgType output j raise RuntimeError f Outputs i j alias unexpectedly out