Owner s module inductor contextlib sys unittest torch torch _inductor torch _inductor utils run_and_get_code torch testing _internal common_utils instantiate_parametrized_tests TestCase torch testing _internal inductor_utils HAS_CPU HAS_CUDA_AND_TRITON torch testing _internal triton_utils requires_cuda_and_triton aten = torch ops aten try try test_torchinductor check_model check_model_cuda except ImportError test_torchinductor manual=fbcode caffe test inductor test_inductor-library check_model check_model_cuda except unittest SkipTest ImportError e sys stderr write f type e e \n __name__ == __main__ sys exit raise instantiate_parametrized_tests ComboKernelTests TestCase check_model_cuda = check_model_cuda check_model_cpu = check_model check_kernel_count = True setUp super setUp torch _inductor metrics reset _test_stack = contextlib ExitStack _test_stack enter_context torch _inductor config patch combo_kernels True benchmark_combo_kernel False tearDown _test_stack close torch _inductor metrics reset super tearDown requires_cuda_and_triton test_activation_functions test_activations b c = torch nn functional relu b = torch nn functional sigmoid b c = torch nn functional tanh c b c inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_activations inps out_compiled = torch compile test_activations inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_reduce_functions test_reduce b c d = torch sum dim= b = torch max b dim= c = torch min c dim= d = torch nn functional tanh d b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_reduce inps out_compiled = torch compile test_reduce inps assertEqual out_eager out_compiled assertTrue torch _inductor metrics generated_kernel_count = requires_cuda_and_triton test_mutated_args test_mutated b c d add_ b sigmoid_ c = torch add c d tanh_ b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_mutated inps out_compiled = torch compile test_mutated inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_reduce_split fn b = torch linalg vector_norm b = torch sum b dim= b inps = torch rand device= cuda torch rand device= cuda out_eager = fn inps out_compiled = torch compile fn inps assertEqual out_eager out_compiled requires_cuda_and_triton test_ d_blocking_partitioning fn b b b c = torch add b c = torch add b c = torch add b c c c check_model_cuda fn torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda t torch rand device= cuda t assertEqual torch _inductor metrics generated_kernel_count instantiate_parametrized_tests ComboKernelBenchmarkTests TestCase check_model_cuda = check_model_cuda check_model_cpu = check_model check_kernel_count = True setUp super setUp torch _inductor metrics reset _test_stack = contextlib ExitStack _test_stack enter_context torch _inductor config patch combo_kernels True benchmark_combo_kernel True tearDown _test_stack close torch _inductor metrics reset super tearDown requires_cuda_and_triton test_activation_benchmark test_activations b c = torch nn functional relu b = torch nn functional sigmoid b c = torch nn functional tanh c b c inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_activations inps out_compiled = torch compile test_activations inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_reduce_benchmark test_reduce b c d = torch sum dim= b = torch max b dim= c = torch min c dim= d = torch nn functional tanh d b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_reduce inps out_compiled = torch compile test_reduce inps assertEqual out_eager out_compiled assertTrue torch _inductor metrics generated_kernel_count = requires_cuda_and_triton test_mutated_benchmark test_mutated b c d add_ b sigmoid_ c = torch add c d tanh_ b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_mutated inps out_compiled = torch compile test_mutated inps assertEqual out_eager out_compiled assertTrue torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_round_robin_dispatch combo kernel dispatch strategy round robin test_mutated b c d add_ b sigmoid_ c = torch add c d tanh_ b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_mutated inps out_compiled = torch compile test_mutated inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_ d_blocking_benchmark fn b b b c = torch add b c = torch add b c = torch add b c c c check_model_cuda fn torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda t torch rand device= cuda t assertTrue = torch _inductor metrics generated_kernel_count = requires_cuda_and_triton test_persistent_reduction_no_x_dim fn x y x sum y sum inps = torch rand device= cuda torch rand device= cuda torch _dynamo mark_dynamic inps min= max= torch _dynamo mark_dynamic inps min= max= out_eager = fn inps out_compiled = torch compile fn inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count instantiate_parametrized_tests ComboKernelDynamicShapesTests TestCase check_model_cuda = check_model_cuda check_model_cpu = check_model check_kernel_count = True setUp super setUp torch _inductor metrics reset _test_stack = contextlib ExitStack _test_stack enter_context torch _inductor config patch combo_kernels True benchmark_combo_kernel True _test_stack enter_context torch _dynamo config patch automatic_dynamic_shapes False assume_static_by_default False tearDown _test_stack close torch _inductor metrics reset super tearDown requires_cuda_and_triton test_dynamic_shapes_activations test_activations b c = torch nn functional relu b = torch nn functional sigmoid b c = torch nn functional tanh c b c inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_activations inps out_compiled = torch compile test_activations inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton test_dynamic_shapes_ d_blocking fn b b b c = torch add b c = torch add b c = torch add b c c c check_model_cuda fn torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda t torch rand device= cuda t assertTrue = torch _inductor metrics generated_kernel_count = requires_cuda_and_triton test_dynamic_shapes_reduce test_reduce b c d = torch sum dim= b = torch max b dim= c = torch min c dim= d = torch nn functional tanh d b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_reduce inps out_compiled = torch compile test_reduce inps assertEqual out_eager out_compiled assertTrue torch _inductor metrics generated_kernel_count = requires_cuda_and_triton test_dynamic_shapes_mutated combo kernel dispatch strategy round robin test_mutated b c d add_ b sigmoid_ c = torch add c d tanh_ b c d inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_mutated inps out_compiled = torch compile test_mutated inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton torch _inductor config patch combo_kernels_autotune test_dynamic_shapes_activations_no_autotune test_activations b c = torch nn functional relu b = torch nn functional sigmoid b c = torch nn functional tanh c b c inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = test_activations inps out_compiled = torch compile test_activations inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton torch _dynamo config patch automatic_dynamic_shapes True torch _dynamo config patch assume_static_by_default True test_dynamic_shapes_persistent_reduction_no_x_dim fn x y x sum y sum inps = torch rand device= cuda torch rand device= cuda torch _dynamo mark_dynamic inps min= max= torch _dynamo mark_dynamic inps min= max= out_eager = fn inps out_compiled = torch compile fn inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton torch _dynamo config patch automatic_dynamic_shapes True torch _dynamo config patch assume_static_by_default True test_dynamic_shapes_persistent_reduction_no_x_dim_ fn x y x sum y sum inps = torch rand device= cuda torch rand device= cuda torch _dynamo mark_dynamic inps min= max= torch _dynamo mark_dynamic inps min= max= out_eager = fn inps out_compiled = torch compile fn inps assertEqual out_eager out_compiled assertEqual torch _inductor metrics generated_kernel_count requires_cuda_and_triton torch _dynamo config patch automatic_dynamic_shapes True torch _dynamo config patch assume_static_by_default True test_dynamic_shapes_ d_blocking_round_robin fn b b b c = torch add b c = torch add b c = torch add b c c c inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda t torch rand device= cuda t torch rand device= cuda t out_eager = fn inps compiled = torch compile fn out_compiled = compiled inps assertEqual out_eager out_compiled assertTrue = torch _inductor metrics generated_kernel_count = torch _inductor metrics reset inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch rand device= cuda t torch rand device= cuda t torch rand device= cuda t out_compiled = compiled inps out_eager = fn inps assertEqual out_eager out_compiled assertTrue = torch _inductor metrics generated_kernel_count = requires_cuda_and_triton torch _dynamo config patch automatic_dynamic_shapes True torch _dynamo config patch assume_static_by_default True torch _inductor config patch triton autotune_at_compile_time True test_dynamic_shapes_persistent_reduction_mixed_x_dim_cuda fn x y z x sum y mean z max inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda torch _dynamo mark_dynamic inps min= max= torch _dynamo mark_dynamic inps min= max= torch _dynamo mark_dynamic inps min= max= out_eager = fn inps out_compiled = torch compile fn inps assertEqual out_eager out_compiled requires_cuda_and_triton test_helper_fn_defined fn x y z x sum y mean z cumsum inps = torch rand device= cuda torch rand device= cuda torch rand device= cuda out_eager = fn inps fn_c = torch compile fn out_compiled code = run_and_get_code fn_c inps code = join code assertEqual out_eager out_compiled assertEqual code count _triton_helper_fn_add arg _ arg _ __name__ == __main__ torch _dynamo test_case run_tests HAS_CPU HAS_CUDA_AND_TRITON run_tests needs= filelock