mypy allow-untyped-defs enum torch torch distributed rpc rpc torch testing _internal dist_utils dist_utils torch nn Tensor torch _jit_internal Future torch distributed nn RemoteModule torch distributed nn api remote_module _REMOTE_MODULE_PICKLED_ATTRIBUTES _RemoteModule torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_utils TemporaryFileName TEST_WITH_ROCM torch testing _internal distributed rpc rpc_agent_test_fixture RpcAgentTestFixture _PARAM_VAL = torch nn Parameter torch ones RPC handler querying device destination worker remote_device module_rref param module_rref local_value parameters param device RPC handler querying __dict__ destination worker remote_module_attributes remote_module remote_module __dict__ RPC handler running forward destination worker remote_forward remote_module args remote_module forward args RPC handler running forward_async destination worker remote_forward_async remote_module args Since future cannot pickled sent over RPC layer have wait behave just like ` ` forward_sync ` ` remote_module forward_async args wait RPC handler getting training mode destination worker get_remote_training_arg module_rref module_rref local_value training ModuleCreationMode enum Enum MODULE_CTOR_WITH_INTERFACE = module_ctor_with_interface MODULE_CTOR = module_ctor torch jit interface MyModuleInterface forward tensor Tensor number int word str = default - tuple str int Tensor pyre-ignore Pyre torch jit interface don t mix well pass torch jit interface RemoteMyModuleInterface forward tensor Tensor number int word str = default - tuple str int Tensor pyre-ignore Pyre torch jit interface don t mix well pass forward_async tensor Tensor number int word str = default - Future tuple str int Tensor pass MyModule nn Module __init__ first_arg first_kwarg=- super __init__ param = _PARAM_VAL forward tensor Tensor number int word str = default - tuple str int Tensor word number tensor BadModule __init__ first_arg first_kwarg=- pass create_scripted_module first_arg first_kwarg=- module = MyModule first_arg first_kwarg=first_kwarg scripted_module = torch jit script module scripted_module Common utils both CPU CUDA test suites CommonRemoteModuleTest RpcAgentTestFixture property world_size Override setting RpcAgentTestFixture staticmethod _create_remote_module_iter remote_device modes=None modes None modes = ModuleCreationMode __members__ values args = kwargs = dict first_kwarg= ModuleCreationMode MODULE_CTOR modes remote_module = RemoteModule remote_device MyModule args kwargs yield remote_module ModuleCreationMode MODULE_CTOR_WITH_INTERFACE modes remote_module = _RemoteModule remote_device create_scripted_module args kwargs _module_interface_cls=MyModuleInterface scripted_remote_module = torch jit script remote_module yield scripted_remote_module RemoteModuleTest CommonRemoteModuleTest dist_utils dist_init test_bad_module rank = dst_worker_name = dist_utils worker_name rank + world_size remote_device = f dst_worker_name cpu args = kwargs = dict first_kwarg= assertRaisesRegex ValueError r Expect ` module_cls\ \ args \ \ kwargs\ ` returns instance nn Module RemoteModule remote_device BadModule args kwargs forward assertRaisesRegex ValueError r Expect ` module_cls\ \ args \ \ kwargs\ ` returns instance nn Module RemoteModule remote_device BadModule args kwargs forward dist_utils dist_init test_forward_async rank = dst_worker_name = dist_utils worker_name rank + world_size args = torch ones remote_module _create_remote_module_iter dst_worker_name ret_fut = remote_module forward_async args ret = ret_fut wait assertEqual ret tuple reversed args dist_utils dist_init test_forward_async_script rank = dst_worker_name = dist_utils worker_name rank + world_size scripted_remote_module = next _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR_WITH_INTERFACE torch jit script run_forward_async scripted_remote_module RemoteMyModuleInterface ret_fut = scripted_remote_module forward_async torch ones ret = ret_fut wait ret ret = run_forward_async scripted_remote_module assertEqual ret torch ones dist_utils dist_init test_forward_sync rank = dst_worker_name = dist_utils worker_name rank + world_size args = torch ones remote_module _create_remote_module_iter dst_worker_name ret = remote_module forward args assertEqual ret tuple reversed args dist_utils dist_init test_forward_sync_script rank = dst_worker_name = dist_utils worker_name rank + world_size scripted_remote_module = next _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR_WITH_INTERFACE torch jit script run_forward scripted_remote_module MyModuleInterface ret = scripted_remote_module forward torch ones ret ret = run_forward scripted_remote_module assertEqual ret torch ones dist_utils dist_init test_forward_with_kwargs rank = dst_worker_name = dist_utils worker_name rank + world_size args = torch ones kwargs = dict word= Only test Python nn Module because script module methods don t support taking kwargs remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR ret_fut = remote_module forward_async args kwargs ret = ret_fut wait assertEqual ret tuple reversed args + ret = remote_module forward args kwargs assertEqual ret tuple reversed args + dist_utils dist_init test_remote_parameters rank = dst_worker_name = dist_utils worker_name rank + world_size Only test Python nn Module because script module methods don t support ` ` remote_parameters ` ` remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR param_rrefs = remote_module remote_parameters assertEqual len param_rrefs assertTrue torch equal param_rrefs to_here _PARAM_VAL dist_utils dist_init test_get_module_rref rank = dst_worker_name = dist_utils worker_name rank + world_size Only test Python nn Module because script module methods don t support ` ` get_module_rref ` ` remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR rref = remote_module get_module_rref assertEqual rref remote_module module_rref param rref to_here parameters assertTrue torch equal param _PARAM_VAL dist_utils dist_init test_train_eval rank = dst_worker_name = dist_utils worker_name rank + world_size remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR remote_module train ret = rpc rpc_sync dst_worker_name get_remote_training_arg args= remote_module get_module_rref assertEqual ret True remote_module eval ret = rpc rpc_sync dst_worker_name get_remote_training_arg args= remote_module get_module_rref assertEqual ret False dist_utils dist_init test_unsupported_methods rank = dst_worker_name = dist_utils worker_name rank + world_size remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex ValueError r Method ` ` register_buffer ` ` supported RemoteModule remote_module register_buffer buffer torch ones assertRaisesRegex ValueError r Method ` ` register_parameter ` ` supported RemoteModule remote_module register_parameter param torch nn Parameter torch ones assertRaisesRegex ValueError r Method ` ` add_module ` ` supported RemoteModule remote_module add_module empty None assertRaisesRegex ValueError r Method ` ` apply ` ` supported RemoteModule fn = torch rand requires_grad=False remote_module apply fn assertRaisesRegex ValueError r Method ` ` cuda ` ` supported RemoteModule remote_module cuda assertRaisesRegex ValueError r Method ` ` cpu ` ` supported RemoteModule remote_module cpu assertRaisesRegex ValueError r Method ` ` type ` ` supported RemoteModule remote_module type torch FloatTensor assertRaisesRegex ValueError r Method ` ` float ` ` supported RemoteModule remote_module float assertRaisesRegex ValueError r Method ` ` double ` ` supported RemoteModule remote_module double assertRaisesRegex ValueError r Method ` ` bfloat ` ` supported RemoteModule remote_module bfloat assertRaisesRegex ValueError r Method ` ` ` ` supported RemoteModule remote_module cpu dtype=torch int hook module grad_input grad_output pass assertRaisesRegex ValueError r Method ` ` register_backward_hook ` ` supported RemoteModule remote_module register_backward_hook hook assertRaisesRegex ValueError r Method ` ` register_forward_pre_hook ` ` supported RemoteModule remote_module register_forward_pre_hook hook assertRaisesRegex ValueError r Method ` ` register_forward_hook ` ` supported RemoteModule remote_module register_forward_hook hook assertRaisesRegex ValueError r Method ` ` state_dict ` ` supported RemoteModule remote_module state_dict assertRaisesRegex ValueError r Method ` ` load_state_dict ` ` supported RemoteModule remote_module load_state_dict assertRaisesRegex ValueError r Method ` ` parameters ` ` supported RemoteModule Please use ` ` remote_parameters ` ` instead remote_module parameters assertRaisesRegex ValueError r Method ` ` named_parameters ` ` supported RemoteModule remote_module named_parameters assertRaisesRegex ValueError r Method ` ` buffers ` ` supported RemoteModule remote_module buffers assertRaisesRegex ValueError r Method ` ` named_buffers ` ` supported RemoteModule remote_module named_buffers assertRaisesRegex ValueError r Method ` ` children ` ` supported RemoteModule remote_module children assertRaisesRegex ValueError r Method ` ` named_children ` ` supported RemoteModule remote_module named_children assertRaisesRegex ValueError r Method ` ` modules ` ` supported RemoteModule remote_module modules assertRaisesRegex ValueError r Method ` ` named_modules ` ` supported RemoteModule remote_module named_modules assertRaisesRegex ValueError r Method ` ` requires_grad_ ` ` supported RemoteModule remote_module requires_grad_ assertRaisesRegex ValueError r Method ` ` zero_grad ` ` supported RemoteModule remote_module zero_grad assertRaisesRegex ValueError r Method ` ` share_memory ` ` supported RemoteModule remote_module share_memory assertRaisesRegex ValueError r Method ` ` extra_repr ` ` supported RemoteModule remote_module extra_repr dist_utils dist_init test_send_remote_module_with_a_new_attribute_not_pickled_over_the_wire rank = dst_worker_name = dist_utils worker_name rank + world_size If new attribute added RemoteModule after initialization will sent over wire RPC new field will pickled because s specified _REMOTE_MODULE_PICKLED_ATTRIBUTES Note adding new attribute out constructor should rarely happen If new attribute added RemoteModule constructor there sanity check enforce developers add attribute either _REMOTE_MODULE_PICKLED_ATTRIBUTES _REMOTE_MODULE_ATTRIBUTES_IGNORE_FOR_PICKLING remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR new_attr_name = new_attr setattr remote_module new_attr_name attrs = rpc rpc_sync dst_worker_name remote_module_attributes remote_module assertNotIn new_attr_name attrs dist_utils dist_init test_remote_module_py_pickle_not_supported rank = dst_worker_name = dist_utils worker_name rank + world_size remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR TemporaryFileName fname assertRaisesRegex RuntimeError Cannot pickle RemoteModule python pickler RemoteModule can only pickled when using RPC torch save remote_module fname dist_utils dist_init test_remote_module_py_pickle_not_supported_script rank = dst_worker_name = dist_utils worker_name rank + world_size remote_module _create_remote_module_iter dst_worker_name modes= ModuleCreationMode MODULE_CTOR_WITH_INTERFACE TemporaryFileName fname assertRaisesRegex torch jit Error can only pickled when using RPC torch save remote_module fname ThreeWorkersRemoteModuleTest CommonRemoteModuleTest property world_size Override setting CommonRemoteModuleTest dist_utils dist_init test_send_remote_module_over_the_wire rank = dst_worker _name = dist_utils worker_name rank + world_size dst_worker _name = dist_utils worker_name rank + world_size Unpickled attributes include both inherent attributes RemoteModule inherited superclass two installed methods expected_unpickled_attrs = list _REMOTE_MODULE_PICKLED_ATTRIBUTES expected_unpickled_attrs append forward_async expected_unpickled_attrs append forward Create remote module worker then pass worker over RPC layer remote_module _create_remote_module_iter dst_worker _name modes= ModuleCreationMode MODULE_CTOR Test querying some simple attributes worker attrs = rpc rpc_sync dst_worker _name remote_module_attributes remote_module assertListEqual list attrs keys expected_unpickled_attrs assertEqual attrs worker assertEqual attrs device cpu assertFalse attrs is_device_map_set assertFalse attrs is_scriptable Test installed methods worker s can initiated worker over RPC layer NOTE In practice remote module should directly stored worker runs ` ` forward ` ` ` ` ` forward_async ` ` have another worker initiate forward over RPC layer args = torch ones ret = rpc rpc_sync dst_worker _name remote_forward remote_module args assertEqual ret tuple reversed args ret = rpc rpc_sync dst_worker _name remote_forward_async remote_module args assertEqual ret tuple reversed args dist_utils dist_init test_send_remote_module_over_the_wire_script_not_supported rank = dst_worker _name = dist_utils worker_name rank + world_size dst_worker _name = dist_utils worker_name rank + world_size Unpickled attributes include both inherent attributes RemoteModule inherited superclass two installed methods expected_unpickled_attrs = list _REMOTE_MODULE_PICKLED_ATTRIBUTES expected_unpickled_attrs append forward_async expected_unpickled_attrs append forward assertRaisesRegex RuntimeError Passing script RemoteModule over RPC supported Create remote module worker then pass worker over RPC layer remote_module _create_remote_module_iter dst_worker _name modes= ModuleCreationMode MODULE_CTOR_WITH_INTERFACE Test querying some simple attributes worker rpc rpc_sync dst_worker _name remote_module_attributes remote_module dist_utils dist_init test_create_remote_module_from_module_rref rank = dst_worker _name = dist_utils worker_name rank + world_size dst_worker _name = dist_utils worker_name rank + world_size Create remote module worker then pass its ` module_rref ` worker over RPC layer remote_module _create_remote_module_iter dst_worker _name modes= ModuleCreationMode MODULE_CTOR remote_module = rpc rpc_sync dst_worker _name RemoteModule init_from_module_rref dst_worker _name remote_module get_module_rref args = torch ones ret = rpc rpc_sync dst_worker _name remote_forward remote_module args ret = rpc rpc_sync dst_worker _name remote_forward remote_module args assertEqual ret ret CudaRemoteModuleTest CommonRemoteModuleTest skip_if_lt_x_gpu dist_utils dist_init test_valid_device rank = dst_rank = rank + world_size dst_worker_name = dist_utils worker_name dst_rank remote_module _create_remote_module_iter f dst_worker_name cuda modes= ModuleCreationMode MODULE_CTOR device = rpc rpc_sync dst_worker_name remote_device remote_module module_rref assertEqual device type cuda assertEqual device index Test rank works well remote_module _create_remote_module_iter f rank dst_rank cuda modes= ModuleCreationMode MODULE_CTOR device = rpc rpc_sync dst_worker_name remote_device remote_module module_rref assertEqual device type cuda assertEqual device index skip_if_lt_x_gpu dist_utils dist_init test_invalid_devices rank = dst_worker_name = dist_utils worker_name rank + world_size assertRaisesRegex RuntimeError r Expected one + device type start device string m forward m _create_remote_module_iter f dst_worker_name foo modes= ModuleCreationMode MODULE_CTOR TEST_WITH_ROCM errorString = r HIP error invalid device ordinal\n r HIP kernel errors might asynchronously reported some other API call r so stacktrace below might incorrect \n r For debugging consider passing AMD_SERIALIZE_KERNEL= errorString = r CUDA error invalid device ordinal assertRaisesRegex RuntimeError errorString m forward m _create_remote_module_iter f dst_worker_name cuda modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex RuntimeError r Invalid device string cpu m forward m _create_remote_module_iter f dst_worker_name cpu modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex RuntimeError r Device string must empty m forward m _create_remote_module_iter f dst_worker_name modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex ValueError r Could parse remote_device worker cuda cuda The valid format workername device m forward m _create_remote_module_iter f dst_worker_name cuda cuda modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex ValueError r Could parse remote_device The valid format workername device m forward m _create_remote_module_iter modes= ModuleCreationMode MODULE_CTOR assertRaisesRegex ValueError r Could parse remote_device cuda The valid format workername device m forward m _create_remote_module_iter cuda modes= ModuleCreationMode MODULE_CTOR skip_if_lt_x_gpu dist_utils dist_init test_input_moved_to_cuda_device rank = dst_worker_name = dist_utils worker_name rank + world_size These two CPU tensors args kwargs should implicitly moved appropriate cuda device t = torch ones args = t t = t kwargs = dict word=t Only test Python nn Module because script module methods don t support taking kwargs remote_module _create_remote_module_iter f dst_worker_name cuda modes= ModuleCreationMode MODULE_CTOR ret_fut = remote_module forward_async args kwargs ret = ret_fut wait assertEqual ret tuple reversed args + t TODO Once RPC backend can support directly sending GPU tensors expected device type should cuda assertEqual ret device type cpu assertEqual ret device type cpu ret = remote_module forward args kwargs assertEqual ret tuple reversed args + t TODO Once RPC backend can support directly sending GPU tensors expected device type should cuda assertEqual ret device type cpu assertEqual ret device type cpu skip_if_lt_x_gpu dist_utils dist_init test_input_moved_to_cuda_device_script rank = dst_worker_name = dist_utils worker_name rank + world_size scripted_remote_module = next _create_remote_module_iter f dst_worker_name cuda modes= ModuleCreationMode MODULE_CTOR_WITH_INTERFACE torch jit script run_forward scripted_remote_module MyModuleInterface ret = scripted_remote_module forward torch ones ret ret = run_forward scripted_remote_module assertEqual ret torch ones TODO Once RPC backend can support directly sending GPU tensors expected device type should cuda assertEqual ret device type cpu