Copyright c Meta Platforms Inc affiliates Owner s oncall distributed contextlib copy itertools unittest torch torch distributed _local_tensor maybe_disable_local_tensor_mode maybe_run_for_local_tensor torch distributed device_mesh init_device_mesh torch distributed tensor DeviceMesh distribute_tensor DTensor Partial Replicate Shard torch distributed tensor _collective_utils shard_dim_alltoall torch distributed tensor _dtensor_spec ShardOrderEntry torch distributed tensor _redistribute redistribute_local_tensor torch distributed tensor debug CommDebugMode torch distributed tensor placement_types _StridedShard torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests TEST_CUDA TEST_HPU torch testing _internal distributed _tensor common_dtensor create_local_tensor_test_class DTensorTestBase map_local_tensor_for_rank with_comms torch utils _debug_mode DebugMode funcol = torch ops c d_functional RedistributeTest DTensorTestBase property world_size with_comms parametrize dtype torch float torch cfloat test_shard_to_replicate_forward_backward dtype test shard - replicate forward device_mesh = build_device_mesh replica_spec = Replicate input_sizes_and_shard_dim = world_size world_size + world_size + world_size world_size + world_size + comm_mode = CommDebugMode input_size shard_dim input_sizes_and_shard_dim shard_spec = Shard shard_dim expected_tensor = torch randn input_size device=self device_type requires_grad=True dtype=dtype dtensor = distribute_tensor expected_tensor device_mesh shard_spec comm_mode reshard_dtensor = dtensor redistribute device_mesh replica_spec assertEqual reshard_dtensor size torch Size input_size assertEqual expected_tensor reshard_dtensor to_local assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor test shard - replicate backward should give gradient shard grad_output = torch ones_like reshard_dtensor comm_mode reshard_dtensor backward grad_output grad_input = dtensor grad assertEqual grad_input placements shard_spec assertEqual grad_input to_local torch ones dtensor to_local size dtype=dtype assertEqual comm_mode get_total_counts with_comms test_replicate_to_replicate_forward_backward device_mesh = build_device_mesh replica_spec = Replicate local_tensor = torch randn device=self device_type requires_grad=True comm_mode = CommDebugMode test replicate - replicate forward replica_tensor = distribute_tensor local_tensor device_mesh replica_spec comm_mode reshard_replica_tensor = replica_tensor redistribute device_mesh replica_spec assertEqual replica_tensor size local_tensor size assertEqual replica_tensor reshard_replica_tensor assertEqual comm_mode get_total_counts test replicate - replicate backward should give gradient replicate grad_output = torch ones_like reshard_replica_tensor comm_mode reshard_replica_tensor backward grad_output grad_input = replica_tensor grad assertEqual grad_input placements replica_spec assertEqual grad_input to_local torch ones assertEqual comm_mode get_total_counts with_comms parametrize dtype torch float torch cfloat test_replicate_to_local_partial_grad dtype device_mesh = build_device_mesh replica_spec = Replicate local_tensor = torch randn device=self device_type requires_grad=True dtype=dtype replica_tensor = distribute_tensor local_tensor device_mesh replica_spec comm_mode = CommDebugMode comm_mode out = replica_tensor redistribute placements= Replicate to_local grad_placements= Partial out backward torch ones_like out assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_reduce with_comms test_replicate_to_shard_forward_backward device_mesh = build_device_mesh replica_spec = Replicate input_sizes_and_shard_dim = world_size world_size + world_size + world_size world_size + world_size + comm_mode = CommDebugMode input_size shard_dim input_sizes_and_shard_dim shard_spec = Shard shard_dim test replicate - shard forward local_replica = torch randn input_size device=self device_type requires_grad=True splitted_list = list torch chunk local_replica world_size dim=shard_dim make local tensor element corresponding chunked list local_tensor = map_local_tensor_for_rank splitted_list rank lambda tl r tl r replica_tensor = distribute_tensor local_replica device_mesh replica_spec comm_mode reshard_tensor = replica_tensor redistribute device_mesh shard_spec assertEqual reshard_tensor size replica_tensor size assertEqual reshard_tensor placements shard_spec assertEqual reshard_tensor to_local local_tensor assertEqual comm_mode get_total_counts test replicate - shard backward should give gradient replicate grad_output = torch ones_like reshard_tensor comm_mode reshard_tensor backward grad_output grad_input = replica_tensor grad assertEqual grad_input placements replica_spec assertEqual grad_input to_local torch ones input_size assertEqual comm_mode get_total_counts assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor with_comms parametrize dtype torch float torch cfloat test_partial_to_replicate_forward_backward dtype Although we don t allow user reshard produce partial placement i e user can t reshard partial we do allow replicate partial internally also partial replicate backward should work expected device_mesh = build_device_mesh partial_local = torch ones device=self device_type requires_grad=True dtype=dtype partial_spec = Partial replica_spec = Replicate comm_mode = CommDebugMode test partial - replicate which trigger all_reduce partial_tensor = DTensor from_local partial_local device_mesh partial_spec comm_mode global_partial_tensor = partial_tensor redistribute device_mesh replica_spec assertEqual partial_tensor size partial_local size assertEqual partial_local world_size global_partial_tensor to_local assertEqual comm_mode get_comm_counts funcol all_reduce test backward have replicate grad partial from_local backward we want replicate - partial pass through comm_mode global_partial_tensor backward torch ones_like global_partial_tensor assertIsNotNone partial_local grad assertEqual partial_local grad size partial_local size assertEqual partial_local grad torch ones_like partial_local dtype=dtype assertEqual comm_mode get_total_counts with_comms test_replicate_to_replicate_forward_backward_datatype_conversion device_mesh = build_device_mesh replica_spec = Replicate forward_datatypes = torch bfloat torch bfloat torch float torch float torch bfloat torch float None None backward_datatypes = torch bfloat torch float torch bfloat torch float None None torch bfloat torch float comm_mode = CommDebugMode forward_dtype backward_dtype zip forward_datatypes backward_datatypes local_tensor = torch randn device=self device_type requires_grad=True test replicate - replicate forward forward datatype cast forward_dtype backward datatype cast backward_dtype replica_tensor = distribute_tensor local_tensor device_mesh replica_spec comm_mode reshard_replica_tensor = replica_tensor redistribute device_mesh replica_spec forward_dtype=forward_dtype backward_dtype=backward_dtype assertEqual replica_tensor size local_tensor size assertEqual replica_tensor forward_dtype reshard_replica_tensor assertEqual comm_mode get_total_counts test replicate - replicate backward should give gradient replicate grad_output = torch ones_like reshard_replica_tensor comm_mode reshard_replica_tensor backward grad_output grad_input = replica_tensor grad assertEqual grad_input placements replica_spec assertEqual grad_input to_local torch ones assertEqual comm_mode get_total_counts with_comms test_shard_to_replicate_forward_backward_datatype_conversion device_mesh = build_device_mesh replica_spec = Replicate shard_dim_and_input_sizes = world_size world_size + world_size + world_size world_size + world_size + forward_datatypes = torch bfloat torch bfloat torch float torch float torch bfloat torch float None None backward_datatypes = torch bfloat torch float torch bfloat torch float None None torch bfloat torch float comm_mode = CommDebugMode forward_dtype backward_dtype zip forward_datatypes backward_datatypes shard_dim input_size shard_dim_and_input_sizes test shard - replicate forward shard_spec = Shard shard_dim expected_tensor = torch randn input_size device=self device_type requires_grad=True dtensor = distribute_tensor expected_tensor device_mesh shard_spec comm_mode reshard_dtensor = dtensor redistribute device_mesh replica_spec forward_dtype=forward_dtype backward_dtype=backward_dtype assertEqual reshard_dtensor size torch Size input_size assertEqual expected_tensor forward_dtype reshard_dtensor to_local assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor test shard - replicate backward should give gradient shard grad_output = torch ones_like reshard_dtensor comm_mode reshard_dtensor backward grad_output grad_input = dtensor grad assertEqual grad_input placements shard_spec assertEqual grad_input to_local torch ones dtensor to_local size assertEqual comm_mode get_total_counts with_comms test_replicate_to_partial device_mesh = build_device_mesh local_tensor = torch randn device=self device_type requires_grad=True partial_spec = Partial replica_spec = Replicate test replicate - partial forward replica_tensor = distribute_tensor local_tensor device_mesh replica_spec assertRaisesRegex RuntimeError Can redistribute partial_tensor = replica_tensor redistribute device_mesh partial_spec torch distributed tensor _redistribute Redistribute comm_mode = CommDebugMode comm_mode partial_tensor = Redistribute apply replica_tensor device_mesh partial_spec assertEqual partial_tensor size local_tensor size test successfully zero out contents other ranks assertEqual replica_tensor to_local world_size partial_tensor to_local assertEqual comm_mode get_total_counts replicate partial sub groups local_tensor = torch randn device=self device_type device_mesh = DeviceMesh device_type torch arange world_size reshape world_size test replicate - partial d-mesh subgroups replica_tensor = distribute_tensor local_tensor device_mesh replica_spec replica_spec comm_mode partial_tensor = Redistribute apply replica_tensor device_mesh partial_spec partial_spec assertEqual partial_tensor size local_tensor size assertEqual replica_tensor to_local world_size partial_tensor to_local assertEqual comm_mode get_total_counts with_comms parametrize dtype torch float torch cfloat test_partial_to_shard dtype device_mesh = build_device_mesh partial_spec = Partial my_rank = rank input_sizes_and_shard_dim = world_size world_size + world_size + world_size world_size + world_size + comm_mode = CommDebugMode input_size shard_dim input_sizes_and_shard_dim shard_spec = Shard shard_dim partial_local = torch ones input_size device=self device_type dtype=dtype partial_tensor = DTensor from_local partial_local device_mesh partial_spec run_check=False full_chunk_size = input_size shard_dim + world_size - world_size chunk_sizes = max min input_size shard_dim full_chunk_size idx + - full_chunk_size idx idx range world_size maybe_run_for_local_tensor _compute_local_shape rank - list int local_shape = list input_size local_shape shard_dim = chunk_sizes rank local_shape local_shape = _compute_local_shape my_rank test partial shard trigger reduce_scatter comm_mode scatter_shard_tensor = partial_tensor redistribute device_mesh shard_spec assertEqual scatter_shard_tensor size partial_tensor size assertEqual scatter_shard_tensor placements shard_spec assertEqual scatter_shard_tensor to_local torch ones local_shape dtype=dtype world_size assertEqual comm_mode get_comm_counts funcol reduce_scatter_tensor with_comms test_redistribute_negative_shard_dim device_mesh = build_device_mesh local_tensor = torch randn device=self device_type requires_grad=True shard_spec = Shard shard_minus_spec = Shard - shard_tensor = distribute_tensor local_tensor device_mesh shard_spec assertEqual shard_tensor placements dim reshard_tensor = shard_tensor redistribute device_mesh shard_minus_spec assertEqual reshard_tensor placements dim with_comms test_redistribute_uneven_sharding mesh = DeviceMesh device_type torch arange world_size reshape data_to_test = uneven last mesh dim torch randn device=self device_type uneven both mesh dims torch randn device=self device_type smaller than mesh dim shape torch randn device=self device_type torch randn device=self device_type sharding_to_tests = Shard Shard Shard Shard input_tensor data_to_test placements sharding_to_tests dt = distribute_tensor input_tensor mesh placements dt_full_tensor = dt full_tensor assertEqual dt_full_tensor input_tensor with_comms parametrize dtype torch float torch cfloat test_redistribute_shard_dim_change dtype test d device mesh mesh_ d = build_device_mesh data_to_test = evenly sharded case torch randn device=self device_type dtype=dtype d more dims torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype sharding_src_dst_pairs = Shard Shard Shard Shard comm_mode = CommDebugMode input_data data_to_test src dst sharding_src_dst_pairs expected_dt = distribute_tensor input_data clone mesh_ d dst sharded_dt = distribute_tensor input_data mesh_ d src comm_mode out_dt = sharded_dt redistribute mesh_ d dst assertEqual out_dt placements expected_dt placements local_out_dt = out_dt to_local local_expected_dt = expected_dt to_local assertEqual out_dt to_local expected_dt to_local TEST_HPU TEST_CUDA assertEqual comm_mode get_comm_counts torch ops _dtensor shard_dim_alltoall TODO Integrate local tensor CommDebugMode is_local_tensor_enabled assertEqual comm_mode get_comm_counts funcol all_gather_into_tensor test d device mesh mesh_ d = DeviceMesh device_type torch arange world_size reshape data_to_test_ d = evenly sharded case torch randn device=self device_type dtype=dtype d more dims torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype uneven case torch randn device=self device_type dtype=dtype sharding_src_dst_pairs_ d = Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard comm_counts_ d = S - S S - R S - S R - S S - R S - S R - S input_data data_to_test_ d input_data ndim sharding_spec_combs = sharding_src_dst_pairs_ d + Shard Shard Shard Shard Shard Shard Shard Shard comm_counts_ d = comm_counts_ d + S - R S - S R - S S - S sharding_spec_combs = sharding_src_dst_pairs_ d idx src dst enumerate sharding_spec_combs expected_dt = distribute_tensor input_data clone mesh_ d dst sharded_dt = distribute_tensor input_data mesh_ d src comm_mode out_dt = sharded_dt redistribute mesh_ d dst assertEqual out_dt placements expected_dt placements is_local_tensor_enabled assertEqual comm_mode get_total_counts comm_counts_ d idx local_out_dt = out_dt to_local local_expected_dt = expected_dt to_local assertEqual local_out_dt local_expected_dt with_comms parametrize dtype torch float torch cfloat test_shard_dim_alltoall dtype init d mesh here so we can test when group_rank = global_rank mesh = init_device_mesh device_type tensor = torch randn world_size device=self device_type dtype=dtype new_tensor = shard_dim_alltoall tensor mesh meta_tensor = torch randn world_size device= meta new_meta_tensor = shard_dim_alltoall meta_tensor mesh assertEqual new_tensor shape new_meta_tensor shape assertEqual new_tensor stride new_meta_tensor stride with_comms test_one_chunk_mesh mesh size second dim mesh = init_device_mesh device_type srcs = Shard Replicate Partial dsts = Shard Shard Replicate comm_mode = CommDebugMode src dst itertools product srcs dsts tensor = torch randn device=self device_type dt = DTensor from_local tensor mesh Shard src comm_mode out = dt redistribute mesh Shard dst assertEqual comm_mode get_total_counts assertEqual out placements Shard dst with_comms test_redistribute_to_partial mesh = init_device_mesh device_type tensor = torch randn device=self device_type test_cases = Partial Partial allowed Partial Shard Partial Shard True Partial Shard Partial Shard True Shard Partial Replicate Partial True Shard Partial prod Replicate Partial prod True Non-Partial Partial NOT allowed Shard Replicate Shard Partial False Shard Replicate Replicate Partial False Shard Shard Replicate Partial False Partial partial allowed only reduction ops same Shard Partial prod Replicate Partial sum False src dst allow test_cases dt = DTensor from_local tensor mesh src raise_context = assertRaisesRegex RuntimeError Can redistribute allow contextlib nullcontext raise_context out = dt redistribute mesh dst assertEqual out placements dst instantiate_parametrized_tests RedistributeTest MultiDimRedistributeTest DTensorTestBase property world_size - int with_comms test_multi_dim_mesh devices = torch arange world_size mesh_shape devices devices view devices view mesh_shape = torch arange world_size view - device_mesh = DeviceMesh device_type mesh_shape tensor_shape = torch distributed get_rank == full_tensor = torch randn tensor_shape these should entirely ignored because distribute_tensor expected override shards ranks = full_tensor = torch ones tensor_shape possibilities = Replicate + Shard i i range full_tensor ndim all_outputs = list itertools product mesh_shape ndim possibilities all_inputs = list itertools product mesh_shape ndim possibilities + Partial inputs all_inputs partial temporarily make Replicated then replace replicated partial afterwards repl_inputs = Replicate s is_partial s s inputs dt = distribute_tensor full_tensor device_mesh repl_inputs repl_inputs = inputs create new DTensor reinterpreting some replicated entries Partial dt = DTensor from_local dt to_local device_mesh inputs run_check=False outputs all_outputs redistribute target outputs dt = dt redistribute device_mesh outputs replicate then get first shard local_full = dt full_tensor torch distributed get_rank == assertEqual local_full shape full_tensor shape num_sums = idx input enumerate inputs input is_partial num_sums = mesh_shape size idx expected = num_sums full_tensor assertEqual local_full expected with_comms test_redistribute_shard_dim_multi_dim_mesh mesh = init_device_mesh device_type input_data = torch randn device=self device_type sharding_src_dst_pairs_ d = Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Shard Replicate Shard Shard Shard Replicate Shard Replicate Shard Shard Shard Shard Shard Shard Shard Shard comm_counts_ d = S - R S - R S - S S - R S - R S - S R - S R - S S - R S - S S - R S - R R - S R - S S - R S - S S - S comm_mode = CommDebugMode idx src_placement dst_placement enumerate sharding_src_dst_pairs_ d expected_dt = distribute_tensor input_data clone mesh dst_placement sharded_dt = distribute_tensor input_data mesh src_placement comm_mode out_dt = sharded_dt redistribute mesh dst_placement assertEqual out_dt placements expected_dt placements assertEqual comm_mode get_total_counts comm_counts_ d idx local_out_dt = out_dt to_local local_expected_dt = expected_dt to_local assertEqual local_out_dt local_expected_dt DistributeWithDeviceOrderTest DTensorTestBase property world_size - int _extract_redistribute_trace_from_debug_mode s str - str re match = re search r trace \s \ s match trace_str = match group trace_str TODO zpcore remove once native redistribute supports shard_order arg redistribute dtensor_input device_mesh placements shard_order use_graph_based_transform=True wrapper function support shard_order redistribution This simpler version Redistribute only considers forward placements None placements = _shard_order_to_placement shard_order device_mesh placements = tuple placements old_spec = dtensor_input _spec new_spec = copy deepcopy old_spec new_spec placements = placements shard_order None new_spec shard_order = shard_order new_spec shard_order = old_spec == new_spec dtensor_input dtensor_input = DTensor from_local redistribute_local_tensor dtensor_input to_local old_spec new_spec use_graph_based_transform=use_graph_based_transform device_mesh dtensor_input _spec = copy deepcopy new_spec dtensor_input returns DTensor TODO zpcore remove once native distribute_tensor supports shard_order arg distribute_tensor input_tensor device_mesh placements shard_order use_graph_based_transform=True wrapper function support shard_order tensor distribution placements None placements = _shard_order_to_placement shard_order device_mesh placements = tuple placements tensor_dt = distribute_tensor input_tensor device_mesh placements fix shard order redistribute tensor_dt device_mesh placements shard_order use_graph_based_transform TODO zpcore remove once native redistribute supports shard_order arg full_tensor dtensor_input wrapper function support DTensor full_tensor redistribute dtensor_input dtensor_input device_mesh placements=None shard_order= to_local _shard_order_to_placement shard_order mesh convert shard_order placement only Replicate Shard placements = Replicate _ range mesh ndim shard_order None entry shard_order tensor_dim = entry tensor_dim mesh_dims = entry mesh_dims mesh_dim mesh_dims placements mesh_dim = Shard tensor_dim tuple placements _convert_shard_order_dict_to_ShardOrder shard_order Convert shard_order dict ShardOrder tuple ShardOrderEntry tensor_dim=tensor_dim mesh_dims=tuple mesh_dims tensor_dim mesh_dims shard_order items with_comms test_ordered_redistribute Test ordered redistribution various sharding syntaxes torch manual_seed mesh = init_device_mesh device_type input_data = torch randn device=self device_type sharding_src_dst_pairs_with_expected_trace = Shard Shard Shard ShardOrderEntry tensor_dim= mesh_dims= Replicate Shard Shard ShardOrderEntry tensor_dim= mesh_dims= Shard Shard Shard ShardOrderEntry tensor_dim= mesh_dims= Replicate Shard Shard ShardOrderEntry tensor_dim= mesh_dims= Shard Shard Shard ShardOrderEntry tensor_dim= mesh_dims= Shard Shard Replicate ShardOrderEntry tensor_dim= mesh_dims= If we use graph search solution redistribution path will S - S S - S - S S which takes only comm count However placement follows default device order greedy solution will triggered which results path S - S S - S - S S comm count Shard Shard Replicate ShardOrderEntry tensor_dim= mesh_dims= Replicate Shard Shard ShardOrderEntry tensor_dim= mesh_dims= ShardOrderEntry tensor_dim= mesh_dims= idx src_placement src_order dst_placement dst_order enumerate sharding_src_dst_pairs_with_expected_trace sharded_dt = distribute_tensor input_data clone mesh src_placement shard_order=src_order DebugMode record_torchfunction=False debug_mode sharded_dt = redistribute sharded_dt mesh dst_placement dst_order trace_str = _extract_redistribute_trace_from_debug_mode debug_mode debug_string idx == assertExpectedInline trace_str S S S - S S S - S S S - RS S - RS S - RS S idx == assertExpectedInline trace_str S S S - S S S - RS S - RS S idx == assertExpectedInline trace_str S S S - S S R- S S R- S S R- S S R- S S R idx == assertExpectedInline trace_str S S R- S S R- RS R- RS S expected_dt = distribute_tensor input_data clone mesh dst_placement shard_order=dst_order assertEqual sharded_dt to_local expected_dt to_local generate_shard_orders mesh tensor_rank Generate all possible sharding placement tensor rank ` tensor_rank ` over mesh _split_list lst list N int compositions n k k == yield n i range n - k + tail compositions n - i k - yield i + tail length = len lst comp compositions length N result = start = size comp result append lst start start + size start += size yield result all_mesh = list range mesh ndim all_device_order = list itertools permutations all_mesh device_order all_device_order split device orders assign each device order segment tensor dim num_split range mesh ndim + splitted_list _split_list list range mesh ndim num_split tensor_dims itertools combinations range tensor_rank len splitted_list shard_order = assert len tensor_dims == len splitted_list tensor_dim mesh_dims zip tensor_dims splitted_list shard_order tensor_dim = device_order mesh_dims mesh_dims - + yield _convert_shard_order_dict_to_ShardOrder shard_order with_comms test_generate_shard_orders Check ` generate_shard_orders ` generates unique sharding combinations math test_inputs = mesh init_device_mesh device_type tensor_rank mesh init_device_mesh device_type tensor_rank mesh init_device_mesh device_type tensor_rank test_input test_inputs all_combinations = shard_order generate_shard_orders test_input mesh test_input tensor_rank all_combinations append shard_order noqa PERF i range len all_combinations j range i + len all_combinations assert all_combinations i = all_combinations j f Duplicate elements found all_combinations all_combinations i all_combinations j expected_total_combination = N = test_input mesh ndim M = test_input tensor_rank i range N + assign total i split device tensor dims M i continue device_combination_count = math comb N - i - choose i- non-empty segments list size N tensor_dim_order_permutation = math comb M i choose i tensor dims expected_total_combination += device_combination_count tensor_dim_order_permutation multiply total possible permutation device order expected_total_combination = math factorial N assertEqual len all_combinations expected_total_combination with_comms test_ordered_distribute_all_combination Exhaustively test all possible sharding combinations verify correctness torch manual_seed maybe_disable_local_tensor_mode mesh = init_device_mesh device_type input_tensor_shape = even sharding uneven sharding padding Verify correctness distribute_tensor Tensor DTensor tensor_shape input_tensor_shape input_data = torch randn tensor_shape device=self device_type tensor_rank = input_data ndim maybe_disable_local_tensor_mode shard_orders = generate_shard_orders mesh tensor_rank shard_order shard_orders sharded_dt = distribute_tensor input_data clone mesh placements=None shard_order=shard_order assertEqual full_tensor sharded_dt input_data Verify correctness redistribution DTensor DTensor This test repeatedly redistributes DTensor various ordered placements checks resulting tensor matches original full tensor tensor_shape input_tensor_shape input_data = torch randn tensor_shape device=self device_type tensor_rank = input_data ndim prev_sharded_dt = None maybe_disable_local_tensor_mode shard_orders = generate_shard_orders mesh tensor_rank shard_order shard_orders prev_sharded_dt None prev_sharded_dt = distribute_tensor input_data clone mesh placements=None shard_order=shard_order sharded_dt = redistribute prev_sharded_dt mesh placements=None shard_order=shard_order assertEqual full_tensor sharded_dt input_data prev_sharded_dt = sharded_dt with_comms test_ordered_redistribute_with_partial Test mixing Partial original placements do redistribute This test takes s complete XA torch manual_seed maybe_disable_local_tensor_mode mesh = init_device_mesh device_type input_tensor_shape = even sharding uneven sharding padding placement_choice = Shard Shard Shard Partial sum Partial min Replicate pick D mesh partial_placement_comb = list itertools combinations placement_choice _is_valid_placement placements tensor_rank Check placements valid tensor rank ` tensor_rank ` placement placements isinstance placement Shard placement dim = tensor_rank False True shape input_tensor_shape placements partial_placement_comb _is_valid_placement placements len shape continue local_tensor = torch randn shape device=self device_type full_tensor = DTensor from_local local_tensor mesh placements maybe_disable_local_tensor_mode shard_orders = generate_shard_orders mesh len shape shard_order shard_orders sharded_dt = redistribute full_tensor mesh placements=None shard_order=shard_order assertEqual full_tensor sharded_dt full_tensor full_tensor unittest skip Temporarily skipping until we support special placement types graph based redistribution with_comms test_ordered_redistribute_for_special_placement Test ordered redistribution special placement torch distributed tensor _ops _embedding_ops _MaskPartial torch manual_seed mesh = init_device_mesh device_type input_data = torch randn device=self device_type src_placement = Shard tgt_placement = _MaskPartial offset_shape=torch Size offset_dim= sharded_dt = distribute_tensor input_data clone mesh src_placement shard_order= ShardOrderEntry tensor_dim= mesh_dims= sharded_dt = redistribute sharded_dt mesh tgt_placement shard_order=None with_comms test_shard_order_same_data_as_strided_shard device_mesh = init_device_mesh device_type x = torch randn device=self device_type specify right-to-left order use _StridedShard strided_placement = _StridedShard - split_factor= Shard - x_strided_dt = distribute_tensor x device_mesh strided_placement specify right-to-left order use ordered shard x_ordered_dt = distribute_tensor x device_mesh placements= Shard Shard shard_order= ShardOrderEntry tensor_dim= mesh_dims= assertEqual x_ordered_dt to_local x_strided_dt to_local RedistributeTestWithLocalTensor = create_local_tensor_test_class RedistributeTest MultiDimRedistributeTestWithLocalTensor = create_local_tensor_test_class MultiDimRedistributeTest skipped_tests= test_multi_dim_mesh DistributeWithDeviceOrderTestWithLocalTensor = create_local_tensor_test_class DistributeWithDeviceOrderTest __name__ == __main__ run_tests