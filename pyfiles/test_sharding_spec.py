Owner s oncall distributed copy dataclasses dataclass typing Union torch torch distributed _shard _shard_tensor sharded_tensor torch distributed _shard sharded_tensor ShardedTensor ShardedTensorMetadata TensorProperties torch distributed _shard sharding_spec _infer_sharding_spec_from_shards_metadata ChunkShardingSpec DevicePlacementSpec EnumerableShardingSpec ShardingSpec ShardMetadata torch distributed _shard sharding_spec _internals check_tensor get_chunk_sharding_params get_chunked_dim_size get_split_size validate_non_overlapping_shards_metadata torch testing _internal common_cuda TEST_MULTIGPU torch testing _internal common_distributed requires_nccl skip_if_lt_x_gpu torch testing _internal common_utils run_tests skip_but_pass_in_sandcastle_if TestCase torch testing _internal distributed _shard sharded_tensor ShardedTensorTestBase with_comms torch testing _internal distributed _shard sharded_tensor _test_st_common _chunk_sharding_specs_list_for_test TestShardingSpec TestCase skip_but_pass_in_sandcastle_if TEST_MULTIGPU CUDA GPUs needed test_device_placement valid devices DevicePlacementSpec cuda DevicePlacementSpec torch device DevicePlacementSpec torch device cuda DevicePlacementSpec rank cuda DevicePlacementSpec rank cpu DevicePlacementSpec rank invalid devices assertRaisesRegex ValueError Could parse remote_device DevicePlacementSpec cuda foo assertRaisesRegex ValueError Could parse remote_device DevicePlacementSpec foo assertRaisesRegex RuntimeError Invalid device string DevicePlacementSpec rank cuda foo assertRaisesRegex RuntimeError Invalid device string DevicePlacementSpec rank cpu skip_but_pass_in_sandcastle_if TEST_MULTIGPU CUDA GPUs needed test_chunked_sharding_spec Test valid specs ChunkShardingSpec torch device torch device ChunkShardingSpec torch device cuda torch device cuda ChunkShardingSpec - cuda cuda ChunkShardingSpec rank cuda rank cuda ChunkShardingSpec rank rank ChunkShardingSpec rank cpu rank cpu Test unimplemented error assertRaisesRegex NotImplementedError support named dimension Named dimension ChunkShardingSpec N cuda cuda Test invalid specs assertRaisesRegex ValueError needs integer ChunkShardingSpec None cuda cuda assertRaisesRegex ValueError needs integer ChunkShardingSpec cuda cuda assertRaisesRegex ValueError Could parse remote_device ChunkShardingSpec random cuda assertRaisesRegex ValueError Could parse remote_device ChunkShardingSpec cuda foo cuda assertRaisesRegex ValueError Could parse remote_device ChunkShardingSpec rank foo cuda assertRaisesRegex RuntimeError Expected one ChunkShardingSpec rank foo cuda assertRaisesRegex RuntimeError Expected one ChunkShardingSpec rank random cuda assertRaisesRegex RuntimeError Invalid device string ChunkShardingSpec rank cuda foo cuda skip_but_pass_in_sandcastle_if TEST_MULTIGPU CUDA GPUs needed test_enumerable_sharding_spec test valid specs test row-wise sharding spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda check_tensor spec shards torch rand size test row column sharding spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda check_tensor spec shards torch rand size test uneven shard sizes spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda check_tensor spec shards torch rand size test invalid sharding assertRaisesRegex ValueError Could parse remote_device ShardMetadata shard_offsets= shard_sizes= placement= cuda foo assertRaisesRegex ValueError same number elements ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError shard_offsets should = ShardMetadata shard_offsets= - shard_sizes= placement= cuda assertRaisesRegex ValueError shard_sizes should = ShardMetadata shard_offsets= shard_sizes= - placement= cuda assertRaisesRegex ValueError Empty shard list provided EnumerableShardingSpec assertRaisesRegex ValueError Found inconsistent ranks shards EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cpu ShardMetadata shard_offsets= shard_sizes= placement= cpu assertRaisesRegex ValueError Shards overlap EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cpu ShardMetadata shard_offsets= shard_sizes= placement= cpu spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError Rank tensor shards rank check_tensor spec shards torch rand size spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError exceeds tensor dim check_tensor spec shards torch rand size spec = EnumerableShardingSpec ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError does match tensor volume check_tensor spec shards torch rand size test_get_split_size assertEqual get_split_size assertEqual get_split_size assertEqual get_split_size assertEqual get_split_size assertEqual get_split_size assertEqual get_split_size test_get_chunked_dim_size assertEqual get_chunked_dim_size assertEqual get_chunked_dim_size assertEqual get_chunked_dim_size assertEqual get_chunked_dim_size assertEqual get_chunked_dim_size test_get_chunk_sharding_params ranks = rank cuda rank cuda rank cuda rank cuda spec = ChunkShardingSpec dim= placements=ranks result = get_chunk_sharding_params spec assertEqual result assertEqual result result = get_chunk_sharding_params spec assertEqual result assertEqual result ranks ranks = ranks ranks ranks ranks = ranks ranks spec placements = ranks result = get_chunk_sharding_params spec assertEqual result assertEqual result result = get_chunk_sharding_params spec assertEqual result assertEqual result _infer_enum_sharding_spec_case shards_metadata = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda spec = _infer_sharding_spec_from_shards_metadata shards_metadata assertTrue isinstance spec EnumerableShardingSpec assertEqual spec shards shards_metadata shards_metadata = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda spec = _infer_sharding_spec_from_shards_metadata shards_metadata assertTrue isinstance spec EnumerableShardingSpec assertEqual spec shards shards_metadata shards_metadata = ShardMetadata shard_offsets= shard_sizes= placement= rank cuda ShardMetadata shard_offsets= shard_sizes= placement= rank cuda ShardMetadata shard_offsets= shard_sizes= placement= rank cuda ShardMetadata shard_offsets= shard_sizes= placement= rank cuda spec = _infer_sharding_spec_from_shards_metadata shards_metadata assertTrue isinstance spec EnumerableShardingSpec assertEqual spec shards shards_metadata _infer_chunk_sharding_spec_case placements sharding_dim st_size world_size = len placements split_size = get_split_size st_size sharding_dim world_size shards_metadata = None world_size idx placement enumerate placements shard_size = copy deepcopy st_size offsets = len st_size offsets sharding_dim = split_size idx shard_size sharding_dim = get_chunked_dim_size st_size sharding_dim split_size idx shards_metadata placement rank = ShardMetadata shard_offsets=offsets shard_sizes=shard_size placement=placement spec = _infer_sharding_spec_from_shards_metadata shards_metadata assertTrue isinstance spec ChunkShardingSpec assertEqual spec dim sharding_dim assertEqual spec placements placements test_infer_sharding_spec_from_shards_metadata _infer_enum_sharding_spec_case chunk_specs = _chunk_sharding_specs_list_for_test seed= spec chunk_specs _infer_chunk_sharding_spec_case spec placements _infer_chunk_sharding_spec_case spec placements _infer_chunk_sharding_spec_case spec placements _infer_chunk_sharding_spec_case spec placements _infer_chunk_sharding_spec_case spec placements _infer_chunk_sharding_spec_case spec placements test_check_overlapping shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda validate_non_overlapping_shards_metadata shards shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError overlap validate_non_overlapping_shards_metadata shards shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError overlap validate_non_overlapping_shards_metadata shards shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda validate_non_overlapping_shards_metadata shards shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError overlap validate_non_overlapping_shards_metadata shards shards = ShardMetadata shard_offsets= shard_sizes= placement= cuda ShardMetadata shard_offsets= shard_sizes= placement= cuda assertRaisesRegex ValueError overlap validate_non_overlapping_shards_metadata shards Custom ShardingSpec simple example do grid sharding dataclass GridShardingSpec ShardingSpec grid_size int placements list Union torch distributed _remote_device str __post_init__ i remote_device enumerate placements isinstance remote_device torch distributed _remote_device placements i = torch distributed _remote_device remote_device build_metadata tensor_sizes torch Size tensor_properties TensorProperties - ShardedTensorMetadata tensor_num_dim = len tensor_sizes assert tensor_num_dim == only support -dim tensor grid sharding shards_metadata = chunk_num dim_size grid_size assert dim_size grid_size == only support dim_size mod grid_size == dim_size grid_size row_chunks = chunk_num tensor_sizes grid_size col_chunks = chunk_num tensor_sizes grid_size assert row_chunks col_chunks == len placements row_idx range row_chunks col_idx range col_chunks shards_metadata append ShardMetadata shard_offsets= row_idx grid_size col_idx grid_size shard_sizes= grid_size grid_size placement=self placements row_idx row_chunks + col_idx ShardedTensorMetadata shards_metadata=shards_metadata size=tensor_sizes tensor_properties=tensor_properties shard tensor torch Tensor src_rank int = process_group=None - ShardedTensor raise NotImplementedError GridShardingSpec shard implemented yet TestCustomShardingSpec ShardedTensorTestBase test_custom_sharding_spec ranks = rank cuda rank cuda rank cuda rank cuda grid_spec = GridShardingSpec grid_size= placements=ranks tensor_properties = TensorProperties dtype=torch get_default_dtype layout=torch strided requires_grad=False memory_format=torch contiguous_format pin_memory=False meta = grid_spec build_metadata torch Size tensor_properties check_tensor meta shards_metadata torch Size with_comms skip_if_lt_x_gpu requires_nccl test_custom_sharding_spec_tensor_ctor Test sharded_tensor ones custom grid sharding spec ranks = rank cuda rank cuda rank cuda rank cuda grid_spec = GridShardingSpec grid_size= placements=ranks st = sharded_tensor ones grid_spec Validate local shard initialized torch ones local_shards = st local_shards assertEqual len local_shards local_shard = local_shards tensor assertEqual torch device f cuda rank local_shard device assertEqual local_shard size assertEqual local_shard torch ones with_comms skip_if_lt_x_gpu requires_nccl test_custom_sharding_spec_shard_tensor Test custom spec can invoked _shard_tensor callsite ranks = rank cuda rank cuda rank cuda rank cuda grid_spec = GridShardingSpec grid_size= placements=ranks assertRaisesRegex NotImplementedError implemented _shard_tensor torch randn grid_spec __name__ == __main__ run_tests