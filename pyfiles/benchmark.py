contextlib json os time numpy np torch tensor_engine Benchmark __init__ mode device dtype mode = mode deterministic = False device = device dtype = dtype output_type = stdout print_ir = False print_kernel = False mode == both requires_grad = True mode == fwd requires_grad = False raise ValueError f invalid mode mode result_grad = None grad_variables = engine = tensor_engine get_engine engine reset device forward all member functions engine method dir engine callable getattr engine method continue don t forward function overridden here hasattr method continue don t forward internal function method startswith _ continue method_engine = getattr engine method setattr method method_engine forward do one step worth computation raise ValueError method should reimplemented subclass check deterministic np testing assert_allclose reference numpy compute atol= e- config returns array current benchmark configs raise ValueError method should reimplemented subclass desc description current benchmark config = config config_str = _ join str x x config device = device NNC_NUM_THREADS os environ num_threads_str = os environ NNC_NUM_THREADS device += num_threads_str f engine mode module _ mode _ device _ config_str staticmethod module raise ValueError method should reimplemented subclass memory_workload raise ValueError method should reimplemented subclass compute_workload number scalar operations takes finish tensor op None staticmethod input_iterable A benchmark child should true utilizes input iter arg False dtype_to_bytes torch tensor dtype=self dtype element_size staticmethod default_configs list default configs benchmark raise ValueError method should reimplemented subclass is_supported True rand shape device=None dtype=None requires_grad=False v = engine rand shape device=device dtype=dtype requires_grad=requires_grad requires_grad grad_variables append v v nchw_rand shape device=None requires_grad=False v = engine nchw_rand shape device=device requires_grad=requires_grad requires_grad grad_variables append v v compute bm_jit bm_jit inputs forward inputs run args print_ir = args print_ir args cuda_fuser == old torch _C _jit_override_can_fuse_on_gpu True args print_kernel os environ PYTORCH_FUSION_DEBUG = run_impl True args cuda_fuser == te torch _C _jit_set_texpr_fuser_enabled True cuda_pointwise_context args cuda_pointwise_loop_levels args cuda_pointwise_block_count args cuda_pointwise_block_size run_impl True args cuda_fuser == nvf torch _C _jit_set_nvfuser_enabled True torch _C _jit_set_profiling_executor True torch _C _jit_set_profiling_mode True torch _C _jit_override_can_fuse_on_cpu False torch _C _jit_override_can_fuse_on_gpu False torch _C _jit_set_bailout_depth args print_kernel os environ PYTORCH_CUDA_FUSER_DEBUG = run_impl True run_impl False run_impl use_fuser warmups = device == cuda iters = iters = engine = tensor_engine get_engine bm_jit = None i range warmups + iters i == warmups device == cuda engine sync_cuda time_start = time time i == jit_mode == trace use_fuser bm_jit = torch jit trace forward example_inputs=self inputs check_trace=False callable getattr reference None check print Warning no reference result module i == The fusion graph visible after first iter executed jit_mode == trace use_fuser print_ir print bm_jit graph_for inputs z = compute mode == both result_grad None result_grad = engine rand_like z engine backward z result_grad grad_variables device == cuda engine sync_cuda duration = time time - time_start iter_time = duration iters memory_workload = memory_workload compute_workload = compute_workload result_dict = desc desc us iter_time e sol memory_workload sol dtype_to_bytes iter_time e algorithmic memory_workload algorithmic dtype_to_bytes iter_time e compute_workload result_dict compute_workload = compute_workload iter_time e dump_result result_dict dump_result result_dict output_type == json print json dumps result_dict output_type == stdout msg = f us SOL f GB s algorithmic f GB s format result_dict desc result_dict us result_dict sol result_dict algorithmic compute_workload result_dict msg += f compute result_dict compute_workload f Gops s print msg raise Exception Unknown output_type + output_type noqa TRY contextlib contextmanager cuda_pointwise_context loop_levels block_count block_size loop_levels old_loop_levels = torch _C _jit_get_te_cuda_pointwise_loop_levels torch _C _jit_set_te_cuda_pointwise_loop_levels loop_levels block_count old_block_count = torch _C _jit_get_te_cuda_pointwise_block_count torch _C _jit_set_te_cuda_pointwise_block_count block_count block_size old_block_size = torch _C _jit_get_te_cuda_pointwise_block_size torch _C _jit_set_te_cuda_pointwise_block_size block_size try yield finally loop_levels torch _C _jit_set_te_cuda_pointwise_loop_levels old_loop_levels block_count torch _C _jit_set_te_cuda_pointwise_block_count old_block_count block_size torch _C _jit_set_te_cuda_pointwise_block_size old_block_size Auxiliary facilitate dynamic input shape DynamicShape r An Auxiliary dynamic shape benchmarks Pre-computes input random shapes also modifies compute method so each call fuser sees different input tensor shape Number random inputs instance SAMPLE_SIZE = __init__ dynamic_range= _input_samples = _input_sample_index = _dynamic_range = dynamic_range dynamic_range dynamic_range _enable_dynamic_shapes = True Returns input test case current index points property inputs _input_samples _input_sample_index An inputs assignment actually adds test case buffer inputs setter inputs val _input_samples append val Runs normal compute while increment test case index compute super compute _input_sample_index = _input_sample_index + SAMPLE_SIZE Defined benchmark benchmark needs specify input tensor construction method essentially same way benchmark creates inputs list initializer instantiate_input raise NotImplementedError Instantiate random shaped inputs start benchmark run run args force disable dynamic shape command line args no_dynamic_shape _enable_dynamic_shapes = False load_inputs super run args pre-compute inputs so creations random tensors do add compute time load_inputs i range SAMPLE_SIZE - instantiate_input returns randomized shape rand_shape shape _enable_dynamic_shapes shape ratios = np random uniform _dynamic_range len shape dyn_shape = list np multiply shape ratios astype int dyn_shape benchmark_classes = register_benchmark_class benchmark_cls benchmark_classes append benchmark_cls