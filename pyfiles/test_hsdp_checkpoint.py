Owner s oncall distributed copy deepcopy torch torch distributed dist torch distributed checkpoint dist_cp torch nn nn torch nn functional F torch distributed checkpoint default_planner DefaultLoadPlanner DefaultSavePlanner torch distributed device_mesh init_device_mesh torch distributed fsdp FullyShardedDataParallel FSDP torch distributed fsdp fully_sharded_data_parallel ShardingStrategy StateDictType torch distributed tensor Replicate torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_utils instantiate_parametrized_tests parametrize run_tests torch testing _internal distributed _tensor common_dtensor DTensorTestBase with_comms torch testing _internal distributed checkpoint_utils with_temp_dir device_type = acc type acc = torch accelerator current_accelerator cpu SimpleModel torch nn Module __init__ - None super __init__ net = nn Linear relu = nn ReLU net = nn Linear net = nn Linear forward x x = F relu net x x = F relu net x x = F relu net x x get_input torch rand device=device_type SimpleModelUneven torch nn Module __init__ - None super __init__ net = nn Linear relu = nn ReLU net = nn Linear net = nn Linear net = nn Linear forward x x = F relu net x x = F relu net x x = F relu net x x = F relu net x x get_input torch rand device=device_type TestHSDPCheckpoint DTensorTestBase property backend curr_backend = dist get_default_backend_for_device device_type f cpu gloo device_type curr_backend skip_if_lt_x_gpu with_comms with_temp_dir parametrize is_even_sharded_model True False test_hsdp_checkpoint is_even_sharded_model - None CHECKPOINT_DIR = temp_dir simple_model = SimpleModel is_even_sharded_model SimpleModelUneven mesh_ d = init_device_mesh device_type world_size model = FSDP simple_model device_type sharding_strategy=ShardingStrategy HYBRID_SHARD device_mesh=mesh_ d optim = torch optim Adam model parameters lr= FSDP set_state_dict_type model StateDictType SHARDED_STATE_DICT state_dict = model model state_dict state_dict_to_save = deepcopy state_dict dist_cp save state_dict=state_dict_to_save storage_writer=dist_cp FileSystemWriter CHECKPOINT_DIR planner=DefaultSavePlanner Update parameters so current model state_dict now different state_dict_to_save model model get_input sum backward optim step At point current state dict different state_dict_to_save k v k v zip state_dict_to_save model items model state_dict items assertEqual k k assertEqual v device_mesh v device_mesh assertEqual v placements v placements assertNotEqual v to_local v to_local dist_cp load state_dict=state_dict_to_save storage_reader=dist_cp FileSystemReader CHECKPOINT_DIR planner=DefaultLoadPlanner model load_state_dict state_dict_to_save model After loading current model state dict should same state_dict_to_save k v k v zip state_dict_to_save model items model state_dict items assertEqual k k assertEqual v device_mesh v device_mesh assertEqual v placements v placements assertEqual v to_local v to_local skip_if_lt_x_gpu with_comms with_temp_dir parametrize is_even_sharded_model True False test_hsdp_fsdp_checkpoint_conversion is_even_sharded_model - None CHECKPOINT_DIR = temp_dir simple_model = SimpleModel is_even_sharded_model SimpleModelUneven save hsdp model state_dict mesh_ d = init_device_mesh device_type world_size hsdp_model = FSDP simple_model device_type sharding_strategy=ShardingStrategy HYBRID_SHARD device_mesh=mesh_ d FSDP set_state_dict_type hsdp_model StateDictType SHARDED_STATE_DICT hsdp_state_dict = model hsdp_model state_dict dist_cp save_state_dict state_dict=hsdp_state_dict storage_writer=dist_cp FileSystemWriter CHECKPOINT_DIR planner=DefaultSavePlanner initialize fsdp model load checkpoint into mesh_ d = init_device_mesh device_type world_size fsdp_model = FSDP simple_model device_type device_mesh=mesh_ d FSDP set_state_dict_type fsdp_model StateDictType SHARDED_STATE_DICT fsdp_state_dict = model fsdp_model state_dict point hsdp model parameters different fsdp model parameters k v k v zip hsdp_state_dict model items fsdp_state_dict model items assertEqual k k assertNotEqual v device_mesh v device_mesh assertNotEqual v placements v placements v _all_gather = v redistribute mesh_ d placements= Replicate Replicate v _all_gather = v redistribute mesh_ d placements= Replicate assertNotEqual v _all_gather to_local v _all_gather to_local load fsdp state_dict storage dist_cp load_state_dict state_dict=fsdp_state_dict storage_reader=dist_cp FileSystemReader CHECKPOINT_DIR planner=DefaultLoadPlanner fsdp_model load_state_dict fsdp_state_dict model state_dict_after_load = fsdp_model state_dict After loading current model state dict should same hsdp_state_dict k v k v zip hsdp_state_dict model items state_dict_after_load items assertEqual k k assertNotEqual v device_mesh v device_mesh assertNotEqual v placements v placements v _all_gather = v redistribute mesh_ d placements= Replicate Replicate v _all_gather = v redistribute mesh_ d placements= Replicate assertEqual v _all_gather to_local v _all_gather to_local instantiate_parametrized_tests TestHSDPCheckpoint __name__ == __main__ run_tests