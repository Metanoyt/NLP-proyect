mypy allow-untyped-defs copy itertools logging typing Callable TYPE_CHECKING hints TRITON_MAX_BLOCK runtime_utils red_text triton_config_to_hashable TYPE_CHECKING triton_compat triton log = logging getLogger __name__ get_field config name name == num_warps config num_warps name == num_stages config num_stages name == waves_per_eu config kwargs get name int config num_warps config kwargs get name None set_field config name value name == num_warps config num_warps = value name == num_stages config num_stages = value config kwargs name = value CoordescTuner The coordinate descent tuner Tune one field coordinate time TODO will necessary tune multiple fields simultaneously TODO what both increasing decreasing field can improve perf i e there multiple local optima __init__ is_mm=False is_native_matmul=False name= unknown size_hints=None inductor_meta=None is_mm = is_mm we will tune num_stages mm Native matmul codegen assumes ZBLOCK= always This because d tl dot slow so we want tile y x only tl dot also does support size smaller than we put restriction is_native_matmul = is_native_matmul assert is_mm is_native_matmul cached_benchmark_results = name = name size_hints = size_hints inductor_meta = inductor_meta get_config_max prefix str - int max_block = TRITON_MAX_BLOCK prefix upper size_hint = size_hints get prefix size_hints None None min max_block size_hint size_hint None max_block get_warpsmax Currently CUDA has maximum threads so max number warps cache_benchmark_result config timing cached_benchmark_results triton_config_to_hashable config = timing lookup_in_cache config cached_benchmark_results get triton_config_to_hashable config call_func func config found = lookup_in_cache config found None log debug CACHED found timing = func config cache_benchmark_result config timing timing property tunable_fields out = XBLOCK YBLOCK ZBLOCK NOTE we should tune R _BLOCK persistent reduction We rely fact persistent reduction s triton Config does have R _BLOCK field guarantee R _BLOCK R _BLOCK following mm BLOCK_M BLOCK_N BLOCK_K num_warps is_mm out append num_stages inductor_meta get is_hip True out append waves_per_eu is_native_matmul out append num_stages out remove ZBLOCK ZBLOCK= always native matmul out value_too_large name str val int - bool block_suffix = BLOCK name endswith block_suffix prefix = name strip block_suffix lower val get_config_max prefix name == num_warps val get_warpsmax name == waves_per_eu val False value_too_small name str val int - bool In native matmul block size should = tl dot is_native_matmul name YBLOCK XBLOCK R _BLOCK val Break value becomes neg val = get_neighbour_values name orig_val radius= include_self=False Get neighbour values radius steps The original value returned s own neighbour assert radius = update cur_val inc=True name == num_stages inc cur_val + cur_val - inc cur_val cur_val out = increment loop cur_val = orig_val _ range radius cur_val = update cur_val True value_too_large name cur_val break out append cur_val decrement loop cur_val = orig_val _ range radius cur_val = update cur_val False value_too_small name cur_val break out append cur_val include_self out append orig_val out staticmethod has_improvement baseline test threshold = test None test baseline - threshold check_all_tuning_directions pyrefly ignore missing-attribute func Callable triton Config float best_config best_timing Check all directions We only do once regular coordinate descent tuning find no better choices any more We only have few tunable fields so should fine candidate_values_list = effective_fields = field tunable_fields old_value = get_field best_config field old_value None continue candidate_values = get_neighbour_values field old_value radius=self inductor_meta get coordinate_descent_search_radius include_self=True candidate_values_list append candidate_values effective_fields append field choices = itertools product candidate_values_list improved = False choice choices assert len choice == len effective_fields candidate_config = copy deepcopy best_config new_val field zip choice effective_fields set_field candidate_config field new_val cmp_res candidate_timing = compare_config func candidate_config best_config best_timing cmp_res improved = True best_config = candidate_config best_timing = candidate_timing improved best_config best_timing compare_config func candidate_config best_config best_timing Check candidate_config better than best_config Return tuple compare_result candidate_timing compare_result true iff candidate_config better log debug Try config s candidate_config try candidate_timing = call_func func candidate_config except Exception e log debug Got exception s e noqa G False float inf has_improvement best_timing candidate_timing log debug Tune s f - s f best_config best_timing candidate_config candidate_timing True candidate_timing False candidate_timing autotune pyrefly ignore missing-attribute func Callable triton Config float pyrefly ignore missing-attribute baseline_config triton Config baseline_timing float &#124; None = None - triton Config pyrefly ignore missing-attribute baseline_timing None baseline_timing = call_func func baseline_config log debug = Do coordinate descent tuning s = name log debug s Baseline Config s baseline timing f name baseline_config baseline_timing improved = True best_config = baseline_config best_timing = baseline_timing tunable_fields = tunable_fields while improved improved = False name tunable_fields cur_val = get_field best_config name some kernel don t have R _BLOCK YBLOCK ZBLOCK So cur_val may None cur_val None continue It s possible candidate_values empty E g XBLOCK initially size_hint x also We would try either larger smaller XBLOCK case candidate_values = get_neighbour_values name cur_val next_val candidate_values candidate_config = copy deepcopy best_config set_field candidate_config name next_val cmp_res candidate_timing = compare_config func candidate_config best_config best_timing cmp_res improved = True best_config best_timing = candidate_config candidate_timing improved inductor_meta get coordinate_descent_check_all_directions old_best_timing = best_timing improved best_config best_timing = check_all_tuning_directions func best_config best_timing improved msg = red_text s Coordinate descend tuning found improvement fx looking all directions log debug msg name old_best_timing best_timing log debug s Improve s f - s f fx name baseline_config baseline_timing best_config best_timing baseline_timing best_timing best_config staticmethod autotune_single_field fn init_val min_val=None max_val=None fn function takes field value returns benchmarking result init_val starting point autotuning Should work well parabola like curve Here real example split-size mix-order-reduction https github com pytorch pytorch pull cache = _bench val val cache cache val = fn val print f split size val - cache val f ms cache val min_val None min_val = max_val None max_val = some arbitrary large value best_val = init_val improved = True while improved improved = False candlist = best_val best_val cand candlist cand = max cand min_val cand = min cand max_val _bench cand _bench best_val best_val = cand improved = True best_val