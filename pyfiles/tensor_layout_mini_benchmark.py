torch torch _inductor ir torch _inductor runtime benchmarking benchmarker to_channels_last x assert x dim == NCHW - NHWC stride_order = y = x clone as_strided x shape ir FlexibleLayout stride_ordered x shape stride_order y copy_ x assert torch allclose x y y bench_conv with_stack=True x = torch rand cuda weight = torch rand cuda x_chan = to_channels_last x weight_chan = to_channels_last weight kwargs = stride padding dilation transposed False output_padding groups baseline_fn torch convolution x weight bias=None kwargs test_fn torch convolution x_chan weight_chan bias=None kwargs warmup baseline_fn test_fn torch cuda synchronize torch profiler profile with_stack=with_stack p baseline_out = baseline_fn test_out = test_fn torch cuda synchronize p export_chrome_trace tmp chrome json assert torch allclose baseline_out test_out atol= e- rtol= e- baseline_out test_out baseline_ms = benchmarker benchmark_gpu baseline_fn rep= test_ms = benchmarker benchmark_gpu test_fn rep= print f baseline baseline_ms test test_ms speedup baseline_ms test_ms f x main bench_conv __name__ == __main__ main