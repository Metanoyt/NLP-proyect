Owner s oncall quantization copy torch torch ao quantization _equalize _equalize torch nn nn torch ao quantization fuse_modules fuse_modules torch testing _internal common_quantization QuantizationTestCase torch testing _internal common_utils raise_on_run_directly TestEqualizeEager QuantizationTestCase checkChannelsEqualized tensor tensor output_axis input_axis Checks channel ranges tensor tensor same which indication equalization has been applied correctly output_channel_tensor = _equalize channel_range tensor output_axis input_channel_tensor = _equalize channel_range tensor input_axis ensuring channels ranges tensor s input same tensor s output assertEqual output_channel_tensor input_channel_tensor getModule model name Given name submodule model submodule curr = model name = name split subname name curr = curr _modules subname curr test_cross_layer_equalization applies _equalize cross_layer_equalization two modules checks make sure channels ranges equivalent module = nn Conv d module = nn Linear module _output_channel_axis = module _input_channel_axis = _equalize cross_layer_equalization module module mod_tensor mod_tensor = module weight module weight checkChannelsEqualized mod_tensor mod_tensor module _output_channel_axis module _input_channel_axis test_converged Sanity checks _equalize converged working identical modules should true modules high difference weights should false module = nn Linear module = nn Linear module weight = nn parameter Parameter torch ones module weight size module weight = nn parameter Parameter torch zeros module weight size input dictionary dictionary_ = linear module dictionary_ = linear module assertTrue _equalize converged dictionary_ dictionary_ e- assertFalse _equalize converged dictionary_ dictionary_ e- test_equalize First checks see _equalize equalize can handle multiple pair modules input then checks correctness function ensuring equalized unequalized versions model yield same output given same input ChainModule nn Module __init__ - None super __init__ linear = nn Linear linear = nn Linear linear = nn Linear forward x x = linear x x = linear x x = linear x x chain = ChainModule chain = copy deepcopy chain _equalize equalize chain linear linear linear linear e- linear = getModule chain linear linear = getModule chain linear linear = getModule chain linear checkChannelsEqualized linear weight linear weight checkChannelsEqualized linear weight linear weight input = torch randn assertEqual chain input chain input test_equalize_fused_convrelu Checks see eager mode equalization supports fused ConvReLU d models A model ConvReLU d constructed Next conv d relu layers fused together adjacent conv d layers have cross-layer equalization applied Finally we ensure channels have been equalized equalized unequalized versions model yield same output given same input M nn Module __init__ - None super __init__ conv = nn Conv d dtype=torch float relu = nn ReLU inplace=False dtype=torch float conv = nn Conv d dtype=torch float relu = nn ReLU inplace=False dtype=torch float conv = nn Conv d dtype=torch float relu = nn ReLU inplace=False dtype=torch float forward x x = conv x x = relu x x = conv x x = relu x x = conv x x = relu x x model = M fused_model = fuse_modules model conv relu conv relu conv relu fused_model = copy deepcopy fused_model _equalize equalize fused_model conv conv conv conv e- conv = getModule fused_model conv conv = getModule fused_model conv conv = getModule fused_model conv checkChannelsEqualized conv weight conv weight checkChannelsEqualized conv weight conv weight input = torch randn assertEqual fused_model input fused_model input assertEqual fused_model input model input test_equalize_fused_linearrelu Checks see eager mode equalization supports fused LinearReLU models A model LinearReLU constructed Next linear relu layers fused together adjacent linear layers have cross-layer equalization applied Finally we ensure channels have been equalized equalized unequalized versions model yield same output given same input M nn Module __init__ - None super __init__ linear = nn Linear relu = nn ReLU inplace=False dtype=torch float linear = nn Linear relu = nn ReLU inplace=False dtype=torch float linear = nn Linear relu = nn ReLU inplace=False dtype=torch float forward x x = linear x x = relu x x = linear x x = relu x x = linear x x = relu x x model = M fused_model = fuse_modules model linear relu linear relu linear relu fused_model = copy deepcopy fused_model _equalize equalize fused_model linear linear linear linear e- linear = getModule fused_model linear linear = getModule fused_model linear linear = getModule fused_model linear checkChannelsEqualized linear weight linear weight checkChannelsEqualized linear weight linear weight input = torch randn assertEqual fused_model input fused_model input assertEqual fused_model input model input __name__ == __main__ raise_on_run_directly test test_quantization py