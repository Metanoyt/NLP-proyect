Implement various linear algebra algorithms low rank matrices __all__ = svd_lowrank pca_lowrank typing Optional torch torch _linalg_utils _utils Tensor torch overrides handle_torch_function has_torch_function get_approximate_basis A Tensor q int niter Optional int = M Optional Tensor = None - Tensor Return tensor math ` Q ` math ` q ` orthonormal columns such math ` Q Q^H A ` approximates math ` A ` If math ` M ` specified then math ` Q ` such math ` Q Q^H A - M ` approximates math ` A - M ` without instantiating any tensors size math ` A ` math ` M ` note The implementation based Algorithm Halko et al note For adequate approximation k-rank matrix math ` A ` where k known advance could estimated number math ` Q ` columns q can chosen according following criteria general math ` k = q = min k m n ` For large low-rank matrices take math ` q = k + ` If k relatively small compared math ` min m n ` choosing math ` q = k + ` may sufficient note To obtain repeatable results reset seed pseudorandom number generator Args A Tensor input tensor size math ` m n ` q int dimension subspace spanned math ` Q ` columns niter int optional number subspace iterations conduct ` ` niter ` ` must nonnegative integer In most cases default value more than enough M Tensor optional input tensor s mean size math ` m n ` References - Nathan Halko Per-Gunnar Martinsson Joel Tropp Finding structure randomness probabilistic algorithms constructing approximate matrix decompositions arXiv math NA math PR available ` arXiv http arxiv org abs ` _ niter = niter None niter dtype = _utils get_floating_dtype A A is_complex A dtype matmul = _utils matmul R = torch randn A shape - q dtype=dtype device=A device The following code could made faster using torch geqrf + torch ormqr geqrf differentiable X = matmul A R M None X = X - matmul M R Q = torch linalg qr X Q _ range niter X = matmul A mH Q M None X = X - matmul M mH Q Q = torch linalg qr X Q X = matmul A Q M None X = X - matmul M Q Q = torch linalg qr X Q Q svd_lowrank A Tensor q Optional int = niter Optional int = M Optional Tensor = None - tuple Tensor Tensor Tensor r Return singular value decomposition ` ` U S V ` ` matrix batches matrices sparse matrix math ` A ` such math ` A \approx U \operatorname diag S V^ \text H ` In case math ` M ` given then SVD computed matrix math ` A - M ` note The implementation based Algorithm Halko et al note For adequate approximation k-rank matrix math ` A ` where k known advance could estimated number math ` Q ` columns q can chosen according following criteria general math ` k = q = min k m n ` For large low-rank matrices take math ` q = k + ` If k relatively small compared math ` min m n ` choosing math ` q = k + ` may sufficient note This randomized method To obtain repeatable results set seed pseudorandom number generator note In general use full-rank SVD implementation func ` torch linalg svd ` dense matrices due its x higher performance characteristics The low-rank SVD will useful huge sparse matrices func ` torch linalg svd ` cannot handle Args A Tensor input tensor size math ` m n ` q int optional slightly overestimated rank A niter int optional number subspace iterations conduct niter must nonnegative integer defaults M Tensor optional input tensor s mean size math ` m n ` which will broadcasted size A function References - Nathan Halko Per-Gunnar Martinsson Joel Tropp Finding structure randomness probabilistic algorithms constructing approximate matrix decompositions arXiv math NA math PR available ` arXiv https arxiv org abs ` _ torch jit is_scripting tensor_ops = A M set map type tensor_ops issubset torch Tensor type None has_torch_function tensor_ops handle_torch_function svd_lowrank tensor_ops A q=q niter=niter M=M _svd_lowrank A q=q niter=niter M=M _svd_lowrank A Tensor q Optional int = niter Optional int = M Optional Tensor = None - tuple Tensor Tensor Tensor Algorithm Halko et al q = q None q m n = A shape - matmul = _utils matmul M None M = M broadcast_to A size Assume A tall m n A = A mH M None M = M mH Q = get_approximate_basis A q niter=niter M=M B = matmul Q mH A M None B = B - matmul Q mH M U S Vh = torch linalg svd B full_matrices=False V = Vh mH U = Q matmul U m n U V = V U U S V pca_lowrank A Tensor q Optional int = None center bool = True niter int = - tuple Tensor Tensor Tensor r Performs linear Principal Component Analysis PCA low-rank matrix batches such matrices sparse matrix This function returns namedtuple ` ` U S V ` ` which nearly optimal approximation singular value decomposition centered matrix math ` A ` such math ` A \approx U \operatorname diag S V^ \text H ` note The relation ` ` U S V ` ` PCA follows - math ` A ` data matrix ` ` m ` ` samples ` ` n ` ` features - math ` V ` columns represent principal directions - math ` S m - ` contains eigenvalues math ` A^T A m - ` which covariance ` ` A ` ` when ` ` center=True ` ` provided - ` ` matmul A V k ` ` projects data first k principal components note Different standard SVD size returned matrices depend specified rank q values follows - math ` U ` m x q matrix - math ` S ` q-vector - math ` V ` n x q matrix note To obtain repeatable results reset seed pseudorandom number generator Args A Tensor input tensor size math ` m n ` q int optional slightly overestimated rank math ` A ` By default ` ` q = min m n ` ` center bool optional True center input tensor otherwise assume input centered niter int optional number subspace iterations conduct niter must nonnegative integer defaults References - Nathan Halko Per-Gunnar Martinsson Joel Tropp Finding structure randomness probabilistic algorithms constructing approximate matrix decompositions arXiv math NA math PR available ` arXiv http arxiv org abs ` _ torch jit is_scripting type A torch Tensor has_torch_function A handle_torch_function pca_lowrank A A q=q center=center niter=niter m n = A shape - q None q = min m n q = q = min m n raise ValueError f q = q must non-negative integer greater than min m n = min m n niter = raise ValueError f niter = niter must non-negative integer dtype = _utils get_floating_dtype A center _svd_lowrank A q niter=niter M=None _utils is_sparse A len A shape = raise ValueError pca_lowrank input expected -dimensional tensor c = torch sparse sum A dim= - m reshape c column_indices = c indices indices = torch zeros len column_indices dtype=column_indices dtype device=column_indices device indices = column_indices C_t = torch sparse_coo_tensor indices c values n dtype=dtype device=A device ones_m _t = torch ones A shape - + m dtype=dtype device=A device M = torch sparse mm C_t ones_m _t mT _svd_lowrank A q niter=niter M=M C = A mean dim= - keepdim=True _svd_lowrank A - C q niter=niter M=None