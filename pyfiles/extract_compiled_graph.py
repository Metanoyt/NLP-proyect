mypy allow-untyped-defs copy dataclasses itertools os collections abc Callable typing Any torch torch _lazy lazy torch _lazy metrics metrics torch fx torch _lazy computation debug lazy_debug torch _lazy tensor_factory_functions tensor_factory_functions debug = os environ get debug_extract_compiled_graph None dataclasses dataclass GraphInputMatcher The GraphInputMatcher setup graph inputs future calls after lazy tracing Specifically those graph inputs corresponding method parameters should replaced arguments current call tensor_id_to_arg_idx maps tensor id parameter index graph_input_tensor_ids graph_input_ivalues list tensor_id ivalue each TS XLA graph inputs tensor_id_to_arg_idx dict int int graph_input_tensor_ids list int there categories graph_input_tensors Category those whose id found tensor_id_to_arg_idx These most likely const tensors we can get its content graph_input_tensors Category those whose id found tensor_id_to_arg_idx We should get tensor method arguments graph_input_ivalues list Any get real graph input tensors __call__ args real_input = tensor_id traced_ivalue zip graph_input_tensor_ids graph_input_ivalues arg_idx = tensor_id_to_arg_idx get tensor_id None arg_idx None inp = traced_ivalue inp = args arg_idx real_input append inp real_input ReturnValueHandler r When ltc_sync_multi called multi tensors compiled graph will contain output only unique tensors - tensor appears multiple times input _ltc_sync_multi only first occurrence matters However python level we still expect multi tensors returned duplication even TS graph dedup output e g method forward TS graph captured LTC will single tensor Python method expects This dedup lazy tensors first get index will used duplicate eager tensors later __init__ lazy_out_list index list list int = total_count = len lazy_out_list tensor_id_to_idx dict int int = dup_idx lazy_tensor enumerate lazy_out_list uniq_idx = tensor_id_to_idx get id lazy_tensor None uniq_idx None index uniq_idx append dup_idx uniq_idx = len index index append dup_idx tensor_id_to_idx id lazy_tensor = uniq_idx duplicate_eager_tensors eager_tensor_list duplicated_list = None total_count assert len eager_tensor_list == len index uniq_idx eager_tensor enumerate eager_tensor_list dup_idx index uniq_idx duplicated_list dup_idx = eager_tensor duplicated_list force_lazy_device model fx GraphModule Factory methods Fx graph may create tensors specific eager devices If we take no actions those eager tensors will mixed lazy tensors cause crash This method overwrite those eager device lazy device tolazydevice dev isinstance dev torch device torch device lazy index=dev index dev hasDeviceArg args kwargs any isinstance arg torch device arg itertools chain args kwargs values nd model graph nodes nd args = tuple tolazydevice arg arg nd args nd kwargs = k tolazydevice v k v nd kwargs items For torchbench like yolov hf_Bart dynamo generates Fx graph eager tensors default device check https gist github com shunting eabdf c c bc b f bb f yolove https gist github com shunting d e d d c hf_Bart To force those tensors lazy device we can simply override device argument since there no explicit device argument What we doing here list covered tensor factory methods we add lazy device argument explicitly TODO This solution no ideal since we may miss some factory methods In future when we support lazy mode method can replaced nd target tensor_factory_functions hasDeviceArg nd args nd kwargs kwargs = dict nd kwargs nd kwargs immutable make mutable copy kwargs device = torch device lazy nd kwargs = kwargs model recompile get_fallback_ops fallback_ops = opname metrics counter_names aten opname continue val = int metrics counter_value opname val fallback_ops append f opname = val fallback_ops extract_compiled_graph model fx GraphModule example_inputs - Callable Optimize eager model LTC returns wrapper execute compiled graph directly without retracing It depends other mechanisms like TorchDynamo guards guarantee returned wrapper only called when s safe lazy_args = arg device= lazy arg example_inputs args_tensor_ids = lazy get_tensor_id lazy_arg lazy_arg lazy_args tensor_id_to_arg_idx = tensor_id i i tensor_id enumerate args_tensor_ids lazy_model = copy deepcopy model device=torch device lazy force_lazy_device lazy_model This line executes lazy tracing enable us extracting compiled graph later metrics reset lazy_out = lazy_model lazy_args fallback_ops = get_fallback_ops metrics reset len fallback_ops raise RuntimeError f Fail extract compiled graph because fallback join fallback_ops isinstance lazy_out tuple list lazy_out = lazy_out args_and_out = tuple lazy_args + tuple lazy_out return_value_handler = ReturnValueHandler args_and_out debug print Fx code \n model code print LTC IR lazy_debug dump_ir args_and_out text TODO part TS backend specific now will generalized support XLA graph_input_tensor_ids graph_input_ivalues = computation get_tensors_ts_device_data_node args_and_out assert len graph_input_tensor_ids == len graph_input_ivalues graph_input_matcher = GraphInputMatcher tensor_id_to_arg_idx graph_input_tensor_ids graph_input_ivalues graph_hash = computation get_graph_hash args_and_out debug print graph_hash graph_hash print f args_tensor_ids args_tensor_ids print tensor ids device data graph_input_tensor_ids sync list output tensors so computation graph these tensors will cached Those computation graphs can retrieved graph hash later lazy sync_multi args_and_out optimized_mod args len args_and_out == graph_input = graph_input_matcher args res = return_value_handler duplicate_eager_tensors computation run_cached_graph graph_hash graph_input assert len res == len args_and_out i arg enumerate args only copy those tensors get inplace updated arg res i arg copy_ res i skip args res len args optimized_mod