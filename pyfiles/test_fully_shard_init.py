Owner s oncall distributed copy itertools typing cast Optional torch torch distributed dist torch nn nn torch distributed _composable replicate torch distributed device_mesh init_device_mesh torch distributed fsdp fully_shard MixedPrecisionPolicy torch distributed fsdp _fully_shard _fsdp_init _get_managed_modules _get_managed_states torch distributed fsdp _fully_shard _fsdp_param ParamModuleInfo torch distributed fsdp _fully_shard _fsdp_param_group _get_param_module_infos torch distributed fsdp _fully_shard _fully_shard FSDPModule torch distributed fsdp _init_utils _init_inter_node_process_group _init_intra_node_process_group torch distributed tensor DeviceMesh distribute_tensor DTensor Replicate Shard torch distributed tensor parallel ColwiseParallel parallelize_module RowwiseParallel torch distributed tensor placement_types _StridedShard torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp FSDPTestMultiThread get_devtype MLP torch testing _internal common_utils run_tests torch testing _internal distributed _tensor common_dtensor ModelArgs Transformer TransformerBlock device_type = torch device get_devtype TestFullyShardDeviceTensor FSDPTestMultiThread Tests tensor parameters moved expected device property world_size - int skip_if_lt_x_gpu test_move_states_to_device_tensor model = MLP torch device cpu with_buffer=True tensor itertools chain model parameters model buffers assertEqual tensor device torch device cpu fully_shard model accelerator_device = torch device device_type type torch get_device_module device_type current_device tensor itertools chain model parameters model buffers assertEqual tensor device accelerator_device skip_if_lt_x_gpu test_move_states_to_device_ignored_param_device cpu_device = torch device cpu model = MLP cpu_device with_buffer=True ignored_params = model out_proj weight model out_proj bias fully_shard model ignored_params=set ignored_params tensor ignored_params assertEqual tensor device cpu_device accelerator_device = torch device device_type type torch get_device_module device_type current_device model device_type tensor ignored_params assertEqual tensor device accelerator_device TestFullyShardDeviceDTensor FSDPTestMultiThread Tests DTensor parameters moved expected device property world_size - int skip_if_lt_x_gpu test_move_states_to_device_dtensor_valid assert world_size = f world_size dp_size = global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp dp_mesh tp_mesh = global_mesh dp global_mesh tp model = MLP torch device cpu with_buffer=True parallelize_module model tp_mesh in_proj ColwiseParallel out_proj RowwiseParallel accelerator_device = torch device device_type type torch get_device_module device_type current_device tensor itertools chain model parameters model buffers isinstance tensor DTensor DTensor constructor moves mesh s device assertEqual tensor device accelerator_device assertEqual tensor _local_tensor device accelerator_device assertEqual tensor device torch device cpu fully_shard model mesh=dp_mesh tensor itertools chain model parameters model buffers assertEqual tensor device accelerator_device isinstance tensor DTensor assertEqual tensor _local_tensor device accelerator_device skip_if_lt_x_gpu test_move_states_to_device_dtensor_invalid assert world_size = f world_size dp_size = global_accelerator_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp global_cpu_mesh = init_device_mesh cpu dp_size world_size dp_size mesh_dim_names= dp tp dp_mesh = global_accelerator_mesh dp tp_mesh = global_cpu_mesh tp mismatched meshes model = MLP torch device cpu with_buffer=True parallelize_module model tp_mesh in_proj ColwiseParallel out_proj RowwiseParallel tensor itertools chain model parameters model buffers assertEqual tensor device torch device cpu isinstance tensor DTensor assertEqual tensor _local_tensor device torch device cpu regex = rf Requires DTensor have mesh same type FSDP mesh got rf cpu DTensor device_type type FSDP assertRaisesRegex ValueError regex fully_shard model mesh=dp_mesh TestFullyShardMeshArg FSDPTestMultiThread Tests ` ` mesh ` ` argument property world_size - int skip_if_lt_x_gpu test_invalid_mesh_ndim mesh = init_device_mesh device_type type world_size model = MLP regex = r fully\_shard expects D D DeviceMesh got DeviceMesh assertRaisesRegex ValueError regex fully_shard model mesh=mesh skip_if_lt_x_gpu test_ d_mesh_without_mesh_dim_names mesh = init_device_mesh device_type type world_size model = MLP regex = Please init D mesh HSDP mesh_dim_names specified assertRaisesRegex AssertionError regex fully_shard model mesh=mesh TestFullyShardManagedModulesAndStates FSDPTestMultiThread Tests getting managed modules states ` ` fully_shard ` ` module property world_size - int skip_if_lt_x_gpu test_managed_modules_single model = MLP Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model expected_managed_modules = list model modules _check_managed_modules managed_modules expected_managed_modules skip_if_lt_x_gpu test_managed_modules_nested model = nn Sequential MLP _ range fully_shard model Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model expected_managed_modules = list model modules + model _check_managed_modules managed_modules expected_managed_modules skip_if_lt_x_gpu test_managed_modules_nested_fully_shard_and_replicate model = nn Sequential MLP _ range replicate model fully_shard model Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model expected_managed_modules = list model modules + model _check_managed_modules managed_modules expected_managed_modules skip_if_lt_x_gpu test_managed_modules_duplicate mlp = MLP model = nn Sequential mlp mlp duplicate MLP Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model Check duplicate module only counted once expected_managed_modules = list mlp modules + model _check_managed_modules managed_modules expected_managed_modules skip_if_lt_x_gpu test_managed_modules_list_of_mlps model = nn Sequential MLP _ range Assume calling ` fully_shard ` ` model model model ` managed_modules = _get_managed_modules model model model expected_managed_modules = list model modules + list model modules + list model modules _check_managed_modules managed_modules expected_managed_modules Assume calling ` fully_shard ` ` model model ` managed_modules = _get_managed_modules model model expected_managed_modules = list model modules + list model modules _check_managed_modules managed_modules list nn Module expected_managed_modules list nn Module assertEqual len managed_modules len expected_managed_modules Check set comparison since we do require anything about order assertEqual set managed_modules set expected_managed_modules skip_if_lt_x_gpu test_managed_states_shared_params_and_buffers model = nn Sequential MLP with_buffer=True _ range model in_proj weight = model in_proj weight model in_proj weight = model in_proj weight model buffer = model buffer Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model params buffers = _get_managed_states managed_modules expected_params = list model parameters de-dups shared expected_buffers = list model buffers de-dups shared _check_managed_states params buffers expected_params expected_buffers skip_if_lt_x_gpu test_managed_states_nested_fully_shard model = nn Sequential MLP with_buffer=True _ range fully_shard model Assume calling ` fully_shard ` ` model ` managed_modules = _get_managed_modules model params buffers = _get_managed_states managed_modules expected_params = list model parameters expected_buffers = list model buffers _check_managed_states params buffers expected_params expected_buffers skip_if_lt_x_gpu test_managed_states_list_of_mlps model = nn Sequential MLP with_buffer=True _ range Assume calling ` fully_shard ` ` model model model ` managed_modules = _get_managed_modules model model model params buffers = _get_managed_states managed_modules expected_params = list model parameters + list model parameters + list model parameters expected_buffers = list model buffers + list model buffers + list model buffers _check_managed_states params buffers expected_params expected_buffers _check_managed_states managed_params list nn Parameter managed_buffers list torch Tensor expected_managed_params list nn Parameter expected_managed_buffers list torch Tensor assertEqual len managed_params len expected_managed_params assertEqual len managed_buffers len expected_managed_buffers assertEqual set managed_params set expected_managed_params assertEqual set managed_buffers set expected_managed_buffers TestFullyShardParamModuleInfos FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_get_param_module_infos_shared_params model = nn Sequential MLP _ range model in_proj weight = model in_proj weight managed_modules = _get_managed_modules model params _ = _get_managed_states managed_modules param_module_infos = _get_param_module_infos params model assertEqual len param_module_infos len params We expect ` params ` already have de-duplicated shared parameters expected_param_module_infos = ParamModuleInfo model in_proj weight model in_proj weight ParamModuleInfo model in_proj bias ParamModuleInfo model out_proj weight ParamModuleInfo model out_proj bias ParamModuleInfo model in_proj bias ParamModuleInfo model out_proj weight ParamModuleInfo model out_proj bias assertEqual len param_module_infos len expected_param_module_infos assertEqual param_module_infos expected_param_module_infos skip_if_lt_x_gpu test_get_param_module_infos_duplicates mlp = MLP model = nn Sequential mlp mlp shared MLP params = list model parameters param_module_infos = _get_param_module_infos params model assertEqual len param_module_infos len params expected_param_module_infos = ParamModuleInfo mlp in_proj weight mlp in_proj weight ParamModuleInfo mlp in_proj bias mlp in_proj bias ParamModuleInfo mlp out_proj weight mlp out_proj weight ParamModuleInfo mlp out_proj bias mlp out_proj bias assertEqual len param_module_infos len expected_param_module_infos assertEqual param_module_infos expected_param_module_infos model = nn Sequential MLP _ range model in_proj = model in_proj shared in-projection params = list model parameters param_module_infos = _get_param_module_infos params model assertEqual len param_module_infos len params expected_param_module_infos = ParamModuleInfo model in_proj weight model in_proj weight ParamModuleInfo mlp in_proj bias ParamModuleInfo mlp out_proj weight ParamModuleInfo mlp out_proj bias skip_if_lt_x_gpu test_get_param_module_infos_list_of_mlps model = nn Sequential MLP _ range managed_modules = _get_managed_modules model model params _ = _get_managed_states managed_modules param_module_infos = _get_param_module_infos params model assertEqual len param_module_infos len params expected_param_module_infos = ParamModuleInfo model in_proj weight ParamModuleInfo model in_proj bias ParamModuleInfo model out_proj weight ParamModuleInfo model out_proj bias ParamModuleInfo model in_proj weight ParamModuleInfo model in_proj bias ParamModuleInfo model out_proj weight ParamModuleInfo model out_proj bias assertEqual len param_module_infos len expected_param_module_infos assertEqual param_module_infos expected_param_module_infos TestFullyShardShardedParameterTensor FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_shard_tensor_parameters Use odd dim sizes test uneven shards model = nn Sequential MLP dim_multiplier= _ range orig_params = param detach clone param model parameters fully_shard model sharded_params = list model parameters _check_ d_sharded_parameters orig_params sharded_params model = nn Sequential MLP dim_multiplier= _ range model in_proj = model in_proj orig_params = param detach clone param model parameters fully_shard model sharded_params = list model parameters _check_ d_sharded_parameters orig_params sharded_params _check_ d_sharded_parameters orig_params list nn Parameter sharded_params list nn Parameter assertEqual len orig_params len sharded_params global_mesh = init_device_mesh device_type type world_size orig_param sharded_param zip orig_params sharded_params assertIsInstance sharded_param DTensor assertEqual sharded_param device_mesh global_mesh assertEqual sharded_param size orig_param size assertEqual sharded_param stride orig_param stride assertEqual sharded_param _spec placements Shard chunks = torch chunk orig_param world_size dim= assertEqual sharded_param _local_tensor chunks rank skip_if_lt_x_gpu test_raise_scalar_parameter Tests raising exception when model has scalar parameters model = nn Sequential MLP dim_multiplier= _ range model register_parameter scalar_p nn Parameter torch tensor device_type assertRaisesRegex ValueError Change scalar_p D tensor numel equal fully_shard model skip_if_lt_x_gpu test_raise_noncontiguous_parameter Tests raising exception when model has non-contiguous parameters This due lack implementation support conv d = nn Conv d memory_format=torch channels_last assertRaisesRegex NotImplementedError FSDP does support non-contiguous parameters fully_shard conv d TestFullyShardShardedParameterDTensor FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_shard_dtensor_parameters dp_size = world_size global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp dp_mesh tp_mesh = global_mesh dp global_mesh tp Use odd dim sizes test uneven shards model = MLP dim_multiplier= orig_params = param detach clone param model parameters orig_param_names = param_name param_name _ model named_parameters parallelize_module model tp_mesh in_proj ColwiseParallel out_proj RowwiseParallel fully_shard model mesh=dp_mesh sharded_params = list model parameters assertEqual len orig_params len sharded_params orig_param_name orig_param sharded_param zip orig_param_names orig_params sharded_params assertIsInstance sharded_param DTensor assertEqual sharded_param device_mesh global_mesh assertEqual sharded_param size orig_param size assertEqual sharded_param stride orig_param stride in_proj orig_param_name expected_placements = _StridedShard split_factor=tp_mesh size Shard out_proj orig_param_name weight orig_param_name expected_placements = Shard Shard expected_placements = Shard Replicate assertEqual sharded_param _spec placements expected_placements TestFullyShardLazyInit FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_fully_shard_is_root Tests ` ` _is_root ` ` set correctly after lazy initialization FSDP model MLP FSDP in_proj FSDP out_proj MLP in_proj out_proj model = nn Sequential MLP MLP fully_shard model in_proj fully_shard model out_proj fully_shard model root gets ` model ` root_state = fully_shard state model root_state _lazy_init model _in_proj_state = fully_shard state model in_proj model _out_proj_state = fully_shard state model out_proj assertTrue root_state _is_root assertFalse model _in_proj_state _is_root assertFalse model _out_proj_state _is_root all_states = root_state _state_ctx all_states assertEqual len all_states assertEqual all_states root_state model _in_proj_state model _out_proj_state skip_if_lt_x_gpu test_fully_shard_module_and_param_fqns Tests module parameter FQNs computed correctly after lazy initialization FSDP model MLP FSDP in_proj FSDP out_proj MLP in_proj out_proj model = nn Sequential MLP MLP fully_shard model in_proj fully_shard model out_proj fully_shard model root gets ` model ` root_state = fully_shard state model root_state _lazy_init root_param_group = root_state _fsdp_param_group assertIsNotNone root_param_group assertEqual root_param_group _module_fqn root_param_fqns = fsdp_param _param_fqn fsdp_param root_param_group fsdp_params assertEqual root_param_fqns in_proj weight in_proj bias out_proj weight out_proj bias model _in_proj_state = fully_shard state model in_proj model _in_proj_param_group = model _in_proj_state _fsdp_param_group assertIsNotNone model _in_proj_param_group assertEqual model _in_proj_param_group _module_fqn in_proj model _in_proj_param_fqns = fsdp_param _param_fqn fsdp_param model _in_proj_param_group fsdp_params assertEqual model _in_proj_param_fqns in_proj weight in_proj bias model _out_proj_state = fully_shard state model out_proj model _out_proj_param_group = model _out_proj_state _fsdp_param_group assertIsNotNone model _out_proj_param_group assertEqual model _out_proj_param_group _module_fqn out_proj model _out_proj_param_fqns = fsdp_param _param_fqn fsdp_param model _out_proj_param_group fsdp_params assertEqual model _out_proj_param_fqns out_proj weight out_proj bias skip_if_lt_x_gpu test_fully_shard_double_lazy_init model = nn Sequential MLP MLP fully_shard model in_proj fully_shard model out_proj fully_shard model root_state = fully_shard state model model _in_proj_state = fully_shard state model in_proj model _in_proj_state _lazy_init regex = FSDP state has already been lazily initialized in_proj\n FSDP requires running forward through root module first assertRaisesRegex RuntimeError regex root_state _lazy_init skip_if_lt_x_gpu test_fully_shard_multi_module_root model = nn Sequential MLP MLP fully_shard model model root_state = fully_shard state model regex = FSDP requires single root module got assertRaisesRegex RuntimeError regex root_state _lazy_init skip_if_lt_x_gpu test_reset_sharded_param_in_lazy_init MyModel nn Module __init__ super __init__ layer = nn Linear bias=False layer = nn Linear bias=False weight_norm = nn Parameter torch empty init_weight_norm torch no_grad weight_norm = torch linalg norm layer weight dim= + torch linalg norm layer weight dim= model weight_norm = nn Parameter weight_norm forward inp torch Tensor - torch Tensor out = layer inp out = layer out out sum + weight_norm sum torch device meta model = MyModel fully_shard model layer fully_shard model layer fully_shard model model layer to_empty device=device_type type model layer to_empty device=device_type type model init_weight_norm inp = torch randn device=device_type type loss = model inp sum loss backward TestFullyShardMetaDeviceInit FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_meta_device_ d_init default_pg = torch distributed distributed_c d _get_default_group mesh = init_device_mesh device_type type mesh_shape= default_pg size Test both even sharding uneven sharding empty local tensor mlp_dim cover foreach_copy code path bf mp_policy MixedPrecisionPolicy MixedPrecisionPolicy param_dtype=torch bfloat reduce_dtype=torch float torch device meta model = nn Sequential MLP mlp_dim dim_multiplier= with_buffer=True bias=False MLP mlp_dim dim_multiplier= bias=False param model parameters assertEqual param device torch device meta fully_shard model mesh=mesh mp_policy=mp_policy fully_shard model mesh=mesh mp_policy=mp_policy fully_shard model mesh=mesh mp_policy=mp_policy param model parameters assertEqual param device torch device meta _test_to_empty_and_reset_parameters model mesh mlp_dim Test we can call ` fully_shard ` under meta-device context ` init_device_mesh ` call still works mlp_dim = torch device meta model = nn Sequential MLP mlp_dim with_buffer=True MLP mlp_dim param model parameters assertEqual param device torch device meta module model model model fully_shard module param model parameters assertEqual param device torch device meta _test_to_empty_and_reset_parameters model mesh mlp_dim skip_if_lt_x_gpu test_meta_device_ d_init assert world_size = f world_size dp_size = global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp dp_mesh tp_mesh = global_mesh dp global_mesh tp Test both even sharding uneven sharding mlp_dim torch device meta model = MLP mlp_dim with_buffer=True param model parameters assertEqual param device torch device meta parallelize_module model tp_mesh in_proj ColwiseParallel out_proj RowwiseParallel param model parameters assertEqual param device torch device meta fully_shard model in_proj mesh=dp_mesh fully_shard model out_proj mesh=dp_mesh fully_shard model mesh=dp_mesh param model parameters assertEqual param device torch device meta _test_to_empty_and_reset_parameters model global_mesh mlp_dim _test_to_empty_and_reset_parameters model nn Module mesh DeviceMesh mlp_dim int Check we can materialize GPU empty values device = torch device device_type type torch get_device_module device_type current_device model to_empty device=device param model parameters assertEqual param device device optim = torch optim Adam model parameters lr= e- Check ` reset_parameters ` each module initializes values const = tensor itertools chain model parameters model buffers tensor detach fill_ const module model modules hasattr module reset_parameters module reset_parameters param model parameters local_tensor = param to_local local_tensor numel assertNotEqual local_tensor torch ones_like local_tensor const buffer model buffers assertNotEqual buffer torch ones_like buffer const Check we can run iteration without erroring inp = torch randn mlp_dim device=device_type type model inp sum backward optim step skip_if_lt_x_gpu test_invalid_meta_device_init default_pg = torch distributed distributed_c d _get_default_group mesh = init_device_mesh device_type type mesh_shape= default_pg size mlp_dim = torch device meta model = nn Sequential MLP mlp_dim with_buffer=True MLP mlp_dim param model parameters assertEqual param device torch device meta fully_shard model mesh=mesh fully_shard model mesh=mesh fully_shard model mesh=mesh inp = torch randn mlp_dim device=device_type type error_regex = FSDP parameters should materialized meta device before training following still meta device r \ in_proj weight in_proj bias out_proj weight out_proj bias \ assertRaisesRegex RuntimeError error_regex model inp skip_if_lt_x_gpu test_rank _broadcast_meta_device_init model_args = ModelArgs dropout_p= Assume we have CPU full state dict rank rank == torch manual_seed ref_model = Transformer model_args full_sd = ref_model state_dict param full_sd values assertEqual param device torch device cpu Initialize sharded model meta device fsdp_mesh = init_device_mesh device_type type world_size torch device meta model = Transformer model_args module model modules isinstance module TransformerBlock fully_shard module mesh=fsdp_mesh fully_shard model mesh=fsdp_mesh param model parameters assertEqual param device torch device meta Construct sharded state dict rank full state dict broadcasting sharding meta_sharded_sd = model state_dict sharded_sd = rank == assertEqual len meta_sharded_sd len full_sd assertEqual list meta_sharded_sd keys list full_sd keys param_name full_param sharded_meta_param zip full_sd items meta_sharded_sd values full_param = full_param detach device_type mesh = sharded_meta_param device_mesh dist broadcast full_param src= group=mesh get_group sharded_tensor = distribute_tensor full_param mesh sharded_meta_param placements sharded_sd param_name = nn Parameter sharded_tensor param_name sharded_meta_param meta_sharded_sd items full_tensor = torch empty sharded_meta_param size device=device_type type dtype=sharded_meta_param dtype mesh = sharded_meta_param device_mesh dist broadcast full_tensor src= group=mesh get_group sharded_tensor = distribute_tensor full_tensor mesh sharded_meta_param placements sharded_sd param_name = nn Parameter sharded_tensor model load_state_dict sharded_sd assign=True param model parameters assertIsInstance param DTensor assertEqual param device type device_type type Construct reference model nonzero ranks broadcasting unsharded model rank sharding all ranks rank = ref_model = Transformer model_args param ref_model parameters torch distributed broadcast param detach src= module ref_model modules isinstance module TransformerBlock fully_shard module mesh=fsdp_mesh fully_shard ref_model mesh=fsdp_mesh param_name param ref_param_name ref_param zip model named_parameters ref_model named_parameters assertEqual param_name ref_param_name assertEqual param ref_param Check one forward backward parity inp = torch randint model_args vocab_size device=device_type type loss = model inp sum loss backward ref_loss = ref_model inp sum ref_loss backward assertEqual loss ref_loss param ref_param zip model parameters ref_model parameters assertEqual param grad ref_param grad TestFullyShardProcessGroupInit FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_ d_process_group_init assert world_size == f world_size For convenience use device mesh s infra construct DP PG practice trainer would do manually via ` new_group ` dp_size = global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp ref_dp_mesh tp_mesh = global_mesh dp global_mesh tp dp_pg = ref_dp_mesh get_group Check ` from_group ` API correctness dp_mesh = DeviceMesh from_group dp_pg device_type type mesh_dim_names= dp Only compare mesh tensors ` DeviceMesh ` objects themselves since ref has parent mesh while ` from_group ` one does assertEqual dp_mesh mesh ref_dp_mesh mesh assertEqual dp_mesh _coordinate_on_dim ref_dp_mesh _coordinate_on_dim assertEqual dp_mesh _dim_group_names ref_dp_mesh _dim_group_names Check D FSDP forward backward parity over DP mesh NOTE We cannot use D DTensor-based training here because DP mesh ` from_group ` does respect parent mesh torch manual_seed mlp_dim = ref_model = MLP mlp_dim param ref_model parameters dist broadcast param detach src= model = copy deepcopy ref_model Parallelize test model ref DP mesh module ref_model in_proj ref_model out_proj ref_model fully_shard module mesh=ref_dp_mesh Parallelize test model new DP mesh PG module model in_proj model out_proj model fully_shard module mesh=dp_mesh Ensure TP ranks have same input inp = torch randn mlp_dim device=device_type type rank dist broadcast inp src= group=tp_mesh get_group rank dist broadcast inp src= group=tp_mesh get_group ref_loss = ref_model inp sum ref_loss backward loss = model inp sum loss backward assertEqual loss ref_loss param ref_param zip model parameters ref_model parameters Cannot compare ` DTensor ` s directly since their meshes equal due ref parameter s mesh having parent mesh while other s mesh does assertEqual param to_local ref_param to_local assertEqual param device_mesh mesh ref_param device_mesh mesh assertEqual param grad to_local ref_param grad to_local assertEqual param grad device_mesh mesh ref_param grad device_mesh mesh skip_if_lt_x_gpu test_ d_process_group_init shard_mesh_dim_size = assert world_size shard_mesh_dim_size == f Expects world_size divisible shard_mesh_dim_size replicate_mesh_dim_size = world_size shard_mesh_dim_size mesh_dim_names = replicate shard ref_mesh = init_device_mesh device_type type replicate_mesh_dim_size shard_mesh_dim_size mesh_dim_names=mesh_dim_names Use global PG parent group practice could subgroup global PG dp_group = dist distributed_c d _get_default_group dp_shard_group = _init_intra_node_process_group shard_mesh_dim_size dp_replicate_group = _init_inter_node_process_group dp_group replicate_mesh_dim_size mesh_tensor = torch tensor dist get_process_group_ranks dp_group dtype=torch int view replicate_mesh_dim_size shard_mesh_dim_size Check ` from_group ` API correctness mesh = DeviceMesh from_group dp_replicate_group dp_shard_group device_type type mesh_dim_names=mesh_dim_names mesh=mesh_tensor assertEqual mesh mesh ref_mesh mesh assertEqual mesh _coordinate_on_dim ref_mesh _coordinate_on_dim mesh_dim_name mesh_dim_names child_mesh = mesh mesh_dim_name ref_child_mesh = ref_mesh mesh_dim_name assertEqual child_mesh ref_child_mesh child_ranks = dist distributed_c d get_process_group_ranks child_mesh get_group ref_child_ranks = dist distributed_c d get_process_group_ranks ref_child_mesh get_group assertEqual child_ranks ref_child_ranks Check HSDP forward backward parity torch manual_seed mlp_dim = ref_model = MLP mlp_dim param ref_model parameters dist broadcast param detach src= model = copy deepcopy ref_model Parallelize test model ref mesh module ref_model in_proj ref_model out_proj ref_model fully_shard module mesh=ref_mesh Parallelize test model new mesh PG module model in_proj model out_proj model fully_shard module mesh=mesh inp = torch randn mlp_dim device=device_type type ref_loss = ref_model inp sum ref_loss backward loss = model inp sum loss backward assertEqual loss ref_loss param ref_param zip model parameters ref_model parameters assertEqual param ref_param assertEqual param grad ref_param grad TestFullyShardHSDPBroadcast FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_hsdp_broadcast_across_replicas shard_size replicate_size = mesh = init_device_mesh device_type type replicate_size shard_size mesh_dim_names= replicate shard model_args = ModelArgs model = Transformer model_args Add buffer show flow works buffers too model buf = torch nn Buffer torch randn model_args dim module model modules isinstance module TransformerBlock fully_shard module mesh=mesh fully_shard model mesh=mesh Only preserve model states replicate mesh s rank mesh get_local_rank replicate tensor itertools chain model parameters model buffers tensor detach fill_ Check replicas different tensor itertools chain model parameters model buffers local_tensor = tensor to_local isinstance tensor DTensor tensor local_tensor_list = torch empty_like local_tensor _ range mesh replicate size dist all_gather local_tensor_list local_tensor group=mesh get_group replicate other_local_tensor local_tensor_list assertEqual other_local_tensor shape local_tensor_list shape assertNotEqual other_local_tensor local_tensor_list Broadcast replicate mesh s rank replicate_group = mesh get_group replicate tensor itertools chain model parameters model buffers E g mesh sharding dim- replicating dim- broadcast sources src_rank = dist get_process_group_ranks replicate_group torch distributed broadcast tensor to_local isinstance tensor DTensor tensor src=src_rank group=replicate_group Check replicas same tensor itertools chain model parameters model buffers local_tensor = tensor to_local isinstance tensor DTensor tensor local_tensor_list = torch empty_like local_tensor _ range mesh replicate size dist all_gather local_tensor_list local_tensor group=mesh get_group replicate other_local_tensor local_tensor_list assertEqual other_local_tensor local_tensor_list Check we can run iteration without erroring inp = torch randint model_args vocab_size device=device_type type model inp sum backward TestHSDPWithCustomHook FSDPTestMultiThread property world_size - int perThreadSetUp - None super perThreadSetUp torch set_default_device device_type skip_if_lt_x_gpu test_custom_hook_custom_stream hsdp_mesh = init_device_mesh device_type type mesh_dim_names= replicate shard model = MLP bias=False fully_shard model mesh=hsdp_mesh model = cast FSDPModule model custom_stream = torch get_device_module device_type Stream native HSDP should reject assertRaises ValueError cm model set_all_reduce_hook lambda output output stream=custom_stream ex = cm exception assertEqual str ex stream cannot set when using native HSDP FSDP + hook custom stream ok intra_pg = _init_intra_node_process_group fsdp_mesh = DeviceMesh from_group intra_pg device_type type dist get_process_group_ranks intra_pg mesh_dim_names= shard hook_used_stream = None _hook _output torch Tensor - None nonlocal hook_used_stream hook_used_stream = torch get_device_module device_type current_stream model = MLP bias=False fully_shard model mesh=fsdp_mesh model = cast FSDPModule model model set_all_reduce_hook _hook stream=custom_stream inp = torch arange dtype=torch float requires_grad=True view out = model inp out sum backward torch get_device_module device_type synchronize assertEqual hook_used_stream custom_stream skip_if_lt_x_gpu test_custom_hsdp_all_reduce_hook world_pg = dist distributed_c d _get_default_group intra_pg = _init_intra_node_process_group inter_pg = _init_inter_node_process_group world_pg mesh = DeviceMesh from_group intra_pg device_type type dist get_process_group_ranks intra_pg mesh_dim_names= shard model = MLP bias=False rank = dist get_rank rank_group = rank init weights constant within each group just simplify test numeric check when we do bwd torch nn init constant_ model in_proj weight rank_group torch nn init constant_ model out_proj weight rank_group model = fully_shard model mesh=mesh hook_called bool = False _custom_hook output torch Tensor - None nonlocal hook_called dist all_reduce output group=inter_pg op=dist ReduceOp AVG hook_called = True model set_all_reduce_hook _custom_hook inp = torch arange dtype=torch float requires_grad=True view out = model inp out sum backward torch get_device_module device_type synchronize custom hook fired assertTrue hook_called within each replica FSDP shards weights dim so half MLP weights x setup out_proj_local_grad = model out_proj weight grad to_local cpu in_proj_local_grad = model in_proj weight grad to_local cpu grad halved custom bwd all reduce hook during avg replica weights assertEqual out_proj_local_grad torch full dtype=torch float device= cpu assertEqual in_proj_local_grad torch arange dtype=torch float device= cpu repeat TestFullyShardShardPlacementFn FSDPTestMultiThread property world_size - int _init_models torch manual_seed model_args = ModelArgs n_layers= dropout_p= model = Transformer model_args param model parameters dist broadcast param detach src= ref_model = copy deepcopy model model ref_model skip_if_lt_x_gpu test_init_ d_transformer_shard_largest_dim model ref_model = _init_models shard_placement_fn param nn Parameter - Optional Shard largest_dim = largest_dim_size = - dim dim_size enumerate param shape dim_size largest_dim_size largest_dim = dim largest_dim_size = dim_size assert largest_dim = f param shape Shard largest_dim layer model layers fully_shard layer shard_placement_fn=shard_placement_fn fully_shard model shard_placement_fn=shard_placement_fn any_shard_dim = False param model parameters assertEqual len param placements assertIsInstance param placements Shard any_shard_dim &#124; = param placements dim == assertTrue any_shard_dim param ref_param zip model parameters ref_model parameters full_param = param full_tensor assertEqual full_param ref_param skip_if_lt_x_gpu test_init_ d_transformer_shard_dim_neg model ref_model = _init_models shard_placement_fn param nn Parameter - Optional Shard Check FSDP will normalize dim non-negative Shard - layer model layers fully_shard layer shard_placement_fn=shard_placement_fn fully_shard model shard_placement_fn=shard_placement_fn param ref_param zip model parameters ref_model parameters full_param = param full_tensor assertEqual full_param ref_param skip_if_lt_x_gpu test_init_ d_transformer_shard_diff_dim model ref_model = _init_models dp_size tp_size = world_size global_mesh = init_device_mesh device_type type dp_size tp_size mesh_dim_names= dp tp model = Transformer parallelize model global_mesh tp use_seq_parallel=True shard_placement_fn param nn Parameter - Optional Shard isinstance param DTensor placement param placements isinstance placement Shard shard_dim = param ndim - - placement dim assert shard_dim = f param shape Shard shard_dim Shard layer model layers fully_shard layer mesh=global_mesh dp shard_placement_fn=shard_placement_fn fully_shard model mesh=global_mesh dp shard_placement_fn=shard_placement_fn linear_weight_names = wq wk wv wo w w param_name param model named_parameters any n param_name n linear_weight_names weight param_name total_placement_dims = placement param placements assertTrue isinstance placement Shard total_placement_dims += placement dim assertEqual param ndim Check FSDP shards either dim- dim- TP shards other assertEqual total_placement_dims assertTrue any isinstance placement Shard placement param placements param ref_param zip model parameters ref_model parameters full_param = param full_tensor assertEqual full_param ref_param skip_if_lt_x_gpu test_init_ d_uneven_shard_largest_dim torch manual_seed model = nn Sequential nn Linear nn Linear shard_placement_fn param nn Parameter - Optional Shard largest_dim = - largest_dim_size = - dim dim_size enumerate param shape dim_size largest_dim_size largest_dim = dim largest_dim_size = dim_size assert largest_dim = f param shape assert largest_dim param ndim f largest_dim= param shape Shard largest_dim assertRaisesRegex NotImplementedError FSDP does support uneven sharding dim fully_shard model shard_placement_fn=shard_placement_fn skip_if_lt_x_gpu test_invalid_shard_dim model = nn Sequential nn Linear nn Linear shard_placement_fn param nn Parameter - Optional Shard Shard Shard invalid D bias parameters assertRaisesRegex AssertionError Shard dim invalid D tensor fully_shard model shard_placement_fn=shard_placement_fn TODO Remove test once we remove old path torch distributed _composable fsdp TestFullyShardOldImport FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_old_import_training model = nn Sequential nn Linear nn Linear mp_policy = MixedPrecisionPolicy param_dtype=torch bfloat fully_shard model mp_policy=mp_policy fully_shard model mp_policy=mp_policy fully_shard model mp_policy=mp_policy assertIsInstance model FSDPModule assertIsInstance model FSDPModule assertIsInstance model FSDPModule inp = torch randn device=device_type model inp sum backward TestFullyShardMixedDtypeParam FSDPTestMultiThread property world_size - int skip_if_lt_x_gpu test_mixed_dtypes_no_grad_param Model torch nn Module __init__ super __init__ no grad params different dtypes w_fp = torch nn Parameter torch empty dtype=torch float _e m fn requires_grad=False w_fp = torch nn Parameter torch empty dtype=torch float forward input mesh = init_device_mesh device_type type world_size model = Model fully_shard model mesh=mesh model __name__ == __main__ run_tests