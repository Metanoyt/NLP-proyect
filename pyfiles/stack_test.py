random operator_benchmark op_bench torch Microbenchmarks Stack operator Configs PT stack operator stack_configs_static_runtime = op_bench config_list attr_names= sizes N attrs= cross_product_configs= device cpu cuda dim list range tags= static_runtime stack_configs_short = op_bench config_list attr_names= sizes N attrs= noqa E noqa E noqa E cross_product_configs= device cpu cuda dim list range tags= short stack_configs_long = op_bench config_list attr_names= sizes N attrs= noqa E + - noqa E E noqa E cross_product_configs= device cpu cuda dim list range tags= long There different codepath CUDA dimensions stack_configs_multidim = op_bench config_list attr_names= sizes N attrs= noqa E noqa E + - + - + noqa E E cross_product_configs= device cpu cuda dim list range tags= multidim StackBenchmark op_bench TorchBenchmarkBase init sizes N dim device random seed inputs = gen_sizes = type sizes list N == - gen_sizes = sizes i range N gen_sizes append old_size callable old_size old_size old_size sizes s gen_sizes inputs append torch rand s device=device result = torch rand gen_sizes device=device inputs = result result inputs inputs dim dim set_module_name stack forward result torch Tensor inputs list torch Tensor dim int torch stack inputs dim=dim out=result op_bench generate_pt_test stack_configs_static_runtime + stack_configs_short + stack_configs_long + stack_configs_multidim StackBenchmark __name__ == __main__ op_bench benchmark_runner main