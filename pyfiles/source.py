This module provides Source classes track origins values PyTorch Dynamo Sources represent where values come e g local variables globals attributes used guard generation code reconstruction during compilation The module includes specialized sources - Local variables synthetic locals - Global variables constants - Object attributes method calls - NN module specialization specialized vs unspecialized - Random values tensor properties - Default argument handling - FSDP Fully Sharded Data Parallel modules Sources play key role Dynamo s guard system tracking value origins guard generation code reconstruction providing methods rebuild code needed recreate values dataclasses enum functools collections abc Callable typing Any Optional TYPE_CHECKING Union torch device device_type torch _guards ChainedSource Guard GuardSource Source utils bytecode_transformation create_binary_subscr create_build_tuple create_call_function TYPE_CHECKING codegen PyCodegen It shouldn t supported construct NNModuleVariable inside FSDP module so those cases omitted intentionally represents nn Modules tracked NNModuleVariable specialized implicit variable name _GUARD_SOURCE_SPECIALIZED_NN_MODULE = GuardSource LOCAL GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL GuardSource GLOBAL_SPECIALIZED_NN_MODULE GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL_SPECIALIZED_NN_MODULE Just ensure guard_source works GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE represents nn Modules tracked UnspecializedNNModuleVariable _GUARD_SOURCE_UNSPECIALIZED_NN_MODULE = GuardSource LOCAL GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE happens UnspecializedNNModule submodule NNModuleVariable GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE Just ensure guard_source works GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE represents nn Modules tracked UnspecializedBuiltinNNModuleVariable _GUARD_SOURCE_UNSPECIALIZED_BUILTIN_NN_MODULE = GuardSource LOCAL GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE Just ensure guard_source works GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE _GUARD_SOURCE_FSDP_MODULE = GuardSource LOCAL GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL GuardSource GLOBAL_FSDP_MODULE GuardSource LOCAL_SPECIALIZED_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_SPECIALIZED_NN_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource LOCAL_UNSPECIALIZED_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_UNSPECIALIZED_NN_MODULE GuardSource GLOBAL_FSDP_MODULE GuardSource LOCAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource LOCAL_FSDP_MODULE GuardSource GLOBAL_UNSPECIALIZED_BUILTIN_NN_MODULE GuardSource GLOBAL_FSDP_MODULE is_constant_source source Source - bool isinstance source ConstantSource True try source guard_source == GuardSource CONSTANT True except NotImplementedError pass False _get_source_debug_name source Optional Source - str source None unknown source try source name except NotImplementedError unknown source dataclasses dataclass frozen=True LocalSource Source local_name str Whether local input root frame is_input bool = False Whether we know input dynamic based example_inputs For non tensors we simply look first index tuple dynamism Optional frozenset str = None Whether item source _content_ cell dereferenced root frame i e s part ` co_cellvars ` ` co_freevars ` is_derefed_cell_contents bool = False reconstruct codegen PyCodegen - None is_derefed_cell_contents codegen load_deref local_name codegen append_output codegen create_load local_name guard_source - GuardSource GuardSource LOCAL name - str f L repr local_name dataclasses dataclass frozen=True SyntheticLocalSource Source local_name str reconstruct codegen PyCodegen - None codegen append_output codegen create_load local_name guard_source - GuardSource GuardSource SYNTHETIC_LOCAL name - str f SYNTHETIC_LOCAL local_name r dataclasses dataclass frozen=True RandomValueSource Source random_call_index int guard_source - GuardSource GuardSource RANDOM_VALUE reconstruct codegen PyCodegen - None codegen append_output codegen create_load codegen tx output random_values_var codegen append_output codegen create_load_const random_call_index codegen append_output create_binary_subscr name - str f random_value_ random_call_index dataclasses dataclass frozen=True GlobalSource Source global_name str reconstruct codegen PyCodegen - None codegen append_output codegen create_load_global global_name add=True guard_source - GuardSource GuardSource GLOBAL name - str f G repr global_name dataclasses dataclass frozen=True GlobalWeakRefSource Source global_name str reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen append_output codegen create_load_global global_name add=True codegen extend_output create_call_function False guard_source - GuardSource GuardSource GLOBAL name - str f G repr global_name dataclasses dataclass frozen=True WeakRefCallSource ChainedSource reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen base codegen extend_output create_call_function False guard_source - GuardSource base guard_source name - str f base name dataclasses dataclass frozen=True CallFunctionNoArgsSource WeakRefCallSource pass dataclasses dataclass frozen=True AttrSource ChainedSource member str __post_init__ - None assert base Can t construct AttrSource without valid base source member member_parts = member split object __setattr__ base AttrSource base join member_parts - object __setattr__ member member_parts - reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs member guard_source - GuardSource base guard_source name - str member isidentifier f getattr base name member r f base name member dataclasses dataclass frozen=True GenericAttrSource ChainedSource member str __post_init__ - None assert base Can t construct AttrSource without valid base source member member_parts = member split object __setattr__ base AttrSource base join member_parts - object __setattr__ member member_parts - reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs member guard_source - GuardSource base guard_source name - str f object __getattribute__ base name member r Represents obj __dict__ where obj type object dataclasses dataclass frozen=True TypeDictSource ChainedSource reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs __dict__ guard_source - GuardSource base guard_source name - str type ob __dict__ can proxy dict But C++ guard accessor we use type- tp_dict which dict So forcefully pass dict object ensure GuardManager registers its working dict object f dict base name __dict__ Represents obj __mro__ where object type object dataclasses dataclass frozen=True TypeMROSource ChainedSource reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs __mro__ guard_source - GuardSource base guard_source name - str f base name __mro__ dataclasses dataclass frozen=True LocalCellSource Source Conceptually ` LocalSource ` cell objects implicitly generated Python e g captured variables local_name str reconstruct codegen PyCodegen - None Although ` LOAD_FAST ` ` LOAD_CLOSURE ` have same semantics Dynamo s bytecode transformation differentiates them slightly so we always emit ` LOAD_CLOSURE ` here codegen append_output codegen create_load_closure local_name All other methods intentionally unimplemented because e g local cell object should never used guards Represents obj __code__ where object type object dataclasses dataclass frozen=True CodeSource ChainedSource reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs __code__ guard_source - GuardSource base guard_source name - str f base name __code__ Represents obj __closure__ where object type object dataclasses dataclass frozen=True ClosureSource ChainedSource reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs __closure__ guard_source - GuardSource base guard_source name - str f base name __closure__ Represents tensor grad source It could represented AttrSource well But we could access grad field tensor directly C++ without going through Python bytecodes Therefore we use separate source grad field dataclasses dataclass frozen=True GradSource ChainedSource member str = grad reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs member guard_source - GuardSource base guard_source name - str f base name member dataclasses dataclass frozen=True ParamBufferSource AttrSource guard_source - GuardSource _GUARD_SOURCE_SPECIALIZED_NN_MODULE base guard_source Special AttrSource differentiate module _buffers module _parameters dataclasses dataclass frozen=True UnspecializedParamBufferSource AttrSource pass This source intended used places where source needed expected symbol will simplified out later Symbols ephemeral sources prioritized simplified out when e g compared against symbol without ephemeral source Guarding source error Example During subclass view fake-ification any close-over ViewFunc state should symbolicized fake-ified avoid invalid specialization during view replay This source useful symbols utilized middle view chain expected present within final view shape metadata dataclasses dataclass frozen=True EphemeralSource Source desc Optional str = None guard_source - GuardSource GuardSource EPHEMERAL name - str f ephemeral + desc desc None make_guard fn Callable Any - Guard raise NotImplementedError is_ephemeral - bool True dataclasses dataclass frozen=True SkipGuardSource ChainedSource reconstruct codegen PyCodegen - None base reconstruct codegen guard_source - GuardSource base guard_source name - str base name TensorProperty enum Enum SIZE = STRIDE = STORAGE_OFFSET = method_name - str TensorProperty SIZE size TensorProperty STRIDE stride TensorProperty STORAGE_OFFSET storage_offset raise AssertionError f unhandled dataclasses dataclass frozen=True TensorPropertySource ChainedSource prop TensorProperty idx Optional int = None None STORAGE_OFFSET __post_init__ - None assert base None prop TensorProperty STORAGE_OFFSET assert idx None assert idx None reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ f call_ prop method_name codegen base idx None codegen append_output codegen create_load_const idx codegen extend_output create_call_function idx None False guard_source - GuardSource base guard_source name - str prop TensorProperty SIZE f base name size idx prop TensorProperty STRIDE f base name stride idx prop TensorProperty STORAGE_OFFSET assert idx None f base name storage_offset raise AssertionError f unhandled prop dataclasses dataclass frozen=True IndexedSource ChainedSource idx int __post_init__ - None assert base None reconstruct codegen PyCodegen - None raise NotImplementedError guard_source - GuardSource base guard_source name - str f idx base name dataclasses dataclass frozen=True NegateSource ChainedSource __post_init__ - None assert base None reconstruct codegen PyCodegen - None raise NotImplementedError guard_source - GuardSource base guard_source name - str NB use method call so function stripping regexes work f base name __neg__ dataclasses dataclass frozen=True ConvertIntSource ChainedSource __post_init__ - None assert base None reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource base guard_source name - str f cast_symbool_to_symint_guardless base name dataclasses dataclass frozen=True DynamicScalarSource ChainedSource is_int bool __post_init__ - None assert base None reconstruct codegen PyCodegen - None Integer casting reconstruction helps reduce amount DynamicInts returned user favor plain ints For example compiled region only does int arithmetic could DynamicInt without casting here codegen add_push_null lambda codegen load_import_from builtins int codegen base codegen extend_output create_call_function False guard_source - GuardSource base guard_source name - str f int base name dataclasses dataclass frozen=True FlattenScriptObjectSource ChainedSource __post_init__ - None assert base None reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource base guard_source name - str f base name __obj_flatten__ dataclasses dataclass frozen=True ScriptObjectQualifiedNameSource ChainedSource __post_init__ - None assert base None reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource base guard_source name - str f base name _type qualified_name AttrProxySource ChainedSource reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource base guard_source name - str f base name get_base dataclasses dataclass frozen=True DefaultsSource ChainedSource idx_key Union int str is_kw bool = False field str = dataclasses field init=False repr=False compare=False _name str = dataclasses field init=False repr=False compare=False __post_init__ - None assert base Base must valid source order properly track guard Defaults its origin is_kw assert isinstance idx_key str object __setattr__ field __kwdefaults__ object __setattr__ _name f base name field idx_key assert isinstance idx_key int object __setattr__ field __defaults__ object __setattr__ _name f base name field idx_key reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs field codegen append_output codegen create_load_const idx_key codegen append_output create_binary_subscr guard_source - GuardSource base guard_source name - str _name dataclasses dataclass frozen=True GetItemSource ChainedSource index Any index_is_slice bool = False __post_init__ - None assert base None isinstance index slice store hashable version slice so whole GetItemSource hashable super __setattr__ index index __reduce__ super __setattr__ index_is_slice True reconstruct codegen PyCodegen - None codegen base index_is_slice codegen append_output codegen create_load_const unpack_slice codegen append_output codegen create_load_const index codegen append_output create_binary_subscr guard_source - GuardSource base guard_source unpack_slice - slice assert index_is_slice slice_class slice_args = index slice_class slice_args name - str Index can following types index slice - example index constant - example string integer assert isinstance index Source index_is_slice f base name unpack_slice r f base name index r dataclasses dataclass frozen=True ConstDictKeySource ChainedSource index Any guard_source - GuardSource base guard_source reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ dict_keys_getitem codegen base codegen append_output codegen create_load_const index codegen extend_output create_call_function False name - str The list creation will CSE d PyExprCSEPass f list dict keys base name index r is_dict_key - bool True dataclasses dataclass frozen=True NonSerializableSetGetItemSource ChainedSource index int __post_init__ - None variables ConstantVariable assert ConstantVariable is_literal index guard_source - GuardSource base guard_source reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ set_getitem codegen base codegen append_output codegen create_load_const index codegen extend_output create_call_function False name - str set ordering might stable f list base name index r is_dict_key - bool False Used access item dictionary dataclasses dataclass frozen=True DictGetItemSource ChainedSource Key access dictionary It can one following types ConstDictKeySource constant - like string integer index Any __post_init__ - None variables ConstantVariable assert isinstance index ConstDictKeySource ConstantVariable is_literal index guard_source - GuardSource base guard_source reconstruct codegen PyCodegen - None Load dict codegen base Load key isinstance index Source codegen index codegen append_output codegen create_load_const index codegen append_output create_binary_subscr name - str isinstance index ConstDictKeySource f base name index name f base name index r Same DictGetItemSource used dict __getitem__ calls ensure torch compile does run overridden __getitem__ method dataclasses dataclass frozen=True DictSubclassGetItemSource ChainedSource Key access dictionary It can one following types ConstDictKeySource constant - like string integer index Any __post_init__ - None variables ConstantVariable assert isinstance index ConstDictKeySource ConstantVariable is_literal index guard_source - GuardSource base guard_source reconstruct codegen PyCodegen - None reconstruct dict __getitem__ dct key Load dict __getitem__ codegen add_push_null lambda codegen load_import_from utils __name__ dict_getitem Load dict codegen base Load key isinstance index Source codegen index codegen append_output codegen create_load_const index codegen extend_output create_call_function False name - str isinstance index ConstDictKeySource f dict __getitem__ base name index name f base name index r dataclasses dataclass frozen=True ListGetItemSource GetItemSource Same GetItemSource reconstruct name overridden list specific reconstruct codegen PyCodegen - None Reconstruct list __getitem__ lst index avoid any side effects possibly overridden __getitem__ Load list __getitem__ codegen add_push_null lambda codegen load_import_from utils __name__ list_getitem Load list codegen base Load index index_is_slice raise RuntimeError List slice temporary object should have source codegen append_output codegen create_load_const index codegen extend_output create_call_function False name - str Index can following types index slice - example index constant - example string integer assert isinstance index Source index_is_slice raise RuntimeError List slice temporary object should have source f list __getitem__ base name index r dataclasses dataclass frozen=True TupleIteratorGetItemSource GetItemSource reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ tuple_iterator_getitem codegen base codegen append_output codegen create_load_const index codegen extend_output create_call_function False name - str f ___tuple_iterator_getitem base name index r dataclasses dataclass frozen=True NamedTupleFieldsSource ChainedSource reconstruct codegen PyCodegen - None codegen base codegen extend_output codegen create_load_attrs _fields guard_source - GuardSource base guard_source name - str f ___namedtuple_fields base name dataclasses dataclass frozen=True DataclassFieldsSource ChainedSource reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ dataclass_fields codegen base codegen extend_output create_call_function False guard_source - GuardSource base guard_source name - str f ___dataclass_fields base name dataclasses dataclass frozen=True TypeSource ChainedSource __post_init__ - None assert base None reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from builtins type codegen base codegen extend_output create_call_function False guard_source - GuardSource base guard_source name - str f type base name dataclasses dataclass frozen=True OptimizerSource ChainedSource reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource base guard_source name - str base name dataclasses dataclass frozen=True NNModuleSource ChainedSource reconstruct codegen PyCodegen - None codegen base guard_source - GuardSource _GUARD_SOURCE_SPECIALIZED_NN_MODULE base guard_source name - str base name dataclasses dataclass frozen=True UnspecializedNNModuleSource NNModuleSource guard_source - GuardSource _GUARD_SOURCE_UNSPECIALIZED_NN_MODULE base guard_source dataclasses dataclass frozen=True UnspecializedBuiltinNNModuleSource UnspecializedNNModuleSource guard_source - GuardSource _GUARD_SOURCE_UNSPECIALIZED_BUILTIN_NN_MODULE base guard_source dataclasses dataclass frozen=True FSDPNNModuleSource NNModuleSource guard_source - GuardSource _GUARD_SOURCE_FSDP_MODULE base guard_source dataclasses dataclass frozen=True GlobalStateSource Source name - str guard_source - GuardSource GuardSource GLOBAL dataclasses dataclass frozen=True TorchSource Source Points actual ` torch ` module - used instead GlobalSource case user has overridden ` torch ` their local namespace __init__ args Any kwargs Any - None super __init__ args kwargs guards GuardBuilder install_guard install_guard make_guard GuardBuilder ID_MATCH name - str __import__ torch reconstruct codegen PyCodegen - None codegen extend_output codegen create_load_const level create_build_tuple fromlist codegen create_import_name torch guard_source - GuardSource GuardSource GLOBAL dataclasses dataclass frozen=True TorchFunctionModeStackSource Source ind int name - str f ___get_torch_function_mode_stack_at _get_index _get_index - int variables torch_function TorchFunctionModeStackVariable TorchFunctionModeStackVariable get_mode_index ind reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from utils __name__ get_torch_function_mode_stack_at codegen extend_output codegen create_load_const _get_index codegen extend_output create_call_function False guard_source - GuardSource GuardSource GLOBAL dataclasses dataclass frozen=True ConstantSource Source source_name str reconstruct codegen PyCodegen - None codegen append_output codegen create_load_global source_name add=False guard_source - GuardSource GuardSource CONSTANT name - str source_name make_guard fn Any - Any raise NotImplementedError dataclasses dataclass frozen=True NumpyTensorSource ChainedSource name - str f ___from_numpy base name guard_source - GuardSource base guard_source reconstruct codegen PyCodegen - None codegen add_push_null lambda codegen load_import_from torch as_tensor codegen base codegen extend_output create_call_function False dataclasses dataclass frozen=True SubclassAttrListSource ChainedSource name - str f base name __tensor_flatten__ guard_source - GuardSource base guard_source NB We don t expect you actually ever generate guards against source ephemeral dataclasses dataclass frozen=True FloatTensorSource ChainedSource name - str f ___as_tensor base name guard_source - GuardSource base guard_source dataclasses dataclass frozen=True CallMethodItemSource ChainedSource name - str f base name item guard_source - GuardSource base guard_source This synthetic source associated singleton shape env guard we always register all frames We get actual guard contents ambient ShapeEnv dataclasses dataclass frozen=True ShapeEnvSource Source name - str guard_source - GuardSource GuardSource SHAPE_ENV dataclasses dataclass frozen=True CurrentStreamSource Source device device_type name - str f ___get_current_stream torch device device type device index reconstruct codegen PyCodegen - None num_args = codegen add_push_null lambda codegen load_import_from utils __name__ get_current_stream codegen add_push_null lambda codegen load_import_from torch device codegen extend_output codegen create_load_const device type device index None num_args += codegen extend_output codegen create_load_const device index codegen extend_output create_call_function num_args False codegen extend_output create_call_function False guard_source - GuardSource GuardSource GLOBAL dataclasses dataclass frozen=True BackwardStateSource Source name - str guard_source - GuardSource GuardSource BACKWARD_STATE get_local_source_name source Source only_allow_input bool = False - Optional str isinstance source ChainedSource get_local_source_name source base only_allow_input=only_allow_input isinstance source LocalSource None only_allow_input source is_input None source local_name is_from_local_source source Source only_allow_input bool = False - bool get_local_source_name source only_allow_input=only_allow_input None is_from_global_source source Source - bool get_global_source_name source None get_global_source_name source Source - Optional str isinstance source ChainedSource get_global_source_name source base isinstance source GlobalSource None source global_name is_from_nonlocal_source source Source - bool isinstance source ChainedSource is_from_nonlocal_source source base isinstance source LocalSource source is_derefed_cell_contents source is_input is_from_closure_source source Source - bool isinstance source ClosureSource True isinstance source ChainedSource is_from_closure_source source base False is_from_source source Source target Source - bool isinstance source ChainedSource is_from_source source base target source == target functools lru_cache is_from_unspecialized_nn_module_source source Source - bool isinstance source UnspecializedNNModuleSource True isinstance source ChainedSource is_from_unspecialized_nn_module_source source base False functools lru_cache is_from_unspecialized_builtin_nn_module_source source Source - bool isinstance source UnspecializedBuiltinNNModuleSource True isinstance source ChainedSource is_from_unspecialized_builtin_nn_module_source source base False functools lru_cache is_from_unspecialized_param_buffer_source source Source - bool isinstance source UnspecializedParamBufferSource True isinstance source ChainedSource is_from_unspecialized_param_buffer_source source base False functools lru_cache is_from_flatten_script_object_source source Source - bool isinstance source FlattenScriptObjectSource True isinstance source ChainedSource is_from_flatten_script_object_source source base False functools lru_cache is_from_optimizer_source source Source - bool isinstance source OptimizerSource True isinstance source ChainedSource is_from_optimizer_source source base False TODO can probably write generic test everything chain helper functools lru_cache is_from_defaults source Source - bool isinstance source DefaultsSource True Accessed func __kwdefaults__ foo isinstance source DictGetItemSource isinstance source base AttrSource source base member == __kwdefaults__ True Accessed func __defaults__ isinstance source GetItemSource isinstance source base AttrSource source base member == __defaults__ True isinstance source ChainedSource is_from_defaults source base False functools lru_cache is_from_skip_guard_source source Source - bool isinstance source SkipGuardSource True isinstance source ChainedSource is_from_skip_guard_source source base False