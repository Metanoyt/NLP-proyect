contextlib collections abc Generator Sequence typing Optional torch torch utils _content_store ContentStoreReader LOAD_TENSOR_READER Optional ContentStoreReader = None contextlib contextmanager load_tensor_reader loc str - Generator None None None global LOAD_TENSOR_READER assert LOAD_TENSOR_READER None load_tensor op we will play merry hell Inductor s memory planning we tensor aliases another tensor we previously returned operator So unlike standard ContentStoreReader use we disable cache so you always get fresh storages no aliasing you LOAD_TENSOR_READER = ContentStoreReader loc cache=False try yield finally LOAD_TENSOR_READER = None register_debug_prims - None torch library define debugprims load_tensor str name int size int stride ScalarType dtype Device device - Tensor torch library impl debugprims load_tensor BackendSelect load_tensor_factory name str size Sequence int stride Sequence int dtype torch dtype device torch device - torch Tensor LOAD_TENSOR_READER None torch _dynamo testing rand_strided rand_strided size stride dtype device torch _dynamo utils clone_input device argument here takes care coercion r = LOAD_TENSOR_READER read_tensor name device=device assert list r size == size f r size = size assert list r stride == stride f r stride = stride assert r device == device f r device = device Unlike other properties we will do coercions dtype mismatch r dtype = dtype r = clone_input r dtype=dtype type ignore no-untyped-call r