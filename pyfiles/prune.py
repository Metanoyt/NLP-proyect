mypy allow-untyped-defs r Pruning methods numbers abc ABC abstractmethod collections abc Iterable torch BasePruningMethod ABC r Abstract base creation new pruning techniques Provides skeleton customization requiring overriding methods such meth ` compute_mask ` meth ` apply ` _tensor_name str __call__ module inputs r Multiply mask into original tensor store result Multiplies mask stored ` ` module name + _mask ` ` into original tensor stored ` ` module name + _orig ` ` stores result into ` ` module name ` ` using meth ` apply_mask ` Args module nn Module module containing tensor prune inputs used setattr module _tensor_name apply_mask module abstractmethod compute_mask t default_mask r Compute returns mask input tensor ` ` t ` ` Starting base ` ` default_mask ` ` which should mask ones tensor has been pruned yet generate random mask apply top ` ` default_mask ` ` according specific pruning method recipe Args t torch Tensor tensor representing importance scores parameter prune default_mask torch Tensor Base mask previous pruning iterations need respected after new mask applied Same dims ` ` t ` ` Returns mask torch Tensor mask apply ` ` t ` ` same dims ` ` t ` ` apply_mask module r Simply handles multiplication between parameter being pruned generated mask Fetches mask original tensor module returns pruned version tensor Args module nn Module module containing tensor prune Returns pruned_tensor torch Tensor pruned version input tensor carry out multiplication mask needs have been computed so pruning method must know what tensor s operating assert _tensor_name None f Module module has pruned gets set apply mask = getattr module _tensor_name + _mask orig = getattr module _tensor_name + _orig pruned_tensor = mask dtype=orig dtype orig pruned_tensor classmethod apply cls module name args importance_scores=None kwargs r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act args arguments passed subclass ` BasePruningMethod ` importance_scores torch Tensor tensor importance scores same shape module parameter used compute mask pruning The values tensor indicate importance corresponding elements parameter being pruned If unspecified None parameter will used its place kwargs keyword arguments passed subclass ` BasePruningMethod ` _get_composite_method cls module name args kwargs Check pruning method has already been applied ` module name ` If so store ` old_method ` old_method = None found = there should technically only hook hook name == name assert using ` found ` hooks_to_remove = k hook module _forward_pre_hooks items exists take existing thing remove hook then go through normal thing isinstance hook BasePruningMethod hook _tensor_name == name old_method = hook hooks_to_remove append k found += assert found = f Avoid adding multiple pruning hooks the\ same tensor name module module Use PruningContainer k hooks_to_remove del module _forward_pre_hooks k Apply new pruning method either scratch top previous one method = cls args kwargs new pruning Have pruning method remember what tensor s been applied method _tensor_name = name combine ` methods ` ` old_method ` ` old_method ` exists old_method None meaning there hook hook already pruning container just add new pruning method container isinstance old_method PruningContainer old_method add_pruning_method method method = old_method rename old_method -- method hook simply single pruning method create container add old pruning method new one isinstance old_method BasePruningMethod container = PruningContainer old_method Have pruning method remember name its tensor setattr container _tensor_name name container add_pruning_method method method = container rename container -- method method method = _get_composite_method cls module name args kwargs point we have no forward_pre_hooks we could have active reparameterization tensor another pruning method had been applied which case ` method ` would PruningContainer simple pruning method Pruning applied module s tensor named ` name ` starting state found prior iteration pruning The pruning mask calculated based importances scores orig = getattr module name importance_scores None assert importance_scores shape == orig shape f importance_scores should have same shape parameter name module importance_scores = orig If first time pruning applied take care moving original tensor new parameter called name + _orig deleting original parameter isinstance method PruningContainer copy ` module name ` ` module name + _orig ` module register_parameter name + _orig orig temporarily delete ` module name ` del module _parameters name default_mask = torch ones_like orig temp If first time pruning applied all above has been done before previous pruning iteration so we re good go default_mask = getattr module name + _mask detach clone memory_format=torch contiguous_format Use try except because anything goes wrong mask computation etc you d want roll back try get final mask computed according specific method mask = method compute_mask importance_scores default_mask=default_mask reparameterize saving mask ` module name + _mask ` module register_buffer name + _mask mask new pruned tensor ` module name ` setattr module name method apply_mask module associate pruning method module via hook compute function before every forward compile run module register_forward_pre_hook method except Exception e isinstance method PruningContainer orig = getattr module name + _orig module register_parameter name orig del module _parameters name + _orig raise e method prune t default_mask=None importance_scores=None r Compute returns pruned version input tensor ` ` t ` ` According pruning rule specified meth ` compute_mask ` Args t torch Tensor tensor prune same dimensions ` ` default_mask ` ` importance_scores torch Tensor tensor importance scores same shape ` ` t ` ` used compute mask pruning ` ` t ` ` The values tensor indicate importance corresponding elements ` ` t ` ` being pruned If unspecified None tensor ` ` t ` ` will used its place default_mask torch Tensor optional mask previous pruning iteration any To considered when determining what portion tensor pruning should act If None default mask ones Returns pruned version tensor ` ` t ` ` importance_scores None assert importance_scores shape == t shape importance_scores should have same shape tensor t importance_scores = t default_mask = default_mask default_mask None torch ones_like t t compute_mask importance_scores default_mask=default_mask remove module r Remove pruning reparameterization module The pruned parameter named ` ` name ` ` remains permanently pruned parameter named ` ` name+ _orig ` ` removed parameter list Similarly buffer named ` ` name+ _mask ` ` removed buffers Note Pruning itself NOT undone reversed before removing pruning tensor has have been applied assert _tensor_name None f Module module has pruned before pruning can removed gets set apply update module name latest trained weights weight = apply_mask module masked weights delete reset hasattr module _tensor_name delattr module _tensor_name orig = module _parameters _tensor_name + _orig orig data = weight data del module _parameters _tensor_name + _orig del module _buffers _tensor_name + _mask setattr module _tensor_name orig PruningContainer BasePruningMethod Container holding sequence pruning methods iterative pruning Keeps track order which pruning methods applied handles combining successive pruning calls Accepts argument instance BasePruningMethod iterable them __init__ args _pruning_methods tuple BasePruningMethod = isinstance args Iterable only item _tensor_name = args _tensor_name add_pruning_method args pyrefly ignore bad-argument-type len args == only item tuple pyrefly ignore index-error _tensor_name = args _tensor_name pyrefly ignore index-error add_pruning_method args manual construction list other iterable no args method args add_pruning_method method add_pruning_method method r Add child pruning ` ` method ` ` container Args method subclass BasePruningMethod child pruning method added container check we re adding pruning method container isinstance method BasePruningMethod method None raise TypeError f type method BasePruningMethod subclass method None _tensor_name = method _tensor_name raise ValueError Can only add pruning methods acting f parameter named _tensor_name PruningContainer + f Found method _tensor_name all checks passed add _pruning_methods tuple _pruning_methods += method type ignore operator __len__ len _pruning_methods __iter__ iter _pruning_methods __getitem__ idx _pruning_methods idx compute_mask t default_mask r Apply latest ` ` method ` ` computing new partial masks returning its combination ` ` default_mask ` ` The new partial mask should computed entries channels zeroed out ` ` default_mask ` ` Which portions tensor ` ` t ` ` new mask will calculated depends ` ` PRUNING_TYPE ` ` handled type handler unstructured mask will computed raveled list nonmasked entries structured mask will computed nonmasked channels tensor global mask will computed across all entries Args t torch Tensor tensor representing parameter prune same dimensions ` ` default_mask ` ` default_mask torch Tensor mask previous pruning iteration Returns mask torch Tensor new mask combines effects ` ` default_mask ` ` new mask current pruning ` ` method ` ` same dimensions ` ` default_mask ` ` ` ` t ` ` _combine_masks method t mask r Combine masks all pruning methods returns new mask Args method BasePruningMethod subclass pruning method currently being applied t torch Tensor tensor representing parameter prune same dimensions mask mask torch Tensor mask previous pruning iteration Returns new_mask torch Tensor new mask combines effects old mask new mask current pruning method same dimensions mask t new_mask = mask start off existing mask new_mask = new_mask dtype=t dtype compute slice t onto which new pruning method will operate method PRUNING_TYPE == unstructured prune entries t where mask slc = mask == struct pruning exclude channels have already been entirely pruned method PRUNING_TYPE == structured hasattr method dim raise AttributeError Pruning methods PRUNING_TYPE structured need have attribute ` dim ` defined find channels keep removing ones have been zeroed out already i e where sum entries == n_dims = t dim D tensor D dim = method dim convert negative indexing dim dim = n_dims + dim dim still negative after subtracting n_dims dim raise IndexError f Index out bounds tensor dimensions n_dims find channels along dim = dim aren t already tots ed out keep_channel = mask sum dim= d d range n_dims d = dim = create slice identify what prune slc = slice None n_dims slc dim = keep_channel method PRUNING_TYPE == global n_dims = len t shape D tensor D slc = slice None n_dims raise ValueError f Unrecognized PRUNING_TYPE method PRUNING_TYPE compute new mask unpruned slice tensor t isinstance slc list slc = tuple slc partial_mask = method compute_mask t slc default_mask=mask slc new_mask slc = partial_mask dtype=new_mask dtype new_mask method = _pruning_methods - mask = _combine_masks method t default_mask mask Identity BasePruningMethod r Utility pruning method does prune any units generates pruning parametrization mask ones PRUNING_TYPE = unstructured compute_mask t default_mask mask = default_mask mask classmethod apply cls module name type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act super apply module name RandomUnstructured BasePruningMethod r Prune currently unpruned units tensor random Args name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune PRUNING_TYPE = unstructured __init__ amount Check range validity pruning amount _validate_pruning_amount_init amount amount = amount compute_mask t default_mask Check amount units prune than number parameters t tensor_size = t nelement Compute number units prune amount int amount tensor_size nparams_toprune = _compute_nparams_toprune amount tensor_size This should raise error number units prune larger than number units tensor _validate_pruning_amount nparams_toprune tensor_size mask = default_mask clone memory_format=torch contiguous_format nparams_toprune = k= supported torch kthvalue prob = torch rand_like t topk = torch topk prob view - k=nparams_toprune mask view - topk indices = mask classmethod apply cls module name amount type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune super apply module name amount=amount L Unstructured BasePruningMethod r Prune currently unpruned units tensor zeroing out ones lowest L -norm Args amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune PRUNING_TYPE = unstructured __init__ amount Check range validity pruning amount _validate_pruning_amount_init amount amount = amount compute_mask t default_mask Check amount units prune than number parameters t tensor_size = t nelement Compute number units prune amount int amount tensor_size nparams_toprune = _compute_nparams_toprune amount tensor_size This should raise error number units prune larger than number units tensor _validate_pruning_amount nparams_toprune tensor_size mask = default_mask clone memory_format=torch contiguous_format nparams_toprune = k= supported torch kthvalue largest=True -- top k largest=False -- bottom k Prune smallest k topk = torch topk torch abs t view - k=nparams_toprune largest=False topk will have indices values mask view - topk indices = mask classmethod apply cls module name amount importance_scores=None type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune importance_scores torch Tensor tensor importance scores same shape module parameter used compute mask pruning The values tensor indicate importance corresponding elements parameter being pruned If unspecified None module parameter will used its place super apply module name amount=amount importance_scores=importance_scores RandomStructured BasePruningMethod r Prune entire currently unpruned channels tensor random Args amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune dim int optional index dim along which we define channels prune Default - PRUNING_TYPE = structured __init__ amount dim=- Check range validity amount _validate_pruning_amount_init amount amount = amount dim = dim compute_mask t default_mask r Compute returns mask input tensor ` ` t ` ` Starting base ` ` default_mask ` ` which should mask ones tensor has been pruned yet generate random mask apply top ` ` default_mask ` ` randomly zeroing out channels along specified dim tensor Args t torch Tensor tensor representing parameter prune default_mask torch Tensor Base mask previous pruning iterations need respected after new mask applied Same dims ` ` t ` ` Returns mask torch Tensor mask apply ` ` t ` ` same dims ` ` t ` ` Raises IndexError ` ` dim = len t shape ` ` Check tensor has structure i e more than dimension such concept channels makes sense _validate_structured_pruning t Check dim valid dim index t raise IndexError _validate_pruning_dim t dim Check amount channels prune than number channels t along dim prune tensor_size = t shape dim Compute number units prune amount int amount tensor_size nparams_toprune = _compute_nparams_toprune amount tensor_size This should raise error number units prune larger than number units tensor _validate_pruning_amount nparams_toprune tensor_size Compute binary mask initializing all s then filling s wherever topk indices indicates along dim mask has same shape tensor t make_mask t dim nchannels nchannels_toprune generate random number associate each channel prob = torch rand nchannels generate mask each channel ing out channels got assigned k = nchannels_toprune lowest values prob threshold = torch kthvalue prob k=nchannels_toprune values channel_mask = prob threshold mask = torch zeros_like t slc = slice None len t shape slc dim = channel_mask slc = tuple slc mask slc = mask nparams_toprune == k= supported torch kthvalue mask = default_mask apply new structured mask top prior potentially unstructured mask mask = make_mask t dim tensor_size nparams_toprune mask = default_mask dtype=mask dtype mask classmethod apply cls module name amount dim=- type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune dim int optional index dim along which we define channels prune Default - super apply module name amount=amount dim=dim LnStructured BasePruningMethod r Prune entire currently unpruned channels tensor based their L\ ` ` n ` ` -norm Args amount int float quantity channels prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune n int float inf -inf fro nuc See documentation valid entries argument ` ` p ` ` func ` torch norm ` dim int optional index dim along which we define channels prune Default - PRUNING_TYPE = structured __init__ amount n dim=- Check range validity amount _validate_pruning_amount_init amount amount = amount n = n dim = dim compute_mask t default_mask r Compute returns mask input tensor ` ` t ` ` Starting base ` ` default_mask ` ` which should mask ones tensor has been pruned yet generate mask apply top ` ` default_mask ` ` zeroing out channels along specified dim lowest L\ ` ` n ` ` -norm Args t torch Tensor tensor representing parameter prune default_mask torch Tensor Base mask previous pruning iterations need respected after new mask applied Same dims ` ` t ` ` Returns mask torch Tensor mask apply ` ` t ` ` same dims ` ` t ` ` Raises IndexError ` ` dim = len t shape ` ` Check tensor has structure i e more than dimension such concept channels makes sense _validate_structured_pruning t Check dim valid dim index t raise IndexError _validate_pruning_dim t dim Check amount channels prune than number channels t along dim prune tensor_size = t shape dim Compute number units prune amount int amount tensor_size nparams_toprune = _compute_nparams_toprune amount tensor_size nparams_tokeep = tensor_size - nparams_toprune This should raise error number units prune larger than number units tensor _validate_pruning_amount nparams_toprune tensor_size Structured pruning prunes entire channels so we need know L_n norm along each channel then find topk based metric norm = _compute_norm t n dim largest=True -- top k largest=False -- bottom k Keep largest k channels along dim=self dim topk = torch topk norm k=nparams_tokeep largest=True topk will have indices values Compute binary mask initializing all s then filling s wherever topk indices indicates along dim mask has same shape tensor t make_mask t dim indices init mask mask = torch zeros_like t e g slc = None None None len t shape = slc = slice None len t shape replace None position=dim indices e g slc = None None dim= indices= slc dim = indices slc = tuple slc use slc slice mask replace all its entries s e g mask = mask slc = mask nparams_toprune == k= supported torch kthvalue mask = default_mask mask = make_mask t dim topk indices mask = default_mask dtype=mask dtype mask classmethod apply cls module name amount n dim importance_scores=None type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune n int float inf -inf fro nuc See documentation valid entries argument ` ` p ` ` func ` torch norm ` dim int index dim along which we define channels prune importance_scores torch Tensor tensor importance scores same shape module parameter used compute mask pruning The values tensor indicate importance corresponding elements parameter being pruned If unspecified None module parameter will used its place super apply module name amount=amount n=n dim=dim importance_scores=importance_scores CustomFromMask BasePruningMethod PRUNING_TYPE = global __init__ mask mask = mask compute_mask t default_mask assert default_mask shape == mask shape mask = default_mask mask dtype=default_mask dtype mask classmethod apply cls module name mask type ignore override r Add pruning fly reparametrization tensor Adds forward pre-hook enables pruning fly reparametrization tensor terms original tensor pruning mask Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act super apply module name mask=mask identity module name r Apply pruning reparametrization without pruning any units Applies pruning reparametrization tensor corresponding parameter called ` ` name ` ` ` ` module ` ` without actually pruning any units Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Note The mask tensor ones Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act Returns module nn Module modified i e pruned version input module Examples xdoctest +SKIP m = prune identity nn Linear bias print m bias_mask tensor Identity apply module name module random_unstructured module name amount r Prune tensor removing random currently unpruned units Prunes tensor corresponding parameter called ` ` name ` ` ` ` module ` ` removing specified ` ` amount ` ` currently unpruned units selected random Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune Returns module nn Module modified i e pruned version input module Examples xdoctest +SKIP m = prune random_unstructured nn Linear weight amount= torch sum m weight_mask == tensor RandomUnstructured apply module name amount module l _unstructured module name amount importance_scores=None r Prune tensor removing units lowest L -norm Prunes tensor corresponding parameter called ` ` name ` ` ` ` module ` ` removing specified ` amount ` currently unpruned units lowest L -norm Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune importance_scores torch Tensor tensor importance scores same shape module parameter used compute mask pruning The values tensor indicate importance corresponding elements parameter being pruned If unspecified None module parameter will used its place Returns module nn Module modified i e pruned version input module Examples xdoctest +SKIP m = prune l _unstructured nn Linear weight amount= m state_dict keys odict_keys bias weight_orig weight_mask L Unstructured apply module name amount=amount importance_scores=importance_scores module random_structured module name amount dim r Prune tensor removing random channels along specified dimension Prunes tensor corresponding parameter called ` ` name ` ` ` ` module ` ` removing specified ` ` amount ` ` currently unpruned channels along specified ` ` dim ` ` selected random Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune dim int index dim along which we define channels prune Returns module nn Module modified i e pruned version input module Examples xdoctest +SKIP m = prune random_structured nn Linear weight amount= dim= columns_pruned = int sum torch sum m weight dim= == print columns_pruned RandomStructured apply module name amount dim module ln_structured module name amount n dim importance_scores=None r Prune tensor removing channels lowest L\ ` ` n ` ` -norm along specified dimension Prunes tensor corresponding parameter called ` ` name ` ` ` ` module ` ` removing specified ` ` amount ` ` currently unpruned channels along specified ` ` dim ` ` lowest L\ ` ` n ` ` -norm Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act amount int float quantity parameters prune If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune n int float inf -inf fro nuc See documentation valid entries argument ` ` p ` ` func ` torch norm ` dim int index dim along which we define channels prune importance_scores torch Tensor tensor importance scores same shape module parameter used compute mask pruning The values tensor indicate importance corresponding elements parameter being pruned If unspecified None module parameter will used its place Returns module nn Module modified i e pruned version input module Examples torch nn utils prune m = prune ln_structured nn Conv d weight amount= dim= n=float -inf LnStructured apply module name amount n dim importance_scores=importance_scores module global_unstructured parameters pruning_method importance_scores=None kwargs r Globally prunes tensors corresponding all parameters ` ` parameters ` ` applying specified ` ` pruning_method ` ` Modifies modules place adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args parameters Iterable module name tuples parameters model prune global fashion i e aggregating all weights prior deciding which ones prune module must type ` nn Module ` name must string pruning_method function valid pruning function module custom one implemented user satisfies implementation guidelines has ` ` PRUNING_TYPE= unstructured ` ` importance_scores dict dictionary mapping module name tuples corresponding parameter s importance scores tensor The tensor should same shape parameter used computing mask pruning If unspecified None parameter will used place its importance scores kwargs other keyword arguments such amount int float quantity parameters prune across specified parameters If ` ` float ` ` should between represent fraction parameters prune If ` ` int ` ` represents absolute number parameters prune Raises TypeError ` ` PRUNING_TYPE = unstructured ` ` Note Since global structured pruning doesn t make much sense unless norm normalized size parameter we now limit scope global pruning unstructured methods Examples torch nn utils prune collections OrderedDict net = nn Sequential OrderedDict first nn Linear second nn Linear parameters_to_prune = net first weight net second weight prune global_unstructured parameters_to_prune pruning_method=prune L Unstructured amount= print sum torch nn utils parameters_to_vector net buffers == tensor ensure parameters list generator tuples isinstance parameters Iterable raise TypeError global_unstructured parameters Iterable importance_scores = importance_scores importance_scores None isinstance importance_scores dict raise TypeError global_unstructured importance_scores must type dict flatten importance scores consider them all once global pruning relevant_importance_scores = torch nn utils parameters_to_vector pyrefly ignore bad-argument-type importance_scores get module name getattr module name module name parameters similarly flatten masks they exist use flattened vector s same dimensions t default_mask = torch nn utils parameters_to_vector getattr module name + _mask torch ones_like getattr module name module name parameters use canonical pruning methods compute new mask even parameter now flattened out version ` parameters ` container = PruningContainer container _tensor_name = temp make match ` method ` method = pruning_method kwargs method _tensor_name = temp make match ` container ` method PRUNING_TYPE = unstructured raise TypeError Only unstructured PRUNING_TYPE supported f ` pruning_method ` Found method pruning_method type method PRUNING_TYPE container add_pruning_method method use ` compute_mask ` method ` PruningContainer ` combine mask computed new method pre-existing mask final_mask = container compute_mask relevant_importance_scores default_mask Pointer slicing mask match shape each parameter pointer = module name parameters param = getattr module name The length parameter num_param = param numel Slice mask reshape param_mask = final_mask pointer pointer + num_param view_as param Assign correct pre-computed mask each parameter add forward_pre_hooks like any other pruning method custom_from_mask module name mask=param_mask Increment pointer continue slicing final_mask pointer += num_param custom_from_mask module name mask r Prune tensor corresponding parameter called ` ` name ` ` ` ` module ` ` applying pre-computed mask ` ` mask ` ` Modifies module place also modified module adding named buffer called ` ` name+ _mask ` ` corresponding binary mask applied parameter ` ` name ` ` pruning method replacing parameter ` ` name ` ` its pruned version while original unpruned parameter stored new parameter named ` ` name+ _orig ` ` Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act mask Tensor binary mask applied parameter Returns module nn Module modified i e pruned version input module Examples torch nn utils prune m = prune custom_from_mask nn Linear name= bias mask=torch tensor print m bias_mask tensor CustomFromMask apply module name mask module remove module name r Remove pruning reparameterization module pruning method forward hook The pruned parameter named ` ` name ` ` remains permanently pruned parameter named ` ` name+ _orig ` ` removed parameter list Similarly buffer named ` ` name+ _mask ` ` removed buffers Note Pruning itself NOT undone reversed Args module nn Module module containing tensor prune name str parameter name within ` ` module ` ` which pruning will act Examples m = random_unstructured nn Linear name= weight amount= m = remove m name= weight k hook module _forward_pre_hooks items isinstance hook BasePruningMethod hook _tensor_name == name hook remove module del module _forward_pre_hooks k module raise ValueError f Parameter name module module has pruned before pruning can removed is_pruned module r Check module pruned looking pruning pre-hooks Check whether ` ` module ` ` pruned looking ` ` forward_pre_hooks ` ` its modules inherit ` BasePruningMethod ` Args module nn Module object either pruned unpruned Returns binary answer whether ` ` module ` ` pruned Examples torch nn utils prune m = nn Linear print prune is_pruned m False prune random_unstructured m name= weight amount= print prune is_pruned m True _ submodule module named_modules hook submodule _forward_pre_hooks values isinstance hook BasePruningMethod True False _validate_pruning_amount_init amount r Validate helper check range amount init Args amount int float quantity parameters prune If float should between represent fraction parameters prune If int represents absolute number parameters prune Raises ValueError amount float s negative integer TypeError amount neither float nor integer Note This does take into account number parameters tensor pruned which known only prune isinstance amount numbers Real raise TypeError f Invalid type amount amount Must int float isinstance amount numbers Integral amount isinstance amount numbers Integral so s float float amount float amount raise ValueError f amount= amount should either float range non-negative integer _validate_pruning_amount amount tensor_size r Validate pruning amount meaningful wrt size data Validation helper check amount parameters prune meaningful wrt size data ` tensor_size ` Args amount int float quantity parameters prune If float should between represent fraction parameters prune If int represents absolute number parameters prune tensor_size int absolute number parameters tensor prune TODO consider removing check allowing users specify number units prune greater than number units left prune In case tensor will just fully pruned isinstance amount numbers Integral amount tensor_size raise ValueError f amount= amount should smaller than number parameters prune= tensor_size _validate_structured_pruning t r Validate tensor pruned least -Dimensional Validation helper check tensor pruned multi- dimensional such concept channels well-defined Args t torch Tensor tensor representing parameter prune Raises ValueError tensor ` t ` least D shape = t shape len shape = raise ValueError Structured pruning can only applied multidimensional tensors Found tensor shape f shape len shape dims _compute_nparams_toprune amount tensor_size r Convert pruning amount percentage absolute value Since amount can expressed either absolute value percentage number units channels tensor utility function converts percentage absolute value standardize handling pruning Args amount int float quantity parameters prune If float should between represent fraction parameters prune If int represents absolute number parameters prune tensor_size int absolute number parameters tensor prune Returns int number units prune tensor incorrect type already checked _validate_pruning_amount_init isinstance amount numbers Integral amount round amount tensor_size _validate_pruning_dim t dim r Validate pruning dimension within bounds tensor dimension Args t torch Tensor tensor representing parameter prune dim int index dim along which we define channels prune dim = t dim raise IndexError f Invalid index dim tensor size t shape _compute_norm t n dim r Compute L_n-norm tensor along all dimensions except specified dimension The L_n-norm will computed across all entries tensor ` t ` along all dimension except one identified dim Example ` t ` shape say x x dim= last dim then norm will have Size each entry will represent ` L_n ` -norm computed using x = entries each channels Args t torch Tensor tensor representing parameter prune n int float inf -inf fro nuc See documentation valid entries argument p torch norm dim int dim identifying channels prune Returns norm torch Tensor L_n norm computed across all dimensions except ` dim ` By construction ` norm shape = t shape - ` dims = all axes except one identified ` dim ` dims = list range t dim convert negative indexing dim dim = dims dim dims remove dim norm = torch norm t p=n dim=dims norm