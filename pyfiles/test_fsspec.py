Owner s oncall distributed shutil tempfile collections abc Callable functools wraps typing Any Optional torch torch distributed dist torch distributed checkpoint dcp torch nn nn torch distributed checkpoint _fsspec_filesystem FileSystem FsspecReader FsspecWriter torch distributed checkpoint optimizer load_sharded_optimizer_state_dict torch distributed checkpoint utils CheckpointException torch distributed fsdp FullyShardedDataParallel FSDP torch distributed fsdp fully_sharded_data_parallel StateDictType torch testing _internal common_distributed requires_accelerator_dist_backend skip_if_lt_x_gpu torch testing _internal common_utils run_tests TestCase torch testing _internal distributed _shard sharded_tensor ShardedTensorTestBase with_comms device_type = acc type acc = torch accelerator current_accelerator cpu BACKEND = torch distributed get_default_backend_for_device device_type with_temp_dir func Optional Callable = None - Optional Callable Wrapper initialize temp directory distributed checkpoint assert func None wraps func wrapper args tuple object kwargs dict str Any - None Only create temp_dir when rank no pg dist is_initialized dist get_rank == temp_dir = tempfile mkdtemp print f Using temp directory temp_dir temp_dir = object_list = temp_dir Broadcast temp_dir all other ranks dist is_initialized dist broadcast_object_list object_list temp_dir = object_list try func args kwargs finally dist is_initialized dist get_rank == shutil rmtree temp_dir ignore_errors=True wrapper MyTestModule torch nn Module __init__ - None super __init__ net = nn Sequential nn Linear nn ReLU net = nn Sequential nn Linear nn ReLU net = nn Linear net = nn Sequential nn ReLU nn Linear forward x net net net net x TestFSSpec ShardedTensorTestBase property world_size - int with_comms backend=BACKEND init_rpc=False requires_accelerator_dist_backend skip_if_lt_x_gpu with_temp_dir test_fsspec CHECKPOINT_DIR = temp_dir model = FSDP MyTestModule device_type optim = torch optim Adam model parameters lr= model torch rand device=dist get_rank sum backward optim step FSDP state_dict_type model StateDictType SHARDED_STATE_DICT state_dict = model model state_dict optim FSDP optim_state_dict model optim dcp save state_dict=state_dict storage_writer=FsspecWriter CHECKPOINT_DIR planner=dcp DefaultSavePlanner model_ = FSDP MyTestModule device_type optim_ = torch optim Adam model_ parameters lr= FSDP summon_full_params model FSDP summon_full_params model_ n_p n_p zip model named_parameters model_ named_parameters assertNotEqual n_p n_p now load model ensure values same FSDP state_dict_type model_ StateDictType SHARDED_STATE_DICT state_dict = model model_ state_dict dcp load state_dict=state_dict storage_reader=FsspecReader CHECKPOINT_DIR planner=dcp DefaultLoadPlanner model_ load_state_dict state_dict model optim_state = load_sharded_optimizer_state_dict model_state_dict=state_dict model optimizer_key= optim storage_reader=FsspecReader CHECKPOINT_DIR flattened_osd = FSDP optim_state_dict_to_load model_ optim_ optim_state optim optim_ load_state_dict flattened_osd FSDP summon_full_params model FSDP summon_full_params model_ n_p n_p zip model named_parameters model_ named_parameters assertEqual n_p n_p opt_at opt idx list iter opt state values idx Adam lazily creates its state assertEqual opt_at optim exp_avg opt_at optim_ exp_avg assertEqual opt_at optim exp_avg_sq opt_at optim_ exp_avg_sq with_comms backend=BACKEND init_rpc=False requires_accelerator_dist_backend skip_if_lt_x_gpu with_temp_dir test_overwrite t t = torch randn torch randn dcp save random t storage_writer=FsspecWriter temp_dir overwrite=False dcp save random t storage_writer=FsspecWriter temp_dir overwrite=True sd = random torch zeros dcp load sd checkpoint_id=self temp_dir assertTrue torch allclose sd random t assertRaisesRegex CheckpointException Checkpoint already exists dcp save random t storage_writer=FsspecWriter temp_dir overwrite=False TestFileSystem TestCase with_temp_dir test_remove_on_fail fs = FileSystem path = fs init_path temp_dir write_file = fs concat_path path writeable assertRaises OSError fs create_stream write_file w s s write aaa raise OSError fail assertFalse fs exists write_file read_file = fs concat_path path readable fs create_stream read_file w s s write bbb assertTrue fs exists read_file assertRaises OSError fs create_stream read_file r s raise OSError fail assertTrue fs exists read_file __name__ == __main__ run_tests