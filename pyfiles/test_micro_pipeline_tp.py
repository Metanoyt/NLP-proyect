Owner s module c d unittest typing Optional torch torch distributed dist functorch make_fx torch _inductor decomposition decompositions torch _inductor fx_passes micro_pipeline_tp _get_unexposed_collectives find_all_gather_patterns find_reduce_scatter_patterns micro_pipeline_tp_pass torch _inductor fx_passes post_grad remove_noop_ops view_to_reshape torch _inductor utils fresh_cache run_and_get_triton_code torch distributed _functional_collectives all_gather_tensor reduce_scatter_tensor torch distributed _symmetric_memory _test_mode torch distributed distributed_c d _get_group_size_by_name torch distributed tensor DeviceMesh Shard torch distributed tensor parallel ColwiseParallel parallelize_module RowwiseParallel torch testing _internal common_device_type e m _type torch testing _internal common_utils type ignore attr-defined instantiate_parametrized_tests MI _ARCH parametrize run_tests runOnRocmArch TestCase torch testing _internal distributed _tensor common_dtensor MLPModule torch testing _internal distributed fake_pg FakeStore torch testing _internal inductor_utils HAS_GPU _make_post_grad_fx f inps gm = make_fx f decompositions tracing_mode= fake inps remove_noop_ops gm graph view_to_reshape gm gm _fp _all_gather tensor torch Tensor gather_dim int group_name str - torch Tensor We don t yet have canonical pattern fp all-gather This pattern observed DTensor + float _experimental ag = all_gather_tensor tensor gather_dim= group=group_name gather_dim == ag view tensor dtype chunks = ag chunk _get_group_size_by_name group_name chunks = chunk view torch uint chunk chunks torch cat chunks dim=gather_dim view tensor dtype instantiate_parametrized_tests MicroPipelineTPTest TestCase setUp torch _inductor config _micro_pipeline_tp = True rank = world_size = torch cuda set_device cuda store = FakeStore dist init_process_group backend= fake world_size=self world_size rank=self rank store=store tearDown dist destroy_process_group unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch fresh_cache test_find_all_gather_patterns group = dist group WORLD func inp torch Tensor - tuple torch Tensor torch Tensor torch Tensor torch Tensor = all_gather_tensor inp gather_dim= group=group group_name b = all_gather_tensor inp gather_dim= group=group group_name c = _fp _all_gather inp gather_dim= group_name=group group_name d = _fp _all_gather inp gather_dim= group_name=group group_name b c d inp = torch rand device= cuda gm = _make_post_grad_fx func inp all_gathers = find_all_gather_patterns gm graph assertEqual len all_gathers If test fails please update find_all_gather_patterns instead modifying following assertions all_gather all_gathers assertEqual all_gather ag_node target torch ops _c d_functional all_gather_into_tensor default assertEqual all_gather group_name group group_name assertEqual all_gathers gather_dim assertEqual all_gathers res_node target torch ops _c d_functional wait_tensor default assertEqual all_gathers gather_dim assertEqual all_gathers res_node target torch ops aten cat default assertEqual all_gathers gather_dim assertEqual all_gathers res_node target torch ops _c d_functional wait_tensor default assertEqual all_gathers gather_dim assertEqual all_gathers res_node target torch ops aten view dtype unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch fresh_cache test_find_reduce_scatter_patterns group = dist group WORLD func inp torch Tensor - torch Tensor = reduce_scatter_tensor inp sum scatter_dim= group=group group_name b = reduce_scatter_tensor inp avg scatter_dim= group=group group_name b inp = torch rand device= cuda gm = make_fx func inp reduce_scatters = find_reduce_scatter_patterns gm graph assertEqual len reduce_scatters If test fails please update find_reduce_scatter_patterns instead modifying following assertions reduce_scatter reduce_scatters assertEqual reduce_scatter input_node op placeholder assertEqual reduce_scatter reduce_scatter_node target torch ops _c d_functional reduce_scatter_tensor default assertEqual reduce_scatter wait_tensor_node target torch ops _c d_functional wait_tensor default assertEqual reduce_scatter group_name group group_name assertEqual reduce_scatters reduce_op sum assertEqual reduce_scatters scatter_dim assertEqual reduce_scatters reduce_op avg assertEqual reduce_scatters scatter_dim unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch fresh_cache test_get_unexposed_collectives group = dist group WORLD func inp torch Tensor - torch Tensor = inp inp T b unexposed hidden b = all_gather_tensor inp gather_dim= group=group group_name c = b inp T d unexposed hidden c d = reduce_scatter_tensor b avg scatter_dim= group=group group_name e exposed e = all_gather_tensor d gather_dim= group=group group_name c e inp = torch rand device= cuda gm = make_fx func inp overlappable_collectives = _get_unexposed_collectives gm graph assertEqual list map str overlappable_collectives all_gather_into_tensor reduce_scatter_tensor unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize A_dims parametrize gather_dim parametrize return_A True False fresh_cache test_fuse_all_gather_matmul A_dims gather_dim return_A gather_dim = A_dims group = dist group WORLD func A_shard torch Tensor B torch Tensor - torch Tensor A = all_gather_tensor A_shard gather_dim=gather_dim group=group return_A A A B None A B A_dims == A_shard_shape = A_dims == A_shard_shape = raise AssertionError f Invalid A_dims A_dims A_shard_shape gather_dim = world_size A_shard = torch rand A_shard_shape device= cuda B = torch rand device= cuda _test_mode compiled = torch compile func code = run_and_get_triton_code compiled A_shard B eager_stride = func A_shard B stride compiled_stride = compiled A_shard B stride assertEqual eager_stride compiled_stride gather_dim == A_dims - Decomposing matmul K dimension supported assertNotIn fused_all_gather_matmul code assertIn all_gather_into_tensor code assertIn fused_all_gather_matmul code assertNotIn all_gather_into_tensor code assertEqual return_A=True code return_A runOnRocmArch MI _ARCH unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize A_dims parametrize gather_dim parametrize return_A True False fresh_cache test_fuse_all_gather_scaled_matmul A_dims gather_dim return_A gather_dim = A_dims group = dist group WORLD func A_shard torch Tensor B torch Tensor A_scale torch Tensor B_scale torch Tensor out_dtype Optional torch dtype - torch Tensor A = _fp _all_gather A_shard gather_dim=gather_dim group_name=group group_name len A_shard shape C = torch _scaled_mm A flatten - B A_scale B_scale out_dtype=out_dtype C = C view A shape - - C = torch _scaled_mm A B A_scale B_scale out_dtype=out_dtype return_A A C None C A_dims == A_shard_shape = A_dims == A_shard_shape = raise AssertionError f Invalid A_dims A_dims A_shard_shape gather_dim = world_size A_shard = torch rand A_shard_shape device= cuda e m _type B = torch rand device= cuda e m _type T A_scale = torch tensor device= cuda B_scale = torch tensor device= cuda gm = _make_post_grad_fx func A_shard B A_scale B_scale torch bfloat _test_mode micro_pipeline_tp_pass gm graph gather_dim == A_dims - assertNotIn fused_all_gather_scaled_matmul str gm graph assertIn all_gather_into_tensor str gm graph Decomposing matmul K dimension supported assertIn fused_all_gather_scaled_matmul str gm graph assertNotIn all_gather_into_tensor str gm graph torch cuda get_device_capability _test_mode compiled = torch compile func code = run_and_get_triton_code compiled A_shard B A_scale B_scale torch bfloat gather_dim == A_dims - assertNotIn fused_all_gather_scaled_matmul code assertIn all_gather_into_tensor code Decomposing matmul K dimension supported assertIn fused_all_gather_scaled_matmul code assertNotIn all_gather_into_tensor code unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize A_dims parametrize scatter_dim fresh_cache test_fuse_matmul_reduce_scatter A_dims scatter_dim scatter_dim = A_dims group = dist group WORLD func A torch Tensor B torch Tensor - torch Tensor reduce_scatter_tensor A B avg scatter_dim group A_dims == A = torch rand device= cuda A_dims == A = torch rand device= cuda raise AssertionError f Invalid A_dims A_dims B = torch rand device= cuda _test_mode compiled = torch compile func code = run_and_get_triton_code compiled A B assertIn fused_matmul_reduce_scatter code assertNotIn reduce_scatter_tensor code runOnRocmArch MI _ARCH unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize A_dims parametrize scatter_dim fresh_cache test_fuse_scaled_matmul_reduce_scatter A_dims scatter_dim scatter_dim = A_dims - group = dist group WORLD func A torch Tensor B torch Tensor A_scale torch Tensor B_scale torch Tensor out_dtype torch dtype - torch Tensor len A shape C = torch _scaled_mm A flatten - B A_scale B_scale out_dtype=out_dtype C = C view A shape - B shape C = torch _scaled_mm A B A_scale B_scale out_dtype=out_dtype reduce_scatter_tensor C avg scatter_dim group A_dims == A = torch rand device= cuda e m _type A_dims == A = torch rand device= cuda e m _type raise AssertionError f Invalid A_dims A_dims B = torch rand device= cuda e m _type T A_scale = torch tensor device= cuda B_scale = torch tensor device= cuda gm = _make_post_grad_fx func A B A_scale B_scale torch bfloat _test_mode micro_pipeline_tp_pass gm graph assertIn fused_scaled_matmul_reduce_scatter str gm graph assertNotIn reduce_scatter_tensor str gm graph torch cuda get_device_capability _test_mode compiled = torch compile func code = run_and_get_triton_code compiled A B A_scale B_scale torch bfloat assertIn fused_scaled_matmul_reduce_scatter code assertNotIn reduce_scatter_tensor code runOnRocmArch MI _ARCH unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize scatter_dim fresh_cache test_fuse_scaled_matmul_reduce_scatter_rowwise_scales_reshape_mm_reshape scatter_dim group = dist group WORLD reshape_mm_reshape A torch Tensor B torch Tensor A_scale torch Tensor B_scale torch Tensor out_dtype torch dtype - torch Tensor Performs scaled_mm followed reduce scatter following reshape - scaled_mm - reshape pattern orig_shape = A shape reshape tensor scale together A = A reshape - orig_shape - A_scale = A_scale reshape - A_scale shape - A_scale = torch reciprocal A_scale C = torch _scaled_mm A B A_scale B_scale out_dtype=out_dtype reshape output have same leading dims original ` A ` tensor C = C view orig_shape - C shape - reduce_scatter_tensor C sum scatter_dim group A = torch rand device= cuda e m _type B = torch rand device= cuda e m _type T A_scale = rowwise scales A_scale = torch full device= cuda B_scale = rowwise scales transposed A B^T B_scale = torch full device= cuda gm = _make_post_grad_fx reshape_mm_reshape A B A_scale B_scale torch bfloat _test_mode micro_pipeline_tp_pass gm graph assertIn fused_scaled_matmul_reduce_scatter str gm graph assertNotIn reduce_scatter_tensor str gm graph torch cuda get_device_capability _test_mode compiled = torch compile reshape_mm_reshape code = run_and_get_triton_code compiled A B A_scale B_scale torch bfloat assertIn fused_scaled_matmul_reduce_scatter code assertNotIn reduce_scatter_tensor code unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch parametrize shard_dim fresh_cache test_dtensor_seq_par shard_dim int model torch nn Module = MLPModule device= cuda bias=False device_mesh = DeviceMesh cuda torch arange world_size parallelize_plan = net ColwiseParallel input_layouts=Shard shard_dim net RowwiseParallel output_layouts=Shard shard_dim model = parallelize_module model device_mesh parallelize_plan shard_dim == inp = torch rand device= cuda shard_dim == inp = torch rand device= cuda raise AssertionError Invalid shard_dim _test_mode compiled = torch compile model code = run_and_get_triton_code compiled inp assertIn fused_all_gather_matmul code assertNotIn all_gather_into_tensor code assertIn fused_matmul_reduce_scatter code assertNotIn reduce_scatter_tensor code instantiate_parametrized_tests MicroPipelineTP GPUTest TestCase setUp torch _inductor config _micro_pipeline_tp = True rank = world_size = torch cuda set_device cuda store = FakeStore dist init_process_group backend= fake world_size=self world_size rank=self rank store=store tearDown dist destroy_process_group unittest skipIf HAS_GPU Inductor+gpu needs triton recent GPU arch fresh_cache test_extra_collectives device_mesh = DeviceMesh cuda torch arange world_size view - mesh_dim_names= tp other func inp torch Tensor w torch Tensor w torch Tensor - torch Tensor hidden = all_gather_tensor inp device_mesh w t full_hidden = all_gather_tensor hidden device_mesh full_hidden = full_hidden pow sum sqrt hidden = reduce_scatter_tensor full_hidden avg device_mesh reduce_scatter_tensor hidden w t avg device_mesh inp = torch rand device= cuda w = torch rand device= cuda w = torch rand device= cuda _test_mode group_names= device_mesh tp get_group group_name compiled = torch compile func code = run_and_get_triton_code compiled inp w w assertIn fused_all_gather_matmul code assertIn all_gather_into_tensor code assertIn fused_matmul_reduce_scatter code assertIn reduce_scatter_tensor code __name__ == __main__ run_tests