Test utilities ONNX export __future__ annotations __all__ = assert_onnx_program typing Any Literal TYPE_CHECKING torch torch utils _pytree TYPE_CHECKING torch onnx _internal exporter _onnx_program assert_onnx_program program _onnx_program ONNXProgram rtol float &#124; None = None atol float &#124; None = None args tuple Any &#124; None = None kwargs dict str Any &#124; None = None strategy str &#124; None = TorchExportNonStrictStrategy backend Literal onnxruntime reference = onnxruntime - None Assert ONNX model produces same output PyTorch ExportedProgram Args program The ` ` ONNXProgram ` ` verify rtol Relative tolerance atol Absolute tolerance args The positional arguments pass program If None default example inputs ExportedProgram will used kwargs The keyword arguments pass program If None default example inputs ExportedProgram will used strategy Assert capture strategy used export program Values can names like TorchExportNonStrictStrategy If None strategy asserted backend The backend use evaluating ONNX program Supported values onnxruntime reference strategy None program _capture_strategy = strategy raise ValueError f Expected strategy strategy used capture exported program f got program _capture_strategy exported_program = program exported_program exported_program None raise ValueError The ONNXProgram does contain ExportedProgram To verify ONNX program initialize ONNXProgram ExportedProgram assign ExportedProgram ONNXProgram exported_program attribute args None kwargs None User did provide example inputs use default example inputs exported_program example_inputs None raise ValueError No example inputs provided exported_program does contain example inputs Please provide arguments verify ONNX program args kwargs = exported_program example_inputs args None args = kwargs None kwargs = torch_module = exported_program module torch_outputs _ = _pytree tree_flatten torch_module args kwargs ONNX outputs always real so we need convert torch complex outputs real representations torch_outputs_adapted = output torch_outputs ONNX graph does support None outputs so we skip them output None continue isinstance output torch Tensor torch_outputs_adapted append torch tensor output torch is_complex output torch_outputs_adapted append torch view_as_real output torch_outputs_adapted append output Obtain ONNX outputs using specified backend backend == onnxruntime onnx_outputs = program args kwargs backend == reference onnx_outputs = program call_reference args kwargs raise ValueError f Unsupported backend backend Supported backends onnxruntime reference TODO justinchuby Include output names error message torch testing assert_close tuple onnx_outputs tuple torch_outputs_adapted rtol=rtol atol=atol equal_nan=True check_device=False