Generates Python bindings ATen functions The bindings generated methods python_variable functions torch _C _nn torch _C _fft torch _C _linalg torch _C _nested torch _C _sparse torch _C _special objects Code tries stick following rules - templates should colocated functions use them no templates currently shared between functions happens maybe put template first one - don t use environment dictionaries when calling template substitute pass named arguments directly everything otherwise s much too hard track what s actually being used who - colocate any new hacks adjustments existing ones same kind ideally data structure rather than code possible See e g SCHEMA_DEFAULT_CONVERSION_HACKS etc - similarly conversions one format another should ideally happen all once single place - no nontrivial nested functions couple-liners ok please no more especially avoid functions read write outer variables defined far away - raise RuntimeError instead asserting put much information available into message I e no need plumb new params whose only purpose fill out error message use what s there __future__ annotations itertools re collections defaultdict typing TYPE_CHECKING yaml torchgen api cpp torchgen api python arg_parser_output_exprs cpp_dispatch_exprs cpp_dispatch_target dispatch_lambda_args dispatch_lambda_exprs dispatch_lambda_return_str has_tensor_options PythonSignature PythonSignatureDeprecated PythonSignatureGroup PythonSignatureNativeFunctionPair signature signature_from_schema structseq_fieldnames torchgen code_template CodeTemplate torchgen context with_native_function torchgen gen cpp_string parse_native_yaml parse_tags_yaml torchgen model Argument BaseOperatorName FunctionSchema NativeFunction SchemaKind Type Variant torchgen utils FileManager split_name_params torchgen yaml_utils YamlLoader gen_inplace_or_view_type is_tensor_list_type gen_trace_type should_trace TYPE_CHECKING collections abc Callable Iterable Sequence declarations blocklist We skip codegen these functions various reasons Future PRs will categorize list eliminate hoist them out eager-only codegen See https github com pytorch pytorch issues These functions require manual Python bindings exposed Python _SKIP_PYTHON_BINDINGS = alias contiguous is_cuda is_sparse is_sparse_csr size stride sym_is_contiguous sym_size sym_stride sym_storage_offset sym_numel _backward _backward_ out &#124; input &#124; weight &#124; bias _forward _forward_out _jvp _unsafe_view tensor _ sparse_ coo &#124; compressed &#124; csr &#124; csc &#124; bsr &#124; bsc _tensor _range _sparse_add_out _sparse_div _sparse_mul _sparse_sub _sparse_dense_add_out index index_out unique_dim_consecutive _cumsum _cumprod _sum _prod _th_ _thnn_ range _solve _inverse _cholesky _triangular_solve _qr _svd slice item _local_scalar_dense _to_copy _to_copy_out _reshape_copy _reshape_copy_out copy_sparse_to_sparse_ copy_ _foreach_copy numpy_T matrix_H mT mH these need attributes Python functions nonzero _ out &#124; numpy set_data _overrideable overridable functions backend extension data is_leaf output_nr _version requires_grad_ retains_grad set_ _fw_primal fake_quantize_per_tensor_affine_cachemask fake_quantize_per_channel_affine_cachemask _new_zeros_with_same_feature_meta _has_same_storage_numel used forward AD internals _reshape_alias replace_ only used functionalization pass doesn t need exposed python copy only used functionalization pass fill Tensor only used functionalization pass fill Scalar only used functionalization pass lift normal_functional only used functionalization pass nbytes itemsize _batch_norm_with_update _batch_norm_with_update_out _batch_norm_no_update SKIP_PYTHON_BINDINGS = re compile rf ^ pattern $ pattern _SKIP_PYTHON_BINDINGS These function signatures exposed Python Note signature list does support regex SKIP_PYTHON_BINDINGS_SIGNATURES = add Scalar Tensor Scalar other Scalar alpha= - Tensor add_ Scalar Tensor Scalar other Scalar alpha= - Tensor sub Scalar Tensor Scalar other Scalar alpha= - Tensor sub_ Scalar Tensor Scalar other Scalar alpha= - Tensor mul Scalar Tensor Scalar other - Tensor mul_ Scalar Tensor Scalar other - Tensor div Scalar Tensor Scalar other - Tensor div_ Scalar Tensor Scalar other - Tensor with_native_function should_generate_py_binding f NativeFunction - bool NativeFunctions entirely code-generated should get python bindings because these codegen implementations often inefficient A handful view_copy style ops exposed accidentally when they handwritten now we moving them codegen bc reasons we need keep them exposed python generated f tags view_copy f tags False name = cpp name f func skip_regex SKIP_PYTHON_BINDINGS skip_regex match name False signature = str f func pattern SKIP_PYTHON_BINDINGS_SIGNATURES pattern == signature False True get_pycname name BaseOperatorName - str f THPVariable_ name is_noarg overloads Sequence PythonSignatureNativeFunctionPair - bool len overloads == overloads signature arguments_count == is_py_variable_method f NativeFunction - bool f python_module None Variant method f variants is_py_torch_function f NativeFunction - bool f python_module None Variant function f variants is_py_nn_function f NativeFunction - bool f python_module == nn is_py_fft_function f NativeFunction - bool f python_module == fft is_py_linalg_function f NativeFunction - bool f python_module == linalg is_py_nested_function f NativeFunction - bool f python_module == nested is_py_sparse_function f NativeFunction - bool f python_module == sparse is_py_special_function f NativeFunction - bool f python_module == special ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Main Function ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ gen out str native_yaml_path str tags_yaml_path str deprecated_yaml_path str template_path str symint bool = True - None fm = FileManager install_dir=out template_dir=template_path dry_run=False native_functions = parse_native_yaml native_yaml_path tags_yaml_path native_functions native_functions = list filter should_generate_py_binding native_functions methods = load_signatures native_functions deprecated_yaml_path method=True create_python_bindings fm methods is_py_variable_method None python_variable_methods cpp method=True symint=symint NOTE num_shards here must synced gatherTorchFunctions torch csrc autograd python_torch_functions_manual cpp functions = load_signatures native_functions deprecated_yaml_path method=False create_python_bindings_sharded fm functions is_py_torch_function torch python_torch_functions cpp method=False num_shards= symint=symint create_python_bindings fm functions is_py_nn_function torch nn python_nn_functions cpp method=False symint=symint create_python_bindings fm functions is_py_fft_function torch fft python_fft_functions cpp method=False symint=symint create_python_bindings fm functions is_py_linalg_function torch linalg python_linalg_functions cpp method=False symint=symint create_python_bindings fm functions is_py_nested_function torch nested python_nested_functions cpp method=False create_python_bindings fm functions is_py_sparse_function torch sparse python_sparse_functions cpp method=False symint=symint create_python_bindings fm functions is_py_special_function torch special python_special_functions cpp method=False symint=symint Currently we only use ` functions ` generate ` return_types ` bindings All methods which structseq have function variant point If any method only operator structseq added future we will have address create_python_return_type_bindings fm functions lambda fn True python_return_types cpp create_python_return_type_bindings_header fm functions lambda fn True python_return_types h valid_tags = parse_tags_yaml tags_yaml_path gen_tags_enum - dict str str enum_of_valid_tags join f \n value tag Tag tag tag sorted valid_tags fm write python_enum_tag cpp gen_tags_enum group_filter_overloads pairs Sequence PythonSignatureNativeFunctionPair pred Callable NativeFunction bool - dict BaseOperatorName list PythonSignatureNativeFunctionPair grouped dict BaseOperatorName list PythonSignatureNativeFunctionPair = defaultdict list pair pairs pred pair function grouped pair function func name name append pair grouped create_python_bindings fm FileManager pairs Sequence PythonSignatureNativeFunctionPair pred Callable NativeFunction bool module str &#124; None filename str method bool symint bool = True - None Generates Python bindings ATen functions py_methods list str = ops_headers list str = py_method_defs list str = py_forwards list str = grouped = group_filter_overloads pairs pred name sorted grouped keys key=str overloads = grouped name py_methods append method_impl name module overloads method=method symint=symint py_method_defs append method_def name module overloads method=method py_forwards extend forward_decls name overloads method=method ops_headers append f #include ATen ops name base h fm write_with_template filename filename lambda generated_comment + f generated fm template_dir_for_comments filename ops_headers ops_headers py_forwards py_forwards py_methods py_methods py_method_defs py_method_defs create_python_return_type_bindings fm FileManager pairs Sequence PythonSignatureNativeFunctionPair pred Callable NativeFunction bool filename str - None Generate function initialize named tuple native functions which returns named tuple registration invocations ` python_return_types cpp ` py_return_types_definition list str = py_return_types_registrations list str = grouped = group_filter_overloads pairs pred name sorted grouped keys key=str overloads = grouped name definitions registrations = generate_return_type_definition_and_registrations overloads py_return_types_definition append definitions \n join definitions py_return_types_registrations append registrations \n join registrations fm write_with_template filename filename lambda generated_comment + f generated fm template_dir_for_comments filename py_return_types py_return_types_definition py_return_types_registrations py_return_types_registrations create_python_return_type_bindings_header fm FileManager pairs Sequence PythonSignatureNativeFunctionPair pred Callable NativeFunction bool filename str - None Generate function initialize named tuple native functions which returns named tuple relevant entry map ` python_return_types cpp ` py_return_types_declarations list str = grouped = group_filter_overloads pairs pred name sorted grouped keys key=str overloads = grouped name declarations = generate_return_type_declarations overloads py_return_types_declarations append declarations \n join declarations fm write_with_template filename filename lambda generated_comment + f generated fm template_dir_for_comments filename py_return_types_declarations py_return_types_declarations create_python_bindings_sharded fm FileManager pairs Sequence PythonSignatureNativeFunctionPair pred Callable NativeFunction bool module str &#124; None filename str method bool num_shards int symint bool = True - None Generates Python bindings ATen functions grouped = group_filter_overloads pairs pred key_func kv tuple BaseOperatorName list PythonSignatureNativeFunctionPair - str kv base env_func kv tuple BaseOperatorName list PythonSignatureNativeFunctionPair - dict str list str name fn_pairs = kv ops_headers f #include ATen ops name base h py_forwards list forward_decls name fn_pairs method=method py_methods method_impl name module fn_pairs method=method symint=symint py_method_defs method_def name module fn_pairs method=method fm write_sharded filename grouped items base_env= generated_comment + f generated fm template_dir_for_comments filename key_fn=key_func env_callable=env_func num_shards=num_shards sharded_keys= ops_headers py_forwards py_methods py_method_defs load_signatures native_functions list NativeFunction deprecated_yaml_path str method bool skip_deprecated bool = False pyi bool = False - Sequence PythonSignatureNativeFunctionPair with_native_function gen_signature_pairs f NativeFunction - PythonSignatureNativeFunctionPair PythonSignatureNativeFunctionPair signature=signature f method=method pyi=pyi function=f pairs = list map gen_signature_pairs native_functions deprecated = load_deprecated_signatures pairs deprecated_yaml_path method=method pyi=pyi pairs skip_deprecated pairs + deprecated load_deprecated_signatures pairs Sequence PythonSignatureNativeFunctionPair deprecated_yaml_path str method bool pyi bool - list PythonSignatureNativeFunctionPair The deprecated yaml doesn t have complete type information we need find leverage original ATen signature which delegates call generate full python signature We join deprecated original signatures using type-only form group original ATen signatures name grouped dict str list PythonSignatureNativeFunctionPair = defaultdict list pair pairs grouped pair signature name append pair find matching original signatures each deprecated signature results list PythonSignatureNativeFunctionPair = open deprecated_yaml_path f deprecated_defs = yaml load f Loader=YamlLoader deprecated deprecated_defs schema = FunctionSchema parse deprecated name aten_name call_args = split_name_params deprecated aten is_out = aten_name endswith _out is_out aten_name = aten_name replace _out HACK these fixed constants used pass aten function The type must known ahead time known_constants = Type parse Scalar schema_args_by_name = name schema arguments flat_all name call_args assert name schema_args_by_name name known_constants f deprecation definition Unrecognized value name Map deprecated signature arguments their aten signature test types alias annotation match is_schema_compatible aten_schema FunctionSchema - bool arguments Iterable Argument is_out arguments = itertools chain aten_schema arguments out aten_schema arguments flat_non_out arguments = aten_schema arguments flat_all i arg enumerate arguments i len call_args arg_name = call_args i arg_name known_constants schema_type = known_constants arg_name schema_annotation = None schema_arg = schema_args_by_name arg_name schema_type = schema_arg type schema_annotation = schema_arg annotation schema_type = arg type schema_annotation = arg annotation False arg default None False len schema returns == len aten_schema returns all == b b zip schema returns aten_schema returns any_schema_found = False pair grouped aten_name is_schema_compatible pair function func continue any_schema_found = True python_sig = signature_from_schema schema category_override=pair function category_override method=method pyi=pyi results append PythonSignatureNativeFunctionPair signature=PythonSignatureDeprecated name=python_sig name input_args=python_sig input_args input_kwargs=python_sig input_kwargs output_args=python_sig output_args tensor_options_args=python_sig tensor_options_args method=python_sig method deprecated_schema=schema deprecated_args_exprs=tuple call_args returns=python_sig returns function=pair function assert any_schema_found f No native function name aten_name matched signature \n str schema results ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Named Tuple Codegen ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ with_native_function gen_structseq_typename_key f NativeFunction - str name = cpp name f func fieldnames = structseq_fieldnames f func returns _ join name + fieldnames emit_structseq_call overloads Sequence PythonSignatureNativeFunctionPair - tuple list str dict str str Generate block named tuple type inits add typeref snippets declarations use them typenames dict str str = map unique name + field name lists typedef name typedefs list str = typedef declarations init code overload overloads fieldnames = structseq_fieldnames overload function func returns fieldnames continue name = cpp name overload function func use with_native_function tn_key = gen_structseq_typename_key overload function typename = typenames get tn_key typename None typename = f NamedTuple typedefs len typedefs typenames tn_key = typename typedefs append f \ static PyTypeObject typename = generated get_ name _structseq typedefs typenames generate_return_type_definition_and_registrations overloads Sequence PythonSignatureNativeFunctionPair - tuple list str list str Generate block function ` python_return_types cpp ` initialize named tuple native function which returns named tuple registration invocations same file typenames dict str str = map unique name + field name lists typedef name definitions list str = function definition register typedef registrations list str = register call typedef overload overloads fieldnames = structseq_fieldnames overload function func returns fieldnames continue fields = join f fn fn fieldnames name = cpp name overload function func use with_native_function tn_key = gen_structseq_typename_key overload function typename = typenames get tn_key typename None typename = f name NamedTuple definitions len definitions typenames tn_key = typename definitions append f \ PyTypeObject get_ name _structseq static PyStructSequence_Field NamedTuple_fields = fields nullptr static PyTypeObject typename static bool is_initialized = false static PyStructSequence_Desc desc = torch return_types name nullptr NamedTuple_fields len fieldnames is_initialized PyStructSequence_InitType typename desc typename tp_repr = reprfunc torch utils returned_structseq_repr is_initialized = true typename registrations append f addReturnType return_types_module name generated get_ name _structseq definitions registrations generate_return_type_declarations overloads Sequence PythonSignatureNativeFunctionPair - list str Generate block function declarations ` python_return_types h ` initialize named tuple native function typenames dict str str = map unique name + field name lists typedef name declarations list str = function declaration register typedef overload overloads fieldnames = structseq_fieldnames overload function func returns fieldnames continue name = cpp name overload function func use with_native_function tn_key = gen_structseq_typename_key overload function typename = typenames get tn_key typename None typename = f name NamedTuple declarations len declarations typenames tn_key = typename declarations append f PyTypeObject get_ name _structseq declarations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Method Impl Codegen ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ python binding all overloads particular function method PY_VARIABLE_METHOD_VARARGS = CodeTemplate r \ $ name static PyObject $ pycname PyObject self_ PyObject args PyObject kwargs $ method_header static PythonArgParser parser $ signatures traceable= $ traceable ParsedArgs $ max_args parsed_args auto _r = parser parse $ self_ args kwargs parsed_args $ check_has_torch_function switch _r idx $ dispatch $ method_footer handler single parsed signature - may single overload pair overloads whose signatures only differ output params plugged into PY_VARIABLE_METHOD_VARARGS item $ dispatch PY_VARIABLE_CASE = CodeTemplate \ case $ overload_index $ body python binding single-overload function method PY_VARIABLE_METHOD_VARARGS_SINGLETON = CodeTemplate \ $ name static PyObject $ pycname PyObject self_ PyObject args PyObject kwargs $ method_header static PythonArgParser parser $ signatures traceable= $ traceable ParsedArgs $ max_args parsed_args auto _r = parser parse $ self_ args kwargs parsed_args $ check_has_torch_function $ dispatch $ method_footer python binding method no args shortcuts parsing PY_VARIABLE_METHOD_NOARGS = CodeTemplate \ $ name static PyObject $ pycname PyObject self_ PyObject args $ method_header $ check_has_torch_function $ dispatch $ method_footer method_impl name BaseOperatorName module str &#124; None overloads Sequence PythonSignatureNativeFunctionPair method bool symint bool = True - str Generate python binding all overloads op pycname = get_pycname name noarg = is_noarg overloads structseq_inits structseq_typenames = emit_structseq_call overloads method_header = HANDLE_TH_ERRORS method_header += structseq_inits method_header += const Tensor = THPVariable_Unpack self_ method method_footer = noarg Py_RETURN_NONE + END_HANDLE_TH_ERRORS traceable = true all should_trace o function o overloads false grouped_overloads Sequence PythonSignatureGroup = group_overloads overloads symint=symint is_singleton = len grouped_overloads == signatures list str = dispatch list str = overload_index overload enumerate grouped_overloads signature = overload signature signature_str symint=symint signatures append f cpp_string str signature dispatch_body = emit_dispatch_case overload structseq_typenames symint=symint dispatch append PY_VARIABLE_CASE substitute overload_index=overload_index body=dispatch_body is_singleton dispatch_body noarg template = PY_VARIABLE_METHOD_NOARGS is_singleton template = PY_VARIABLE_METHOD_VARARGS_SINGLETON template = PY_VARIABLE_METHOD_VARARGS template substitute name=name pycname=pycname method_header=method_header max_args=max o signature arguments_count o overloads signatures=signatures traceable=traceable check_has_torch_function=gen_has_torch_function_check name=name module=module noarg=noarg method=method dispatch=dispatch method_footer=method_footer self_= self_ method nullptr gen_has_torch_function_check name BaseOperatorName module str &#124; None noarg bool method bool - str noarg method f \ check_has_torch_function self_ handle_torch_function self_ name self_ = self_ method nullptr namespace = torch THPVariableFunctionsModule torch nn THPNNVariableFunctionsModule torch fft THPFFTVariableFunctionsModule torch linalg THPLinalgVariableFunctionsModule torch nested THPNestedVariableFunctionsModule torch sparse THPSparseVariableFunctionsModule torch special THPSpecialVariableFunctionsModule module module THPVariableClass f \ _r has_torch_function handle_torch_function _r self_ args kwargs namespace module torch Tensor handler output no-output overload pair PY_VARIABLE_OUT = CodeTemplate \ _r isNone $ out_idx $ call_dispatch $ call_dispatch_out emit_dispatch_case overload PythonSignatureGroup structseq_typenames dict str str symint bool = True - str Emit dispatch code single parsed signature This corresponds either single native function pair differ only output params In latter case single python signature used both dispatching switches presence absence passed output args overload outplace None dispatch output no-output variants branch _r isNone out_idx PY_VARIABLE_OUT substitute out_idx=overload signature output_idx call_dispatch=emit_single_dispatch overload signature overload base structseq_typenames symint=symint call_dispatch_out=emit_single_dispatch overload signature overload outplace structseq_typenames symint=symint no-output version only emit_single_dispatch overload signature overload base structseq_typenames symint=symint ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Forward Declarations Codegen ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ forward_decls name BaseOperatorName overloads Sequence PythonSignatureNativeFunctionPair method bool - tuple str method pycname = get_pycname name is_noarg overloads f \ static PyObject pycname PyObject self_ PyObject args f \ static PyObject pycname PyObject self_ PyObject args PyObject kwargs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Method Def Binding Table Entry Codegen ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ method_def name BaseOperatorName module str &#124; None overloads Sequence PythonSignatureNativeFunctionPair method bool - str Generate method entry pycname = get_pycname name name dunder_method PyMethodDef entry binary op throws implemented error pycname = f TypeError_to_NotImplemented_ pycname is_noarg overloads flags = METH_NOARGS method METH_VARARGS &#124; METH_KEYWORDS pycname = f castPyCFunctionWithKeywords pycname flags = METH_VARARGS &#124; METH_KEYWORDS module == torch flags += &#124; METH_STATIC f name pycname flags nullptr ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Overload Sorting Grouping ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ group_overloads overloads Sequence PythonSignatureNativeFunctionPair symint bool = True - Sequence PythonSignatureGroup bases dict str PythonSignatureNativeFunctionPair = outplaces dict str PythonSignatureNativeFunctionPair = first group signature ignoring out arguments overload overloads sig = overload signature signature_str skip_outputs=True symint=symint overload function func is_out_fn sig outplaces raise RuntimeError f Found duplicated function definition \n- overload function func \n f Existing definition \n- outplaces sig function func outplaces sig = overload sig bases raise RuntimeError f Found duplicated function definition \n- overload function func \n f Existing definition \n- bases sig function func bases sig = overload sig out outplaces items sig bases candidates list str = overload overloads str overload function func name name == str out function func name name overload function func is_out_fn overload signature deprecated candidates append overload signature signature_str skip_outputs=True symint=symint out_sig = out signature signature_str symint=symint raise RuntimeError f While identifying overloads we found out schema out_sig without corresponding non-out variant f We expected non-out variant have schema \n- sig \nPlease check you spelled schema correctly native_functions yaml We discovered following candidate s \n + \n join f - candidate candidate candidates grouped = PythonSignatureGroup from_pairs functional=base out=outplaces get sig sig base bases items sort_overloads grouped symint=symint This function declares partial order declarations sorts them according its linear extension This necessary because there s some ambiguity choice overload we want different order See Note Order overloads matters A few examples ambiguous python signature pairs All parameters have same type except one taking Tensor other taking Scalar A numeric PyObject can casted into Tensor zero-dim Tensor object can accepted Scalar type parameter see python_arg_parser cpp Therefore same input arguments might accepted either python signature We want always parse one taking Tensor first bitwise_and Tensor input Tensor other Tensor out=None bitwise_and Tensor input Scalar other Tensor out=None If they have different number parameters then they ambiguous - difference output param can ignored s optional multiply Tensor input Tensor other Tensor out=None multiply Tensor input Scalar other Both positional args keyword-only args considered together subtract Tensor other Scalar alpha= subtract Scalar other Scalar alpha= A few ambiguous cases which does NOT handle yet If there any difference other parameters besides Tensor Scalar difference then they considered ambiguous method anymore However difference could too trivial disambiguate foo Tensor input Scalar other Scalar bar foo Tensor input Tensor other double bar If they taking different number parameters then they considered ambiguous anymore even difference only optional kwargs foo Scalar other Scalar alpha= foo Tensor other Scalar alpha= Scalar beta= sort_overloads grouped_overloads Sequence PythonSignatureGroup symint bool = True - Sequence PythonSignatureGroup NB Smaller here means lower priority is_arg_smaller t Type t Type - bool str t == Scalar str t == Tensor str t == Scalar str t == Tensor Dimname str t Dimname str t In discussion https github com pytorch pytorch issues has been discussed why important prioritize int int over int str t == int str t == int str t == int TensorList currently throws error during argument parsing s why needs last signature ordering See discussion https github com pytorch pytorch issues str t == Tensor str t find = - Prioritize IntArrayRef overload over SymIntArrayRef str t == SymInt str t == int Make sure both SymInt sorted consistently w r t Tensor since Tensor can implicitly converted either int SymInt Prioritize Tensor overload since otherwise gets shadowed str t == SymInt str t == int str t == Tensor is_smaller s PythonSignature s PythonSignature - bool Returns True s s partial order args args = s arguments skip_outputs=True s arguments skip_outputs=True len args = len args False TODO should use some canonical form instead str arg type - see comments above The old codegen used deprecated dynamic_type arg type which ignores optional annotation i e Scalar Scalar equal = all arg type == arg type arg arg zip args args smaller_or_equal = all str arg type == str arg type is_arg_smaller arg type arg type arg arg zip args args smaller_or_equal equal First sort signature grouped_overloads = sorted grouped_overloads key=lambda x x signature signature_str symint=symint Construct relation graph larger_than dict int set int = defaultdict set i overload enumerate grouped_overloads i overload enumerate grouped_overloads is_smaller overload signature overload signature larger_than i add i larger_than list grouped_overloads Use topological sort sort overloads according partial order N = len grouped_overloads sorted_ids list int = list filter lambda x x larger_than range N idx range N The size sorted_ids will grow N eventually i = sorted_ids idx j sorted larger_than keys larger = larger_than j larger discard i larger del larger_than j sorted_ids append j grouped_overloads x x sorted_ids ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Codegen API Integration ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ emit_single_dispatch ps PythonSignature f NativeFunction structseq_typenames dict str str symint bool = True - str Emit dispatch code single native function with_native_function go f NativeFunction - str header comments isinstance ps PythonSignatureDeprecated schema_comment = f deprecated aten ps deprecated_schema schema_comment = f aten f func dispatch lambda signature name = cpp name f func lambda_formals = join f type_str name dispatch_lambda_args ps f symint=symint lambda_return = dispatch_lambda_return_str f dispatch lambda body dispatch_callee = cpp_dispatch_target f dispatch_args = join cpp_dispatch_exprs f python_signature=ps arg parser outputs dispatch lambda arguments parser_outputs = arg_parser_output_exprs ps f symint=symint lambda_arg_exprs = dispatch_lambda_exprs ps f symint=symint inits = \n join lambda_arg_exprs inits lambda_args = join lambda_arg_exprs exprs scatter fields TODO Checking ` ps method requires_grad parser_outputs ` hacky solution enabling requires_grad argument tensor methods new_full new_empty new_zeros A much better more difficult implement solution involves refactoring according Ed s description here https github com pytorch pytorch issues #issuecomment- need_set_requires_grad = ps tensor_options_args has_tensor_options f ps method requires_grad parser_outputs set_requires_grad = f set_requires_grad parser_outputs requires_grad expr need_set_requires_grad lambda_return == void Make in-place foreach ` ` python-binding level ref https github com pytorch pytorch pull #pullrequestreview- self_arg = f func arguments self_arg return_stmt str str f func name startswith _foreach_ f func kind == SchemaKind inplace note crcrpar ` _foreach_pow ScalarAndTensor ` does NOT have its in-place variant unlikely have future Thus s safe have following assert assert self_arg None is_tensor_list_type self_arg argument type return_stmt = PyObject self_tensorlist = _r args Py_INCREF self_tensorlist self_tensorlist return_stmt = Py_RETURN_NONE f \ schema_comment inits auto dispatch_ name = lambda_formals - lambda_return pybind gil_scoped_release no_gil dispatch_callee dispatch_args dispatch_ name lambda_args set_requires_grad return_stmt typename = structseq_typenames get gen_structseq_typename_key f structseq_typeref = f typename typename None f \ schema_comment inits auto dispatch_ name = lambda_formals - lambda_return pybind gil_scoped_release no_gil dispatch_callee dispatch_args wrap structseq_typeref dispatch_ name lambda_args set_requires_grad go f