mypy ignore-errors copy math os sys collections abc Callable dataclasses dataclass functools partial wraps torch torch fx fx torch hub tqdm torch multiprocessing reductions StorageWeakRef torch utils _content_store ContentStoreWriter compile_utils get_outputs get_placeholders is_tuple = object dataclass LoadTensorMeta size list int stride list int dtype torch dtype device torch device ConcreteProp torch fx Interpreter __init__ mod writer=None skip_offload=False super __init__ mod writer = writer skip_offload = skip_offload seen_storages = set run_node n pbar update r = super run_node n name = n name isinstance r torch Tensor writer None n meta concrete_value = r StorageWeakRef r untyped_storage seen_storages Refuse offload tensors which alias other live tensors because will violate operator contracts n meta concrete_value = None skip_offload writer write_tensor os path join eager name r n meta concrete_value = LoadTensorMeta r size r stride r dtype r device seen_storages add StorageWeakRef r untyped_storage n meta concrete_value = is_tuple r propagate args tqdm desc= Saving intermediates delta debugging total=len module graph nodes disable=self writer None pbar pbar = pbar r = super run args skip_offload pbar set_description Saved To skip next time run -- skip-saving-eager-intermediates r is_load_tensor_node node node op == call_function node target torch ops debugprims load_tensor default inplace modifies node inps _convert_node_to_placeholder graph node inps node op == output node op == placeholder False is_load_tensor_node node False concrete_val = node meta get concrete_value None isinstance concrete_val torch Tensor node op = placeholder node target = node name node args = node kwargs = inps append concrete_val True concrete_val None False concrete_val is_tuple r = False tuple_user list node users r = _convert_node_to_placeholder graph tuple_user inps r NB We must erase node point because we iterating over nodes would change iteration order graph erase_node node r isinstance concrete_val LoadTensorMeta node op = call_function node target = torch ops debugprims load_tensor default node args = os path join eager node name concrete_val size concrete_val stride node kwargs = device concrete_val device dtype concrete_val dtype True False create_minified_hlo_graph minified_fx_graph inputs Takes minified FX graph primary input ports HLO via StableHLO Provides minified HLO graph output archive them local directory hlo_dir = f os getcwd hlo_files os makedirs hlo_dir exists_ok=True torch_xla stablehlo save_torch_model_as_stablehlo save_torch_model_as_stablehlo minified_fx_graph inputs hlo_dir dump_state fx_g inps print f Working Repro len fx_g graph nodes nodes inps = i shape i dtype i device type i inps inps = torch zeros + torch ones shape dtype=dtype device=device shape dtype device inps fx_g code is_power_of_two n n == False n n - == dataclass ReproState graph fx Graph inps list torch Tensor __post_init__ ph_nodes = get_placeholders graph assert len ph_nodes == len inps minifier fail_f fx GraphModule inps module_fails dump_state Callable = dump_state save_dir=None offload_to_disk=False skip_offload=False skip_sanity=False max_granularity=None Minimizes FX graph given inputs such resulting FX graph still returns True module_fails Does main strategies Truncates suffix Removes some suffix graph sets new output Delta Debugging Tries replacing half graph inputs If fails tries replacing quarter graph etc xdoctest +SKIP failing failing_function = fx symbolic_trace f minimize failing_function torch randn lambda fx_g inps fx_g inps note module_fails returns True fails assert isinstance inps tuple list failing_graph = fail_f graph cur_size = len failing_graph nodes max_granularity None is_power_of_two max_granularity raise RuntimeError f max_granularity max_granularity power two num_queries = deepcopy_fx_graph fx_graph fx GraphModule fail_f copy deepcopy fx_graph graph graph_fails graph inps nonlocal num_queries graph = copy deepcopy graph num_queries += mod = fx GraphModule fail_f graph mod graph lint module_fails mod inps writer = None offload_to_disk writer = ContentStoreWriter save_dir ConcreteProp fail_f writer=writer skip_offload=skip_offload propagate inps skip_sanity graph_fails failing_graph inps raise RuntimeError Input graph did fail tester print f Started off cur_size nodes file=sys stderr _register_strategy strategy Callable name str wraps strategy new_func old_state ReproState granularity= print file=sys stderr print f Strategy name G granularity f len old_state graph nodes nodes len old_state inps inputs file=sys stderr new_state = strategy deepcopy_fx_graph old_state graph list old_state inps granularity new_state None new_nodes = len new_state graph nodes old_nodes = len old_state graph nodes new_inps = len new_state inps old_inps = len old_state inps new_outs = len get_outputs new_state graph old_outs = len get_outputs old_state graph progress_made = False new_nodes old_nodes progress_made = True print f SUCCESS Went old_nodes new_nodes nodes file=sys stderr new_inps old_inps progress_made = True print f SUCCESS Went old_inps new_inps inputs file=sys stderr new_outs old_outs progress_made = True print f SUCCESS Went old_outs new_outs outputs file=sys stderr progress_made raise RuntimeError Success raised no progress made graph_fails new_state graph new_state inps print WARNING Something went wrong applying minification file=sys stderr None new_state print f FAIL name file=sys stderr None new_func register_strategy name str partial _register_strategy name=name register_strategy Truncate suffix remove_suffix cur_graph cur_inps granularity tested = set new_graph = fx Graph env = idx node enumerate cur_graph nodes new_node = new_graph node_copy node lambda x env x node op placeholder output If idx divisible granularity would have been checked already idx granularity == idx granularity = idx tested output_node = new_graph output new_node len new_graph nodes len cur_graph nodes graph_fails new_graph cur_inps ReproState new_graph cur_inps tested add idx new_graph erase_node output_node env node = new_node None register_strategy Remove outputs remove_outputs cur_graph cur_inps granularity granularity = max granularity idx node enumerate cur_graph nodes node idx = idx node op == output output = node break isinstance output args fx Node None output_args = sorted output args key=lambda x x idx isinstance x fx Node int e len output_args == None idx range len output_args granularity output args = output_args idx + output_args idx + granularity graph_fails cur_graph cur_inps ReproState cur_graph cur_inps None remove_unused_inputs_unchecked cur_state ReproState cur_graph = cur_state graph cur_inps = cur_state inps ph_nodes = get_placeholders cur_graph assert len ph_nodes == len cur_inps new_inps = idx range len ph_nodes len ph_nodes idx users == cur_graph erase_node ph_nodes idx new_inps append cur_inps idx len new_inps len cur_inps ReproState cur_graph new_inps None remove_unused_inputs_checked cur_state ReproState new_state = remove_unused_inputs_unchecked cur_state new_state None graph_fails new_state graph new_state inps new_state None _remove_unused_wrapper cur_graph cur_inps granularity remove_unused_inputs_checked ReproState cur_graph cur_inps remove_unused_inputs = register_strategy Remove unused inputs _remove_unused_wrapper register_strategy Eliminate dead code eliminate_dead_code cur_graph cur_inps granularity cur_graph eliminate_dead_code graph_fails cur_graph cur_inps ReproState cur_graph cur_inps None _consolidate_placeholders cur_graph inps new_graph = fx Graph env = seen_non_placeholder = False Move all placeholders front also any load_tensor front convert into input because can live all time node cur_graph nodes node op == placeholder new_node = new_graph node_copy node lambda x env x env node = new_node seen_non_placeholder is_load_tensor_node node new_node = new_graph placeholder node name env node = new_node inps append torch ops debugprims load_tensor default node args node kwargs seen_non_placeholder = True Move everyone node cur_graph nodes node env new_node = new_graph node_copy node lambda x env x env node = new_node new_graph register_strategy Delta Debugging delta_debugging cur_graph fx Graph cur_inps granularity num_nodes = len cur_graph nodes start_range range num_nodes granularity is_removing = False new_graph = deepcopy_fx_graph cur_graph new_inps = cur_inps end_range = min num_nodes start_range + granularity idx range start_range end_range new_node = list new_graph nodes idx _convert_node_to_placeholder new_graph new_node new_inps is_removing = True is_removing continue new_graph eliminate_dead_code new_graph = _consolidate_placeholders new_graph new_inps new_state = remove_unused_inputs_unchecked ReproState new_graph new_inps new_state None new_state = ReproState new_graph new_inps graph_fails new_state graph new_state inps ReproState new_state graph new_state inps None register_strategy Consolidate Inputs consolidate_inputs cur_graph cur_inps granularity old_len = len cur_inps cur_graph = _consolidate_placeholders cur_graph cur_inps len cur_inps old_len graph_fails cur_graph cur_inps ReproState cur_graph cur_inps None failing_state = ReproState failing_graph inps try_granularity failing_state granularity use_non_granular print f Trying granularity granularity file=sys stderr strategies = num_nodes = len failing_state graph nodes num_outputs = len get_outputs failing_state graph num_outputs num_nodes strategies += remove_outputs use_non_granular strategies += eliminate_dead_code remove_unused_inputs consolidate_inputs strategies += remove_suffix delta_debugging strategy strategies new_state = strategy failing_state granularity new_state None new_state None while True dump_state fx GraphModule fail_f failing_state graph failing_state inps granularity = int math floor math log len failing_state graph nodes max_granularity None granularity = min max_granularity granularity new_state = try_granularity failing_state granularity use_non_granular=True new_state None failing_state = new_state continue granularity = has_progress = False while granularity = new_state = try_granularity failing_state granularity use_non_granular=False new_state None failing_state = new_state has_progress = True break granularity = has_progress continue new_state = remove_outputs failing_state new_state None failing_state = new_state continue break graph_fails failing_state graph failing_state inps raise RuntimeError Uh oh something went wrong Final graph failing print f Made num_queries queries file=sys stderr failing_fx = fx GraphModule fail_f failing_state graph If XLA debugging environment enabled create minified HLO graph well XLA_HLO_DEBUG os environ create_minified_hlo_graph failing_fx failing_state inps dump_state failing_fx failing_state inps print Wrote minimal repro out repro py file=sys stderr failing_fx failing_state inps