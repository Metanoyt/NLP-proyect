Owner s module decompositions functools itertools re unittest collections defaultdict functools partial torch _inductor decomposition torch autograd torch Tensor torch _decomp core_aten_decompositions decomposition_table torch _dispatch python enable_python_dispatcher torch _export utils _is_cia_op torch _ops DispatchKey torch testing make_tensor torch testing _internal common_cuda SM OrLater tf _off torch testing _internal common_device_type instantiate_device_type_tests onlyCPU onlyCUDA onlyNativeDeviceTypes ops torch testing _internal common_methods_invocations op_db skip skipOps xfail torch testing _internal common_modules module_db modules torch testing _internal common_utils is_iterable_of_tensors run_tests skipIfCrossRef skipIfTorchDynamo suppress_warnings TEST_WITH_ASAN TEST_WITH_SLOW TestCase unMarkDynamoStrictTest torch utils _pytree pytree torch utils _python_dispatch TorchDispatchMode torch utils _pytree tree_flatten tree_map tree_unflatten aten = torch ops aten TODO isn t going work non-aten namespaces overload_to_aten_name op op _schema name split All operators can have decomp tests decomposition_names = overload_to_aten_name k k decomposition_table isinstance k torch _ops OpOverload core_decomposition_names = overload_to_aten_name k k core_aten_decompositions isinstance k torch _ops OpOverload _is_cia_op k _decomp_test_ops = op op op_db op aten_name decomposition_names op aten_backward_name decomposition_names _decomp_test_ops_core_autograd = op op op_db op aten_name core_decomposition_names op supports_autograd _sdpa_op_info = op op op_db scaled_dot_product_attention op aten_name diff_arg arg requires_grad=True is_differentiable_arg arg requires_grad arg requires_grad arg is_floating_point arg is_complex is_iterable_of_tensors arg all is_differentiable_arg arg True all is_differentiable_arg arg False raise RuntimeError NYI The test runner can t handle isinstance arg Tensor is_differentiable_arg arg Version autograd grad some differences - pytree inputs allowed leaves pytree have all tensors - input used part derivatives we will zero-filled tensor result _autograd_grad outputs inputs grad_outputs=None retain_graph=False create_graph=True inputs inputs_spec = tree_flatten inputs diff_inputs = tuple inp inp inputs inp requires_grad grad_outputs None diff_outputs = tuple out out outputs out requires_grad diff_grad_outputs = out go out go zip outputs grad_outputs out requires_grad len diff_grad_outputs == diff_outputs grad_outputs = diff_outputs grad_outputs = zip diff_grad_outputs grad_inputs = torch autograd grad diff_outputs diff_inputs grad_outputs retain_graph=retain_graph create_graph=create_graph allow_unused=True result = grad_inputs_iter = iter grad_inputs inp inputs inp requires_grad grad_input = next grad_inputs_iter grad_input None result append torch zeros_like inp result append grad_input result append torch zeros_like inp tree_unflatten result inputs_spec _as_tuple val isinstance val tuple val val ref_vjp_no_create f primals result = f primals wrapped cotangents _autograd_grad _as_tuple result primals _as_tuple cotangents create_graph=False retain_graph=True result wrapped dtype_precisions = torch float e- torch bfloat e- torch float e- e- torch float e- e- torch complex e- torch complex e- e- torch complex e- e- Returns default rtol atol comparing scalars tensors given dtypes _getDefaultRtolAndAtol dtype dtype rtol = max dtype_precisions get dtype dtype_precisions get dtype atol = max dtype_precisions get dtype dtype_precisions get dtype rtol atol op_assert_ref test_case op test_dtype i orig decomp ref args kwargs assert orig dtype == decomp dtype f i Operation op orig numel == decomp numel == assert orig numel == decomp numel assert orig shape == decomp shape f i Operation op tol_table = torch bfloat torch ops aten native_layer_norm default e- torch float torch ops aten native_layer_norm default e- torch float torch ops aten native_layer_norm_backward default e- torch bfloat torch ops aten native_layer_norm_backward default e- torch bfloat torch ops aten native_batch_norm default e- torch float torch ops aten native_batch_norm default e- torch bfloat torch ops aten _native_batch_norm_legit default e- torch bfloat torch ops aten _native_batch_norm_legit no_stats e- torch float torch ops aten _native_batch_norm_legit default e- torch float torch ops aten _native_batch_norm_legit no_stats e- torch bfloat torch ops aten linalg_vector_norm default e- torch float torch ops aten linalg_vector_norm default e- torch bfloat torch ops aten var_mean correction e- torch float torch ops aten var_mean correction e- torch bfloat torch ops aten var_mean dim e- torch float torch ops aten var_mean dim e- torch float torch ops aten nll_loss_forward default e- torch bfloat torch ops aten nll_loss_forward default e- torch float torch ops aten nll_loss d_forward default e- torch bfloat torch ops aten nll_loss d_forward default e- torch float torch ops aten hardswish default e- torch bfloat torch ops aten hardswish default e- torch float torch ops aten multi_margin_loss default e- torch bfloat torch ops aten multi_margin_loss default e- torch float torch ops aten multilabel_margin_loss_forward default e- torch bfloat torch ops aten multilabel_margin_loss_forward default e- torch float torch ops aten reflection_pad d_backward default e- torch bfloat torch ops aten reflection_pad d_backward default e- torch float torch ops aten reflection_pad d_backward default e- torch bfloat torch ops aten reflection_pad d_backward default e- torch float torch ops aten reflection_pad d_backward default e- torch bfloat torch ops aten reflection_pad d_backward default e- torch float torch ops aten _batch_norm_with_update default e- torch bfloat torch ops aten _batch_norm_with_update default e- see https github com pytorch pytorch pull torch float torch ops aten mv default e- torch bfloat torch ops aten mv default e- torch float torch ops aten log_sigmoid_backward default e- torch float torch ops aten _softmax_backward_data default e- ref is_floating_point orig_diff = orig - ref abs max decomp_diff = decomp - ref abs max atol = tol_table get test_dtype op e- decomp_diff orig_diff + atol raise RuntimeError f Difference float larger decomposition op __name__ f than original output i Original max diff orig_diff Decomp max diff decomp_diff \n f atol = atol \n f args = args \n f kwargs = kwargs test_case assertEqual orig decomp msg=f op __name__ \nargs = args \nkwargs = kwargs op_assert_equal test_case op test_dtype orig decomp args kwargs test_case assertEqual orig dtype decomp dtype f Operation op orig dtype orig dtype decomp dtype decomp dtype args kwargs Before adding entry table make sure your decomposition right tol_table = Due strange epsilon behaviors see https github com pytorch pytorch issues torch float torch ops aten native_layer_norm default e- e- torch float torch ops aten native_layer_norm_backward default e- e- torch float torch ops aten native_layer_norm default e- e- This exceeds default tolerances only CPU CUDA s fine torch float torch ops aten grid_sampler_ d default e- e- Exceeds tolerances CUDA likely due fma torch float torch ops aten mv default e- e- torch complex torch ops aten mv default e- e- torch float torch ops aten upsample_bicubic d vec e- e- torch float torch ops aten upsample_bicubic d default e- e- The decomposition TOO correct It computes everything int so sometimes there s off-by-one error See https github com pytorch pytorch issues https github com pytorch pytorch issues torch int torch ops aten linspace default torch uint torch ops aten linspace default torch int torch ops aten linspace default torch int torch ops aten linspace default torch int torch ops aten linspace default torch int torch ops aten linspace Tensor_Tensor torch uint torch ops aten linspace Tensor_Tensor torch int torch ops aten linspace Tensor_Tensor torch int torch ops aten linspace Tensor_Tensor torch int torch ops aten linspace Tensor_Tensor torch int torch ops aten linspace Tensor_Scalar torch uint torch ops aten linspace Tensor_Scalar torch int torch ops aten linspace Tensor_Scalar torch int torch ops aten linspace Tensor_Scalar torch int torch ops aten linspace Tensor_Scalar torch int torch ops aten linspace Scalar_Tensor torch uint torch ops aten linspace Scalar_Tensor torch int torch ops aten linspace Scalar_Tensor torch int torch ops aten linspace Scalar_Tensor torch int torch ops aten linspace Scalar_Tensor decomp dtype op tol_table rtol atol = tol_table decomp dtype op rtol atol = _getDefaultRtolAndAtol orig dtype decomp dtype test_case assertEqual orig decomp rtol=rtol atol=atol msg=f op __name__ \nargs = args \nkwargs = kwargs Given f returns f such - f takes only positional arguments - All arguments f floating-point Tensors - All outputs f floating-point Tensors normalize_op_input_output f args kwargs output_process_fn_grad=None requires_grad=True flat_args args_spec = tree_flatten args diff_argnums = tuple i i arg enumerate flat_args diff_arg arg requires_grad=requires_grad assert len diff_argnums primals = tuple flat_args i i diff_argnums functools wraps f wrapped primals _args = list flat_args num arg zip diff_argnums primals _args num = arg _args = tree_unflatten _args args_spec result = f _args kwargs output_process_fn_grad None result = output_process_fn_grad result isinstance result tuple TODO We should check integer outputs also agree result = tuple r r result isinstance r Tensor r is_floating_point r is_complex assert len result result wrapped primals NB This also upcasts dtype arguments TODO handle complex correctly upcast_tensor x dtype=torch float isinstance x Tensor x dtype is_floating_point x dtype=dtype isinstance x torch dtype x torch float torch bfloat torch float dtype x normalize_op_input_output f sample requires_grad=True args = tuple sample input + list sample args normalize_op_input_output f args sample kwargs sample output_process_fn_grad requires_grad=requires_grad CROSS_REF_EXCLUDE_SET = CUBLAS_STATUS_NOT_SUPPORTED when calling ` cublasGemmStridedBatchedExFix handle opa opb int m int n int k void falpha CUDA_R_ BF int lda stridea b CUDA_R_ BF int ldb strideb void fbeta c CUDA_R_ BF int ldc stridec int num_batches CUDA_R_ F CUBLAS_GEMM_DEFAULT_TENSOR_OP ` cuda torch bfloat nn functional bilinear randomness None None special ndtr aten special_ndtr decomposed None None new_empty None None empty_like None None empty AssertionError False true aten item decomposed saw calls aten _local_scalar_dense default None None item It s only in-place op without out-of-place equivalent Python API Its OpInfo wrongly registers ` torch zero_ x clone ` None None zero_ No idea what s going here In recursive test logsumexp default fails args = torch tensor -math inf test seems pass when tested locally logsumexp test None torch float masked logsumexp None torch float masked logsumexp exp_vml_cpu implemented Half torch cpu torch float signal windows exponential torch cpu torch float signal windows gaussian sin_vml_cpu implemented Half torch cpu torch float signal windows cosine CompositeAutogradImplicit See https github com pytorch pytorch issues None None nn functional relu This decomp runs before autograd None None nn functional rrelu None None meshgrid Decomposition registered Autograd None None nn functional hardshrink None None nn functional softshrink diag decomposed just registers decomp diag_out torch diag CompImplicit None None diag _softmax_backward_data s CPU kernel bfloat always grad_input float cpu torch bfloat _softmax_backward_data None None norm native_batch_norm only implicit when python dispatcher noncomposite otherwise None None native_batch_norm None None _upsample_bilinear d_aa None None empty_strided aten empty_strided decomposed None None bernoulli bernoulli function randomness so couldn t do cross-reference CROSS_REF_BACKWARD_EXCLUDE_SET = Decomposed backward formula precise cpu torch bfloat nn functional hardswish cuda torch float nn functional cross_entropy None None bernoulli bernoulli function randomness so couldn t do cross-reference all_decomposed = set all_called = defaultdict int Helpful snippet testing coverage atexit check_coverage print missing coverage print \n join map str decomposition_table keys - all_decomposed atexit register check_coverage Helpful snippet Horace create his google sheet atexit dump_ops open run_ops txt w f open count_ops txt w g op count sorted all_called items key=lambda x x __name__ f write f op __name__ \n g write f count \n open run_decompositions txt w f op sorted i __name__ i all_decomposed f write f op \n atexit register dump_ops any_unsupported args kwargs test_unsupported t type t torch Tensor type t torch nn Parameter These all things we haven t coded decompositions handle correctly Maybe they should any t is_sparse_csr t is_sparse t is_mkldnn t is_quantized t is_nested torch _is_functional_tensor t torch overrides is_tensor_like t Decompositions will generally change behavior Tensor-like subclasses so bypass tests case too True False flat_args = pytree arg_tree_leaves args kwargs any test_unsupported x x flat_args core_backward_failures = skip _softmax_backward_data slow fails -- timeout= secs xfail addcdiv skip addcmul slow fails -- timeout= secs skip deg rad slow fails -- timeout= secs skip diag_embed slow fails -- timeout= secs skip frac slow fails -- timeout= secs skip grid_sampler_ d slow fails -- timeout= secs xfail lerp skip logaddexp slow fails -- timeout= secs skip native_dropout_backward slow fails -- timeout= secs xfail nn functional binary_cross_entropy_with_logits skip nn functional glu slow fails -- timeout= secs xfail nn functional hardshrink xfail nn functional softshrink skip nn functional unfold slow fails -- timeout= secs xfail norm xfail norm fro xfail norm inf xfail norm nuc skip rad deg slow fails -- timeout= secs skip renorm slow fails -- timeout= secs skip rot slow fails -- timeout= secs skip rsub slow fails -- timeout= secs skip sgn slow fails -- timeout= secs skip special xlog py slow fails -- timeout= secs xfail stack skip tril slow fails -- timeout= secs skip triu slow fails -- timeout= secs skip unfold_copy slow fails -- timeout= secs skip xlogy slow fails -- timeout= secs xfail zero_ TEST_WITH_SLOW core_backward_failures update skip addr slow takes sec A skip baddbmm slow takes + sec A skip clamp_min slow takes sec A skip clamp_max slow takes sec A skip logit slow takes sec A skip nn functional hardswish slow takes sec A skip std_mean slow takes sec A skip split variant_name= list_args slow takes sec A skip transpose slow takes sec A skip unbind slow takes sec A skip unsafe_split slow takes sec A comprehensive_failures = xfail nn functional interpolate bilinear dtypes= torch uint off one error xfail nn functional interpolate bicubic dtypes= torch uint off one error xfail nn functional upsample_bilinear dtypes= torch uint off one error unMarkDynamoStrictTest TestDecomp TestCase longMessage = True NB This actually overlaps test_comprehensive only runs things definitely decomposed so s lot faster run onlyNativeDeviceTypes skipIfCrossRef suppress_warnings ops _decomp_test_ops test_quick device dtype op do_cross_ref device dtype op run_all=False skipOps TestDecomp test_quick_core_backward core_backward_failures onlyNativeDeviceTypes skipIfCrossRef suppress_warnings ops _decomp_test_ops_core_autograd allowed_dtypes= torch float test_quick_core_backward device dtype op test_keys = torch device device type dtype op name None dtype op name None None op name any key CROSS_REF_BACKWARD_EXCLUDE_SET key test_keys skipTest f op name dtype supported sample_input op sample_inputs device dtype requires_grad=True aten_name = op decomp_aten_name op aten_name args = sample_input input + list sample_input args kwargs = sample_input kwargs func = partial op get_op kwargs DecompCrossRefMode precision rel_tol dtype run_all=False mode enable_python_dispatcher torch autograd gradcheck func args check_decomposed aten_name mode unittest skipIf TEST_WITH_ASAN Skipped under ASAN onlyNativeDeviceTypes skipIfCrossRef skipOps TestDecomp test_comprehensive comprehensive_failures suppress_warnings ops op_db test_comprehensive device dtype op do_cross_ref device dtype op run_all=True test_uniform device size = dtype = torch float x = make_tensor size dtype=dtype device=device low = high = torch manual_seed ref = torch ops aten uniform x low high torch manual_seed res = torch _decomp decompositions uniform x low=low high=high assertEqual ref res test_bernoulli_default device p = p_t = p torch ones torch manual_seed ref = torch ops aten bernoulli default p_t torch manual_seed res = torch _decomp decompositions bernoulli p_t ref_p = ref sum torch prod torch tensor ref size res_p = res sum torch prod torch tensor res size assertEqual ref_p res_p atol= p rtol= test_broadcasting_index_copy device x = torch zeros device=device xs = torch ones device=device index_copy xs x torch _decomp decompositions index_copy_ xs torch tensor device x index_copy xs x xs_two = torch ones device=device xs_two = x assertEqual xs xs_two test_cat_single_input device decomp_table = torch _inductor decomposition select_decomp_table cat_inductor = decomp_table torch ops aten cat default inp = torch rand device=device inps = inp _ range dim - assertEqual torch cat inps dim cat_inductor inps dim suppress_warnings tf _off only tests RNNs since we have py dispsatcher decomps them modules filter lambda m m module_cls torch nn RNN torch nn LSTM torch nn GRU module_db test_rnn_decomp_module device dtype module_info training module_cls = module_info module_cls module_inputs = module_info module_inputs_func module_info device=device dtype=dtype requires_grad=True training=training module_input module_inputs module_input forward_input None continue args kwargs = module_input constructor_input args module_input constructor_input kwargs m = module_cls args kwargs m device dtype args kwargs = module_input forward_input args module_input forward_input kwargs DecompCrossRefMode precision rel_tol dtype run_all=True enable_python_dispatcher decomp_out = m args kwargs non_decomp_out = m args kwargs without check incorrect decomps python dispatcher level can still pass because they re checking aten decomps torch_dispatch level assertEqual decomp_out non_decomp_out test_batch_norm_unflatten_weight_bias device https github com pytorch pytorch issues shape = input = torch randn shape device=device weight = torch randn device=device bias = torch randn device=device mean = torch randn device=device var = torch randn device=device res = torch _decomp decompositions native_batch_norm input weight bias mean var False e- assertEqual shape res shape test_arange_graph device torch fx experimental proxy_tensor make_fx func x start le = x shape - start None = torch arange le dtype=torch float device=x device = torch arange start le dtype=torch float device=x device pattern = r device = device\ +\ requires_grad = False cfunc = make_fx func decomposition_table=decomposition_table fx_g = cfunc torch rand device=device None fx_g_code = fx_g code strip Remove device requires_grad fx_g_code = re sub pattern fx_g_code assertExpectedInline fx_g_code \ forward x_ start_ iota = torch ops prims iota default start = step = dtype = torch int mul = torch ops prims mul default iota iota = None add = torch ops prims add default mul mul = None convert_element_type = torch ops prims convert_element_type default add torch float add = None convert_element_type fx_g = cfunc torch rand device=device fx_g_code = fx_g code strip Remove device requires_grad fx_g_code = re sub pattern fx_g_code assertExpectedInline fx_g_code \ forward x_ start_ iota = torch ops prims iota default start = step = dtype = torch int mul = torch ops prims mul default iota iota = None add = torch ops prims add default mul mul = None convert_element_type = torch ops prims convert_element_type default add torch float add = None convert_element_type test_masked_fill device torch fx experimental proxy_tensor make_fx torch device device type xpu cuda torch _C _get_privateuse _backend_name skipTest only runs XPU CUDA PrivateUse func scores mask value scores masked_fill mask value scores_t = torch tensor device=device mask_t = torch tensor True True True True device=device value_t = torch tensor dtype=scores_t dtype cfunc = make_fx func decomposition_table=decomposition_table fx_g = cfunc scores_t mask_t value_t assertExpectedInline fx_g code strip \ forward scores_ mask_ value_ where = torch ops prims where default mask_ value_ scores_ mask_ = value_ = scores_ = None where DecompCrossRefMode TorchDispatchMode __init__ test_case saved_precision saved_rel_tol dtype run_all test_case = test_case saved_precision = saved_precision saved_rel_tol = saved_rel_tol test_dtype = dtype run_all = run_all We check correctness each decomposition right after running So when we encounter decomposition we run function normally then run decomposition ensure they re identical called = set decomposed = set __torch_dispatch__ func types args= kwargs=None test_case precision = saved_precision test_case rel_tol = saved_rel_tol called add func all_called func += Stuff we shouldn t bother testing TODO remove detach decomp table N b Testing in-place ops would need dedicated logic in_place = func name - == _ ignored_ops = torch ops aten detach default non-deterministic ops torch ops aten empty memory_format torch ops aten empty_like default torch ops aten new_empty default torch ops aten empty_strided default torch ops aten new_empty_strided default torch ops aten randn default torch ops aten native_dropout default func decomposition_table func ignored_ops torch Tag nondeterministic_seeded func tags any_unsupported args kwargs in_place func args kwargs decomposed add func all_decomposed add func We take main strategies verifying correctness numerical stability decompositions The first one simply tolerance checking between decomp_out pytorch_out However fp bf reductions becomes very finicky there many guarantees we can make So fp bf we instead compare difference decomp_out pytorch_out_ pytorch_out pytorch_out_ In other words we compare how far decomposition pytorch ground truth i e fp If decomposition results more error we error We also decompose decomposition recursively further coverage some paths exercised directly OpInfos sadly just other ops decomposition = decomposition_table func do_relative_check = test_dtype torch float torch bfloat run_all Execute recursively via DFS find root possible error first decomp_out = pytree tree_leaves decomposition args kwargs decomp_out = pytree tree_leaves decomposition args kwargs At stage we should decomposing in-place op We d like have decompositions decompose out-of-place ops into out-of-place ops because decompositions run after functionalisation we would like them de-functionalise graph would break AoTAutograd We run real function after decomposition make sure decomposition does modify any inputs in-place If does real_out should different than decom_out so we should catch real_out_unflat = func args kwargs real_out = pytree tree_leaves real_out_unflat assert len real_out == len decomp_out do_relative_check device_arg = kwargs get device None upcast x isinstance x Tensor x device type == mps device_arg torch device device_arg type == mps upcast_tensor x dtype=torch float upcast_tensor x dtype=torch float real_out_double _ = tree_flatten func tree_map upcast args tree_map upcast kwargs i orig decomp ref enumerate zip real_out decomp_out real_out_double isinstance orig torch Tensor assert type orig type decomp assert orig == decomp continue op_assert_ref test_case func test_dtype i orig decomp ref args kwargs orig decomp zip real_out decomp_out isinstance orig torch Tensor assert type orig type decomp assert orig == decomp continue op_assert_equal test_case func test_dtype orig decomp args kwargs real_out_unflat check_decomposed aten_name mode assertTrue any overload_to_aten_name c == aten_name c mode decomposed msg= f aten aten_name decomposed saw calls f join map str list mode called If your op f CompositeImplicitAutograd you should skip test f updating CROSS_REF_EXCLUDE_SET skipIfTorchDynamo Test does work TorchDynamo do_cross_ref device dtype op run_all test_keys = torch device device type dtype op name None dtype op name None None op name any key CROSS_REF_EXCLUDE_SET key test_keys skipTest f op name dtype supported skip_decomp_vjp = any key CROSS_REF_BACKWARD_EXCLUDE_SET key test_keys requires_grad = op supports_autograd dtype op supported_backward_dtypes torch device device type TODO OpInfo really ought error out case s exercised test_ops_gradients atm The problem complex per-se which supported data movement only ops when we do backwards we expect other ops like add work dtype = torch complex samples = op sample_inputs device dtype requires_grad=requires_grad aten_name = op decomp_aten_name op aten_name func = op get_op run_without_python_dispatcher mode any isinstance op torch _ops OpOverload op has_kernel_for_dispatch_key DispatchKey CompositeImplicitAutograd op mode decomposed union func sample_input samples requires_grad fn primals = normalize_op_input_output func sample_input primals = tree_map lambda x x isinstance x torch Tensor x primals Once https github com pytorch pytorch pull I can store called list mode object instance no explicit clearing necessary I will create fresh mode each region DecompCrossRefMode precision rel_tol dtype run_all mode enable_python_dispatcher decomp_out decomp_vjp_fn = ref_vjp_no_create fn primals run_without_python_dispatcher mode without check incorrect decomps python dispatcher level can still pass because they re checking aten decomps torch_dispatch level DecompCrossRefMode precision rel_tol dtype run_all mode decomp_out decomp_vjp_fn = ref_vjp_no_create fn primals aten_name decomposition_names check_decomposed aten_name mode skip_decomp_vjp op aten_backward_name decomposition_names run_all cotangents = tree_map lambda x torch randn_like x decomp_out DecompCrossRefMode precision rel_tol dtype run_all mode enable_python_dispatcher decomp_vjp_fn cotangents run_without_python_dispatcher mode without check incorrect decomps python dispatcher level can still pass because they re checking aten decomps torch_dispatch level DecompCrossRefMode precision rel_tol dtype run_all mode decomp_vjp_fn cotangents run_all check_decomposed op aten_backward_name mode aten_name decomposition_names run_all args = sample_input input + list sample_input args kwargs = sample_input kwargs A failure here might because decomposition op wrong because decomposition used particular op wrong DecompCrossRefMode precision rel_tol dtype run_all mode enable_python_dispatcher func args kwargs run_without_python_dispatcher mode without check incorrect decomps python dispatcher level can still pass because they re checking aten decomps torch_dispatch level DecompCrossRefMode precision rel_tol dtype run_all mode func args kwargs run_all check_decomposed aten_name mode assert op supports_autograd skipTest only backwards decomposed dtype doesn t support AD instantiate_device_type_tests TestDecomp globals DecompOneOffTests TestCase onlyNativeDeviceTypes skipIfCrossRef test_contiguous_softmax device size = stride = dtype = torch float x = torch randn size dtype=dtype device=device x = torch as_strided x size stride ref = torch ops aten _softmax x - False res = torch _decomp decompositions _softmax x - False assertEqual ref stride res stride onlyNativeDeviceTypes skipIfCrossRef test_contiguous_log_softmax device size = stride = dtype = torch float x = torch randn size dtype=dtype device=device x = torch as_strided x size stride ref = torch ops aten _log_softmax x - False res = torch _decomp decompositions _log_softmax x - False assertEqual ref stride res stride onlyCUDA test_exponential_non_inf device inp = torch empty device=device torch _dynamo utils preserve_rng_state exp_ref = inp exponential_ exp = torch _refs exponential inp assertEqual exp exp_ref assertFalse exp isinf any unittest skipIf TEST_WITH_ASAN Skipped under ASAN skipIfCrossRef onlyCUDA test_amp_batch_norm_backward device = cuda grad_out = torch randn dtype=torch float device=device x = torch randn dtype=torch float device=device weight = torch randn dtype=torch float device=device rmean = torch randn dtype=torch float device=device rvar = torch randn dtype=torch float device=device mean = torch randn dtype=torch float device=device ref = torch ops aten native_batch_norm_backward grad_out x weight rmean rvar mean mean False e- True True True res = torch _decomp decompositions native_batch_norm_backward grad_out x weight rmean rvar mean mean False e- True True True b zip ref res assertEqual stride b stride assertEqual dtype b dtype onlyNativeDeviceTypes skipIfCrossRef test_elu_backward device size = dtype = torch float grad_out = torch randn size dtype=dtype device=device out = torch randn size dtype=dtype device=device ref = torch ops aten elu_backward grad_out True out res = torch _decomp decompositions elu_backward grad_out True out assertEqual ref res onlyNativeDeviceTypes skipIfCrossRef test_threshold_backward_dtype device grad = torch randint device=device input_tensor = torch randint device=device ref = torch ops aten threshold_backward grad input_tensor res = torch _decomp decompositions threshold_backward grad input_tensor assertEqual ref dtype res dtype onlyNativeDeviceTypes skipIfCrossRef test_weight_norm_interface device g = torch randn device=device v = torch randn device=device ref = torch ops aten _weight_norm_interface g v res = torch _decomp decompositions _weight_norm_interface g v assertTrue torch allclose ref res assertTrue torch allclose ref res inp = torch rand device=device inp = torch rand device=device assertEqual torch ops aten _weight_norm_interface inp inp torch _decomp decompositions _weight_norm_interface inp inp onlyCPU skipIfCrossRef skipOps DecompOneOffTests test_sdpa xfail nn functional scaled_dot_product_attention dtypes= torch half ops _sdpa_op_info test_sdpa device dtype op SDPA doesn t support float aligned aten src ATen native transformers attention cpp If we add support float over there we should update test well query_layer = torch randn device=device dtype=dtype key_layer = torch randn device=device dtype=dtype value_layer = torch randn device=device dtype=dtype masks = None torch ones device=device dtype=torch bool atol rtol = dtype_precisions dtype mask masks is_causal = mask None decomposed_res = torch _decomp decompositions scaled_dot_product_flash_attention_for_cpu query_layer key_layer value_layer is_causal attn_mask=mask actual_res = decomposed_res Output has form N H L E should continuous L N H E order subsequent view L N H E valid So permute before checking tensor contiguous assertTrue actual_res permute is_contiguous eager_res = op query_layer key_layer value_layer attn_mask=mask dropout_p= is_causal=is_causal assertTrue torch allclose actual_res eager_res atol=atol rtol=rtol onlyCPU test_native_layer_norm_cpu_decomp device f x w b torch ops aten native_layer_norm default x w b eps= x = torch randn dtype=torch bfloat device= cpu w = torch randn dtype=torch bfloat requires_grad=True device= cpu b = torch randn dtype=torch bfloat requires_grad=True device= cpu out_ref = f x w b torch _subclasses fake_tensor FakeTensorMode enable_python_dispatcher FakeTensorMode x = torch randn dtype=torch bfloat device= cpu w = torch randn dtype=torch bfloat requires_grad=True device= cpu b = torch randn dtype=torch bfloat requires_grad=True device= cpu out = f x w b o_ref o zip out_ref out assertEqual o_ref dtype o dtype onlyCUDA unittest skipIf SM OrLater triton test_rms_norm_decomp_cuda device torch compile rms_norm_sinh b c output = torch nn functional rms_norm b c torch sinh output normalized_shape_arg = input_tensor = torch randn device=device requires_grad=True weight_tensor = torch randn device=device requires_grad=True forward_pass_fn rms_norm_sinh input_tensor normalized_shape_arg weight_tensor model_output generated_codes = torch _inductor utils run_fw_bw_and_get_code forward_pass_fn check RMSNorm fused sinh assertTrue triton_per_fused_add_mean_mul_pow_rsqrt_sinh generated_codes assertTrue triton_per_fused__fused_rms_norm_backward_cosh_mul generated_codes instantiate_device_type_tests DecompOneOffTests globals HasDecompTest TestCase setUp super setUp maxDiff = None staticmethod _can_appear_in_trace op torch _ops OpOverload - bool has_tensor_arg = any Tensor str type itertools chain op _schema arguments op _schema returns has_tensor_arg False try CompositeImplicitAutograd ops transparent tracer so don t need decompositions _is_cia_op op except RuntimeError e has_key fails some jit-registered ops which shouldn t relevant here anyway does exist str e False raise test_has_decomposition all_aten_overloads name torch _C _dispatch_get_all_op_names name startswith aten continue name = name name packet_name overload_name = name split packet_name overload_name = name default packet = getattr aten packet_name assert isinstance packet torch _ops OpOverloadPacket op = getattr packet overload_name yield op This operators only registered some CI configurations so would cause test fail allow_list = aten get_gradients default overloads_wanting_decomp = op op all_aten_overloads _can_appear_in_trace op ops_missing_decomp = overloads_wanting_decomp - decomposition_table keys ops_missing_decomp -= allow_list assertExpected join sorted op name + \n op ops_missing_decomp test_aten_core_operators If decomposition isn t included core decompositions then must decompose core ATen operator See NOTE Core ATen Ops If test fails then either - Add decomposition torch _decomp core_aten_decompositions decomposition should used inductor core operator - Run test again EXPECTTEST_ACCEPT= update list core ATen operators inductor will use decomposition Some decompositions registered CompositeImplicitAutograd operators which never appear AOTAutograd s graph so never used useful_decomps = op op decomposition_table keys isinstance op torch _ops OpOverload _can_appear_in_trace op core_decomps = torch _decomp core_aten_decompositions keys core_aten_ops = useful_decomps - core_decomps assertExpected join sorted op name + \n op core_aten_ops test_conv d_decomposition torch _inductor decomposition conv d_to_conv d check_case N= C_in= C_out= L= K= stride= padding= dilation= groups= dtype=torch float device= cpu torch manual_seed x = torch randn N C_in L dtype=dtype device=device w = torch randn C_out C_in groups K dtype=dtype device=device b = torch randn C_out dtype=dtype device=device ref = torch ops aten conv d default x w b stride= stride padding= padding dilation= dilation groups=groups got = conv d_to_conv d x w b stride= stride padding= padding dilation= dilation groups=groups assertTrue torch allclose ref got atol= e- rtol= e- A few cases check_case default check_case stride= padding= K= check_case stride= padding= K= check_case dilation= padding= K= dilation check_case groups= C_in= C_out= groups= bigger check_case groups= C_in= C_out= grouped conv __name__ == __main__ run_tests