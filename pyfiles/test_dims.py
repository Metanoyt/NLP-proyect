Owner s module functorch Copyright c Facebook Inc its affiliates All rights reserved This source code licensed under BSD-style license found LICENSE file root directory source tree gc unittest skip skipIf attn_ft BertSelfAttention BertSelfAttentionA Linear attn_positional BertSelfAttention BertSelfAttentionB functorch dim torch functorch dim Dim DimList dimlists dims stack Tensor torch testing _internal common_utils run_tests skipIfTorchDynamo TEST_CUDA TestCase try torchvision models resnet except ImportError resnet = None contextlib contextmanager time perf_counter measure_perf = False measure_perf torchdim magic_trace magic_trace contextmanager magic_trace args kwargs yield contextmanager measure what b = perf_counter yield e = perf_counter print f what e - b f seconds triu A i j = dims = A i j zero = torch tensor dtype=torch float XXX - torch where janky torch where i = j zero order i j gpu_time lmb name r= b = torch cuda Event enable_timing=True e = torch cuda Event enable_timing=True magic_trace name + fxt _ range r lmb b record _ range r lmb e record e synchronize elapsed = b elapsed_time e torch profiler profile schedule=torch profiler schedule wait= warmup= active= on_trace_ready=tensorboard_trace_handler name with_stack=True profiler _ range lmb profiler step print name elapsed r elapsed r skipIfTorchDynamo Bad interaction TestMin TestCase setUp super setUp gc disable gc collect interesting = set o gc get_objects isinstance o torch Tensor Dim Tensor DimList interesting add id o cuda _testMethodName mem_allocated = torch cuda memory_allocated tearDown interesting = o gc get_objects isinstance o torch Tensor Dim Tensor DimList id o interesting interesting append o extra_memory = cuda _testMethodName extra_memory += torch cuda memory_allocated - mem_allocated nolevels = _n_levels_in_use == extra_memory = len interesting = refcycle refcycle garbage export_image garbage pdf gc collect assert nolevels f cleanup failed _n_levels_in_use assertEqual extra_memory f extra cuda memory left allocated extra_memory assertEqual len interesting f extra torch Tensor Dim Tensor left allocated len interesting objects types f type t t interesting test_manual_stuff A_ = torch rand B_ = torch rand i j k = dims A = A_ i k B = B_ k j C = A expand j B expand i sum k torch testing assert_close C order i j torch mm A_ B_ torch testing assert_close torch triu A_ triu A_ D_ = torch randint d = dims D = D_ d A index i D order k d attn batch_size= sequence_length= hidden_size= num_attention_heads= linear=Linear device=None time=False maybe_to x x device None x device attention_probs_dropout_prob = A = maybe_to BertSelfAttentionA hidden_size num_attention_heads attention_probs_dropout_prob linear=linear B = maybe_to BertSelfAttentionB hidden_size num_attention_heads attention_probs_dropout_prob A load_state_dict B state_dict hidden_state = maybe_to torch rand batch_size sequence_length hidden_size b_out = B hidden_state a_out = A hidden_state torch testing assert_close a_out b_out why does simple matmul do right thing time gpu_time lambda B hidden_state positional r= gpu_time lambda A hidden_state first_class r= approach relative_key relative_key_query A = maybe_to BertSelfAttentionA hidden_size num_attention_heads attention_probs_dropout_prob approach sequence_length linear=linear B = maybe_to BertSelfAttentionB hidden_size num_attention_heads attention_probs_dropout_prob approach sequence_length A load_state_dict B state_dict hidden_state = maybe_to torch rand batch_size sequence_length hidden_size b_out = B hidden_state a_out = A hidden_state torch testing assert_close a_out b_out time gpu_time lambda B hidden_state positional r= gpu_time lambda A hidden_state first_class r= A = maybe_to BertSelfAttentionA hidden_size num_attention_heads attention_probs_dropout_prob None None linear=linear B = maybe_to BertSelfAttentionB hidden_size num_attention_heads attention_probs_dropout_prob None None A load_state_dict B state_dict hidden_state = maybe_to torch rand batch_size sequence_length hidden_size past_key_value = maybe_to torch rand batch_size num_attention_heads sequence_length hidden_size num_attention_heads maybe_to torch rand batch_size num_attention_heads sequence_length hidden_size num_attention_heads b_out = B hidden_state past_key_value=past_key_value a_out = A hidden_state past_key_value=past_key_value torch testing assert_close a_out b_out time gpu_time lambda B hidden_state positional r= gpu_time lambda A hidden_state first_class r= test_attn attn test_inplace some embeddings table embeddings = torch zeros some sparse updates embeddings indices = torch arange + values = torch rand i n f = dims embeddings indices i f += values i f test_adapt f ci co = dims python adapts bytecode after number iterations check we still match names correctly _ range f skipIf TEST_CUDA no CUDA test_attn_cuda size BERT paper pretraining sequence length attn batch_size= hidden_size= sequence_length= num_attention_heads= device= cuda time=measure_perf linear=torch nn Linear test_stack i j d = dims A = torch rand _r = stack A i j d j b = r unbind d assertTrue torch allclose order i j i expand j order i j assertTrue torch allclose b order i j j expand i order i j test_max ap = torch rand i j k = dims = ap i j k r i = max dim=k torch testing assert_close r order i j ap max test_mm i j k q = dims = torch rand b = torch rand a_ = i k b_ = b k j q size = _r = a_ expand j q b_ expand i q sum k order q i j r = a_ b_ sum k order q i j print r print b test_with_dims_split = torch arange view i j k = dims k size = r = i j k x = r order i j k torch testing assert_close x test_hello A = torch rand B = torch rand i j k = dims r = A i r = A i k B k j sum k order i j torch testing assert_close r A B assertEqual A sum A i sum i assertEqual A sum A i sum - i torch testing assert_close A sum A i sum keepdim=True sum i torch testing assert_close A i std i True A std True torch testing assert_close A i k max i order k A max torch testing assert_close A sort A i k sort k order i k XXX - chunk changes size dimension has take new dimension assert torch allclose A chunk A i k chunk k order i k torch testing assert_close A i renorm i order i A renorm torch testing assert_close A expand - - A i k expand j order j i k z = dims C = torch arange torch testing assert_close A A i k index k C z order i z o l = dims o size = r = A i k index k o l torch testing assert_close r order i o l A view - rr = r index o l k torch testing assert_close A rr order i k r = i + k - r = torch arange None + torch arange None - torch testing assert_close r order i k r test torch testing assert_close A T A k order k test dimlist a_ b_ = dimlists torch testing assert_close A i a_ order a_ i A T test one bound dimlist torch testing assert_close A a_ order a_ A T test dimlist will end up empty torch testing assert_close A i b_ k order i k b_ A test too few things A i + i torch testing assert_close A i + i order i A + torch arange None test too many elements try A raise NotImplementedError except IndexError pass c d = dims c size = torch testing assert_close A i c d order i c d A view torch testing assert_close A c + c + order c A torch arange + torch arange C = torch rand c_ x y z = dims b c = C split dim= s = dims ref = C split dim= t = C s c_ split x y z dim=c_ b d zip ref t x y z torch testing assert_close b order s d D = torch rand torch testing assert_close D transpose flatten D i k j order i j order k r = id x x torch rand_like A i k dims assert id i r id k r r = id x x torch nn functional dropout A i k dims assert id i r id k r test_simple i j k = dims x = torch rand z = x i j z + z + z + z z order i j test_mm_fuse i j k = dims A = torch rand B = torch rand C = A i k B k j sum k order i j torch testing assert_close C A B test_time_mm_fuse i j k = dims A = torch rand B = torch rand _ range r = A B _ range = A i k b = B k j r = b sum k measure pp _ range A B magic_trace_stop_indicator measure fc _ range A i k B k j sum k order i j magic_trace f fxt _ range A i k B k j sum k order i j magic_trace p fxt _ range A B magic_trace_stop_indicator torch testing assert_close r order i j r test_compare_dims i j = dims i size = j size = i j noqa B test_seg i k = dims i size = k size = i + k - test_expand A = torch rand i = dims assertEqual list A i expand order i size test_network resnet None skipTest no torchvision rn = resnet norm_layer=lambda x torch nn BatchNorm d x track_running_stats=False rn train img = torch rand imgf = img view i j = dims r = rn img i j r = r order i j view r = rn imgf torch testing assert_close r r atol= e- rtol= e- test_dim_args = dimlists assert isinstance DimList = dims b = dimlists assert isinstance Dim assert isinstance b DimList assertEqual str b = dims sizes= assertEqual size assertEqual b size = dims sizes= b = dimlists sizes= assertEqual len b = dims b = dimlists sizes= assertEqual b size assertEqual b size test_diag i = dims A = torch rand A i i test_softmax_split = torch rand g i = dims sizes= None = i g m_b _ = max i f_b = torch exp - m_b l_b = f_b sum i m _ = m_b max g c = torch exp m_b - m f = c f_b order i g l = c l_b sum g torch testing assert_close f l torch nn functional softmax dim= test_index A = torch rand i j k = dims o l = dims o size = r = A i k index k o l torch testing assert_close r order i o l A view - rr = r index o l k torch testing assert_close A rr order i k z = dims C = torch arange x = A i k index k C z order i z torch testing assert_close A x C = torch rand ik = dims torch testing assert_close C index ik order ik C permute reshape failures came up monkey patching some operators test_monkey A = torch rand A = x = torch randn x_clone = x clone ia = torch tensor ib = torch tensor first_shape = x ia None ib shape x_clone ia None ib = torch randn first_shape x_clone x = torch autograd Variable torch tensor z = torch autograd Variable torch IntTensor = z z + x new assertEqual x new z z + tolist test_index_placement A = torch rand i j = dims sizes= = A i + j + r = order i j torch testing assert_close A permute r test_order i j = dims A = torch rand torch testing assert_close A i order i A permute test_mask = torch rand i j = dims sizes= size size i = j i sum j order i test_eq i j = dims sizes= assertEqual i == j sum i j test_dims_with_size x = dims assertEqual len x assert isinstance x Dim Foo pass y = Foo z y x q = dims assertEqual str z z assertEqual str y x d assertEqual str q d test_dir i j = dims sizes= dir i = j test_doc assertEqual Tensor clamp __doc__ torch Tensor clamp __doc__ test_embed embeddings = torch rand ids = torch tensor slow Pythonic values_ = torch empty batch range ids size feature range embeddings size values_ batch feature = embeddings ids batch feature torchdim single indexing kernel batch feature = dims values = embeddings ids batch feature order batch feature torch testing assert_close values values_ test_functorch A = torch rand B = torch rand C = torch rand i j = dims AA = torch mm A i C BB = torch mm B j C assertEqual list torch mm AA T BB order i j shape test_permute_orig d = dims t_fc = torch rand d assertEqual t_fc permute dims= shape t_fc permute shape test_order_keyword d = dims t = torch rand d assertRaises TypeError lambda t order wrong= test_big_split total = l = while total l append torch randint item total += l - x = torch randn total x split l skip_functorch_only = test_time_mm_fuse test_attn_cuda TestMinFunctorchOnly TestMin setUp super setUp functorch dim POINTWISE_OPTIMIZE = False tearDown functorch dim POINTWISE_OPTIMIZE = True super tearDown n skip_functorch_only setattr TestMinFunctorchOnly n skip skip_functorch_only lambda None __name__ == __main__ run_tests