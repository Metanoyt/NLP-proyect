csv gc json os abc ABC abstractmethod typing Optional typing_extensions Self torch _C _instruction_counter i_counter torch _dynamo config config torch _dynamo utils CompileTimeInstructionCounter log_to_scuba = os getenv CI false == true log_to_scuba fbscribelogger make_scribe_logger scribe_log_torch_benchmark_compile_time = make_scribe_logger TorchBenchmarkCompileTime struct TorchBenchmarkCompileTimeLogEntry The commit SHA triggered workflow e g b d f d b bfa d fac Derived GITHUB_SHA optional string commit_sha The unit timestamp second Scuba Time Column override optional i time optional i instruction_count Instruction count compilation step optional string name Benchmark name Commit date author date commit commit_sha timestamp e g Increasing merge bot used though monotonic duplicates occur when stack landed optional i commit_date A unique number each workflow run within repository e g Derived GITHUB_RUN_ID optional string github_run_id A unique number each attempt particular workflow run repository e g Derived GITHUB_RUN_ATTEMPT optional string github_run_attempt Indicates branch protections rulesets configured ref triggered workflow run Derived GITHUB_REF_PROTECTED optional bool github_ref_protected The fully-formed ref branch tag triggered workflow run e g refs pull merge refs heads main Derived GITHUB_REF optional string github_ref The weight record according current sampling rate optional i weight The name current job Derived JOB_NAME e g linux-jammy-py -gcc test default linux xlarge optional string github_job The GitHub user who triggered job Derived GITHUB_TRIGGERING_ACTOR optional string github_triggering_actor A unique number each run particular workflow repository e g Derived GITHUB_RUN_NUMBER optional string github_run_number_str noqa B BenchmarkBase ABC Measure total number instruction spent _work Garbage collection NOT disabled during _work _enable_instruction_count = False Measure total number instruction spent convert_frame compile_inner Garbage collection disabled during _work avoid noise _enable_compile_time_instruction_count = False number iterations used run when collecting instruction_count compile_time_instruction_count _num_iterations = __init__ category str device str backend str = mode str = dynamic=None - None These individual attributes used support different filters dashboard later _category = category _device = device _backend = backend _mode = mode Training inference _dynamic = dynamic with_iterations value int - Self _num_iterations = value enable_instruction_count - Self _enable_instruction_count = True enable_compile_time_instruction_count - Self _enable_compile_time_instruction_count = True name - str backend - str _backend mode - str _mode category - str _category device - str _device is_dynamic - Optional bool _dynamic description - str abstractmethod _prepare - None pass abstractmethod _work - None pass _prepare_once - None noqa B pass _count_instructions - int print f collecting instruction count name results = i range _num_iterations _prepare id = i_counter start _work count = i_counter end id print f instruction count iteration i count results append count min results _count_compile_time_instructions - int gc disable try print f collecting compile time instruction count name config record_compile_time_instruction_count = True results = i range _num_iterations _prepare gc collect CompileTimeInstructionCounter record only called convert_frame _compile_inner hence will only count instruction count spent compile_inner CompileTimeInstructionCounter clear _work count = CompileTimeInstructionCounter value count == raise RuntimeError compile time instruction count please check your benchmarks print f compile time instruction count iteration i count results append count config record_compile_time_instruction_count = False min results finally gc enable _write_to_json output_dir str - None Write result into JSON format so can uploaded benchmark database displayed OSS dashboard The JSON format defined https github com pytorch pytorch wiki How-to-integrate-with-PyTorch-OSS-benchmark-database records = entry results metric_name = entry value = entry metric_name value None continue records append benchmark name pr_time_benchmarks mode mode extra_info is_dynamic is_dynamic device device description description model name name type category backend backend metric name metric_name benchmark_values value open os path join output_dir f name json w f json dump records f append_results path str - None open path newline= csvfile Create writer object writer = csv writer csvfile Write data CSV file entry results writer writerow entry TODO huydhn This requires path write so needs same place CSV writer now _write_to_json os path dirname os path abspath path print - None entry results print f entry entry entry collect_all - Self _prepare_once results = _enable_instruction_count _enable_compile_time_instruction_count raise RuntimeError supported until we update logger both logs same field now _enable_instruction_count r = _count_instructions results append name instruction_count r log_to_scuba scribe_log_torch_benchmark_compile_time name=self name instruction_count=r _enable_compile_time_instruction_count enable_cpp_symbolic_shape_guards has impact these benchmarks Keep using False value consistency config patch enable_cpp_symbolic_shape_guards False r = _count_compile_time_instructions results append name compile_time_instruction_count r log_to_scuba TODO add new field compile_time_instruction_count logger scribe_log_torch_benchmark_compile_time name=self name instruction_count=r