Owner s oncall distributed logging unittest datetime timedelta typing Optional unittest mock MagicMock patch torch torch distributed dist torch nn nn torch distributed _shard sharded_tensor init_from_local_shards Shard ShardedTensorShard ShardMetadata torch distributed checkpoint _pg_transport _cast_tensor _prepare_state_dict _prepare_tensor _StateDictMeta _TensorMeta PGTransport torch distributed device_mesh init_device_mesh torch distributed distributed_c d _get_default_group torch distributed tensor DTensor torch testing _internal common_distributed at_least_x_gpu HAS_ACCELERATOR MultiProcContinuousTest requires_accelerator_dist_backend torch testing _internal common_utils run_tests skip_but_pass_in_sandcastle_if TestCase device_type = acc type acc = torch accelerator current_accelerator cpu logger = logging getLogger __name__ _create_sharded_tensor_state_dict rank int world_size int device torch device - dict Create state_dict ShardedTensor deterministic testing Args rank Current rank world_size Total world size device Device create tensors Returns dict State dictionary ShardedTensor Create deterministic local shard rank global_size = shard_size = global_size world_size start_idx = rank shard_size end_idx = rank + shard_size Create local tensor deterministic values local_tensor = torch arange start_idx end_idx dtype=torch float device=device reshape shard_size Create ShardedTensor using init_from_local_shards sharded_tensor = init_from_local_shards ShardedTensorShard tensor=local_tensor metadata=ShardMetadata shard_offsets= start_idx shard_sizes= shard_size placement=f rank rank device global_size sharded_tensor sharded_tensor rank_scalar torch tensor float rank device=device SimpleModel nn Module __init__ seed int = super __init__ Set seed deterministic initialization torch manual_seed seed net = nn Linear relu = nn ReLU net = nn Linear forward x net relu net x ring_send_recv_checkpoint transport PGTransport state_dict rank world_size step= Use transport send rank + receive rank - Each rank exchanges its own state_dict previous rank next_rank = rank + world_size prev_rank = rank - world_size rank == transport send_checkpoint next_rank state_dict received_checkpoint = transport recv_checkpoint prev_rank received_checkpoint = transport recv_checkpoint prev_rank transport send_checkpoint next_rank state_dict received_checkpoint _test_pg_transport device - None model = SimpleModel device transport = PGTransport _get_default_group timedelta seconds= device original_state_dict = model state_dict received_checkpoint = ring_send_recv_checkpoint transport=transport state_dict=original_state_dict rank=self rank world_size=self world_size assertEqual original_state_dict received_checkpoint _test_pg_transport_with_mixed_content device - None Create device mesh DTensor device_mesh = init_device_mesh device type world_size Create DTensor local_tensor = torch randn device=device dtensor = DTensor from_local local_tensor device_mesh Include mixed content state dict Dtensor Tensor non-tensor model = SimpleModel device state_dict = net weight model net weight data net bias model net bias data net weight model net weight data net bias model net bias data dtensor dtensor non-tensor some string nested tensor torch randn value list transport = PGTransport _get_default_group timedelta seconds= device received_checkpoint = ring_send_recv_checkpoint transport=transport state_dict=state_dict rank=self rank world_size=self world_size assertEqual state_dict received_checkpoint _test_pg_transport_with_sharded_tensor device - None Set current accelerator device NCCL XCCL device type == cuda device type == xpu torch accelerator set_device_index device state_dict = _create_sharded_tensor_state_dict rank world_size device transport = PGTransport _get_default_group timedelta seconds= device print state_dict received_checkpoint = ring_send_recv_checkpoint transport=transport state_dict=state_dict rank=self rank world_size=self world_size print finished comms print received_checkpoint Validate received checkpoint matches what we expect rank - prev_rank = rank - world_size Compare rank_scalar should previous rank Note PGTransport moves received tensors CPU when no state_dict callback provided expected_rank_scalar = torch tensor float prev_rank device= cpu received_rank_scalar = received_checkpoint rank_scalar type ignore index print f expected_rank_scalar= received_rank_scalar= torch testing assert_close expected_rank_scalar received_rank_scalar For ShardedTensor validate local shard data matches what prev_rank would have received_st = received_checkpoint sharded_tensor type ignore index global_size = shard_size = global_size world_size prev_start_idx = prev_rank shard_size prev_end_idx = prev_rank + shard_size expected_local_tensor = torch arange prev_start_idx prev_end_idx dtype=torch float device= cpu reshape shard_size Compare actual tensor data received_local_tensor = received_st local_shards tensor torch testing assert_close expected_local_tensor received_local_tensor PgTransportCPU MultiProcContinuousTest world_size = timeout timedelta = timedelta seconds= classmethod backend_str cls - Optional str gloo classmethod device_type cls - str cpu property device - torch device torch device device_type test_pg_transport - None _test_pg_transport device test_pg_transport_with_mixed_content - None _test_pg_transport_with_mixed_content device test_pg_transport_with_sharded_tensor - None _test_pg_transport_with_sharded_tensor device PgTransportGPU MultiProcContinuousTest world_size = timeout timedelta = timedelta seconds= classmethod backend_str cls - Optional str dist get_default_backend_for_device cls device_type property device - torch device torch device f device_type rank requires_accelerator_dist_backend skip_but_pass_in_sandcastle_if at_least_x_gpu test requires + accelerators test_pg_transport - None _test_pg_transport device requires_accelerator_dist_backend skip_but_pass_in_sandcastle_if at_least_x_gpu test requires + accelerators test_pg_transport_with_mixed_content - None _test_pg_transport_with_mixed_content device requires_accelerator_dist_backend skip_but_pass_in_sandcastle_if at_least_x_gpu test requires + accelerators test_pg_transport_with_sharded_tensor - None _test_pg_transport_with_sharded_tensor device TestCastTensor TestCase test_cast_tensor_different_dtypes Test casting tensors different dtypes dtypes = torch float torch float torch int torch int torch bool dtype dtypes original = torch tensor dtype=dtype casted = _cast_tensor original torch uint Check storage same assertIs original untyped_storage casted untyped_storage Check size correct assertEqual casted numel original untyped_storage nbytes test_cast_tensor_with_stride Test casting tensors non-standard strides Create tensor non-standard stride original = torch tensor dtype=torch float transposed = original t Transpose get non-standard stride casted = _cast_tensor transposed torch uint Check storage same assertIs transposed untyped_storage casted untyped_storage Check size correct assertEqual casted numel transposed untyped_storage nbytes test_cast_tensor_with_offset Test casting tensors storage offset Create tensor storage offset original = torch tensor dtype=torch float sliced = original This creates tensor storage offset casted = _cast_tensor sliced torch uint Check storage same assertIs sliced untyped_storage casted untyped_storage Check size correct assertEqual casted numel sliced untyped_storage nbytes TestPrepareTensor TestCase test_prepare_tensor_basic Test basic tensor preparation tensor = torch tensor dtype=torch float prepared_tensor meta = _prepare_tensor tensor Check metadata assertEqual meta shape tensor shape assertEqual meta dtype tensor dtype assertEqual meta storage_offset tensor storage_offset assertEqual meta stride tensor stride assertEqual meta nbytes tensor untyped_storage nbytes Check prepared tensor assertEqual prepared_tensor dtype torch uint assertEqual prepared_tensor numel tensor untyped_storage nbytes test_prepare_tensor_different_shapes Test preparing tensors different shapes shapes = shape shapes tensor = torch randn shape prepared_tensor meta = _prepare_tensor tensor Check metadata assertEqual meta shape tensor shape assertEqual meta dtype tensor dtype assertEqual meta storage_offset tensor storage_offset assertEqual meta stride tensor stride assertEqual meta nbytes tensor untyped_storage nbytes test_prepare_tensor_with_stride Test preparing tensors non-standard strides tensor = torch tensor dtype=torch float transposed = tensor t Transpose get non-standard stride prepared_tensor meta = _prepare_tensor transposed Check metadata assertEqual meta shape transposed shape assertEqual meta dtype transposed dtype assertEqual meta storage_offset transposed storage_offset assertEqual meta stride transposed stride assertEqual meta nbytes transposed untyped_storage nbytes TestPrepareStateDict TestCase test_prepare_state_dict_basic Test basic state dict preparation state_dict = weight torch randn bias torch randn device = torch device cpu meta tensors = _prepare_state_dict state_dict device Check metadata assertEqual len meta paths assertEqual len meta non_tensor_leaves assertEqual len tensors Check all non_tensor_leaves _TensorMeta instances leaf meta non_tensor_leaves assertIsInstance leaf _TensorMeta test_prepare_state_dict_nested Test preparing nested state dict state_dict = layer weight torch randn bias torch randn layer weight torch randn bias torch randn device = torch device cpu meta tensors = _prepare_state_dict state_dict device Check metadata assertEqual len meta paths assertEqual len meta non_tensor_leaves assertEqual len tensors test_prepare_state_dict_with_non_tensor_values Test preparing state dict non-tensor values state_dict = weight torch randn bias torch randn config lr momentum step device = torch device cpu meta tensors = _prepare_state_dict state_dict device Check metadata - actual number paths depends how pytree flattens dict The nested config dict might flattened differently assertEqual len meta non_tensor_leaves len meta paths assertEqual len tensors Check non-tensor values preserved non_tensor_values = leaf leaf meta non_tensor_leaves isinstance leaf _TensorMeta assertEqual len non_tensor_values config step TestPGTransportMocked TestCase setUp device = torch device cpu pg = MagicMock timeout = timedelta seconds= Mock Work object mock_work = MagicMock mock_work wait = MagicMock Setup process group mock mock_work pg send = MagicMock return_value=self mock_work pg recv = MagicMock return_value=self mock_work test_send_checkpoint_basic Test basic send_checkpoint functionality mocked process group transport = PGTransport pg timeout device state_dict = weight torch randn bias torch randn dst_ranks = transport send_checkpoint dst_ranks state_dict Check send called correct parameters First metadata length then metadata then each tensor expected_calls = len dst_ranks + len state_dict assertEqual pg send call_count expected_calls Check wait called all work objects assertEqual mock_work wait call_count expected_calls test_recv_checkpoint_basic Test basic recv_checkpoint functionality mocked process group Setup mock pickle loads valid _StateDictMeta patch pickle loads mock_loads Create mock state dict metadata torch utils _pytree tree_flatten_with_path state_dict = weight torch randn bias torch randn leaves treespec = tree_flatten_with_path state_dict paths = path path _ leaves Create mock tensor metadata tensor_metas = _ v leaves tensor_metas append _TensorMeta shape=v shape dtype=v dtype storage_offset=v storage_offset stride=v stride nbytes=v untyped_storage nbytes mock_meta = _StateDictMeta treespec=treespec paths=paths non_tensor_leaves=tensor_metas mock_loads return_value = mock_meta Setup len_t buf tensors mock recv side_effect tensor_list args kwargs tensor_list numel == This len_t tensor_list fill_ Some arbitrary length mock_work pg recv side_effect = side_effect Create transport call recv_checkpoint transport = PGTransport pg timeout device transport recv_checkpoint src_rank= Check recv called assertGreaterEqual pg recv call_count At least len_t buf Check wait called assertGreaterEqual mock_work wait call_count test_send_checkpoint_empty_state_dict Test send_checkpoint empty state dict transport = PGTransport pg timeout device state_dict = dst_ranks = transport send_checkpoint dst_ranks state_dict Check send called only metadata assertEqual pg send call_count len_t buf_t Check wait called assertEqual mock_work wait call_count test_send_checkpoint_with_non_tensor_values Test send_checkpoint non-tensor values state dict transport = PGTransport pg timeout device state_dict = weight torch randn config lr dst_ranks = transport send_checkpoint dst_ranks state_dict Check send called metadata one tensor assertEqual pg send call_count len_t buf_t one tensor Check wait called assertEqual mock_work wait call_count test_recv_checkpoint_with_state_dict_callback Test recv_checkpoint state_dict callback Setup mock pickle loads valid _StateDictMeta patch pickle loads mock_loads Create mock state dict metadata torch utils _pytree tree_flatten_with_path state_dict = weight torch randn bias torch randn leaves treespec = tree_flatten_with_path state_dict paths = path path _ leaves Create mock tensor metadata tensor_metas = _ v leaves tensor_metas append _TensorMeta shape=v shape dtype=v dtype storage_offset=v storage_offset stride=v stride nbytes=v untyped_storage nbytes mock_meta = _StateDictMeta treespec=treespec paths=paths non_tensor_leaves=tensor_metas mock_loads return_value = mock_meta Setup len_t buf tensors mock recv side_effect tensor_list args kwargs tensor_list numel == This len_t tensor_list fill_ Some arbitrary length mock_work pg recv side_effect = side_effect Create state_dict callback callback_state_dict = weight torch randn bias torch randn state_dict_callback = MagicMock return_value=callback_state_dict Create transport state_dict callback call recv_checkpoint transport = PGTransport pg timeout device state_dict=state_dict_callback transport recv_checkpoint src_rank= Check state_dict callback called state_dict_callback assert_called_once TestPGTransportEdgeCases TestCase setUp device = torch device cpu pg = MagicMock timeout = timedelta seconds= Mock Work object mock_work = MagicMock mock_work wait = MagicMock Setup process group mock mock_work pg send = MagicMock return_value=self mock_work pg recv = MagicMock return_value=self mock_work unittest skipIf HAS_ACCELERATOR No accelerator test_send_checkpoint_with_cpu_tensors Test send_checkpoint CPU tensors when device accelerator device = torch device f device_type Create state dict CPU tensors state_dict = cpu_tensor torch randn cpu_tensor torch randn Create transport accelerator device transport = PGTransport pg timeout device Call send_checkpoint transport send_checkpoint state_dict Check send called assertGreaterEqual pg send call_count len_t buf_t tensors Check wait called assertGreaterEqual mock_work wait call_count __name__ == __main__ run_tests