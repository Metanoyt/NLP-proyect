mypy allow-untyped-defs torch torch distributed dist torch distributed _shard sharded_tensor ShardedTensor torch distributed _shard sharded_tensor _ops _common _sharded_op_common torch distributed _shard sharding_spec ChunkShardingSpec torch distributed _shard sharding_spec _internals get_chunk_sharding_params get_chunked_dim_size get_split_size torch distributed _shard sharding_spec api custom_sharding_spec_op torch distributed nn functional _all_gather_base all_reduce all_to_all_single _chunk_sharding_spec_check spec op For given op implementation check sharding spec ChunkShardingSpec isinstance spec ChunkShardingSpec raise NotImplementedError f Only ChunkShardingSpec supported op __name__ _register_sharded_op_on_local_tensor op early_stop_func=None extra_check=None customized_func=None Handles ` ` __torch_function__ ` ` dispatch ops which performed single local tensor sharded tensor such op like ` ` torch nn functional softmax ` ` ` ` torch Tensor view ` ` For more complicated ops customized func can used generate new local tensor sharding spec sharded tensor size Args op The op registered applied all shards st early_stop_func Callable optional func early stop Default ` ` None ` ` no early stop extra_check Callable optional func extra condition check Default ` ` None ` ` no extra check customized_func Callable optional func customized logic generate new local tensor sharding spec sharded tensor size Default ` ` None ` ` we simply lower real op call single local tensor st Return func Callable registered implementation sharded op ` ` __torch_function__ ` ` dispatch custom_sharding_spec_op ChunkShardingSpec op _sharded_op_common op early_stop_func extra_check sharded_tensor_op_on_local_tensor types args= kwargs=None pg=None pyrefly ignore index-error st = args sharding_spec = st sharding_spec len st local_shards = raise TypeError f torch function op __name__ args args f kwargs kwargs only supported single local tensor st_size = st size customized_func local_tensor sharding_spec st_size = customized_func args kwargs pg args = st local_tensor args local_tensor = op args kwargs ShardedTensor _init_from_local_tensor local_tensor contiguous sharding_spec st_size type ignore arg-type process_group=pg init_rrefs=st _init_rrefs _handle_col_wise_sharding_base op_func col_dim input world_size weight local_shard pg gathered_inputs mode=None gathered_per_sample_weights=None gathered_offsets=None padding_idx=None For col-wise sharding weight lots logic common So we extract common logic put function Step To get input each rank Step To perform op concatenated tensor Step To distribute results each rank col rearrangement Step To concatenate all results all ranks Args op_func operator which applied input tensor col_dim dim result tensor after operation input tensor applied op world_size number ranks weight sharded weight tensor local_shard col-wise sharded weight tensor pg process group gathered_inputs list inputs all ranks If specified we don t need communicate each rank any more mode aggregation mode EmbeddingBag gathered_per_sample_weights per_sample_weights across all ranks gathered_offsets offsets across all ranks padding_idx If specified entries padding_idx do contribute gradient therefore embedding vector padding_idx updated during training i e remains fixed pad Note embedding vector padding_idx excluded reduction Return final result input being applied op run operator s function all inputs results = i inp enumerate gathered_inputs op_func torch nn functional embedding_bag result = op_func inp local_shard offsets=gathered_offsets i gathered_offsets None None mode=mode per_sample_weights=gathered_per_sample_weights i gathered_per_sample_weights None None padding_idx=padding_idx op_func torch nn functional embedding result = op_func inp local_shard padding_idx=padding_idx result = op_func inp local_shard results append torch transpose result col_dim Distribute results each rank col rearrangement output = _result_distribute_with_col_rearrange results input world_size weight pg transpose output result torch transpose output col_dim _result_distribute_with_col_rearrange results input world_size weight pg For col-wise sharding weight we need distribute results each rank We do them function Note index Sharding Spec equal rank number we need do rearrangement based order given Sharding Spec placement Args results results ops applied inputs all ranks We need distribute them back their original ranks input tensor applied op world_size number ranks weight sharded weight tensor pg process group Return column rearranged result Process results outputs all all sharding_dim = weight _sharding_spec dim sharding_dim_size = weight size sharding_dim dims = list results size dims = sharding_dim_size combined_results = torch cat results output = torch empty dims device=combined_results device dtype=combined_results dtype Compute output splits split_size = get_split_size sharding_dim_size world_size output_split_sizes = world_size idx placement enumerate weight _sharding_spec placements output_split_sizes placement rank = get_chunked_dim_size sharding_dim_size split_size idx distribute outputs using all all output = all_to_all_single output combined_results output_split_sizes=output_split_sizes group=pg Check we need rearrange columns appropriately output rearrange_columns = any idx = placement rank idx placement enumerate weight _sharding_spec placements rearrange_columns output indices = placement weight _sharding_spec placements dim_size = output_split_sizes placement rank start = sum split_size i placement rank i split_size enumerate output_split_sizes indices += list range start start + dim_size output index_select torch tensor indices device=output device _handle_max_norm_col_wise max_norm norm_type local_shard input world_size gathered_inputs pg For col-wise sharding weight we need aggregate norm across all ranks before we can perform proper re-norm Note max_norm logic only applied embedding indices looked up whole shard Args max_norm If given each embedding vector norm larger than max_norm renormalized have norm max_norm Note will modify weight in-place norm_type The p p-norm compute max_norm option local_shard col-wise shared local weight used lookup input tensor applied op world_size number ranks gathered_inputs list inputs all ranks pg process group Return local_shard_norm_renormed local_shard re-normed max_norm norm larger than norm_type = norm_type norm_type None unique_inp = torch unique torch cat gathered_inputs local_shard_sum = torch sum torch pow torch abs local_shard norm_type dim= dtype=local_shard dtype For col-wise sharding we need first aggregate powered sum each rank first then calculate norm local_shard_sum = all_reduce local_shard_sum group=pg local_shard_norm = torch pow local_shard_sum norm_type max_norm_tensor = torch full local_shard size float inf dtype=local_shard dtype device=input device max_norm_tensor unique_inp = max_norm local_shard_t = local_shard t contiguous normalized_tensor = torch where local_shard_norm max_norm_tensor max_norm_tensor local_shard_norm Make sure divisor zero local_shard_norm local_shard_norm == = local_shard_norm_renormed = torch div torch mul local_shard_t normalized_tensor local_shard_norm t contiguous local_shard_norm_renormed _all_gather_base_input input pg Use _all_gather_base get concatenated input each rank Args input tensor applied op pg process group Returns gathered_inputs input gathered each rank concat dim allgather inputs first gather_inp_size = list input size gather_inp_size = input size dist get_world_size pg gather_inp = torch empty gather_inp_size device=input device dtype=input dtype _all_gather_base gather_inp input group=pg _handle_row_wise_mask gather_inp padding_idx weight world_size rank Mask input embedding look-up IDs which stored current rank This function also adjust ` ` padding_idx ` ` so only used rank where corresponding row stored Note ` ` max_norm ` ` flag only weights rows being looked up will re-normed So we need extra row masked ID so does affect final result ` ` max_norm ` ` Args gather_inp tensor applied op gathered all ranks padding_idx If specified entries padding_idx do contribute gradient therefore embedding vector padding_idx updated during training i e remains fixed pad Note embedding vector padding_idx excluded reduction weight weight tensor Embedding look-up table world_size number ranks rank cuda process Returns lookup_input Tensor masked input padding_idx adjusted padding_idx padding_row The extra row we used during lookup so looking up does affect ` ` max_norm ` ` start_pos chunk_size = get_chunk_sharding_params weight size world_size weight _sharding_spec rank mask = gather_inp start_pos &#124; gather_inp = start_pos + chunk_size lookup_input = gather_inp clone - start_pos lookup_input mask = chunk_size padding_idx None padding_idx = start_pos padding_idx start_pos + chunk_size padding_idx = padding_idx - start_pos padding_idx = None When max_norm set will only re-norm row being looked up padding_row = torch zeros weight size device=gather_inp device dtype=weight dtype lookup_input padding_idx padding_row