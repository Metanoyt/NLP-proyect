mypy allow-untyped-defs collections functools inspect textwrap types warnings torch torch _jit_internal _jit_internal torch _sources fake_range torch jit _builtins _find_builtin torch jit _check AttributeTypeIsSupportedChecker torch jit _state _add_script_class _get_script_class _python_cu torch jit frontend get_class_properties get_default_args get_jit_class_def get_jit_def torch nn Module ScriptMethodStub = collections namedtuple ScriptMethodStub resolution_callback def_ original_method PropertyStub = collections namedtuple PropertyStub resolution_callback def_ TODO there should more principled way doing ignored_attributes = _version _parameters _buffers _non_persistent_buffers_set _backward_hooks _backward_pre_hooks _forward_hooks _forward_hooks_with_kwargs _forward_pre_hooks _forward_pre_hooks_with_kwargs _forward_hooks_always_called _state_dict_hooks _state_dict_pre_hooks _load_state_dict_pre_hooks _load_state_dict_post_hooks _modules _initializing dump_patches _compile_and_register_class obj rcb qualified_name script_class = _get_script_class obj script_class ast = get_jit_class_def obj obj __name__ defaults = torch jit frontend get_default_args_for_class obj script_class = torch _C _jit_script_class_compile qualified_name ast defaults rcb _add_script_class obj script_class script_class make_stub func name rcb = _jit_internal createResolutionCallbackFromClosure func ast = get_jit_def func name self_name= RecursiveScriptModule ScriptMethodStub rcb ast func make_stub_from_method nn_module method_name func = getattr nn_module method_name isinstance func ScriptMethodStub func Make sure name present resulting AST will match name requested here The only time they don t match you do something like _forward pass forward = _forward In case actual function object will have name ` _forward ` even though we requested stub ` forward ` make_stub func method_name make_stubs_from_exported_methods mod stubs = name dir mod item = getattr mod name None _jit_internal get_torchscript_modifier item _jit_internal FunctionModifiers EXPORT stubs append make_stub_from_method mod name stubs jit_ignored_properties module user_annotated_ignored_attributes = getattr module __jit_ignored_attributes__ get_properties_names module k k v vars module items isinstance v property properties = get_properties_names type module user_annoted_ignored_properties = set ignored_attr user_annotated_ignored_attributes ignored_attr properties user_annoted_ignored_properties add ignored_attr user_annoted_ignored_properties base types can constants addition tuples lists these base types also considered constants If you edit list then you also need edit handlers ConstantValue jit script init cpp _constant_types = bool float int str type None torch device torch layout torch dtype torch qscheme _get_valid_constant attr v owner_type isinstance v _constant_types v isinstance v tuple list tuple _get_valid_constant attr x owner_type x v constants = join torch typename typ typ _constant_types raise TypeError textwrap dedent f torch typename type v object attribute owner_type attr valid constant Valid constants nn ModuleList value type constants list tuple SourceContext torch _C _jit_tree_views SourceRangeFactory __init__ source filename file_lineno leading_whitespace_len super __init__ source filename file_lineno leading_whitespace_len get_annotations obj In Python- + recommended use inspect get_annotations See https docs python org howto annotations html But also annotations base inherited unannotated derived one so they must manually extracted annotations = inspect get_annotations obj annotations annotations get_cls_annotations cls cls_annotations = inspect get_annotations cls cls_annotations cls_annotations base cls __bases__ cls_annotations = get_cls_annotations base cls_annotations cls_annotations cls = obj isinstance obj type type obj get_cls_annotations cls infer_concrete_type_builder nn_module share_types=True Build ConcreteModuleTypeBuilder nn Module This ConcreteModuleType doesn t have JIT type associated yet must filled caller concrete_type_builder = torch _C ConcreteModuleTypeBuilder type nn_module isinstance nn_module torch nn ModuleDict concrete_type_builder set_module_dict isinstance nn_module torch nn ModuleList torch nn Sequential concrete_type_builder set_module_list isinstance nn_module torch nn ParameterList concrete_type_builder set_parameter_list isinstance nn_module torch nn ParameterDict concrete_type_builder set_parameter_dict class_annotations = get_annotations nn_module isinstance nn_module torch ao quantization QuantWrapper class_annotations = Get user-annotated ignored attributes user_annotated_ignored_attributes = getattr nn_module __jit_ignored_attributes__ concrete_type_builder add_ignored_attributes user_annotated_ignored_attributes ignored_properties = jit_ignored_properties nn_module try infer type type annotation object itself infer_type name item The forward function Module special never use annotations we need infer type directly using JIT I originally wanted write test isinstance class_annotations name Callable isinstance typing things doesn t seem work isinstance list Callable also true inferred = False try name class_annotations class_annotations name = torch nn Module __annotations__ forward ann_to_type = torch jit annotations ann_to_type class_annotations name fake_range attr_type = torch _C InferredType ann_to_type isinstance item torch jit Attribute ann_to_type = torch jit annotations ann_to_type item type fake_range attr_type = torch _C InferredType ann_to_type attr_type = torch _C _jit_try_infer_type item inferred = True except RuntimeError re raise RuntimeError f Error inferring type name item re re attr_type inferred added_names = set name item nn_module _parameters items name user_annotated_ignored_attributes continue assert item None isinstance item torch Tensor attr_type _ = infer_type name item We currently have invariant various places our code parameters must Tensors However nn Module API also allows NoneType parameters These parameters returned part ` parameters ` its variants available through direct attribute access concrete_type_builder add_attribute name attr_type type True False added_names add name name item nn_module _buffers items name user_annotated_ignored_attributes continue assert item None isinstance item torch Tensor attr_type _ = infer_type name item concrete_type_builder add_attribute name attr_type type False True added_names add name name item nn_module _modules items name user_annotated_ignored_attributes continue attr_type _ = infer_type name item item None Modules can None We don t have direct support optional Modules so register NoneType attribute instead concrete_type_builder add_attribute name attr_type type False False continue attr_type success assert attr_type type is_interface_type type can inferred should module interface type sub_concrete_type = torch _C ConcreteModuleType from_jit_type attr_type type otherwise we get concrete module type item add concrete_type sub_concrete_type = get_module_concrete_type item share_types concrete_type_builder add_module name sub_concrete_type added_names add name populate constants_set constants_set = set getattr nn_module __constants__ Constants annotated via ` Final T ` rather than being added ` __constants__ ` name ann class_annotations items torch _jit_internal is_final ann constants_set add name name constants_set name added_names TODO We should really error case its bc-breaking so we need warn least one release name nn_module _modules hint = submodule name nn_module _buffers hint = buffer name nn_module _parameters hint = parameter raise AssertionError added_names must submodule parameter buffer warnings warn f name found ScriptModule constants f non-constant hint Consider removing stacklevel= continue hasattr nn_module name TODO We should really error case its bc-breaking so we need warn least one release warnings warn f name found ScriptModule constants actually set __init__ Consider removing stacklevel= continue value = getattr nn_module name concrete_type_builder add_constant name _get_valid_constant name value type nn_module __name__ added_names add name populate overloads overloads = getattr nn_module __overloads__ update any annotated overloads overloads update get_overload_name_mapping get_overload_annotations nn_module ignored_properties name overloaded_names overloads items concrete_type_builder add_overload name overloaded_names name value nn_module __dict__ items name ignored_attributes name startswith __ Python objects have lots random attributes attached them PyTorch adds few more Prevent these getting compiled continue name user_annotated_ignored_attributes continue name added_names Don t re-add anything we already added continue isoverloadpacket = isinstance value torch _ops OpOverloadPacket isoverloadpacket value = value op Handle Python function attributes inspect isfunction value try scripted_fn = torch jit script value concrete_type_builder add_function_attribute name torch _C _jit_try_infer_type scripted_fn type value except Exception e If we fail script function isn t hard error Instead we will add list attributes we failed convert compilation error hint = This function exists attribute Python module we failed compile TorchScript function f \nThe error stack reproduced here \n e concrete_type_builder add_failed_attribute name hint continue Handle calls builtin functions either bespoke builtins torch jit _builtins call aten function like torch add builtin_symbol_name = _find_builtin value builtin_symbol_name concrete_type_builder add_builtin_function name builtin_symbol_name continue Handle Script function attributes isinstance value torch jit ScriptFunction concrete_type_builder add_function_attribute name torch _C _jit_try_infer_type value type value continue If we got here regular data attribute add concrete type attr_type inferred = infer_type name value attr_type success concrete_type_builder add_attribute name attr_type type False False TODO could add more detail here For example what user should do when pytype ` list ` ` NoneType ` inferred_msg = Its type inferred try adding type annotation attribute inferred additional_info = f attr_type reason inferred_msg hint = This attribute exists Python module f we failed convert Python type torch typename type value f TorchScript type additional_info concrete_type_builder add_failed_attribute name hint add hooks concrete type hook nn_module _forward_hooks values concrete_type_builder add_forward_hook hook pre_hook nn_module _forward_pre_hooks values concrete_type_builder add_forward_pre_hook pre_hook concrete_type_builder ConcreteTypeStore type_store dict type Module list torch _C ConcreteModuleType methods_compiled set torch _C ConcreteModuleType __init__ - None Python module type = List ConcreteModuleType type_store = ConcreteTypes have had their methods already compiled methods_compiled = set get_or_create_concrete_type nn_module Infer ConcreteType ` nn Module ` instance Underlying JIT types reused possible concrete_type_builder = infer_concrete_type_builder nn_module nn_module_type = type nn_module nn_module_type type_store type_store nn_module_type = Search type store already-available JIT type known_types = type_store nn_module_type known_type known_types known_type equals concrete_type_builder known_type We didn t find anything generate new JIT type concrete type concrete_type = concrete_type_builder build type_store nn_module_type append concrete_type concrete_type concrete_type_store = ConcreteTypeStore create_methods_and_properties_from_stubs concrete_type method_stubs property_stubs method_defs = m def_ m method_stubs method_rcbs = m resolution_callback m method_stubs method_defaults = get_default_args m original_method m method_stubs property_defs = p def_ p property_stubs property_rcbs = p resolution_callback p property_stubs concrete_type _create_methods_and_properties property_defs property_rcbs method_defs method_rcbs method_defaults create_hooks_from_stubs concrete_type hook_stubs pre_hook_stubs hook_defs = h def_ h hook_stubs hook_rcbs = h resolution_callback h hook_stubs pre_hook_defs = h def_ h pre_hook_stubs pre_hook_rcbs = h resolution_callback h pre_hook_stubs concrete_type _create_hooks hook_defs hook_rcbs pre_hook_defs pre_hook_rcbs get_module_concrete_type nn_module share_types=True Get concrete type nn_modules If share_types True concrete type fetched concrete_type_store If False new concrete type created without first searching concrete_type_store Args nn_module The original Python nn Module we creating ScriptModule share_types = Whether share underlying JIT types between modules possible Returns A concrete type nn_module assert isinstance nn_module Module isinstance nn_module torch jit ScriptModule hasattr nn_module _concrete_type nn_module _concrete_type share_types Look into store cached JIT types concrete_type = concrete_type_store get_or_create_concrete_type nn_module Get concrete type directly without trying reuse existing JIT type type store concrete_type_builder = infer_concrete_type_builder nn_module share_types concrete_type_builder set_poisoned concrete_type = concrete_type_builder build concrete_type create_script_class obj Create RecursiveScriptClass instance Python object Arguments obj A Python object qualified_class_name = _jit_internal _qualified_name type obj rcb = _jit_internal createResolutionCallbackForClassMethods type obj Script type obj hasn t already been scripted _compile_and_register_class type obj rcb qualified_class_name class_ty = _python_cu get_class qualified_class_name Create empty torch _C ScriptObject scripted type cpp_object = torch _C _create_object_with_type class_ty Copy all attributes over torch _C ScriptObject name value obj __dict__ items cpp_object setattr name value Wrap torch _C ScriptObject RecursiveScriptClass instance wrap_cpp_class cpp_object create_script_module nn_module stubs_fn share_types=True is_tracing=False Create new ScriptModule nn Module Args nn_module The original Python nn Module we creating ScriptModule stubs_fn Lambda takes nn Module generates list ScriptMethodStubs compile share_types Whether share underlying JIT types between modules possible NOTE Only set False when we cannot guarantee type sharing will work correctly This only happens today traced modules where same module can produce different traced methods depending inputs is_tracing Whether function called during tracing scripting If tracing we don t need do AttributeTypeIsSupportedChecker because all unsupported attributes will baked constant tracing graph In addition check significantly slows down traced modules when module size big assert isinstance nn_module torch jit RecursiveScriptModule check_module_initialized nn_module concrete_type = get_module_concrete_type nn_module share_types is_tracing AttributeTypeIsSupportedChecker check nn_module create_script_module_impl nn_module concrete_type stubs_fn create_script_module_impl nn_module concrete_type stubs_fn Convert nn Module RecursiveScriptModule Args nn_module The original Python nn Module we creating ScriptModule concrete_type The fully initialized ConcreteType module stubs_fn Lambda takes nn Module generates list ScriptMethodStubs compile cpp_module = torch _C _create_module_with_type concrete_type jit_type method_stubs = stubs_fn nn_module property_stubs = get_property_stubs nn_module hook_stubs pre_hook_stubs = get_hook_stubs nn_module ignored_properties = jit_ignored_properties nn_module init_fn script_module Initialize ScriptModule Copy attributes parameters buffers original ` nn_module ` new ScriptModule name concrete_type get_attributes keys orig_value = getattr nn_module name orig_value = orig_value value isinstance orig_value torch jit Attribute orig_value cpp_module setattr name orig_value Copy submodules original ` nn_module ` new ScriptModule recursively scripting them name sub_concrete_type concrete_type get_modules orig_value = getattr nn_module name assert isinstance orig_value Module f Expected Module got type orig_value module_type = sub_concrete_type jit_type isinstance module_type torch _C InterfaceType use interface inference rule compile module scripted = interface_script module_type orig_value isinstance orig_value torch jit ScriptModule scripted = orig_value always reuse provided stubs_fn infer methods compile scripted = create_script_module_impl orig_value sub_concrete_type stubs_fn cpp_module setattr name scripted script_module _modules name = scripted Copy ignored unused methods attrs original ` nn_module ` new ScriptModule This ensures we can access these Python methods ScriptModule name dir nn_module name ignored_properties continue item = getattr nn_module name None inspect ismethod item _jit_internal is_ignored_fn item unbound_function = getattr nn_module name __func__ bound_method = unbound_function __get__ script_module setattr script_module name bound_method concrete_type is_ignored_attribute name setattr script_module name item For convenience attach concrete type new ScriptModule script_module _concrete_type = concrete_type Actually create ScriptModule initializing function we just defined script_module = torch jit RecursiveScriptModule _construct cpp_module init_fn Compile methods necessary concrete_type concrete_type_store methods_compiled create_methods_and_properties_from_stubs concrete_type method_stubs property_stubs Create hooks after methods ensure no name collisions between hooks methods If done before hooks can overshadow methods aren t exported create_hooks_from_stubs concrete_type hook_stubs pre_hook_stubs torch _C _run_emit_module_hook cpp_module concrete_type_store methods_compiled add concrete_type Copy forward hooks pre-hooks new ScriptModule allow hooks run eager ScriptFunctions idx fn enumerate script_module _c _get_forward_pre_hooks script_module _forward_pre_hooks idx = fn idx fn enumerate script_module _c _get_forward_hooks script_module _forward_hooks idx = fn Special handling so methods like __len__ work script methods classes derived containers isinstance nn_module torch nn ModuleList torch nn Sequential torch nn ModuleDict __len__ cpp_module _method_names script_module define f __len__ \n len nn_module \n isinstance nn_module torch nn ModuleDict __contains__ cpp_module _method_names len nn_module keys keys = repr list nn_module keys script_module define f __contains__ key str \n key keys \n script_module define __contains__ key str \n False\n Make compiled methods available Python ScriptModule method_stub method_stubs method_stub original_method None define d methods don t have Python original_method so we don t need do any Python re-wrapping stuff continue name = method_stub original_method __name__ name = method_stub def_ name name TODO Why skip Because torch jit _overload_method will mangle name function continue script_method = cpp_module _get_method name Wrap original propagate docstrings such TODO we don t currently do functions recursively compiled we should wrapped_script_method = functools wraps method_stub original_method script_method Add methods script_module directly This ensures they will found first when ` name ` looked up opposed stubs nn Module forward script_module __dict__ name = wrapped_script_method Make module properties available Python ScriptModule property_stub property_stubs property_name = property_stub def_ name name fget = cpp_module _get_method property_stub def_ getter_name name Setter optional so may exist setter_name = property_stub def_ setter_name fset = cpp_module _get_method setter_name name setter_name None script_module __dict__ property_name = property property_name fget fset type ignore arg-type copy over python methods script module they aren t defined script module currently internal api used only module containers name dir nn_module name ignored_properties continue item = getattr nn_module name None _jit_internal get_torchscript_modifier item _jit_internal FunctionModifiers COPY_TO_SCRIPT_WRAPPER add_python_attr_to_scripted_model script_module nn_module name script_module We define shims certain attributes RecursiveScriptModule support magic methods To check script model defines attribute we need also check attribute shim script_model_defines_attr script_model attr script_attr = getattr script_model attr None script_attr None False default_attr = getattr torch jit RecursiveScriptModule attr None default_attr None False script_attr = default_attr add_python_attr_to_scripted_model script_model orig attr hasattr orig attr script_model_defines_attr script_model attr setattr script_model attr getattr orig attr get_overload_annotations mod jit_ignored_properties original function = mangled overload name overload function overloads = name dir type mod name jit_ignored_properties continue item = getattr mod name None callable item continue builtin functions like repr python do have __module__ defined hasattr item __module__ item __module__ None method_overloads = _jit_internal _get_overloaded_methods item mod __class__ method_overloads None continue pyrefly ignore missing-attribute item __func__ method_overloads raise RuntimeError _jit_internal get_overload_no_implementation_error_message method item __func__ names = name + __ + str i i range len method_overloads overloads item = list zip names method_overloads overloads get_overload_name_mapping overload_info Same format __overloads__ original function = overload names overload_name_mappings dict str list str = orig_fn overloads overload_info items original_name = orig_fn __name__ original_name overload_name_mappings overload_name_mappings original_name = overload_name _ overloads overload_name_mappings original_name append overload_name overload_name_mappings _check_no_signature func signature = torch jit annotations get_signature func None fake_range inspect ismethod func signature None qual_name = _jit_internal _qualified_name func raise RuntimeError f Must explicitly add type annotations overloaded functions qual_name make_stubs_for_overloads overload_info overload_stubs = orig_fn overloads overload_info items orig_ast = get_jit_def orig_fn orig_fn __name__ self_name= RecursiveScriptModule overload_name overload_fn overloads _check_no_signature overload_fn over_ast = get_jit_def overload_fn overload_fn __name__ self_name= RecursiveScriptModule new_ast = torch _C _replace_overloaded_method_decl over_ast decl orig_ast overload_name _rcb = _jit_internal createResolutionCallbackFromClosure orig_fn overload_stubs append ScriptMethodStub _rcb new_ast overload_fn overload_stubs check_module_initialized mod assert isinstance mod torch nn Module hasattr mod _parameters raise RuntimeError f torch typename type mod has been initialized did you forget call super This avoid importing torch distributed nn hasattr mod remote_parameters name param mod _parameters items param None torch nn parameter is_lazy param raise RuntimeError f torch typename type mod has uninitialized parameters name Did you forget run forward pass name buf mod _buffers items buf None torch nn parameter is_lazy buf raise RuntimeError f torch typename type mod has uninitialized buffers name Did you forget run forward pass infer_methods_to_compile nn_module Implement default rules which methods should act starting points compilation TODO add link when rules published check_module_initialized nn_module ignored_properties = jit_ignored_properties nn_module methods list str = hasattr nn_module forward _jit_internal is_ignored_fn nn_module forward forward_func = getattr nn_module forward __func__ None module_forward = getattr torch nn Module forward None forward_func = module_forward methods = forward exported = name dir nn_module name ignored_properties continue item = getattr nn_module name None _jit_internal get_torchscript_modifier item _jit_internal FunctionModifiers EXPORT exported append name methods = methods + exported overload_name_mappings = dict getattr nn_module __overloads__ overload_info = get_overload_annotations nn_module ignored_properties overload_name_mappings update get_overload_name_mapping overload_info overload_stubs = make_stubs_for_overloads overload_info nn_module __overloads__ = overload_name_mappings we shouldn t directly compile overloaded methods just its overloads ignore_overloaded method_name method_name overload_name_mappings filtered_methods = filter ignore_overloaded methods Unique methods We don t want use set store methods because introduces non-determinism compile order uniquer set str = set uniqued_methods = name filtered_methods name uniquer continue uniqued_methods append name uniquer add name stubs = make_stub_from_method nn_module method method uniqued_methods overload_stubs + stubs get_hook_stubs nn_module Return forward hook pre_hook ScriptModuleStubs check_module_initialized nn_module hook_map dict = hook_stubs = hook nn_module _forward_hooks values hook __name__ hook_map id hook = id hook_map hook __name__ raise RuntimeError f Hook hook __name__ type nn_module __name__ has least two different python definitions Please use unique names all hooks hook_map hook __name__ = hook hook_stubs append make_stub hook hook __name__ pre_hook_stubs = pre_hook nn_module _forward_pre_hooks values pre_hook __name__ hook_map id pre_hook = id hook_map pre_hook __name__ raise RuntimeError f Pre-hook pre_hook __name__ type nn_module __name__ has least two different python definitions Please use unique names all hooks hook_map pre_hook __name__ = pre_hook pre_hook_stubs append make_stub pre_hook pre_hook __name__ hook_stubs pre_hook_stubs get_property_stubs nn_module Create property stubs properties module creating method stubs getter setter module_ty = type nn_module properties_asts = get_class_properties module_ty self_name= RecursiveScriptModule rcbs = name dir module_ty item = getattr module_ty name None isinstance item property item fget raise RuntimeError f Property name nn_module __name__ must have getter rcbs name = _jit_internal createResolutionCallbackFromClosure item fget stubs = PropertyStub rcbs ast name name ast ast properties_asts stubs interface_script mod_interface nn_module Make ScriptModule nn Module using interface methods rule determining which methods compile Args mod_interface interface type module have nn_module The original Python nn Module we creating ScriptModule isinstance nn_module torch jit ScriptModule nn_module check_module_initialized nn_module infer_interface_methods_to_compile nn_module Rule infer methods interface type It used know which methods need act starting points compilation stubs = make_stub_from_method nn_module method method mod_interface getMethodNames stubs create_script_module nn_module infer_interface_methods_to_compile try_compile_fn fn loc _jit_internal is_ignored_fn fn Don t do anything ignore d functions None isinstance fn torch nn Module Since modules callable pybind recognizes them functions don t do anything them None inspect isfunction fn inspect ismethod fn raise RuntimeError f ` fn ` function Recursive scripting only supports Python functions methods currently \n f Consider manually annotating ` fn ` torch jit script The object returned __prepare_scriptable__ might have different closure Resolve here get right resolution callback fn = fn __prepare_scriptable__ hasattr fn __prepare_scriptable__ fn type ignore operator We don t have actual scope where function defined we can extract necessary info closed over variables function object rcb = _jit_internal createResolutionCallbackFromClosure fn torch jit script fn _rcb=rcb wrap_cpp_class cpp_class Wrap torch _C Object Python RecursiveScriptClass torch jit RecursiveScriptClass cpp_class wrap_cpp_module cpp_module Wrap torch _C ScriptModule Python ScriptModule recursively all submodules init_fn script_module name cpp_module torch _C ModuleDict script_module _c items setattr script_module name wrap_cpp_module cpp_module script_module _concrete_type = torch _C ConcreteModuleType from_jit_type script_module _c _type idx fn enumerate script_module _c _get_forward_pre_hooks script_module _forward_pre_hooks idx = fn idx fn enumerate script_module _c _get_forward_hooks script_module _forward_hooks idx = fn torch jit RecursiveScriptModule _construct cpp_module init_fn compile_unbound_method concrete_type fn _jit_internal is_ignored_fn fn None stub = make_stub fn fn __name__ torch _jit_internal _disable_emit_hooks We don t want call hooks here since graph calling function yet complete create_methods_and_properties_from_stubs concrete_type stub stub lazy_bind concrete_type unbound_method Return function lazily binds ` unbound_method ` provided Module IValue then invokes method We do so any Python shenanigans will poison type sharing impossible compile time lazy_binding_method cpp_module args init_fn script_module orig_class = concrete_type py_class Copy ignored unused methods original module new one This ensures they available during execution name dir orig_class item = getattr orig_class name None _jit_internal is_ignored_fn item setattr script_module name item Copy constants over so they available during execution name value concrete_type get_constants items setattr script_module name value script_module = torch jit RecursiveScriptModule _construct cpp_module init_fn method = types MethodType unbound_method script_module method args make lazy binding method look like original method lazy_binding_method original_fn = unbound_method type ignore attr-defined lazy_binding_method __name__ = unbound_method __name__ torch _jit_internal copy_torchscript_modifier unbound_method lazy_binding_method lazy_binding_method