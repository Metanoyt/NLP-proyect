Owner s oncall distributed copy functools contextlib nullcontext typing Optional torch torch nn nn torch distributed device_mesh DeviceMesh init_device_mesh torch distributed fsdp CPUOffloadPolicy fully_shard torch distributed tensor distribute_tensor DTensor Shard torch distributed tensor parallel ColwiseParallel parallelize_module RowwiseParallel torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp FSDPTest FSDPTestMultiThread get_devtype MLP torch testing _internal common_utils run_tests torch testing _internal distributed _tensor common_dtensor ModelArgs Transformer TransformerBlock device_type = torch device get_devtype TestFullyShardStateDictMultiProcess FSDPTest property world_size - int min torch get_device_module device_type device_count skip_if_lt_x_gpu test_dp_state_dict_save_load fsdp_mesh = init_device_mesh device_type type world_size run_subtests mlp_dim mesh fsdp_mesh _test_dp_state_dict_save_load world_size == TODO remove evenness check when FSDP supports uneven sharding see https github com pytorch pytorch blob cbb e ddf f b f bbf f torch distributed fsdp _fully_shard _fsdp_param py#L -L noqa B run_subtests mlp_dim mesh fsdp_mesh use_shard_placement_fn True _test_dp_state_dict_save_load world_size = hsdp_mesh = init_device_mesh device_type type world_size mesh_dim_names= dp_replicate dp_shard run_subtests mlp_dim mesh hsdp_mesh _test_dp_state_dict_save_load run_subtests mlp_dim mesh hsdp_mesh use_shard_placement_fn True _test_dp_state_dict_save_load _test_dp_state_dict_save_load mlp_dim int mesh DeviceMesh use_shard_placement_fn bool = False torch manual_seed base_model = nn Sequential MLP mlp_dim nn Sequential MLP mlp_dim nn Linear mlp_dim mlp_dim MLP mlp_dim _shard_placement_fn param nn Parameter - Optional Shard largest_dim = largest_dim_size = - dim dim_size enumerate param shape dim_size largest_dim_size largest_dim = dim largest_dim_size = dim_size Shard largest_dim shard_placement_fn = _shard_placement_fn use_shard_placement_fn None fully_shard_fn = functools partial fully_shard mesh=mesh shard_placement_fn=shard_placement_fn Check basic ` reshard_after_forward=True ` model = copy deepcopy base_model module model fully_shard_fn module fully_shard_fn model _test_state_dict_save_load model Check ` reshard_after_forward=False ` before after forward model = copy deepcopy base_model module model fully_shard_fn module reshard_after_forward=False fully_shard_fn model reshard_after_forward=False _test_state_dict_save_load model ref_sharded_sd = model state_dict inp = torch randn mlp_dim device=device_type type model inp parameters resharded after forward Check state dict hooks reshard sharded_sd = model state_dict assertEqual set ref_sharded_sd keys set sharded_sd keys key value ref_sharded_sd items assertEqual value sharded_sd key skip_if_lt_x_gpu test_cached_state_dict run_subtests mlp_dim mutate_after_state_dict True False _test_cached_state_dict _test_cached_state_dict mlp_dim int mutate_after_state_dict bool torch manual_seed model = nn Linear mlp_dim mlp_dim bias=False fully_shard model reshard_after_forward=True optim = torch optim AdamW model parameters lr= e- call state_dict once use ` sd ` directly reduce cpu overhead sd = model state_dict assert isinstance model weight DTensor mutate_after_state_dict assertTrue sd weight _local_tensor untyped_storage data_ptr == model weight _local_tensor untyped_storage data_ptr model = model cpu model = model cuda assertTrue sd weight _local_tensor untyped_storage data_ptr = model weight _local_tensor untyped_storage data_ptr torch manual_seed + rank inp = torch rand mlp_dim mlp_dim device= cuda _ range optim zero_grad loss = model inp sum loss backward optim step mutate_after_state_dict assertTrue sd weight _local_tensor untyped_storage data_ptr == model weight _local_tensor untyped_storage data_ptr skip_if_lt_x_gpu test_dp_state_dict_cpu_offload run_subtests offload_policy CPUOffloadPolicy pin_memory=True CPUOffloadPolicy pin_memory=False cpu_state_dict True False _test_dp_state_dict_cpu_offload _test_dp_state_dict_cpu_offload offload_policy CPUOffloadPolicy cpu_state_dict bool mlp_dim = torch manual_seed torch device meta model = nn Sequential nn Linear mlp_dim mlp_dim bias=False nn Linear mlp_dim mlp_dim bias=False module model fully_shard module offload_policy=offload_policy fully_shard model offload_policy=offload_policy split full sd into multiple pieces test loading ` strict=False ` state_dicts = name dtensor model named_parameters full_tensor = torch randn dtensor size sharded_tensor = distribute_tensor full_tensor dtensor device_mesh dtensor placements cpu_state_dict sharded_tensor = sharded_tensor cpu state_dicts append name sharded_tensor check we can load some parameters still meta device sd state_dicts model load_state_dict sd assign=True strict=False lazy init without error inp = torch rand mlp_dim mlp_dim device=device_type type context = assertRaisesRegex RuntimeError rf Found following parameters non-CPU device \ \ weight device\ type= device_type type cpu_state_dict nullcontext context model inp sum state_dict = model state_dict name dtensor state_dict items assertEqual dtensor device type cpu skip_if_lt_x_gpu test_ d_state_dict_correctness dp_size = global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp dp_mesh tp_mesh = global_mesh dp global_mesh tp torch manual_seed mlp_dim = model init model = nn Sequential MLP mlp_dim _ range model_ d = copy deepcopy model FSDP + TP model_ d = parallelize_module model_ d device_mesh=tp_mesh parallelize_plan= in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel mlp model_ d fully_shard mlp mesh=dp_mesh fully_shard model_ d mesh=dp_mesh state_dict parity check model_state_dict = model state_dict model_ d_state_dict = model_ d state_dict tensor dtensor zip model_state_dict values model_ d_state_dict values assertTrue isinstance dtensor DTensor assertEqual tensor dtensor full_tensor skip_if_lt_x_gpu test_dp_tp_state_dict_save_load dp_size = global_mesh = init_device_mesh device_type type dp_size world_size dp_size mesh_dim_names= dp tp run_subtests mlp_dim functools partial _test_dp_tp_state_dict_save_load global_mesh _test_dp_tp_state_dict_save_load global_mesh DeviceMesh mlp_dim int dp_mesh tp_mesh = global_mesh dp global_mesh tp torch manual_seed model = nn Sequential MLP mlp_dim _ range model = parallelize_module model device_mesh=tp_mesh parallelize_plan= in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel mlp model fully_shard mlp mesh=dp_mesh fully_shard model mesh=dp_mesh _test_state_dict_save_load model skip_if_lt_x_gpu test_hsdp_tp_state_dict_save_load global_mesh = init_device_mesh device_type type world_size mesh_dim_names= dp_replicate dp_shard tp run_subtests mlp_dim functools partial _test_hsdp_tp_state_dict_save_load global_mesh _test_hsdp_tp_state_dict_save_load global_mesh DeviceMesh mlp_dim int dp_mesh tp_mesh = global_mesh dp_replicate dp_shard global_mesh tp torch manual_seed model = nn Sequential MLP mlp_dim _ range model = parallelize_module model device_mesh=tp_mesh parallelize_plan= in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel in_proj ColwiseParallel out_proj RowwiseParallel mlp model fully_shard mlp mesh=dp_mesh fully_shard model mesh=dp_mesh _test_state_dict_save_load model _test_state_dict_save_load model nn Module param_name param model named_parameters assertIsInstance param DTensor f Expects parameters sharded DTensors got param_name f type param param old_fill_value = new_fill_value = + rank torch no_grad param model parameters param fill_ old_fill_value Use parameters currently sharded meaning their data pointers correspond sharded parameter data param_name_to_data_ptr = n p to_local data_ptr n p model named_parameters ref_sharded_sizes = p size p model parameters state_dict = model state_dict param ref_sharded_size zip model parameters ref_sharded_sizes assertEqual param size ref_sharded_size assertTrue isinstance param nn Parameter Verify keys match values DTensors values share same storage existing sharded parameter data assertEqual set state_dict keys set param_name_to_data_ptr keys param_name tensor state_dict items assertTrue isinstance tensor DTensor param_name_to_data_ptr param_name == Check padding added DTensor assertGreater rank assertEqual torch count_nonzero tensor to_local item assertEqual tensor to_local data_ptr param_name_to_data_ptr param_name Verify we can load new state dict contains DTensors storages different current model parameters new_state_dict dict str DTensor = param_name dtensor state_dict items Construct new DTensors exercise load state dict writeback new_state_dict param_name = dtensor detach clone fill_ new_fill_value param model parameters assertEqual param to_local torch ones_like param to_local old_fill_value model load_state_dict new_state_dict param_name param model named_parameters assertEqual param to_local torch ones_like param to_local new_fill_value local_param = param to_local Only guarantee local tensor s data pointer does change sharding even i e no padding otherwise FSDP may re-pad local tensor changing its data pointer local_param size param device_mesh size == param size assertEqual local_param data_ptr param_name_to_data_ptr param_name TestFullyShardStateDictMultiThread FSDPTestMultiThread property world_size skip_if_lt_x_gpu test_rank _offload_full_state_dict Construct reference unsharded model all ranks model_args = ModelArgs dropout_p= torch manual_seed ref_model = Transformer model_args device_type param ref_model parameters torch distributed broadcast param detach src= Construct sharded model sharded state dict all ranks model = copy deepcopy ref_model module model modules isinstance module TransformerBlock fully_shard module fully_shard model sharded_sd = model state_dict Save reference CPU full state dict rank delete reference model otherwise rank = del ref_model ref_gpu_full_sd = ref_model state_dict ref_full_sd = k v cpu k v ref_gpu_full_sd items del ref_gpu_full_sd Reshard GPU sharded state dict CPU full state dict rank full_sd = param_name sharded_param sharded_sd items full_param = sharded_param full_tensor rank == full_sd param_name = full_param cpu del full_param Check we have CPU full state dict only rank rank == assertEqual len full_sd len ref_full_sd assertEqual list full_sd keys list ref_full_sd keys param ref_param zip full_sd values ref_full_sd values strict=True assertEqual param device torch device cpu assertEqual param device ref_param device assertEqual param ref_param assertEqual len full_sd __name__ == __main__ run_tests