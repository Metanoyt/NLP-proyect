__future__ annotations contextlib copy enum functools io itertools json logging os sys time warnings abc ABC abstractmethod collections defaultdict contextlib AbstractContextManager dataclasses dataclass inspect currentframe itertools count operator attrgetter typing Any Callable Optional TYPE_CHECKING TypeVar Union typing_extensions Never override ParamSpec Protocol TypedDict Unpack unittest mock torch _inductor async_compile torch fx torch utils _pytree pytree functorch compile min_cut_rematerialization_partition torch fx torch _dispatch python enable_python_dispatcher torch _dynamo compiled_autograd config dynamo_config logging dynamo_logging utils dynamo_utils torch _dynamo device_interface get_interface_for_device torch _dynamo repro after_aot wrap_compiler_debug torch _dynamo utils chromium_event_timed CompileEventLogger counters detect_fake_mode dynamo_timed flatten_graph_inputs get_metrics_context lazy_format_graph_code set_feature_use torch _functorch config functorch_config torch _functorch _aot_autograd subclass_parametrization unwrap_tensor_subclass_parameters torch _functorch aot_autograd aot_export_module GraphOutputName make_boxed_func SerializableAOTDispatchCompiler torch _inductor codecache code_hash FxGraphCache output_code_log torch _inductor cudagraph_utils BoxedDeviceIndex format_default_skip_message log_cudagraph_skip_and_bump_counter PlaceholderInfo torch _inductor custom_graph_pass CustomPartitionerFn torch _inductor debug create_mapping_pre_post_grad_nodes save_args_for_compile_fx_inner torch _inductor output_code CompiledAOTI CompiledFxGraph CompiledFxGraphConstantsWithGm get_expanded_dims index_expanded_dims OutputCode torch _inductor runtime cache_dir_utils cache_dir torch _inductor utils BoxedBool count_tangents fresh_cache get_all_devices InputType is_gpu should_assume_input_aligned should_use_remote_fx_graph_cache tensor_is_aligned torch _library fake_class_registry FakeScriptObject torch _logging trace_structured torch _utils_internal compile_time_strobelight_meta torch fx GraphModule torch fx experimental symbolic_shapes free_unbacked_symbols SymExprPrinter torch fx passes fake_tensor_prop FakeTensorProp torch monitor _WaitCounter torch utils _ordered_set OrderedSet _dynamo backends common aot_autograd _dynamo exc ShortenTraceback SkipFrame fx _lazy_graph_module _use_lazy_graph_module fx graph _PyTreeCodeGen utils _triton has_triton config metrics codegen common get_wrapper_codegen_for_device init_backend_registration debug DebugContext decomposition select_decomp_table exc InductorError fx_passes joint_graph joint_graph_passes fx_passes post_grad post_grad_passes view_to_reshape fx_passes pre_grad pre_grad_passes graph GraphLowering ir get_device_type IRNode output_code complex_memory_overlap noqa F triton_bundler TritonBundler utils align_inputs_from_check_idxs clone_preserve_strides copy_misaligned_inputs get_cloned_parameter_buffer_name get_first_incompatible_cudagraph_node maybe_get_suppress_shape_guards_ctx output_node remove_unaligned_input_idxs shape_env_from_inputs virtualized V TYPE_CHECKING collections abc Generator Sequence torch _inductor output_code _StrideExprStr torch _ops OpOverload torch export pt _archive _package_weights Weights ir ExternKernelNode _P = ParamSpec _P _T = TypeVar _T TYPE_CHECKING config is_fbcode no-op decorator time_and_log attr str - Callable Callable _P _T Callable _P _T dynamo_utils identity log_optimus_to_scuba args object kwargs object - None pass torch _inductor fb utils log_optimus_to_scuba time_and_log TYPE_CHECKING types torch _functorch _aot_autograd schemas FQN GraphInputName GraphSignature CompileFxOutput = Union Callable list object Sequence torch Tensor str list str Weights FxCompileMode enum Enum NORMAL = For testing - use serde FxCompile scheme debug serialization deserialization GraphMoule CompiledFxGraph SERIALIZE = Compile using subprocess instead in-process SUBPROCESS = dataclass FxCompileConfig mode FxCompileMode use_async bool use_progressive bool _fx_compile_mode_default - FxCompileConfig name = TORCHINDUCTOR_FX_COMPILE_MODE value = os environ get name value None FxCompileConfig FxCompileMode NORMAL False False use_async = False use_progressive = False value lower startswith progressive+ use_progressive = True value = value value lower startswith async+ use_async = True value = value try value = value upper FxCompileConfig FxCompileMode value use_async use_progressive except KeyError logging log = logging getLogger __name__ log error Invalid value s s Expected one s Using default value name join sorted repr x x FxCompileMode __members__ keys Remove environment so subprocesses don t ALSO complain os environ pop name FxCompileConfig FxCompileMode NORMAL False False _get_progression_configs - list dict str Any TODO make configurable max_autotune True _fx_compile_config = _fx_compile_mode_default fx_compile_mode = _fx_compile_config mode fx_compile_async = _fx_compile_config use_async fx_compile_progressive = _fx_compile_config use_progressive log = logging getLogger __name__ perf_hint_log = torch _logging getArtifactLogger __name__ perf_hints pre_grad_graphs_log = torch _logging getArtifactLogger __name__ pre_grad_graphs post_grad_graphs_log = torch _logging getArtifactLogger __name__ post_grad_graphs static_inputs_log = torch _logging getArtifactLogger __name__ cudagraph_static_inputs inductor_metrics_log = torch _logging getArtifactLogger __name__ inductor_metrics get_static_input_idxs num_fixed int - list int If we inlining NNModules we treat all torch nn Parameters static purposes cudagraphs Rather than copying these into cudagraph-owned memory like we do normal inputs each run we will re-record cudagraph these parameter locations change context = torch _guards TracingContext try_get fixed = list range num_fixed context context fw_metadata fixed context fw_metadata static_input_indices record_original_output_strides gm GraphModule - None output_node = gm graph find_nodes op= output output_strides = isinstance output_node args torch fx Node output_node_args = output_node args output_node_args = output_node args output output_node_args isinstance output torch fx Node val = output meta get val None isinstance val torch Tensor output_strides append val stride pyrefly ignore bad-argument-type output_strides append None output_node meta original_output_strides = output_strides _recursive_record_original_output_strides gm GraphModule - None invoke_subgraph HOP requires output strides respected node gm graph find_nodes op= call_function target=torch ops higher_order invoke_subgraph subgraph = getattr gm node args target _recursive_record_original_output_strides subgraph record_original_output_strides gm _recursive_record_user_visible_output_idxs gm GraphModule - None invoke_subgraph HOP requires output strides respected node gm graph find_nodes op= call_function target=torch ops higher_order invoke_subgraph subgraph = getattr gm node args target node subgraph graph find_nodes op= output node meta user_visible_output_idxs = idx idx range len node args isinstance node args idx torch fx Node _recursive_record_user_visible_output_idxs subgraph functools lru_cache None _step_logger - Callable None dynamo_logging get_step_logger log functools cache _warn_tf _disabled - None torch cuda is_available torch backends cuda matmul allow_tf torch cuda get_device_capability = warnings warn TensorFloat tensor cores float matrix multiplication available enabled Consider setting ` torch set_float _matmul_precision high ` better performance _resolve_name_collision mod GraphModule gm GraphModule - None In aot_export_module make_fx we create get_attr nodes name prefix _tensor_constant _torchbind_obj See Tracer create_arg torch fx _symbolic_trace py However might result name collision original mod already has different buffer same name We resolve potential name collision here changing target name new number post fix existing_keys = OrderedSet name name val mod named_parameters remove_duplicate=False existing_keys update OrderedSet name name val mod named_buffers remove_duplicate=False find_smallest_i graph fx Graph prefix str - int i = node graph nodes node op == get_attr node target startswith prefix len node target len prefix post_fix = node target split prefix - post_fix isdigit i = max i int post_fix key existing_keys key startswith prefix len key len prefix post_fix = key split prefix - post_fix isdigit i = max i int post_fix i + node gm graph nodes node op == get_attr target_name = node target target_name startswith _tensor_constant target_name startswith _torchbind_obj continue hasattr mod target_name continue gm_target = attrgetter target_name gm model_target = attrgetter target_name mod isinstance gm_target FakeScriptObject isinstance model_target FakeScriptObject gm_target real_obj model_target real_obj continue gm_target device == model_target device gm_target dtype == model_target dtype torch equal gm_target model_target If tensors same name gm model indeed same we don t need rename Check device first avoid torch equal wrapper_CUDA__equal raise when different device continue prefix = _tensor_constant target_name startswith _tensor_constant _torchbind_obj new_id = find_smallest_i gm graph prefix new_target_name = f prefix new_id node target = new_target_name setattr gm new_target_name gm_target existing_keys add new_target_name _unlift_graph mod GraphModule gm GraphModule graph_signature GraphSignature - GraphModule torch export unflatten _assign_attr _AttrKind _resolve_name_collision mod gm state_dict dict str Union torch nn parameter Parameter torch Tensor = name param mod named_parameters remove_duplicate=False state_dict name = param _assign_attr param gm name attr_kind=_AttrKind PARAMETER name buffer mod named_buffers remove_duplicate=False state_dict name = buffer _assign_attr buffer gm name attr_kind=_AttrKind BUFFER placeholder_nodes = gm graph find_nodes op= placeholder lifted_inputs list Optional FQN = In AOTI module parameters buffers lifted graph inputs As result mutation buffers has side effect which makes their initial values different Eager So we clone them here copy We cloning parameters although will needed we want support training node placeholder_nodes node_name = node name node_name graph_signature inputs_to_parameters parameter_name = graph_signature inputs_to_parameters node_name lifted_inputs append parameter_name node_name graph_signature inputs_to_buffers buffer_name = graph_signature inputs_to_buffers node_name lifted_inputs append buffer_name gm meta get_cloned_parameter_buffer_name buffer_name = clone_preserve_strides state_dict buffer_name assert node_name graph_signature user_inputs lifted_inputs append None torch export _unlift _unlift outputs tuple torch fx Node = tuple gm graph output_node args type ignore arg-type mutated_outputs = buffer_mutations = graph_signature buffers_to_mutate user_input_mutations = graph_signature user_inputs_to_mutate output_tokens = graph_signature output_tokens idx out enumerate outputs value Optional Union FQN GraphInputName = None idx len buffer_mutations + len user_input_mutations + len output_tokens name = GraphOutputName out name name buffer_mutations value = buffer_mutations name name user_input_mutations value = user_input_mutations name mutated_outputs append value unlifted_gm = _unlift gm lifted_inputs mutated_outputs pytree treespec_leaf None unlifted_gm _get_subgraph_names gm GraphModule skip_invoke_subgraph bool = False - Generator str None None all_subgraph_names OrderedSet str = OrderedSet x target x gm graph find_nodes op= get_attr fx_subgraph_names OrderedSet str = OrderedSet child_name child_module gm named_children Sometimes owning_module can have unused children Skip them checking them get_attr node targets child_name all_subgraph_names isinstance child_module torch fx GraphModule fx_subgraph_names add child_name skip_invoke_subgraph node gm graph find_nodes op= call_function target=torch ops higher_order invoke_subgraph fx_subgraph_names discard node args target yield fx_subgraph_names _recursive_pre_grad_passes gm GraphModule example_inputs Sequence InputType - GraphModule dynamo_timed _recursive_pre_grad_passes log_pt _compile_event=True dynamo_compile_column_us= pre_grad_pass_time_us add_passes = config add_pre_grad_passes remove_passes = config remove_pre_grad_passes subgraph_name _get_subgraph_names gm subgraph = getattr gm subgraph_name we don t have recursive example inputs passing empty set here new_subgraph = _recursive_pre_grad_passes subgraph setattr gm subgraph_name new_subgraph pre_grad_passes gm example_inputs add_passes remove_passes _recursive_joint_graph_passes gm GraphModule skip_invoke_subgraph bool = False - None dynamo_timed _recursive_joint_graph_passes log_pt _compile_event=True dynamo_compile_column_us= joint_graph_pass_time_us invoke_subgraph already runs _recursive_joint_graph_passes In AOTAutograd ` run_joint_graph_passes_on_hops ` partitions invoke_subgraph HOP before calling partitioner outer graph AOTAutograd has access partition_fn which internally calls ` _recursive_joint_graph_passes ` subgraph So skip recursing skip_invoke_subgraph subgraph_name _get_subgraph_names gm skip_invoke_subgraph subgraph = getattr gm subgraph_name _recursive_joint_graph_passes subgraph skip_invoke_subgraph joint_graph_passes gm _recursive_post_grad_passes gm GraphModule is_inference bool = False - None dynamo_timed _recursive_post_grad_passes log_pt _compile_event=True dynamo_compile_column_us= post_grad_pass_time_us subgraph_name _get_subgraph_names gm subgraph = getattr gm subgraph_name _recursive_post_grad_passes subgraph is_inference post_grad_passes gm is_inference split_const_gm gm GraphModule skip_constructor bool = True lifted_constant_names Optional list str = None skip_folding_node_fn Optional Callable torch fx Node bool = None - tuple GraphModule dict str int This function takes GraphModule input gm The gm will split into components const_gm which consists subgraph gm can constant folded gm being inplace modified which returns graph after constant folding If additional lifted_constants argument passed we will assume gm has been lifted run transformation accordingly When skip_folding_node_fn callback passed we will skip constant folding nodes which callback returns True const_output_index mapping corresponding node name gm output index const_gm Returns const_gm const_output_index torch _inductor constant_folding CONST_MODULE_TAG META_TAG MODULE_TAG replace_node_with_constant run_and_get_constant_graph const_gm = run_and_get_constant_graph gm skip_constructor lifted_constant_names skip_folding_node_fn const_result = const_gm lifted_constant_names None None const_outputs = x name idx idx x enumerate tuple const_gm graph nodes - args to_erase_node = to_replace_node = const_output_index = node gm graph nodes node name const_outputs to_replace_node append node node meta META_TAG == CONST_MODULE_TAG node op = placeholder to_erase_node append node node to_replace_node new_const_name = _FOLDED_CONST_ + node name replace_node_with_constant gm node const_result const_outputs node name type ignore index lifted_constant_names None None new_const_name const_output_index new_const_name = const_outputs node name node to_erase_node - node users n node users assert n meta META_TAG == MODULE_TAG f node node user empty gm graph erase_node node gm recompile const_gm const_output_index is_tf _warning_applicable gm GraphModule - bool aten = torch ops aten tf _ops = OrderedSet aten mm default aten addmm default aten bmm default aten baddbmm default target tf _ops node gm graph find_nodes op= call_function target=target isinstance node meta get val None torch Tensor node meta val dtype == torch float node meta val device type == cuda True False maybe_disable_comprehensive_padding example_inputs Sequence InputType - AbstractContextManager None None For CPU backend enable comprehensive padding causes some unit tests fail due changing number generated kernels Skip now has_gpu = any is_gpu t device type t example_inputs isinstance t torch Tensor config disable_padding_cpu config comprehensive_padding has_gpu perf_hint_log info Skip comprehensive padding CPU config patch comprehensive_padding=False config aot_inductor use_runtime_constant_folding perf_hint_log info Skip comprehensive padding use_runtime_constant_folding config patch comprehensive_padding=False contextlib nullcontext maybe_disable_graph_partition cpp_wrapper bool aot_mode bool - AbstractContextManager None None graph partition does support cpp_wrapper aot_mode yet cpp_wrapper aot_mode config patch graph_partition=False contextlib nullcontext fake_tensor_prop gm GraphModule example_inputs Sequence InputType force_allow_non_fake_inputs bool = False - torch _subclasses FakeTensorMode If we can detect fake mode context inputs create one The created fake mode will returned Ensure decomps support symbolic shapes used enable_python_dispatcher fake_mode = detect_fake_mode example_inputs fake_mode fake_mode = torch _subclasses FakeTensorMode allow_non_fake_inputs=True FakeTensorProp gm mode=fake_mode propagate example_inputs ctx = contextlib nullcontext force_allow_non_fake_inputs mock patch object fake_mode allow_non_fake_inputs True ctx type ignore attr-defined FakeTensorProp gm mode=fake_mode propagate_dont_convert_inputs example_inputs fake_mode pass config dict back user get_patched_config_dict config_patches Optional Union str dict str Any = None - dict str Any config patch config_patches config get_config_copy contextlib contextmanager with_fresh_cache_if_config - Generator None None None config force_disable_caches Don t delete cache dir because has survive beyond compile_fx call Let s put temp dirs under default cache dir so they re easier locate fresh_cache dir=cache_dir delete=False yield yield _CompileFxKwargs TypedDict total=False cudagraphs Optional BoxedBool static_input_idxs Sequence int is_backward bool graph_id Optional int cpp_wrapper bool aot_mode bool is_inference bool layout_opt Optional bool extern_node_serializer Optional Callable list ExternKernelNode Any boxed_forward_device_index Optional BoxedDeviceIndex fx_wrapper bool _CompileFxCallable Protocol __call__ gm GraphModule example_inputs Sequence InputType kwargs Unpack _CompileFxKwargs - OutputCode compile_fx_inner gm GraphModule example_inputs Sequence InputType kwargs Unpack _CompileFxKwargs - OutputCode kwargs setdefault cudagraphs None kwargs setdefault static_input_idxs kwargs setdefault is_backward False kwargs setdefault graph_id None kwargs setdefault cpp_wrapper False kwargs setdefault fx_wrapper False kwargs setdefault is_inference False kwargs setdefault boxed_forward_device_index None kwargs setdefault layout_opt None kwargs setdefault extern_node_serializer None Need with_fresh_cache_if_config compile_fx_inner even we already have one compile_fx The reason compilation backward graph may happen after compile_fx we may want use _LazyGraphModule compiling backward graph well contextlib ExitStack stack stack enter_context torch utils _python_dispatch _disable_current_modes stack enter_context _use_lazy_graph_module dynamo_config use_lazy_graph_module stack enter_context dynamo_utils dynamo_timed compile_fx_inner phase_name= inductor_compile log_pt _compile_event=True log_waitcounter=True waitcounter_name_override= compile_inductor dynamo_compile_column_us= inductor_cumulative_compile_time_us stack enter_context with_fresh_cache_if_config stack enter_context DebugContext CompileEventLogger pt _compile inductor_compile is_backward=kwargs is_backward wrap_compiler_debug _compile_fx_inner compiler_name= inductor gm example_inputs kwargs time_and_log attr= compilation time seconds _compile_fx_inner gm GraphModule example_inputs Sequence InputType graph_kwargs Unpack _CompileFxKwargs - OutputCode Inductor API compiles single graph If you change argument list function make sure you also update call save_args_for_compile_fx_inner below accordingly aot_mode bool = V aot_compilation Clean up Compiled Triton Kernels per inductor compile future objects may valid use after they run autotuned torch _inductor async_compile CompiledTritonKernels cache_clear dynamo_utils count_calls gm graph == aot_mode trigger real recompilation _LazyGraphModule before returning forward method torch _dynamo utils CompileEventLogLevel torch fx _lazy_graph_module _LazyGraphModule _LazyGraphModule force_recompile gm compile_id = torch _guards CompileContext current_compile_id CompileEventLogger log_instant_event backward no-op metadata= compile_id compile_id log_level=CompileEventLogLevel PT _COMPILE make_boxed_func gm forward static_input_idxs Sequence int = graph_kwargs setdefault static_input_idxs static_inputs_log debug static input idxs compile_fx_inner s static_input_idxs inputs_to_check = get_input_idxs_to_check example_inputs static_input_idxs assert isinstance next iter reversed gm graph nodes args tuple list f inductor can only compile FX graphs which tuple list got gm graph graph_kwargs get cudagraphs None graph_kwargs cudagraphs = BoxedBool config triton cudagraphs config save_args save_args_for_compile_fx_inner gm example_inputs graph_kwargs start = time time fx_graph_remote_cache = should_use_remote_fx_graph_cache Check registered backend s support caching init_backend_registration backends_support_caching = all backend supports_caching backend get_wrapper_codegen_for_device device type config cpp_wrapper config fx_wrapper device get_all_devices gm backend None dynamo_timed fx_codegen_and_compile log_pt _compile_event=True log_waitcounter=True use_cache = config force_disable_caches config fx_graph_cache fx_graph_remote_cache aot_mode backends_support_caching torch _functorch config bundled_autograd_cache local = config fx_graph_cache remote = fx_graph_remote_cache set_feature_use fx_cache use_cache log debug FX cache status use_cache= s local= s remote= s aot_mode= s force_disable_caches= s use_cache local remote aot_mode config force_disable_caches TODO This hack purely get some info extract_tensor_metadata_for_cache_key figure out how have modify example inputs i input enumerate example_inputs isinstance input torch Tensor is_gpu input device type i static_input_idxs input _is_inductor_static = True type ignore attr-defined mb_compiled_graph Optional OutputCode = None key_info = None cache_info = None remote_cache = None constants = CompiledFxGraphConstantsWithGm gm TODO time will slightly inconsistent one computed prepare_key load_with_key dump those settings cache_event_time start_time = time time_ns use_cache key_info cache_info = FxGraphCache prepare_key gm example_inputs graph_kwargs inputs_to_check remote Attempt cache lookup key_info None key debug_lines = key_info log debug FX cache key generated s key remote remote_cache = FxGraphCache get_remote_cache log debug Using remote FX cache mb_compiled_graph cache_info = FxGraphCache load_with_key key debug_lines example_inputs local remote_cache is_backward=graph_kwargs get is_backward False constants=constants log debug Failed generate FX cache key torch _functorch config bundled_autograd_cache assert mb_compiled_graph None assert cache_info None When using bundled autograd cache we still want use TritonBundler we don t want save results here The results will get saved directly AOTAutogradCache TritonBundler begin_compile try mb_compiled_graph = fx_codegen_and_compile gm example_inputs inputs_to_check graph_kwargs assert mb_compiled_graph None triton_bundle triton_bundler_meta = TritonBundler collect mb_compiled_graph set_triton_bundle triton_bundle except ShortenTraceback SkipFrame raise except Exception e raise InductorError e currentframe with_traceback e __traceback__ None finally TritonBundler end_compile CACHE BYPASS Compile graph don t save cache can happen either because cache disabled we determined input uncacheable cache_info None cache_info cache_state == bypass assert mb_compiled_graph None log debug FX cache bypass reason s cache_info get cache_bypass_reason unknown cache_info None FX cache disabled key generation failed try mb_compiled_graph = fx_codegen_and_compile gm example_inputs inputs_to_check graph_kwargs except Exception e raise InductorError e currentframe with_traceback e __traceback__ None CACHE MISS Compile graph save cache cache_info cache_state == miss assert mb_compiled_graph None assert key_info None log debug FX cache miss compiling saving cache TritonBundler begin_compile try mb_compiled_graph = fx_codegen_and_compile gm example_inputs inputs_to_check graph_kwargs assert mb_compiled_graph None mb_compiled_graph _time_taken_ns = time time_ns - start_time cache_key debug_lines = key_info mb_compiled_graph _fx_graph_cache_key = cache_key mb_compiled_graph _fx_graph_cache_debug_lines = debug_lines triton_bundle triton_bundler_meta = TritonBundler collect mb_compiled_graph set_triton_bundle triton_bundle except ShortenTraceback SkipFrame raise except Exception e raise InductorError e currentframe with_traceback e __traceback__ None finally TritonBundler end_compile triton_bundler_meta None cache_info triton_bundler_meta = str triton_bundler_meta cache_info time_taken_ns = mb_compiled_graph _time_taken_ns log debug Saving compiled graph FX cache key s cache_key FxGraphCache _save_graph cache_key mb_compiled_graph example_inputs local remote_cache CACHE HIT much really do just make sure cache key recorded graph assert cache_info cache_state == hit assert mb_compiled_graph None assert key_info None cache_key debug_lines = key_info log debug FX cache hit key s cache_key mb_compiled_graph _fx_graph_cache_key = cache_key mb_compiled_graph _fx_graph_cache_debug_lines = debug_lines assert mb_compiled_graph None compiled_graph = mb_compiled_graph Logging observability we log single chromium event tlparse log every cache action In event bypass we also logged remote table earlier log_cache_bypass cache_state = cache_info cache_state cache_info None disabled Here grepping fx_graph_cache_hit fx_graph_cache_miss fx_graph_cache_bypass fx_graph_cache_disabled CompileEventLogger instant f fx_graph_cache_ cache_state metadata=cache_info time_ns=start_time Add event data about cache hits miss TODO add remote cache get put timings here too CompileEventLogger pt _compile inductor_compile cache_state=cache_state cache_event_time=start_time key=cache_info get key cache_info None components=cache_info get components cache_info None cache_bypass_reason= cache_info get cache_bypass_reason cache_info cache enabled remote_cache_enabled=remote local_cache_enabled=local Don t clog up main tlparse output disabled cache cache_info None trace_structured artifact metadata_fn=lambda name f fx_graph_cache_ cache_state encoding json payload_fn=lambda json dumps cache_info compiled_graph post_compile example_inputs constants graph_kwargs log debug FX codegen compilation took fs time time - start This message printing overview information inductor mm counts shapes etc after lowering log isEnabledFor logging INFO mm_table_data = key value counters aten_mm_info items parts = key split _ len parts Unexpected format show as-is mm_table_data append key - value continue Determine batched operation checking operation name name = _ join parts - len parts = _ join parts - is_batched = name endswith bmm baddbmm is_batched len parts = Batched operation last parts batch m n k batch m n k = parts - name = _ join parts - mm_table_data append name batch m n k value Non-batched operation last parts m n k m n k = parts - name = _ join parts - mm_table_data append name - m n k value log info Overview info inductor aten mms log info &#124; &#124; &#124; &#124; &#124; format noqa G Name B M N K Count log info - row mm_table_data pyrefly ignore not-iterable log info &#124; &#124; &#124; &#124; &#124; format row noqa G log info - Not strictly necessary good clean up straggling futures unused reclaim memory torch _inductor async_compile CompiledTritonKernels cache_clear _step_logger logging INFO torchinductor done compiling f BACKWARDS graph_kwargs is_backward FORWARDS f graph graph_kwargs graph_id compiled_graph _FxCompileStat Count successful compiles type codegen_and_compile int = __repr__ - str f codegen_and_compile codegen_and_compile FxCompile ABC An FxCompile represents mechanism can turn GraphModule into OutputCode Some stats logging debugging _compile_stats dict type FxCompile _FxCompileStat = defaultdict _FxCompileStat TODO We should probably eventually add some kind async version so we can kick off compile then go do other things - we ll need know what kind API we want first abstractmethod codegen_and_compile gm GraphModule example_inputs Sequence InputType inputs_to_check Sequence int graph_kwargs _CompileFxKwargs - OutputCode classmethod _reset_stats cls - None cls _compile_stats clear _InProcessFxCompile FxCompile override codegen_and_compile gm GraphModule example_inputs Sequence InputType inputs_to_check Sequence int graph_kwargs _CompileFxKwargs - OutputCode Generates OutputCode GraphModule example_inputs Sorry about mess we need graph_kwargs continue able propagate further TODO _CompileFxKwargs actually has stronger types than signature need tighten up assert cudagraphs graph_kwargs graph_kwargs cudagraphs None cudagraphs BoxedBool = graph_kwargs cudagraphs static_input_idxs Sequence int = graph_kwargs get static_input_idxs is_backward bool = graph_kwargs get is_backward False graph_id Optional int = graph_kwargs get graph_id None cpp_wrapper bool = graph_kwargs get cpp_wrapper False fx_wrapper bool = graph_kwargs get fx_wrapper False aot_mode bool = V aot_compilation is_inference bool = graph_kwargs get is_inference False extern_node_serializer Optional Callable list ExternKernelNode Any = graph_kwargs get extern_node_serializer None _WaitCounter pytorch wait_counter actual_codegen_and_compile guard dynamo_utils preserve_rng_state sleep_sec = config sleep_sec_TESTING_ONLY None time log warning Sleeping s since sleep_sec_TESTING_ONLY set sleep_sec time sleep sleep_sec is_tf _warning_applicable gm _warn_tf _disabled inductor_counters = counters inductor copy lift maximum depth Python interpreter stack adapt large deep models sys setrecursionlimit max sys getrecursionlimit _step_logger logging INFO torchinductor compiling f BACKWARDS is_backward FORWARDS f graph graph_id fd = io StringIO torch _dynamo repro after_aot save_graph_repro fd gm example_inputs inductor save_dir=None runnable_graph_str = fd getvalue trace_structured artifact metadata_fn=lambda name fx_graph_runnable encoding string payload_fn=lambda runnable_graph_str V debug fx_graph gm example_inputs TODO Should we actually dump It should redundant aot structured logs trace_structured inductor_input_graph payload_fn=lambda gm print_readable print_output=False shape_env = gm shape_env shape_env None shape_env = shape_env_from_inputs example_inputs Convert view reshape graph This necessary primarily layout optimization Do unconditionally uniformity It s needed because when we do layout optimization contiguous tensor eager mode may becomes channels last tensor A view op previously can applied contiguous tensor may able applied channels tensor any more An error like RuntimeError view size compatible input tensor s size stride least one dimension spans across two contiguous subspaces Use reshape instead will printed Replace view op reshape op case As example timm_resnest botnet t_ convnext_base etc will fail we don t do Also has done before FakeTensorProp below avoid failed view call view_to_reshape gm dynamo_timed additional_fake_tensor_prop log_pt _compile_event=True It safe run FakeTensorProp under no_grad because time we re inductor we assume AOTAutograd has already taken care autograd so there should no more autograd-related API s graph torch no_grad fake_mode = fake_tensor_prop gm example_inputs _recursive_record_original_output_strides gm pattern matcher passes might preserve striding information node meta val future we rely these being correct we will need fix trace_structured artifact metadata_fn=lambda name before_post_grad_graph encoding string payload_fn=lambda gm print_readable print_output=False include_stride=True include_device=True V set_fake_mode fake_mode has some issues memory training cuda_context = get_cuda_device_context gm cuda_context _recursive_post_grad_passes gm is_inference=is_inference V debug fx_graph_transformed gm example_inputs post_grad_graphs_log debug s lazy_format_graph_code AFTER POST GRAD gm include_stride=True include_device=True colored=True We re printing graph used cache key - so printer which little less readable faster appropriate inductor_post_grad_graph_str = gm print_readable print_output=False include_stride=True include_device=True fast_sympy_print=True inductor_post_grad_graph used inductor provenance tracking highlighter front-end trace_structured artifact metadata_fn=lambda name inductor_post_grad_graph encoding string payload_fn=lambda inductor_post_grad_graph_str config trace provenance_tracking_level = provenance_tracking_json = torch fx traceback get_graph_provenance_json gm graph torch _inductor debug _inductor_post_to_pre_grad_nodes = create_mapping_pre_post_grad_nodes torch _inductor debug _pre_grad_graph_id provenance_tracking_json metrics_context = get_metrics_context metrics_context in_progress num_graph_breaks = counters graph_break total CompileEventLogger compilation_metric overwrite=True num_graph_breaks=num_graph_breaks config is_fbcode try log_optimus_to_scuba extra_logging= pt _configs str get_patched_config_dict except Exception TODO T need work around now support vllm See details vllm compilation pass_manager py log warning failed log pt _configs V set_fake_mode fake_mode maybe_disable_comprehensive_padding example_inputs maybe_disable_graph_partition cpp_wrapper aot_mode const_output_index = None const_graph = None const_wrapper_code = None const_kernel_code = None aot_mode config aot_inductor use_runtime_constant_folding torchbind objects have name starts _torchbind_obj See caffe torch fx _symbolic_trace py lines= const_gm const_output_index = split_const_gm gm skip_folding_node_fn=lambda node node op == get_attr isinstance node target str node target startswith _torchbind_obj isinstance node meta get val None FakeScriptObject const_graph = GraphLowering const_gm example_inputs= shape_env=shape_env graph_id=graph_id cpp_wrapper=cpp_wrapper aot_mode=aot_mode extern_node_serializer=extern_node_serializer is_inference=is_inference is_backward=is_backward is_const_graph=True fx_wrapper=fx_wrapper V set_graph_handler const_graph V set_extern_kernel_nodes assert cpp_wrapper AOT mode only supports C++ wrapper const_graph run const_wrapper_code const_kernel_code = const_graph codegen_with_cpp_wrapper graph = GraphLowering gm example_inputs will used AOTInductor dry-run generated code Triton kernel tuning For forward pass we have real inputs used example_inputs For backward pass we currently use fake tensors defake them later example_inputs=example_inputs shape_env=shape_env graph_id=graph_id cpp_wrapper=cpp_wrapper aot_mode=aot_mode extern_node_serializer=extern_node_serializer is_inference=is_inference is_backward=is_backward const_output_index=const_output_index const_wrapper_code= const_wrapper_code value const_wrapper_code None const_kernel_code= const_kernel_code value const_kernel_code None const_module=const_graph inputs_to_check=inputs_to_check fx_wrapper=fx_wrapper metrics_helper = metrics CachedMetricsHelper We going start code generating runtime asserts so make sure you don t start adding new ones lowering process graph freeze_runtime_asserts V set_graph_handler graph V set_extern_kernel_nodes graph run example_inputs output_strides list Optional tuple _StrideExprStr = graph graph_outputs None We ll put output strides compiled graph so we can later them caller via TracingContext p = SymExprPrinter out graph graph_outputs isinstance out IRNode out has_tensor_output len free_unbacked_symbols out get_stride == Convert string eval load path output_strides append tuple p doprint s s out get_layout stride output_strides append None _check_triton_bf _support graph TODO The switching between AOT mode here bit messy s localized block code below so I m going touch now compiled_fn Any compiled_fn_runner = None dynamo_timed GraphLowering compile_to_fn log_pt _compile_event=True graph aot_mode graph fx_wrapper assert graph cpp_wrapper compiled_fn = graph codegen gm type ignore attr-defined output_code_log debug Output graph module \n s compiled_fn print_readable print_output=False graph aot_mode codecache AotCodeCompiler assert graph cpp_wrapper AOT mode only supports C++ wrapper wrapper_code kernel_code = graph codegen_with_cpp_wrapper output_code_log debug Output wrapper code \n s wrapper_code value kernel_code value output_code_log debug Output kernel code \n s kernel_code value serialized_extern_kernel_nodes = None V extern_kernel_nodes serialized_extern_kernel_nodes = graph extern_node_serializer V extern_kernel_nodes output_code_log debug Serialized Extern Kernel Nodes \n s serialized_extern_kernel_nodes dynamo_timed AotCodeCompiler compile log_pt _compile_event=True Directly file path compiled code compiled_fn = AotCodeCompiler compile graph wrapper_code value kernel_code value serialized_extern_kernel_nodes device_type=graph device_type additional_files= dict fromkeys graph wrapper_code additional_files + const_graph wrapper_code additional_files const_graph compiled_module = graph compile_to_module compiled_fn = compiled_module call compiled_fn_runner = getattr compiled_module runner None Dump provenance artifacts debugging trace inductor_provenance_tracking_node_mappings = None inductor_kernel_stack_trace_str = None config trace provenance_tracking_level = inductor_provenance_tracking_node_mappings = json dumps torch _inductor debug dump_inductor_provenance_info inductor_kernel_stack_trace_str = json dumps torch _inductor debug _inductor_kernel_stack_trace trace_structured artifact metadata_fn=lambda name inductor_provenance_tracking_node_mappings encoding json payload_fn=lambda inductor_provenance_tracking_node_mappings trace_structured artifact metadata_fn=lambda name inductor_provenance_tracking_kernel_stack_traces encoding json payload_fn=lambda inductor_kernel_stack_trace_str inductor_kernel_stack_trace_str metrics_context = get_metrics_context metrics_context in_progress metrics_context add_to_set inductor_provenance inductor_kernel_stack_trace_str node_runtimes = None inductor_metrics_log isEnabledFor logging INFO num_bytes nodes_num_elem node_runtimes = graph count_bytes pyrefly ignore bad-assignment metrics num_bytes_accessed += num_bytes metrics node_runtimes += node_runtimes metrics nodes_num_elem += nodes_num_elem inductor_metrics_log info Graph Metrics \n s num_bytes_accessed num_bytes nodes_num_elem nodes_num_elem node_runtimes node_runtimes Collect dump op runtimes tensor metadata TLParse config log_tlparse _ _ node_runtimes = graph count_bytes torch _inductor debug log_runtime_and_tensor_meta node_runtimes Collect dump collective-op schedule external diagnostics torch _inductor debug log_collective_schedule graph scheduler nodes cudagraphs config triton cudagraph_skip_dynamic_graphs V graph disable_cudagraphs_reason torch _inductor utils any_is_symbolic example_inputs stack_trace = None node gm graph nodes meta_val = node meta get val None node op == placeholder isinstance meta_val torch Tensor torch _inductor utils any_is_symbolic meta_val continue stack_trace = node meta get stack_trace None break disable = graph symbolic shapes inputs config triton cudagraph_skip_dynamic_graphs=True stack_trace disable = f disable Found stack_trace \n disable = f disable \n pyrefly ignore unbound-name V graph disable_cudagraphs_reason = disable pyrefly ignore unbound-name cudagraphs V graph disable_cudagraphs_reason maybe_incompat_node = get_first_incompatible_cudagraph_node gm maybe_incompat_node disable = f disabling cudagraphs due incompatible op maybe_incompat_node target stack_trace = maybe_incompat_node meta get stack_trace None disable = f disable Found stack_trace \n pyrefly ignore unbound-name V graph disable_cudagraphs_reason = disable pyrefly ignore unbound-name V aot_compilation assert isinstance compiled_fn pyrefly ignore unbound-name str list torch fx GraphModule type compiled_fn CompiledAOTI compiled_fn TODO Hoist above V aot_compilation pyrefly ignore unbound-name cudagraphs V graph disable_cudagraphs_reason torch _inductor cudagraph_utils check_lowering_disable_cudagraph pyrefly ignore unbound-name V graph disable_cudagraphs_reason = check_lowering_disable_cudagraph pyrefly ignore unbound-name V graph device_node_mapping _compile_stats type codegen_and_compile += pyrefly ignore unbound-name torch _inductor debug RECORD_GRAPH_EXECUTION pyrefly ignore unbound-name torch _inductor debug GRAPH_COMPILE_IDS None compile_id = str pyrefly ignore unbound-name torch _guards CompileContext current_compile_id graph_id = graph_kwargs get graph_id graph_id None pyrefly ignore unbound-name torch _inductor debug GRAPH_COMPILE_IDS graph_id = compile_id CompiledFxGraph pyrefly ignore bad-argument-type compiled_fn graph gm output_strides pyrefly ignore unbound-name V graph disable_cudagraphs_reason metrics_helper get_deltas counters inductor - inductor_counters cudagraphs example_inputs static_input_idxs graph_kwargs inputs_to_check runnable_graph_str inductor_post_grad_graph_str compiled_fn_runner inductor_provenance_tracking_node_mappings inductor_kernel_stack_trace_str fx_codegen_and_compile gm GraphModule example_inputs Sequence InputType This derivable other inputs function we pass explicitly because s nontrivial compute inputs_to_check Sequence int graph_kwargs Unpack _CompileFxKwargs - OutputCode scheme FxCompile fx_compile_mode == FxCompileMode NORMAL scheme = _InProcessFxCompile fx_compile_mode == FxCompileMode SERIALIZE compile_fx_ext _DebugSerdeFxCompile scheme = _DebugSerdeFxCompile fx_compile_mode == FxCompileMode SUBPROCESS compile_fx_subproc _SubprocessFxCompile scheme = _SubprocessFxCompile fx_compile_async compile_fx_async _AsyncFxCompile compile_fx_ext _OutOfProcessFxCompile pyrefly ignore unbound-name assert isinstance scheme _OutOfProcessFxCompile async only valid out-of-process compile mode pyrefly ignore unbound-name scheme = _AsyncFxCompile scheme fx_compile_progressive compile_fx_async _ProgressiveFxCompile compile_fx_ext _OutOfProcessFxCompile pyrefly ignore unbound-name assert isinstance scheme _OutOfProcessFxCompile progressive only valid out-of-process compile mode progression_configs = _get_progression_configs Use in-process compile fast version fast_scheme = _InProcessFxCompile pyrefly ignore unbound-name scheme = _ProgressiveFxCompile fast_scheme scheme progression_configs pyrefly ignore unbound-name scheme codegen_and_compile gm example_inputs inputs_to_check graph_kwargs get_input_idxs_to_check inputs Sequence InputType static_input_idxs Sequence int - Sequence int This function runs compile time generates list indices which we might need do copy preserve alignment requirements ids_to_check = i input enumerate inputs isinstance input torch Tensor non-tensors don t need alignment continue is_gpu input device type right now we only care gpu tensors continue maybe_get_suppress_shape_guards_ctx suppress guards so tensor_is_aligned should_assume_input_aligned do add guards input s storage offset i static_input_idxs tensor_is_aligned input continue should_assume_input_aligned input continue we get here then our triton code assumes input aligned b we can t sure ahead time input will actually aligned therefore runtime we ll need check input aligned clone make aligned ids_to_check append i ids_to_check cudagraphify model Callable Any static_input_idxs Sequence int = device_index int stack_traces list Optional str is_backward bool is_inference bool constants tuple torch Tensor = placeholders Sequence PlaceholderInfo = mutated_input_idxs tuple int = - Callable Any torch _inductor cudagraph_trees cudagraphify_impl new_cudagraphify_impl cudagraphify_fn Callable Any config triton cudagraph_trees cudagraphify_fn = functools partial new_cudagraphify_impl device_index=device_index stack_traces=stack_traces is_backward=is_backward is_inference=is_inference constants=constants placeholders=placeholders mutated_input_idxs=mutated_input_idxs compile_id=torch _guards CompileContext current_compile_id cudagraphify_fn = cudagraphify_impl compiled_fn = None run new_inputs Sequence InputType - Any nonlocal compiled_fn compiled_fn None dynamo_utils preserve_rng_state compiled_fn = cudagraphify_fn model new_inputs static_input_idxs type ignore arg-type compiled_fn new_inputs type ignore arg-type run static_input x torch Tensor - torch Tensor Copy input while preserving strides torch empty_strided x size x stride dtype=x dtype device=x device index_expanded_dims_and_copy_ dst torch Tensor src torch Tensor expanded_dims list int - None Index into expanded dimensions both dst src then copy_ dst = index_expanded_dims dst expanded_dims src = index_expanded_dims src expanded_dims dst copy_ src cudagraphify_impl model Callable Any inputs list torch Tensor static_input_idxs Sequence int = - Callable list InputType Any Assumes inputs static_input_idxs i always same memory address check_input_idxs = get_input_idxs_to_check inputs static_input_idxs type ignore arg-type pyrefly ignore annotation-mismatch static_input_idxs OrderedSet int = OrderedSet remove_unaligned_input_idxs inputs static_input_idxs type ignore arg-type copy_misaligned_inputs inputs check_input_idxs type ignore arg-type assert isinstance inputs list inps_expanded_dims = get_expanded_dims x idx static_input_idxs idx x enumerate inputs allocate static tensor inputs static_inputs = x isinstance x torch Tensor static_input x idx static_input_idxs x detach idx x enumerate inputs copy over input values fresh allocations idx x expanded_dims enumerate zip inputs inps_expanded_dims isinstance x torch Tensor idx static_input_idxs index_expanded_dims_and_copy_ static_inputs idx x expanded_dims warmup torch cuda synchronize stream = torch cuda Stream stream wait_stream torch cuda current_stream copy static_inputs because will cleared model torch cuda stream stream model list static_inputs stream synchronize torch cuda current_stream wait_stream stream torch cuda synchronize record graph = torch cuda CUDAGraph torch cuda graph graph stream=stream capture_error_mode= thread_local static_outputs = model list static_inputs isinstance static_outputs list tuple static_outputs = static_outputs config size_asserts run new_inputs list InputType - Callable list InputType Any assert len static_inputs == len new_inputs idx dst src expanded_dims enumerate zip static_inputs new_inputs inps_expanded_dims isinstance dst torch Tensor continue assert isinstance src torch Tensor idx static_input_idxs assert dst data_ptr == src data_ptr TODO - could make one single op multiple slices avoid dispatch Could also pre-index ` dst ` tensors index_expanded_dims_and_copy_ dst src expanded_dims new_inputs clear graph replay pyrefly ignore bad-return static_outputs copy_indices = idx idx range len static_inputs idx static_input_idxs run new_inputs list InputType - Callable list InputType Any idx copy_indices expanded_dims = inps_expanded_dims idx src = new_inputs idx assert isinstance src torch Tensor index_expanded_dims_and_copy_ static_inputs idx src expanded_dims new_inputs clear graph replay pyrefly ignore bad-return static_outputs align_inputs_from_check_idxs run check_input_idxs OrderedSet compile_fx_aot model_ GraphModule example_inputs_ list InputType inner_compile _CompileFxCallable = compile_fx_inner config_patches Optional dict str Any = None - Union list Union str Weights str GraphModule assert isinstance model_ GraphModule model_ See NOTE Unwrapping subclasses AOT unwrap_tensor_subclass_parameters model_ pyrefly ignore annotation-mismatch config_patches dict str Any = copy deepcopy config_patches config_patches get fx_wrapper False config fx_wrapper If fx_wrapper set then set cpp_wrapper config_patches cpp_wrapper = True output_path = config_patches get aot_inductor output_path config aot_inductor output_path output_path assert output_path endswith pt The output path aot_compile should have extension pt specifying output path so AOTInductor If you would like package AOTInductor generated files into pt please call ` torch _inductor aoti_compile_and_package ` config_patches = config_patches aot_inductor output_path code_hash model_ code utils maybe_aoti_standalone_config config_patches = maybe_aoti_standalone_config config_patches extern_node_serializer = config_patches pop extern_node_serializer None saved_compile_id = model_ meta get dynamo_compile_id None saved_compile_context = torch _guards CompileContext saved_compile_id V set_aot_compilation True torch _guards compile_context saved_compile_context chromium_event_timed compile_fx_aot log_pt _compile_event=True reset_event_log_on_exit=True get_metrics_context compiled_artifacts = compile_fx model_ example_inputs_ inner_compile=functools partial inner_compile extern_node_serializer=extern_node_serializer config_patches=config_patches assert isinstance compiled_artifacts CompiledAOTI compiled_artifacts filename _graph_counter = count fw_compiler_freezing aot_autograd_model GraphModule aot_example_inputs Sequence InputType dynamo_model GraphModule num_example_inputs int inner_compile Callable Any cudagraphs BoxedBool graph_id int forward_device BoxedDeviceIndex - Callable list object Sequence torch Tensor torch _inductor freezing convert_conv_weights_to_channels_last freeze partition_fn won t called _recursive_joint_graph_passes aot_autograd_model layout_opt = GraphLowering decide_layout_opt aot_autograd_model is_inference=True layout_opt make sure meta val properly setup fake_tensor_prop aot_autograd_model aot_example_inputs True convert_conv_weights_to_channels_last aot_autograd_model opt_model preserved_arg_indices = freeze dynamo_model aot_autograd_model aot_example_inputs type ignore arg-type aot_example_inputs = aot_example_inputs ind ind preserved_arg_indices fake_mode = detect_fake_mode aot_example_inputs freezing all graph outputs should user visible _ model_outputs_node = opt_model graph nodes model_outputs = model_outputs_node args model_outputs_node meta user_visible_output_idxs = idx idx n enumerate model_outputs isinstance n torch fx Node static_input_idxs list Any = constant params will real tensors fake tracing_context = torch _guards TracingContext try_get unwrapped_args_offsets = max_offset_idx = tracing_context None assert tracing_context params_flat_unwrap_subclasses None params_flat_unwrap = tracing_context params_flat_unwrap_subclasses max_offset_idx = max len params_flat_unwrap - preserved_indices_params_flat = OrderedSet int unwrapped_idxs = tracing_context params_unwrapped_to_flat_index assert unwrapped_idxs None current_offset = len params_flat_unwrap unwrapped_args_offsets = i range len params_flat_unwrap i preserved_arg_indices params_flat_unwrap i = None i unwrapped_idxs i == unwrapped_idxs i - current_offset += preserved_indices_params_flat add unwrapped_idxs i unwrapped_args_offsets append current_offset Deallocate wrapped params all subelements deallocated assert tracing_context params_flat None i range len tracing_context params_flat i preserved_indices_params_flat tracing_context params_flat i = None tracing_context fw_metadata static_input_idxs = tracing_context fw_metadata static_input_indices mock patch object fake_mode allow_non_fake_inputs True optimized_function = inner_compile opt_model aot_example_inputs static_input_idxs=static_input_idxs cudagraphs=cudagraphs graph_id=graph_id is_inference=True boxed_forward_device_index=forward_device layout_opt=layout_opt aot_inductor codegens call takes just inputs so we don t wrapper drops constant-ified params V aot_compilation optimized_function wrapper args list object - Sequence torch Tensor args_new = args i - unwrapped_args_offsets min i max_offset_idx i preserved_arg_indices args clear optimized_function args_new wrapper _boxed_call = True type ignore attr-defined wrapper get_cpp_wrapper_config - dict str object config triton cudagraphs log_cudagraph_skip_and_bump_counter format_default_skip_message cpp wrapper enabled Set autotune_at_compile_time True default option explicitly set triton autotune_at_compile_time config triton autotune_at_compile_time config triton autotune_at_compile_time None has_triton triton autotune_cublasLt False triton cudagraphs False TODO removed triton store_cubin True get_cuda_device_context gm torch fx GraphModule - AbstractContextManager None Returns cuda device context manager there single device graph torch cuda is_available contextlib nullcontext cuda_devices OrderedSet torch device = OrderedSet device device get_all_devices gm device type == cuda torch cuda device next iter cuda_devices type ignore return-value len cuda_devices == contextlib nullcontext partition_fn gm GraphModule joint_inputs Sequence object kwargs object - tuple GraphModule GraphModule cuda_context = get_cuda_device_context gm cuda_context We can skip invoke_subgraph because entire_partition_fn called recursively invoke_subgraph partitioning _recursive_joint_graph_passes gm skip_invoke_subgraph=True static_lifetime_input_indices Optional list int = kwargs pop type ignore assignment static_lifetime_input_indices None config custom_partitioner_fn None dynamo_utils dynamo_timed min_cut_rematerialization_partition log_pt _compile_event=True min_cut_rematerialization_partition gm joint_inputs compiler= inductor static_lifetime_input_indices=static_lifetime_input_indices kwargs assert isinstance config custom_partitioner_fn CustomPartitionerFn dynamo_utils dynamo_timed config custom_partitioner_fn __class__ __name__ log_pt _compile_event=True config custom_partitioner_fn gm joint_inputs compiler= inductor static_lifetime_input_indices=static_lifetime_input_indices kwargs get_num_model_outputs model GraphModule - int model_outputs_node = output_node model model_outputs = pytree arg_tree_leaves model_outputs_node args len model_outputs dataclass frozen=True CompilerConfigExtra cudagraphs BoxedBool graph_id int forward_device BoxedDeviceIndex create_compiler_config_extra config types ModuleType - CompilerConfigExtra Although cudagraphs may have been enabled via config various conditions which tested within bowels Inductor may force cudagraphs disabled This mutable box lets us retrieve final determination cudagraphs actually can used cudagraphs = BoxedBool config triton cudagraphs TODO The modern style use CompileId TracingContext identify Inductor compilation However CompileId cannot uniquely identify multiple Inductor compilations arise DDPOptimizer graph_id = next _graph_counter See Backward Generation Handling forward_device = BoxedDeviceIndex None CompilerConfigExtra cudagraphs=cudagraphs graph_id=graph_id forward_device=forward_device compile_fx_forward gm GraphModule example_inputs Sequence InputType num_orig_model_outputs int num_example_inputs int compiler_config_extra CompilerConfigExtra inner_compile Callable OutputCode = compile_fx_inner is_inference bool = False - OutputCode Compile forward graph given graph module Args gm The graph module compile example_inputs The example inputs use compilation num_orig_model_outputs The number model outputs original dynamo graph num_example_inputs The number example inputs original dynamo graph compiler_config_extra Extra configuration compiler inner_compile The inner compile function use is_inference Whether inference graph is_inference partition_fn won t called trace_structured artifact metadata_fn=lambda name before_joint_graph encoding string payload_fn=lambda gm print_readable print_output=False include_stride=True include_device=True _recursive_joint_graph_passes gm trace_structured artifact metadata_fn=lambda name after_joint_graph encoding string payload_fn=lambda gm print_readable print_output=False include_stride=True include_device=True fixed = torch _inductor utils num_fw_fixed_arguments num_example_inputs len example_inputs model_outputs_node = output_node gm config keep_output_stride model_outputs = pytree arg_tree_leaves model_outputs_node args num_model_outputs = len model_outputs context = torch _guards TracingContext try_get See Note User Outputs inductor graph context None context fw_metadata is_inference original_output_start_index = context fw_metadata num_mutated_inp_runtime_indices original_output_start_index = assert num_orig_model_outputs = num_model_outputs Note User Outputs inductor graph We makes following assumption For inference len orig_model_outputs == len model_outputs For training len orig_model_outputs = len model_outputs During training most time model_outputs starts original module s outputs followed saved activations But can true model have inplace updated tensors AOTAutograd will make those tensors being returned before original module s output To make things safe we ll use original_output_start_index field set AOTAutograd decide where original module outputs start orig_output_end_idx = original_output_start_index + num_orig_model_outputs Sanity check we about splice out user outputs full set graph outputs Make sure we re within bounds assert orig_output_end_idx = num_model_outputs model_outputs_node meta user_visible_output_idxs = idx idx range original_output_start_index orig_output_end_idx isinstance model_outputs idx torch fx Node model_outputs_node meta user_visible_output_idxs = We also mark invoke_subgraph outputs user_visible force outputs invoke_subgraph subgraph follow original strides _recursive_record_user_visible_output_idxs gm inner_compile gm example_inputs static_input_idxs=get_static_input_idxs fixed cudagraphs=compiler_config_extra cudagraphs graph_id=compiler_config_extra graph_id is_inference=is_inference boxed_forward_device_index=compiler_config_extra forward_device compile_fx_backward gm GraphModule example_inputs Sequence InputType compiler_config_extra CompilerConfigExtra inner_compile Callable OutputCode = compile_fx_inner - OutputCode Compile backward graph given graph module Args gm The graph module compile example_inputs The example inputs use compilation compiler_config_extra Extra configuration compiler inner_compile The inner compile function use torch _dynamo convert_frame compile_lock compile_lock model_outputs_node = output_node gm config bw_outputs_user_visible model_outputs = pytree arg_tree_leaves model_outputs_node args model_outputs_node meta user_visible_output_idxs = idx idx n enumerate model_outputs isinstance n torch fx Node model_outputs_node meta user_visible_output_idxs = fixed = count_tangents gm config patch get_cpp_wrapper_config config cpp_wrapper contextlib nullcontext inner_compile gm example_inputs static_input_idxs=list range fixed cudagraphs=compiler_config_extra cudagraphs is_backward=True graph_id=compiler_config_extra graph_id boxed_forward_device_index=compiler_config_extra forward_device run_pre_grad_passes model_ GraphModule example_inputs_ Sequence InputType - GraphModule before_pre_grad_graph used inductor provenance tracking highlighter front-end trace_structured artifact metadata_fn=lambda name before_pre_grad_graph encoding string payload_fn=lambda model_ print_readable print_output=False include_stride=True include_device=True + f \n\n graph id id model_ graph pre_grad_graphs_log debug s lazy_format_graph_code BEFORE PRE GRAD model_ include_stride=True include_device=True colored=True torch _inductor debug _pre_grad_graph_id = id model_ graph config trace provenance_tracking_level == node model_ graph nodes node stack_trace torch _inductor debug _inductor_pre_grad_node_stack_trace node name = node stack_trace model_ = _recursive_pre_grad_passes model_ example_inputs_ trace_structured artifact metadata_fn=lambda name after_pre_grad_graph encoding string payload_fn=lambda model_ print_readable print_output=False include_stride=True include_device=True + f \n\n graph id id model_ graph model_ compile_fx model_ GraphModule example_inputs_ Sequence InputType inner_compile Callable OutputCode = compile_fx_inner config_patches Optional dict str Any = None decompositions Optional dict OpOverload Callable Any = None ignore_shape_env bool = False - CompileFxOutput Main entry point compiling given FX graph Despite fact lives mod ` torch _inductor ` function responsible calling into AOT Autograd we will eventually get callback ` ` inner_compile ` ` perform actual compilation In other words function orchestrates end-to-end compilation inductor backend when you use func ` torch compile ` NB This function TAKES OWNERSHIP input ` ` model_ ` ` can potentially mutate Make copy you need preserve original GraphModule Some arguments trigger recursive call compile_fx Handle these short circuits first before anything torch _inductor compiler_bisector CompilerBisector CompilerBisector disable_subsystem inductor pre_grad_graph model_ config_patches config patch config_patches compile_fx model_ example_inputs_ need extra layer patching backwards compiled out scope inner_compile=config patch config_patches inner_compile decompositions=decompositions ignore_shape_env=ignore_shape_env Wake up AsyncCompile subproc pool early possible there s cuda any isinstance e torch Tensor e device type cuda xpu e example_inputs_ torch _inductor async_compile AsyncCompile wakeup config cpp_wrapper config fx_wrapper torch _export non_strict_utils _fakify_script_objects cpp_wrapper_config = config cpp_wrapper fx_wrapper_config = config fx_wrapper config patch get_cpp_wrapper_config V set_real_inputs example_inputs_ inputs_ Sequence InputType = _extract_inputs_from_exported_gm model_ example_inputs_ isinstance model_ GraphModule example_inputs_ fake_mode = detect_fake_mode inputs_ _fakify_script_objects model_ inputs_ fake_mode patched_mod fake_args _ _ _ _maybe_wrap_and_compile_fx_main patched_mod fake_args inner_compile=functools partial inner_compile cpp_wrapper=cpp_wrapper_config fx_wrapper=fx_wrapper_config decompositions=decompositions ignore_shape_env=ignore_shape_env _maybe_wrap_and_compile_fx_main model_ example_inputs_ inner_compile decompositions ignore_shape_env _extract_inputs_from_exported_gm gm GraphModule example_inputs_ Sequence InputType - Sequence InputType fake_inputs = node meta get val node gm graph nodes node op == placeholder Replace non-tensor constant inputs Nones since these being used anyways graph fake_inputs = inp isinstance inp torch Tensor None inp fake_inputs any v None v fake_inputs Validate devices before switching fake tensors idx fi i zip count fake_inputs example_inputs_ fi None assert isinstance i torch Tensor fi device = i device raise ValueError f Device mismatch between fake input example input position idx f fi device vs i device If model exported via torch export make sure torch export torch aot_compile run same device fake_inputs example_inputs_ _maybe_wrap_and_compile_fx_main model_ GraphModule example_inputs_ Sequence InputType inner_compile Callable OutputCode decompositions Optional dict OpOverload Callable Any ignore_shape_env bool - CompileFxOutput Part compile_fx called after patching configs Ultimately we want call _compile_fx_main where actual work happens But under various conditions various forms wrapping might needed around _compile_fx_main Each wrapper below takes self-contained compile_gm function which called inside wrapper This just recursively calls function compile_gm = functools partial _maybe_wrap_and_compile_fx_main inner_compile=inner_compile decompositions=decompositions ignore_shape_env=ignore_shape_env graph_returns_tuple model_ make_graph_return_tuple model_ example_inputs_ compile_gm isinstance model_ GraphModule isinstance model_ graph _codegen _PyTreeCodeGen graph result dynamo export handle_dynamo_export_graph model_ example_inputs_ compile_gm any isinstance x list tuple dict x example_inputs_ NB short circuit never occurs Dynamo produced graphs which pre-flattened flatten_graph_inputs model_ example_inputs_ compile_gm Finally do actual work _compile_fx_main model_ example_inputs_ inner_compile decompositions ignore_shape_env _compile_fx_main model_ GraphModule example_inputs_ Sequence InputType inner_compile Callable OutputCode decompositions Optional dict OpOverload Callable Any ignore_shape_env bool - CompileFxOutput Main part compile_fx called after wrapping done Roughly speaking here steps will apply pre-grad passes create ` fw_compiler ` ` bw_compiler ` functions out ` inner_compile ` call aot_autograd which - creates joint graph ` decompositions ` - b partitions ` partition_fn ` into fw bw graphs applying joint-graph passes - c calls ` fw_compiler ` ` bw_compiler ` those graphs applying post-grad passes - d finally assembles fw bw compiled functions back together returns _use_lazy_graph_module dynamo_config use_lazy_graph_module enable_python_dispatcher torch fx traceback preserve_node_meta config trace provenance_tracking_level == torch _inductor debug reset_provenance_globals Pre-grad passes cannot run we weren t given GraphModule Dynamo will always produce GraphModule handles cases where user directly passes plain Module intention having AOTAutograd trace TODO Get rid isinstance model_ GraphModule model_ = run_pre_grad_passes model_ example_inputs_ assert config _raise_error_for_testing num_example_inputs = len example_inputs_ compiler_config_extra = create_compiler_config_extra config decompositions = decompositions decompositions None select_decomp_table fw_compiler_base gm GraphModule example_inputs Sequence InputType is_inference bool - OutputCode dynamo_utils dynamo_timed compile_fx locals fw_compiler_base isinstance model_ GraphModule num_orig_model_outputs = get_num_model_outputs model_ num_orig_model_outputs = get_num_model_outputs gm compile_fx_forward gm example_inputs num_orig_model_outputs=num_orig_model_outputs num_example_inputs=num_example_inputs compiler_config_extra=compiler_config_extra inner_compile=inner_compile is_inference=is_inference fw_compiler Callable GraphModule Sequence InputType OutputCode = functools partial fw_compiler_base is_inference=False fw_compiler = SerializableAOTDispatchCompiler OutputCode fw_compiler config freezing torch is_grad_enabled inference_compiler Callable Any = functools partial fw_compiler_freezing dynamo_model=model_ num_example_inputs=num_example_inputs inner_compile=inner_compile cudagraphs=compiler_config_extra cudagraphs graph_id=compiler_config_extra graph_id forward_device=compiler_config_extra forward_device inference_compiler = functools partial fw_compiler_base is_inference=True inference_compiler = SerializableAOTDispatchCompiler OutputCode inference_compiler compile_time_strobelight_meta phase_name= backward bw_compiler gm GraphModule example_inputs Sequence InputType - OutputCode dynamo_utils dynamo_timed compile_fx locals bw_compiler compile_fx_backward gm example_inputs compiler_config_extra=compiler_config_extra inner_compile=inner_compile bw_compiler = SerializableAOTDispatchCompiler OutputCode bw_compiler fake_mode = detect_fake_mode example_inputs_ torch _subclasses FakeTensorMode allow_non_fake_inputs=True tracing_context = torch _guards TracingContext try_get torch _guards TracingContext fake_mode V aot_compilation utils is_valid_aoti_model_name is_valid_aoti_model_name functorch_config patch unlift_effect_tokens=True gm graph_signature = aot_export_module model_ example_inputs_ trace_joint=False decompositions=decompositions torch _export utils _detect_fake_mode_from_gm fake_mode = _detect_fake_mode_from_gm gm type ignore assignment aot_export_module doesn t account constant tensor attributes so we end up having tensors don t have fake vals attached This can happen when upstream export non-strict where we preserve original module params buffers Once AOTI switches ep run_decompositions flow lower post-autograd opset will go away node gm graph nodes node op == get_attr val node meta target = attrgetter node target gm isinstance target torch Tensor assert fake_mode None node meta val = fake_mode from_tensor target static_shapes=True isinstance target torch ScriptObject node meta val = torch _library fake_class_registry maybe_to_fake_obj fake_mode target isinstance target FakeScriptObject node meta val = target unlifted_gm = _unlift_graph model_ gm graph_signature dynamo_flat_name_to_original_fqn model_ meta unlifted_gm meta dynamo_flat_name_to_original_fqn = model_ meta dynamo_flat_name_to_original_fqn dynamo_compile_id model_ meta unlifted_gm meta dynamo_compile_id = model_ meta dynamo_compile_id Disable amp aot_dispatch_autograd https github com pytorch pytorch pull In inference_compiler fw_compiler_base _recursive_joint_graph_passes will call into _sfdp_init register patterns When fallback_random set True sdpa patterns will traced during runtime If amp turned traced FP patterns will have prims convert_element_type which will same generated FP patterns disable_amp = torch _C _is_any_autocast_enabled context = torch _C _DisableAutocast disable_amp contextlib nullcontext V set_fake_mode fake_mode compiled_autograd _disable context inference_compiler unlifted_gm example_inputs_ V set_fake_mode fake_mode torch _guards tracing tracing_context compiled_autograd _disable functorch_config patch unlift_effect_tokens=True try aot_autograd fw_compiler=fw_compiler bw_compiler=bw_compiler inference_compiler=inference_compiler decompositions=decompositions partition_fn=partition_fn keep_inference_input_mutations=True cudagraphs=compiler_config_extra cudagraphs boxed_forward_device_index=compiler_config_extra forward_device ignore_shape_env=ignore_shape_env model_ example_inputs_ except ShortenTraceback e We will also shorten traceback inside dynamo This only useful inductor called directly FX graph raise e remove_dynamo_frames None see TORCHDYNAMO_VERBOSE= graph_returns_tuple gm GraphModule - bool True FX graph returns tuple isinstance gm GraphModule True can t check assume true rv = output_node gm args isinstance rv list tuple True isinstance rv torch fx node Node hasattr rv target _schema len rv target _schema returns all str ret type == Tensor ret rv target _schema returns graphs whose result one node multiple outputs True False make_graph_return_tuple gm GraphModule inputs Sequence InputType compile_gm Callable Any - Callable Any Mutate gm so returns tuple This only needed graphs created torchdynamo non-tuples node = output_node gm rv = node args rv spec = pytree tree_flatten rv gm graph inserting_before node gm graph output rv gm graph erase_node node assert graph_returns_tuple gm compiled_fn = compile_gm gm inputs functools wraps compiled_fn wrapper args Any kwargs Any - Any pytree tree_unflatten compiled_fn args kwargs spec wrapper handle_dynamo_export_graph gm GraphModule inputs Sequence InputType compile_gm Callable Any - Callable Any ` torch _dynamo export ` embeds pytrees FX graph codegen object convert normal FX graph so inductor can compile codegen = gm graph _codegen gm graph _codegen = torch fx graph CodeGen gm recompile compiled_fn = compile_gm gm codegen process_inputs inputs functools wraps compiled_fn type ignore misc wrapper args Any - Any codegen process_outputs compiled_fn codegen process_inputs args wrapper _check_triton_bf _support graph GraphLowering - None warn_and_skip device Optional torch device - Never torch _dynamo exc SkipFrame assert device None device_interface = get_interface_for_device device type device_props = device_interface get_device_properties device warnings warn f device_props name does support bfloat compilation natively skipping raise SkipFrame BF supported node itertools chain graph graph_inputs values graph graph_outputs isinstance node IRNode continue device_type = get_device_type node device_type is_gpu device_type node get_dtype = torch bfloat continue Print warning skip frame attempting compile bfloat device without hardware support dtype device_interface = get_interface_for_device device_type device_interface is_bf _supported including_emulation=False warn_and_skip node get_device _aoti_flatten_inputs gm torch fx GraphModule args Union list Any tuple Any kwargs Optional dict str Any = None options Optional dict str Any = None - tuple list Any dict str Any Flatten inputs graph module flat inputs options Add aot_inductor serialized_in_spec aot_inductor serialized_out_spec options pyrefly ignore missing-module-attribute compile_fx graph_returns_tuple assert graph_returns_tuple gm Graph output must tuple This so we can avoid pytree processing outputs Please change module have tuple outputs We will serialize pytree info into so constant strings in_spec = None out_spec = None isinstance gm graph _codegen torch fx graph _PyTreeCodeGen codegen = gm graph _codegen gm graph _codegen = torch fx graph CodeGen gm recompile codegen pytree_info in_spec None in_spec = codegen pytree_info in_spec codegen pytree_info out_spec None out_spec = codegen pytree_info out_spec hasattr gm _in_spec in_spec = gm _in_spec hasattr gm _out_spec out_spec = gm _out_spec serialized_in_spec = pytree treespec_dumps in_spec in_spec None serialized_out_spec = pytree treespec_dumps out_spec out_spec None flat_args_with_path received_spec = pytree tree_flatten_with_path args kwargs any isinstance x torch ScriptObject x flat_args_with_path torch _dynamo exc UserError UserErrorType raise UserError UserErrorType INVALID_INPUT TorchBind objects found inputs TorchBind object inputs supported AOTInductor TorchBind objects can only attributes Replace non-tensor constant inputs Nones since these being used anyways graph flat_example_inputs = x isinstance x torch Tensor None x flat_args_with_path in_spec None received_spec = in_spec raise ValueError noqa B Trying flatten user inputs exported input tree spec \n f in_spec \n actually got inputs tree spec \n f received_spec options = aot_inductor serialized_in_spec serialized_in_spec aot_inductor serialized_out_spec serialized_out_spec options None options aot_inductor serialized_in_spec serialized_in_spec aot_inductor serialized_out_spec serialized_out_spec flat_example_inputs options