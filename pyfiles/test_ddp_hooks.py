Owner s oncall distributed os sys torch torch distributed dist torch nn dist is_available print Distributed available skipping tests file=sys stderr sys exit torch distributed algorithms ddp_comm_hooks DDPCommHookType register_ddp_comm_hook torch nn parallel DistributedDataParallel torch testing _internal common_distributed MultiProcessTestCase requires_nccl skip_if_lt_x_gpu torch testing _internal common_utils run_tests TEST_WITH_DEV_DBG_ASAN TEST_WITH_DEV_DBG_ASAN print Multiprocessing spawn compatible dev dbg asan file=sys stderr sys exit gpus_for_rank world_size visible_devices = list range torch cuda device_count gpus_per_process = torch cuda device_count world_size gpus_for_rank = rank range world_size gpus_for_rank append visible_devices rank gpus_per_process rank + gpus_per_process gpus_for_rank Task nn Module __init__ - None super __init__ torch manual_seed p = nn Parameter torch randn forward x p x TestDdpCommHook nn Module __init__ - None super __init__ t = Task forward x rank t x + rank DistributedDataParallelCommHookTest MultiProcessTestCase setUp super setUp _spawn_processes tearDown try os remove file_name except OSError pass _get_process_group_nccl store = dist FileStore file_name world_size dist init_process_group backend= nccl world_size=self world_size rank=self rank store=store dist distributed_c d _get_default_group property world_size _local_model local_model = TestDdpCommHook cpu local_model _get_grads process_group hook_type=None device_id = gpus_for_rank world_size rank gpu_model = DistributedDataParallel TestDdpCommHook device_id device_ids= device_id process_group=process_group Register DDP Communication Hook defined hook_type None register_ddp_comm_hook comm_hook_type=hook_type model=gpu_model state=process_group _run_and_get_grads gpu_model _run_and_get_grads model torch manual_seed input = torch randn Run forward output = model input rank Run backward output mean backward The only layer param = next model parameters param grad requires_nccl skip_if_lt_x_gpu test_ddp_comm_hook_allreduce_hook This unit test verifies ` ` allreduce ` ` hook registered case gives same result no hook registered case process_group = _get_process_group_nccl No hook registered case get reference grads reference_grads = _get_grads process_group None Register hook case get hook grads hook_grads = _get_grads process_group DDPCommHookType ALLREDUCE torch testing assert_close hook_grads reference_grads rtol= e- atol= requires_nccl skip_if_lt_x_gpu test_ddp_comm_hook_fp compress_hook This unit test verifies ` ` fp compress ` ` hook registered case gives close result no hook registered case process_group = _get_process_group_nccl No hook registered case get reference grads reference_grads = _get_grads process_group None Register hook case get hook grads hook_grads = _get_grads process_group DDPCommHookType FP _COMPRESS torch testing assert_close hook_grads reference_grads rtol= e- atol= e- requires_nccl skip_if_lt_x_gpu test_ddp_comm_hook_quantize_per_tensor_hook This unit test verifies ` ` quantize per tensor ` ` hook registered case gives close result no hook registered case process_group = _get_process_group_nccl No hook registered case get reference grads reference_grads = _get_grads process_group None Register hook case get hook grads hook_grads = _get_grads process_group DDPCommHookType QUANTIZE_PER_TENSOR torch testing assert_close hook_grads reference_grads rtol= e- atol= e- requires_nccl skip_if_lt_x_gpu test_ddp_comm_hook_quantize_per_channel_hook This unit test verifies ` ` quantize per channel ` ` hook registered case gives close result no hook registered case process_group = _get_process_group_nccl No hook registered case get reference grads reference_grads = _get_grads process_group None Register hook case get hook grads hook_grads = _get_grads process_group DDPCommHookType QUANTIZE_PER_CHANNEL torch testing assert_close hook_grads reference_grads rtol= e- atol= e- requires_nccl skip_if_lt_x_gpu test_ddp_comm_hook_noop_hook This unit test verifies ` ` noop ` ` hook registered case subsequent allreduce gives same result no hook registered case process_group = _get_process_group_nccl No hook registered case get reference grads reference_grads = _get_grads process_group None Register hook case get hook grads hook_grads = _get_grads process_group DDPCommHookType NOOP Apply subsequent allreduce average grads hook_grads div_ world_size dist all_reduce hook_grads group=process_group torch testing assert_close hook_grads reference_grads rtol= e- atol= requires_nccl skip_if_lt_x_gpu test_is_last_hook process_group = _get_process_group_nccl hook flags bucket flags append bucket is_last fut = torch futures Future fut set_result bucket buffer fut flags = device_id = gpus_for_rank world_size rank model = nn Sequential nn Linear bias=False nn Linear bias=False _ range gpu_model = DistributedDataParallel model device_id device_ids= device_id process_group=process_group gpu_model register_comm_hook state=flags hook=hook input = torch randn gpu_model input sum backward assertTrue flags - assertFalse any flags - __name__ == __main__ assert torch cuda _initialized test_distributed must have initialized CUDA context main process run_tests