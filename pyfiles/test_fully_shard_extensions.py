Owner s oncall distributed contextlib copy functools math threading typing Any Optional Union torch torch distributed dist torch nn nn torch utils _pytree pytree torch autograd grad_mode _unsafe_preserve_version_counter torch distributed device_mesh DeviceMesh init_device_mesh torch distributed fsdp fully_shard MixedPrecisionPolicy torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp check_sharded_parity FSDPTest FSDPTestMultiThread get_devtype MLP torch testing _internal common_utils run_tests torch testing _internal two_tensor TwoTensor device_type = torch device get_devtype two_tensor_fsdp_pre_all_gather_v mesh DeviceMesh - tuple tuple torch Tensor Any all_gather_inputs = b metadata = None all_gather_inputs metadata two_tensor_fsdp_pre_all_gather_v mesh DeviceMesh outer_size torch Size outer_stride tuple int module nn Module mp_policy MixedPrecisionPolicy - tuple tuple torch Tensor Any all_gather_inputs = b metadata = None all_gather_inputs metadata two_tensor_fsdp_post_all_gather all_gather_outputs tuple torch Tensor metadata Any param_dtype torch dtype out Optional torch Tensor = None - Union tuple torch Tensor tuple torch Tensor None assert metadata None f metadata b = all_gather_outputs out None assert isinstance out TwoTensor f type out dtype == param_dtype assert untyped_storage data_ptr == out untyped_storage data_ptr assert b untyped_storage data_ptr == out b untyped_storage data_ptr assert out dtype == param_dtype f out dtype param_dtype assert out b dtype == param_dtype f out b dtype param_dtype out copy_ out b copy_ b tensors_to_free = b If cast real then all-gather outputs will alias returned ` TwoTensor ` s ` ` ` b ` two_tensor = TwoTensor b param_dtype two_tensor tensors_to_free BFloat AllGatherTensor torch Tensor staticmethod __new__ cls data torch Tensor pad_in_pre_all_gather bool = True torch Tensor _make_wrapper_subclass cls data shape data stride data storage_offset dtype=data dtype device=data device __init__ data torch Tensor pad_in_pre_all_gather bool = True _data = data _pad_in_pre_all_gather = pad_in_pre_all_gather fsdp_pre_all_gather mesh DeviceMesh outer_size torch Size outer_stride tuple int module nn Module mp_policy MixedPrecisionPolicy - tuple tuple torch Tensor Any assert mesh ndim == f mesh ndim mesh_size = mesh size requires_padding = outer_size mesh_size = requires_padding _pad_in_pre_all_gather sharded_padded_size = list outer_size sharded_padded_size = math ceil outer_size mesh_size padded_out = torch empty sharded_padded_size dtype=torch bfloat device=self device padded_out _data size copy_ _data padded_out None _data torch bfloat None fsdp_post_all_gather all_gather_outputs tuple torch Tensor metadata Any param_dtype torch dtype out Optional torch Tensor = None - Union tuple torch Tensor tuple torch Tensor None assert metadata None f metadata tensor = all_gather_outputs assert tensor dtype == torch bfloat f tensor dtype out None _unsafe_preserve_version_counter out out copy_ tensor upcast_tensor = tensor param_dtype upcast_tensor tensor upcast_tensor classmethod __torch_dispatch__ cls func types args kwargs pad_in_pre_all_gather = None unwrap x cls nonlocal pad_in_pre_all_gather pad_in_pre_all_gather None pad_in_pre_all_gather = x _pad_in_pre_all_gather assert pad_in_pre_all_gather == x _pad_in_pre_all_gather x _data out = func pytree tree_map_only cls unwrap args pytree tree_map_only cls unwrap kwargs pytree tree_map_only torch Tensor lambda x cls x pad_in_pre_all_gather out __tensor_flatten__ _data None staticmethod __tensor_unflatten__ inner_tensors outer_size torch Size outer_stride tuple int inner_tensors _data __repr__ f __class__ __name__ _data TestFullyShardAllGatherExtensionsCommon property world_size - int contextlib contextmanager _patch_two_tensor_fsdp_all_gather pre_all_gather_version int lock = threading Lock pre_all_gather_version == TwoTensor fsdp_pre_all_gather = two_tensor_fsdp_pre_all_gather_v pre_all_gather_version == TwoTensor fsdp_pre_all_gather = two_tensor_fsdp_pre_all_gather_v TwoTensor fsdp_post_all_gather = two_tensor_fsdp_post_all_gather dist barrier try yield finally dist barrier lock only one thread needs delete hasattr TwoTensor fsdp_pre_all_gather delattr TwoTensor fsdp_pre_all_gather hasattr TwoTensor fsdp_post_all_gather delattr TwoTensor fsdp_post_all_gather _init_two_tensor_mlp - nn Module Disable bias because reference model will end up bias gradient ` TwoTensor ` whereas FSDP model does model = nn Sequential MLP bias=False _ range mlp model mlp in_proj weight = nn Parameter TwoTensor mlp in_proj weight mlp in_proj weight clone mlp out_proj weight = nn Parameter TwoTensor mlp out_proj weight mlp out_proj weight clone model TestFullyShardAllGatherExtensionsMultiProcess TestFullyShardAllGatherExtensionsCommon FSDPTest skip_if_lt_x_gpu test_all_gather_extensions_train_parity _patch_two_tensor_fsdp_all_gather pre_all_gather_version= run_subtests reshard_after_forward True False _test_all_gather_extensions_train_parity _patch_two_tensor_fsdp_all_gather pre_all_gather_version= run_subtests reshard_after_forward True False _test_all_gather_extensions_train_parity _test_all_gather_extensions_train_parity reshard_after_forward bool torch manual_seed model = _init_two_tensor_mlp ref_model = copy deepcopy model device_type ref_optim = torch optim Adam ref_model parameters lr= e- foreach=True fully_shard_fn = functools partial fully_shard reshard_after_forward=reshard_after_forward mlp model fully_shard_fn mlp fully_shard_fn model optim = torch optim Adam model parameters lr= e- foreach=True check_sharded_parity ref_model model torch manual_seed + rank + inp = torch randn device=device_type iter_idx range losses list torch Tensor = _model ref_model model losses append _model inp sum losses - backward _model ref_model _ param _model named_parameters dist all_reduce param grad param grad detach div_ world_size assertEqual losses losses check_sharded_parity ref_model model _optim ref_optim optim _optim step _optim zero_grad set_to_none= iter_idx == check_sharded_parity ref_model model TestFullyShardAllGatherExtensionsMultiThread TestFullyShardAllGatherExtensionsCommon FSDPTestMultiThread property world_size - int property device - torch device torch device device_type skip_if_lt_x_gpu test_all_gather_extensions_end_to_end _patch_two_tensor_fsdp_all_gather pre_all_gather_version= run_subtests reshard_after_forward True False _test_all_gather_extensions_end_to_end _patch_two_tensor_fsdp_all_gather pre_all_gather_version= run_subtests reshard_after_forward True False _test_all_gather_extensions_end_to_end _test_all_gather_extensions_end_to_end reshard_after_forward bool Check we can run meta-device initialization flow torch device meta model = _init_two_tensor_mlp param model parameters assertEqual param device torch device meta fully_shard_fn = functools partial fully_shard reshard_after_forward=reshard_after_forward mp_policy=MixedPrecisionPolicy param_dtype=torch bfloat mlp model fully_shard_fn mlp fully_shard_fn model model to_empty device=self device param model parameters nn init trunc_normal_ param optim = torch optim Adam model parameters lr= e- foreach=True Run few iterations check errors torch manual_seed + rank + inp = torch randn device=device_type _ range model inp sum backward optim step optim zero_grad skip_if_lt_x_gpu test_all_gather_extensions_monkey_patch tls = threading local tls ran_pre_all_gather = False Define pre post-all-gather pair quantizes bf all-gather de-quantizes back parameter dtype fsdp_pre_all_gather mesh DeviceMesh outer_size torch Size outer_stride tuple int module nn Module mp_policy MixedPrecisionPolicy - tuple tuple torch Tensor Any nonlocal tls tls ran_pre_all_gather = True torch bfloat None torch no_grad fsdp_post_all_gather all_gather_outputs tuple torch Tensor metadata Any param_dtype torch dtype out Optional torch Tensor = None - Union tuple torch Tensor tuple torch Tensor None tensor = all_gather_outputs assert metadata None f metadata assert tensor dtype == torch bfloat f tensor dtype out None _unsafe_preserve_version_counter out out copy_ tensor upcast_tensor = tensor param_dtype upcast_tensor tensor upcast_tensor torch device meta model = _init_two_tensor_mlp mlp model fully_shard mlp fully_shard model model to_empty device=self device param model parameters nn init trunc_normal_ param Monkey patch pre post-all-gather functions after ` to_empty ` since local tensor objects change materialization assertGreater sum weight n n _ model named_parameters param_name param model named_parameters weight param_name Need use ` _local_tensor ` patch tensor object local_param = param _local_tensor Monkey patch ` torch Tensor ` instance methods show extension can work even without subclass local_param fsdp_pre_all_gather = fsdp_pre_all_gather __get__ local_param local_param fsdp_post_all_gather = fsdp_post_all_gather __get__ local_param optim = torch optim Adam model parameters lr= e- foreach=True Run few iterations check errors torch manual_seed + rank + inp = torch randn device=device_type _ range model inp sum backward optim step optim zero_grad assert tls ran_pre_all_gather skip_if_lt_x_gpu test_all_gather_extension_outer_size_stride NOTE We cannot easily test incorrect case where user-defined ` ` fsdp_pre_all_gather ` ` does correctly pad local tensor because only some ranks may require padding which case only those ranks will error out all-gather will timeout assert world_size = f Assumes world size least got world_size= model = MLP dim= dim_multiplier= module model modules param_name param module named_parameters recurse=False weight param_name param = nn Parameter BFloat AllGatherTensor param setattr module param_name param need fix reshard_after_forward=True https github com pytorch pytorch issues fully_shard model reshard_after_forward=False optim = torch optim AdamW model parameters lr= e- fused=True torch manual_seed + rank + inp = torch randn device=device_type loss = model inp sum loss backward optim step optim zero_grad skip_if_lt_x_gpu test_all_gather_extension_hsdp_mesh tls = threading local replicate_size = shard_size = world_size replicate_size mesh = init_device_mesh device_type type replicate_size shard_size mesh_dim_names= dp_replicate dp_shard fsdp_pre_all_gather mesh DeviceMesh outer_size torch Size outer_stride tuple int module nn Module mp_policy MixedPrecisionPolicy - tuple tuple torch Tensor Any nonlocal tls tls mesh = mesh None torch no_grad fsdp_post_all_gather all_gather_outputs tuple torch Tensor metadata Any param_dtype torch dtype out Optional torch Tensor = None - Union tuple torch Tensor tuple torch Tensor None tensor = all_gather_outputs out None tensor tensor model = _init_two_tensor_mlp mlp model fully_shard mlp mesh=mesh fully_shard model mesh=mesh assertGreater sum weight n n _ model named_parameters param_name param model named_parameters weight param_name Need use ` _local_tensor ` patch tensor object local_param = param _local_tensor Monkey patch ` torch Tensor ` instance methods show extension can work even without subclass local_param fsdp_pre_all_gather = fsdp_pre_all_gather __get__ local_param local_param fsdp_post_all_gather = fsdp_post_all_gather __get__ local_param inp = torch randn device=device_type model inp Check FSDP passes only shard mesh pre-all-gather assertEqual tls mesh ndim assertEqual tls mesh size shard_size __name__ == __main__ run_tests