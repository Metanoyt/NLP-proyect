The model here https github com pytorch examples blob master word_language_model model py typing Optional torch torch nn nn torch Tensor RNNModel nn Module Container module encoder recurrent module decoder __init__ rnn_type ntoken ninp nhid nlayers dropout= tie_weights=False batchsize= super __init__ drop = nn Dropout dropout encoder = nn Embedding ntoken ninp rnn_type LSTM GRU rnn = getattr nn rnn_type ninp nhid nlayers dropout=dropout try nonlinearity = RNN_TANH tanh RNN_RELU relu rnn_type except KeyError raise ValueError An invalid option ` -- model ` supplied options LSTM GRU RNN_TANH RNN_RELU None rnn = nn RNN ninp nhid nlayers nonlinearity=nonlinearity dropout=dropout decoder = nn Linear nhid ntoken Optionally tie weights Using Output Embedding Improve Language Models Press Wolf https arxiv org abs Tying Word Vectors Word Classifiers A Loss Framework Language Modeling Inan et al https arxiv org abs tie_weights nhid = ninp raise ValueError When using tied flag nhid must equal emsize decoder weight = encoder weight init_weights rnn_type = rnn_type nhid = nhid nlayers = nlayers hidden = init_hidden batchsize staticmethod repackage_hidden h Detach hidden states their history isinstance h torch Tensor h detach tuple RNNModel repackage_hidden v v h init_weights initrange = encoder weight data uniform_ -initrange initrange decoder bias data fill_ decoder weight data uniform_ -initrange initrange forward input hidden emb = drop encoder input output hidden = rnn emb hidden output = drop output decoded = decoder output view output size output size output size hidden = RNNModel repackage_hidden hidden decoded view output size output size decoded size init_hidden bsz weight = next parameters data rnn_type == LSTM weight new nlayers bsz nhid zero_ weight new nlayers bsz nhid zero_ weight new nlayers bsz nhid zero_ RNNModelWithTensorHidden RNNModel Supports GRU scripting staticmethod repackage_hidden h Detach hidden states their history h detach forward input Tensor hidden Tensor emb = drop encoder input output hidden = rnn emb hidden output = drop output decoded = decoder output view output size output size output size hidden = RNNModelWithTensorHidden repackage_hidden hidden decoded view output size output size decoded size RNNModelWithTupleHidden RNNModel Supports LSTM scripting staticmethod repackage_hidden h tuple Tensor Tensor Detach hidden states their history h detach h detach forward input Tensor hidden Optional tuple Tensor Tensor = None emb = drop encoder input output hidden = rnn emb hidden output = drop output decoded = decoder output view output size output size output size hidden = repackage_hidden tuple hidden decoded view output size output size decoded size