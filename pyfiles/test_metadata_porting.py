Owner s oncall quantization copy unittest torch torch _export torch ao quantization quantize_pt e convert_pt e prepare_pt e torch ao quantization quantizer QuantizationAnnotation Quantizer torch ao quantization quantizer xnnpack_quantizer get_symmetric_quantization_config torch ao quantization quantizer xnnpack_quantizer_utils OP_TO_ANNOTATOR torch fx Node torch testing _internal common_quantization QuantizationTestCase torch testing _internal common_utils IS_WINDOWS raise_on_run_directly skipIfCrossRef TestHelperModules Conv dWithObsSharingOps torch nn Module __init__ - None super __init__ conv = torch nn Conv d hardtanh = torch nn Hardtanh adaptive_avg_pool d = torch nn AdaptiveAvgPool d linear = torch nn Linear forward x x = conv x x = adaptive_avg_pool d x x = hardtanh x x = x view - x = linear x x _tag_partitions backend_name str op_name str annotated_partitions list list Node index partition_nodes enumerate annotated_partitions tag_name = backend_name + _ + op_name + _ + str index node partition_nodes assert quantization_tag node meta f node already tagged node meta quantization_tag = tag_name _QUANT_OPS = torch ops quantized_decomposed quantize_per_tensor default torch ops quantized_decomposed dequantize_per_tensor default torch ops quantized_decomposed quantize_per_tensor tensor torch ops quantized_decomposed dequantize_per_tensor tensor torch ops quantized_decomposed quantize_per_channel default torch ops quantized_decomposed dequantize_per_channel default torch ops quantized_decomposed choose_qparams tensor TODO rename TestPortMetadataPass align util name unittest skipIf IS_WINDOWS Windows yet supported torch compile TestMetaDataPorting QuantizationTestCase _test_quant_tag_preservation_through_decomp model example_inputs from_node_to_tags ep = torch export export model example_inputs strict=True found_tags = True not_found_nodes = from_node tag from_node_to_tags items n ep graph_module graph nodes from_node_meta = n meta get from_node None from_node_meta None continue isinstance from_node_meta list raise ValueError f from_node metadata type type from_node_meta expected list meta from_node_meta node_target = meta target node_target == str from_node node_tag = n meta get quantization_tag None node_tag None tag = node_tag not_found_nodes += str n target + found_tags = False break found_tags break assertTrue found_tags f Decomposition did preserve quantization tag not_found_nodes _test_metadata_porting model example_inputs quantizer node_tags=None - torch fx GraphModule m_eager = model eval program capture m = copy deepcopy m_eager m = torch export export m example_inputs strict=True module m = prepare_pt e m quantizer Calibrate m example_inputs m = convert_pt e m m example_inputs recorded_node_tags = n m graph nodes quantization_tag n meta continue n op == call_function n target _QUANT_OPS key = n target n op == get_attr key = get_attr continue key recorded_node_tags recorded_node_tags key = set n op == call_function n meta quantization_tag recorded_node_tags key raise ValueError f key n format_node has tag n meta quantization_tag associated another node same type recorded_node_tags key add n meta quantization_tag assertEqual set recorded_node_tags keys set node_tags keys k v recorded_node_tags items assertEqual v node_tags k m skipIfCrossRef mlazos retracing FX graph torch function mode doesn t propagate metadata because stack trace mode torch function impl doesn t match traced graph stored lineno test_simple_metadata_porting Model under test conv d - avgpool - hardtanh - linear Check quantization tags conv d avgpool linear correctly set BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule backend_string = BackendA quantization_config = get_symmetric_quantization_config is_per_channel=True annotated_partitions = OP_TO_ANNOTATOR linear gm quantization_config _tag_partitions backend_string linear annotated_partitions annotated_partitions = OP_TO_ANNOTATOR conv gm quantization_config _tag_partitions backend_string conv d annotated_partitions annotated_partitions = OP_TO_ANNOTATOR adaptive_avg_pool d gm quantization_config _tag_partitions backend_string adaptive_avg_pool d annotated_partitions validate model torch fx GraphModule - None pass example_inputs = torch randn get_attr_tags = BackendA_conv d_ BackendA_linear_ quantize_per_tensor_tags = BackendA_conv d_ BackendA_adaptive_avg_pool d_ BackendA_linear_ dequantize_per_tensor_tags = BackendA_adaptive_avg_pool d_ BackendA_conv d_ BackendA_linear_ dequantize_per_channel_tags = BackendA_conv d_ BackendA_linear_ node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor default quantize_per_tensor_tags torch ops quantized_decomposed dequantize_per_tensor default dequantize_per_tensor_tags torch ops quantized_decomposed dequantize_per_channel default dequantize_per_channel_tags m = _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags from_node_to_tags = torch ops aten adaptive_avg_pool d default BackendA_adaptive_avg_pool d_ torch ops aten linear default BackendA_linear_ _test_quant_tag_preservation_through_decomp m example_inputs from_node_to_tags test_metadata_porting_with_no_quant_inbetween Model under test conv d - avgpool - hardtanh - linear Dont quantize avgpool Check quantization tags conv d linear correctly set BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule backend_string = BackendA quantization_config = get_symmetric_quantization_config is_per_channel=True annotated_partitions = OP_TO_ANNOTATOR linear gm quantization_config _tag_partitions backend_string linear annotated_partitions annotated_partitions = OP_TO_ANNOTATOR conv gm quantization_config _tag_partitions backend_string conv d annotated_partitions validate model torch fx GraphModule - None pass example_inputs = torch randn get_attr_tags = BackendA_conv d_ BackendA_linear_ quantize_per_tensor_tags = BackendA_conv d_ BackendA_linear_ dequantize_per_tensor_tags = BackendA_conv d_ BackendA_linear_ dequantize_per_channel_tags = BackendA_conv d_ BackendA_linear_ node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor default quantize_per_tensor_tags torch ops quantized_decomposed dequantize_per_tensor default dequantize_per_tensor_tags torch ops quantized_decomposed dequantize_per_channel default dequantize_per_channel_tags _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags unittest skip Temporarily disabled test_metadata_porting_for_dq Model under test conv d - avgpool - hardtanh - linear Quantize all except linear Quantize linear dynamic quantization Check quantization tags conv d avgpool linear correctly set BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule backend_string = BackendA static quantiazation quantization_config = get_symmetric_quantization_config is_per_channel=True annotated_partitions = OP_TO_ANNOTATOR conv gm quantization_config _tag_partitions backend_string conv d annotated_partitions annotated_partitions = OP_TO_ANNOTATOR adaptive_avg_pool d gm quantization_config _tag_partitions backend_string adaptive_avg_pool d annotated_partitions dynamic quantization quantization_config_dynamic = get_symmetric_quantization_config is_per_channel=True is_dynamic=True annotated_partitions = OP_TO_ANNOTATOR linear gm quantization_config_dynamic _tag_partitions backend_string linear_dynamic annotated_partitions validate model torch fx GraphModule - None pass example_inputs = torch randn TODO add get_attr_tags when test re-enabled get_attr_tags = quantize_per_tensor_tags = BackendA_conv d_ BackendA_adaptive_avg_pool d_ quantize_per_tensor_tensor_tags = BackendA_linear_dynamic_ choose_qparams_tensor_tensor_tags = BackendA_linear_dynamic_ dequantize_per_tensor_tags = BackendA_adaptive_avg_pool d_ BackendA_conv d_ dequantize_per_tensor_tensor_tags = BackendA_linear_dynamic_ dequantize_per_channel_tags = BackendA_conv d_ BackendA_linear_dynamic_ node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor default quantize_per_tensor_tags torch ops quantized_decomposed quantize_per_tensor tensor quantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_tensor default dequantize_per_tensor_tags torch ops quantized_decomposed dequantize_per_tensor tensor dequantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_channel default dequantize_per_channel_tags torch ops quantized_decomposed choose_qparams tensor choose_qparams_tensor_tensor_tags _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags test_metadata_porting_for_two_dq Model under test conv d - avgpool - hardtanh - linear Quantize linear conv dynamic quantization Check quantization tags conv d avgpool linear correctly set BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule backend_string = BackendA dynamic quantization quantization_config_dynamic = get_symmetric_quantization_config is_per_channel=True is_dynamic=True annotated_partitions = OP_TO_ANNOTATOR conv gm quantization_config_dynamic _tag_partitions backend_string conv d_dynamic annotated_partitions annotated_partitions = OP_TO_ANNOTATOR linear gm quantization_config_dynamic _tag_partitions backend_string linear_dynamic annotated_partitions validate model torch fx GraphModule - None pass example_inputs = torch randn get_attr_tags = BackendA_conv d_dynamic_ BackendA_linear_dynamic_ choose_qparams_tensor_tags = BackendA_conv d_dynamic_ BackendA_linear_dynamic_ quantize_per_tensor_tensor_tags = BackendA_conv d_dynamic_ BackendA_linear_dynamic_ dequantize_per_tensor_tensor_tags = BackendA_conv d_dynamic_ BackendA_linear_dynamic_ dequantize_per_channel_tags = BackendA_conv d_dynamic_ BackendA_linear_dynamic_ node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor tensor quantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_tensor tensor dequantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_channel default dequantize_per_channel_tags torch ops quantized_decomposed choose_qparams tensor choose_qparams_tensor_tags _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags test_metadata_porting_for_dq_no_static_q Model under test conv d - avgpool - hardtanh - linear Dont quantize anything except linear Quantize linear dynamic quantization Check quantization tags conv d avgpool linear correctly set BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule backend_string = BackendA dynamic quantization quantization_config_dynamic = get_symmetric_quantization_config is_per_channel=True is_dynamic=True annotated_partitions = OP_TO_ANNOTATOR linear gm quantization_config_dynamic _tag_partitions backend_string linear_dynamic annotated_partitions validate model torch fx GraphModule - None pass example_inputs = torch randn get_attr_tags = BackendA_linear_dynamic_ choose_qparams_tensor_tags = BackendA_linear_dynamic_ quantize_per_tensor_tensor_tags = BackendA_linear_dynamic_ dequantize_per_tensor_tensor_tags = BackendA_linear_dynamic_ dequantize_per_channel_tags = BackendA_linear_dynamic_ node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor tensor quantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_tensor tensor dequantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_channel default dequantize_per_channel_tags torch ops quantized_decomposed choose_qparams tensor choose_qparams_tensor_tags _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags test_no_metadata_porting BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule quantization_config = get_symmetric_quantization_config is_per_channel=True OP_TO_ANNOTATOR linear gm quantization_config OP_TO_ANNOTATOR conv gm quantization_config OP_TO_ANNOTATOR adaptive_avg_pool d gm quantization_config validate model torch fx GraphModule - None pass example_inputs = torch randn node_tags = m = _test_metadata_porting TestHelperModules Conv dWithObsSharingOps example_inputs BackendAQuantizer node_tags from_node_to_tags = _test_quant_tag_preservation_through_decomp m example_inputs from_node_to_tags test_no_metadata_porting_through_unknown_ops Model under test matmul - add - relu matmul has get_attr first input quantization_tag should propagated add even s part chain ends get_attr MatmulWithConstInput torch nn Module __init__ - None super __init__ register_parameter w torch nn Parameter torch rand forward x y x = torch matmul w x z = x + y torch nn functional relu z BackendAQuantizer Quantizer annotate gm torch fx GraphModule - torch fx GraphModule qconfig = get_symmetric_quantization_config n gm graph nodes n op = call_function continue n meta quantization_annotation = QuantizationAnnotation input_qspec_map= n args qconfig input_activation output_qspec=qconfig output_activation tag = str n target n meta quantization_tag = tag arg n args arg op == get_attr arg meta quantization_tag = tag validate model torch fx GraphModule - None pass example_inputs = torch randn torch randn get_attr_tags = aten matmul default quantize_per_tensor_tensor_tags = aten matmul default aten add Tensor aten relu default dequantize_per_tensor_tensor_tags = aten matmul default aten add Tensor aten relu default node_tags = get_attr get_attr_tags torch ops quantized_decomposed quantize_per_tensor default quantize_per_tensor_tensor_tags torch ops quantized_decomposed dequantize_per_tensor default dequantize_per_tensor_tensor_tags _test_metadata_porting MatmulWithConstInput example_inputs BackendAQuantizer node_tags __name__ == __main__ raise_on_run_directly test test_quantization py