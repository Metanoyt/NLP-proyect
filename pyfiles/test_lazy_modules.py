Owner s module nn pickle unittest torch torch nn nn torch nn Buffer Parameter torch nn parameter UninitializedBuffer UninitializedParameter torch testing _internal common_cuda TEST_CUDA torch testing _internal common_utils run_tests suppress_warnings TEST_PRIVATEUSE TestCase LazyModule torch nn modules lazy LazyModuleMixin torch nn Module pass TestLazyModules TestCase suppress_warnings test_lazy_module_parameter module = LazyModule module register_parameter test_param UninitializedParameter assertTrue module has_uninitialized_params state_dict = module state_dict assertIsInstance state_dict test_param UninitializedParameter new_module = LazyModule An error raised when there attempt replace existing parameter uninitialized one new_module register_parameter test_param nn Parameter torch ones assertRaisesRegex RuntimeError shape uninitialized new_module load_state_dict state_dict Uninitialized parameters overridden when state dict loaded contains valid one new_module = LazyModule new_module register_parameter test_param nn Parameter torch ones module load_state_dict new_module state_dict assertEqual module test_param torch ones Uninitialized parameters left unchanged module = LazyModule module register_parameter test_param UninitializedParameter assertTrue module has_uninitialized_params new_module = LazyModule new_module register_parameter test_param UninitializedParameter module load_state_dict new_module state_dict assertTrue module has_uninitialized_params suppress_warnings test_lazy_module_buffer module = LazyModule module test_buffer = UninitializedBuffer assertTrue module has_uninitialized_params state_dict = module state_dict assertIsInstance state_dict test_buffer UninitializedBuffer new_module = LazyModule An error raised when there attempt replace existing parameter uninitialized one new_module test_buffer = Buffer torch ones assertRaisesRegex RuntimeError shape uninitialized new_module load_state_dict state_dict Uninitialized parameters overridden when state dict loaded contains valid one new_module = LazyModule new_module test_buffer = Buffer torch ones module load_state_dict new_module state_dict assertEqual module test_buffer torch ones Uninitialized parameters left unchanged module = LazyModule module test_buffer = UninitializedBuffer assertTrue module has_uninitialized_params new_module = LazyModule new_module test_buffer = UninitializedBuffer module load_state_dict new_module state_dict module load_state_dict new_module state_dict assertTrue module has_uninitialized_params suppress_warnings test_lazy_module_jit_param module = LazyModule module register_parameter test_param UninitializedParameter assertTrue module has_uninitialized_params assertRaisesRegex RuntimeError run forward pass torch jit script module suppress_warnings test_lazy_module_jit_buffer module = LazyModule module test_buffer = UninitializedBuffer assertTrue module has_uninitialized_params assertRaisesRegex RuntimeError run forward pass torch jit script module suppress_warnings test_lazy_share_memory_param module = LazyModule module register_parameter test_param UninitializedParameter assertTrue module has_uninitialized_params assertRaisesRegex RuntimeError share memory uninitialized module share_memory suppress_warnings test_lazy_share_memory_buffer module = LazyModule module test_buffer = UninitializedBuffer assertTrue module has_uninitialized_params assertRaisesRegex RuntimeError share memory uninitialized module share_memory suppress_warnings test_linear module = nn LazyLinear assertIsInstance module weight UninitializedParameter assertIsInstance module bias UninitializedParameter input = torch ones output = module input assertIsInstance module nn Linear assertNotIsInstance module nn LazyLinear assertTrue module weight shape == assertTrue module bias shape == assertTrue module weight = any assertTrue module bias = any assertTrue output = any y = module input assertTrue torch equal torch nn functional linear input module weight module bias y suppress_warnings test_lazy_linear_pickle module = nn LazyLinear assertIsInstance module weight UninitializedParameter assertIsInstance module bias UninitializedParameter module = pickle loads pickle dumps module assertIsInstance module nn LazyLinear assertIsInstance module weight UninitializedParameter assertIsInstance module bias UninitializedParameter input = torch ones module input fully materialized new_module = pickle loads pickle dumps module assertIsInstance new_module nn Linear assertNotIsInstance new_module nn LazyLinear assertTrue new_module weight shape == assertNotIsInstance new_module weight UninitializedParameter assertTrue new_module bias shape == assertNotIsInstance new_module bias UninitializedParameter suppress_warnings test_linear_state module = nn Linear lazy_module = nn LazyLinear lazy_module load_state_dict module state_dict Parameters have been initialized module won t become full Linear one until first iteration This due limitations state_dict loading logic assertFalse lazy_module has_uninitialized_params assertTrue lazy_module weight shape == assertTrue lazy_module bias shape == module = nn Linear lazy_module = nn LazyLinear assertRaisesRegex RuntimeError shape uninitialized module load_state_dict lazy_module state_dict suppress_warnings test_lazy_linear_state_and_forward module = nn Linear lazy_module = nn LazyLinear lazy_module load_state_dict module state_dict Parameters have been initialized module won t become full Linear one until first iteration This due limitations state_dict loading logic assertFalse lazy_module has_uninitialized_params assertTrue isinstance lazy_module nn LazyLinear input = torch randn lazy_module input assertFalse isinstance lazy_module nn LazyLinear assertTrue lazy_module in_features == _check_lazy_conv cls lazy_cls func init_args input_shape expected_weight_shape expected_bias_shape forward_args forward_kwargs module = lazy_cls init_args assertIsInstance module weight UninitializedParameter module bias None assertIsInstance module bias UninitializedParameter input = torch ones input_shape module input forward_args forward_kwargs assertIsInstance module cls assertNotIsInstance module lazy_cls assertEqual module weight shape expected_weight_shape module bias None assertEqual module bias shape expected_bias_shape y = module input assertTrue torch equal func input module weight module bias y _check_lazy_conv_pickle cls lazy_cls init_args input_shape expected_weight_shape expected_bias_shape module = lazy_cls init_args assertIsInstance module weight UninitializedParameter module bias None assertIsInstance module bias UninitializedParameter module = pickle loads pickle dumps module assertIsInstance module lazy_cls assertIsInstance module weight UninitializedParameter module bias None assertIsInstance module bias UninitializedParameter input = torch ones input_shape module input fully materialized new_module = pickle loads pickle dumps module assertIsInstance new_module cls assertNotIsInstance new_module lazy_cls assertEqual new_module weight shape expected_weight_shape assertNotIsInstance new_module weight UninitializedParameter new_module bias None assertEqual new_module bias shape expected_bias_shape assertNotIsInstance new_module bias UninitializedParameter _check_lazy_conv_state gen_module gen_lazy_module expected_weight_shape expected_bias_shape module = gen_module lazy_module = gen_lazy_module lazy_module load_state_dict module state_dict Parameters have been initialized module won t become full Conv one until first iteration This due limitations state_dict loading logic assertFalse lazy_module has_uninitialized_params assertEqual lazy_module weight shape expected_weight_shape lazy_module bias None assertEqual lazy_module bias shape expected_bias_shape module = gen_module lazy_module = gen_lazy_module assertRaisesRegex RuntimeError shape uninitialized module load_state_dict lazy_module state_dict test_lazy_pre_forward_hook This test test whether lazymodule can register other pre-forward hook functions successfully TestModule torch nn modules lazy LazyModuleMixin torch nn Module initialize_parameters input None forward input input hook_function module input input + module = TestModule module register_forward_pre_hook hook_function output = module torch zeros assertEqual output torch ones test_lazy_forward_hook This test test whether lazymodule can register other forward hook functions successfully TestModule torch nn modules lazy LazyModuleMixin torch nn Module initialize_parameters input None forward input input hook_function module input output input + module = TestModule module register_forward_hook hook_function output = module torch zeros assertEqual output torch ones suppress_warnings test_lazy_conv d _check_lazy_conv nn Conv d nn LazyConv d torch nn functional conv d suppress_warnings test_lazy_conv d_pickle _check_lazy_conv_pickle nn Conv d nn LazyConv d suppress_warnings test_lazy_conv d_state _check_lazy_conv_state lambda nn Conv d lambda nn LazyConv d suppress_warnings test_lazy_conv d _check_lazy_conv nn Conv d nn LazyConv d torch nn functional conv d suppress_warnings test_lazy_conv d_pickle _check_lazy_conv_pickle nn Conv d nn LazyConv d suppress_warnings test_lazy_conv d_state _check_lazy_conv_state lambda nn Conv d lambda nn LazyConv d suppress_warnings test_lazy_conv d _check_lazy_conv nn Conv d nn LazyConv d torch nn functional conv d suppress_warnings test_lazy_conv d_pickle _check_lazy_conv_pickle nn Conv d nn LazyConv d suppress_warnings test_lazy_conv d_state _check_lazy_conv_state lambda nn Conv d lambda nn LazyConv d suppress_warnings test_lazy_conv_transposed d _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d suppress_warnings test_lazy_conv_transpose d_kwargs _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d output_size= suppress_warnings test_lazy_conv_transpose d_pickle _check_lazy_conv_pickle nn ConvTranspose d nn LazyConvTranspose d suppress_warnings test_lazy_conv_transpose d_state _check_lazy_conv_state lambda nn ConvTranspose d lambda nn LazyConvTranspose d suppress_warnings test_lazy_conv_transpose d _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d suppress_warnings test_lazy_conv_transpose d_kwargs _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d output_size= suppress_warnings test_lazy_conv_transpose d_pickle _check_lazy_conv_pickle nn ConvTranspose d nn LazyConvTranspose d suppress_warnings test_lazy_conv_transpose d_state _check_lazy_conv_state lambda nn ConvTranspose d lambda nn LazyConvTranspose d suppress_warnings test_lazy_conv_transpose d _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d suppress_warnings test_lazy_conv_transpose d_kwargs _check_lazy_conv nn ConvTranspose d nn LazyConvTranspose d torch nn functional conv_transpose d output_size= suppress_warnings test_lazy_conv_transpose d_pickle _check_lazy_conv_pickle nn ConvTranspose d nn LazyConvTranspose d suppress_warnings test_lazy_conv_transpose d_state _check_lazy_conv_state lambda nn ConvTranspose d lambda nn LazyConvTranspose d _check_lazy_norm cls lazy_cls input_shape affine False True track_running_stats False True lazy_module = lazy_cls affine=affine track_running_stats=track_running_stats affine assertIsInstance lazy_module weight UninitializedParameter assertIsInstance lazy_module bias UninitializedParameter track_running_stats assertIsInstance lazy_module running_mean UninitializedBuffer assertIsInstance lazy_module running_var UninitializedBuffer input = torch ones input_shape lazy_output = lazy_module input assertIsInstance lazy_module cls assertNotIsInstance lazy_module lazy_cls num_features = input_shape module = cls num_features affine=affine track_running_stats=track_running_stats expected_output = module input assertEqual lazy_output expected_output module weight None assertEqual lazy_module weight shape module weight shape assertEqual lazy_module weight module weight module bias None assertEqual lazy_module bias shape module bias shape assertEqual lazy_module bias module bias module running_mean None assertEqual lazy_module running_mean shape module running_mean shape assertEqual lazy_module running_mean module running_mean module running_var None assertEqual lazy_module running_var shape module running_var shape assertEqual lazy_module running_var module running_var module num_batches_tracked None assertEqual lazy_module num_batches_tracked shape module num_batches_tracked shape assertEqual lazy_module num_batches_tracked module num_batches_tracked _check_lazy_norm_pickle cls lazy_cls input_shape affine False True track_running_stats False True module = lazy_cls affine=affine track_running_stats=track_running_stats module = pickle loads pickle dumps module assertIsInstance module lazy_cls affine assertIsInstance module weight UninitializedParameter assertIsInstance module bias UninitializedParameter track_running_stats assertIsInstance module running_mean UninitializedBuffer assertIsInstance module running_var UninitializedBuffer input = torch ones input_shape module input fully materialized module = pickle loads pickle dumps module assertNotIsInstance module lazy_cls assertIsInstance module cls affine assertNotIsInstance module weight UninitializedParameter assertNotIsInstance module bias UninitializedParameter track_running_stats assertNotIsInstance module running_mean UninitializedBuffer assertNotIsInstance module running_var UninitializedBuffer _check_lazy_batchnorm_state cls lazy_cls module = cls lazy_module = lazy_cls affine=True track_running_stats=True lazy_module load_state_dict module state_dict Parameters have been initialized module won t become full Conv one until first iteration This due limitations state_dict loading logic assertFalse lazy_module has_uninitialized_params assertEqual lazy_module weight shape assertEqual lazy_module bias shape assertEqual lazy_module running_mean shape assertEqual lazy_module running_var shape module = cls lazy_module = lazy_cls assertRaisesRegex RuntimeError shape uninitialized module load_state_dict lazy_module state_dict _check_lazy_instancenorm_state cls lazy_cls affine False True track_running_stats False True module = cls affine=affine track_running_stats=track_running_stats lazy_module = lazy_cls affine=affine track_running_stats=track_running_stats lazy_module load_state_dict module state_dict Parameters have been initialized module won t become full InstanceNorm one until first iteration This due limitations state_dict loading logic assertFalse lazy_module has_uninitialized_params affine assertEqual lazy_module weight shape assertEqual lazy_module bias shape track_running_stats assertEqual lazy_module running_mean shape assertEqual lazy_module running_var shape module = cls affine=True track_running_stats=True lazy_module = lazy_cls affine=True track_running_stats=True assertRaisesRegex RuntimeError shape uninitialized module load_state_dict lazy_module state_dict _check_lazy_norm_with_dict_input cls lazy_cls input_shape input = input torch ones input_shape lazy_module = lazy_cls lazy_output = lazy_module input num_features = input_shape module = cls num_features expected_output = module input assertEqual lazy_output expected_output test_lazy_batchnorm d _check_lazy_norm nn BatchNorm d nn LazyBatchNorm d _check_lazy_norm nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_pickle _check_lazy_norm_pickle nn BatchNorm d nn LazyBatchNorm d _check_lazy_norm_pickle nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_state _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d _check_lazy_norm nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_pickle _check_lazy_norm_pickle nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_state _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d _check_lazy_norm nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_pickle _check_lazy_norm_pickle nn BatchNorm d nn LazyBatchNorm d test_lazy_batchnorm d_state _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d _check_lazy_batchnorm_state nn BatchNorm d nn LazyBatchNorm d test_lazy_instancenorm d _check_lazy_norm nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_pickle _check_lazy_norm_pickle nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_state _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d _check_lazy_norm nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_pickle _check_lazy_norm_pickle nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_state _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d _check_lazy_norm nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_pickle _check_lazy_norm_pickle nn InstanceNorm d nn LazyInstanceNorm d test_lazy_instancenorm d_state _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d _check_lazy_instancenorm_state nn InstanceNorm d nn LazyInstanceNorm d test_lazy_batchnorm_with_dict_input _check_lazy_norm_with_dict_input nn BatchNorm d nn LazyBatchNorm d _check_lazy_norm_with_dict_input nn BatchNorm d nn LazyBatchNorm d _check_lazy_norm_with_dict_input nn BatchNorm d nn LazyBatchNorm d suppress_warnings test_materialize_dtype module = LazyModule module register_parameter test_param UninitializedParameter module test_param materialize assertTrue module test_param dtype == torch get_default_dtype module = LazyModule module register_parameter test_param UninitializedParameter module half module test_param materialize assertTrue module test_param dtype == torch float unittest skipIf TEST_CUDA TEST_PRIVATEUSE CUDA PRIVATEUSE available suppress_warnings test_materialize_device module = LazyModule module register_parameter test_param UninitializedParameter module test_param materialize assertTrue module test_param device type == cpu TEST_CUDA device = cuda TEST_PRIVATEUSE device = torch _C _get_privateuse _backend_name module = LazyModule module register_parameter test_param UninitializedParameter module device module test_param materialize assertTrue module test_param device type == device suppress_warnings test_chained_initialization MyNetwork torch nn Module __init__ - None super __init__ linear_ = torch nn LazyLinear linear_ = torch nn LazyLinear forward x y = linear_ x linear_ y net = MyNetwork net torch ones assertTrue net linear_ weight shape == assertTrue net linear_ bias shape == assertTrue net linear_ weight shape == assertTrue net linear_ bias shape == suppress_warnings test_optimizer_pass optimizers = torch optim Adadelta torch optim Adagrad torch optim Adamax torch optim Adam torch optim AdamW torch optim ASGD torch optim SGD torch optim Rprop torch optim RMSprop torch optim LBFGS torch optim NAdam torch optim RAdam run_step module optim assertIsInstance optim param_groups params UninitializedParameter module test_param materialize assertIsInstance optim param_groups params Parameter assertNotIsInstance optim param_groups params UninitializedParameter p module parameters p grad = torch rand_like p isinstance optim torch optim LBFGS optim step lambda optim step optim_cls optimizers module = LazyModule module register_parameter test_param UninitializedParameter optim_cls torch optim SGD optim = optim_cls module parameters lr= optim_cls torch optim Adagrad assertRaisesRegex ValueError uninitialized parameter optim = optim_cls module parameters continue optim = optim_cls module parameters run_step module optim suppress_warnings test_weight_norm m = nn LazyLinear assertRaisesRegex ValueError have uninitialized parameters m = torch nn utils weight_norm m suppress_warnings test_spectral_norm m = nn LazyLinear assertRaisesRegex ValueError have uninitialized parameters m = torch nn utils spectral_norm m suppress_warnings test_invalid_functions param = torch nn parameter UninitializedParameter assertRaisesRegex ValueError uninitialized parameter torch empty_like param assertRaisesRegex ValueError uninitialized parameter torch add param param assertRaisesRegex ValueError uninitialized parameter param + param __name__ == __main__ run_tests