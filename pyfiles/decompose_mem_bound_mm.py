mypy allow-untyped-defs logging torch torch Tensor torch _dynamo utils counters is_node_meta_valid torch fx experimental symbolic_shapes statically_known_false statically_known_true config pattern_matcher Arg CallFunction Match register_graph_pattern split_cat construct_pattern_matcher_pass aten = torch ops aten log = logging getLogger __name__ TODO need better strategy decomposing mm The following two constants CUDA device only MIN_FIRST_DIMENSION_DECOMPOSITION = MAX_OTHER_DIMENSION_DECOMPOSITION = The following two constants CPU device only CPU_MAX_FIRST_DIMENSION_DECOMPOSITION = CPU_MAX_OTHER_DIMENSION_DECOMPOSITION = min_first_dimension_decomposition = MIN_FIRST_DIMENSION_DECOMPOSITION max_other_dimension_decomposition = MAX_OTHER_DIMENSION_DECOMPOSITION cpu_max_first_dimension_decomposition = CPU_MAX_FIRST_DIMENSION_DECOMPOSITION cpu_max_other_dimension_decomposition = CPU_MAX_OTHER_DIMENSION_DECOMPOSITION decompose_mm_pass config post_grad_fusion_options min_first_dimension_decomposition = config post_grad_fusion_options decompose_mm_pass get min_first_dimension_decomposition MIN_FIRST_DIMENSION_DECOMPOSITION max_other_dimension_decomposition = config post_grad_fusion_options decompose_mm_pass get max_other_dimension_decomposition MAX_OTHER_DIMENSION_DECOMPOSITION cpu_max_first_dimension_decomposition = config post_grad_fusion_options decompose_mm_pass get cpu_max_first_dimension_decomposition CPU_MAX_FIRST_DIMENSION_DECOMPOSITION cpu_max_other_dimension_decomposition = config post_grad_fusion_options decompose_mm_pass get cpu_max_other_dimension_decomposition CPU_MAX_OTHER_DIMENSION_DECOMPOSITION check_device Tensor b Tensor device= cuda - bool device type == b device type b device type == device realize_inputs inputs list torch fx Node inp inputs isinstance inp torch fx node Node inp meta inductor_realize_to_strides = True should_decompose_bmm mat mat - bool is_node_meta_valid mat is_node_meta_valid mat mat = mat meta val mat = mat meta val False len mat shape = len mat shape = False check_device mat mat device= cuda mat shape min_first_dimension_decomposition False m n k must = MAX_OTHER_DIMENSION_DECOMPOSITION use bool deal BooleanAtom type bool mat shape max_other_dimension_decomposition + bool mat shape max_other_dimension_decomposition + bool mat shape max_other_dimension_decomposition False True check_device mat mat device= cpu mat shape = cpu_max_first_dimension_decomposition mat shape = cpu_max_first_dimension_decomposition True False should_decompose_mm mat mat - bool Determines whether matrix multiplication mm should decomposed into pointwise operations based input matrices metadata shapes device placement configuration options Args mat The first matrix operand Expected object ` meta ` attribute containing val key tensor-like object ` shape ` attribute mat The second matrix operand Same requirements ` mat ` Returns bool True matrix multiplication should decomposed according following logic - Both inputs must have valid node metadata - Both matrices must -dimensional - If configuration option ` skip_dynamic_shape_dim_check ` False - Decomposition only considered statically-shaped matrices - For CUDA devices ` mat shape ` must least ` min_first_dimension_decomposition ` both dimensions ` mat ` must less than ` max_other_dimension_decomposition ` - For CPU devices All relevant dimensions must less than equal their respective CPU decomposition thresholds - If ` skip_dynamic_shape_dim_check ` True - Decomposition considered dynamic shapes well using combination ` statically_known_true ` ` statically_known_false ` checks handle uncertainty - The same dimension device checks apply allow dynamic static uncertainty - Returns False any above conditions met Notes - Relies helper functions such ` is_node_meta_valid ` ` check_device ` ` statically_known_true ` ` statically_known_false ` well configuration values like ` min_first_dimension_decomposition ` ` max_other_dimension_decomposition ` etc - Designed use graph optimization fusion passes where decomposing large dynamic matrix multiplications can improve performance memory usage is_node_meta_valid mat is_node_meta_valid mat mat = mat meta val mat = mat meta val False len mat shape = len mat shape = False case we skip decompose mm input dynamic shape config post_grad_fusion_options decompose_mm_pass get skip_dynamic_shape_dim_check False check_device mat mat device= cuda statically_known_true mat shape = min_first_dimension_decomposition statically_known_true mat shape max_other_dimension_decomposition statically_known_true mat shape max_other_dimension_decomposition check_device mat mat device= cpu statically_known_true mat shape = cpu_max_first_dimension_decomposition statically_known_true mat shape = cpu_max_other_dimension_decomposition statically_known_true mat shape = cpu_max_other_dimension_decomposition case we decompose mm input dynamic shape check_device mat mat device= cuda statically_known_true mat shape = min_first_dimension_decomposition statically_known_false mat shape = min_first_dimension_decomposition statically_known_true mat shape max_other_dimension_decomposition statically_known_false mat shape max_other_dimension_decomposition statically_known_true mat shape max_other_dimension_decomposition statically_known_false mat shape max_other_dimension_decomposition check_device mat mat device= cpu statically_known_true mat shape = cpu_max_first_dimension_decomposition statically_known_false mat shape = cpu_max_first_dimension_decomposition statically_known_true mat shape = cpu_max_other_dimension_decomposition statically_known_false mat shape = cpu_max_other_dimension_decomposition statically_known_true mat shape = cpu_max_other_dimension_decomposition statically_known_false mat shape = cpu_max_other_dimension_decomposition print_decompose_pattern match Match inputs list torch fx Node node = match nodes - log debug Decompose s input shape s node target join str input meta val shape val input meta None input inputs register_graph_pattern CallFunction aten bmm Arg Arg pass_dict=construct_pattern_matcher_pass decompose_mm_pass decompose_bmm match Match mat torch fx Node mat torch fx Node repl mat mat torch sum mat None mat None dim=- mat dtype should_decompose_bmm mat mat counters inductor decompose_bmm += pyrefly ignore bad-argument-type match replace_by_example repl mat mat print_decompose_pattern match mat mat realize_inputs mat mat register_graph_pattern CallFunction aten addmm Arg Arg Arg pass_dict=construct_pattern_matcher_pass decompose_mm_pass decompose_addmm match Match mat torch fx Node mat torch fx Node mat torch fx Node repl mat mat mat torch sum mat None mat None dim=- mat dtype + mat should_decompose_mm mat mat counters inductor decompose_addmm += pyrefly ignore bad-argument-type match replace_by_example repl mat mat mat print_decompose_pattern match mat mat mat realize_inputs mat mat mat register_graph_pattern CallFunction aten mm Arg Arg pass_dict=construct_pattern_matcher_pass decompose_mm_pass decompose_mm match Match mat torch fx Node mat torch fx Node repl mat mat torch sum mat None mat None dim=- mat dtype should_decompose_mm mat mat counters inductor decompose_mm += pyrefly ignore bad-argument-type match replace_by_example repl mat mat print_decompose_pattern match mat mat realize_inputs mat mat