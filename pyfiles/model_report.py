mypy allow-untyped-defs collections OrderedDict collections abc Callable typing Any torch torch ao quantization fx _equalize EqualizationQConfig torch ao quantization fx _model_report detector DETECTOR_IS_POST_OBS_KEY DETECTOR_OBS_ARGS_KEY DETECTOR_OBS_TO_INSERT_KEY DETECTOR_TARGET_NODE_KEY DetectorBase DetectorQConfigInfo torch ao quantization fx _model_report model_report_visualizer ModelReportVisualizer torch ao quantization fx graph_module GraphModule torch ao quantization observer ObserverBase torch ao quantization qconfig_mapping QConfig QConfigMapping ModelReport r The ModelReport aims provide users easy way diagnose issues they run into their models The works all traceable GraphModules help diagnose issues though requirements type model more-so depends specific report user trying generate With respect reports ModelReport initialized set Detector classes each which generate reports quantization configuration issues use might have Currently supports generating reports - Suggestions per-channel vs per-tensor quantization nn Module - Suggestions dynamic vs static quantization linear layers Graph Modules - Suggestions input-weight equalization linear conv layers Graph Modules - Suggestions outlier detection all layers Graph Modules The ModelReport has primary functionality inserting observers primarily ModelReportObserver where needed each detector gather information needs then after calibration ModelReport compiles report generated each Detector into single report user It also has capability remove all observers inserted well attr ` _model ` The model we wish generate report Must traceable GraphModule attr ` _desired_report_detectors ` The set Detectors representing desired reports ModelReport Make sure these all unique types detectors do have more than same attr ` _desired_detector_names ` The set detector names _desired_report_detectors This set generated calling get_detector_name each detector attr ` _detector_name_to_observer_fqns ` The mapping each detector fqns observers interest The purpose keep track what observers inserted each detector so they can removed end desired attr ` _prepared_flag ` A boolean flag keeps track whether we have prepared model This ensure we only insert observers once ModelReport instance attr ` _removed_observers ` A boolean track we have removed observers already The purpose ensure we don t attempt remove observers twice same ModelReport instance This also allows functionality where we can generate report multiple times long we haven t removed observers yet Note This initially designed work Fx Graph Mode workflow mind However full functionality available long there traceable GraphModule being used One method get traceable GraphModule without going through Fx workflow use QuantizationTracer General Flow Fx workflow Initialize ModelReport object reports interest passing initialized detector objects model Prepare your model prepare_fx Call model_report prepare_detailed_calibration add relevant observers Calibrate your model data Call model_report generate_report your model generate report optionally remove added observers Optional Call model_report generate_visualizer get ModelReportVisualizer instance To help parsing report information debugging view report info - Table - Histogram - Line plot Call model_report generate_qconfigs generate qconfigs based report suggestions Example QuantizationTracer xdoctest +SKIP get necessary qconfig config = PrepareCustomConfig skipped_module_names skipped_module_classes = get_skipped_module_name_and_classes config False initialize our model get GraphModule model = SomeModel tracer = QuantizationTracer skipped_module_names skipped_module_classes graph_module = GraphModule model tracer trace model get our set detectors ModelReport instance detector_set = set DynamicStaticDetector tolerance= InputWeightEqualizationDetector ratio_threshold= tracer_reporter = ModelReport graph_module tracer_detector_set now we insert observers calibrate model tracer_model_with_observers = tracer_reporter prepare_detailed_calibration i range num_callibration_batches example_input = get_callibration_input tracer_model_with_observers example_input finally we generate reports optionally remove observers we inserted reports = tracer_reporter generate_model_report remove_inserted_observers=True Optional we can generate qconfig mapping based suggestions qconfigs = model_report generate_qconfig_mapping Optional we can generate equalization mapping based suggestions qconfigs = model_report generate_equalization_mapping Optional we get ModelReportVisualizer instance do any visualizations desired model_report_visualizer = tracer_reporter generate_visualizer __init__ model GraphModule desired_report_detectors set DetectorBase len desired_report_detectors == raise ValueError Should include least desired report keep track model we wish generate report _model GraphModule = model keep reports private so they can t modified _desired_report_detectors = desired_report_detectors _desired_detector_names = detector get_detector_name detector desired_report_detectors keep mapping desired reports observers interest get readings remove them can create large set set can then used traverse graph remove added observers _detector_name_to_observer_fqns dict str set str = initialize each report have empty set observers interest desired_report _desired_detector_names _detector_name_to_observer_fqns desired_report = set flags ensure we can only prepare remove observers once _prepared_flag = False _removed_observers = False store reports we generated visualization purposes initially empty since no reports generated _generated_reports dict str dict = get_desired_reports_names - set str Returns copy desired reports viewing _desired_detector_names copy get_observers_of_interest - dict str set str Returns copy observers interest viewing _detector_name_to_observer_fqns copy prepare_detailed_calibration - GraphModule r Takes graph model inserts following observers - ModelReportObserver Each observer inserted based desired_reports into relevant locations Right now each report _desired_detector_names has independent insertions However module already has Observer same type insertion will occur This because all same type Observer collect same information so redundant Returns same GraphModule observers inserted already prepared once cannot prepare again _prepared_flag raise ValueError Already ran preparing detailed calibration Run report generation next after calibration loop through each detector find where placements should keep track insert_observers_fqns dict str Any = detector _desired_report_detectors determine observer points each detector obs_fqn_to_info = detector determine_observer_insert_points _model map each insert point observer use insert_observers_fqns update obs_fqn_to_info update set observers report cares about _detector_name_to_observer_fqns detector get_detector_name = set obs_fqn_to_info keys now insert all observers their desired locations observer_fqn insert_observers_fqns target_node = insert_observers_fqns observer_fqn DETECTOR_TARGET_NODE_KEY insert_obs = insert_observers_fqns observer_fqn DETECTOR_OBS_TO_INSERT_KEY insert_post = insert_observers_fqns observer_fqn DETECTOR_IS_POST_OBS_KEY observer_args = insert_observers_fqns observer_fqn DETECTOR_OBS_ARGS_KEY _insert_observer_around_module observer_fqn target_node insert_obs observer_args insert_post _prepared_flag = True _model _insert_observer_around_module obs_fqn str target_node torch fx node Node obs_to_insert ObserverBase observer_args tuple insert_post bool r Helper function inserts observer into both graph structure module model Args node_fqn str The fully qualified name observer we want insert target_node torch fx node Node The node model we inserting observers around obs_to_insert ObserverBase The observer we inserting around target_node observer_args Tuple The arguments we want pass into observer insert_post bool whether meant post observer node we inserting post then our target node next node insert_post target_node = target_node next _model graph inserting_before target_node _model add_submodule obs_fqn obs_to_insert _model graph create_node op= call_module target=obs_fqn args=observer_args recompile model after inserts made _model recompile _get_node_from_fqn node_fqn str - torch fx node Node r Takes node fqn returns node based fqn Args node_fqn str The fully qualified name node we want find model Returns Node object given node_fqn otherwise returns None node_to_return = None node _model graph nodes target matches fqn s node we looking node target == node_fqn node_to_return = node break node_to_return None raise ValueError The node_fqn found within module assert MyPy isinstance node_to_return torch fx node Node raise AssertionError node_to_return must torch fx node Node node_to_return generate_model_report remove_inserted_observers bool - dict str tuple str dict r Generates all requested reports Note You should have calibrated model relevant data before calling The reports generated specified desired_reports specified desired_reports Can optionally remove all observers inserted ModelReport instance Args remove_inserted_observers bool True remove observers inserted ModelReport instance Returns mapping each desired report name tuple The textual summary report information A dictionary containing relevant statistics information report Note Throws exception we try generate report model we already removed observers Throws exception we try generate report without preparing calibration we haven t prepped model calibration then we shouldn t generate report yet _prepared_flag raise Exception noqa TRY Cannot generate report without preparing model calibration we already removed observers we cannot generate report _removed_observers raise Exception noqa TRY Cannot generate report model you already removed observers keep track all reports interest their outputs reports_of_interest = detector _desired_report_detectors generate individual report detector report_output = detector generate_detector_report _model reports_of_interest detector get_detector_name = report_output user wishes remove inserted observers go ahead remove remove_inserted_observers _removed_observers = True get set all Observers inserted instance ModelReport all_observers_of_interest set str = set desired_report _detector_name_to_observer_fqns observers_of_interest = _detector_name_to_observer_fqns desired_report all_observers_of_interest update observers_of_interest go through all_observers_of_interest remove them graph model observer_fqn all_observers_of_interest remove observer model _model delete_submodule observer_fqn remove observer graph structure node_obj = _get_node_from_fqn observer_fqn node_obj _model graph erase_node node_obj raise ValueError Node no longer exists GraphModule structure remember recompile model _model recompile save generated reports visualization purposes saved_reports dict str dict = report_name report_tuple report_name report_tuple reports_of_interest items _generated_reports = saved_reports reports interest reports_of_interest _is_same_info_for_same_key info_dict_a dict info_dict_b dict - bool r Takes two dictionaries ensures any common keys between two have same values Args info_dict_a Dict First dictionary we wish compare info_dict_b Dict Second dictionary we wish compare Returns True all shared keys have same values false otherwise get set keys both dict_a_keys set = set info_dict_a keys dict_b_keys set = set info_dict_b keys get insersection keys check same value both dicts intersecting_keys set = dict_a_keys intersection dict_b_keys key intersecting_keys dict_a_val = info_dict_a key dict_b_val = info_dict_b key s tensor we have handle separately type dict_a_val torch Tensor dict_b_val tensor automatically false type dict_b_val torch Tensor sum dict_a_val = dict_b_val = False non-tensor vals dict_a_val = dict_b_val False no non matching shared keys found true True _reformat_reports_for_visualizer - OrderedDict r Takes generated reports reformats them into format desired ModelReportVisualizer Returns OrderedDict mapping module_fqns their features we want reorder reformat information so ordered terms order found model first create new dict all modules keys features under respective module module_fqns_to_features dict str dict = report_name _generated_reports get mod - feature dict go through module_info = _generated_reports report_name module_fqn module_info check already our accumulation dict module_fqn module_fqns_to_features we merge all features together new_info dict = module_info module_fqn present_info dict = module_fqns_to_features module_fqn merge them together into new unioned dict same features keys - same info so okay override do safety check make sure shared keys have same info _is_same_info_for_same_key new_info present_info module_fqns_to_features module_fqn = new_info present_info error_str = You have same key different values across detectors error_str += Someone incorrectly implemented detector conflicting keys existing detectors raise ValueError error_str we just set module_fqns_to_features module_fqn = module_info module_fqn our ordered dict so modules can ordered order how they appear model features_by_module OrderedDict str dict = OrderedDict we loop through modules graph order fqn _module _model named_modules find fqn fqns_to_features fqn module_fqns_to_features add our ordered dict features_by_module fqn = module_fqns_to_features fqn ordered dict info we created features_by_module generate_visualizer - ModelReportVisualizer r Generates ModelReportVisualizer instance using reports generated generate_model_report method Returns generated ModelReportVisualizer instance initialized Note Throws exception attempt get visualizers without generating report check user has generated reports least once len _generated_reports == raise Exception noqa TRY Unable generate visualizers without first generating reports get ordered dict mapping modules their full set collected features stats module_fqns_to_features OrderedDict = _reformat_reports_for_visualizer create ModelReportVisualizer instance visualizer ModelReportVisualizer = ModelReportVisualizer module_fqns_to_features visualizer _generate_qconfig_mapping_helper detector_qconfig_info_combined dict str DetectorQConfigInfo generation_function Callable - QConfigMapping r This helper takes compiled detector qconfig info has been compiled together merges into QConfigMapping keep track qconfigmapping qconfig_mapping = QConfigMapping loop through each module fqn attempt create QConfigMapping fqn module _model named_modules we have qconfig info module fqn detector_qconfig_info_combined qconfig_info_compiled = detector_qconfig_info_combined fqn now generate qconfig add mapping generated_qconfig = generation_function qconfig_info_compiled module add our config qconfig_mapping set_module_name fqn generated_qconfig compiled mapping qconfig_mapping _update_detector_quantizaiton_qconfig_info combined_info DetectorQConfigInfo new_info DetectorQConfigInfo r Takes old new information updates combined information Args combined_info DetectorQConfigInfo The DetectorQConfigInfo we compiling all information new_info DetectorQConfigInfo The DetectorQConfigInfo information we trying merge new info into combined_info is_activation_dynamic = combined_info is_activation_dynamic new_info is_activation_dynamic combined_info is_weight_per_channel = combined_info is_weight_per_channel new_info is_weight_per_channel _update_detector_equalization_qconfig_info combined_info DetectorQConfigInfo new_info DetectorQConfigInfo r Takes old new information updates combined information Args combined_info DetectorQConfigInfo The DetectorQConfigInfo we compiling all information new_info DetectorQConfigInfo The DetectorQConfigInfo information we trying merge new info into is_equalization_recommended = combined_info is_equalization_recommended new_info is_equalization_recommended combined_info is_equalization_recommended = is_equalization_recommended _generate_module_fqn_to_detector_info_mapping update_qconfig_info_function Callable - dict str DetectorQConfigInfo r Generates QConfigMapping based suggestions ModelReport API The generated mapping encompasses all different types feedback different detectors all into one place These configs based suggestions provided ModelReport API can only generated once reports have been generated Args update_qconfig_info_function Callable takes function takes two DetectorQConfigInfo updates one being compiled Returns Dict mapping module_fqns DetectorQConfigInfo objects Note Throws exception we try generate mapping model we already removed observers Throws exception we try generate mapping without preparing calibration we haven t prepped model calibration then we shouldn t generate mapping yet _prepared_flag raise Exception noqa TRY Cannot generate report without preparing model calibration we already removed observers we cannot mapping _removed_observers raise Exception noqa TRY Cannot generate report model you already removed observers keep track qconfig info each module across detectors detector_qconfig_info_combined dict str DetectorQConfigInfo = detector _desired_report_detectors get info detector detector_info dict str DetectorQConfigInfo = detector get_qconfig_info _model we go through modules module_fqn detector_info see we already have info module_fqn detector_qconfig_info_combined we combine current options what there current_options = detector_qconfig_info_combined module_fqn detector_options = detector_info module_fqn update_qconfig_info_function current_options detector_options we just use now detector_qconfig_info_combined module_fqn = detector_info module_fqn detector_qconfig_info_combined generate_qconfig_mapping - QConfigMapping r Generates QConfigMapping based suggestions ModelReport API The generated mapping encompasses all different types feedback different detectors all into one place These configs based suggestions provided ModelReport API can only generated once reports have been generated Returns QConfigMapping quantization configuration Note Throws exception we try generate mapping model we already removed observers Throws exception we try generate mapping without preparing calibration get mapping info detector_qconfig_info_combined = _generate_module_fqn_to_detector_info_mapping _update_detector_quantizaiton_qconfig_info we will do bit processing remove fqns don t have input weight recommended now we generate QConfig each options mapping QConfigMapping = _generate_qconfig_mapping_helper detector_qconfig_info_combined _quantization_config_generator generated mapping mapping _quantization_config_generator detector_qconfig_info DetectorQConfigInfo module torch nn Module - QConfig r Returns quantization configuration generated DetectorQConfigInfo object detector_qconfig_info generate_quantization_qconfig module _equalization_config_generator detector_qconfig_info DetectorQConfigInfo module torch nn Module - EqualizationQConfig r We ignore module argument here only focus thedetector_qconfig_info Returns equalization configuration generated DetectorQConfigInfo object detector_qconfig_info generate_equalization_qconfig generate_equalization_mapping - QConfigMapping r Generates QConfigMapping based suggestions ModelReport API equalization The generated mapping encompasses all different types feedback input-weight equalization detector These configs based suggestions provided ModelReport API can only generated once reports have been generated Returns QConfigMapping equalization configuration get mapping info detector_qconfig_info_combined = _generate_module_fqn_to_detector_info_mapping _update_detector_equalization_qconfig_info now we generate QConfig each options mapping QConfigMapping = _generate_qconfig_mapping_helper detector_qconfig_info_combined _equalization_config_generator generated mapping mapping