Owner s oncall jit ruff noqa F os re sys threading types typing typing_extensions collections OrderedDict typing Dict List Optional Tuple torch torch jit frontend torch nn nn torch Tensor torch testing FileCheck Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir torch testing _internal common_utils raise_on_run_directly torch testing _internal jit_utils _tmp_donotuse_dont_inline_everything JitTestCase TestRecursiveScript JitTestCase test_inferred_nonetype M nn Module __init__ - None super __init__ x = None forward assert x None m = torch jit script M checkModule M test_script_function_attribute torch jit script fn x x + x torch jit script fn x x - x M torch nn Module __init__ fn super __init__ fn = fn forward x fn x fn _mod = M fn fn _mod = M fn checkModule fn _mod torch randn checkModule fn _mod torch randn test_python_function_attribute M torch nn Module __init__ fn super __init__ fn = fn forward x fn x mod = M torch sigmoid checkModule mod torch randn test_failed_function_compilation fn x i_dont_exist noqa F M torch nn Module __init__ fn super __init__ fn = fn forward x fn x m = M fn assertRaisesRegexWithHighlight RuntimeError failed compile i_dont_exist torch jit script m test_init_error M nn Module __init__ - None x = forward pass assertRaisesRegex RuntimeError has been initialized torch jit script M test_script_after_eval M nn Module forward training m = M sm = torch jit script m m eval sm = torch jit script m m eval mode training should False assertFalse m training sm created while m had training = True assertTrue sm training assertEqual sm training sm _c getattr training assertEqual sm sm created after m eval ed assertFalse sm training assertEqual sm training sm _c getattr training assertEqual sm test_module_name MyModule torch nn Module __init__ - None super __init__ x = forward t t + x m = torch jit script MyModule FileCheck check MyModule run m graph test_repeated_error_stack d x - c x d x b x c x x b x try torch jit script except Exception e FileCheck check_count being compiled run str e try torch jit script except Exception e Make sure no entries left over previous failure FileCheck check_count being compiled run str e test_constants_with_final M torch nn Module x torch jit Final int __init__ - None super __init__ x = forward t t + x checkModule M torch randn M torch nn Module x typing_extensions Final int __init__ - None super __init__ x = forward t t + x checkModule M torch randn M torch nn Module x typing Final int __init__ - None super __init__ x = forward t t + x checkModule M torch randn test_ignore_class torch jit ignore MyScriptClass unscriptable + TestModule torch nn Module forward x MyScriptClass assertRaisesRegexWithHighlight torch jit frontend FrontendError Cannot instantiate MyScriptClass t = torch jit script TestModule test_method_call M nn Module test x x forward z y = test z z + + y checkModule M torch randn test_module_repr Submodule nn Module forward x x MyModule nn Module __init__ - None super __init__ conv = nn Conv d lin = nn Linear sub = Submodule forward x lin x + sub x + conv x m = torch jit script MyModule capture_stdout out print m f = FileCheck f check MyModule f check Conv d f check Linear f check Submodule f run out assertEqual m original_name MyModule test_dir test_module_dir mod dir_set = dir mod scripted_mod = torch jit script mod dir_scripted = set dir scripted_mod set currently copied over ignore_set = training __delitem__ __setitem__ clear items keys pop update values attr dir_set attr ignore_set continue assertTrue attr dir_scripted attr MyModule nn Module __init__ - None super __init__ conv = nn Conv d lin = nn Linear forward x lin x + conv x test_module_dir MyModule test custom __dir__ containers conv = nn Conv d linear = nn Linear test_module_dir nn Sequential conv linear test_module_dir nn ModuleDict OrderedDict conv conv linear linear test_class_compile other_fn int b Tensor - Tensor b B __init__ x x = helper x + + other_fn x N torch nn Module forward x b = B x b helper x checkModule N torch randn test_error_stack d x int - int x + c x d hello + d x b x c x x b x try scripted = torch jit script except RuntimeError e checker = FileCheck checker check Expected value type int checker check c x checker check b x checker check x checker run str e test_error_stack_module d x int - int x + c x d hello + d x b x c x Submodule torch nn Module forward x b x M torch nn Module __init__ - None super __init__ submodule = Submodule some_method y y + submodule y forward x some_method x try scripted = torch jit script M except RuntimeError e checker = FileCheck checker check Expected value type int checker check c being compiled since called b checker check b being compiled since called checker run str e _tmp_donotuse_dont_inline_everything test_script_basic a_python_fn b c + b + c torch jit script a_script_fn d e f a_python_fn d e f graph = str a_script_fn graph FileCheck check prim CallFunction run graph FileCheck check_not ^a_python_fn run graph t = torch ones assertEqual a_script_fn t t t t + t + t test_error_stack_class X bad_fn pdb noqa F fn x - X X try torch jit script fn except Exception e checker = FileCheck checker check statements checker check being compiled since called checker run str e test_error_stack_annotation X bad_fn pdb noqa F fn x - X X try torch jit script fn except Exception e checker = FileCheck checker check statements checker check being compiled since called checker check - X checker run str e test_module_basic Other torch nn Module __constants__ = x __init__ x super __init__ x = x param = torch nn Parameter torch ones some_unscriptable_method = = forward t t + x + param M torch nn Module __init__ - None super __init__ other = Other forward t other t checkModule M torch ones test_module_function_export Other torch nn Module __constants__ = x __init__ x super __init__ x = x param = torch nn Parameter torch ones torch jit export some_entry_point y y + forward t t + x + param M torch nn Module __init__ - None super __init__ other = Other forward t other t checkModule M torch ones test_iterable_modules Inner torch nn Module forward x x + M torch nn Module __init__ - None super __init__ sequential = nn Sequential Inner Inner nn Sequential Inner Inner module_list = nn ModuleList Inner Inner forward x mod module_list x += mod x x += sequential x x checkModule M torch randn test_prepare_scriptable_basic SeluButReluWhenScripted torch nn SELU __prepare_scriptable__ nn ReLU t = torch randn m = SeluButReluWhenScripted sm = torch jit script m eager_out = m t script_out = sm t assertNotEqual eager_out script_out test_prepare_scriptable_iterable_modules SeluButReluWhenScripted torch nn SELU __prepare_scriptable__ nn ReLU M torch nn Module __init__ - None super __init__ shared = SeluButReluWhenScripted sequential = nn Sequential SeluButReluWhenScripted SeluButReluWhenScripted nn Sequential SeluButReluWhenScripted shared SeluButReluWhenScripted shared module_list = nn ModuleList SeluButReluWhenScripted shared SeluButReluWhenScripted forward x mod module_list x += mod x x += sequential x x t = torch randn m = M eager_out = m t clone sm = torch jit script m script_out = sm t clone assertNotEqual eager_out script_out test_prepare_scriptable_cycle t = torch randn c = torch nn Module p = torch nn Module c __dict__ _p = p p __dict__ _c = c sm = torch jit script p test_prepare_scriptable_escape_hatch NonJitableClass __call__ int int args total = int + int arg args total += arg total obj = NonJitableClass assertEqual obj assertEqual obj assertRaisesRegex torch jit frontend NotSupportedError expected_regex= can t take variable number arguments torch jit script obj escape_hatch int int int int - int int + int NonJitableClassWithEscapeHatch NonJitableClass __prepare_scriptable__ escape_hatch jit_obj = torch jit script NonJitableClassWithEscapeHatch assertEqual jit_obj assertRaisesRegex RuntimeError expected_regex=re escape expected most argument s received argument s jit_obj test_attributes torch jit script Inner __init__ - None b = string torch jit script Foo __init__ - None = inner = Inner torch jit script SFoo __init__ - None = inner = Inner __setstate__ obj Tuple int Inner - None inner = obj = inner = inner __getstate__ inner untyped_values = my_dict I am test test my_float my_int my_bool False my_tuple my_list my_tensor torch randn my_int_list my_tensor_list torch ones + i i range my_bool_list True True False True my_float_list my_str_list hello bye typed_values = my_empty_list my_empty_dict my_none None my_object Foo my_object SFoo M torch nn Module TODO re-enable once test Python -only syntax file my_empty_list List int my_empty_dict Dict str int my_none Optional int forward x my_dict my_float my_int my_bool my_tensor my_int_list my_tensor_list my_bool_list my_float_list my_str_list my_empty_list my_empty_dict my_none my_object my_object inner b my_object my_object inner b TODO followup fix test We can t define attributes like we should doing M torch nn Module my_empty_list List int my_empty_dict Dict str int my_none Optional int my_out_of_line_attribute List int = since there s no string frontend Python classes so ` define ` trick doesn t work M __annotations__ = my_empty_list List int my_empty_dict Dict str int my_none Optional int my_object Foo my_object SFoo m = M name value untyped_values + typed_values setattr m name value checkModule m torch randn test_function_attribute_in_submodule N nn Module __init__ norm super __init__ activation = torch nn functional relu norm = norm forward src output = src output = norm output output M nn Module __init__ - None super __init__ encoder_norm = nn ReLU encoder = N encoder_norm forward x encoder x m = M checkModule m torch randn test_inner_traced_module Dummy nn Module forward x x Model nn Module __init__ dummies super __init__ _dummies = dummies forward x out = dummy _dummies out append dummy x out dummy = torch jit trace Dummy torch randn dummies = nn ModuleList dummy model = Model dummies checkModule model torch rand test_script_loaded_module Test we can hold loaded ScriptModule submodule Dummy nn Module forward x x dummy = torch jit script Dummy dummy = getExportImportCopy dummy ContainsLoaded torch nn Module __init__ - None super __init__ encoder = dummy forward input encoder input checkModule ContainsLoaded torch rand test_optional_module Dummy nn Module __init__ - None super __init__ foo = nn Linear forward x foo None foo x x mod = Dummy checkModule mod torch rand mod foo = None checkModule mod torch rand test_thread_safe_error_stacks prior causes segfault See Note Thread-safe CallStack callstacks = callstack_creator factory = torch _C _jit_tree_views SourceRangeFactory source code py x = torch _C CallStack factory make_range callstacks append x del x t = threading Thread target=callstack_creator t start t join del t del callstacks assertTrue len callstacks == test_override_instance_method_ignore M torch nn Module torch jit ignore i_am_ignored old m = M Override ignored method binding new method instance torch jit ignore i_am_ignored new m i_am_ignored = types MethodType i_am_ignored m assertEqual m i_am_ignored new ScriptModule should correctly reflect override s = torch jit script m assertEqual s i_am_ignored new __name__ == __main__ raise_on_run_directly test test_jit py