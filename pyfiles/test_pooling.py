Owner s module nn itertools math operator os random subprocess sys unittest functools partial reduce itertools repeat torch torch nn nn torch nn functional F torch inf nan torch autograd gradcheck gradgradcheck torch testing make_tensor torch testing _internal common_cuda TEST_CUDA torch testing _internal common_device_type dtypes dtypesIfCUDA dtypesIfMPS expectedFailureMeta expectedFailureMPS instantiate_device_type_tests largeTensorTest onlyCPU onlyCUDA onlyNativeDeviceTypes skipCUDAIfRocm TEST_WITH_ROCM torch testing _internal common_dtype floating_types_and torch testing _internal common_nn _test_bfloat _ops _test_module_empty_input NNTestCase torch testing _internal common_utils gcIfJetson instantiate_parametrized_tests parametrize parametrize_test run_tests set_default_dtype skipIfTorchDynamo slowTest subtest TEST_WITH_UBSAN TestCase TestAvgPool TestCase _sum_pool d x kernel_size windows = torch nn functional unfold x kernel_size=kernel_size stride=kernel_size torch sum windows dim= _sum_pool d x kernel_size Because unfold does support D sliding window we will split tensor multiple tensors calculate sum h = kernel_size splited_x = t sum t x split h t size == h sum_pool d assumes tensor n m view so unsqueeze two times splited_x = _sum_pool d t unsqueeze unsqueeze kernel_size t splited_x joined_x = torch cat splited_x joined_x view joined_x numel _avg_pool d x kernel_size size = reduce operator mul kernel_size _sum_pool d x kernel_size size _avg_pool d x kernel_size size = reduce operator mul kernel_size _sum_pool d x kernel_size size test_doubletensor_avg_pool d n m = input = torch rand n m dtype=torch double i range n + j range m + actual = torch nn functional avg_pool d input i j actual = actual view actual numel expected = _avg_pool d input i j assertEqual actual expected rtol= atol= e- test_doubletensor_avg_pool d_with_divisor n m = input = torch rand n m dtype=torch double i range n + j range m + divisor i j actual = F avg_pool d input i j divisor_override=divisor actual = actual view actual numel expected = _sum_pool d input i j divisor assertEqual actual expected rtol= atol= e- test_doubletensor_avg_pool d h w d = input = torch rand h w d dtype=torch double i range h + j range w + k range d + actual = torch nn functional avg_pool d input unsqueeze i j k actual = actual view actual numel expected = _avg_pool d input i j k assertEqual actual expected rtol= atol= e- test_doubletensor_avg_pool d_with_divisor h w d = input = torch rand h w d dtype=torch double i range h + j range w + k range d + divisor i j actual = torch nn functional avg_pool d input unsqueeze i j k divisor_override=divisor actual = actual view actual numel expected = _sum_pool d input i j k divisor assertEqual actual expected rtol= atol= e- test_avg_pool d_ceil_mode Regression test gh- x = torch randn y = torch nn functional avg_pool d x ceil_mode=True count_include_pad=True kernel_size= stride= assertTrue torch isnan y any TEST_CUDA y = torch nn functional avg_pool d x cuda ceil_mode=True count_include_pad=True kernel_size= stride= assertTrue torch isnan y any test_avg_pool d_ceil_mode Regression test gh- x = torch randn y = torch nn functional avg_pool d x ceil_mode=True count_include_pad=True kernel_size= padding= stride= assertTrue torch isnan y any TEST_CUDA y = torch nn functional avg_pool d x cuda ceil_mode=True count_include_pad=True kernel_size= padding= stride= assertTrue torch isnan y any test_avg_pool d_ceil_mode Regression test gh- x = torch randn y = torch nn functional avg_pool d x ceil_mode=True count_include_pad=True kernel_size= stride= assertTrue torch isnan y any TEST_CUDA y = torch nn functional avg_pool d x cuda ceil_mode=True count_include_pad=True kernel_size= stride= assertTrue torch isnan y any TestPoolingNN NNTestCase _do_cuda_memory_leak_check = True _do_cuda_non_default_stream = True test_adaptive_pooling_size_none numel pool_type Max Avg cls_name = f Adaptive pool_type Pool numel d module_cls = getattr nn cls_name output_size = numel - + None module = module_cls output_size input = torch randn numel + output = module input assertEqual output size + numel - + unittest skipIf TEST_WITH_UBSAN signed integer overflow error UBSAN test_adaptive_pooling_size_overflow x x fffffffffffffff = xfffffffffffffffc = - int _t Tensor numel int _t so following check negative allocs correctly handled assertRaises RuntimeError lambda torch nn AdaptiveMaxPool d x FFFFFFFFFFFFFFF torch empty test_adaptive_pooling_avg_nhwc device_list = cpu TEST_CUDA device_list append cuda device device_list input = torch randint dtype=torch float device input = input contiguous memory_format=torch channels_last requires_grad_ grad = torch randint dtype=torch float device pool = torch nn AdaptiveAvgPool d device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn AdaptiveAvgPool d device out = pool input out backward grad ref_out = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertEqual out ref_out assertEqual input grad ref_input grad test_adaptive_pooling_avg_nhwc_non_contiguous device_list = cpu TEST_CUDA device_list append cuda device device_list input = torch randint dtype=torch float device input = input contiguous memory_format=torch channels_last input = input requires_grad_ grad = torch randint dtype=torch float device grad = grad pool = torch nn AdaptiveAvgPool d device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn AdaptiveAvgPool d device out = pool input out backward grad ref_out = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertEqual out ref_out assertEqual input grad ref_input grad test_adaptive_pooling_lower_precision _test_adaptive_pooling_lower_precision device dtype mod memory_format input = torch randint dtype=torch float input = input device memory_format=memory_format requires_grad_ pool = mod device input = input detach clone dtype=dtype requires_grad_ True out = pool input out sum backward out = pool input out sum backward assertTrue out is_contiguous memory_format=memory_format assertEqual out dtype dtype assertEqual input grad dtype dtype assertEqual out out float atol= rtol= assertEqual input grad input grad float atol= rtol= device_list = cpu device device_list dtype torch bfloat torch float _test_adaptive_pooling_lower_precision device dtype torch nn AdaptiveAvgPool d torch contiguous_format _test_adaptive_pooling_lower_precision device dtype torch nn AdaptiveAvgPool d torch channels_last _test_adaptive_pooling_lower_precision device dtype torch nn AdaptiveMaxPool d torch contiguous_format _test_adaptive_pooling_lower_precision device dtype torch nn AdaptiveMaxPool d torch channels_last unittest skipIf TEST_CUDA CUDA unavailable largeTensorTest GB device= cuda test_adaptive_pooling_avg_nhwc_launch_config_backward input = torch randint + dtype=torch float device= cuda input = input contiguous memory_format=torch channels_last requires_grad_ grad = torch randint dtype=torch float device= cuda pool = torch nn AdaptiveAvgPool d cuda ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn AdaptiveAvgPool d cuda out = pool input out backward grad ref_out = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertEqual out ref_out assertEqual input grad ref_input grad unittest skipIf TEST_CUDA CUDA unavailable largeTensorTest GB device= cuda test_adaptive_pooling_avg_nhwc_launch_config_forward input = torch randint dtype=torch float device= cuda input = input contiguous memory_format=torch channels_last requires_grad_ pool = torch nn AdaptiveAvgPool d + cuda ref_input = input detach clone contiguous requires_grad_ True ref_pool = torch nn AdaptiveAvgPool d + cuda out = pool input ref_out = ref_pool ref_input assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertEqual out ref_out unittest skipIf TEST_CUDA CUDA unavailable test_adaptive_avg_pooling_overflow input = torch randint - dtype=torch half device= cuda avg_pool = torch nn AdaptiveAvgPool d out = avg_pool input assertFalse torch isinf out any assertFalse torch isnan out any unittest skipIf TEST_CUDA CUDA unavailable test_adaptive_avg_pooling_nhwc_overflow input = torch randint - dtype=torch half device= cuda input = input contiguous memory_format=torch channels_last avg_pool = torch nn AdaptiveAvgPool d out = avg_pool input assertFalse torch isinf out any assertFalse torch isnan out any test_MaxUnpool d_output_size m = nn MaxPool d stride= return_indices=True mu = nn MaxUnpool d stride= big_t = torch rand big_t = output_big indices_big = m big_t assertRaises RuntimeError lambda mu output_big indices_big small_t = torch rand i range j range small_t i j = output_small indices_small = m small_t h range w range = h = = w = size = h w h == size = + size mu output_small indices_small output_size=size assertRaises ValueError lambda mu output_small indices_small h w test_max_unpool d_nhwc_cpu input = torch randn float cpu input = input contiguous memory_format=torch channels_last ref_input = input clone contiguous pool = nn MaxPool d stride= return_indices=True cpu ref_pool = nn MaxPool d stride= return_indices=True cpu out ind = pool input ref_out ref_ind = ref_pool ref_input out requires_grad_ ref_out requires_grad_ unpool = nn MaxUnpool d stride= cpu ref_unpool = nn MaxUnpool d stride= cpu upout = unpool out ind ref_upout = ref_unpool ref_out ref_ind grad = torch randn upout size float cpu grad = grad contiguous memory_format=torch channels_last ref_grad = grad clone contiguous upout backward grad ref_upout backward ref_grad assertTrue upout is_contiguous memory_format=torch channels_last assertTrue ref_upout is_contiguous assertTrue torch allclose upout ref_upout assertTrue torch allclose out grad ref_out grad test_max_unpool set_default_dtype torch double Test D output indices = F max_pool d torch randn stride= return_indices=True assertEqual F max_unpool d output indices F max_unpool d output indices stride= Test list tuple passed argument max_unpool d input = torch randn requires_grad=True output indices = F max_pool d input stride= return_indices=True assertEqual F max_unpool d output indices stride= output_size=input shape F max_unpool d output indices stride= output_size=input size gradcheck F max_unpool d output indices check_forward_ad=True Test D output indices = F max_pool d torch randn requires_grad=True stride= return_indices=True assertEqual F max_unpool d output indices F max_unpool d output indices stride= gradcheck F max_unpool d output indices check_forward_ad=True Test D output indices = F max_pool d torch randn requires_grad=True stride= return_indices=True assertEqual F max_unpool d output indices F max_unpool d output indices stride= gradcheck F max_unpool d output indices check_forward_ad=True test_max_unpool d_input_check x = torch ones assertRaises RuntimeError F max_unpool d x torch zeros x shape dtype=int test_quantized_max_pool d_empty_kernel This used segfault when called empty kernel see https github com pytorch pytorch issues base = torch randn temp_tensor = torch quantize_per_tensor base torch quint x assertRaises RuntimeError torch quantized_max_pool d temp_tensor test_quantized_max_pool d This used segfault when called negative dilation see https github com pytorch pytorch issues input = torch randn input = torch quantize_per_tensor input - - torch qint assertRaisesRegex RuntimeError Expected dilation = torch quantized_max_pool d input - TestPoolingNNDeviceType NNTestCase expectedFailureMPS No double float shape prop does work onlyNativeDeviceTypes dtypes torch float torch double test_adaptive_pooling_zero_batch dtype device inp = torch ones dtype=dtype device=device mod = torch nn AdaptiveAvgPool d device _test_module_empty_input mod inp check_size=False inp = torch ones dtype=dtype device=device mod = torch nn AdaptiveAvgPool d device _test_module_empty_input mod inp check_size=False inp = torch ones dtype=dtype device=device mod = torch nn AdaptiveAvgPool d device _test_module_empty_input mod inp check_size=False The tests used verify functions raises errors backward propagation when output_size = adaptive_ avg max _pool its variants These tests explicitly written because ErrorInputs does support backward calls Issue https github com pytorch pytorch issues expectedFailureMPS No double float shape prop does work onlyNativeDeviceTypes dtypes torch float torch float dtypesIfCUDA torch float torch float torch bfloat torch float test_adaptive_pooling_empty_output_size dtype device error_msg = Expected grad_output have non-zero size non-batch dimensions make_arg = partial make_tensor device=device dtype=dtype requires_grad=True input = make_arg output_size = fns = nn functional adaptive_avg_pool d nn functional adaptive_avg_pool d nn functional adaptive_max_pool d nn functional adaptive_max_pool d fn fns assertRaisesRegex RuntimeError error_msg fn input output_size sum backward fns = nn functional adaptive_avg_pool d nn functional adaptive_max_pool d input = make_arg fn fns assertRaisesRegex RuntimeError error_msg fn input output_size sum backward expectedFailureMPS Error message does match onlyNativeDeviceTypes test_adaptive_avg_pooling_backward_fails device grad_output = torch randn device=device input = torch randn device=device assertRaisesRegex RuntimeError Expected dimensions torch ops aten _adaptive_avg_pool d_backward grad_output input grad_output = torch randn device=device input = torch randn device=device assertRaisesRegex RuntimeError Expected dimensions torch ops aten _adaptive_avg_pool d_backward grad_output input onlyNativeDeviceTypes test_adaptive_max_pooling_backward_fails device grad_output = torch randn device=device input = torch randn device=device indices = torch ones dtype=torch long device=device assertRaisesRegex RuntimeError expected sizes torch ops aten adaptive_max_pool d_backward grad_output input indices grad_output = torch randn device=device input = torch randn device=device indices = torch ones dtype=torch long device=device assertRaisesRegex RuntimeError expected dimensions torch ops aten adaptive_max_pool d_backward grad_output input indices expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_batch device mod = nn FractionalMaxPool d output_ratio= inp = torch ones device=device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected input inp = torch randn device=device mod inp expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_batch device mod = nn FractionalMaxPool d output_ratio= device inp = torch ones device=device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected input inp = torch randn device=device mod inp expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_out_size device mod = nn FractionalMaxPool d output_size= inp = torch rand device=device out = mod inp assertEqual out torch empty device=device expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_out_size device mod = nn FractionalMaxPool d output_size= inp = torch rand device=device out = mod inp assertEqual out torch empty device=device expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_samples device samples = torch rand device=device mod = nn FractionalMaxPool d output_size= _random_samples=samples inp = torch randn device=device out = mod inp assertEqual out torch empty device=device inp = torch randn device=device assertRaisesRegex RuntimeError Expect _random_samples mod inp expectedFailureMPS Op implemented onlyNativeDeviceTypes test_FractionalMaxPool d_zero_samples device samples = torch rand device=device mod = nn FractionalMaxPool d output_size= _random_samples=samples inp = torch randn device=device out = mod inp assertEqual out torch empty device=device inp = torch randn device=device assertRaisesRegex RuntimeError Expect _random_samples mod inp onlyNativeDeviceTypes test_FractionalMaxPool d_errors device samples = torch rand device=device assertRaisesRegex ValueError kernel_size must greater than nn FractionalMaxPool d output_size= _random_samples=samples assertRaisesRegex ValueError kernel_size must greater than nn FractionalMaxPool d output_size= _random_samples=samples samples = torch randn assertRaisesRegex RuntimeError too large relative nn FractionalMaxPool d kernel_size= output_size= samples assertRaisesRegex ValueError kernel_size must greater than nn FractionalMaxPool d kernel_size=- output_size= samples onlyNativeDeviceTypes test_MaxPool d_errors device samples = torch randn assertRaisesRegex RuntimeError integer out range nn MaxPool d kernel_size= samples assertRaisesRegex RuntimeError kernel size should greater than zero nn MaxPool d kernel_size=- samples onlyNativeDeviceTypes test_MaxPool_zero_batch_dim device inp = torch randn device=device mod = torch nn MaxPool d stride= device _test_module_empty_input mod inp check_size=False D supposed okay numel inputs so dont test error raising case inp = torch randn device=device mod = torch nn MaxPool d stride= device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected inp = torch randn device=device mod inp inp = torch ones device=device mod = torch nn MaxPool d stride= device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected inp = torch ones device=device mod inp onlyNativeDeviceTypes test_MaxUnpool_zero_batch_dim device pool = torch nn MaxPool d stride= return_indices=True device unpool = torch nn MaxUnpool d stride= device inp = torch randn requires_grad=True device=device output indices = pool inp output requires_grad_ True unpool_out = unpool output indices unpool_out sum backward assertEqual inp grad torch zeros_like inp assertEqual unpool_out torch zeros_like unpool_out pool = torch nn MaxPool d stride= return_indices=True device unpool = torch nn MaxUnpool d stride= device inp = torch randn requires_grad=True device=device output indices = pool inp unpool_out = unpool output indices unpool_out sum backward assertEqual inp grad torch zeros_like inp assertEqual unpool_out torch zeros_like unpool_out pool = torch nn MaxPool d stride= return_indices=True device unpool = torch nn MaxUnpool d stride= device inp = torch randn requires_grad=True device=device output indices = pool inp output requires_grad_ True unpool_out = unpool output indices unpool_out sum backward assertEqual inp grad torch zeros_like inp assertEqual unpool_out torch zeros_like unpool_out slowTest onlyNativeDeviceTypes skipCUDAIfRocm parametrize_test module_name module_size output_size test_index should_error Some tests failing trunk https github com pytorch pytorch issues subtest MaxUnpool d - True name= case subtest MaxUnpool d True name= case subtest MaxUnpool d - False name= case subtest MaxUnpool d True name= case subtest MaxUnpool d - False name= case subtest MaxUnpool d - True name= case subtest MaxUnpool d True name= case subtest MaxUnpool d - False name= case subtest MaxUnpool d True name= case subtest MaxUnpool d - False name= case test_MaxUnpool_index_errors device module_name module_size output_size test_index should_error NOTE CUDA tests need run subprocess because they cause device asserts torch device device type == cuda error_msgs = MaxUnpool d r Assertion ` maxind = maxind outputImageSize ` failed MaxUnpool d r Assertion ` index = index outputImageSize ` failed script = f torch unpool = torch nn module_name module_size device output = torch rand output_size dtype=torch float device= device indices = torch zeros output_size dtype=torch int device= device indices flatten = test_index unpool output indices torch cuda synchronize p = subprocess run sys executable -c script cwd=os path dirname os path realpath __file__ capture_output=True text=True output = p stdout + \n + p stderr error_msg = error_msgs module_name should_error assertIn error_msg output The expected error found assertNotIn Error output Should have produced error module_class = getattr torch nn module_name unpool = module_class module_size device output = torch rand output_size dtype=torch float device=device indices = torch zeros output_size dtype=torch int device=device indices flatten = test_index should_error assertRaisesRegex RuntimeError r Found invalid max index unpool output indices unpool output indices https github com pytorch pytorch issues onlyNativeDeviceTypes test_MaxUnpool_invalid_output_size device input d = torch randn input d = torch randn unpool d = torch nn MaxUnpool d unpool d = torch nn MaxUnpool d assertRaisesRegex RuntimeError There should exactly unpool d input d torch zeros_like input d dtype=torch int assertRaisesRegex RuntimeError There should exactly unpool d input d torch zeros_like input d dtype=torch int expectedFailureMPS onlyNativeDeviceTypes test_AdaptiveMaxPool_zero_batch_dim device inp = torch randn device=device mod = torch nn AdaptiveMaxPool d device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected inp = torch randn device=device mod inp inp = torch randn device=device mod = torch nn AdaptiveMaxPool d device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected inp = torch randn device=device mod inp inp = torch ones device=device mod = torch nn AdaptiveMaxPool d device _test_module_empty_input mod inp check_size=False assertRaisesRegex RuntimeError Expected inp = torch ones device=device mod inp onlyCPU test_LPPool d_kernel_size_overflow_large device avgpool = torch nn LPPool d - e ceil_mode=True device inp = torch randn device=device assertRaisesRegex RuntimeError integer out range avgpool inp onlyNativeDeviceTypes test_AvgPool d_empty device avgpool = torch nn AvgPool d stride= device inp = torch randn device=device _test_module_empty_input avgpool inp check_size=False clast_inp = torch randn device=device contiguous memory_format=torch channels_last _test_module_empty_input avgpool clast_inp check_size=False test empty non-batch input assertRaisesRegex RuntimeError D D inp = torch randn device=device avgpool inp parametrize_test kernel max avg parametrize_test pooling_dims test_pooling_shape device kernel pooling_dims Test output shape calculation pooling functions kernel == max pooling_dims == This case causes process abort so need skip now skipTest Skipping avoid abort Checks output shape against expected D D D check expected_out_shape sizes args kwargs hasattr torch nn functional f kernel _pool pooling_dims d op = getattr torch nn functional f kernel _pool pooling_dims d t = torch randn sizes pooling_dims + device=device assertEqual op t args kwargs shape expected_out_shape pooling_dims + check kernel_size= stride= padding= ceil_mode=True check kernel_size= stride= padding= ceil_mode=False check kernel_size= stride= padding= ceil_mode=True Test case issue https github com pytorch pytorch issues x = torch randn device=device y = torch nn functional max_pool d x stride= padding= ceil_mode=True assertEqual y size onlyNativeDeviceTypes TODO fix XLA test_adaptive_avg_pool d_output_size_one device helper size memory_format x = torch randint size dtype=torch float device=device requires_grad=True memory_format == non_contiguous x = x x = x memory_format=memory_format net = torch nn AdaptiveAvgPool d out = net x ref_out = x contiguous mean - - view x size x size out sum backward make sure doesn t crash assertEqual out ref_out memory_format == torch channels_last assertTrue out is_contiguous memory_format=torch channels_last c = out size assertEqual out stride c c c assertTrue out is_contiguous c = out size assertEqual out stride c mf torch contiguous_format torch channels_last non_contiguous helper mf onlyNativeDeviceTypes test_adaptive_avg_pool d_output_size_one device x = torch randn dtype=torch float device=device requires_grad=True net = torch nn AdaptiveAvgPool d out = net x ref_out = x contiguous mean - - - view out shape out sum backward make sure doesn t crash assertEqual out ref_out assertTrue out is_contiguous c = out size assertEqual out stride c expectedFailureMPS Runtime Error raised mps expectedFailureMeta Runtime Error raised meta onlyNativeDeviceTypes dtypes torch uint torch int torch short torch int torch long test_adaptive_pooling_no_suppot_input device dtype numel pool_type Max Avg cls_name = f Adaptive pool_type Pool numel d module_cls = getattr nn cls_name output_size = numel module = module_cls output_size input = torch randn numel + device=device dtype assertRaisesRegex RuntimeError implemented module input expectedFailureMPS TODO fixme onlyNativeDeviceTypes gcIfJetson dtypes torch float torch double dtypesIfCUDA torch half torch float torch double test_avg_pool d_nhwc device dtype helper n c h w kernel_size stride=None count_include_pad=True divisor_override=None padding= stride None stride = kernel_size input = torch randn n c h w dtype=dtype device=device input = input contiguous memory_format=torch channels_last requires_grad_ grad = torch randn n c h - kernel_size stride + w - kernel_size stride + dtype=dtype device=device pool = torch nn AvgPool d kernel_size stride=stride count_include_pad=count_include_pad divisor_override=divisor_override device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn AvgPool d kernel_size stride=stride count_include_pad=count_include_pad divisor_override=divisor_override device out = pool input out backward grad ref_out = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertEqual out ref_out assertEqual input grad ref_input grad helper helper count_include_pad=False padding= helper count_include_pad=False padding= stride= helper divisor_override= helper ROCm GB MI hits OOM error Clear caching allocator prior running large subtest TEST_WITH_ROCM cuda device torch cuda empty_cache helper helper stride= helper padding= stride= helper stride= helper stride= onlyCPU dtypes torch float torch double test_max_pool d_corner_cases device dtype check x args expected model = torch nn MaxPool d args isinstance x list x = torch tensor x device=device dtype=dtype expected = torch tensor expected device=device dtype=dtype assertEqual model x expected Pooling args kernel_size stride padding dilation return_indices ceil_mode check None False False check None False False float -inf check None False False float -inf float -inf check False False check False True onlyCPU dtypes torch float torch double skipIfTorchDynamo OOMs https github com pytorch pytorch issues test_max_pool d device dtype FIXME For now compare against max_pool d indices check x args kwargs model = torch nn MaxPool d args kwargs ref_model = torch nn MaxPool d args kwargs return_indices=True assertEqual model x ref_model x sizes = random sample range _ range kernel_sizes = random sample range strides = random sample range dilations = random sample range ceil_modes = True False size kernel_size stride dilation ceil_mode itertools product sizes kernel_sizes strides dilations ceil_modes padding = random sample range math floor kernel_size + check torch randn size device=device dtype=dtype kernel_size stride padding dilation ceil_mode=ceil_mode Non-contiguous test tensor = torch randn device=device dtype=dtype check tensor ceil_mode=True check tensor transpose ceil_mode=True onlyCUDA gcIfJetson test_max_pool d device helper n c h w ks x = torch randn n c h w device= cuda dtype=torch float requires_grad=True ref_x = x detach clone cpu requires_grad_ pool = torch nn MaxPool d kernel_size=ks y = pool x ref_y = pool ref_x y sum backward ref_y sum backward assertEqual y ref_y assertEqual x grad ref_x grad helper ks= helper ks= helper ks= test max_pool d expectedFailureMPS TODO Fixme onlyNativeDeviceTypes dtypes torch half torch bfloat torch float torch double dtypesIfCUDA torch half torch float torch double gcIfJetson test_max_pool d_nhwc device dtype helper n c h w kernel_size stride=None stride None stride = kernel_size input = torch randn n c h w dtype=dtype device=device input = input contiguous memory_format=torch channels_last requires_grad_ grad = torch randn n c h - kernel_size stride + w - kernel_size stride + dtype=dtype device=device pool = torch nn MaxPool d kernel_size stride return_indices=True device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn MaxPool d kernel_size stride return_indices=True device out ind = pool input out backward grad ref_out ref_ind = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertTrue ind is_contiguous memory_format=torch channels_last assertTrue ref_ind is_contiguous assertEqual out ref_out assertEqual ind ref_ind assertEqual input grad ref_input grad helper helper helper stride= helper stride= helper stride= onlyCPU dtypes torch int torch int test_max_pool d_corner_cases device dtype check x args expected memory_format model = torch nn MaxPool d args isinstance x list x = torch tensor x device=device dtype=dtype memory_format=memory_format expected = torch tensor expected device=device dtype=dtype memory_format=memory_format assertEqual model x expected Pooling args kernel_size stride padding dilation return_indices ceil_mode check - - - - False True - - - - torch contiguous_format check - - - - False True - - - - torch channels_last expectedFailureMPS TODO Fixme onlyNativeDeviceTypes dtypes torch half torch bfloat torch float torch double dtypesIfCUDA torch half torch float torch double gcIfJetson test_max_pool d_ndhwc device dtype helper n c h w d kernel_size stride=None batch = n batch batch = input = torch randn batch c d h w dtype=dtype device=device input = input contiguous memory_format=torch channels_last_ d requires_grad_ n input = input squeeze detach clone requires_grad_ isinstance kernel_size int kernel_size = kernel_size stride None stride = kernel_size isinstance stride int stride = stride grad = torch randn batch c d - kernel_size stride + h - kernel_size stride + w - kernel_size stride + dtype=dtype device=device grad = grad contiguous memory_format=torch channels_last_ d n grad = grad squeeze pool = torch nn MaxPool d kernel_size stride return_indices=True device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn MaxPool d kernel_size stride return_indices=True device out ind = pool input out backward grad ref_out ref_ind = ref_pool ref_input ref_out backward ref_grad len out shape == assertTrue out unsqueeze is_contiguous memory_format=torch channels_last_ d assertTrue out is_contiguous memory_format=torch channels_last_ d assertTrue ref_out is_contiguous len ind shape == assertTrue ind unsqueeze is_contiguous memory_format=torch channels_last_ d assertTrue ind is_contiguous memory_format=torch channels_last_ d assertTrue ref_ind is_contiguous assertEqual out ref_out assertEqual ind ref_ind dtype == torch half assertEqual input grad ref_input grad atol= rtol= assertEqual input grad ref_input grad helper helper helper helper helper stride= helper stride= helper stride= helper stride= helper stride= helper stride= helper stride= onlyCPU dtypes torch half torch bfloat test_max_pool_bfloat _half device dtype helper shape kernel_size stride memory_format dtype input = torch randn shape dtype=dtype device=device input = input memory_format=memory_format requires_grad_ len shape == pool = torch nn MaxPool d kernel_size stride return_indices=True device pool = torch nn MaxPool d kernel_size stride return_indices=True device input = input detach clone float requires_grad_ True out ind = pool input out sum backward out ind = pool input out sum backward assertTrue out is_contiguous memory_format=memory_format assertEqual out dtype dtype assertEqual input grad dtype dtype assertEqual out out dtype=dtype assertEqual ind ind assertEqual input grad input grad dtype=dtype helper torch contiguous_format dtype helper torch channels_last dtype helper torch contiguous_format dtype helper torch channels_last dtype helper torch contiguous_format dtype helper torch channels_last dtype helper torch contiguous_format dtype helper torch channels_last_ d dtype helper torch contiguous_format dtype helper torch channels_last_ d dtype onlyCUDA gcIfJetson test_max_pool d_indices device helper n c h w ks n None x = torch randn c h w device= cuda dtype=torch float requires_grad=True x = torch randn n c h w device= cuda dtype=torch float requires_grad=True ref_x = x detach clone cpu requires_grad_ pool = torch nn MaxPool d kernel_size=ks return_indices=True y idx = pool x ref_y ref_idx = pool ref_x y sum backward ref_y sum backward assertEqual y ref_y assertEqual idx ref_idx assertEqual implicitly compares shape tensors assertEqual x grad ref_x grad helper ks= helper None ks= onlyNativeDeviceTypes test_max_pool d_with_indices_backward_fails device grad_output = torch randn device=device input = torch randn device=device indices = torch ones dtype=torch long device=device kernel_size = stride = padding = dilation = ceil_mode = False assertRaisesRegex RuntimeError Expected tensor dimension torch ops aten max_pool d_with_indices_backward grad_output input kernel_size stride padding dilation ceil_mode indices test_max_unpool_invalid_indices input = torch randn negative_indices = torch tensor - dtype=torch int large_indices = torch tensor dtype=torch int output_size = assertRaisesRegex RuntimeError Found invalid max index F max_unpool d input negative_indices output_size assertRaisesRegex RuntimeError Found invalid max index F max_unpool d input large_indices output_size input = torch randn negative_indices = torch tensor - dtype=torch int large_indices = torch tensor dtype=torch int output_size = assertRaisesRegex RuntimeError Found invalid max index F max_unpool d input negative_indices output_size assertRaisesRegex RuntimeError Found invalid max index F max_unpool d input large_indices output_size onlyCPU dtypes torch half torch bfloat test_avg_pool d_reduced_floating device dtype helper n c h w kernel_size stride memory_format input = torch randn n c h w dtype=torch float device=device dtype=dtype input = input memory_format=memory_format requires_grad_ pool = torch nn AvgPool d kernel_size stride device input = input detach clone float requires_grad_ True out = pool input out sum backward out = pool input out sum backward assertTrue out is_contiguous memory_format=memory_format assertEqual out dtype dtype assertEqual input grad dtype dtype assertEqual out out dtype=dtype assertEqual input grad input grad dtype=dtype helper torch contiguous_format helper torch channels_last helper torch contiguous_format helper torch channels_last dtypes torch float torch double dtypesIfMPS torch float expectedFailureMPS test_adaptive_pooling_max_nhwc currently fails MPS - ISSUE# test_adaptive_pooling_max_nhwc device dtype helper input_size output_plane_size contig n_plane_dims = len output_plane_size mod = torch nn AdaptiveMaxPool d n_plane_dims == torch nn AdaptiveMaxPool d channels_last = torch channels_last n_plane_dims == torch channels_last_ d output_size = input_size + output_plane_size input = torch randint input_size device=device dtype=dtype input = input contiguous memory_format=channels_last grad = torch randint output_size device=device dtype=dtype grad = grad contiguous memory_format=channels_last contig input = input grad = grad input requires_grad_ True pool = mod output_plane_size return_indices=True device ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = mod output_plane_size return_indices=True device out ind = pool input out backward grad ref_out ref_ind = ref_pool ref_input ref_out backward ref_grad channels_last_ d case does channels_last_ d outputs n_plane_dims == assertTrue out is_contiguous memory_format=channels_last assertTrue ind is_contiguous memory_format=channels_last assertTrue ref_out is_contiguous assertTrue ref_ind is_contiguous assertEqual out ref_out assertEqual ind ref_ind assertEqual input grad ref_input grad contig True False helper contig helper contig helper contig helper contig helper contig helper contig helper contig dtypes torch float torch double dtypesIfMPS torch float expectedFailureMPS test_pooling_max_nhwc currently fails MPS - ISSUE# test_pooling_max_nhwc device dtype helper n c h w kernel_size stride padding dilation contig device output_height = math floor h + padding - dilation kernel_size - - stride + output_width = math floor w + padding - dilation kernel_size - - stride + input = torch randint n c h w device=device dtype=dtype input = input contiguous memory_format=torch channels_last grad = torch randint n c output_height output_width device=device dtype=dtype grad = grad contiguous memory_format=torch channels_last contig input = input grad = grad input requires_grad_ True pool = torch nn MaxPool d kernel_size stride padding dilation return_indices=True ceil_mode=False ref_input = input detach clone contiguous requires_grad_ True ref_grad = grad detach clone contiguous ref_pool = torch nn MaxPool d kernel_size stride padding dilation return_indices=True ceil_mode=False device out ind = pool input out backward grad ref_out ref_ind = ref_pool ref_input ref_out backward ref_grad assertTrue out is_contiguous memory_format=torch channels_last assertTrue ref_out is_contiguous assertTrue ind is_contiguous memory_format=torch channels_last assertTrue ref_ind is_contiguous assertEqual out ref_out assertEqual ind ref_ind assertEqual input grad ref_input grad contig True False helper contig device helper contig device helper contig device onlyCUDA test_pool d_size_one_feature_dim device Tests crazy strides feature dim size x = torch randn device=device strange_strides = y = x as_strided x size strange_strides x = x cpu as_strided x size strange_strides to_test = max_pool d lambda t F max_pool d t stride= avg_pool d lambda t F avg_pool d t stride= test fn to_test items Should crash out_y = fn y out_x = fn x assertEqual out_y out_x device msg=test onlyCUDA largeTensorTest GB largeTensorTest GB cpu test_pool d_large_size_int device See https github com pytorch pytorch issues x = torch randn dtype=torch half device=device requires_grad=True y = torch nn functional max_pool d x g = torch randn_like y dtype=torch half torch cuda synchronize y backward g torch cuda synchronize ref_x = x detach cpu float max_pool d_cpu implemented half ref_x requires_grad = True ref_g = g cpu float ref_y = torch nn functional max_pool d ref_x ref_y backward ref_g assertEqual y ref_y exact_dtype=False assertEqual x grad ref_x grad exact_dtype=False onlyCUDA test_AvgPool d_backward_after_cat_dim _device device x has have batch_size test contiguous checks x = torch randn device=device requires_grad=True y = F avg_pool d x kernel_size= padding= stride= grad = torch randn y size device=device increase stride dimension tensor still contiguous because size stride = list grad stride stride = stride grad set_ grad storage grad size stride assert grad is_contiguous y backward grad _test_maxpool_indices num_dim adaptive=False device= cpu dtype=torch float expected_indices dim dtype dim == torch tensor dtype=dtype repeat dim == torch tensor dtype=dtype repeat expected_grad dim dtype dim == torch tensor dtype=dtype repeat grad = expected_grad dim - dtype=dtype zero = torch zeros grad size dtype=dtype torch stack zero grad zero grad expected_output dim dtype dim == torch arange dtype=dtype view dim == col = torch arange dtype=dtype torch stack col col + view adaptive cls_name = f AdaptiveMaxPool num_dim d FIXME Test fails when using f-string cls_name = f MaxPool num_dim d module_cls = getattr nn cls_name module = module_cls return_indices=True device dtype=dtype numel = num_dim + input = torch arange numel + view repeat num_dim device dtype=dtype input_var = input detach clone requires_grad_ Check forward output indices = module input_var num_dim = expected_indices = expected_indices num_dim dtype=indices data dtype expected_output = expected_output num_dim dtype=output data dtype assertEqual indices dim input dim assertEqual indices data squeeze expected_indices assertEqual output data squeeze expected_output assertTrue output requires_grad assertFalse indices requires_grad Make sure backward works grad_output = torch ones output size device=device dtype=dtype output backward grad_output retain_graph=True expected_grad = expected_grad num_dim dtype=input_var grad data dtype assertEqual input_var grad data expected_grad view_as input Make sure backward after changing indices will result error indices add_ assertRaises RuntimeError lambda output backward grad_output Make sure -Infinity handled correctly t = torch tensor float -inf m = nn MaxPool d kernel_size= return_indices=True output indices = m t assertEqual output float -inf assertEqual indices t = torch tensor float -inf m = nn MaxPool d kernel_size= return_indices=True output indices = m t assertEqual output float -inf assertEqual indices t = torch tensor float -inf m = nn MaxPool d kernel_size= return_indices=True output indices = m t assertEqual output float -inf assertEqual indices dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_MaxPool d_indices device dtype _test_maxpool_indices device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_MaxPool d_indices device dtype _test_maxpool_indices device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_MaxPool d_indices device dtype _test_maxpool_indices device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_AdaptiveMaxPool d_indices device dtype _test_maxpool_indices adaptive=True device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_AdaptiveMaxPool d_indices device dtype _test_maxpool_indices adaptive=True device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat expectedFailureMPS dtypes torch float test_AdaptiveMaxPool d_indices device dtype _test_maxpool_indices adaptive=True device=device dtype=dtype dtypesIfCUDA floating_types_and torch half torch bfloat expectedFailureMPS dtypes torch float test_maxpool_indices_no_batch_dim device dtype Check indices no batch dim consistent single batch max_pool_cases = nn MaxPool d return_indices=True torch randn device=device dtype=dtype nn MaxPool d return_indices=True torch randn device=device dtype=dtype nn MaxPool d return_indices=True torch randn device=device dtype=dtype nn AdaptiveMaxPool d return_indices=True torch randn device=device dtype=dtype nn AdaptiveMaxPool d return_indices=True torch randn device=device dtype=dtype nn AdaptiveMaxPool d return_indices=True torch randn device=device dtype=dtype module input max_pool_cases _ indices_no_batch = module input _ indicies_single_batch = module input unsqueeze assertEqual indices_no_batch indicies_single_batch squeeze dtypesIfCUDA torch half torch float torch double dtypes torch float expectedFailureMPS Exception raise onlyNativeDeviceTypes TODO Fails XLA gcIfJetson test_max_pool_nan_inf device dtype adaptive adaptive_ num_dim fn_name = f adaptive max_pool num_dim d fn = getattr F fn_name x = torch full + num_dim nan device=device dtype=dtype requires_grad=True res = fn x adaptive res backward torch randn_like res assertTrue math isnan res item x requires_grad_ False res = fn x adaptive assertTrue math isnan res item x = torch full + num_dim -inf device=device dtype=dtype requires_grad=True res = fn x adaptive res backward torch randn_like res assertTrue math isinf res item x requires_grad_ False res = fn x adaptive assertTrue math isinf res item expectedFailureMPS float expectedFailureMeta RuntimeError Unrecognized tensor type ID Meta onlyNativeDeviceTypes test_fractional_max_pool d device set_default_dtype torch double x = torch randn requires_grad=True device=device samples = x new uniform_ func x F fractional_max_pool d x output_size= _random_samples=samples assertEqual func x shape gradcheck func x gradgradcheck func x x = torch randn requires_grad=True device=device assertEqual func x shape device_type = cuda Reference https github com pytorch pytorch issues Raises - RuntimeError TensorAccessor expected dims tensor has CUDA gradcheck gradcheck func x gradgradcheck func x kernel_size assertRaisesRegex RuntimeError kernel_size must either Incorrect kernel_size F fractional_max_pool d x kernel_size=kernel_size output_size= _random_samples=samples err_large_msg = too large relative input err_out_size_msg = output_size must either output_size msg err_large_msg + height err_large_msg + width err_out_size_msg err_out_size_msg assertRaisesRegex RuntimeError msg Incorrect output_size F fractional_max_pool d x output_size=output_size _random_samples=samples onlyNativeDeviceTypes test_fractional_max_pool d_backward_fails device grad_output = torch randn device=device input = torch randn device=device kernel_size = output_size = indices = torch ones dtype=torch long device=device assertRaisesRegex RuntimeError gradOutput sizes unexpected torch ops aten fractional_max_pool d_backward grad_output input kernel_size output_size indices expectedFailureMPS float expectedFailureMeta RuntimeError Unrecognized tensor type ID Meta onlyNativeDeviceTypes test_fractional_max_pool d device set_default_dtype torch double x = torch randn requires_grad=True device=device samples = x new uniform_ func x F fractional_max_pool d x output_size= _random_samples=samples assertEqual func x shape gradcheck func x gradgradcheck func x x = torch randn requires_grad=True device=device assertEqual func x shape gradcheck func x gradgradcheck func x kernel_size assertRaisesRegex RuntimeError kernel_size must either Incorrect kernel_size F fractional_max_pool d x kernel_size=kernel_size output_size= _random_samples=samples err_large_msg = too large relative input err_out_size_msg = output_size must either output_size msg err_large_msg + time err_large_msg + height err_large_msg + width err_out_size_msg err_out_size_msg err_out_size_msg assertRaisesRegex RuntimeError msg Incorrect output_size F fractional_max_pool d x output_size=output_size _random_samples=samples expectedFailureMPS Not implemented dtypesIfCUDA torch half torch float torch double dtypes torch float onlyNativeDeviceTypes TODO Fails XLA test_fractional_max_pool_nan_inf device dtype num_dim fn_name = f FractionalMaxPool num_dim d fn = getattr nn fn_name kernel_size= output_size= x = torch full + num_dim nan device=device dtype=dtype requires_grad=True res = fn x res backward torch randn_like res assertTrue math isnan res item x = torch full + num_dim -inf device=device dtype=dtype requires_grad=True res = fn x res backward torch randn_like res assertTrue math isinf res item expectedFailureMPS TODO Fix me onlyNativeDeviceTypes TODO RuntimeError message different XLA test_pooling_zero_stride device op max avg num_dim fn_name = f op _pool num_dim d fn = getattr F fn_name x = torch ones + num_dim device=device dtype=torch float assertRaisesRegex RuntimeError r stride should zero &#124; stride must greater than zero lambda fn x kernel_size= stride= fn_module_name = f op title Pool num_dim d fn_module = getattr nn fn_module_name kernel_size= stride= assertRaisesRegex RuntimeError r stride should zero &#124; stride must greater than zero lambda fn_module x dtypesIfCUDA floating_types_and torch half torch bfloat dtypes torch float test_pool_large_size device dtype op max avg num_dim fn_name = f op _pool num_dim d fn = getattr F fn_name smallest integer expressible float x = torch ones + num_dim - device=device dtype=dtype res = fn x stride= padding= check output shape still computed correctly assertEqual x shape res shape onlyCUDA largeTensorTest GB test_pooling_large device helper pool inp = torch randn + dtype=torch half device= cuda assertTrue inp numel - pool inp torch cuda synchronize asserts test finishes normally without raising errors helper nn MaxPool d helper nn AvgPool d helper nn FractionalMaxPool d helper nn AdaptiveMaxPool d helper nn AdaptiveAvgPool d dtypesIfCUDA floating_types_and torch half torch bfloat expectedFailureMPS dtypes torch float test_pool_invalid_size device dtype op max avg num_dim fn_name = f op _pool num_dim d op == max New implementation without indices supports empty tensors TODO Heitor change once with_indices code updated fn_name += _with_indices fn = getattr F fn_name use configuration gives zero outputs only when doing correct floor division stride x = torch ones + num_dim device=device dtype=dtype assertRaisesRegex RuntimeError r too small &#124; smaller than try fn x stride= padding= dilation= except TypeError some implementations do support dilation fn x stride= padding= onlyCUDA test_pooling_bfloat device _test_bfloat _ops torch nn AvgPool d stride= device inp_dims= prec= _test_bfloat _ops torch nn AvgPool d stride= device inp_dims= prec= _test_bfloat _ops torch nn AvgPool d stride= device inp_dims= prec= _test_bfloat _ops torch nn AdaptiveAvgPool d device inp_dims= prec= _test_bfloat _ops torch nn AdaptiveAvgPool d device inp_dims= prec= _test_bfloat _ops torch nn AdaptiveAvgPool d device inp_dims= prec= test_maxpool d_non_square_backward device previous CUDA routine backward calculates kernel launch grid size last two dimensions interchanged so tailing along longer dim get ignored Here we test whether every position gets gradient dim shape = tuple i = dim i range x = torch randn shape device=device requires_grad=True F max_pool d x kernel_size= sum backward assertEqual x grad torch ones_like x grad slowTest test_adaptive_pool_odd_size device See https github com pytorch pytorch issues Ih Iw Oh Ow = imgs = torch randint low= high= size= Ih Iw dtype=torch float _imgs = F adaptive_avg_pool d imgs Oh Ow _imgs = F adaptive_max_pool d imgs Oh Ow Id Ih Iw Od Oh Ow = imgs = torch randint low= high= size= Id Ih Iw dtype=torch float F adaptive_avg_pool d imgs Od Oh Ow F adaptive_max_pool d imgs Od Oh Ow instantiate_device_type_tests TestPoolingNNDeviceType globals allow_mps=True instantiate_parametrized_tests TestPoolingNN __name__ == __main__ run_tests