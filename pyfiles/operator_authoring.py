timeit functools partial numpy np pandas pd torch functorch compile pointwise_operator WRITE_CSV = False CUDA = False SIZES = NUMBER = REPEAT = pointwise_operator nnc_add b + b pointwise_operator nnc_addnorm b mean std + b - mean std eager_addnorm b mean std + b - mean std inplace_addnorm b mean std out out = torch add b out=out torch sub out mean out=out torch div out std out=out out ts_addnorm = torch jit script eager_addnorm ts_ip_addnorm = torch jit script inplace_addnorm maybe_synced fn CUDA synchronize = torch cuda synchronize synchronize warmup _fn result = fn synchronize result _fn fn benchmark_loop setup result = np zeros REPEAT len SIZES dtype=np float s n enumerate SIZES nnc aten = setup n nnc = maybe_synced nnc aten = maybe_synced aten r range result shape result r s = timeit timeit nnc number=NUMBER s result r s = timeit timeit aten number=NUMBER s result = np median result axis= assert result shape == len SIZES result = result result print result result test make_args nnc=nnc_add aten=torch add setup n args = make_args n result_aten = aten args result_nnc = nnc args assert result_nnc dtype == result_aten dtype assert result_nnc size == result_aten size assert result_nnc stride == result_aten stride torch testing assert_close result_aten result_nnc lambda nnc args lambda aten args benchmark_loop setup test_inplace make_args nnc=nnc_add aten=torch add inplace_setup n b = make_args n result_aten = torch clone result_nnc = torch clone nnc result_nnc b out=result_nnc aten result_aten b out=result_aten torch testing assert_close result_aten result_nnc lambda nnc b out=a lambda aten b out=a benchmark_loop inplace_setup test_out make_args out nnc=nnc_add aten=torch add out_setup n args = make_args n result_aten = out n result_nnc = out n aten args out=result_aten nnc args out=result_nnc torch testing assert_close result_aten result_nnc result = out n lambda nnc args out=result lambda aten args out=result benchmark_loop out_setup test_backwards make_args nnc=nnc_add aten=torch add backwards_setup n args = make_args n grad_var = args requires_grad aten args sum backward correct = grad_var grad clone grad_var grad zero_ nnc args sum backward torch testing assert_close correct grad_var grad lambda nnc args sum backward lambda aten args sum backward benchmark_loop backwards_setup main torch set_num_threads TODO jansel add parallel support torch _C _jit_override_can_fuse_on_cpu True device = cuda CUDA cpu I = partial torch randint device=device R = partial torch randn device=device results = add test lambda n R n n R n n broadcast test lambda n R n n R broadcast test lambda n R n n R n broadcast test lambda n R n R n inplace test_inplace lambda n R n n R n out= test_out lambda n R n n R n n out=lambda n R n n transposed test lambda n R n n R n n transpose transposed test lambda n R n n transpose R n n transpose slice test lambda n R n + n + n n R n n slice test lambda n R n n R n n strided out test_out lambda n R n n R n n out=lambda n R n + n + n n out convert test_out lambda n R n n R n n out=lambda n R n n dtype=torch float issue n test lambda n R R n float+double test lambda n R n n R n n dtype=torch float int+long test lambda n I n n dtype=torch int I n n dtype=torch int int+short test lambda n I n n dtype=torch int I n n dtype=torch int float+int test lambda n R n n dtype=torch float I n n dtype=torch int double+long test lambda n R n n dtype=torch float I n n dtype=torch int fused addnorm test lambda n R n n R n n R n n R n n nnc=nnc_addnorm aten=eager_addnorm fused addnorm vs TS test lambda n R n n R n n R n n R n n nnc=nnc_addnorm aten=ts_addnorm fused addnorm out= test_out lambda n R n n R n n R n n R n n nnc=nnc_addnorm aten=inplace_addnorm out=lambda n R n n fused addnorm out= vs TS test_out lambda n R n n R n n R n n R n n nnc=nnc_addnorm aten=ts_ip_addnorm out=lambda n R n n fused addnorm backward test_backwards lambda n R n n R n n requires_grad=True R n n R n n nnc=nnc_addnorm aten=eager_addnorm fused addnorm backward vs TS test_backwards lambda n R n n R n n requires_grad=True R n n R n n nnc=nnc_addnorm aten=ts_addnorm df = pd DataFrame np stack r n r results columns= f n x n rjust n SIZES index= n n r results WRITE_CSV df to_csv operator_authoring_results csv print wrote operator_authoring_results csv print print Speedups over aten pd options display float_format = f x format print df __name__ == __main__ main