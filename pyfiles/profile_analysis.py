json logging math collections defaultdict dataclasses dataclass typing Any Callable Optional Union torch torch _inductor analysis device_info DeviceInfo lookup_device_info torch _inductor utils tabulate_ d zip_dicts torch utils _pytree pytree torch utils _ordered_set OrderedSet torch utils flop_counter flop_registry log = logging getLogger __name__ ATEN_PREFIX = aten dataclass ProfileEvent category str key str self_device_time_ms float benchmark run multiple times we average count across all runs It should integer define float just case count float adapters convert json trace into format works flops_counter ArgsType = tuple tuple Any dict Any Any AdapterType = Callable tuple Any tuple Any ArgsType adapters_map dict str AdapterType = parse_list lst str - list int lst = lst replace replace substrings = lst split int substring strip substring substrings register_adapter aten Union str list str - Callable AdapterType AdapterType decorator func AdapterType - AdapterType pyrefly ignore unknown-name global _adapters_map isinstance aten str adapters_map aten = func aten adapters_map = func func decorator register_adapter _slow_conv d_forward _slow_conv d_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any tmp = list shapes tmp append False tmp = list concrete len tmp raise ParseException slow conv d has less than concrete inputs tmp = tmp conv_adapter tuple tmp tuple tmp register_adapter convolution _convolution cudnn_convolution conv_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any tmp = list shapes len tmp == transposed = False len tmp transposed = bool tmp tmp = transposed raise ParseException f Convolution has wrong number inputs len tmp kwargs dict Any Any = transposed calculate output shape transposed conv_out_dims x int kernel int stride int - int x - kernel stride + stride = parse_list concrete inp = shapes w = shapes out_x_y = conv_out_dims args args zip inp w stride out = inp w + out_x_y we only need xy values kwargs out_val = out tuple tmp kwargs default_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any shapes register_adapter addmm addmm_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any tmp = list shapes tuple tmp register_adapter bmm bmm_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any tmp = list shapes tuple tmp register_adapter baddbmm baddbmm_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any tmp = list shapes tuple tmp register_adapter mm mm_adapter shapes tuple Any concrete tuple Any - tuple tuple Any dict Any Any shapes _parse_kernel_name name str - Optional str parse name kernel event name name startswith ATEN_PREFIX name len ATEN_PREFIX conv name convolution addmm name addmm bmm name bmm baddbmm name baddbmm _mm name mm None _calculate_flops event dict str Any - int This function has parse kernel name which error prone There doesn t seem another solution will support all different backends can generate kernels so make sure update function when new ops backends desired name = event name kernel_flop event args event args kernel_flop = event args kernel_flop op_name = _parse_kernel_name name op_name None op_obj = getattr torch ops aten op_name None op_obj None op_obj flop_registry flop_function = flop_registry op_obj Input Dims event args Concrete Inputs event args input_shapes = event args Input Dims concrete = event args Concrete Inputs op_name adapters_map try args kwargs = adapters_map op_name input_shapes concrete except ParseException e msg = f Failed parse op_name e log warning msg try args kwargs = default_adapter input_shapes concrete except ParseException e msg = f Failed parse op_name e log warning msg flop_function args kwargs _get_size_from_string type_string str - int hasattr torch type_string getattr torch type_string itemsize _default_estimate_gb event dict str Any - float sizes_and_types = zip event args Input Dims event args Input type bw = size typ sizes_and_types isize = _get_size_from_string typ bw += isize math prod pytree tree_flatten size bw e _estimate_gb event dict str Any - float Our best effort estimate gb should refactored soon MemoryCounter name = event name kernel_num_gb event args event args kernel_num_gb = event args kernel_num_gb Input type event args Input Dims event args op_name = _parse_kernel_name name op_name None _default_estimate_gb event op_obj = getattr torch ops aten op_name None op_obj None _default_estimate_gb event Input Dims event args Concrete Inputs event args _default_estimate_gb event input_shapes = event args Input Dims NOTE these will refactored into similar object FlopCounter soon mm_formula M int N int K int size int - int M K + N K + M N size op_name == addmm add_in_size = math prod pytree tree_flatten input_shapes add_type_size = _get_size_from_string event args Input type M = input_shapes N = input_shapes assert input_shapes == input_shapes K = input_shapes mul_type_size = _get_size_from_string event args Input type mm_formula M N K mul_type_size + add_in_size add_type_size e op_name == mm M = input_shapes N = input_shapes assert input_shapes == input_shapes K = input_shapes type_size = _get_size_from_string event args Input type mm_formula M N K type_size e op_name == baddbmm add_in_size = math prod pytree tree_flatten input_shapes add_type_size = _get_size_from_string event args Input type B = input_shapes M = input_shapes N = input_shapes K = input_shapes mul_type_size = _get_size_from_string event args Input type B mm_formula M N K mul_type_size + add_in_size add_type_size e op_name == bmm add_in_size = math prod pytree tree_flatten input_shapes add_type_size = _get_size_from_string event args Input type B = input_shapes M = input_shapes N = input_shapes K = input_shapes mul_type_size = _get_size_from_string event args Input type B mm_formula M N K mul_type_size + add_in_size add_type_size e op_name convolution _convolution cudnn_convolution _slow_conv d_forward concrete = event args Concrete Inputs conv_out_dim x int kernel int stride int - int x - kernel stride + stride = parse_list concrete op_name = _slow_conv d_forward concrete inp = input_shapes w = input_shapes out_x_y = conv_out_dim args args zip inp w stride out = inp w + out_x_y each output element reads w w chunk input_reads = out out out out inp w w Assume weights cache so only read once weight_reads = w w w w input_reads + weight_reads e _default_estimate_gb event _create_extern_mapping data dict str Any - defaultdict int list dict str Any compute mapping external ids non kernels which contain information we need estimate flops etc extern_mapping defaultdict int list dict str Any = defaultdict list event data traceEvents args event External id event args event cat = cpu_op continue len extern_mapping event args External id raise ParseException duplicate external id event extern_mapping event args External id append event extern_mapping _augment_trace_helper data dict str Any - dict str Any extern_mapping = _create_extern_mapping data event data traceEvents cat event event cat = kernel continue args event raise ParseException f kernel has no args event External id event args event_str = f kernel has no External id event log info event_str continue external_op = extern_mapping event args External id flops = _calculate_flops external_op flops == flops = _calculate_flops event external_op args kernel_flop = flops external_op args kernel_num_gb = _estimate_gb external_op event args kernel_flop = external_op args kernel_flop event args kernel_num_gb = external_op args kernel_num_gb data _dtype_map = float torch float float torch float int torch int int torch int int torch int int torch int long torch long long int torch long bfloat torch bfloat float torch float float torch double dataclass frozen=True KernelStats flops int bw float latency float us achieved_flops float achieved_bandwidth float KernelNameMap = defaultdict str OrderedSet KernelStats dataclass frozen=False Device name str index int info Optional DeviceInfo stats KernelNameMap __repr__ - str f Device name index info DeviceMap = dict int Device Table = tuple list str dict str list str JsonProfile _devices DeviceMap __init__ path str benchmark_name Optional str = None dtype Optional Union torch dtype str = None Convenience running common operations chrome perfetto json traces path = path open path f data = json load f events = data traceEvents benchmark_name = benchmark_name dtype None dtype = None isinstance dtype torch dtype pyrefly ignore bad-assignment dtype = dtype pyrefly ignore bad-assignment dtype = _dtype_map get dtype _create_devices convert_dtype event dict str Any - Optional torch dtype Each op has list dtypes each input arg We need convert these into single dtype flop estimation Issues - converting strings concrete torch dtypes - What we have float float float all inputs Our choice use largest buffer dtype Input Dims event args Input type event args Concrete Inputs event args bfloat event name torch bfloat float event name torch float None input_sizes = event args Input Dims input_types = event args Input type concrete_inputs = event args Concrete Inputs assert len input_sizes == len input_types assert len input_types == len concrete_inputs len input_sizes == raise RuntimeError Empty input_sizes input_types biggest_size = biggest_index = i range len input_sizes concrete_inputs i = concrete inputs usually small tensors so we can just skip continue my_size = input_sizes i total_size = sum parse_list my_size total_size biggest_size biggest_size = total_size biggest_index = i ret_type = input_types biggest_index ret_type _dtype_map _dtype_map ret_type raise RuntimeError f Unknown type ret_type Please add _dtype_map _create_devices - None _devices = dev data deviceProperties name = dev name device_info = lookup_device_info name device_info None log info Unsupported device profile s please consider contributing _device_mapping name _devices dev id = Device name dev id device_info defaultdict OrderedSet calculate_flops event dict str Any - int _calculate_flops event estimate_gb event dict str Any - float _estimate_gb event augment_trace - None data = _augment_trace_helper data _compute_stats - None populates name - stats map event events cat event args event event cat = kernel continue device event args continue dev_tmp = event args device dev_tmp _devices continue dev = _devices event args device dur = event dur us kernel_flop event args assert dur = us s flop us op_flops = event args kernel_flop dur e op_flops = kernel_num_gb event args assert dur = us s gb = gb s op_gbps = event args kernel_num_gb dur e op_gbps = dev info None dtype = convert_dtype event dtype dtype None raise RuntimeError dtype found tensor default dtype set achieved_flops = op_flops e dev info tops dtype achieved_bandwidth = op_gbps dev info dram_bw_gbs achieved_flops = achieved_bandwidth = name event args continue dev stats event name add KernelStats flops=op_flops bw=op_gbps latency=dur achieved_bandwidth=achieved_bandwidth achieved_flops=achieved_flops _create_single_table dev Device - Table Create table devices mapped indices headers = Kernel Name Kernel Count FLOPS Kernel Reads GB Dur us Achieved FLOPS Achieved Bandwidth rows dict str list str = safe_div_format x float y float - str y == f x y f kernel_name stats_set dev stats items ker_count = flops = flops_count = achieved_flops = bw = bw_count = achieved_bandwidth = latency = stats stats_set stats flops = flops += stats flops achieved_flops += stats achieved_flops flops_count += stats bw = bw += stats bw achieved_bandwidth += stats achieved_bandwidth bw_count += latency += stats latency ker_count += assert ker_count = rows kernel_name = str ker_count safe_div_format flops flops_count safe_div_format bw bw_count safe_div_format latency ker_count safe_div_format achieved_flops flops_count safe_div_format achieved_bandwidth bw_count headers rows _create_tables devs DeviceMap - dict int Table idx _create_single_table dev idx dev devs items _combine_tables table Table table _name str table Table table _name str - Table new_headers = Kernel Name + f table _name head head table + f table _name head head table t _length = len table t _length = len table new_rows = key row row zip_dicts table table d _default= Empty t _length d _default= Empty t _length assert row None assert row None new_rows key = row + row new_headers new_rows report other Optional JsonProfile = None name_limit int = - str create_ret table_headers list str table_rows dict str list str - str table_flattened = kernel_name name_limit kernel_vals kernel_name kernel_vals table_rows items tabulate_ d table_flattened headers=table_headers other None _compute_stats other _compute_stats self_tables = _create_tables _devices other_tables = _create_tables other _devices self_name = benchmark_name benchmark_name None Table other_name = other benchmark_name other benchmark_name None Table ret = assert _devices keys == other _devices keys device_idx t t zip_dicts self_tables other_tables d _default=None d _default=None assert t None assert t None table_headers table_rows = _combine_tables t self_name t other_name tab_string = create_ret table_headers table_rows pyrefly ignore bad-argument-type ret append f _devices device_idx \n tab_string \n join ret _compute_stats self_tables = _create_tables _devices ret = idx table self_tables items table_headers table_rows = table tab_string = create_ret table_headers table_rows pyrefly ignore bad-argument-type ret append f _devices idx \n tab_string \n join ret dump out str - None open out w f json dump data f combine_with other JsonProfile - JsonProfile Combine profile another profile merging their trace events Returns new JsonProfile object combined data Create new combined data structure combined_data = traceEvents data traceEvents + other data traceEvents deviceProperties data get deviceProperties Merge device properties avoiding duplicates other_device_props = other data get deviceProperties existing_device_ids = OrderedSet dev id dev combined_data deviceProperties device_prop other_device_props device_prop id existing_device_ids combined_data deviceProperties append device_prop Copy any other top-level properties first profile key value data items key combined_data combined_data key = value os Create temporary file write combined data tempfile tempfile NamedTemporaryFile mode= w suffix= json delete=False tmp_file json dump combined_data tmp_file tmp_path = tmp_file name try Create new JsonProfile combined data combined_profile = JsonProfile tmp_path benchmark_name=f benchmark_name Profile _+_ other benchmark_name Profile dtype=self dtype other dtype combined_profile finally Clean up temporary file os unlink tmp_path ParseException RuntimeError pass main - None Main function profile analysis script argparse parser = argparse ArgumentParser parser add_argument -- diff nargs= metavar= input_file name input_file name dtype help= Two json traces compare specified file name file name dtype parser add_argument -- name_limit type=int help= maximum name size final report parser add_argument -- augment_trace -a nargs= metavar= input_file output_file dtype help= Augment trace inductor meta information Provide input output file paths parser add_argument -- analysis nargs= metavar= input_file dtype help= Run analysis single trace specified file dtype parser add_argument -- combine nargs= + metavar= input_files output_file help= Combine multiple profiles into single profile merging trace events Specify input_file \ input_file input_file output_file The last argument output file all preceding arguments \ input files combine args = parser parse_args args diff p = JsonProfile args diff args diff dtype=args diff p augment_trace p = JsonProfile args diff args diff dtype=args diff p augment_trace args name_limit print p report p name_limit=args name_limit print p report p args analysis p = JsonProfile args analysis dtype=args analysis p augment_trace args name_limit print p report name_limit=args name_limit print p report args augment_trace p = JsonProfile args augment_trace dtype=args augment_trace p augment_trace p dump args augment_trace args combine input_files = args combine - All arguments except last one output_file = args combine - Last argument output file len input_files print Error At least input files required combining Load first profile combined = JsonProfile input_files dtype=None Iteratively combine all other profiles input_file input_files profile = JsonProfile input_file dtype=None combined = combined combine_with profile combined dump output_file print f Successfully combined join input_files into output_file __name__ == __main__ main