functools typing Any Callable torch Feedback = float Choice = str Value = Any CHOICE_COL = choice FEEDBACK_COL = feedback AHFeature The context AutoHeuristic stores list features AutoHeuristic needs know whether feature categorical i e continuous variable learn machine learning model __init__ name str value Value is_categorical bool = False - None name = name value = value is_categorical = is_categorical AHOperation AHOperation can used augment data collected AutoHeuristic One might example store features like m k n also want use features like m n k n learn heuristic Instead storing features can created collected data one can use AHOperation create new features collected data __init__ name str func Callable Any Value is_categorical bool = False - None name = name func = func is_categorical = is_categorical apply_operation data Any - None data name = func data AHContext This used specify which information AutoHeuristic should store For each choice AutoHeursitic will store context collected feedback The context could something like shape tensor i e information will help learn heuristic features list AHFeature context_dict dict str Value __init__ - None features = context_dict = add_feature name str value Value is_categorical bool = False - None features append AHFeature name value is_categorical=is_categorical context_dict name = value get_numerical_and_categorical_features - tuple list str list str numerical_features = categorical_features = feature features feature is_categorical categorical_features append feature name numerical_features append feature name numerical_features categorical_features get_feature_names_csv - str join feature name feature features get_feature_values_csv - str join str feature value feature features get_value name str - Value context_dict name apply_operations operations list AHOperation - None op operations op apply_operation context_dict AHMetadata __init__ shared_memory Any device_capa tuple int int choices list Choice name str - None use amount shared_memory device_capability identify GPU TODO AlnisM there might better way do shared_memory = shared_memory device_capa = device_capa choices = choices name = name to_dict - dict str Value shared_memory shared_memory device_capa device_capa name name get_metadata_str_from_log log_path str - str open log_path newline= file json_string = file readline strip json_string check_minsize context AHContext minsize int - bool context get_value m = minsize context get_value k = minsize context get_value n = minsize pad_mm_precondition metadata AHMetadata context AHContext - bool metadata shared_memory == metadata device_capa == A precondition check_minsize context metadata shared_memory == metadata device_capa == H precondition check_minsize context True get_mixedmm_precondition metadata AHMetadata context AHContext - bool m = context get_value m k = context get_value k n = context get_value n m k n False mat _iscontig = context get_value mat _iscontig mat _iscontig = context get_value mat _iscontig mat _iscontig mat _iscontig get_mult_dims_ops - list AHOperation m_times_k_op = AHOperation m k lambda data data m data k m_times_n_op = AHOperation m n lambda data data m data n k_times_n_op = AHOperation k n lambda data data k data n m_times_k_op m_times_n_op k_times_n_op get_arith_intensity data Any - float m = data m k = data k n = data n m == k == n == m k n m k + k n + m n pad_mm_operations - list AHOperation mult_dims_ops = get_mult_dims_ops k_div_m_times_n_op = AHOperation k m n lambda data data k data m data n bfloat_perf_hit data Any - bool m = data m k = data k n = data n is_bfloat = str data mat _dtype == torch bfloat k m k n is_bfloat bfloat_perf_hit_op = AHOperation bfloat_perf_hit bfloat_perf_hit is_categorical=True arith_intensity_op = AHOperation arith_intensity get_arith_intensity dims_need_padding_ops = get_dims_need_padding_ops dims_multiple_ops = get_dims_multiple_ops is_contig_ops = get_is_contig_ops ah_operations = mult_dims_ops + k_div_m_times_n_op bfloat_perf_hit_op arith_intensity_op ah_operations extend dims_need_padding_ops ah_operations extend dims_multiple_ops ah_operations extend is_contig_ops ah_operations between_op data Any dim str lower int upper int - bool data dim = lower data dim = upper between_ops - list AHOperation dims = m k n limits = ah_operations = dim dims lower upper limits between_op_fn = functools partial between_op dim=dim lower=lower upper=upper using LEQ instead = because = cannot exported dot between_op_name = f lower LEQ dim LEQ upper ah_operations append AHOperation between_op_name between_op_fn is_categorical=True ah_operations pow _op data Any dim str exponent int - bool data dim == exponent mm_operations - list AHOperation mult_dims_ops = get_mult_dims_ops arith_intensity_op = AHOperation arith_intensity get_arith_intensity mult_dims_ops + arith_intensity_op mixed_mm_operations - list AHOperation mm_operations + between_ops is_multiple data Any dim str mult int - bool data dim mult == get_dims_multiple_ops - list AHOperation multiples = dims = m k n dims_multiple_ops = dim dims mult multiples is_multiple_fn = functools partial is_multiple dim=dim mult=mult dims_multiple_op = AHOperation f dim _multiple_ mult is_multiple_fn is_categorical=True dims_multiple_ops append dims_multiple_op dims_multiple_ops get_dims_need_padding_ops - list AHOperation mat _innermost_needs_padding_fn data Any - bool mat _stride_ = data mat _stride_ mat _stride_ = data mat _stride_ m_padded_length = data m_padded_length k_padded_length = data k_padded_length mat _innermost_needs_padding = False mat _stride_ == m_padded_length = mat _innermost_needs_padding = True mat _stride_ == k_padded_length = mat _innermost_needs_padding = True mat _innermost_needs_padding mat _innermost_op = AHOperation mat _innermost_needs_padding mat _innermost_needs_padding_fn is_categorical=True mat _innermost_needs_padding_fn data Any - bool mat _stride_ = data mat _stride_ mat _stride_ = data mat _stride_ k_padded_length = data k_padded_length n_padded_length = data n_padded_length mat _innermost_needs_padding = False mat _stride_ == k_padded_length = mat _innermost_needs_padding = True mat _stride_ == n_padded_length = mat _innermost_needs_padding = True mat _innermost_needs_padding mat _innermost_op = AHOperation mat _innermost_needs_padding mat _innermost_needs_padding_fn is_categorical=True num_dims_needs_padding_fn data Any - int m_padded_length = data m_padded_length k_padded_length = data k_padded_length n_padded_length = data n_padded_length num_dims_needs_padding = m_padded_length = num_dims_needs_padding += k_padded_length = num_dims_needs_padding += n_padded_length = num_dims_needs_padding += num_dims_needs_padding num_dims_op = AHOperation num_dims_needs_padding num_dims_needs_padding_fn mat _innermost_op mat _innermost_op num_dims_op get_is_contig_ops - list AHOperation mat _is_contig_fn data Any - bool stride_ = data mat _stride_ stride_ = data mat _stride_ k = data k stride_ == k stride_ == mat _is_contig_op = AHOperation mat _iscontig mat _is_contig_fn is_categorical=True mat _is_contig_fn data Any - bool stride_ = data mat _stride_ stride_ = data mat _stride_ n = data n stride_ == n stride_ == mat _is_contig_op = AHOperation mat _iscontig mat _is_contig_fn is_categorical=True mat _is_contig_op mat _is_contig_op context_add_strides context AHContext name str stride tuple int - None i s enumerate stride context add_feature f name _stride_ i s context_add_using_tf context AHContext dtype torch dtype - None using_tf = not_float_ dtype == torch float using_tf = torch backends cuda matmul allow_tf context add_feature using_tf using_tf is_categorical=True