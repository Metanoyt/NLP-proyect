Owner s module inductor os unittest torch torch _inductor config inductor_config torch _dynamo device_interface get_interface_for_device torch _inductor autoheuristic autoheuristic AutoHeuristic LocalFeedback torch _inductor autoheuristic autoheuristic_utils AHContext torch _inductor runtime runtime_utils cache_dir torch _inductor test_case run_tests TestCase torch _inductor utils get_gpu_shared_memory torch testing _internal common_utils skipIfXpu torch testing _internal inductor_utils GPU_TYPE HAS_GPU IS_A IS_H skipIfXpu msg= AutoHeuristic doesn t currently work XPU stack AutoHeuristicTest TestCase count_lines_in_file file_path open file_path file line_count = sum line file line_count run_mm f b torch mm b cf = torch compile f = torch randn device=GPU_TYPE dtype=torch float b = torch randn device=GPU_TYPE dtype=torch float cf b get_path_to_autoheuristic_log name device_name = AutoHeuristic get_device_identifier path = cache_dir + autoheuristic + device_name + + name + txt path test_autoheuristic_pad_mm_default test ensures data collected pad_mm when autoheuristic config set its default value run_mm assertFalse os path exists get_path_to_autoheuristic_log pad_mm inductor_config patch autoheuristic_collect= foo test_autoheuristic_pad_mm_off test ensures data collected pad_mm when autoheuristic_collect does contain pad_mm run_mm assertFalse os path exists get_path_to_autoheuristic_log pad_mm assert_autoheuristic_collected_data run_mm AutoHeuristic get_device_identifier path = get_path_to_autoheuristic_log pad_mm assertTrue os path exists path num_lines = count_lines_in_file path line metadata line header line per choice orig padded assertEqual num_lines inductor_config patch autoheuristic_collect= pad_mm test_autoheuristic_pad_mm_collect_data test ensures data collected pad_mm when autoheuristic_collect= pad_mm assert_autoheuristic_collected_data inductor_config patch autoheuristic_collect= foo pad_mm test_autoheuristic_pad_mm_collect_data test ensures data collected pad_mm when autoheuristic_collect contains pad_mm assert_autoheuristic_collected_data inductor_config patch autoheuristic_collect= test test_autoheuristic test basic functionality autoheuristic fallback fallback choices = b c feedback_fn choice choice == choice == b choice == c raise RuntimeError unexpected choice feedback = LocalFeedback feedback_fn context = AHContext context add_feature fa name = test autoheuristic = AutoHeuristic fallback choices feedback context name when autoheuristic configured only collect data we always fallback assertEqual autoheuristic get_choice fallback assertEqual autoheuristic get_collected_feedback assertEqual autoheuristic get_collected_feedback b assertEqual autoheuristic get_collected_feedback c path = get_path_to_autoheuristic_log name assertTrue os path exists path num_lines = count_lines_in_file path assertEqual num_lines shared_memory = get_gpu_shared_memory fst snd = get_interface_for_device GPU_TYPE get_device_capability open path file lines = file readlines assertTrue numerical_features fa lines assertTrue categorical_features lines assertTrue f shared_memory shared_memory lines assertTrue f device_capa fst snd lines assertTrue name test lines assertEqual fa choice feedback lines rstrip assertEqual lines rstrip assertEqual b lines rstrip assertEqual c lines rstrip unittest skipIf IS_A heuristic only run A inductor_config patch autoheuristic_use= pad_mm test_autoheuristic_a Make sure heuristic does break anything TODO AlnisM Find way check whether heuristic used run_mm unittest skipIf IS_H heuristic only run H inductor_config patch autoheuristic_use= pad_mm test_autoheuristic_h Make sure heuristic does break anything TODO AlnisM Find way check whether heuristic used run_mm run_mixed_mm fn b torch mm b dtype = torch randn device=GPU_TYPE dtype=torch float b = torch randint - dtype=torch int device=GPU_TYPE t torch compile fn mode= max-autotune-no-cudagraphs b have set autoheuristic_use= because autoheuristic_use= mixed_mm autoheuristic creates precompile key puts into registry then choice made heuristic might added list choices select_algorithm now creates new precompile key will different precompile key created autoheuristic inductor_config patch autoheuristic_collect= mixed_mm autoheuristic_use= fx_graph_cache=False fx_graph_remote_cache=False test_global_feedback run_mixed_mm path = get_path_to_autoheuristic_log mixed_mm assertTrue os path exists path num_lines = count_lines_in_file path line metadata line header line fallback + least config assertTrue num_lines inductor_config patch autoheuristic_use= mixed_mm unittest skipIf IS_A heuristic only run A test_mixed_mm_a run_mixed_mm TODO AlnisM Find way check whether heuristic used __name__ == __main__ HAS_GPU run_tests