mypy allow-untyped-defs collections enum typing cast torch torch distributed dist api constants rpc_constants _utils _group_membership_management _update_group_membership __all__ = backend_registered register_backend construct_rpc_backend_options init_backend BackendValue BackendType BackendValue = collections namedtuple BackendValue construct_rpc_backend_options_handler init_backend_handler _backend_type_repr BackendType + name _backend_type_doc = An enum available backends PyTorch ships builtin ` ` BackendType TENSORPIPE ` ` backend Additional ones can registered using func ` ~torch distributed rpc backend_registry register_backend ` function Create enum type ` BackendType ` empty members Can t handle Function Enum API mypy bug BackendType = enum Enum value= BackendType names= type ignore misc Unable assign function method mypy bug BackendType __repr__ = _backend_type_repr type ignore assignment BackendType __doc__ BackendType __doc__ = _backend_type_doc backend_registered backend_name Checks backend_name registered RPC backend Args backend_name str string identify RPC backend Returns True backend has been registered ` ` register_backend ` ` False backend_name BackendType __members__ keys register_backend backend_name construct_rpc_backend_options_handler init_backend_handler Registers new RPC backend Args backend_name str backend string identify handler construct_rpc_backend_options_handler function Handler invoked when rpc_backend construct_rpc_backend_options dict called init_backend_handler function Handler invoked when ` _init_rpc_backend ` function called backend This returns agent global BackendType backend_registered backend_name raise RuntimeError f RPC backend backend_name already registered Create new enum type ` BackendType ` extended members existing_enum_dict = member name member value member BackendType extended_enum_dict = dict backend_name BackendValue construct_rpc_backend_options_handler=construct_rpc_backend_options_handler init_backend_handler=init_backend_handler existing_enum_dict Can t handle Function Enum API mypy bug BackendType = enum Enum value= BackendType names=extended_enum_dict type ignore misc Unable assign function method mypy bug BackendType __repr__ = _backend_type_repr type ignore assignment BackendType __doc__ BackendType __doc__ = _backend_type_doc pyrefly ignore unsupported-operation BackendType backend_name construct_rpc_backend_options backend rpc_timeout=rpc_constants DEFAULT_RPC_TIMEOUT_SEC init_method=rpc_constants DEFAULT_INIT_METHOD kwargs backend value construct_rpc_backend_options_handler rpc_timeout init_method kwargs init_backend backend args kwargs backend value init_backend_handler args kwargs _init_process_group store rank world_size Initialize ProcessGroup process_group_timeout = rpc_constants DEFAULT_PROCESS_GROUP_TIMEOUT We re using bunch private APIs here since ` new_group ` requires default group initialized group = dist ProcessGroupGloo store rank world_size process_group_timeout assert group None Failed initialize default ProcessGroup rank = - rank = group rank raise RuntimeError f rank argument rank doesn t match pg rank group rank world_size = - world_size = group size raise RuntimeError f world_size argument world_size doesn t match pg size group size group _tensorpipe_construct_rpc_backend_options_handler rpc_timeout init_method num_worker_threads=rpc_constants DEFAULT_NUM_WORKER_THREADS _transports=None _channels=None kwargs TensorPipeRpcBackendOptions TensorPipeRpcBackendOptions rpc_timeout=rpc_timeout init_method=init_method num_worker_threads=num_worker_threads _transports=_transports _channels=_channels _tensorpipe_validate_devices devices device_count all d type == cpu d type == cuda = d index device_count d devices detect any worker has invalid device_map configurations reverse device maps _tensorpipe_exchange_and_check_all_device_maps my_name my_device_count my_device_maps my_devices group gathered list tuple str int dict str dict torch device torch device list torch device = _ range group size dist all_gather_object gathered my_name my_device_count my_device_maps my_devices group all_names = name name _ _ _ gathered all_device_counts = name count name count _ _ gathered all_device_maps = name map_ name _ map_ _ gathered all_devices = name devices name _ _ devices gathered _validate_device_maps all_names all_device_counts all_device_maps all_devices passed all checked construct reverse mapping get list devices handled agent reverse_device_maps = _create_reverse_mapping my_name all_names all_device_maps my_devices = _create_device_list my_devices my_device_maps reverse_device_maps reverse_device_maps my_devices _validate_device_maps all_names all_device_counts all_device_maps all_devices is_static_group=True node all_names devices = all_devices node len set devices = len devices raise ValueError f Node node has duplicated devices\ndevices = devices _tensorpipe_validate_devices devices all_device_counts node raise ValueError f Node node has devices invalid indices\n f devices = devices \n f device count = all_device_counts node source_node all_names For dynamic group non-static do check target node name since may have joined yet is_static_group set all_device_maps source_node keys issubset all_names raise ValueError f Node source_node has invalid target node names its device maps\n f device maps = all_device_maps source_node keys \n f node names = all_names target_node map_ all_device_maps source_node items len set map_ values = len map_ raise ValueError f Node source_node has duplicated target devices f its device map target_node \n f device map = map_ all_devices source_node set map_ keys issubset all_devices source_node raise ValueError f Node source_node has unexpected source devices f its device map target_node \n f device map = map_ \n f devices = all_devices source_node _tensorpipe_validate_devices map_ keys all_device_counts source_node raise ValueError f Node source_node has source devices invalid indices f its device map target_node \n f device map = map_ \n f device count = all_device_counts source_node all_devices get target_node set map_ values issubset all_devices target_node raise ValueError f Node source_node has unexpected target devices f its device map target_node \n f device map = map_ \n f devices = all_devices target_node target_node all_device_counts _tensorpipe_validate_devices map_ values all_device_counts target_node raise ValueError f Node source_node has target devices invalid indices f its device map target_node \n f device map = map_ \n f device count = all_device_counts target_node _create_device_list my_devices my_device_maps reverse_device_maps my_devices devices_set set torch device = set map_ my_device_maps values devices_set update map_ keys map_ reverse_device_maps values devices_set update map_ keys devices_set discard torch device cpu my_devices = list devices_set my_devices = sorted my_devices key=lambda d d index my_devices _create_reverse_mapping my_name all_names all_device_maps reverse_device_maps dict str dict torch device torch device = node all_names my_name all_device_maps node reverse_device_maps node = v k k v all_device_maps node my_name items reverse_device_maps _get_device_infos TensorPipeAgent agent = cast TensorPipeAgent api _get_current_rpc_agent opts = agent _get_backend_options device_count = torch cuda device_count torch cuda is_available opts devices torch cuda init device_count opts device_maps opts devices _set_devices_and_reverse_device_map agent TensorPipeAgent agent = cast TensorPipeAgent agent Group state retrieved local agent On initialization tensorpipe agent retrieves information all existing workers so group state valid my_worker_info = agent get_worker_info my_name = my_worker_info name all_worker_infos = agent get_worker_infos One round get device_maps all workers construct reverse device maps all_device_counts all_device_maps all_devices all_names = worker_info all_worker_infos worker_name = worker_info name worker_name = my_name TODO make async device_count device_map devices = api rpc_sync worker_name _get_device_infos opts = agent _get_backend_options device_count device_map devices = torch cuda device_count opts device_maps opts devices all_device_counts worker_name = device_count all_device_maps worker_name = device_map all_devices worker_name = devices all_names append worker_name _validate_device_maps all_names all_device_counts all_device_maps all_devices is_static_group=False reverse_device_maps = _create_reverse_mapping my_name all_names all_device_maps Perform RPC call all workers including itself include newly joined worker information device maps worker_name all_names Set device list each worker all_devices worker_name = _create_device_list all_devices worker_name all_device_maps worker_name reverse_device_maps api rpc_sync worker_name _update_group_membership args= my_worker_info all_devices worker_name reverse_device_maps True _tensorpipe_init_backend_handler store name rank world_size rpc_backend_options TensorPipeAgent TensorPipeRpcBackendOptions isinstance store dist Store raise TypeError f ` store ` must c d Store store isinstance rpc_backend_options TensorPipeRpcBackendOptions raise TypeError f ` rpc_backend_options ` must ` TensorPipeRpcBackendOptions ` rpc_backend_options device_count = torch cuda device_count is_static_group = bool world_size world_size specified so static group ranks cannot join leave is_static_group The agent s join method required behave like barrier perform collective operations which relies process group instead re-implementing top RPCs group = _init_process_group store rank world_size reverse_device_maps devices = _tensorpipe_exchange_and_check_all_device_maps name device_count rpc_backend_options device_maps rpc_backend_options devices group torch cuda is_available devices It s necessary initialize PyTorch CUDA states here e g CUDACachingAllocator If missing we could hit errors like allocator initialized because other processes might send CUDA-related RPC request process before user code process initializes its PyTorch CUDA states torch cuda init TODO add try-except destroy _agent all processes any fails agent = TensorPipeAgent store name rank world_size rpc_backend_options reverse_device_maps devices api _init_rpc_states agent Run one dummy round RPC initialize channels transports Without s easy hit timeout rpc shutdown there no other RPC process before rpc shutdown agent initialization can take longer than s api _all_gather None timeout=rpc_backend_options rpc_timeout Need barrier here make sure no peers leave before rank finishes _all_gather group barrier wait agent initialization dynamic rpc ranks can join leave _group_membership_management store name True Construct TPAgent empty reverse_device_map devices these properties will updated after initialization agent = TensorPipeAgent store name rank world_size rpc_backend_options api _init_rpc_states agent try Notify all workers group rank has joined set devices reverse_device_map This synchronous operation completes once all existing ranks updated _set_devices_and_reverse_device_map agent except Exception api shutdown raise agent register_backend TENSORPIPE _tensorpipe_construct_rpc_backend_options_handler _tensorpipe_init_backend_handler