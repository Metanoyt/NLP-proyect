Owner s module onnx flake noqa B Test op correctness comparing PyTorch results ## Usage Set env var CATCH_ORT_SEGFAULT catch segfaults ONNX Runtime ## How add new operator test This test use PyTorch s OpInfo mechanism generate test cases each operator You may find all OpInfos https github com pytorch pytorch blob ec d f fdd c b dc aa f torch testing _internal common_methods_invocations py#L To enable test cases operator Add ` TorchLibOpInfo ` entry ` TORCH_LIB_OPINFO ` ` ops_test_data py ` Specify ` complex ` function designed complex inputs The ` op_info_name ` ` TorchLibOpInfo ` needs unique TORCH_LIB_OPINFO list complex=True ops can share same name non-complex ops because they tested separately Add ` skip ` ` xfail ` skip xfail tests Prefer xfail over skip when possible because allows us monitor behavior update test will passes If test now failing because xpass because some previous errors now fixed removed corresponding xfail If sample inputs OpInfo needs adjusted fit aten signature create input wrangler function See ` _mean_input_wrangler ` example To test different ONNX functions registered overloads same op use ` ops_test_common duplicate_opinfo ` create new OpInfo new names map each one overload __future__ annotations copy dataclasses functools typing Any Optional TYPE_CHECKING typing_extensions Self numpy np ops_test_common torch torch onnx _internal exporter _torchlib ops core core_ops nn nn_ops torch testing _internal common_methods_invocations torch testing _internal opinfo definitions opinfo_definitions TYPE_CHECKING collections abc Callable Collection Create copy op_db modify OPS_DB = copy deepcopy common_methods_invocations op_db Append extra op_db into op database testing OPS_DB extend opinfo_definitions signal op_db dataclasses dataclass TorchLibOpInfo A dataclass store information test torchlib op The name op_info e g add op_info_name str The torchlib ONNX Function test op Callable Any The input wrangler function adjust input fit aten signature input_wrangler Optional Callable list Any dict str Any tuple list Any dict str Any = None Whether op non-deterministic nondeterministic bool = False Whether compare shape only output index For example means compare value output shape output We may able combine nondeterministic option compare_shape_only_for_output tuple int = Whether function designed complex inputs complex bool = False The ONNX opset version which function introduced Its specifies minimum ONNX opset version required use function It ensures function only used when target ONNX opset version compatible For example ` opset_introduced= ` function will only used when exporting ONNX models targeting opset version higher opset_introduced int = The acceptable tolerance inference result difference between PyTorch ORT Format dtype rtol atol For example torch float e- e- tolerance dict torch dtype tuple float float = dataclasses field default_factory=dict Expected skips fails test subtests skips_or_fails list ops_test_common DecorateMeta = dataclasses field default_factory=list get_tolerance dtype torch dtype - tuple float &#124; None float &#124; None Returns rtol atol tolerance given dtype tolerance = tolerance get dtype None tolerance Use PyTorch default specified https pytorch org docs stable testing html None None skip variant_name str = reason str dtypes Optional Collection torch dtype = None device_type Optional str = None matcher Optional Callable Any Any = None enabled_if bool = True test_class_name Optional str = None - Self Skips OpInfo test Args variant_name Optional OpInfo variant_test_name reason The reason skipping dtypes The dtypes skip device_type Device type E g cpu cuda matcher A function matches test sample input It used only when skip SKIP_XFAIL_SUBTESTS list enabled_if Whether skip enabled test_class_name The test name apply skip If None skip applied all test classes skips_or_fails append ops_test_common skip op_info_name variant_name reason=reason dtypes=dtypes device_type=device_type matcher=matcher enabled_if=enabled_if test_class_name=test_class_name xfail variant_name str = reason str dtypes Optional Collection torch dtype = None device_type Optional str = None matcher Optional Callable Any Any = None enabled_if bool = True test_class_name Optional str = None - Self Expects OpInfo test fail Args variant_name Optional OpInfo variant_test_name reason The reason failure dtypes The dtypes expect failure device_type Device type E g cpu cuda matcher A function matches test sample input It used only when xfail SKIP_XFAIL_SUBTESTS list enabled_if Whether xfail enabled test_class_name The test name apply xfail If None xfail applied all test classes skips_or_fails append ops_test_common xfail op_info_name variant_name reason=reason dtypes=dtypes device_type=device_type matcher=matcher enabled_if=enabled_if test_class_name=test_class_name Modify section ########################################################## _amin_amax_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any dim kwargs Supply empty dim match aten signature kwargs dim = np array dtype=np int Convert dim numpy array kwargs dim = np array kwargs dim dtype=np int reshape - args kwargs _avg_pool_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any dim kwargs len args kwargs divisor_override = args pop len args kwargs count_include_pad = args pop len args kwargs ceil_mode = args pop len args padding = args pop isinstance padding np ndarray Cannot using list padding here because element will numpy int instead int padding = padding tolist kwargs padding = padding len args stride = args pop isinstance stride np ndarray stride = stride tolist kwargs stride = stride kernel_size = args pop isinstance kernel_size np ndarray kernel_size = kernel_size tolist kwargs kernel_size = kernel_size args kwargs _cross_entropy_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any reduction kwargs reduction_vals = none mean sum value = kwargs reduction idx = reduction_vals index value kwargs reduction = idx args kwargs _dropout_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any training kwargs kwargs train = kwargs training kwargs pop training args kwargs _einsum_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Swap equation tensors revert special handling OpInfo args args kwargs _embedding_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Remove arguments present aten op signature kwargs pop max_norm None kwargs pop norm_type None args kwargs _empty_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Remove arguments present aten op signature kwargs pop requires_grad None args kwargs _grid_sample_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Convert string attribute int input inter_mode_options = bilinear nearest bicubic padding_mode_options = zeros border reflection args append inter_mode_options kwargs mode args append padding_mode_options kwargs padding_mode args append kwargs align_corners kwargs clear args kwargs _im col_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Move kernel_size dilation padding stride args kwargs len args == Handle stride stride = args pop isinstance stride np ndarray convert stride list int stride = stride tolist kwargs stride = stride Handle padding padding = args pop isinstance padding np ndarray convert padding list int padding = padding tolist kwargs padding = padding Handle dilation dilation = args pop isinstance dilation np ndarray convert dilation list int dilation = dilation tolist kwargs dilation = dilation Handle kernel_size kernel_size = args pop isinstance kernel_size np ndarray convert kernel_size list int kernel_size = kernel_size tolist kwargs kernel_size = kernel_size args kwargs _index_put_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any args = np array elem elem args args kwargs _max_pool_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Remove return_indices argument because op doesn t accept kwargs pop return_indices None args kwargs _mean_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Make dims tensor dim kwargs kwargs dim = np array kwargs dim dtype=np int args kwargs _mse_loss_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any reduction kwargs reduction_vals = none mean sum default= value = kwargs reduction idx = reduction_vals index value kwargs reduction = idx args kwargs _nll_loss_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any reduction kwargs aten_nll_loss can only accept integer argument instead string reduction_vals = none mean sum value = kwargs reduction kwargs reduction = reduction_vals index value args kwargs _nonzero_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any kwargs pop as_tuple None args kwargs _reflection_pad d_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any args pop remove reflect arg args kwargs _replication_pad d_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any args pop remove replicate arg args kwargs _replication_pad d_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any args pop remove replicate arg args kwargs _roll_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any len args = isinstance args np ndarray convert dims list int Change dims args kwargs keep tuple list type dims = args pop kwargs dims = dims tolist isinstance args int convert dims list int dims = args pop kwargs dims = kwargs dims append dims len args = isinstance args np ndarray convert shift list int shifts = args pop kwargs shifts = shifts tolist isinstance args int shifts = args pop kwargs shifts = kwargs shifts append shifts args kwargs _scalar_tensor_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any kwargs pop requires_grad None args kwargs _scatter_reduce_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any Put string into kwargs otherwise FullGraph mode could find get reduce argument kwargs reduce = args pop args kwargs _sum_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any kwargs get dim None kwargs dim = np array kwargs dim dtype=np int args kwargs _unflatten_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any args = np array args dtype=np int args kwargs _where_input_wrangler args list Any kwargs dict str Any - tuple list Any dict str Any The aten where op takes condition x y inputs Swap first two inputs args args = args args args kwargs Ops tested numerical consistency between onnx pytorch Find names OpInfos torch testing _internal common_methods_invocations py TESTED_TORCHLIB_OPS tuple TorchLibOpInfo = TorchLibOpInfo abs core_ops aten_abs TorchLibOpInfo abs core_ops aten_abs_complex complex=True TorchLibOpInfo add core_ops aten_add tolerance= torch float e- e- TorchLibOpInfo add core_ops aten_add_complex complex=True TorchLibOpInfo gelu_op nn_ops aten_gelu_opset opset_introduced= TorchLibOpInfo nn functional group_norm nn_ops aten_group_norm opset_introduced= skip reason= ONNX Runtime does support zero sized inputs GroupNorm matcher=lambda sample sample input numel == TorchLibOpInfo nn functional rms_norm nn_ops aten_rms_norm opset_introduced= skip reason= ONNX Runtime does support d inputs zero sized inputs RMSNorm matcher=lambda sample len sample input shape sample input numel == ops_test_common duplicate_opinfo OPS_DB all all_dim all_dims ops_test_common duplicate_opinfo OPS_DB any any_dim any_dims ops_test_common duplicate_opinfo OPS_DB arange arange_start arange_start_step ops_test_common duplicate_opinfo OPS_DB atleast_ d atleast_ d_Sequence ops_test_common duplicate_opinfo OPS_DB atleast_ d atleast_ d_Sequence ops_test_common duplicate_opinfo OPS_DB atleast_ d atleast_ d_Sequence ops_test_common duplicate_opinfo OPS_DB bitwise_left_shift bitwise_left_shift_int bitwise_left_shift_int bitwise_left_shift_int bitwise_left_shift_int ops_test_common duplicate_opinfo OPS_DB bitwise_right_shift bitwise_right_shift_int bitwise_right_shift_int bitwise_right_shift_int bitwise_right_shift_int ops_test_common duplicate_opinfo OPS_DB cat concat concatenate ops_test_common duplicate_opinfo OPS_DB clone lift_fresh_copy ops_test_common duplicate_opinfo OPS_DB diagonal diagonal_bool ops_test_common duplicate_opinfo OPS_DB div div_mode div_mode_int ops_test_common duplicate_opinfo OPS_DB ge ge_bool ops_test_common duplicate_opinfo OPS_DB gt gt_bool ops_test_common duplicate_opinfo OPS_DB index_put index_put_bool ops_test_common duplicate_opinfo OPS_DB le le_bool ops_test_common duplicate_opinfo OPS_DB lt lt_bool ops_test_common duplicate_opinfo OPS_DB max max_dim ops_test_common duplicate_opinfo OPS_DB maximum maximum_bool ops_test_common duplicate_opinfo OPS_DB mean mean_dim ops_test_common duplicate_opinfo OPS_DB min min_dim ops_test_common duplicate_opinfo OPS_DB minimum minimum_bool ops_test_common duplicate_opinfo OPS_DB nn functional pad nn functional reflection_pad d nn functional replication_pad d nn functional replication_pad d ops_test_common duplicate_opinfo OPS_DB nn functional gelu gelu_op ops_test_common duplicate_opinfo OPS_DB nn functional scaled_dot_product_attention nn functional scaled_dot_product_attention_bool_mask ops_test_common duplicate_opinfo OPS_DB nn functional celu nn functional celu_type_promoted ops_test_common duplicate_opinfo OPS_DB ops aten _log_softmax ops aten _log_softmax_half ops_test_common duplicate_opinfo OPS_DB ops aten _softmax ops aten _softmax_half ops_test_common duplicate_opinfo OPS_DB prod prod_dim_int ops_test_common duplicate_opinfo OPS_DB round round_decimals ops_test_common duplicate_opinfo OPS_DB squeeze squeeze_dim ops_test_common duplicate_opinfo OPS_DB view_as_complex view_as_complex_copy ops_test_common duplicate_opinfo OPS_DB view_as_real view_as_real_copy MARK End edits here These ops deterministic so we check shape dtype only NONDETERMINISTIC_OPS frozenset str = frozenset info op_info_name info TESTED_TORCHLIB_OPS info nondeterministic COMPARE_SHAPE_ONLY_OPS dict str set = info op_info_name set info compare_shape_only_for_output info TESTED_TORCHLIB_OPS TORCHLIB_OPINFO_MAPPING dict str TorchLibOpInfo = info op_info_name info info TESTED_TORCHLIB_OPS info complex TESTED_OPS = frozenset TORCHLIB_OPINFO_MAPPING EXPECTED_SKIPS_OR_FAILS tuple ops_test_common DecorateMeta = tuple functools reduce Flatten list lambda b b meta meta info skips_or_fails meta matcher None info TESTED_TORCHLIB_OPS SKIP_XFAIL_SUBTESTS tuple ops_test_common DecorateMeta = tuple functools reduce Flatten list lambda b b meta meta info skips_or_fails meta matcher None info TESTED_TORCHLIB_OPS MARK Complex supported functions COMPLEX_FUNCTION_MAPPING dict str TorchLibOpInfo = info op_info_name info info TESTED_TORCHLIB_OPS info complex Call dir torch ops prims compare entries OPS_DB create OpInfo newly added prims ops PRIMS_OPS_WITH_OP_INFO = abs acos acosh add amax amin as_strided as_strided_scatter asin asinh atan atan atanh bitwise_and bitwise_not bitwise_or bitwise_xor cat ceil clone conj conj_physical cos cosh digamma div empty eq erf erfc exp exp expm fill floor fmax fmin fmod full full_like gcd ge gt hypot igamma igammac imag isfinite le lgamma log log log p log lt maximum minimum mul ne neg nextafter normal pow prod real reciprocal remainder reshape round rsqrt scalar_tensor sign signbit sin sinh sqrt squeeze sub sum svd tan tanh transpose trunc uniform where op PRIMS_OPS_WITH_OP_INFO Duplicate opinfo prim ops The new names all start prims_ E g abs - prims_abs ops_test_common duplicate_opinfo_for_prims OPS_DB op Duplicate cases where prims op name different torch op name ops_test_common duplicate_opinfo_for_prims OPS_DB i bessel_i ops_test_common duplicate_opinfo_for_prims OPS_DB special bessel_j bessel_j ops_test_common duplicate_opinfo_for_prims OPS_DB special bessel_j bessel_j ops_test_common duplicate_opinfo_for_prims OPS_DB special erfcx erfcx ops_test_common duplicate_opinfo_for_prims OPS_DB special i e bessel_i e ops_test_common duplicate_opinfo_for_prims OPS_DB special i bessel_i ops_test_common duplicate_opinfo_for_prims OPS_DB special i e bessel_i e ops_test_common duplicate_opinfo_for_prims OPS_DB special ndtri ndtri ops_test_common duplicate_opinfo_for_prims OPS_DB special spherical_bessel_j spherical_bessel_j ops_test_common duplicate_opinfo_for_prims OPS_DB special zeta zeta OP_WITH_SKIPPED_XFAIL_SUBTESTS = frozenset meta op_name meta SKIP_XFAIL_SUBTESTS ALL_OPS_IN_DB = frozenset op_info name op_info OPS_DB Assert all ops OPINFO_FUNCTION_MAPPING OPS_DB assert TESTED_OPS issubset ALL_OPS_IN_DB f TESTED_OPS - ALL_OPS_IN_DB OPS_DB assert NONDETERMINISTIC_OPS issubset TESTED_OPS f NONDETERMINISTIC_OPS - TESTED_OPS TESTED_OPS