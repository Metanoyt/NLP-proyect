mypy allow-untyped-defs __future__ annotations abc contextlib dataclasses difflib io sys typing Any TYPE_CHECKING torch torch fx torch _subclasses fake_tensor unset_fake_temporarily TYPE_CHECKING collections abc Callable torch _subclasses fake_tensor dataclasses dataclass PackageInfo package_name str version str &#124; None commit_hash str &#124; None to_onnx_domain_string - str join filter None pkg package_name version commit_hash classmethod from_python_class cls python_class_name type &#124; str - PackageInfo isinstance python_class_name type python_class_name = python_class_name __module__ package_name = python_class_name split package = __import__ package_name version = getattr package __version__ None TODO Figure out how retrieve commit hash commit_hash = None cls package_name version commit_hash dataclasses dataclass GraphModuleOnnxMeta package_info PackageInfo contextlib contextmanager _patch_difflib_sequence_matcher_init Context patching ` difflib SequenceMatcher ` fx readable graph Under context ` autojunk ` argument ` difflib SequenceMatcher ` will always considered ` False ` This prevent ` difflib SequenceMatcher ` recognizing stacktrace messages fx readable graph junk these messages tend long repeat multiple times which falls under junk filter criteria ` difflib SequenceMatcher ` used underneath all sorts diffing functions ` difflib ` including ` difflib unified_diff ` ` difflib ndiff ` ` difflib context_diff ` Unfortunately there no way pass ` autojunk ` argument these functions they all default ` True ` This context patching will affect all them ` Reference Automatic junk heuristic https docs python org library difflib html ` _ original_init = difflib SequenceMatcher __init__ patched_init isjunk=None a= b= autojunk=True original_init isjunk b autojunk=False difflib SequenceMatcher __init__ = patched_init type ignore assignment try yield finally difflib SequenceMatcher __init__ = original_init type ignore assignment _unified_diff str b str - str Return string containing unified diff two strings This function calls patched version ` difflib unified_diff ` ` autojunk ` set ` False ` ` difflib SequenceMatcher ` More details can found ` _patch_difflib_sequence_matcher_init ` function Args The first string b The second string Returns The unified diff two strings If there no diff no diff Example = GraphModule torch nn Module forward input_ids torch Tensor attention_mask torch Tensor File modeling py code input_ids = input_ids view - input_shape - view = input_ids view - input_ids = None b = lambda torch nn Module forward input_ids i attention_mask i File modeling py code input_ids = input_ids view - input_shape - view i = torch ops aten view default input_ids - input_ids = None print _unified_diff b --- +++ - + -class GraphModule torch nn Module - forward input_ids torch Tensor attention_mask torch Tensor +class lambda torch nn Module + forward input_ids i attention_mask i File modeling py code input_ids = input_ids view - input_shape - - view = input_ids view - input_ids = None + view i = torch ops aten view default input_ids - input_ids = None a_list = splitlines keepends=True b_list = b splitlines keepends=True _patch_difflib_sequence_matcher_init Set ` n ` ` sys maxsize ` show entire graph when there diff diff = join difflib unified_diff a_list b_list n=sys maxsize diff no diff diff _transform_diagnose_call_message_formatter run Callable Transform args Any kwargs Any - str f Running __class__ __name__ pass maybe_fx_graph_tabular graph torch fx Graph - str &#124; None Return Graph nodes tabular format Equivalent stdout ` graph print_tabular ` If ` tabulate ` installed ` None ` Args graph The Graph print Returns The Graph printed tabular format None ` tabulate ` installed f = io StringIO contextlib redirect_stdout f try graph print_tabular except ImportError None f getvalue Transform abc ABC Base FX graph transformations used FX-ONNX exporter Similar ` FX Interpreter https pytorch org docs stable fx html#torch fx Interpreter ` _ specializations execute FX graph Node-by-Node Methods ` Transform ` can overridden customize behavior model This pattern can useful many things including writing code transformations well analysis passes The following methods can overridden _run + -- run_node + -- placeholder + -- get_attr + -- call_function + -- call_method + -- call_module + -- output One important aspect note transformation modifies model input output signature e g additional inputs outputs added model ` InputAdaptStep ` ` OutputAdaptStep ` needed reconcile attr ` ONNXProgram model_proto ` That model signature model representation must match TODO bowbao Add more overridable methods call hierarchy TODO bowbao Create example once more overridable methods added module torch fx GraphModule The module transformed fake_mode fake_tensor FakeTensorMode &#124; None The existing fake mode detected ` module ` __init__ module torch fx GraphModule Initialize transform Args module The module transformed module = module fake_mode = _detect_fake_mode _detect_fake_mode - fake_tensor FakeTensorMode &#124; None Detect fake mode graph Scan through all nodes graph their meta val detect fake mode fake_tensors = node meta get val node module graph nodes unset_fake_temporarily torch _dynamo utils detect_fake_mode fake_tensors _maybe_fakefy_args fake_mode fake_tensor FakeTensorMode &#124; None args Any - tuple Any fake_mode None args NB This should hit cache tensors fakefied before E g when fx graph produced Dynamo tuple fake_mode from_tensor t isinstance t torch Tensor t t args abc abstractmethod _run args kwargs - torch fx GraphModule run args kwargs - torch fx GraphModule Run transform ` module ` Note method may may mutate ` module ` returned ` GraphModule ` could either ` module ` new ` GraphModule ` Args args Positional arguments ` module ` run kwargs Keyword arguments ` module ` run _run args kwargs