Module handling ATen ONNX functions registration https github com pytorch pytorch blob aa bb dee f e c c b cdc torch onnx _internal fx registration py NOTE Why do we need different registry than one torchlib The registry torchlib used register functions already implemented torchlib designed static singleton It does take into account custom ops different opsets etc The registry implemented exporter designed modifiable export time users designed dispatching mind mypy allow-untyped-defs __future__ annotations dataclasses importlib util logging math operator types collections abc Callable typing Literal TypeAlias Union torch torch _ops torch onnx _internal _lazy_import onnxscript onnxscript_apis torch onnx _internal exporter _constants _schemas torch onnx _internal exporter _torchlib _torchlib_registry TorchOp TypeAlias = Union torch _ops OpOverload types BuiltinFunctionType Callable logger = logging getLogger __name__ dataclasses dataclass OnnxDecompMeta A wrapper onnx-script function additional metadata onnx_function The onnx-script function torchlib fx_target The PyTorch node callable target signature The ONNX signature function When None signature inferred is_custom Whether function custom function is_complex Whether function function handles complex valued inputs opset_introduced The ONNX opset version which function introduced Its specifies minimum ONNX opset version required use function device The device function registered If None registered all devices skip_signature_inference Whether skip signature inference function onnx_function Callable fx_target TorchOp signature _schemas OpSignature &#124; None is_custom bool = False is_complex bool = False opset_introduced int = device Literal cuda cpu &#124; str &#124; None = None noqa PYI skip_signature_inference bool = False __post_init__ - None signature None skip_signature_inference try isinstance onnx_function onnxscript OnnxFunction signature = _schemas OpSignature from_function type ignore attr-defined onnx_function pyrefly ignore missing-attribute onnx_function function_ir domain pyrefly ignore missing-attribute onnx_function name pyrefly ignore missing-attribute opset_version=self onnx_function opset version signature = _schemas OpSignature from_function onnx_function __traced onnx_function __name__ except Exception e Log warning op custom Raise exception builtin ops is_custom raise When function targeting HOP example will accept functions arguments fail generate ONNX signature In case we set signature None dispatch function always logger warning noqa G Failed infer signature function s because s All nodes targeting ` s ` will dispatched function onnx_function e fx_target signature = signature onnx_function _pt_onnx_signature = signature type ignore attr-defined _get_overload qualified_name str - torch _ops OpOverload &#124; None Obtain torch op namespace op_name overload TODO justinchuby Handle arbitrary custom ops namespace opname_overload = qualified_name split op_name maybe_overload = opname_overload split namespace == _operator Builtin functions getattr operator op_name namespace == math getattr math op_name namespace == torchvision importlib util find_spec torchvision None logger warning torchvision installed Skipping s qualified_name None try op_packet = getattr getattr torch ops namespace op_name maybe_overload overload = maybe_overload default op_packet _overload_names op_packet _overload_names Has default overload overload = default logger warning s does have default overload This could error specifying op name Ignoring qualified_name stacklevel= None getattr op_packet overload type ignore call-overload except AttributeError qualified_name endswith getitem This special case where we registered function incorrectly BC reasons pt = we need keep None logger info s found version PyTorch qualified_name None except Exception logger exception Failed find torch op s qualified_name None ONNXRegistry Registry ONNX functions The registry maintains mapping qualified names symbolic functions under fixed opset version It supports registering custom onnx-script functions dispatcher dispatch calls appropriate function __init__ - None Initializes registry _opset_version = _constants TORCHLIB_OPSET functions dict TorchOp &#124; str list OnnxDecompMeta = property opset_version - int The ONNX opset version exporter should target _opset_version classmethod from_torchlib cls opset_version=_constants TORCHLIB_OPSET - ONNXRegistry Populates registry ATen functions torchlib Args torchlib_registry The torchlib registry use populating registry registry = cls registry _opset_version = opset_version meta _torchlib_registry get_torchlib_ops registry _register meta fx_target meta TODO justinchuby Remove once torchlib migrated PyTorch torchlib_ops = onnxscript_apis get_torchlib_ops torchlib_meta torchlib_ops qualified_name = torchlib_meta qualified_name overload_func = torchlib_meta function try NOTE This heavily guarded try-except because we don t want fail entire registry population one function fails target = _get_overload qualified_name target None continue meta = OnnxDecompMeta onnx_function=overload_func fx_target=target signature=None is_custom=False is_complex=torchlib_meta is_complex registry _register target meta except Exception logger exception Failed register s Skipped qualified_name continue registry _cleanup_registry_based_on_opset_version registry _register target TorchOp onnx_decomposition OnnxDecompMeta - None Registers OnnxDecompMeta operator Args target The PyTorch node callable target onnx_decomposition The OnnxDecompMeta register target_or_name str &#124; TorchOp isinstance target torch _ops OpOverload Get qualified name aten op because torch _ops OpOverload lookup dictionary unreliable some reason target_or_name = target name target_or_name = target onnx_decomposition is_custom functions setdefault target_or_name insert onnx_decomposition functions setdefault target_or_name append onnx_decomposition register_op target TorchOp function Callable is_complex bool = False - None Registers custom operator torch ops namespace op_name overload Args target The PyTorch node callable target function The onnx-script function register is_complex Whether function function handles complex valued inputs isinstance target torch _ops OpOverloadPacket raise TypeError f Target target should provided OpOverload instead OpOverloadPacket You can get default overload op default _register target OnnxDecompMeta onnx_function=function fx_target=target signature=None is_custom=True is_complex=is_complex get_decomps target TorchOp - list OnnxDecompMeta Returns list OnnxDecompMeta given op torch ops namespace op_name overload The list ordered time registration The custom operators should come first list Args target The PyTorch node callable target Returns A list OnnxDecompMeta corresponding given name None name registry target_or_name str &#124; TorchOp isinstance target torch _ops OpOverload Get qualified name aten op because torch _ops OpOverload lookup dictionary unreliable some reason target_or_name = target name target_or_name = target decomps = functions get target_or_name sorted decomps key=lambda x x is_custom reverse=True is_registered target TorchOp - bool Returns whether given op registered torch ops namespace op_name overload Args target The PyTorch node callable target Returns True given op registered otherwise False bool get_decomps target _cleanup_registry_based_on_opset_version - None Pick implementation highest opset version valid until current opset version cleaned_functions = target_or_name decomps functions items Filter decompositions only include those opset_introduced = opset_version decomps = d d decomps d opset_introduced = opset_version Keep only decomposition highest opset_introduced decomps Find maximum opset_introduced max_opset = max d opset_introduced d decomps Keep all decompositions maximum opset_introduced cleaned_functions target_or_name = d d decomps d opset_introduced == max_opset functions = cleaned_functions __repr__ - str f __class__ __name__ functions= functions