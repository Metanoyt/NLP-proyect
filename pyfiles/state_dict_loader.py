mypy allow-untyped-decorators mypy allow-untyped-defs inspect logging os warnings typing Any cast Optional TYPE_CHECKING Union typing_extensions deprecated torch torch distributed dist torch distributed checkpoint default_planner _EmptyStateDictLoadPlanner torch distributed checkpoint logger _dcp_method_logger torch distributed checkpoint stateful Stateful _storage_utils _storage_setup default_planner DefaultLoadPlanner planner LoadPlan LoadPlanner storage StorageReader utils _api_bc_check _DistWrapper _profile TYPE_CHECKING torch distributed checkpoint metadata Metadata __all__ = load_state_dict load logger = logging getLogger deprecated ` load_state_dict ` deprecated will removed future versions Please use ` load ` instead category=FutureWarning load_state_dict state_dict dict str Any storage_reader StorageReader process_group Optional dist ProcessGroup = None coordinator_rank int = no_dist bool = False planner Optional LoadPlanner = None - None This method deprecated Please switch load storage_reader reset _profile TODO test returning ` load ` here instead _load_state_dict state_dict storage_reader process_group coordinator_rank no_dist planner _dcp_method_logger log_exceptions=True _api_bc_check load state_dict dict str Any checkpoint_id Union str os PathLike None = None storage_reader Optional StorageReader = None planner Optional LoadPlanner = None process_group Optional dist ProcessGroup = None no_dist bool = False - None Load checkpoint into distributed state dict SPMD style Each rank must have same keys their ` ` state_dict ` ` provided API Mismatched keys may result hangs errors If unsure you can use ` ` utils _assert_same_keys ` ` API check may incur communication costs Each rank will try read least amount data necessary fulfill requested ` state_dict ` When loading ` ShardedTensor ` ` DTensor ` instances each rank only reads data their local shards For each ` ` Stateful ` ` object having both ` ` state_dict ` ` ` ` load_state_dict ` ` load will first call ` ` state_dict ` ` before attempting deserialization followed ` ` load_state_dict ` ` once deserialization complete For each non- ` ` Stateful ` ` object load will deserialize object then replace ` ` state_dict ` ` deserialized object warning All tensors ` ` state_dict ` ` must allocated their destination device prior calling function All non-tensor data loaded using ` torch load ` modified place state_dict warning Users must call ` load_state_dict ` root module ensure load pos-processing non-tensor data properly propagates note If no process group initialized function will assume intent load checkpoint into local process This can useful case local inference when using regular Tensors opposed DTensor ShardedTensor note Rank assumed coordinator rank Args state_dict Dict str Any The state_dict load checkpoint into checkpoint_id Union str os PathLike None The ID checkpoint instance The meaning checkpoint_id depends storage It can path folder file It can also key storage key-value store Default ` ` None ` ` storage_reader Optional StorageReader Instance StorageWriter used perform reads If specified DCP will automatically infer reader based checkpoint_id If checkpoint_id also None exception will raised Default ` ` None ` ` planner Optional LoadPlanner Instance LoadPlanner If specified default planner will used Default ` ` None ` ` process_group Optional ProcessGroup ProcessGroup used cross-rank synchronization Default ` ` None ` ` no_dist bool If ` ` True ` ` function will assume intent load checkpoint without using cross-rank synchronization Default ` ` False ` ` Returns None Examples xdoctest +SKIP my_model = MyModule optimizer = Adagrad my_model parameters model_state_dict = my_model state_dict fs_storage_reader = torch distributed checkpoint FileSystemReader checkpoint torch distributed checkpoint load_state_dict state_dict=model_state_dict storage_reader=fs_storage_reader module load_state_dict function might have customized steps flush state_dict must call ensure correct behavior my_model load_state_dict model_state_dict note load_state_dict uses collectives coordinate reads across ranks For NCCL-based process groups internal tensor representations objects must moved GPU device before communication takes place In case device used given ` ` torch cuda current_device ` ` user s responsibility ensure set so each rank has individual GPU via ` ` torch cuda set_device ` ` no_dist = no_dist dist is_available dist is_initialized no_dist warnings warn torch distributed disabled unavailable uninitialized assuming intent load single process stacklevel= _profile storage_reader = cast StorageReader _storage_setup storage_reader checkpoint_id reader=True All ranks must have same keys their ` state_dict ` provided API See documentation more details Here we simply sort keys ensure all ranks load values same order keys = sorted state_dict keys statetful_sd = key keys key state_dict continue elem = state_dict key statetful_sd key = elem state_dict isinstance elem Stateful elem _load_state_dict state_dict=statetful_sd storage_reader=storage_reader process_group=process_group no_dist=no_dist planner=planner key keys key state_dict continue elem = state_dict key isinstance elem Stateful If state_dict Stateful object DCP does in-place load original state dict elem load_state_dict statetful_sd key Otherwise replace state_dict loaded state_dict state_dict key = statetful_sd key _load_state_dict state_dict dict str Any storage_reader StorageReader process_group Optional dist ProcessGroup = None coordinator_rank int = no_dist bool = False planner Optional LoadPlanner = None - None torch _C _log_api_usage_once torch distributed checkpoint load_state_dict distW = _DistWrapper process_group no_dist coordinator_rank planner None planner = DefaultLoadPlanner ckpt_kwargs = ckpt_id = getattr storage_reader checkpoint_id None None ckpt_kwargs checkpoint_id = ckpt_id ckpt_kwargs process_group = distW group use_collectives = True metadata Optional Metadata = None _dcp_method_logger ckpt_kwargs local_step nonlocal use_collectives nonlocal metadata Use global metadata available otherwise fallback rank local metadata try metadata = storage_reader read_metadata except Exception logger info Global metadata found Falling back rank local metadata metadata kwargs inspect signature storage_reader read_metadata parameters try metadata = storage_reader read_metadata rank=distW rank noqa F use_collectives = False except Exception logger info Rank local metadata found planner None raise AssertionError planner None metadata None raise AssertionError metadata None planner set_up_planner state_dict metadata distW is_coordinator kwargs inspect signature storage_reader set_up_storage_reader parameters storage_reader set_up_storage_reader metadata distW is_coordinator rank=distW rank use_collectives=use_collectives storage_reader set_up_storage_reader metadata distW is_coordinator local_plan = planner create_local_plan local_plan = storage_reader prepare_local_plan local_plan local_plan _dcp_method_logger ckpt_kwargs global_step all_local_plans planner None raise AssertionError planner None all_local_plans = planner create_global_plan all_local_plans all_local_plans = storage_reader prepare_global_plan all_local_plans all_local_plans central_plan Optional LoadPlan = None use_collectives central_plan = distW reduce_scatter plan local_step global_step local_plan LoadPlan = local_step global_plan list LoadPlan = global_step local_plan central_plan = global_plan _dcp_method_logger ckpt_kwargs read_data planner None raise AssertionError planner None central_plan None raise AssertionError central_plan None final_local_plan = planner finish_plan central_plan all_reads = storage_reader read_data final_local_plan planner all_reads wait None use_collectives _ = distW all_gather read read_data read_data distW barrier _load_state_dict_from_keys keys Optional Union set str str = None checkpoint_id Union str os PathLike None = None storage_reader Optional StorageReader = None process_group Optional dist ProcessGroup = None - dict str Any Load only specified keys checkpoint no keys specified entire checkpoint will loaded Note method completely loads checkpoint into current process distributed warning warning All non-tensor data loaded using ` torch load ` note As opposed usual pattern function does take state dict input does load inplace Instead new state dict directly initialized read file note If no process group initialized function will assume intent load checkpoint into local process This can useful case local inference when using regular Tensors opposed DTensor ShardedTensor note Rank assumed coordinator rank Args keys Optional Union set str str Loads any key specified set If no keys specified entire checkpoint loaded checkpoint_id Union str os PathLike None The ID checkpoint instance The meaning checkpoint_id depends storage It can path folder file It can also key storage key-value store Default ` ` None ` ` storage_reader Optional StorageReader Instance StorageWriter used perform reads If specified DCP will automatically infer reader based checkpoint_id If checkpoint_id also None exception will raised Default ` ` None ` ` process_group Optional ProcessGroup ProcessGroup used cross-rank synchronization Default ` ` None ` ` Returns State dict specified keys torch _C _log_api_usage_once torch distributed checkpoint _load_state_dict_from_keys no_dist = dist is_available dist is_initialized no_dist warnings warn torch distributed unavailable uninitialized assuming intent load single process stacklevel= storage_reader = cast StorageReader _storage_setup storage_reader checkpoint_id reader=True isinstance keys str keys = keys sd dict str Any = _load_state_dict state_dict=sd storage_reader=storage_reader process_group=process_group no_dist=no_dist planner=_EmptyStateDictLoadPlanner keys=keys sd