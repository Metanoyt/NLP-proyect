mypy ignore-errors torch torch fx experimental proxy_tensor make_fx torch testing _utils wrapper_set_seed torch utils _pytree pytree make_fx_check func args kwargs tracing_mode assert_close=torch testing assert_close randomize_data=False f new_args = handle_sizes_for_dynamic_shapes func args kwargs run f args kwargs wrapper_set_seed f args kwargs traced_f = make_fx f tracing_mode=tracing_mode new_args msg = op args kwargs make_fx op args kwargs produced different values This could mean your abstract impls meta FakeTensor impls incorrect your operator completely traceable e g relies some global state there bug make_fx Note you passed python function operator make_fx_check still possible python function will still work torch compile because handles capturing pieces your python code compile Randomize data run traced graph catch bugs where we may have baked Tensor data into trace This guaranteed succeed because ` f ` might have preconditions values inputs so we just ignore we used random data fails randomize_data new_args = randomize new_args try expected = run f new_args except Exception randomize_data raise result = run traced_f new_args assert_close result expected msg=msg Arguably we should make make_fx promote torch Size objects symbolic shapes Absent here our strategy If any argument torch Size maybe get dynamic shapes - Create temporary Tensor whose size torch Size we want Note we use expanded Tensor we cannot pass meta Tensors make_fx - Pass make_fx such converted proxy Tensor - Unpack size wrapper get torch Size dynamic shapes symbolic mode no-op otherwise handle_sizes_for_dynamic_shapes func args kwargs f args kwargs extra_args extra_kwargs extra_args i t extra_args args i = t size extra_kwargs k t extra_kwargs items kwargs k = t size func args kwargs extra_args = extra_kwargs = i arg enumerate args isinstance arg torch Size extra_args append i torch empty arg device= cpu key value kwargs items isinstance value torch Size extra_kwargs key = torch empty value device= cpu f args kwargs extra_args extra_kwargs randomize args transform x x dtype is_floating_point x x detach clone uniform_ requires_grad_ x requires_grad pytree tree_map_only torch Tensor transform args