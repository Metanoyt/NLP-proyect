mypy allow-untyped-defs functools itertools logging collections abc Sequence dataclasses dataclass typing Any Optional unittest mock patch autotune_process TensorMeta ir Buffer IRNode Layout utils IndentedBuffer unique virtualized V common KernelTemplate rocm_benchmark_request ROCmBenchmarkRequest rocm_kernel ROCmTemplateCaller ROCmTemplateKernel rocm_template_buffer ROCmTemplateBuffer rocm_utils DTYPE_TO_ROCM_TYPE log = logging getLogger __name__ FIXME unify CUDA version dataclass frozen=True ArgInfo name str ty str ROCmTemplate KernelTemplate index_counter = itertools count gfx _threads_per_warp = __init__ name str input_nodes list Buffer layout Layout input_reorder Optional list int = None - None Baseclass ROCm C++ Templates derived KernelTemplate Not instantiated directly Args name str The name ROCmTemplate object input_nodes List IRNode A list input IRNodes layout Layout The layout output buffer tensor input_reorder Optional List int An optional list specifies order input nodes super __init__ name input_nodes = input_nodes output_node Buffer = Buffer name= buf_out layout=layout input_reorder = input_reorder layout = layout generate type ignore override kwargs - ROCmTemplateCaller Generates ROCm template caller object given GEMM template operation This ROCmTemplateCaller may used call benchmark generated ROCm kernel standalone manner enable Autotuning Args kwargs Additional keyword arguments Returns A ROCmTemplateCaller object representing generated ROCm template caller kernel_name = f rocm_ name kernel_hash_name = f rocm_ name _ next index_counter patch object V graph get_dtype _fake_get_dtype output_node ROCmTemplateKernel kernel_name=kernel_name runtime_arg_info=self get_runtime_arg_info runtime_arg_values=self get_runtime_arg_values kwargs kernel code = render kernel=kernel kwargs _ call_args _ _ = kernel args python_argdefs log debug Autotune key s Generated Code \n s kernel_hash_name code log debug Args cpp_argdefs s python_argdefs s kernel args cpp_argdefs DTYPE_TO_ROCM_TYPE kernel args python_argdefs input_reorder = input_reorder input_reorder None list range len input_nodes expected_args = list unique input_nodes idx get_name idx input_reorder expected_args extend output_node get_name assert list call_args len expected_args == expected_args call_args expected_args size_args = size_args hasattr size_args subclass should define size_args size_args_ints = V graph sizevars size_hint arg arg size_args resolve ints benchmarking The runtime args come right after size args runtime_args = get_runtime_arg_values kwargs extra_args = size_args_ints + runtime_args bmreq = ROCmBenchmarkRequest kernel_name=kernel_name input_tensor_meta=TensorMeta from_irnodes input_nodes output_tensor_meta=TensorMeta from_irnodes output_node extra_args=extra_args source_code=code make_kernel_render template_node ROCmTemplateBuffer epilogue_nodes Optional Sequence IRNode = None kernel = ROCmTemplateKernel kernel_name= KERNEL_NAME runtime_arg_info=self get_runtime_arg_info runtime_arg_values=self get_runtime_arg_values kwargs render = functools partial render kernel=kernel template_buffer_node=template_node epilogue_nodes=epilogue_nodes kwargs includes op argument case CUTLASSGemmTemplate kernel render ROCmTemplateCaller kernel_hash_name name input_nodes output_node get_layout make_kernel_render bmreq kwargs header - IndentedBuffer res = IndentedBuffer res splice #include exception #include iostream #include memory #include random #include vector res globals - IndentedBuffer res = IndentedBuffer res splice We compile all models -fvisibility=hidden Any symbols need exposed final shared library must declared PT_EXPORT make them visible #ifdef __GNUC__ Applies any compiler GNU extensions clang g++ #define PT_EXPORT __attribute__ __visibility__ default #else #ifdef _WIN #define PT_EXPORT __declspec dllexport #else #define PT_EXPORT #endif #endif res render kwargs - str raise NotImplementedError get_runtime_arg_info - list ArgInfo get_runtime_arg_values kwargs - list Any