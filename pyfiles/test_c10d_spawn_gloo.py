Owner s oncall distributed copy os tempfile test_c d_spawn _torch_dist_nn_available TestDistributedNNFunctions torch torch distributed c d torch nn nn torch testing _internal common_cuda TEST_CUDA torch testing _internal common_distributed requires_gloo skip_if_lt_x_gpu torch testing _internal common_utils run_tests skip_but_pass_in_sandcastle_if TEST_WITH_DEV_DBG_ASAN TestCase Fails Python- see https github com pytorch pytorch issues DistributedDataParallelSingleProcessTest TestCase setUp rank = world_size = file = tempfile NamedTemporaryFile delete=False noqa P tearDown try os remove file name except OSError pass _test_base net inp check_allclose=True store = c d FileStore file name world_size c d init_process_group backend= gloo store=store rank=self rank world_size=self world_size process_group = c d distributed_c d _get_default_group inp is_cuda device_ids = torch cuda current_device device_ids = None ddp = nn parallel DistributedDataParallel copy deepcopy net device_ids=device_ids process_group=process_group net_opt = torch optim Adam net parameters lr= ddp_opt = torch optim Adam ddp parameters lr= i j zip ddp parameters net parameters assertTrue i allclose j _ range net_out = net inp ddp_out = ddp inp net_out sum backward ddp_out sum backward net_opt step ddp_opt step check_allclose i j zip ddp parameters net parameters assertTrue i allclose j requires_gloo test_cpu _test_base nn Linear torch randn requires_gloo skip_but_pass_in_sandcastle_if TEST_CUDA At least CUDA GPUS needed test_cuda _test_base nn Linear torch randn requires_gloo skip_but_pass_in_sandcastle_if TEST_CUDA At least CUDA GPUS needed test_rnn This test inspired bug reported https github com pytorch pytorch issues BATCH_SIZE = Divisible INPUT_DIM = OUTPUT_DIM = HIDDEN_DIM = N_LAYERS = SEQ_LEN = Net nn Module __init__ input_dim hidden_dim output_dim hidden_layers super __init__ input_dim = input_dim hidden_dim = hidden_dim output_dim = output_dim hidden_layers = hidden_layers lstm = nn LSTM input_dim hidden_dim hidden_layers batch_first=True h o = nn Linear hidden_dim output_dim forward x y lstm flatten_parameters h_t _ = lstm x output = h o h_t loss = nn functional mse_loss output y loss net = Net INPUT_DIM HIDDEN_DIM OUTPUT_DIM N_LAYERS inp = torch randn BATCH_SIZE SEQ_LEN INPUT_DIM torch rand BATCH_SIZE SEQ_LEN OUTPUT_DIM Not checking result allclose parameter inconsistency exist prior change See _test_base net inp check_allclose=False Skip dev-asan torch + multiprocessing spawn have known issues TEST_WITH_DEV_DBG_ASAN TestDistributedNNFunctionsGloo TestDistributedNNFunctions Test Common Ops First requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_broadcast _test_broadcast gloo requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_reduce _test_reduce gloo requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_allreduce _test_allreduce gloo requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_all_gather _test_all_gather gloo requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_all_to_all _test_all_to_all gloo requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_all_to_all_single _test_all_to_all_single gloo Test Ops only supported GLOO requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_gather store = c d FileStore file_name world_size This required because these functions calls directly dist needs world initialized c d init_process_group store=store rank=self rank world_size=self world_size backend= gloo device = torch device f cuda rank x = torch ones device=device + rank x requires_grad = True tensors = torch distributed nn gather x rank == i t enumerate tensors assertEqual t torch ones device=device + i rank == t tensors zeros = torch zeros device=device assertEqual t zeros y = torch sum torch stack tensors axis= z = y sin sum z backward Test gradient x_s = torch ones device=device assertEqual x grad x_s cos requires_gloo skip_if_lt_x_gpu skip_but_pass_in_sandcastle_if _torch_dist_nn_available torch distributed nn available test_scatter store = c d FileStore file_name world_size This required because these functions calls directly dist needs world initialized c d init_process_group store=store rank=self rank world_size=self world_size backend= gloo device = torch device f cuda rank x = torch ones device=device x = torch ones device=device + x requires_grad = True x requires_grad = True y = torch distributed nn scatter x x rank == assertEqual y + torch ones device=device rank == assertEqual y torch ones device=device z = y sin sum z backward Test gradient rank == x _s = torch ones device=device cos x _s = torch ones device=device cos assertEqual x grad x _s assertEqual x grad x _s rank == assertEqual x grad torch zeros device=device __name__ == __main__ run_tests