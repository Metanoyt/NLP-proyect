Owner s oncall jit os sys unittest torch Make helper files test importable pytorch_test_dir = os path dirname os path dirname os path realpath __file__ sys path append pytorch_test_dir torch testing _internal common_utils raise_on_run_directly torch testing _internal jit_utils JitTestCase canonical graph torch _C _jit_pass_canonicalize graph str False TestCustomOperators JitTestCase test_dynamic_op_registry torch _ops _OpNamespace assertTrue hasattr torch ops _test torch ops __dict__ torch ops __dict__ pop _test Don t use ` hasattr ` because will call ` __getattr__ ` assertNotIn _test torch ops __dict__ torch ops _test assertIn _test torch ops __dict__ assertEqual type torch ops _test _OpNamespace assertNotIn leaky_relu torch ops _test __dict__ op = torch ops _test leaky_relu assertTrue callable op assertIn leaky_relu torch ops _test __dict__ op = torch ops _test leaky_relu assertEqual op op test_getting_invalid_attr attr __origin__ __self__ assertRaisesRegexWithHighlight AttributeError f Invalid attribute attr _OpNamespace _test getattr torch ops _test attr test_simply_calling_an_operator input = torch randn output = torch ops aten relu input assertEqual output input relu test_default_arguments_are_used output = torch ops _test leaky_relu torch tensor - assertEqual output torch tensor - test_passing_too_many_args assertRaisesRegexWithHighlight RuntimeError r aten relu\ \ expected most argument\ s\ received argument\ s\ torch ops aten relu test_passing_too_few_args assertRaisesRegexWithHighlight RuntimeError r aten relu\ \ missing value argument torch ops aten relu test_passing_one_positional_but_not_the_second assertRaisesRegexWithHighlight RuntimeError r aten type_as\ \ missing value argument other torch ops aten type_as torch ones test_passing_unknown_kwargs assertRaisesRegexWithHighlight RuntimeError Unknown keyword argument foo operator _test leaky_relu torch ops _test leaky_relu torch ones foo=torch ones test_passing_and_returning_lists Replace actual test once we support lists b = torch rand torch rand output = torch ops _test cat b output_ref = torch cat b assertEqual output output_ref test_calling_scripted_custom_op torch jit script func x torch ops aten relu x input = torch ones assertEqual func input input relu test_calling_traced_custom_op input = torch ones func = torch jit trace torch ops aten relu input assertEqual func input input relu unittest skip Need figure out default dtype differences between fbcode oss test_script_graph_for_custom_ops_matches_traced_graph input = torch ones trace = torch jit trace torch ops aten relu input assertExpectedInline canonical trace graph \ graph Float Float = aten relu test_script_graph_contains_custom_op torch jit script func x torch ops aten relu x assertExpectedInline canonical func graph \ graph x Tensor Tensor = aten relu x test_generic_list assertEqual torch ops _test get_first hello hello https github com pytorch pytorch issues test_where_no_scalar x = torch rand torch ops aten where x - does raise __name__ == __main__ raise_on_run_directly test test_jit py