Owner s module inductor itertools sys unittest typing NamedTuple torch torch _inductor config torch _inductor test_case TestCase InductorTestCase torch testing _internal common_utils slowTest torch testing _internal inductor_utils GPU_TYPE RUN_GPU try try test_combo_kernels test_foreach test_pattern_matcher test_select_algorithm test_torchinductor test_torchinductor_dynamic_shapes except ImportError test_combo_kernels manual=fbcode caffe test inductor combo_kernels-library test_foreach manual=fbcode caffe test inductor foreach-library test_pattern_matcher manual=fbcode caffe test inductor pattern_matcher-library test_select_algorithm manual=fbcode caffe test inductor select_algorithm-library test_torchinductor manual=fbcode caffe test inductor test_inductor-library test_torchinductor_dynamic_shapes manual=fbcode caffe test inductor test_inductor-library_dynamic_shapes except unittest SkipTest __name__ == __main__ sys exit raise GpuWrapperTemplate pass TestGpuWrapper InductorTestCase device = GPU_TYPE test_aoti_debug_printer_works_on_constants batch_size = seq_length = hidden_size = test_fn inp = torch randn batch_size seq_length hidden_size device=self device weight = torch randn hidden_size hidden_size device=self device matmul_output = inp weight torch nn LayerNorm hidden_size device=self device matmul_output True comp = torch compile options= cpp_wrapper True aot_inductor debug_intermediate_value_printer test_fn comp test_non_tensor_args_wrapped_on_cpu RUN_GPU skipTest GPU available test_fn x s x + s sum compiled = torch compile options= cpp_wrapper True test_fn x = torch randn device=self device torch utils _device DeviceContext device _ code = test_torchinductor run_and_get_cpp_code compiled x assertIn torch tensor arg device= cpu code DynamicShapesGpuWrapperGpuTests InductorTestCase device = GPU_TYPE test_annotation_training batch_size = seq_length = hidden_size = create_test_fn test_fn inp = torch randn batch_size seq_length hidden_size device=self device weight = torch randn hidden_size hidden_size device=self device matmul_output = inp weight torch nn LayerNorm hidden_size device=self device matmul_output True test_fn fn = torch compile options= annotate_training True cpp_wrapper True create_test_fn fn test_failures_gpu_wrapper = test_mm_plus_mm _dynamic_shapes test_torchinductor TestFailure gpu_wrapper is_skip=True test_randint_xpu test_torchinductor TestFailure gpu_wrapper is_skip=False test_randint_xpu_dynamic_shapes test_torchinductor TestFailure gpu_wrapper is_skip=False ATen ops scaled_dot_product_efficient_attention implemented XPU test_scaled_dot_product_efficient_attention_xpu test_torchinductor TestFailure gpu_wrapper is_skip=False test_scaled_dot_product_efficient_attention_xpu_dynamic_shapes test_torchinductor TestFailure gpu_wrapper is_skip=False make_test_case name device tests condition=True slow=False func_inputs=None code_string_count=None check_code=True test_name = f name _ device device name code_string_count None code_string_count = func = getattr tests test_name assert callable func callable func = slowTest func slow func config patch cpp_wrapper=True fn tests setUpClass tests setUp try torch _C _PreserveDispatchKeyGuard torch _C _dispatch_tls_set_dispatch_key_included torch _C DispatchKey Dense True _ code = test_torchinductor run_and_get_cpp_code func func_inputs func_inputs check_code assertEqual CppWrapperCodeCache code True assertTrue all code count string == code_string_count string string code_string_count finally tests tearDown tests tearDownClass fn __name__ = test_name copy fn __dict__ = copy deepcopy func __dict__ condition setattr GpuWrapperTemplate test_name fn RUN_GPU BaseTest NamedTuple name str device str = GPU_TYPE tests InductorTestCase = test_torchinductor GPUTests check_code bool = True XPU Not implemented yet XPU_BASE_TEST_SKIP = test_dynamic_shapes_persistent_reduction_mixed_x_dim Maintain two separate test lists cuda cpp now item BaseTest test_add_complex BaseTest test_add_complex BaseTest test_as_strided buffer reuse BaseTest test_batch_norm_ d_ BaseTest test_bernoulli BaseTest test_bitwise int BaseTest test_bmm BaseTest test_bmm BaseTest test_buffer_use_after_remove BaseTest test_cat alias BaseTest test_convolution BaseTest test_conv_backward BaseTest test_custom_op_ BaseTest test_custom_op_ BaseTest test_custom_op_ BaseTest test_embedding_bag test default FallbackKernel BaseTest test_index_put_deterministic_fallback BaseTest test_adding_tensor_offsets BaseTest test_index_tensor BaseTest test_inductor_layout_optimization_input_mutations BaseTest test_insignificant_strides BaseTest test_layer_norm BaseTest test_linear BaseTest test_linear BaseTest test_mm_views BaseTest test_multi_device BaseTest test_multi_threading BaseTest test_pow BaseTest test_profiler_mark_wrapper_call BaseTest test_randint BaseTest test_reduction Reduction BaseTest test_relu multiple inputs BaseTest test_repeat_interleave_ BaseTest test_roi_align BaseTest test_scalar_input BaseTest test_scaled_dot_product_attention BaseTest test_scaled_dot_product_efficient_attention BaseTest test_sort BaseTest test_silu single input single output BaseTest test_sum_dtype float BaseTest test_sum_int bool int int uint BaseTest test_transpose multiple outputs buffer clear BaseTest f test_unspec_inputs_ str dtype dtype test_torchinductor test_dtypes BaseTest test_consecutive_split_cumprod BaseTest test_pointwise_hermite_polynomial_he BaseTest test_pointwise_hermite_polynomial_h BaseTest test_foreach_cpp_wrapper tests=test_foreach ForeachTests test foreach BaseTest test_enable_dynamic_shapes_cpp_wrapper tests=test_foreach ForeachTests BaseTest test_dynamic_shapes_persistent_reduction_mixed_x_dim tests=test_combo_kernels ComboKernelDynamicShapesTests BaseTest test_cat_slice_cat tests=test_pattern_matcher TestPatternMatcher TODO Re-enable test after fixing cuda wrapper conv Triton templates dynamic shapes This test unstable succeeds when ATEN kernel used fails when Triton kernel used Currently passes CI ATEN kernel chosen fails locally Triton kernel chosen Ideally should succeed whatever kernels BaseTest test_convolution device=None tests=test_select_algorithm TestSelectAlgorithm BaseTest test_mm_plus_mm device=None tests=test_select_algorithm TestSelectAlgorithm BaseTest test_mm_plus_mm device=None tests=test_select_algorithm TestSelectAlgorithm BaseTest test_fft_real_input BaseTest test_fft_real_input_real_output some dtypes may raise exception skipped test_dtypeview so set check_code False here BaseTest f test_dtypeview_ str dtype_x _ str dtype_y check_code=False dtype_x dtype_y itertools product test_torchinductor test_dtypes test_torchinductor test_dtypes BaseTest test_dtypeview_fusion skip enough SMs BaseTest test_addmm device=None tests=test_select_algorithm TestSelectAlgorithm skip enough SMs BaseTest test_linear_relu device=None tests=test_select_algorithm TestSelectAlgorithm item device == xpu item name XPU_BASE_TEST_SKIP continue make_test_case item name item device item tests check_code=item check_code torch _inductor utils is_big_gpu GPU_TYPE == cuda is_big_gpu skip_list = test_addmm test_linear_relu need skip instead omit otherwise fbcode ci can flaky test_name skip_list test_failures_gpu_wrapper f test_name _cuda = test_torchinductor TestFailure gpu_wrapper is_skip=True test_failures_gpu_wrapper f test_name _gpu_dynamic_shapes = test_torchinductor TestFailure gpu_wrapper is_skip=True test_torchinductor copy_tests GpuWrapperTemplate TestGpuWrapper gpu_wrapper test_failures_gpu_wrapper DynamicShapesGpuWrapperTemplate = test_torchinductor_dynamic_shapes make_dynamic_cls GpuWrapperTemplate test_torchinductor copy_tests DynamicShapesGpuWrapperTemplate DynamicShapesGpuWrapperGpuTests gpu_wrapper test_failures_gpu_wrapper xfail_prop= _expected_failure_dynamic_wrapper __name__ == __main__ torch _inductor test_case run_tests RUN_GPU run_tests needs= filelock