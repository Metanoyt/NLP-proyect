__future__ annotations collections dataclasses functools itertools typing typing Any Optional Union sympy torch utils _ordered_set OrderedSet utils _sympy functions FloorDiv ModularIndexing utils _sympy symbol make_symbol SymT dependencies Dep extract_loop_body_with_args MemoryDep runtime hints ReductionHint scheduler SchedulerNode utils cache_on_self virtualized V typing TYPE_CHECKING collections abc Iterable Sequence torch _inductor tiling_utils CoalesceVarAnalysis NodeScheduleMarker staticmethod only_nodes Iterable NodeScheduleEntry - Iterable SchedulerNode item item DisableReduction item EnableReduction yield item type ignore misc staticmethod is_reduction - bool False NodeScheduleEntry = Union SchedulerNode type NodeScheduleMarker DisableReduction NodeScheduleMarker Marker invoke ` kernel disable_reduction ` This closes reduction loop allows pointwise ops occur output reduction EnableReduction NodeScheduleMarker Marker end DisableReduction block staticmethod filter node_schedule list NodeScheduleEntry - Iterable SchedulerNode Get nodes node_schedule skipping those DisableReduction block disabled = False node node_schedule node EnableReduction DisableReduction Don t tile stuff outside main reduction loop disabled = node DisableReduction disabled pass yield node type ignore misc SIMDKernelFeatures An ordered schedule nodes will become single kernel __init__ node_schedule list NodeScheduleEntry numel sympy Expr reduction_numel sympy Expr = sympy S One coalesce_analysis Optional CoalesceVarAnalysis = None node_schedule = node_schedule numel excludes reduction_numel numel sympy Expr = V graph sizevars simplify numel reduction_numel sympy Expr = V graph sizevars simplify reduction_numel _stats_cache dict tuple sympy Expr MemoryStats = coalesce_analysis = coalesce_analysis cache_on_self is_reduction - bool reduction_numel = cache_on_self scheduler_nodes - Iterable SchedulerNode tuple NodeScheduleMarker only_nodes node_schedule reduction_nodes - list SchedulerNode n n scheduler_nodes n is_reduction cache_on_self buf_accesses - dict str list Dep only needed config benchmark_kernel buf_accesses = collections defaultdict list node scheduler_nodes access node read_writes reads &#124; node read_writes writes buf_accesses access name append access buf_accesses cache_on_self op_counts - collections Counter str counts collections Counter str = collections Counter node scheduler_nodes counts update node _body op_counts counts contains_op op_name str - bool True V ops op_name used node_schedule bool op_counts get op_name get_mutations - OrderedSet str mutations OrderedSet str = OrderedSet node scheduler_nodes buf node get_outputs mutations update buf get_mutations mutations cache_on_self select_index_dtype - torch dtype Gather all used buffer names buffer_names OrderedSet str = OrderedSet node scheduler_nodes buffer_names update node get_buffer_names buffer_names update node used_buffer_names buffers = V graph get_buffer name name buffer_names In theory we can separately check xnumel rnumel = int_max some indexers do use full linear index so we need conservative here total_numel = numel reduction_numel simd SIMDScheduling SIMDScheduling can_use_ bit_indexing total_numel buffers torch int torch int cache_on_self get_reduction_hint - ReductionHint reductions = reduction_nodes len reductions hints = reduction_hint n n reductions hints count hints == len hints reduction_hint_val = hints reduction_hint_val = ReductionHint DEFAULT reduction_hint_val == ReductionHint INNER has_non_contiguous_pw_in_reduction_kernel reduction_hint_val = ReductionHint DEFAULT reduction_hint_val = ReductionHint DEFAULT reduction_hint_val cache_on_self buffer_read_counts - dict str int Counts how many times each buffer read within kernel read_counts dict str int = collections defaultdict int node scheduler_nodes node read_writes reads contains MemoryDep objects each read read_dep node read_writes reads read_counts read_dep name += dict read_counts Convert defaultdict regular dict has_non_contiguous_pw_in_reduction_kernel - bool pointwise_nodes = n n scheduler_nodes n is_reduction n group == numel reduction_numel node pointwise_nodes An index can integer when loading random seed all isinstance dep MemoryDep dep is_contiguous isinstance dep index sympy Integer int dep stride _for_last_dim dep itertools chain node read_writes reads node read_writes writes True False staticmethod reduction_hint node Any - ReductionHint assert node is_reduction node node data reduction_hint = ReductionHint INNER all dep is_contiguous dep itertools chain node read_writes reads node read_writes writes ReductionHint INNER node node data reduction_hint memory_stats groups_dict Optional dict str sympy Expr = None - MemoryStats Analysis generate features can used heuristics groups_dict None groups = numel reduction_numel groups_dict keys == OrderedSet x r _ groups = groups_dict x groups_dict r _ raise NotImplementedError f groups_dict= groups_dict r result = _stats_cache get groups result None _stats_cache groups = result = MemoryStats compute MemoryEstimator groups result MemoryEstimator Estimate various properties kernel use heuristics We simulate memory effects CSE buffer elimination codegen kernel_sizes tuple sympy Expr outside_loop MemoryEstimate loops list MemoryEstimate persistent MemoryEstimate symbols list sympy Symbol __init__ features SIMDKernelFeatures groups Sequence sympy Expr features = features inside_reduction = features is_reduction store_buffer_names OrderedSet str = OrderedSet must_keep_buffers OrderedSet str = OrderedSet num_reductions_dims = groups = groups symbols = make_symbol SymT INDEX i i range len groups We doing two estimates simultaneously first non-persistent aka looped reduction using outside_loop loops we add item loops each corresponding each reduction loop kernel outside_loop only used broadcasting point-wise ops don t use reduction dimension second persistent kernel using persistent persistent kernels don t have loops so we only have one MemoryEstimate point-wise ops two estimates will same they matter reductions only outside_loop = MemoryEstimate loops = MemoryEstimate persistent = MemoryEstimate simulate_codegen remove_kernel_local simulate_codegen - None simd SIMDKernel kernel_size_outside_loop = groups - sympy S One kernel_size_inside_loop = tuple groups kernel_sizes = kernel_size_inside_loop node features node_schedule node DisableReduction inside_reduction = False kernel_sizes = kernel_size_outside_loop continue node EnableReduction inside_reduction = True kernel_sizes = kernel_size_inside_loop loops append MemoryEstimate continue assert isinstance node SchedulerNode rw = extract_loop_body_with_args node _body SIMDKernel map_kernel_groups_to_node_sizes kernel_sizes node get_ranges set_ranges dict zip symbols kernel_sizes dep rw _reads isinstance dep MemoryDep continue dep = dep simplify_with_ranges persistent writes get dep name cache miss persistent reads dep name add dep cache behavior looped kernels more complex than persistent case above some operations lifted outside loop they don t use reduction dimension other operations inside loop can only reused within same loop outside_loop writes get dep name loops - writes get dep name scope dep reads dep name add dep dep name store_buffer_names loops - reads get dep name must_keep_buffers add dep name dep rw _writes isinstance dep MemoryDep continue dep = dep simplify_with_ranges store_buffer_names add dep name persistent writes dep name add dep scope dep writes dep name add dep remove_kernel_local - None Remove any kernel-local buffers fused_node_names = OrderedSet n get_name n features scheduler_nodes name store_buffer_names persistent reads get name V graph scheduler can_buffer_be_removed_through_fusion name fused_node_names persistent remove name name must_keep_buffers we can also remove looped kernel outside_loop remove name loop loops loop remove name loops - loops pop pointwise ops scope dep MemoryDep - MemoryEstimate Determine how read write should categorized inside_reduction has_reduction_var dep index dep is_indirect loops - outside_loop has_reduction_var index sympy Expr - bool sym symbols -self num_reductions_dims isinstance sym sympy Symbol sym index free_symbols True False set_ranges lengths list list sympy Expr - list list sympy Expr assert len kernel_sizes == len lengths make_flat_range sym numel length sym numel length zip symbols kernel_sizes lengths staticmethod make_flat_range sym sympy Symbol numel sympy Expr lengths list sympy Expr - list sympy Expr len lengths == numel == lengths sym divisor = sympy S One itervars = length reversed lengths V graph sizevars statically_known_equals divisor length numel expr = FloorDiv sym divisor expr = ModularIndexing sym divisor length itervars append expr divisor = divisor length reversed itervars dataclasses dataclass MemoryEstimate Tracks memory usage single loop generated kernel reads dict str OrderedSet MemoryDep = dataclasses field default_factory=functools partial collections defaultdict OrderedSet writes dict str OrderedSet MemoryDep = dataclasses field default_factory=functools partial collections defaultdict OrderedSet remove name str - None reads pop name None writes pop name None __bool__ - bool bool reads writes __repr__ - str f MemoryEstimate reads= itertools chain from_iterable reads values r writes= itertools chain from_iterable writes values r dataclasses dataclass StatsForDim Memory usage stats block dimension generated kernel different user dimensions number load store ops count_per_thread_contiguous int = count_per_thread_broadcast int = count_per_thread_non_contiguous int = excludes broadcast total bytes each load store op single element bytes_per_thread_contiguous int = bytes_per_thread_broadcast int = bytes_per_thread_non_contiguous int = excludes broadcast total bytes read entire kernel bytes_contiguous_or_broadcast sympy Expr = sympy S Zero bytes_non_contiguous sympy Expr = sympy S Zero __add__ other typing Self - StatsForDim StatsForDim count_per_thread_contiguous=self count_per_thread_contiguous + other count_per_thread_contiguous count_per_thread_broadcast=self count_per_thread_broadcast + other count_per_thread_broadcast count_per_thread_non_contiguous=self count_per_thread_non_contiguous + other count_per_thread_non_contiguous bytes_per_thread_contiguous=self bytes_per_thread_contiguous + other bytes_per_thread_contiguous bytes_per_thread_broadcast=self bytes_per_thread_broadcast + other bytes_per_thread_broadcast bytes_per_thread_non_contiguous=self bytes_per_thread_non_contiguous + other bytes_per_thread_non_contiguous bytes_contiguous_or_broadcast=self bytes_contiguous_or_broadcast + other bytes_contiguous_or_broadcast bytes_non_contiguous=self bytes_non_contiguous + other bytes_non_contiguous property count_per_thread - int count_per_thread_contiguous + count_per_thread_broadcast + count_per_thread_non_contiguous property bytes_per_thread - int bytes_per_thread_contiguous + bytes_per_thread_broadcast + bytes_per_thread_non_contiguous property bytes - sympy Expr bytes_contiguous_or_broadcast + bytes_non_contiguous property contiguous_score - float - count_per_thread_non_contiguous max count_per_thread dataclasses dataclass StatsForLoop Memory usage stats single loop generated kernel load store ops count_per_thread int = bytes_per_thread int = __add__ other typing Self - StatsForLoop StatsForLoop count_per_thread=self count_per_thread + other count_per_thread bytes_per_thread=self bytes_per_thread + other bytes_per_thread dataclasses dataclass StatsForReadsOrWrites Memory usage stats collected reads writes both dim list StatsForDim loop list StatsForLoop total bytes contiguous any dimension bytes_contiguous_or_broadcast sympy Expr = sympy S Zero bytes_non_contiguous sympy Expr = sympy S Zero __add__ other typing Self - StatsForReadsOrWrites assert len dim == len other dim assert len loop == len other loop StatsForReadsOrWrites dim= + b b zip dim other dim loop= + b b zip loop other loop bytes_contiguous_or_broadcast=self bytes_contiguous_or_broadcast + bytes_contiguous_or_broadcast bytes_non_contiguous=self bytes_non_contiguous + other bytes_non_contiguous property count_per_thread - int dim count_per_thread property bytes_per_thread - int dim bytes_per_thread property bytes - sympy Expr bytes_contiguous_or_broadcast + bytes_non_contiguous classmethod compute cls loop_deps list dict str OrderedSet MemoryDep index_symbols list sympy Symbol - typing Self ndim = len index_symbols result = cls dim = StatsForDim _ range ndim dep_group loop_deps result loop append loop_stats = StatsForLoop name deps dep_group items assert deps contiguous_or_broadcast = True ndim numel = sympy S Zero itemsize = V graph get_dtype name itemsize loop_stats count_per_thread += len deps loop_stats bytes_per_thread += itemsize len deps dep deps strides list sympy Expr = V graph sizevars stride_vars dep index index_symbols i range ndim V graph sizevars statically_known_equals strides i dim i count_per_thread_contiguous += dim i bytes_per_thread_contiguous += itemsize V graph sizevars statically_known_equals strides i dep is_indirect dim i count_per_thread_broadcast += dim i bytes_per_thread_broadcast += itemsize dim i count_per_thread_non_contiguous += dim i bytes_per_thread_non_contiguous += itemsize contiguous_or_broadcast i = False numel += dep get_numel len deps can t read more elements than exist buffer numel = sympy Min numel V graph get_numel name nbytes = numel itemsize i range ndim contiguous_or_broadcast i dim i bytes_contiguous_or_broadcast += nbytes dim i bytes_non_contiguous += nbytes any contiguous_or_broadcast result bytes_contiguous_or_broadcast += nbytes result bytes_non_contiguous += nbytes len result loop first loop represent outside loop compute which could long lived result loop = result loop + x x result loop result dataclasses dataclass StatsForKernelType Memory usage stats collected both persistent looped kernels reads StatsForReadsOrWrites writes StatsForReadsOrWrites memory StatsForReadsOrWrites classmethod compute cls loops list MemoryEstimate estimator MemoryEstimator - typing Self reads = StatsForReadsOrWrites compute loop reads loop loops estimator symbols writes = StatsForReadsOrWrites compute loop writes loop loops estimator symbols cls reads=reads writes=writes memory=reads + writes dataclasses dataclass MemoryStats Memory usage stats collected each generated kernel persistent StatsForKernelType looped StatsForKernelType get persistent bool - StatsForKernelType persistent persistent looped classmethod compute cls estimator MemoryEstimator - typing Self persistent = StatsForKernelType compute estimator persistent estimator len estimator loops == estimator outside_loop estimator loops looped = persistent loops persistent same common case looped = StatsForKernelType compute estimator outside_loop estimator loops estimator cls persistent=persistent looped=looped