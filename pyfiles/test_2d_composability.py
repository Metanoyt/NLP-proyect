Owner s oncall distributed copy functools io copy deepcopy typing Optional torch torch distributed dist torch distributed checkpoint dcp torch nn nn torch nn functional F torch distributed _composable replicate torch distributed checkpoint state_dict get_model_state_dict get_optimizer_state_dict set_model_state_dict set_optimizer_state_dict StateDictOptions torch distributed device_mesh DeviceMesh init_device_mesh torch distributed fsdp CPUOffloadPolicy fully_shard FullyShardedDataParallel FSDP torch distributed fsdp _common_utils _get_module_fsdp_state clean_tensor_name torch distributed fsdp fully_sharded_data_parallel StateDictType torch distributed tensor DTensor Replicate Shard torch distributed tensor debug CommDebugMode torch distributed tensor parallel ColwiseParallel parallelize_module RowwiseParallel torch distributed tensor parallel ddp _pre_dp_module_transform torch distributed tensor parallel fsdp DTensorExtensions torch distributed tensor parallel input_reshard input_reshard torch nn parallel DistributedDataParallel DDP torch testing _internal common_distributed skip_if_lt_x_gpu skip_if_rocm_arch_multiprocess torch testing _internal common_fsdp FSDPTest MLP MLPStack torch testing _internal common_utils instantiate_parametrized_tests MI _ARCH parametrize run_tests TEST_XPU xfailIf torch testing _internal distributed _tensor common_dtensor DTensorTestBase MLPModule ModelArgs Transformer with_comms torch testing _internal distributed checkpoint_utils with_temp_dir device_type = acc type acc = torch accelerator current_accelerator cpu SimpleModel nn Module __init__ super __init__ net = nn Linear relu = nn ReLU net = nn Linear net = nn Linear forward x x = F relu net x x = F relu net x x = F relu net x x get_input torch rand device=device_type SimpleModelUneven nn Module __init__ super __init__ torch manual_seed net = nn Linear relu = nn ReLU net = nn Linear net = nn Linear net = nn Linear forward x x = F relu net x x = F relu net x x = F relu net x x = net x x get_input torch rand device=device_type TestFullyShard DTraining FSDPTest global c d_ops global funcol c d_ops = torch ops c d funcol = torch ops c d_functional property world_size - int min torch accelerator device_count init_global_mesh - DeviceMesh Prefer test = GPUs GPUs use -way TP dp_size = world_size init_device_mesh device_type dp_size world_size dp_size mesh_dim_names= dp tp skip_if_rocm_arch_multiprocess MI _ARCH skip_if_lt_x_gpu test_train_parity_ d_mlp global_mesh = init_global_mesh run_subtests reshard_after_forward False True use_activation_checkpointing False True mlp_dim functools partial _test_train_parity_ d_mlp global_mesh _test_train_parity_ d_mlp global_mesh DeviceMesh reshard_after_forward bool use_activation_checkpointing bool mlp_dim int dp_mesh tp_mesh = global_mesh dp global_mesh tp dp_pg = dp_mesh get_group used ` replicate ` torch manual_seed model = MLPStack mlp_dim ref_model = copy deepcopy model device_type replicate ref_model device_ids= rank process_group=dp_pg ref_optim = torch optim Adam ref_model parameters lr= e- foreach=False model parallelize tp_mesh dp_mesh use_activation_checkpointing reshard_after_forward=reshard_after_forward optim = torch optim Adam model parameters lr= e- foreach=False torch manual_seed + dp_pg rank + iter_idx range inp = torch randn mlp_dim device=device_type losses list torch Tensor = _model _optim ref_model ref_optim model optim _optim zero_grad set_to_none= iter_idx == losses append _model inp sum losses - backward _optim step assertEqual losses losses skip_if_lt_x_gpu xfailIf TEST_XPU https github com intel torch-xpu-ops issues test_train_parity_ d_transformer run_subtests use_shard_placement_fn False True _test_train_parity_ d_transformer _test_train_parity_ d_transformer use_shard_placement_fn bool torch manual_seed model_args = ModelArgs n_layers= dropout_p= model = Transformer model_args ref_model = copy deepcopy model device_type ref_optim = torch optim AdamW ref_model parameters lr= e- dp_size tp_size = world_size global_mesh = init_device_mesh device_type dp_size tp_size mesh_dim_names= dp tp model = Transformer parallelize model global_mesh tp use_seq_parallel=True _shard_placement_fn param nn Parameter - Optional Shard isinstance param DTensor placement param placements isinstance placement Shard shard_dim = param ndim - - placement dim assert shard_dim = f param shape Shard shard_dim Shard shard_placement_fn = _shard_placement_fn use_shard_placement_fn None layer model layers fully_shard layer mesh=global_mesh dp shard_placement_fn=shard_placement_fn fully_shard model mesh=global_mesh dp shard_placement_fn=shard_placement_fn optim = torch optim AdamW model parameters lr= e- param ref_param zip model parameters ref_model parameters full_param = param full_tensor assertEqual full_param ref_param torch manual_seed + global_mesh get_local_rank dp inp = torch randint model_args vocab_size device=device_type _ range ref_loss = ref_model inp sum loss = model inp sum assertEqual ref_loss loss ref_loss backward loss backward param ref_model parameters param grad None dist all_reduce param grad group=global_mesh get_group dp op=dist ReduceOp AVG Specially check TP placement ` pos_embeddings weight ` its which since grad naturally has replicate placement requiring FSDP redistribute shard placement before FSDP runs its reduce-scatter assertIsInstance model pos_embeddings weight placements Shard assertIsInstance model pos_embeddings weight grad placements Shard ref_param param zip ref_model parameters model parameters full_grad = param grad full_tensor assertEqual ref_param grad full_grad ref_optim step optim step ref_optim zero_grad optim zero_grad param ref_param zip model parameters ref_model parameters full_param = param full_tensor assertEqual full_param ref_param skip_if_lt_x_gpu xfailIf TEST_XPU https github com pytorch pytorch issues test_tp_with_fsdp_offloading global_mesh = init_device_mesh device_type world_size mesh_dim_names= dp tp dp_mesh tp_mesh = global_mesh dp global_mesh tp torch manual_seed mlp_dim = model = MLPStack mlp_dim ref_model = copy deepcopy model device_type ref_optim = torch optim Adam ref_model parameters lr= e- foreach=False Parallelize N-way TP -way FSDP model parallelize tp_mesh dp_mesh use_activation_checkpointing=False reshard_after_forward=True offload_policy=CPUOffloadPolicy param model parameters assertEqual param device type cpu num_mlps = sum isinstance module MLP module model modules optim = torch optim Adam model parameters lr= e- foreach=False NOTE We still see FSDP all-gather reduce-scatter c d ops called they will just no-ops without issuing any kernels We prefer keep no-op check c d level FSDP inp = torch randn mlp_dim device=device_type same all ranks _ range ref_optim zero_grad optim zero_grad CommDebugMode fwd_comm_mode loss = model inp sum fwd_comm_counts = fwd_comm_mode get_comm_counts assertEqual len fwd_comm_counts assertEqual fwd_comm_counts funcol all_reduce num_mlps assertEqual fwd_comm_counts c d_ops _allgather_base_ ref_loss = ref_model inp sum assertEqual loss ref_loss CommDebugMode bwd_comm_mode loss backward bwd_comm_counts = bwd_comm_mode get_comm_counts assertEqual len bwd_comm_counts First MLP s input gradient does need all-reduced assertEqual bwd_comm_counts funcol all_reduce num_mlps - assertEqual bwd_comm_counts c d_ops _allgather_base_ assertEqual bwd_comm_counts c d_ops _reduce_scatter_base_ ref_loss backward optim step ref_optim step skip_if_lt_x_gpu xfailIf TEST_XPU https github com intel torch-xpu-ops issues with_temp_dir test_train_parity_ d_transformer_checkpoint_resume Tests train parity D transformer without checkpointing against D transformer checkpoint save load run_subtests use_seq_parallel False True If reusing then load into same model optimizer instance construct new ones requiring eager optim state init reuse_model_optim False True optimizer_class torch optim Adam torch optim AdamW TODO need update ` parallelize ` before including foreach=True testing foreach False _test_train_parity_ d_transformer_checkpoint_resume _test_train_parity_ d_transformer_checkpoint_resume use_seq_parallel bool reuse_model_optim bool optimizer_class type torch optim Optimizer foreach bool train_step _model nn Module _optim torch optim Optimizer _inp torch Tensor - torch Tensor loss = _model _inp sum loss backward _optim step _optim zero_grad loss parallelize _model Transformer mesh DeviceMesh use_seq_parallel bool _model = Transformer parallelize _model mesh tp use_seq_parallel layer _model layers fully_shard layer mesh=mesh dp fully_shard _model mesh=mesh dp _model global_mesh = init_global_mesh Baseline run two iterations without checkpointing seed = torch manual_seed seed model_args = ModelArgs dropout_p= model_no_cp = parallelize Transformer model_args global_mesh use_seq_parallel optim_no_cp = optimizer_class model_no_cp parameters lr= e- foreach=foreach torch manual_seed + global_mesh dp get_local_rank + inp = torch randint model_args vocab_size device=device_type loss_no_cp = train_step model_no_cp optim_no_cp inp loss_no_cp = train_step model_no_cp optim_no_cp inp Test run one iteration save checkpoint zero states init new model optimizer load checkpoint run another iteration torch manual_seed seed model_cp = parallelize Transformer model_args global_mesh use_seq_parallel optim_cp = optimizer_class model_cp parameters lr= e- foreach=foreach loss_cp = train_step model_cp optim_cp inp assertEqual loss_no_cp loss_cp sharded_sd = model get_model_state_dict model_cp Use ` get_optimizer_state_dict ` handle eager optim state init when constructing new optimizer instance optim get_optimizer_state_dict model_cp optim_cp dcp save state_dict=sharded_sd storage_writer=dcp FileSystemWriter temp_dir reuse_model_optim torch no_grad param model_cp parameters param zero_ optim_sd = optim_cp state_dict param_states optim_sd state values state_value param_states values torch is_tensor state_value state_value zero_ torch manual_seed seed + different seed model_cp = parallelize Transformer model_args global_mesh use_seq_parallel optim_cp = optimizer_class model_cp parameters lr= e- foreach=foreach assertNotEqual loss_no_cp train_step model_cp optim_cp inp sharded_sd = model get_model_state_dict model_cp optim get_optimizer_state_dict model_cp optim_cp dcp load state_dict=sharded_sd storage_reader=dcp FileSystemReader temp_dir assertGreater len optim_cp state_dict state loss_cp = train_step model_cp optim_cp inp assertEqual loss_no_cp loss_cp TestFullyShard DStateDict DTensorTestBase property backend need specify gloo backend testing cpu offload cpu gloo xpu xccl TEST_XPU cpu gloo cuda nccl with_comms skip_if_lt_x_gpu test_fully_shard_tp_ d_set_full_state_dict dummy_model = SimpleModel device_type mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp parallelize_plan = net ColwiseParallel net RowwiseParallel net ColwiseParallel model = parallelize_module dummy_model tp_mesh parallelize_plan fully_shard model mesh=dp_mesh optim = torch optim Adam model parameters lr= model model get_input sum backward optim step ref_msd ref_osd both default sharded state dict ref_msd = copy deepcopy get_model_state_dict model ref_osd = copy deepcopy get_optimizer_state_dict model optimizers=optim options = StateDictOptions full_state_dict=True cpu_offload=True broadcast_from_rank =True full_msd = get_model_state_dict model options=options full_osd = get_optimizer_state_dict model optimizers=optim options=options load full_msd full_osd into model optim loads slice full tensor into each rank s local DTensor set_model_state_dict model full_msd options=options set_optimizer_state_dict model optimizers=optim optim_state_dict=full_osd options=options check after setting full state dict model optim default sharded state dict same initial default sharded state dict new_msd = get_model_state_dict model new_osd = get_optimizer_state_dict model optimizers=optim assertEqual ref_msd new_msd assertEqual ref_osd new_osd Test dFSDP ParallelIntegration DTensorTestBase init_model device_type model_parallel_size= torch manual_seed model = MLPModule device_type torch manual_seed twod_model = MLPModule device_type model = DDP model -D mesh dp tp world_size = dist get_world_size mesh_ d = init_device_mesh device_type world_size model_parallel_size model_parallel_size mesh_dim_names= dp tp dp_pg = mesh_ d get_group mesh_dim= parallelize_plan = net ColwiseParallel net RowwiseParallel twod_model = parallelize_module twod_model mesh_ d tp parallelize_plan _pre_dp_module_transform twod_model TODO Add tests when using gradient_as_bucket_view static_graph DDP twod_model = DDP twod_model process_group=dp_pg model twod_model dp_pg _check_module m m check_grad=False named_parameters = dict m named_parameters name param_m m named_parameters name named_parameters print name named_parameters keys assertTrue name named_parameters param_m = named_parameters name check_grad param_m = param_m grad param_m = param_m grad isinstance param_m DTensor replicate = Replicate param_m = param_m redistribute device_mesh=param_m device_mesh placements=replicate to_local assertEqual param_m param_m with_comms skip_if_lt_x_gpu test_ d_ddp_integration_functionality - None model twod_model dp_pg = init_model device_type optim = torch optim Adam model parameters lr= e- twod_optim = torch optim Adam twod_model parameters lr= e- Create Input input_seed = dist get_rank dp_pg torch manual_seed input_seed + input = torch rand device=self device_type output = model input twod_output = twod_model input assertEqual output twod_output output sum backward twod_output sum backward _check_module model twod_model check_grad=True optim step twod_optim step _check_module model twod_model torch manual_seed input_seed + input = torch rand device=self device_type output = model input twod_output = twod_model input assertEqual output twod_output TODO Add save load D verification TODO add additional tests multi_param_group optim_in_backward fsdp_nested TestNew dParallelTraining DTensorTestBase _compare_params m m FSDP summon_full_params m FSDP summon_full_params m n_p n_p zip m named_parameters m named_parameters p = n_p p = n_p n_p = n_p assertTrue n_p n_p name = n_p name == net bias rank = continue type p DTensor p = p redistribute p device_mesh Replicate to_local assertTrue torch allclose p p f p vs p with_comms skip_if_lt_x_gpu test_ d_fsdp_state_enable_extension mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp model = FSDP SimpleModel device_type device_mesh=mesh_ d dp fsdp_state = _get_module_fsdp_state model assertTrue isinstance fsdp_state _fsdp_extension DTensorExtensions _test_ d_e e_training use_orig_params=False recompute_activation=False - None torch manual_seed model = SimpleModel f device_type rank model = FSDP model use_orig_params=use_orig_params optim = torch optim Adam model parameters lr= torch manual_seed mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp parallelize_plan = net ColwiseParallel net RowwiseParallel model_ d = parallelize_module SimpleModel device_type tp_mesh parallelize_plan model_ d = FSDP model_ d device_mesh=dp_mesh use_orig_params=use_orig_params optim_ d = torch optim Adam model_ d parameters lr= recompute_activation model_ d = input_reshard model_ d mesh_ d tp Check named parameters returning same name least param_names_ d = clean_tensor_name name name _ model_ d named_parameters name _ model named_parameters name = clean_tensor_name name name param_names_ d print name param_names_ d assertTrue name param_names_ d _compare_params model model_ d TODO add additional tests multi_param_group optim_in_backward i range Ensure all input across TP ranks same TODO add get_group_rank DeviceMesh torch manual_seed i + dist get_rank dp_mesh get_group mesh_dim= input = torch rand f device_type rank output = model input output_ d = model_ d input assertEqual output output_ d output sum backward output_ d sum backward optim step optim_ d step assertEqual model input model_ d input Ensure all params still same after optimizer update _compare_params model model_ d with_comms skip_if_lt_x_gpu test_ d_e e_training_default _test_ d_e e_training with_comms skip_if_lt_x_gpu test_ d_e e_training_use_orig_params _test_ d_e e_training use_orig_params=True with_comms skip_if_lt_x_gpu test_ d_e e_training_not_use_orig_params TODO need revisit input_reshard API about why failed multi-gpu tests _test_ d_e e_training recompute_activation=True _test_ d_e e_training recompute_activation=False TODO update all state dict unit tests use distributed checkpoint state_dict consolidate all state_dict test test distributed checkpoint TestNew dParallelStateDict DTensorTestBase property backend need specify gloo backend testing cpu offload cpu gloo xpu xccl TEST_XPU cpu gloo cuda nccl with_comms skip_if_lt_x_gpu test_fsdp_ d_extension Test whether _fsdp_extension FSDPstate has been set correctly mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp parallelize_plan = net ColwiseParallel net RowwiseParallel net ColwiseParallel model_ d = parallelize_module SimpleModel device_type mesh_ d tp parallelize_plan=parallelize_plan model_ d = FSDP model_ d device_mesh=mesh_ d dp use_orig_params=True model_ d_fsdp_state = _get_module_fsdp_state model_ d assertTrue isinstance model_ d_fsdp_state _fsdp_extension DTensorExtensions mesh_ d = init_device_mesh device_type world_size model_ d = FSDP SimpleModel device_type device_mesh=mesh_ d use_orig_params=True model_ d_fsdp_state = _get_module_fsdp_state model_ d assertEqual model_ d_fsdp_state _fsdp_extension None with_comms skip_if_lt_x_gpu parametrize is_even_sharded_model True False test_ d_state_dict is_even_sharded_model simple_model = SimpleModel is_even_sharded_model SimpleModelUneven Create model without wrapper torch manual_seed no_wrap_model = simple_model f device_type rank no_wrap_state_dict = no_wrap_model state_dict Create model sharded D FSDP + TP torch manual_seed mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp parallelize_plan = net ColwiseParallel net RowwiseParallel model_ d = parallelize_module simple_model device_type tp_mesh parallelize_plan model_ d = FSDP model_ d device_mesh=dp_mesh use_orig_params=True FSDP set_state_dict_type model_ d StateDictType SHARDED_STATE_DICT state_dict_ d = model_ d state_dict no_wrap_items two_d_items zip no_wrap_state_dict items state_dict_ d items no_wrap_k no_wrap_v = no_wrap_items two_d_k two_d_v = two_d_items assertEqual no_wrap_k two_d_k check all value D state_dict DTensor assertTrue isinstance two_d_v DTensor assertEqual len two_d_v placements outer dimension FSDP dimension placement always Shard assertEqual two_d_v placements Shard assertEqual two_d_v device_mesh mesh_ d check parameter value same between D model model without wrapper all_gather_two_d_v = two_d_v redistribute mesh_ d Replicate Replicate assertEqual torch allclose no_wrap_v all_gather_two_d_v to_local True with_comms skip_if_lt_x_gpu parametrize is_even_sharded_model True False test_ d_load_state_dict is_even_sharded_model simple_model = SimpleModel is_even_sharded_model SimpleModelUneven torch manual_seed mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp parallelize_plan = net ColwiseParallel net RowwiseParallel model_ d = parallelize_module simple_model device_type tp_mesh parallelize_plan model_ d = FSDP model_ d device_mesh=dp_mesh use_orig_params=True optim_ d = torch optim Adam model_ d parameters lr= FSDP set_state_dict_type model_ d StateDictType SHARDED_STATE_DICT checkpoint = io BytesIO torch save model_ d state_dict checkpoint Deepcopy save current state_dict compare state_dict loaded back below ref_state_dict = deepcopy model_ d state_dict Update parameters so model state_dict will different ref_dtensor_sd model_ d model_ d get_input f device_type rank sum backward optim_ d step Load ref_state_dict back checkpoint seek load_ref_state_dict = torch load checkpoint model_ d load_state_dict load_ref_state_dict new_state_dict = model_ d state_dict Check whether new_state_dict same ref_state_dict k v k v zip ref_state_dict items new_state_dict items check whether fqn same assertEqual k k assertEqual type v DTensor assertEqual type v DTensor check whether DTensor same TODO D DTensor comparison supported time so we comparing spec local tensor now TODO Update compare two DTensors once D DTensor comparison supported assertEqual v to_local v to_local assertEqual v device_mesh v device_mesh assertEqual v placements v placements with_comms skip_if_lt_x_gpu parametrize is_even_sharded_model True False test_ d_optim_state_dict is_even_sharded_model simple_model = SimpleModel is_even_sharded_model SimpleModelUneven Create model without wrapper torch manual_seed no_wrap_model = simple_model f device_type rank no_wrap_optim = torch optim Adam no_wrap_model parameters lr= no_wrap_model no_wrap_model get_input f device_type rank sum backward no_wrap_optim step no_wrap_osd = get_optimizer_state_dict no_wrap_model optimizers=no_wrap_optim Create model sharded D FSDP + TP torch manual_seed mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp parallelize_plan = net ColwiseParallel net RowwiseParallel model_ d = parallelize_module simple_model device_type mesh_ d tp parallelize_plan model_ d = FSDP model_ d device_mesh=mesh_ d dp use_orig_params=True FSDP set_state_dict_type model_ d StateDictType SHARDED_STATE_DICT optim_ d = torch optim Adam model_ d parameters lr= model_ d model_ d get_input f device_type rank sum backward optim_ d step optim_ d_osd = get_optimizer_state_dict model_ d optimizers=optim_ d ref_optim_ d_osd = deepcopy optim_ d_osd no_wrap_osd_states = no_wrap_osd state optim_ d_osd_states = optim_ d_osd state assertEqual len no_wrap_osd_states len optim_ d_osd_states assertEqual no_wrap_osd_states keys optim_ d_osd_states keys fqn states no_wrap_osd_states items dist_states = optim_ d_osd_states get fqn state_name state states items dist_state = dist_states get state_name If state DTensor we all gather both DP TP dimension compare no_wrap state isinstance dist_state DTensor dist_state = dist_state device_type redistribute placements= Replicate Replicate to_local assertTrue isinstance dist_state torch Tensor assertTrue torch allclose state dist_state Update parameters d optim states will different ref_optim_state_dict model_ d model_ d get_input f device_type rank sum backward optim_ d step set_optimizer_state_dict model_ d optimizers=optim_ d optim_state_dict=ref_optim_ d_osd ref_optim_ d_osd_states = ref_optim_ d_osd state new_optim_ d_osd_states = optim_ d_osd state Compare new optim state dict after load reference one assertEqual len ref_optim_ d_osd_states len new_optim_ d_osd_states assertEqual ref_optim_ d_osd_states keys new_optim_ d_osd_states keys fqn states ref_optim_ d_osd_states items new_states = new_optim_ d_osd_states get fqn state_name state states items new_state = new_states get state_name isinstance new_state DTensor assertEqual new_state placements state placements assertEqual new_state device_mesh state device_mesh assertTrue torch allclose new_state to_local state to_local assertEqual new_state state with_comms with_temp_dir skip_if_lt_x_gpu test_fsdp _tp_ d_set_full_state_dict This workaround loading full state dict into FSDP +TP D model Since named_parameters FSDP does DTensor we don t have information shard full_state_dict load directly into d model In order load full state dict FSDP +TP D model we need do load full state dict into D FSDP model dcp save full shard state dict into storage initialize D FSDP +TP model get default sharded state dict D model full_state_dict=False dcp load state dict storage load state dict into D model dummy_model = SimpleModel device_type mesh_ d = init_device_mesh device_type world_size model = FSDP dummy_model device_mesh=mesh_ d optim = torch optim Adam model parameters lr= model model get_input sum backward optim step ref_full_msd = get_model_state_dict model options=StateDictOptions full_state_dict=True cpu_offload=True ref_full_osd = get_optimizer_state_dict model optimizers=optim options=StateDictOptions full_state_dict=True cpu_offload=True state_dict = model ref_full_msd optim ref_full_osd save full state dict into storage first dcp save state_dict checkpoint_id=self temp_dir initialize d model dummy_model = SimpleModel device_type mesh_ d = init_device_mesh device_type world_size mesh_dim_names= dp tp tp_mesh = mesh_ d tp dp_mesh = mesh_ d dp parallelize_plan = net ColwiseParallel net RowwiseParallel net ColwiseParallel model_ d = parallelize_module dummy_model tp_mesh parallelize_plan model_ d = FSDP model_ d device_mesh=dp_mesh use_orig_params=True optim_ d = torch optim Adam model_ d parameters lr= get default sharded state dict model_ d note because we can set full_state_dict back D directly msd = get_model_state_dict model_ d osd = get_optimizer_state_dict model_ d optimizers=optim_ d state_dict = model msd optim osd dcp load state_dict=state_dict checkpoint_id=self temp_dir set_model_state_dict model_ d state_dict model set_optimizer_state_dict model_ d optimizers=optim_ d optim_state_dict=state_dict optim check after setting sharded state dict model optim full state dict same initial full state dict new_full_msd = get_model_state_dict model options=StateDictOptions full_state_dict=True cpu_offload=True new_full_osd = get_optimizer_state_dict model optimizers=optim options=StateDictOptions full_state_dict=True cpu_offload=True assertEqual ref_full_msd new_full_msd assertEqual ref_full_osd new_full_osd instantiate_parametrized_tests TestNew dParallelStateDict __name__ == __main__ run_tests