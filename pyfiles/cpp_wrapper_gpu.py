mypy allow-untyped-defs __future__ annotations dataclasses re sys itertools count zip_longest typing Any Optional Union typing_extensions Self sympy torch torch dtype torch_dtype torch _inductor codecache get_cpp_wrapper_cubin_path_name torch _inductor runtime runtime_utils dynamo_timed config codecache CudaKernelParamCache ir GraphPartitionSignature TensorBox TMADescriptorExperimental TMADescriptorStable utils cache_on_self get_gpu_type GPU_ALIGN_BYTES IndentedBuffer virtualized V aoti_hipify_utils maybe_hipify_code_wrapper common get_device_op_overrides TritonScratchWorkspace cpp_utils cexpr cpp_wrapper_cpu CppWrapperCpu multi_kernel MultiKernelCall triton_utils should_unwrap_unspec_arg wrapper PythonWrapperCodegen SymbolicCallArg _cpp_string_literal_escapes = \\ \\\\ \\ \n \\n \t \\t \r \\r _cpp_string_literal_pattern = re compile r \\\n\t\r cpp_string_literal s str - str escaped = _cpp_string_literal_pattern sub lambda match _cpp_string_literal_escapes match group s f escaped dataclasses dataclass DeferredTritonCallWrapper When using cpp wrapper GPU kernel load launch needs wait Triton kernels tuned stored cubin files so use deferred generating final wrapper around triton kernel until right before prefix written wrapper_name str kernel_name str kernel_name_to_body dict str str arg_types list Any generate wrapper CppWrapperGpu Generate GPU kernel definition well load launch code prefix = wrapper prefix kernel_name startswith multi_kernel_ MultiKernel will select one kernel after running autotune block kernel_name = MultiKernelCall lookup_choice kernel_name params = CudaKernelParamCache get kernel_name assert params f CudaKernelParamCache populated kernel_name def_args = params def_args arg_types = arg_types inductor_meta = params inductor_meta extra_launcher_args inductor_meta len def_args len arg_types extra_launcher_args should already def_args assert len def_args == len arg_types - len inductor_meta extra_launcher_args arg_types = arg_types + SymbolicCallArg len inductor_meta extra_launcher_args V graph aot_mode prefix writeline maybe_hipify_code_wrapper f static wrapper device_codegen cpp_kernel_type kernel_name = nullptr kernel_var_name = kernel_name kernel_var_name = f kernels_ kernel_name tensors can RAIIAtenTensorHandle ConstantHandle so make them template types template_types = f typename name _type_ name arg_type zip def_args arg_types isinstance arg_type torch_dtype UnwrapUnspecArg V graph aot_mode template_types append typename kernels_type_ template_types prefix writeline f template join template_types prefix writeline f static inline void wrapper_name prefix indent assert len def_args == len arg_types def_args arg_types name arg_type zip def_args arg_types isinstance arg_type torch_dtype UnwrapUnspecArg prefix writeline f const name _type_ name issubclass arg_type SymbolicCallArg sympy Expr int prefix writeline f int _t name arg_type float prefix writeline f float name arg_type bool prefix writeline f bool name raise ValueError f Unexpected arg type arg_type prefix writeline int _t device_idx_ prefix writeline maybe_hipify_code_wrapper f wrapper device_codegen cpp_stream_type stream_ V graph aot_mode prefix writeline kernels_type_ kernels_ prefix writeline const std optional std string cubin_dir_ = std nullopt prefix writeline prefix indent V graph aot_mode Emit original Triton kernel debugging purposes prefix writeline prefix splice kernel_name_to_body kernel_name prefix writeline generate_grid prefix inductor_meta params generate_load_kernel prefix kernel_var_name params generate_launch_kernel prefix wrapper kernel_var_name params prefix writeline config aot_inductor embed_kernel_binary Ensure cubin file included package V graph wrapper_code additional_files append params get_cpp_wrapper_cubin_path_name generate_grid prefix IndentedBuffer inductor_meta dict str Any params dict str Any runtime triton_heuristics GridExpr grid = GridExpr from_meta inductor_meta params config mode= cpp line grid prefix prefix writeline line prefix splice f \ uint _t grid_ = grid x_grid uint _t grid_ = grid y_grid uint _t grid_ = grid z_grid prefix writeline grid_ == &#124; &#124; grid_ == &#124; &#124; grid_ == generate_load_kernel prefix kernel_var_name params prefix writeline f kernel_var_name == nullptr prefix indent embed_kernel_args = f __ params inductor_meta kernel_name _start torch xpu is_available XPU needs end address kernel calculate size kernel binary embed_kernel_args append f __ params inductor_meta kernel_name _end load_kernel_args = embed_kernel_args cpp_string_literal params mangled_name str params shared_mem V graph aot_mode config aot_inductor embed_kernel_binary cpp_string_literal params get_cpp_wrapper_cubin_path_name cpp_string_literal params mangled_name str params shared_mem cubin_dir_ prefix writeline f kernel_var_name = loadKernel join load_kernel_args prefix writeline generate_launch_kernel prefix wrapper kernel_var_name params Generate GPU kernel launching code This where all call args being sorted out generated If enable_kernel_profile enabled all args related information would packed function triton_meta = params triton_meta assert len arg_types == len params def_args arg_types params def_args arg_type_loookup = dict zip params def_args arg_types difference between Python C++ wrapper C++ wrapper strips out equal_to_ constants call_args = name name params call_args name triton_meta constants arg_types = arg_type_loookup name name call_args arg_signatures = triton_meta signature name name call_args scratch_spaces = name params name name global_scratch profile_scratch params get name None None call_args_str = wrapper generate_args_decl prefix call_args arg_types arg_signatures scratch_spaces=scratch_spaces prefix writeline f void kernel_args_ = call_args_str launch_kernel_args = kernel_var_name grid_ grid_ grid_ str params num_warps str params shared_mem kernel_args_ stream_ wrapper device == xpu launch_kernel_args append str params threads_per_warp enable_kernel_profile = config cpp enable_kernel_profile sys platform linux win enable_kernel_profile normalized_kernel_name = re sub r ^a-zA-Z - _ _ f kernel_var_name prefix writeline prefix indent prefix writelines f std unordered_map std string C IValueHandle kwargs_ normalized_kernel_name Add launch args info record_launch_kernel_args = grid_ grid_ grid_ grid_ grid_ grid_ num_warps str params num_warps shared_mem str params shared_mem k v record_launch_kernel_args arg_name = f normalized_kernel_name _ k prefix writelines f Create c IValue k f C IValueHandle tmp_ arg_name f aoti_torch_int _to_ivalue v tmp_ arg_name f RAIIC IValueHandle RAII_ arg_name tmp_ arg_name f kwargs_ normalized_kernel_name emplace k RAII_ arg_name Add input info This copies logic args_decl signature dtype = i int _t i int _t fp float signature_is_tma_desc sig sig False sig == nvTmaDesc True sig startswith tensordesc True False curr_arg_id = - total_args = ordered_argsname = write_dummy_scalar_ivalue arg_name We only care about shape therefore we create dummy scalar here prefix writelines f Create c IValue arg_ curr_arg_id f C IValueHandle tmp_ arg_name f aoti_torch_int _to_ivalue tmp_ arg_name f RAIIC IValueHandle RAII_ arg_name tmp_ arg_name pyrefly ignore bad-argument-type total_args append f tmp_ arg_name process_args_for_input_shape arg arg_type arg_signature=None nonlocal curr_arg_id curr_arg_id += arg_name = f normalized_kernel_name _arg_ curr_arg_id ignore tma descriptors host-side TMA descriptors need passed compiled Triton kernel value isinstance arg_type UnwrapUnspecArg signature_is_tma_desc arg_signature write_dummy_scalar_ivalue arg_name isinstance arg_type torch_dtype signature_is_tma_desc arg_signature This Tensor prefix writelines f Create c IValue arg_ curr_arg_id f C IValueHandle tmp_ arg_name f aoti_torch_tensor_to_ivalue arg tmp_ arg_name f RAIIC IValueHandle RAII_ arg_name tmp_ arg_name pyrefly ignore bad-argument-type total_args append f tmp_ arg_name isinstance arg_type type SymbolicCallArg arg_signature None arg_signature signature dtype keys arg_type sympy Integer int sympy Float float write_dummy_scalar_ivalue arg_name arg_signature arg_signature startswith tensordesc Skip tma related args pass write_dummy_scalar_ivalue arg_name Add input name shape information arg arg_type arg_signature zip_longest call_args arg_types arg_signatures pyrefly ignore bad-argument-type ordered_argsname append f arg process_args_for_input_shape arg arg_type arg_signature Add input name into kwargs name_var = f normalized_kernel_name _input_names prefix writelines Create c IValue input names f C IValueHandle tmp_ name_var f std vector const char name_var join ordered_argsname f aoti_torch_strlist_to_ivalue name_var data len ordered_argsname tmp_ name_var f RAIIC IValueHandle RAII_ name_var tmp_ name_var f kwargs_ normalized_kernel_name emplace Input Args RAII_ name_var inputs_info_ = f normalized_kernel_name _inputs_info_ We pass non-RAII handles since C doesn t automatically free them The RAII will make sure they get freed when they out scope tmp_args = join total_args prefix writelines Aggregate all c IValue inputs f std vector C IValueHandle inputs_info_ tmp_args Start recording Function prefix writelines torch aot_inductor RAIIAtenRecordFunctionHandle f record_ normalized_kernel_name _ f kernel_var_name f reinterpret_cast IValueMapHandle kwargs_ normalized_kernel_name f inputs_info_ f launchKernel join launch_kernel_args prefix writeline prefix writeline f launchKernel join launch_kernel_args CppWrapperGpu CppWrapperCpu Generates cpp wrapper running GPU calls CUDA kernels __init__ - None device = get_gpu_type device_codegen = get_device_op_overrides device super __init__ grid_id = count _kernel_name_to_body dict str str = _triton_call_wrappers dict str DeferredTritonCallWrapper = autotune_input_prefix = _REAL_AUTOTUNE_INPUT staticmethod create is_subgraph bool subgraph_name Optional str parent_wrapper Optional PythonWrapperCodegen partition_signatures Optional GraphPartitionSignature = None TODO - support subgraph codegen lifting functions Check comment CppWrapperCpu ` codegen_subgraph ` function CppWrapperGpu write_header V graph is_const_graph We do write header constant graph will written main module super write_header header splice maybe_hipify_code_wrapper device_codegen kernel_driver cache_on_self write_tma_descriptor_helpers_once header splice device_codegen tma_descriptor_helpers write_get_raw_stream device_idx int graph_name str - str name = f stream device_idx writeline maybe_hipify_code_wrapper f device_codegen cpp_stream_type name writeline f AOTI_TORCH_ERROR_CODE_CHECK device_codegen aoti_get_stream device_idx void name name get_autotuning_input_name idx f autotune_input_prefix _ idx codegen_inputs See Note Input Alignment handling Inductor JIT Inductor does guard input alignment It relies copy_misaligned_inputs copy misaligned inputs aligned buffers For AOTInductor we need do same cpp config is_fbcode TODO This added because FC Remove once newly added shim symbols e g aoti_torch_clone_preserve_strides have landed super codegen_inputs V graph aot_mode V graph inputs_to_check idx V graph inputs_to_check input_name = V graph graph_input_names idx assert input_name V graph graph_inputs f input_name found graph inputs value = V graph graph_inputs input_name assert isinstance value TensorBox f input_name expected tensor found type value warn_msg = f Input idx compiled GPU_ALIGN_BYTES -bytes aligned aligned run time Copying aligned tensor guarantee correctness expect performance hit prefix splice f reinterpret_cast std uintptr_t input_name data_ptr GPU_ALIGN_BYTES - = AOTI_TORCH_WARN warn_msg AtenTensorHandle input_name _aligned aoti_torch_clone_preserve_strides input_name input_name _aligned input_name = std move RAIIAtenTensorHandle input_name _aligned super codegen_inputs _define_kernel_helper kernel_name str kernel_body str metadata Optional str = None gpu bool = True cpp_definition Optional str = None gpu _kernel_name_to_body kernel_name = kernel_body config triton autotune_at_compile_time Call PythonWrapperCodegen create autotune code block PythonWrapperCodegen _define_kernel_helper kernel_name kernel_body metadata gpu cpp_definition CppWrapperCpu _define_kernel_helper kernel_name kernel_body metadata gpu cpp_definition generate is_inference dynamo_timed CppWrapperGpu generate log_pt _compile_event=True super generate is_inference finalize_prefix Define triton kernels now autotuning finished old_prefix = prefix new content should go start prefix Generating triton kernel callers can modify prefix cached dtypes so do before running finalize_prefix put generated code after finalize_prefix code prefix = IndentedBuffer kernel _triton_call_wrappers values prefix writeline \n kernel generate triton_prefix = prefix prefix = IndentedBuffer super finalize_prefix prefix splice triton_prefix prefix writeline \n prefix splice old_prefix generate_tma_descriptor desc write_tma_descriptor_helpers_once isinstance desc TMADescriptorExperimental _generate_experimental_tma_descriptor desc assert isinstance desc TMADescriptorStable _generate_stable_tma_descriptor desc _generate_experimental_tma_descriptor desc generate data pointer source tensor source = generate_args_decl code=self call_args= val_to_arg_str desc tensor arg_types= desc tensor get_dtype arg_signatures= None these args passed initNDTMADescriptor which NOT triton kernel is_triton_kernel=False desc_name = desc name writeline f alignas CUtensorMap desc_name ` source ` form ` var_x ` where ` var_x ` data pointer CUdeviceptr we dereference ` source ` cast ` void ` pass data pointer source tensor helper function ` init DTMADescriptor ` ptr = f reinterpret_cast void source dims = join val_to_arg_str dim dim desc dims block_dims = join val_to_arg_str dim dim desc block_dims element_size = val_to_arg_str desc element_size fn = f init desc rank DTMADescriptor args = f desc_name ptr dims block_dims element_size writeline f fn args _generate_stable_tma_descriptor desc source = generate_args_decl code=self call_args= val_to_arg_str desc tensor arg_types= desc tensor get_dtype arg_signatures= None these args passed initNDTMADescriptor which NOT triton kernel is_triton_kernel=False desc_name = desc name Pack relevant information into StableTMADescriptor struct See Note AOTI TMA Stable handling more details writeline f alignas StableTMADescriptor desc_name fill_array name values i val enumerate values writeline f name i = val ptr = f reinterpret_cast void source rank = len desc tensor get_size fill_array f desc_name block_shape desc block_shape fill_array f desc_name global_shape desc tensor get_size fill_array f desc_name strides desc tensor get_stride element_size = val_to_arg_str desc tensor get_dtype itemsize fn = initTMADescriptor args = join str x x f desc_name m ptr element_size rank f desc_name block_shape f desc_name global_shape f desc_name strides writeline f fn args generate_args_decl code Union IndentedBuffer Self call_args arg_types arg_signatures is_triton_kernel=True scratch_spaces Optional dict str int = None Generates any declarations args pass into kernel call then returns arg names In more detail declarations e g function has side effect generating lines like ` auto var_ = ` returns string list args e g var_ var_ call_args list call arguments arg_types list argument types arg_signatures list signatures all args is_triton_kernel whether these passed into triton kernel In particular calls triton kernels will have additional global scratch space arg injected front arg list new_args list str = Add more cases other types needed signature dtype = i int _t i int _t fp float signature_is_tma_desc sig sig False sig == nvTmaDesc True sig startswith tensordesc True False process_tma_stable_arg arg arg_type arg_signature var_name Note AOTI TMA Stable handling For most args single arg passed python triton interface maps single arg cubin interface However host-side TMA descriptors single python arg turns into + N args cubin interface where N rank To do TMA codegen time aoti we generate struct StableTMADescriptor containing necessary information then when we call function i e here we unpack struct members code writeline f auto var_name = cexpr arg result = result append f var_name m https github com triton-lang triton blob b bdac b b d e fd ec third_party nvidia backend driver py#L noqa B match = re match tensordesc ^ \\ ^ \\ arg_signature assert match None shape = match group ndim = shape count + i range ndim result append f var_name block_shape i i range ndim result append f var_name strides i result process_args arg arg_type arg_signature=None var_name = f var_ next arg_var_id ignore tma descriptors host-side TMA descriptors need passed compiled Triton kernel value isinstance arg_type UnwrapUnspecArg signature_is_tma_desc arg_signature codegen_tensor_item arg_type dtype arg var_name indented_buffer=code new_args append f var_name isinstance arg_type torch_dtype signature_is_tma_desc arg_signature device_ptr_type = device_codegen cpp_device_ptr code writeline maybe_hipify_code_wrapper f device_ptr_type var_name = reinterpret_cast device_ptr_type arg data_ptr new_args append f var_name arg_type sympy Integer int code writeline f int var_name = cexpr arg new_args append f var_name arg_type sympy Float float code writeline f float var_name = cexpr arg new_args append f var_name For symbolic call arguments examine arg signatures triton meta explicitly cast right type Reason ` auto ` can infer unexpected type against kernel input signature isinstance arg_type type SymbolicCallArg arg_signature None arg_signature signature dtype keys code writeline f signature dtype arg_signature var_name = cexpr arg new_args append f var_name arg_signature arg_signature startswith tensordesc new_args extend process_tma_stable_arg arg arg_type arg_signature var_name code writeline f auto var_name = cexpr arg new_args append f var_name arg arg_type arg_signature zip_longest call_args arg_types arg_signatures process_args arg arg_type arg_signature scratch_name workspace_size scratch_spaces items is_triton_kernel scratch = device_codegen cpp_scratch next arg_var_id workspace=TritonScratchWorkspace size=workspace_size generate_dtype_str= lambda codegen_dtype torch uint prefix=scratch_name None scratch_def scratch_var = scratch code writelines maybe_hipify_code_wrapper x x scratch_def new_args append f scratch_var join new_args _generate_kernel_call_helper kernel_name str call_args device=None triton=True arg_types=None raw_keys=None raw_args=None triton_meta=None graph_name= original_fxnode_name=None Override default value argument gpu True here generate_kernel_call can still called gpu=False because mix cpu kernels gpu kernels device = device V graph get_current_device_or_throw device type == cpu Even CppWrapperGpu we may see cpp kernels CppWrapperCpu _generate_kernel_call_helper kernel_name call_args device=device triton=triton arg_types=arg_types raw_keys=raw_keys raw_args=raw_args triton_meta=triton_meta triton config triton autotune_at_compile_time kernel_name kernel_autotune_names Call PythonWrapperCodegen create autotune code block PythonWrapperCodegen _generate_kernel_call_helper kernel_name call_args device=device triton=triton arg_types=arg_types raw_keys=raw_keys raw_args=raw_args triton_meta=triton_meta original_fxnode_name=original_fxnode_name stream = stream V graph aot_mode write_get_raw_stream device index graph_name triton call_args arg_types = prepare_triton_wrapper_args call_args pyrefly ignore bad-argument-type arg_types wrapper_name = f call_ kernel_name wrapper_name _triton_call_wrappers _triton_call_wrappers wrapper_name = DeferredTritonCallWrapper wrapper_name kernel_name _kernel_name_to_body arg_types device_idx = this- device_idx_ V graph aot_mode str device index call_args append device_idx call_args append stream V graph aot_mode call_args append kernels call_args append this- cubin_dir_ debug_printer_manager = V graph wrapper_code debug_printer debug_printer_manager set_printer_args call_args len arg_types kernel_name arg_types None debug_printer_manager writeline f wrapper_name join call_args casted = pyrefly ignore no-matching-overload arg_type arg zip arg_types call_args new_arg = arg arg_type endswith arg = nullptr new_arg = f arg data_ptr pyrefly ignore bad-argument-type casted append f arg_type cexpr new_arg call_args_str = join casted writeline f kernels kernel_name call_args_str stream staticmethod prepare_triton_wrapper_args call_args list Any arg_types list Any - tuple list Any list Any assert len call_args == len arg_types call_args arg_types new_args = new_args_types = arg arg_type zip call_args arg_types isinstance arg str isinstance arg_type torch_dtype should_unwrap_unspec_arg arg dynamo wraps unspec variable d CPU tensor need convert scalar arg_type = UnwrapUnspecArg dtype=arg_type new_args append arg isinstance arg bool new_args append str arg lower isinstance arg int float SymbolicCallArg new_args append str arg new_args append cexpr V graph sizevars simplify arg new_args_types append arg_type new_args new_args_types make_zero_buffer name f AOTI_TORCH_ERROR_CODE_CHECK aoti_torch_zero_ name get dataclasses dataclass UnwrapUnspecArg Marker we need call item tensor dtype torch_dtype