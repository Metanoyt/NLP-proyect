Owner s module onnx onnxruntime pytorch_test_common pytorch_test_common skipIfNoCuda torch torch onnx _internal torchscript_exporter verification torch onnx _internal torchscript_exporter _globals GLOBALS torch onnx _internal torchscript_exporter utils _trigger_symbolic_function_registration torch testing _internal common_utils _jit_graph_to_onnx_model graph operator_export_type opset_version r This function exports torch jit Graph object serialized ONNX ModelProto This function testing purpose It only keeps essential parts IR graph conversions It also does interact actual PyTorch modules nor PyTorch tensor inputs GLOBALS export_onnx_opset_version = opset_version _trigger_symbolic_function_registration graph = torch onnx utils _optimize_graph graph operator_export_type params_dict= proto _ _ _ = graph _export_onnx opset_version False operator_export_type False False True proto _TestJITIRToONNX Abstract base test cases Intentionally sub-class unittest TestCase so unittest pytest don t run directly unitest TestCase mixed another base when creating concrete sub-types See MakeTestCase opset_version = - Sub-classes must override ort_providers = CPUExecutionProvider check_shape = True check_dtype = True ignore_none = True True tracing Flase scripting run_test graph_ir example_inputs parse_tensor_constants=False graph = torch _C parse_ir graph_ir parse_tensor_constants jit_outs = torch _C _jit_interpret_graph graph example_inputs onnx_proto = _jit_graph_to_onnx_model graph torch onnx OperatorExportTypes ONNX opset_version ort_sess = onnxruntime InferenceSession onnx_proto providers=self ort_providers ort_outs = verification _run_onnx ort_sess example_inputs options = verification VerificationOptions rtol= e- atol= e- check_shape=self check_shape check_dtype=self check_dtype ignore_none=self ignore_none acceptable_error_percentage=None verification _compare_onnx_pytorch_outputs ort_outs jit_outs options test_example_ir graph_ir = graph Float Float int = prim Constant value= Float = aten add = torch randn b = torch randn run_test graph_ir b test_where_constants graph_ir = graph Bool device=cpu Float device=cpu Double device=cpu = prim Constant value= Float = aten where = torch zeros dtype=bool b = torch zeros run_test graph_ir b parse_tensor_constants=True test_add_sub_with_graph_inputs op add sub rsub graph_ir = f graph Float Float int Float = aten op = torch randn b = torch randn run_test graph_ir b test_native_layer_norm graph_ir = graph x Float w Float b Float int = prim Constant value= int = prim Constant value= int = prim ListConstruct float = prim Constant value= e- Float Float Float = aten native_layer_norm x w b x = torch randn w = torch randn b = torch randn run_test graph_ir x w b test_convolution graph_ir = graph Tensor Tensor NoneType = prim Constant int = prim Constant value= int = prim Constant value= bool = prim Constant value= int = prim Constant value= Tensor = aten convolution x = torch randn w = torch randn run_test graph_ir x w test_log_softmax graph_ir = graph x Tensor half_to_float bool = prim Constant value= dim int = prim Constant value= y = aten _log_softmax x dim half_to_float y x = torch randn run_test graph_ir x skipIfNoCuda test_log_softmax_half_to_float graph_ir = graph x Tensor half_to_float bool = prim Constant value= dim int = prim Constant value= y = aten _log_softmax x dim half_to_float y x = torch randn half cuda run_test graph_ir x test_native_dropout graph_ir = graph Float float = prim Constant value= training bool = prim Constant value= Tensor Tensor = aten native_dropout training = torch randn run_test graph_ir MakeTestCase opset_version int - type name = f TestJITIRToONNX_opset opset_version type str name pytorch_test_common ExportTestCase dict _TestJITIRToONNX __dict__ opset_version=opset_version TestJITIRToONNX_opset = MakeTestCase __name__ == __main__ common_utils run_tests