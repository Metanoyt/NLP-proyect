mypy allow-untyped-defs __future__ annotations collections contextlib dataclasses dis functools inspect logging operator random re tempfile itertools chain count typing Any Callable Optional TYPE_CHECKING Union sympy sympy Expr torch torch _ops torch utils _pytree pytree torch dtype torch_dtype torch _dynamo utils counters dynamo_timed torch _inductor codegen debug_utils DebugPrinterManager torch _inductor codegen multi_kernel MultiKernelState torch _inductor runtime runtime_utils cache_dir torch _logging trace_structured torch fx experimental symbolic_shapes CallMethodKey ConvertIntKey DivideByKey resolve_unbacked_bindings SymTypes torch fx node _get_qualified_name torch utils _ordered_set OrderedSet torch utils _sympy singleton_int SingletonInt torch utils _sympy symbol symbol_is_type SymT async_compile config ir codecache output_code_log ir IRNode ReinterpretView runtime triton_heuristics runtime hints DeviceProperties utils cache_on_self DelayReplaceLine get_benchmark_name get_dtype_size IndentedBuffer is_codegen_graph_partition_subgraph is_using_cudagraph_partition LineContext sympy_product sympy_str sympy_subs triton_version_uses_attrs_dict virtualized V common ArgName CodeGen DeferredLine PythonPrinter WorkspaceArg WorkspaceZeroMode cpp_utils cexpr triton_utils config_of should_unwrap_unspec_arg signature_to_meta TYPE_CHECKING collections abc Iterator Sequence triton graph GraphLowering ir ExternKernel scheduler BaseSchedulerNode wrapper_fxir FxConverter log = logging getLogger __name__ pexpr = PythonPrinter doprint ReuseKey = tuple torch device torch dtype str bool BufferLike = Union ir Buffer WorkspaceArg FxConversionFunc = Callable WrapperLine None buffer_reuse_key node BufferLike - ReuseKey storage_size = V graph get_allocation_storage_size node alignment = node get_name V graph unaligned_buffers node get_device_or_error node get_dtype NB symbolic so we don t try reuse buffer s s just because they happen share same size hint sympy_str V graph sizevars simplify storage_size alignment can_match_buffer_size input_buf BufferLike output_buf BufferLike Return True input_buf can re-inplaced output_buf This differs ` buffer_reuse_key ` general buffer reuse input_buf get_device_or_error = output_buf get_device_or_error False input_buf get_dtype = output_buf get_dtype False input_size = V graph sizevars simplify V graph get_allocation_storage_size input_buf output_size = V graph sizevars simplify V graph get_allocation_storage_size output_buf NB symbolic so we don t try reuse buffer s s just because they happen share same size hint sympy_str input_size == sympy_str output_size statically known input_size = output_size = input_size V graph sizevars statically_known_geq output_size input_size V graph sizevars statically_known_leq output_size input_size True False TODO Move well known place TritonMetaParams = dict str int TritonGrid = Union tuple Union int sympy Expr Callable TritonMetaParams tuple int user_defined_kernel_grid_fn_code name str configs list triton Config type ignore name-defined grids list TritonGrid wrapper Optional PythonWrapperCodegen = None original_fxnode_name Optional str = None - tuple str str output = IndentedBuffer _convert_to_sympy_expr item Union int sympy Expr - sympy Expr item isinstance item sympy Expr sympy Integer item determine_grid grid TritonGrid example_grid Optional TritonGrid = None This function tuple two values first one real grid which used generated code second one example grid concreate values which used autotune block run generated kernels compile time wrapper None callable grid as-is when used eager mode when grid callable grid grid Grid contains ints Expr so utilize wrapper s expr printer codegen sympy_grid = tuple _convert_to_sympy_expr g g grid example_grid example_grid = sympy_grid wrapper codegen_python_shape_tuple sympy_grid wrapper codegen_python_shape_tuple tuple wrapper generate_example_arg_value g type g g example_grid type ignore union-attr config triton autotune_at_compile_time None writeline line str example_grid Optional str = None output writeline line wrapper config triton autotune_at_compile_time name wrapper kernel_autotune_names wrapper kernel_autotune_calls writeline example_grid line fn_name = f grid_wrapper_for_ name writeline f fn_name meta kernel_autotune_calls_indent = wrapper kernel_autotune_calls indent wrapper config triton autotune_at_compile_time contextlib nullcontext output indent kernel_autotune_calls_indent config triton autotune_at_compile_time original_fxnode_name V graph autotuning_grids original_fxnode_name V graph autotuning_grids example_grids = V graph autotuning_grids original_fxnode_name example_grids = None len grids len grids == grid example_grid = determine_grid grids example_grids writeline f grid f example_grid assert len grids assert len grids == len configs seen OrderedSet str = OrderedSet sort configs largest kwargs smallest emit grids order approximately decreasing specificity TODO aakhundov sorting below generally sufficient so maybe we ll need restrict supported cases identical kwarg names all autotuning configs grid c example_grid sorted zip grids configs example_grids key=lambda x len x kwargs reverse=True guardslist = c kwargs Remove AMD specific kwargs kwarg c kwargs kwarg matrix_instr_nonkdim waves_per_eu kpack guardslist append f meta kwarg == c kwargs kwarg guardslist guards = join guardslist guards = True configs empty kwargs grid example_grid = determine_grid grid example_grid statement = f guards grid statement seen continue seen add statement writeline statement f guards example_grid fn_name output getvalue user_defined_triton_kernel_transitive_closure_source_code kernel - str Given triton kernel function pointer collect transitive closure its dependencies compile_wrapper = IndentedBuffer compile_wrapper splice kernel src strip=True Also include any possible kernel being called indirectly triton triton JITFunction type ignore name-defined attr-defined triton language constexpr type ignore name-defined global constexpr vars handled above symbols_included = OrderedSet kernel __name__ traverse cur_kernel here we extract unqualified names i e attributes without prepended module name loaded kernel code which matched co_names __globals__ below codegen respective imports necessary kernel compilation unqualified_loads = OrderedSet inst argval inst dis Bytecode cur_kernel fn inst opname == LOAD_GLOBAL global_annotations = cur_kernel fn __globals__ get __annotations__ symbol_name cur_kernel fn __code__ co_names symbol_name symbols_included continue symbol_name cur_kernel fn __globals__ symbol = cur_kernel fn __globals__ symbol_name isinstance symbol JITFunction compile_wrapper newline compile_wrapper writeline triton jit compile_wrapper splice symbol src strip=True symbols_included add symbol_name traverse symbol hasattr triton constexpr_function isinstance symbol triton runtime jit ConstexprFunction compile_wrapper newline compile_wrapper writeline triton constexpr_function compile_wrapper splice symbol src strip=True symbols_included add symbol_name traverse symbol isinstance symbol int str bool constexpr compile_wrapper newline isinstance symbol constexpr symbol_str = f tl constexpr symbol value r symbol_str = f symbol r annotation = global_annotations get symbol_name isinstance annotation type annotation_code = f annotation __module__ annotation __name__ annotation_code = f annotation r compile_wrapper writeline f symbol_name annotation_code = symbol_str compile_wrapper writeline f symbol_name = symbol_str symbols_included add symbol_name symbol_name unqualified_loads symbol_name = tl already imported hasattr symbol __module__ only codegen imports triton JITFunctions imported other modules will codegened separate branch above symbol __module__ startswith triton global symbol imported triton referenced without module qualification i e ` store ` instead ` tl store ` need codegen compile_wrapper writeline f symbol __module__ symbol __name__ symbol_name symbols_included add symbol_name traverse kernel compile_wrapper getvalue dataclasses dataclass SymbolicCallArg inner sympy Symbol original symbolic expression represented inner inner_expr sympy Expr __str__ str inner MemoryPlanningState __init__ super __init__ reuse_pool dict ReuseKey list FreeIfNotReusedLine = collections defaultdict list total_allocated_buffer_size int = __contains__ key ReuseKey - bool bool reuse_pool get key None pop key ReuseKey - FreeIfNotReusedLine item = reuse_pool key pop assert item is_reused item push key ReuseKey item FreeIfNotReusedLine - None assert item is_reused reuse_pool key append item WrapperLine codegen_fx converter FxConverter - FxConversionFunc raise NotImplementedError f FX codegen yet supported type type dataclasses dataclass EnterSubgraphLine WrapperLine wrapper PythonWrapperCodegen graph GraphLowering __post_init__ - None wrapper push_computed_sizes wrapper computed_sizes codegen code IndentedBuffer - None wrapper push_codegened_graph graph code do_indent codegen_fx converter FxConverter - FxConversionFunc converter _generate_enter_subgraph dataclasses dataclass ConditionalLine WrapperLine wrapper PythonWrapperCodegen node ir Conditional codegen code IndentedBuffer - None raise NotImplementedError Only supports FX codegen staticmethod codegen_fx converter FxConverter - FxConversionFunc converter _generate_conditional dataclasses dataclass CommentLine WrapperLine line LineContext codegen code IndentedBuffer - None code writeline line staticmethod codegen_fx converter FxConverter - FxConversionFunc converter _generate_comment dataclasses dataclass DynamicScalarLine WrapperLine wrapper PythonWrapperCodegen node ir DynamicScalar codegen code IndentedBuffer - None wrapper _codegen_dynamic_scalar node staticmethod codegen_fx converter FxConverter - FxConversionFunc converter _generate_dynamic_scalar dataclasses dataclass ExitSubgraphLine WrapperLine wrapper PythonWrapperCodegen __post_init__ - None wrapper computed_sizes = wrapper pop_computed_sizes codegen code IndentedBuffer - None wrapper pop_codegened_graph code do_unindent codegen_fx converter FxConverter - FxConversionFunc converter _generate_exit_subgraph dataclasses dataclass EnterDeviceContextManagerLine WrapperLine device_idx int last_seen_device_guard_index Optional int codegen code IndentedBuffer - None V graph cpp_wrapper code writeline \n V graph aot_mode In AOT mode we have stream provided param A stream associated device so we never expect device change CUDAStreamGuard sets stream device last_seen_device_guard_index None code writeline f V graph device_ops cpp_aoti_stream_guard stream_guard stream this- device_idx_ assert last_seen_device_guard_index == device_idx AOTInductor only supports running one CUDA device last_seen_device_guard_index None code writeline f V graph device_ops cpp_aoti_device_guard device_guard device_idx code writeline f device_guard set_index device_idx Note _DeviceGuard has less overhead than device only accepts integers code writeline f V graph device_ops device_guard device_idx code do_indent code writeline V graph device_ops set_device device_idx codegen_fx converter FxConverter - FxConversionFunc converter _generate_enter_device_context_manager ExitDeviceContextManagerLine WrapperLine codegen code IndentedBuffer - None V graph cpp_wrapper code do_unindent codegen_fx converter FxConverter - FxConversionFunc converter _generate_exit_device_context_manager dataclasses dataclass ExternKernelAllocLine WrapperLine wrapper PythonWrapperCodegen node ir ExternKernelAlloc codegen code IndentedBuffer - None node = node args = node codegen_args node codegen_kwargs wrapper _generate_extern_kernel_alloc_helper node args codegen_fx converter FxConverter - FxConversionFunc converter _generate_extern_kernel_alloc dataclasses dataclass ExternKernelOutLine WrapperLine wrapper PythonWrapperCodegen node ir ExternKernelOut codegen code IndentedBuffer - None node = node args = node codegen_args node codegen_kwargs skip_out=True kernel_name = node get_kernel_name V graph cpp_wrapper node cpp_kernel_name == torch inductor _mm_plus_mm For https github com pytorch pytorch issues kernel_name = aoti_torch__mm_plus_mm_out kernel_name = node get_kernel_name device = d type d = node get_device V graph device_type wrapper _generate_extern_kernel_out_helper kernel_name node codegen_reference node output_view codegen_reference node output_view None args device node get_stack_traces codegen_fx converter FxConverter - FxConversionFunc converter _generate_extern_kernel_out dataclasses dataclass FreeLine WrapperLine wrapper PythonWrapperCodegen node Union BufferLike ir TorchBindObject codegen code IndentedBuffer - None assert node get_name V graph removed_buffers code writeline wrapper make_buffer_free node codegen_fx converter FxConverter - FxConversionFunc converter _generate_free dataclasses dataclass KernelCallLine WrapperLine wrapper PythonWrapperCodegen kernel_name str call_args tuple Any raw_keys tuple Any raw_args tuple Any arg_types list str triton bool triton_meta dict str Any device torch device graph_name str original_fxnode_name str codegen code IndentedBuffer - None wrapper _generate_kernel_call_helper kernel_name call_args triton=self triton arg_types=self arg_types raw_keys=self raw_keys raw_args=self raw_args triton_meta=self triton_meta device=self device graph_name=self graph_name original_fxnode_name=self original_fxnode_name codegen_fx converter FxConverter - FxConversionFunc converter _generate_kernel_call dataclasses dataclass KernelDefinitionLine WrapperLine wrapper PythonWrapperCodegen kernel_name str kernel_body str metadata Optional str = None gpu bool = True cpp_definition Optional str = None codegen code IndentedBuffer - None wrapper _define_kernel_helper kernel_name kernel_body metadata=self metadata gpu=self gpu cpp_definition=self cpp_definition codegen_fx converter FxConverter - FxConversionFunc converter _generate_kernel_definition dataclasses dataclass MemoryPlanningLine WrapperLine wrapper PythonWrapperCodegen plan state MemoryPlanningState - MemoryPlanningLine First pass find reuse codegen code IndentedBuffer - None Second pass output code __str__ - str Emits string representation fits one line args list str = field dataclasses fields field name == wrapper continue val = getattr field name args append f field name = val get_name field type ir Buffer val f type __name__ join args EfficientPeakEstimate __init__ memory estimate_peak_memory get_freeable_input_buf scheduler_nodes = V graph scheduler nodes graph_inputs = OrderedSet V graph graph_inputs keys graph_outputs = OrderedSet V graph get_output_names names_to_freeable_bufs = get_freeable_input_buf scheduler_nodes graph_inputs overall_peak_memory peak_by_scheduler_node = estimate_peak_memory scheduler_nodes names_to_freeable_bufs graph_outputs segmented_tree SegmentedTree segmented_tree = SegmentedTree peak_by_scheduler_node operator add max _get_size node BufferLike - int V graph sizevars size_hint V graph get_allocation_storage_size node fallback= get_dtype_size node get_dtype peak_between line_a FreeIfNotReusedLine line_b AllocateLine segmented_tree summarize_range line_a scheduler_node_index + line_b scheduler_node_index - update_peak_between line_a FreeIfNotReusedLine line_b AllocateLine line_a scheduler_node_index + == line_b scheduler_node_index segmented_tree update_range line_a scheduler_node_index + line_b scheduler_node_index - _get_size line_b node dataclasses dataclass AllocateLine MemoryPlanningLine node BufferLike __post_init__ assert V graph scheduler current_node None scheduler_node_index = V graph scheduler nodes index V graph scheduler current_node should_reuse_buffer free_line FreeIfNotReusedLine size int - bool free_line scheduler_node_index + == scheduler_node_index True overall_peak_memory = wrapper estimate_peak overall_peak_memory peak_memory_in_range = wrapper estimate_peak peak_between free_line new_peak_memory = size + peak_memory_in_range new_peak_memory = overall_peak_memory plan state MemoryPlanningState - MemoryPlanningLine node get_name V graph removed_buffers NullLine wrapper try reuse recently freed buffer key = buffer_reuse_key node config allow_buffer_reuse key state free_line = state pop key size = V graph sizevars size_hint V graph get_allocation_storage_size node fallback= get_dtype_size node get_dtype should_reuse_buffer free_line size free_line is_reused = True wrapper estimate_peak update_peak_between free_line ReuseLine wrapper free_line node node state push key free_line node get_device_or_error type == cpu static_shape = wrapper static_shape_for_buffer_or_none node static_shape None state total_allocated_buffer_size += int functools reduce operator mul static_shape codegen code IndentedBuffer - None assert node get_name V graph removed_buffers line = wrapper make_buffer_allocation node code writeline line codegen_fx converter FxConverter - FxConversionFunc converter _generate_allocate dataclasses dataclass FreeIfNotReusedLine MemoryPlanningLine node BufferLike is_reused bool = False __post_init__ assert V graph scheduler current_node None scheduler_node_index = V graph scheduler nodes index V graph scheduler current_node plan state MemoryPlanningState - MemoryPlanningLine len node get_inputs_that_alias_output isinstance node layout ir MultiOutputLayout assert is_reused node get_name V graph removed_buffers NullLine wrapper config allow_buffer_reuse state push buffer_reuse_key node codegen code IndentedBuffer - None assert node get_name V graph removed_buffers is_reused code writeline wrapper make_buffer_free node codegen_fx converter FxConverter - FxConversionFunc converter _generate_free_if_not_reused dataclasses dataclass ReinterpretLine MemoryPlanningLine node BufferLike reused_as BufferLike layout ir Layout plan state MemoryPlanningState - MemoryPlanningLine codegen code IndentedBuffer - None assert isinstance layout ir NonOwningLayout assert isinstance layout view ir ReinterpretView wrapper codegen_deferred_allocation reused_as get_name layout view codegen_fx converter FxConverter - FxConversionFunc converter _generate_reinterpret dataclasses dataclass ReuseLine MemoryPlanningLine node BufferLike reused_as BufferLike delete_old bool = True plan state MemoryPlanningState - MemoryPlanningLine node get_name V graph removed_buffers assert reused_as get_name V graph removed_buffers NullLine wrapper assert reused_as get_name V graph removed_buffers codegen code IndentedBuffer - None assert node get_name V graph removed_buffers assert reused_as get_name V graph removed_buffers code writeline wrapper make_buffer_reuse node reused_as delete_old codegen_fx converter FxConverter - FxConversionFunc converter _generate_reuse NullLine MemoryPlanningLine codegen_fx converter FxConverter - FxConversionFunc converter _generate_null dataclasses dataclass CommBufferLine WrapperLine wrapper PythonWrapperCodegen type ignore name-defined noqa F node ir Buffer property size - int torch _inductor utils is_symbolic numel = node get_numel dtype = node get_dtype is_symbolic numel raise AssertionError f The size comm buffer can t symbolic node int numel dtype itemsize property comm_buffer_type - ir CommBufferType layout = node get_output_spec assert isinstance layout ir CommBufferLayout layout comm_buffer_type property group_name - str layout = node get_output_spec assert isinstance layout ir CommBufferLayout layout group_name dataclasses dataclass CommBufferAllocateLine CommBufferLine codegen code IndentedBuffer - None assert node get_name V graph removed_buffers name = node get_name device = node get_device dtype = node get_dtype shape = tuple node get_size stride = tuple node get_stride code writeline make_allocation_line comm_buffer_type group_name wrapper name device dtype shape stride staticmethod make_allocation_line comm_buffer_type group_name wrapper name device dtype shape stride comm_buffer_type == ir CommBufferType SYMM_MEM f name = empty_strided_p p f wrapper codegen_shape_tuple shape f wrapper codegen_shape_tuple stride f dtype f torch device cuda device index f group_name= group_name f alloc_id= random randint - raise NotImplementedError f Unsupported comm buffer type comm_buffer_type codegen_fx converter FxConverter - FxConversionFunc converter _generate_comm_buffer_allocate dataclasses dataclass CommBufferFreeLine CommBufferLine codegen code IndentedBuffer - None line = wrapper make_buffer_free node code writeline f line comm_buffer_type value buffer free codegen_fx converter FxConverter - FxConversionFunc converter _generate_comm_buffer_free dataclasses dataclass MultiOutputLine WrapperLine Given MultiOutputLayout buffer indexes actual buffer s result wrapper PythonWrapperCodegen result_name str arg_name str indices Sequence Any codegen code IndentedBuffer - None codegen_list_tuple_access basename indices type ignore no-untyped-def len indices itype i = indices issubclass itype list codegen_list_tuple_access f basename i indices issubclass itype tuple cpp wrapper code needs use std get access tuple tuple_access = wrapper codegen_tuple_access basename result_name str i codegen_list_tuple_access tuple_access indices issubclass itype dict codegen_list_tuple_access f basename i indices raise AssertionError non supported index type itype basename value = codegen_list_tuple_access arg_name indices code writeline f wrapper declare result_name = value wrapper ending codegen_fx converter FxConverter - FxConversionFunc converter _generate_multi_output dataclasses dataclass IndexPutFallbackLine WrapperLine wrapper PythonWrapperCodegen node ir IndexPutFallback indices list Optional ir IRNode codegen code IndentedBuffer - None node = node assert ir is_node_sequence node inputs x values = t codegen_reference t node inputs indices = idx codegen_reference idx wrapper none_str idx indices wrapper _generate_index_put_fallback node get_kernel_name x indices values node codegen_const_args codegen_fx converter FxConverter - FxConversionFunc converter _generate_index_put_fallback dataclasses dataclass ScatterFallbackLine WrapperLine wrapper PythonWrapperCodegen node ir ScatterFallback codegen code IndentedBuffer - None node = node assert ir is_node_sequence node inputs node src_is_tensor x index src = t codegen_reference t node inputs x index = t codegen_reference t node inputs src = node constant_args wrapper _generate_scatter_fallback x x node constant_args index src node cpp_kernel_name node python_kernel_name node src_is_tensor node kwargs reduce node codegen_kwargs codegen_fx converter FxConverter - FxConversionFunc converter _generate_scatter_fallback dataclasses dataclass SymbolicCallArgLine WrapperLine wrapper PythonWrapperCodegen arg SymbolicCallArg graph GraphLowering codegen code IndentedBuffer - None wrapper _generate_symbolic_call_arg_helper arg graph codegen_fx converter FxConverter - FxConversionFunc converter _generate_symbolic_call_arg dataclasses dataclass UnbackedSymbolDefsLine WrapperLine wrapper PythonWrapperCodegen output_name str outputs Any unbacked_bindings Optional dict sympy Symbol pytree KeyPath codegen code IndentedBuffer - None wrapper _codegen_unbacked_symbol_defs_for_outputs output_name outputs unbacked_bindings codegen_fx converter FxConverter - FxConversionFunc converter _generate_unbacked_symbol_defs BufferName = str Line = Union MemoryPlanningLine LineContext PythonWrapperCodegen CodeGen Generate outer wrapper Python calls kernels supports_caching = True Whether output code cacheable __init__ super __init__ _names_iter Iterator int = count args_to_buffers dict str Union None ir TensorBox ir Buffer ir TorchBindObject = imports = IndentedBuffer header = IndentedBuffer prefix = IndentedBuffer suffix = IndentedBuffer kernel_declarations = IndentedBuffer wrapper_call = IndentedBuffer kernel_autotune_defs = IndentedBuffer kernel_autotune_calls = IndentedBuffer subgraph_definitions = IndentedBuffer kernel_autotune_names OrderedSet str = OrderedSet Map key kernel argument name value tuple resulting example tensor name kernel where tensor most recently used kernel_autotune_example_args dict str tuple str str = kernel_autotune_tmp_arg_idx int = If generated source code exactly same reuse pre-existing kernel src_to_kernel dict str str = kernel_numel_expr OrderedSet tuple str GraphLowering = OrderedSet lines list Line = declare = declare_maybe_reference = ending = comment = none_str = None move_begin = std move V graph cpp_wrapper move_end = V graph cpp_wrapper last_seen_device_guard_index Optional int = None supports_intermediate_hooks = True user_defined_kernel_cache dict tuple Any tuple str Any = unbacked_symbol_decls OrderedSet str = OrderedSet str sympy Symbol computed_sizes OrderedSet sympy Symbol = OrderedSet launcher_fn_name = None This function can overridden change launcher name set_launcher_fn_name used tracking which GraphLowering instance --- parent graph nested subgraph --- currently codegened primary use case including graph instance into cache key avoid cross-graph caching during lowering nested subgraphs codegened_graph_stack = computed_sizes_stack = write_header is_codegen_graph_partition_subgraph See Note Removed Graph Partition Arguments write_prefix write_kernel_autotune_defs_header V graph aot_mode name hashed V graph constant_reprs items include hash so our code cache puts different constants into different files write_constant name hashed allocated = OrderedSet BufferName freed = OrderedSet BufferName maps reusing buffer reused buffer reuses dict BufferName BufferName = write_get_raw_stream = functools lru_cache None type ignore assignment write_get_raw_stream functools cache add_import_once line str - None imports writeline line config triton autotune_at_compile_time kernel_autotune_calls writeline line add_import_once = add_import_once _metas dict str str = _meta_vars OrderedSet str = OrderedSet multi_kernel_state = MultiKernelState already_codegened_subgraphs OrderedSet str = OrderedSet allocated_workspaces dict str Any = intermediate tensor value printing utility debug_printer = DebugPrinterManager debug_printer_level=config aot_inductor debug_intermediate_value_printer use_array_ref=config aot_inductor allow_stack_allocation Additional files dependent wrapper ex cubin files additional_files = staticmethod create is_subgraph bool subgraph_name Optional str parent_wrapper Optional PythonWrapperCodegen partition_signatures Optional ir GraphPartitionSignature = None is_subgraph assert subgraph_name None assert parent_wrapper None SubgraphPythonWrapperCodegen subgraph_name parent_wrapper partition_signatures PythonWrapperCodegen set_launcher_fn_name - None pyrefly ignore bad-assignment launcher_fn_name = call write_constant name str hashed str - None header writeline f name = None hashed write_header - None context = torch _guards TracingContext try_get aot_config_comment = context None context aot_graph_name None aot_config_comment = f AOT ID context aot_graph_name inductor_debug_utils = int config aot_inductor debug_intermediate_value_printer inductor_debug_utils = torch _inductor codegen debug_utils _print_debugging_tensor_value_info torch _inductor config test_configs track_memory_lifecycle inductor_debug_utils = torch _inductor runtime debug_utils tracked_empty_strided\n imports splice f aot_config_comment ctypes c_void_p c_long c_int torch math random os tempfile math inf nan cmath nanj torch _inductor hooks run_intermediate_hooks torch _inductor utils maybe_profile torch _inductor codegen memory_planning _align align torch device empty_strided async_compile __name__ AsyncCompile torch _inductor select_algorithm extern_kernels inductor_debug_utils strip=True header splice aten = torch ops aten inductor_ops = torch ops inductor _quantized = torch ops _quantized assert_size_stride = torch _C _dynamo guards assert_size_stride assert_alignment = torch _C _dynamo guards assert_alignment empty_strided_cpu = torch _C _dynamo guards _empty_strided_cpu empty_strided_cpu_pinned = torch _C _dynamo guards _empty_strided_cpu_pinned empty_strided_cuda = torch _C _dynamo guards _empty_strided_cuda empty_strided_xpu = torch _C _dynamo guards _empty_strided_xpu empty_strided_mtia = torch _C _dynamo guards _empty_strided_mtia reinterpret_tensor = torch _C _dynamo guards _reinterpret_tensor alloc_from_pool = torch ops inductor _alloc_from_pool async_compile = AsyncCompile strip=True try Only add empty_strided_p p distributed SymmetricMemory available torch _C _distributed_c d _SymmetricMemory noqa F header splice empty_strided_p p = torch _C _distributed_c d _SymmetricMemory empty_strided_p p strip=True except AttributeError ImportError pass config annotate_training header writeline torch cuda nvtx include_extra_header header str pass write_kernel_autotune_defs_header - None kernel_autotune_defs splice f torch torch _dynamo testing rand_strided torch _dynamo utils preserve_rng_state torch _inductor select_algorithm AlgorithmSelectorCache async_compile __name__ AsyncCompile async_compile = AsyncCompile generate_example_value = AlgorithmSelectorCache generate_example_value empty_strided_cuda = torch _C _dynamo guards _empty_strided_cuda empty_strided_xpu = torch _C _dynamo guards _empty_strided_xpu try torch _C _cuda_getCurrentRawStream noqa F kernel_autotune_defs splice get_raw_stream = torch _C _cuda_getCurrentRawStream strip=True except ImportError AttributeError pass cache_on_self write_triton_header_once - None import_str = f triton triton language tl triton_heuristics __name__ start_graph end_graph config triton autotune_at_compile_time kernel_autotune_calls splice import_str kernel_autotune_calls writeline V graph device_ops import_get_raw_stream_as get_raw_stream V graph cpp_wrapper imports splice import_str strip=True imports writeline V graph device_ops import_get_raw_stream_as get_raw_stream write_get_raw_stream_header - None import_get_raw_stream_str = V graph device_ops import_get_raw_stream_as get_raw_stream config triton autotune_at_compile_time kernel_autotune_calls contains import_get_raw_stream_str kernel_autotune_calls writeline import_get_raw_stream_str V graph cpp_wrapper imports contains import_get_raw_stream_str imports writeline import_get_raw_stream_str cache_on_self write_get_raw_stream_header_once - None write_get_raw_stream_header add_meta_once meta TritonMetaParams - str pyrefly ignore bad-assignment meta = repr meta meta _metas var = f meta len _metas pyrefly ignore unsupported-operation _metas meta = var header writeline f var = meta config triton autotune_at_compile_time kernel_autotune_calls writeline f var = meta _meta_vars add var pyrefly ignore index-error _metas meta cache_on_self get_output_refs - list str x codegen_reference wrapper_call x get_graph_outputs mark_output_type - None get_graph_inputs - dict str Union ir TensorBox ir TorchBindObject sympy Expr V graph graph_inputs get_graph_outputs - list IRNode V graph graph_outputs codegen_input_size_asserts - None name buf get_graph_inputs items isinstance buf sympy Expr ir TorchBindObject continue graph partition may take IRNode output previous partition name V graph graph_input_names isinstance buf ir GeneratorState continue comparing strides size tensor tricky Ignore them now sympy_product buf get_size == continue size = codegen_python_shape_tuple buf get_size stride = codegen_python_shape_tuple buf get_stride prefix writeline f assert_size_stride name size stride codegen_input_nan_asserts - None prefix writeline make sure graph inputs nan inf name buf get_graph_inputs items isinstance buf sympy Expr ir TorchBindObject continue line = f assert name isnan any item prefix writeline line line = f assert name isinf any item prefix writeline line write_async_compile_wait - None prefix splice async_compile wait globals del async_compile write_args input_names list str lhs = join input_names len input_names == lhs += prefix writeline f lhs = args prefix writeline args clear write_launcher_fn_call_get_indent - int config graph_partition prefix splice Runner __init__ partitions partitions = partitions recursively_apply_fns fns new_callables = fn c zip fns partitions new_callables append fn c partitions = new_callables call args prefix_indent = prefix splice f launcher_fn_name args prefix_indent = prefix_indent get_graph_input_names - list str V graph graph_input_names write_prefix - None assert launcher_fn_name None write_async_compile_wait prefix_indent = write_launcher_fn_call_get_indent prefix indent prefix_indent config triton debug_sync_graph prefix writeline V graph device_ops synchronize phase = V graph get_training_phase config annotate_training prefix writeline f training_annotation = nvtx _device_range_start phase graph_input_names = get_graph_input_names write_args graph_input_names codegen_inputs avoid duplicating asserts both partition functions call function when using cudagraph partition is_using_cudagraph_partition is_codegen_graph_partition_subgraph codegen_input_size_and_nan_asserts codegen_input_size_and_nan_asserts - None config size_asserts codegen_input_size_asserts config nan_asserts codegen_input_nan_asserts function below takes graph name input so stream caching happens per graph instance important nested subgraph codegening write_get_raw_stream device_idx int graph_name str - str write_get_raw_stream_header name = f stream device_idx config triton autotune_at_compile_time kernel_autotune_calls writeline f name = get_raw_stream device_idx V graph cpp_wrapper For cpp wrapper no need continue codegen main body name writeline f name = get_raw_stream device_idx name get_codegened_graph codegened_graph_stack - push_codegened_graph graph codegened_graph_stack append graph pop_codegened_graph codegened_graph_stack pop push_computed_sizes computed_sizes copy deepcopy computed_sizes_stack append deepcopy computed_sizes pop_computed_sizes computed_sizes_stack pop next_kernel_suffix - str f next _names_iter codegen_device_guard_enter device_idx int - None writeline EnterDeviceContextManagerLine device_idx last_seen_device_guard_index config triton autotune_at_compile_time mimic logic EnterDeviceContextManagerLine codegen autotune code block write_triton_header_once kernel_autotune_calls writeline f V graph device_ops device_guard device_idx kernel_autotune_calls do_indent is_codegen_graph_partition_subgraph Need get_raw_stream subgraph write_get_raw_stream_header kernel_autotune_calls writeline f stream device_idx = get_raw_stream device_idx last_seen_device_guard_index = device_idx codegen_device_guard_exit - None writeline ExitDeviceContextManagerLine config triton autotune_at_compile_time kernel_autotune_calls do_unindent generate_return output_refs list str - None output_refs config nan_asserts wrapper_call writeline return_vars = + join output_refs + wrapper_call writeline var return_vars wrapper_call do_indent wrapper_call writeline isinstance var torch Tensor wrapper_call do_indent wrapper_call writeline assert var isnan any item wrapper_call writeline assert var isinf any item wrapper_call do_unindent wrapper_call writeline + join output_refs + wrapper_call writeline generate_before_suffix result IndentedBuffer - None generate_after_suffix result IndentedBuffer - None config graph_partition all_partition_name_list = join all_partition_names + len all_partition_names == result splice f runner = Runner partitions= all_partition_name_list call = runner call recursively_apply_fns = runner recursively_apply_fns generate_end result IndentedBuffer - None generate_fallback_kernel node ir FallbackKernel - None writeline ExternKernelAllocLine node generate_extern_kernel_alloc node ir ExternKernelAlloc node codegen_comment writeline ExternKernelAllocLine node isinstance node layout ir Layout node codegen_size_asserts _generate_extern_kernel_alloc_helper extern_kernel args If s NoneLayout then extern_kernel should essentially treated doesn t anything no_return = isinstance extern_kernel layout ir NoneLayout output_name = extern_kernel get_name origin_node = extern_kernel get_origin_node kernel_name = extern_kernel get_kernel_name ending = ending config memory_planning view_as_complex kernel_name view operation fallbacks cause issues since inductor doesn t know memory still needed might reuse ending = f clone ending no_return writeline f declare kernel_name join args ending writeline f declare output_name = kernel_name join args ending supports_intermediate_hooks config generate_intermediate_hooks origin_node None counters inductor intermediate_hooks += writeline f run_intermediate_hooks origin_node name r output_name generate_extern_kernel_out node ir ExternKernelOut - None node codegen_comment writeline ExternKernelOutLine node _generate_extern_kernel_out_helper kernel str out str out_view Optional str args list str device str stack_traces Optional OrderedSet str = None - None add debug printer code triton kernel calls jit inductor level debug_printer_manager = V graph wrapper_code debug_printer debug_printer_manager set_printer_args args kernel None None extern args append f out= out_view out_view out debug_printer_manager writeline f kernel join args _generate_tma_descriptor_call_experimental desc apply_size_hints=False dims = desc dims block_dims = desc block_dims apply_size_hints dims = tuple V graph sizevars atomically_apply_size_hint d d dims block_dims = tuple V graph sizevars atomically_apply_size_hint d d block_dims ptr = f desc tensor codegen_reference data_ptr Explicitly call Python version val_to_arg_str dims = join PythonWrapperCodegen val_to_arg_str dim dim dims block_dims = join PythonWrapperCodegen val_to_arg_str dim dim block_dims element_size = PythonWrapperCodegen val_to_arg_str desc element_size prefix = triton tools experimental_descriptor fn = f prefix create_ desc rank d_tma_descriptor args = f ptr dims block_dims element_size call = f fn args call _generate_tma_descriptor_call_stable desc apply_size_hints=False block_shape = desc block_shape apply_size_hints block_shape = tuple V graph sizevars atomically_apply_size_hint d d block_shape prefix = triton tools tensor_descriptor TensorDescriptor fn = f prefix from_tensor args = f desc tensor codegen_reference block_shape call = f fn args call _generate_tma_descriptor_call desc apply_size_hints=False isinstance desc ir TMADescriptorExperimental _generate_tma_descriptor_call_experimental desc apply_size_hints assert isinstance desc ir TMADescriptorStable _generate_tma_descriptor_call_stable desc apply_size_hints generate_tma_descriptor desc call = _generate_tma_descriptor_call desc line = f desc name = call ending writeline line generate_scatter_fallback node ir ScatterFallback writeline ScatterFallbackLine node _generate_scatter_fallback output inputs cpp_kernel_name python_kernel_name src_is_tensor reduce kwargs line = f python_kernel_name join map str inputs python_kernel_name startswith aten scatter_reduce line += join + kwargs reduce line += f reduce= repr reduce line += writeline line generate_index_put_fallback node ir IndexPutFallback - None Collect index tensors into list indices list Optional ir IRNode = valid_indices = node inputs iter_valid_indices = iter valid_indices i _ enumerate node indices node indices i None index = next iter_valid_indices assert isinstance index ir IRNode indices append index indices append None writeline IndexPutFallbackLine node indices _generate_index_put_fallback kernel x indices values accumulate indices_str = f join indices args = x indices_str values accumulate writeline wrap_kernel_call kernel args generate_fallback_kernel_with_runtime_lookup buf_name str python_kernel_name str get_args Callable Sequence str op_overload Union torch _ops OpOverload torch _ops HigherOrderOperator raw_args Sequence Any outputs Sequence ir Buffer - None writeline f buf_name = python_kernel_name join get_args generate is_inference dynamo_timed PythonWrapperCodegen generate _generate is_inference get_wrapper_call_indent - int config graph_partition contextlib contextmanager set_writeline new Callable None - Iterator Callable None old = writeline try writeline = new type ignore method-assign yield new finally writeline = old type ignore method-assign _write_multi_kernel_defs - None kernel_defs = multi_kernel_state kernel_defs config triton autotune_at_compile_time kernel_autotune_defs splice kernel_defs header splice kernel_defs _generate is_inference config profile_bandwidth write_triton_header_once contextlib ExitStack stack stack enter_context wrapper_call indent config profiler_mark_wrapper_call generate_profiler_mark_wrapper_call stack config profile_bandwidth generate_start_graph run_wrapper_ir_passes is_inference config triton store_cubin config triton autotune_at_compile_time generate_reset_kernel_saved_flags At point we shouldn t generate any new memory planning lines Override writeline point wrapper call case gets called set_writeline wrapper_call writeline line lines isinstance line WrapperLine pyrefly ignore missing-attribute line codegen wrapper_call wrapper_call writeline line _write_multi_kernel_defs output_refs = get_output_refs mark_output_type config triton debug_sync_graph wrapper_call writeline V graph device_ops synchronize config profile_bandwidth generate_end_graph config triton store_cubin config triton autotune_at_compile_time generate_save_uncompiled_kernels config triton autotune_at_compile_time generate_and_run_autotune_block cpp_wrapper currently doesn t support nvtx config annotate_training config cpp_wrapper wrapper_call writeline nvtx _device_range_end training_annotation generate_return output_refs Assemble final code sections result = IndentedBuffer result splice imports result writeline result splice header We do want cpp header intermediate const graph Headers would rendered main module instead V graph aot_mode V graph cpp_wrapper V graph is_const_graph result = IndentedBuffer Add subgraph definitions result result splice subgraph_definitions finalize_prefix result splice prefix wrapper_call_indent = get_wrapper_call_indent result indent wrapper_call_indent result splice wrapper_call generate_before_suffix result result splice suffix generate_after_suffix result generate_end result add_benchmark_harness result result getvaluewithlinemap kernel_declarations getvaluewithlinemap generate_and_run_autotune_block Compose kernel_autotune_defs kernel_autotune_calls into single block code execute trigger Triton kernel compilation auto-tuning kernel_autotune_defs splice async_compile wait globals del async_compile scope = type ignore var-annotated config triton autotune_at_compile_time V graph autotuning_inputs scope = get_autotuning_input_name idx v type ignore attr-defined idx v enumerate V graph autotuning_inputs tuning_code = kernel_autotune_defs getvalue + \n + kernel_autotune_calls getvalue output_code_log level == logging DEBUG Save autotuning code block into file Create temporary file tempfile NamedTemporaryFile dir=cache_dir suffix= py delete=False f f write tuning_code encode utf- file_path = f name output_code_log debug Auto-tuning code written s file_path trace_structured artifact metadata_fn=lambda name inductor_autotune_at_compile_time_code encoding string payload_fn=lambda tuning_code Execute code autotune kernels try exec tuning_code scope except Exception e raise RuntimeError f Failed run autotuning code block e e memory_plan memory_planning MemoryPlanner lines = MemoryPlanner plan lines memory_plan_reuse outputs = get_graph_outputs out_names = V graph _get_output_names outputs while lines isinstance lines - MemoryPlanningLine TODO seems legit NullLine has no node lines - node name out_names type ignore attr-defined these lines will pointless lines pop codegen allocations two passes planning_states = MemoryPlanningState past_planning_states = i range len lines line = lines i isinstance line MemoryPlanningLine lines i = line plan planning_states - isinstance line EnterSubgraphLine planning_states append MemoryPlanningState isinstance line ExitSubgraphLine past_planning_states append planning_states pop past_planning_states append planning_states pop assert len planning_states == conservatively use sum all allocated buffer sizes potentially nested scopes total allocated size FIXME rec used _total_allocated_buffer_size = sum s total_allocated_buffer_size s past_planning_states run_wrapper_ir_passes is_inference bool We disable planning during training because presently increases peak memory consumption is_inference config memory_planning memory_plan config allow_buffer_reuse estimate_peak = EfficientPeakEstimate memory_plan_reuse codegen_input_symbol_assignment name str value ir TensorBox bound_vars OrderedSet sympy Symbol code = prefix functools cache sizeof name code writeline f name _size = name size f name _size functools cache strideof name code writeline f name _stride = name stride f name _stride isinstance value sympy Expr isinstance value sympy Symbol value bound_vars code writeline f value = name bound_vars add value isinstance value ir TensorBox dim size enumerate value get_size isinstance size sympy Symbol size bound_vars code writeline f size = sizeof name dim bound_vars add size dim stride enumerate value get_stride isinstance stride sympy Symbol stride bound_vars code writeline f stride = strideof name dim bound_vars add stride isinstance value ir TorchBindObject isinstance value ir GeneratorState torch _inductor config graph_partition pass raise AssertionError f Unknown value type type value codegen_inputs Assign all symbolic shapes locals bound_vars = OrderedSet sympy Symbol There subtle case cpp wrapper codegen which requires generating symbol inputs first followed non-symbol ones When dynamic size constraint specified Export time expression we need solve expression proper define symbol cpp Thus we enforcing iterating order here make sure all plain size symbols defined first graph_inputs = get_graph_inputs inputs = k v k v graph_inputs items isinstance v sympy Symbol + k v k v graph_inputs items isinstance v sympy Symbol name value inputs codegen_input_symbol_assignment name value bound_vars _verify_input_symbol_assignment value ir TensorBox bound_vars OrderedSet sympy Symbol expr chain from_iterable value get_size value get_stride isinstance expr Expr isinstance expr sympy Symbol continue undefined_symbols = sym sym expr free_symbols sym bound_vars len undefined_symbols raise AssertionError f For expr expected undefined_symbols have been codegen-ed For inputs size strides which contain sympy expressions we can encounter symbols weren t defined yet Now let s check each symbol defined _ value inputs isinstance value ir TensorBox continue _verify_input_symbol_assignment value bound_vars ensure_size_computed sym sympy Symbol isinstance sym sympy Symbol symbol_is_type sym SymT PRECOMPUTED_SIZE sym computed_sizes computed_sizes add sym expr = V graph sizevars inv_precomputed_replacements sym arg = SymbolicCallArg sym expr writeline SymbolicCallArgLine arg V graph finalize_prefix pass codegen_cpp_sizevar x Expr simplify bool = True - str raise RuntimeError codegen_cpp_sizevar only implemented cpp_wrapper codegen_python_sizevar x Expr simplify bool = True - str pexpr x simplify=simplify codegen_sizevar x Expr - str codegen_python_sizevar x codegen_tuple_access basename str name str index str - str f basename index codegen_python_shape_tuple shape Sequence Expr - str parts = map codegen_python_sizevar shape len parts == len parts == f parts f join parts codegen_shape_tuple shape Sequence Expr - str codegen_python_shape_tuple shape codegen_alloc_from_pool name offset dtype shape stride - tuple str list str alloc_from_pool format join name pexpr offset bytes numel str dtype codegen_python_shape_tuple shape codegen_python_shape_tuple stride codegen_reinterpret_view data size stride offset writeline Callable None dtype=None - str size == data layout size stride == data layout stride offset == data layout offset dtype None dtype = data dtype f aten view dtype data get_name dtype f data get_name size = codegen_python_shape_tuple size stride = codegen_python_shape_tuple stride offset = codegen_sizevar offset dtype None dtype = data dtype f aten view dtype reinterpret_tensor data get_name size stride offset dtype f reinterpret_tensor data get_name size stride offset codegen_device_copy src dst non_blocking Union bool str writeline f dst copy_ src non_blocking codegen_multi_output node ir MultiOutput result_name = node get_name arg_name = node input_name writeline MultiOutputLine result_name arg_name node indices codegen_dynamic_select_index node clamp index_str = f node index + node size node index node index clamp index_str = f max min node size index_str writeline f node unbacked_offset_symbol = node base_offset + node base_dim_stride index_str record unbacked_symbol_decls so we won t generate declaration symbol again unbacked_symbol_decls add str node unbacked_offset_symbol codegen_dynamic_slice_size node clamp_index x pos = codegen_sizevar sympy Max sympy Min x node size neg = codegen_sizevar sympy Max sympy Min x + node size node size f pos x = neg codegen_with_step start_var end_var step step == f end_var - start_var step_ = codegen_sizevar step f end_var - start_var + step_ - step_ codegen start end sym = node unbacked_size_symbol start = clamp_index node start end = clamp_index node end writeline f sym _start = start writeline f sym _end = end with_step = codegen_with_step f sym _start f sym _end node step writeline f sym = max with_step unbacked_symbol_decls add str node unbacked_size_symbol codegen_dynamic_scalar node writeline DynamicScalarLine node _codegen_dynamic_scalar node data = t codegen_reference t node inputs len node keypath == writeline f node sym = data item len node keypath == isinstance node keypath ConvertIntKey writeline f node sym = data item len node keypath == isinstance node keypath DivideByKey writeline f node sym _undivided = data item writeline f assert node sym _undivided node keypath divisor == f f node sym _undivided divisible node keypath divisor writeline f node sym = node sym _undivided node keypath divisor raise AssertionError f unrecognized keypath node keypath No one should ever use buffer uniformity define variable assign None writeline f node get_name = None benchmark_compiled_module output add_fake_input name shape stride device dtype output writeline f name = rand_strided f codegen_python_shape_tuple shape f codegen_python_shape_tuple stride f device= device dtype= dtype add_expr_input name val output writeline f name = val add_torchbind_input name value pickle assert isinstance value torch ScriptObject output writeline f name = pickle loads pickle dumps value r output writelines benchmark_compiled_module times= repeat= output indent output splice torch _dynamo testing rand_strided torch _inductor utils print_performance strip=True name value V graph constants items all constants global variables s why we need these global var_name lines output writeline f global name add_fake_input name value size value stride value device value dtype len V graph torchbind_constants output writeline pickle name torchbind_obj V graph torchbind_constants items all constants global variables s why we need these global var_name lines output writeline f global name add_torchbind_input name torchbind_obj name value V graph graph_inputs items isinstance value sympy Symbol isinstance V graph sizevars var_to_val get value None SingletonInt Inductor should only work dense - dense graph SingletonInts belong metadata should only live subclass continue isinstance value ir TorchBindObject len V graph torchbind_constants == otherwise we have already imported pickle package output writeline pickle output writeline f global name add_torchbind_input name value get_real_obj isinstance value sympy Expr Don t need add symbolic TODO fallback those below actually will generate possibly invalid benchmark code because s guaranteed actually valid value kernel question See https github com pytorch pytorch issues add_expr_input name V graph sizevars size_hint value fallback= isinstance value ir GeneratorState add_expr_input name f torch cuda default_generators value device index graphsafe_get_state shape = V graph sizevars size_hint x fallback= x value get_size stride = V graph sizevars size_hint x fallback= x value get_stride add_fake_input name shape stride value get_device value get_dtype call_str = f call join V graph graph_inputs keys output writeline f fn = lambda call_str output writeline print_performance fn times=times repeat=repeat add_benchmark_harness output Append benchmark harness generated code debugging config benchmark_harness benchmark_compiled_module output output writelines __name__ == __main__ output indent output writelines torch _inductor wrapper_benchmark compiled_module_main f compiled_module_main get_benchmark_name benchmark_compiled_module define_kernel kernel_name str kernel_body str metadata Optional str = None gpu bool = True cpp_definition Optional str = None writeline KernelDefinitionLine kernel_name kernel_body metadata=metadata gpu=gpu cpp_definition=cpp_definition staticmethod _format_kernel_definition kernel_name str kernel_body str metadata Optional str = None config triton autotune_at_compile_time metadata Generating autotune block Need replace C++ comment starter Python comment starter metadata = re sub r ^ metadata flags=re MULTILINE metadata_comment = f metadata \n metadata body = f \n\n metadata_comment kernel_name = kernel_body body _define_kernel_helper kernel_name str kernel_body str metadata Optional str = None gpu bool = True cpp_definition Optional str = None config triton autotune_at_compile_time body = _format_kernel_definition kernel_name kernel_body metadata=metadata kernel_autotune_defs splice body V graph cpp_wrapper For cpp wrapper no need continue codegen main body body = _format_kernel_definition kernel_name kernel_body metadata=metadata header splice body define_subgraph_launcher_fn name str subgraph_code subgraph_definitions splice subgraph_code value define_user_defined_triton_kernel kernel configs kwargs restore_value_args reset_to_zero_args grids list list Union int sympy Expr runtime triton_heuristics config_to_dict FixedGrid PrecomputedGrid common ConstexprArg KernelArgType SizeArg TensorArg TMADescriptorArg triton gen_common_triton_imports TritonKernel original_name = kernel __name__ signature list KernelArgType = constants dict str Any = arg_indices list int = equal_to_ _args list str = add_to_signature idx arg signature append arg arg_indices append idx add_arg idx arg is_constexpr=False equals_ =False equals_none=False is_constexpr triton_version_uses_attrs_dict tl constexpr args appear signature new versions triton old versions triton add_to_signature idx arg arg name kwargs arg may appear kwargs autotuned arg case will added triton_heuristics after autotuning constants arg name = kwargs arg name only case where arg name isn t kwargs should when arg constexpr assert arg name kwargs equals_ triton_version_uses_attrs_dict new versions triton add equal-to- arg signature labeled constexpr add arg constant new versions triton add equal-to- arg signature labeled e g i add arg constant add_to_signature idx ConstexprArg name=arg name add_to_signature idx arg constants arg name = equals_none triton_version_uses_attrs_dict new versions triton add none arg signature constexpr arg constant old versions triton include none arg constant signature add_to_signature idx ConstexprArg name=arg name constants arg name = None add_to_signature idx arg arg_names = p name p kernel params constexprs = p num p kernel params p is_constexpr idx key enumerate arg_names idx constexprs add_arg idx ConstexprArg name=key is_constexpr=True continue key kwargs continue arg = kwargs key kwargs key None add_arg idx ConstexprArg name=key equals_none=True isinstance arg ir TMADescriptor api_type block_shape dtype = stable arg block_shape arg tensor get_dtype isinstance arg ir TMADescriptorStable experimental None None add_arg idx TMADescriptorArg name=key api_type=api_type block_shape=block_shape dtype=dtype isinstance arg ir Buffer add_arg idx TensorArg name=key buffer=arg get_name dtype=arg get_dtype isinstance arg ir ReinterpretView ReinterpretView we use underlying buffer name note possibly non-zero offset relative underlying buffer add_arg idx TensorArg name=key buffer=arg data get_name dtype=arg get_dtype offset=arg layout offset equals_ = isinstance arg int sympy Integer V graph sizevars statically_known_equals arg type ignore arg-type add_arg idx SizeArg key arg equals_ =equals_ triton_signature = signature_to_meta signature size_dtype=None try infer based symints indices=arg_indices argdefs= ArgName x x kernel arg_names triton_meta dict str Any = signature triton_signature device DeviceProperties create V graph get_current_device_or_throw Triton compiler includes equal_to_ args into constants even when they constexpr otherwise there may segfault during launching Inductor-compiled Triton kernel TODO aakhundov add None args constants too currently causes CUDA errors test_aot_inductor test_triton_kernel_with_none_input https github com pytorch pytorch issues #issuecomment- https github com triton-lang triton blob efe ed d f c e b efe d python triton runtime jit py#L constants constants dict fromkeys equal_to_ _args configs config_of signature indices=arg_indices restore_value_args triton_meta restore_value = tuple restore_value_args reset_to_zero_args triton_meta reset_to_zero = tuple reset_to_zero_args len grids == compute grid wrapper pass arg inductor_meta dict str Any = FixedGrid setup_grid_as_args extra_launcher_call_args = map sympy sympify grids rename_sizes_for_launcher expr Union int sympy Expr - sympy Expr isinstance expr sympy Expr symbols = expr free_symbols symbols expr symbols sort key=str sym symbols sym extra_launcher_args continue extra_launcher_args sym = sympy Symbol f _launcher_s len extra_launcher_args sympy_subs expr extra_launcher_args assert isinstance expr int sympy Integer expr extra_launcher_args dict sympy Symbol sympy Symbol = grids = map rename_sizes_for_launcher grid grid grids assert grids len grids == len configs precomputed_grids = grid cfg sorted zip grids configs key=lambda x len x kwargs reverse=True precomputed_grids append config config_to_dict cfg python map pexpr grid cpp map cexpr grid python_slow map pexpr grid inductor_meta = grid_type PrecomputedGrid __name__ precomputed_grids precomputed_grids extra_launcher_args map str extra_launcher_args values extra_launcher_call_args = extra_launcher_args keys Distinguish between different functions using function id cache_key Any = id kernel fn len configs arg kwargs values We need key non tensor arg only autotune mode isinstance arg ir Buffer ir ReinterpretView cache_key append arg cache_key append str triton_meta cache_key extend str inductor_meta cache_key = tuple cache_key cache_key user_defined_kernel_cache user_defined_kernel_cache cache_key extra_launcher_call_args name = f original_name _ len user_defined_kernel_cache compile_wrapper = IndentedBuffer config triton unique_user_kernel_names compile_wrapper writeline f async_compile triton name r compile_wrapper writeline f async_compile triton original_name r inductor_meta kernel_name = name inductor_meta update TritonKernel inductor_meta_common compile_wrapper splice gen_common_triton_imports compile_wrapper splice f triton_heuristics user_autotune configs= map config_to_dict configs r inductor_meta= inductor_meta r triton_meta= triton_meta r filename=__file__ custom_kernel=True triton jit kernel_src = user_defined_triton_kernel_transitive_closure_source_code kernel config triton unique_user_kernel_names We replace original_name unique name kernel_src = kernel_src replace f original_name f name kernel_src = kernel_src replace \\ \\ \\ compile_wrapper splice kernel_src current_device = V graph get_current_device_or_throw compile_wrapper writeline f device_str= current_device type _ lineno = inspect getsourcelines kernel fn srcfile = inspect getsourcefile kernel fn metadata = f Original path srcfile lineno define_kernel name compile_wrapper getvalue metadata Add cache next use user_defined_kernel_cache cache_key = name triton_meta name triton_meta extra_launcher_call_args generate_numel_expr kernel_name str tree suffix Optional str = None sym_name = f kernel_name _ tree prefix numel suffix None sym_name += f _ suffix sym = sympy Symbol sym_name is_integer=True is_positive=True We can get symbolic expressions here like s It fine have them here we need handle them correctly their own type This tricky do so we wrap custom type distinct scalars also sympy scalars well This handled ` generate_args_decl ` which has correct comment TODO only works constant now need type info I agree needs type info while true type info suffices type hint purposes producing correct code type arg = SymbolicCallArg sym tree numel is_benchmark_kernel = kernel_name == is_benchmark_kernel writeline SymbolicCallArgLine arg V graph arg _generate_symbolic_call_arg_helper arg SymbolicCallArg graph GraphLowering - None writeline f arg inner = pexpr arg inner_expr generate_workspace_allocation ws WorkspaceArg name = ws get_name line = AllocateLine ws ws zero_mode == WorkspaceZeroMode UNINITIALIZED writeline line ws zero_mode == WorkspaceZeroMode ZERO_ON_CALL writeline line writeline make_zero_buffer name ws zero_mode == WorkspaceZeroMode ZERO_PER_GRAPH prior = allocated_workspaces get name prior assert isinstance prior AllocateLine isinstance prior node WorkspaceArg expand existing allocation prior node = WorkspaceArg maximum prior node ws writeline line writeline make_zero_buffer name allocated_workspaces name = line raise AssertionError ws zero_mode config triton autotune_at_compile_time kernel_autotune_calls writeline PythonWrapperCodegen make_allocation name ws device ws dtype shape= V graph sizevars size_hint ws count stride= ws zero_mode = WorkspaceZeroMode UNINITIALIZED kernel_autotune_calls writeline PythonWrapperCodegen make_zero_buffer name generate_workspace_deallocation ws WorkspaceArg ws zero_mode = WorkspaceZeroMode ZERO_PER_GRAPH writeline FreeIfNotReusedLine ws make_zero_buffer name f name zero_ ending wrap_kernel_call name call_args f name join call_args ending generate_profiler_mark_wrapper_call stack wrapper_call writeline torch profiler record_function wrapper_call writeline f record_function graph_ V graph graph_id _inductor_wrapper_call stack enter_context wrapper_call indent generate_start_graph wrapper_call writeline start_graph generate_end_graph wrapper_call writeline f end_graph config profile_bandwidth_output r generate_reset_kernel_saved_flags wrapper_call splice f kernel globals values isinstance kernel triton_heuristics __name__ CachingAutotuner kernel cuda_kernel_saved = False generate_save_uncompiled_kernels Precompile save CUBINs Triton kernels haven t been precompiled saved side effect running generated JIT model Python wrapper This can happen when model contains control flow only one pass through control flow operators covers kernels saved remaining kernels launched hence saved The main purpose codegen compile save Triton kernels outside active control flow path subsequent AOTInductor code generation compilation wrapper_call splice f kernel globals values isinstance kernel triton_heuristics __name__ CachingAutotuner kernel cuda_kernel_saved len kernel launchers == kernel precompile kernel save_gpu_kernel stream= stream use dummy stream launcher=kernel launchers prepare_triton_kernel_call call_args wrap_arg arg isinstance arg str dynamo wraps unspec variable d CPU tensor need convert scalar arg + item should_unwrap_unspec_arg arg arg isinstance arg int float bool SymbolicCallArg str arg pexpr V graph sizevars simplify arg wrap_arg arg arg call_args generate_example_arg_value arg arg_type raw_arg=None isinstance arg_type torch_dtype isinstance raw_arg ir TMADescriptor first we generate underlying buffer buf_name = raw_arg get_tensor get_name buf = args_to_buffers arg args_to_buffers get arg buf_name = arg buf = args_to_buffers arg assert raw_arg None V graph get_buffer arg raw_arg can t None same time buf_name = f tmp_arg_ kernel_autotune_tmp_arg_idx buf = raw_arg kernel_autotune_tmp_arg_idx += assert buf None f Failed find buffer arg arg size = tuple V graph sizevars atomically_apply_size_hint e fallback=config unbacked_symint_fallback e buf get_size allocation_size = tuple V graph sizevars atomically_apply_size_hint e fallback=config unbacked_symint_fallback e V graph get_allocation_size buf stride = tuple V graph sizevars atomically_apply_size_hint e fallback=config unbacked_symint_fallback e buf get_stride device = buf get_device dtype = buf get_dtype offset = V graph sizevars size_hint buf get_layout offset fallback=config unbacked_symint_fallback value = f generate_example_value size stride device dtype offset allocation_size kernel_autotune_calls writeline f buf_name = value isinstance raw_arg ir TMADescriptor generate another line initializing host-side TMA descriptor underlying buffer created above value = _generate_tma_descriptor_call desc=raw_arg apply_size_hints=True buf_name = arg kernel_autotune_calls writeline f buf_name = value buf_name issubclass arg_type sympy Basic isinstance arg SymbolicCallArg arg symbol symbolic expression isinstance arg str arg _meta_vars arg raw_arg None None arg = raw_arg isinstance arg SymbolicCallArg arg = arg inner_expr arg V graph sizevars inv_precomputed_replacements arg = V graph sizevars inv_precomputed_replacements arg str V graph sizevars atomically_apply_size_hint arg fallback=config unbacked_symint_fallback isinstance arg str int float bool str arg isinstance arg list f join generate_example_arg_value type arg raise NotImplementedError f Unsupported type type arg _grid_dim_str grid_per_dim isinstance grid_per_dim list + join _grid_dim_str item item grid_per_dim + pexpr grid_per_dim generate_kernel_call kernel_name str call_args device=None triton=True arg_types=None raw_keys=None raw_args=None triton_meta=None original_fxnode_name=None Generates kernel call code triton Defines whether backend uses Triton codegen Otherwise uses CUDA language when gpu=True C++ when gpu=False Store buffers corresponding each call arg This used generate example args autotuning later args_to_buffers update arg V graph try_get_buffer arg arg call_args isinstance arg str device = device V graph get_current_device_or_throw writeline KernelCallLine kernel_name=kernel_name call_args=call_args pyrefly ignore bad-argument-type raw_keys=raw_keys pyrefly ignore bad-argument-type raw_args=raw_args pyrefly ignore bad-argument-type arg_types=arg_types triton=triton pyrefly ignore bad-argument-type triton_meta=triton_meta device=device graph_name=V graph name pyrefly ignore bad-argument-type original_fxnode_name=original_fxnode_name _generate_kernel_call_helper kernel_name str call_args device=None triton=True arg_types=None raw_keys=None raw_args=None triton_meta=None graph_name= original_fxnode_name=None device = device V graph get_current_device_or_throw triton device type = cuda device type == cpu writeline wrap_kernel_call kernel_name call_args device type == mps TODO Fix me MPS does expose streams now writeline wrap_kernel_call f kernel_name generated_kernel call_args raise RuntimeError f device device type nyi call_args_str = prepare_triton_kernel_call call_args call_args_str = join call_args_str stream_name = PythonWrapperCodegen write_get_raw_stream device index graph_name triton stream_ptr = f c_void_p stream_name writeline f kernel_name kernel_name call_args_str stream_ptr write_triton_header_once config triton autotune_at_compile_time kernel_name kernel_autotune_names Create example args autotune separate epilogue assert arg_types None len call_args == len arg_types call_args arg_types do match autotune_args = None original_fxnode_name V graph autotuning_mapping autotune_args = V graph autotuning_mapping get original_fxnode_name None get_autotune_deletion_call - str After all autotune kernel calls have been written i e kernel_autotune_example_args complete returns deletion call all autotune example tensors unnecessary after kernel_name called tensors_to_delete = tensor tensor kn kernel_autotune_example_args values kn == kernel_name tensors_to_delete f del join tensors_to_delete \n infer_arg_by_inputs raw_keys raw_args idx reused_args We try infer raw_arg i e raw_args idx remaining raw_args This particularly useful jagged cases where dimension often being passed input target_arg = raw_args idx target_arg reused_args True i raw_key raw_arg enumerate zip raw_keys raw_args i == idx isinstance raw_arg IRNode continue triton_input = autotune_args raw_key autotune_args triton_input = get_autotuning_input_name type ignore attr-defined autotune_args raw_key triton_input == continue try layout = raw_arg get_layout dim s enumerate layout size s == target_arg reused_args target_arg = f triton_input shape dim True except NotImplementedError If layout IRNode implemented we could just skip Only raise other Error cases continue False all_args = raw_args None create dummy raw_args uniform behavior following loop assert raw_keys None keys None args raw_keys = None len call_args raw_args = None len call_args assert len raw_args == len call_args call_args raw_args do match reused_args = i arg arg_type raw_key raw_arg enumerate pyrefly ignore no-matching-overload zip call_args arg_types raw_keys raw_args key = None isinstance arg str = str arg arg may passed kwarg style then we need extract its value key arg = arg split = triton_input Optional str = None autotune_args raw_key autotune_args triton_input = get_autotuning_input_name type ignore attr-defined autotune_args raw_key triton_input arg_str = triton_input isinstance arg_type torch_dtype issubclass arg_type sympy Basic isinstance arg SymbolicCallArg reused_args raw_arg = arg_str raw_key == infer_arg_by_inputs raw_keys raw_args i reused_args Empty raw_key means arg s native triton kernel being added inductor arg_str = reused_args raw_arg isinstance arg_type torch_dtype workspace allocation already generated ` generate_workspace_allocation ` ` TritonKernel call_kernel ` re match r ^ workspace &#124; semaphore arg arg_str = arg arg kernel_autotune_example_args arg_str = generate_example_arg_value arg arg_type raw_arg arg_str = kernel_autotune_example_args arg kernel_autotune_example_args arg = arg_str kernel_name arg_str = generate_example_arg_value arg arg_type raw_arg all_args append arg_str key None f key = arg_str Make sure kernel launch under device guard because models don t always run device kernel_autotune_calls writeline f V graph device_ops device_guard device index kernel_autotune_calls do_indent kernel_autotune_calls writeline f kernel_name run join all_args stream= stream_name kernel_autotune_calls do_unindent kernel_autotune_calls writeline DelayReplaceLine del_call get_autotune_deletion_call del_call kernel_autotune_names add kernel_name V graph cpp_wrapper For cpp wrapper no need continue codegen main body add debug printer code triton kernel calls jit inductor level debug_printer_manager = V graph wrapper_code debug_printer debug_printer_manager set_printer_args call_args kernel_name arg_types None debug_printer_manager writeline f kernel_name run call_args_str stream= stream_name write_triton_header_once writeline line lines append line writelines lines line lines writeline line enter_context ctx lines append LineContext ctx val_to_arg_str s type_=None torch utils _triton has_triton_package has_triton_package triton isinstance s SymTypes pexpr s node expr isinstance s sympy Expr pexpr s isinstance s tuple list dataclasses dataclass Shim ref Any __repr__ ref Explicitly call Python version val_to_arg_str repr type s Shim PythonWrapperCodegen val_to_arg_str s isinstance s torch _ops OpOverload _get_qualified_name s isinstance s ir Buffer ir MutableBox ReinterpretView s codegen_reference has_triton_package isinstance s triton language dtype type ignore possibly-undefined repr s isinstance s ir GeneratorState s codegen_reference repr s The following methods memory management make_buffer_allocation buffer BufferLike device = buffer get_device dtype = buffer get_dtype shape = tuple buffer get_size allocation_shape = tuple V graph get_allocation_size buffer stride = tuple buffer get_stride is_pinned = buffer get_is_pinned make_allocation buffer get_name device dtype shape stride allocation_shape is_pinned cache_on_self write_memory_track_allocation_once import_str = torch _inductor runtime debug_utils check_memory_step track_tensor V graph cpp_wrapper imports splice import_str strip=True make_allocation name device dtype shape stride allocation_shape=None is_pinned=False allocation_shape None allocation_shape = shape codegen_shape_tuple = codegen_python_shape_tuple shape codegen_allocation_shape_tuple = codegen_python_shape_tuple allocation_shape codegen_stride_tuple = codegen_python_shape_tuple stride torch _inductor config test_configs track_memory_lifecycle out = f name = tracked_empty_strided f codegen_allocation_shape_tuple f codegen_stride_tuple f dtype= dtype f device= device type f name= name device type == cpu is_pinned out = f name = empty_strided_cpu_pinned f codegen_allocation_shape_tuple f codegen_stride_tuple f dtype device type cpu cuda xpu mtia optimized path faster allocations saving ~ us versus stuff below out = f name = empty_strided_ device type f codegen_allocation_shape_tuple f codegen_stride_tuple f dtype all other devices out = f name = empty_strided f codegen_allocation_shape_tuple f codegen_stride_tuple f device= device type dtype= dtype codegen_shape_tuple = codegen_allocation_shape_tuple need extra as_strided call out = out + f as_strided codegen_shape_tuple codegen_stride_tuple out make_comment line writeline CommentLine line make_tensor_alias new_name old_name comment= f declare new_name = old_name ending comment comment make_buffer_free buffer Union BufferLike ir TorchBindObject f del buffer get_name make_free_by_names names_to_del list str f del join name name names_to_del codegen_exact_buffer_reuse old_name str new_name str del_line str f declare_maybe_reference new_name = old_name del_line ending comment reuse write_provenance_debug_handle kernel_name debug_handle Optional int = None debug_handle None writeline f comment Provenance debug handles kernel_name debug_handle make_buffer_reuse old BufferLike new BufferLike delete_old bool assert old get_dtype == new get_dtype old_name = old get_name new_name = new get_name del_line = old_name V graph get_output_names delete_old del_line = f make_buffer_free old old get_size == new get_size old get_stride == new get_stride codegen_exact_buffer_reuse old_name new_name del_line reinterpret_view = codegen_reinterpret_view old new get_size new get_stride wrapper_call writeline f declare new_name = reinterpret_view del_line comment reuse codegen_deferred_allocation name str view ir ReinterpretView - None writeline DeferredLine name f declare name = view codegen_reference ending comment alias codegen_allocation buffer ir Buffer name = buffer get_name name V graph removed_buffers name allocated isinstance buffer ir DonatedBuffer ir SubgraphBuffer allocated add name isinstance buffer get_defining_op ir ExternKernelAlloc ir MultiOutput buffer should_allocate layout = buffer get_output_spec isinstance layout ir MutationLayoutSHOULDREMOVE isinstance layout ir NoneLayout isinstance layout ir NonOwningLayout assert isinstance layout view ir ReinterpretView f unexpected type layout view layout view box = layout view data assert isinstance box ir StorageBox type box input_buffer = box data assert isinstance input_buffer ir Buffer type box codegen_allocation input_buffer writeline ReinterpretLine input_buffer buffer layout isinstance layout ir CommBufferLayout writeline CommBufferAllocateLine buffer writeline AllocateLine buffer codegen_free buffer name = buffer get_name can freed reused isinstance buffer ir InputBuffer ir TorchBindObject writeline FreeLine buffer isinstance buffer get_output_spec ir CommBufferLayout Comm buffers eligible in-place reuse Their reuse achieved exclusively via buffer planning writeline CommBufferFreeLine buffer can_reuse buffer freed add name writeline FreeIfNotReusedLine buffer can_reuse input_buffer output_buffer=None name = input_buffer get_name name V graph removed_buffers name V graph graph_inputs isinstance V graph graph_inputs_original name ir DonatedBuffer name V graph constants name V graph torchbind_constants name V graph never_reuse_buffers name freed did_reuse buffer reused_buffer Check whether given buffer reused possible reuser wrapper codegen Can consulted inside ir codegen e g determine whether copy needed buffer get_name reuses reuses buffer get_name == reused_buffer get_name codegen_inplace_reuse input_buffer ir Buffer output_buffer ir Buffer assert can_match_buffer_size input_buffer output_buffer codegen_allocation input_buffer freed add input_buffer get_name allocated add output_buffer get_name reuses output_buffer get_name = input_buffer get_name writeline ReuseLine input_buffer output_buffer codegen_unbacked_symbol_decl symbol name = str symbol name unbacked_symbol_decls name When CppWrapperCpu we should only generate declaration once unbacked_symbol_decls add name declare + name codegen_unbacked_symbol_defs_for_outputs output_name str outputs Any unbacked_bindings Optional dict sympy Symbol pytree KeyPath - None unbacked_bindings = resolve_unbacked_bindings V graph sizevars shape_env unbacked_bindings writeline UnbackedSymbolDefsLine output_name outputs unbacked_bindings _codegen_unbacked_symbol_defs_for_outputs output_name str outputs Any unbacked_bindings Optional dict sympy Symbol pytree KeyPath - None unbacked_bindings This code designed generate code expressions symbolic paths keypaths associated certain symbols unbacked bindings These keypaths describe how access unbacked symbol structured way For example we might want generate u = outs stride where s = u keypath describes structure outs stride like SequenceKey CallMethodKey stride SequenceKey s keypath unbacked_bindings items ` go ` recursively constructs code expression processing each element keypath construct expression incrementally For example given output name outs keypath SequenceKey CallMethodKey stride generates outs based SequenceKey then recursively go outs CallMethodKey stride go expr str keypath pytree KeyPath keypath == expr len keypath = isinstance keypath CallMethodKey isinstance keypath pytree SequenceKey go f expr keypath name keypath idx keypath isinstance keypath CallMethodKey go f expr keypath name keypath isinstance keypath pytree SequenceKey go f std get keypath idx expr keypath V graph cpp_wrapper go f expr keypath idx keypath isinstance keypath DivideByKey TODO need assert divisibility TODO invalid C++ codegen go f expr __floordiv__ keypath divisor keypath raise AssertionError f unrecognized keypath keypath ` go_outer ` manages top-level logic generating final expression It handles special cases C++ code generation adjusts keypath based context e g single vs multiple outputs go_outer type ignore no-untyped-def V graph cpp_wrapper Special handling top level buffer access because get_name actually never bound individual output arguments bound generate_c_shim_fallback_kernel len outputs == out = outputs When fallback kernel returns list consisting single tensor output represented MultiOutput non empty indices In case we strip first key path away go outputs get_name keypath isinstance out ir MultiOutput len out indices = keypath assert isinstance keypath pytree SequenceKey go outputs keypath idx get_name keypath go output_name keypath writeline f codegen_unbacked_symbol_decl s = go_outer ending codegen_subgraph_by_inlining subgraph outer_inputs outer_outputs TODO desertfire - This function old way supporting subgraph codegen inlining subgraphs output code For python wrapper we have moved lifting subgraphs functions supported ` codegen_subgraph ` function However does work cpp wrapper With cpp wrapper we make two passes kernels shared first pass next Therefore both Python CppWrapper need share some codegen infra For now CppWrapperCpu has been updated lift subgraph functions Therefore cpp_wrapper first pass PythonWrapper we still fallback old way inlining subgraphs output code Once we update CppWrapperCpu we can remove function _codegen_subgraph_prefix assert len subgraph graph graph_inputs == len outer_inputs inner_input outer_input zip subgraph graph graph_inputs outer_inputs writeline f declare inner_input = outer_input ending _codegen_subgraph_suffix assert len subgraph graph graph_outputs == len outer_outputs inner_output outer_output zip subgraph graph graph_outputs outer_outputs writeline f outer_output = inner_output codegen_reference ending try push_codegened_graph subgraph graph writeline f comment subgraph subgraph name _codegen_subgraph_prefix parent_graph = V graph V set_graph_handler subgraph graph subgraph graph codegen_subgraph parent_graph=parent_graph _codegen_subgraph_suffix finally pop_codegened_graph codegen_partition_call partition_id int partition_signatures ir GraphPartitionSignature Generate code call graph partition input_deallocation = partition_signatures input_deallocation output_nodes = partition_signatures output_nodes input_names = list input_deallocation keys + symbol_input name symbol_input partition_signatures symbol_inputs inputs = join input_names + len input_names == output_names = node get_name node output_nodes outputs = join output_names + len output_nodes == Create list inputs subgraph call writeline f partition partition_id _args = inputs names_to_del = name name deallocate input_deallocation items deallocate names_to_del writeline f del join names_to_del Call subgraph launcher function writeline f outputs = partitions partition_id partition partition_id _args writeline f del partition partition_id _args set_all_partition_names num_partitions int all_partition_names = f partition_ idx idx range num_partitions codegen_subgraph_call_with_flattened_outputs subgraph outer_inputs outer_flattened_outputs Get input output names subgraph outer_output_names = join outer_flattened_outputs + len outer_flattened_outputs == outer_input_names = join outer_inputs + len outer_inputs == writeline f subgraph graph name _args = outer_input_names Call subgraph launcher function writeline f outer_output_names = subgraph graph name subgraph graph name _args codegen_subgraph_call subgraph outer_inputs outer_buffer_name Get input output names subgraph outer_input_names = join outer_inputs + len outer_inputs == writeline f subgraph graph name _args = outer_input_names Since buffers already put into args list we can free buffers here V graph scheduler free_buffers Call subgraph launcher function writeline f outer_buffer_name = subgraph graph name subgraph graph name _args codegen_subgraph_common subgraph push_codegened_graph subgraph graph make_comment make_comment f comment subgraph subgraph name parent_graph = V graph subgraph graph cpp_wrapper = parent_graph cpp_wrapper subgraph graph fx_wrapper = parent_graph fx_wrapper subgraph graph name already_codegened_subgraphs If already codegened parent wrapper already has subgraph fn name subgraph graph name V set_graph_handler subgraph graph do graph partition subgraph config patch graph_partition False Call codegen subgraph recursively subgraph_code _ = subgraph graph codegen subgraph_name = subgraph graph name already_codegened_subgraphs add subgraph_name define_subgraph_launcher_fn subgraph_name subgraph_code codegen_subgraph_with_flattened_outputs subgraph outer_inputs outer_flattened_outputs codegen_subgraph_common subgraph codegen_subgraph_call_with_flattened_outputs subgraph outer_inputs outer_flattened_outputs codegen_subgraph subgraph outer_inputs outer_buffer_name Codegen subgraph recursively calling codegen subgraph This lifts subgraph function output code codegen_subgraph_common subgraph codegen_subgraph_call subgraph outer_inputs outer_buffer_name codegen_invoke_subgraph invoke_subgraph name = invoke_subgraph get_name writeline f name = None len invoke_subgraph outputs outer_inputs = buf codegen_reference buf invoke_subgraph inputs V graph aot_mode outer_outputs = f name i i range len invoke_subgraph outputs codegen_subgraph_by_inlining invoke_subgraph subgraph outer_inputs outer_outputs codegen_subgraph invoke_subgraph subgraph outer_inputs name codegen_conditional conditional - None name = conditional get_name outer_inputs = buf codegen_reference buf conditional operands predicate = conditional predicate codegen_reference isinstance conditional predicate ir ShapeAsConstantBuffer move Tensor predicate host predicate = f predicate item writeline f name = None len conditional outputs writeline f predicate writeline EnterSubgraphLine conditional true_subgraph graph V graph aot_mode outer_outputs = f name i i range len conditional outputs codegen_subgraph_by_inlining conditional true_subgraph outer_inputs outer_outputs codegen_subgraph conditional true_subgraph outer_inputs name writeline ExitSubgraphLine writeline writeline EnterSubgraphLine conditional false_subgraph graph V graph aot_mode outer_outputs = f name i i range len conditional outputs codegen_subgraph_by_inlining conditional false_subgraph outer_inputs outer_outputs codegen_subgraph conditional false_subgraph outer_inputs name writeline ExitSubgraphLine codegen_while_loop while_loop stack_output while_loop codegened host side while_loop codegen_subgraph subgraph outer_inputs outer_outputs Helper method deduplicate subgraph codegen logic V graph aot_mode codegen_subgraph_by_inlining subgraph outer_inputs outer_outputs codegen_subgraph_with_flattened_outputs subgraph outer_inputs outer_outputs name = while_loop get_name outer_carried_inputs = buf codegen_reference buf while_loop carried_inputs outer_additional_inputs = buf codegen_reference buf while_loop additional_inputs ckp_offset = len outer_carried_inputs writeline f name = None len outer_carried_inputs stack_output writeline f name extend _ range len outer_carried_inputs i inp enumerate outer_carried_inputs set initial state before loop writeline f name i = inp cond_outer_inputs = f name i i range len outer_carried_inputs outer_additional_inputs cond_outer_outputs = f name _cond_result body_outer_inputs = list cond_outer_inputs same inputs cond_fn body_fn Carry over state body_fn Note We only carry over carried_inputs part inputs additional ones passed they re before body_outer_outputs = body_outer_inputs len outer_carried_inputs Check condition beginning set up flag codegen_subgraph while_loop cond_subgraph cond_outer_inputs cond_outer_outputs writeline f should_loop = cond_outer_outputs writeline should_loop stack_output Handle case when loop never executes i carried_input enumerate outer_carried_inputs writeline EnterSubgraphLine while_loop body_subgraph graph writeline f name i = carried_input unsqueeze clone writeline ExitSubgraphLine i carried_input enumerate outer_carried_inputs writeline EnterSubgraphLine while_loop body_subgraph graph writeline f name i = carried_input clone writeline ExitSubgraphLine writeline while should_loop Body execution writeline EnterSubgraphLine while_loop body_subgraph graph codegen_subgraph while_loop body_subgraph body_outer_inputs body_outer_outputs writeline ExitSubgraphLine Collect outputs enabled stack_output writeline EnterSubgraphLine while_loop body_subgraph graph i range len outer_carried_inputs writeline f name i + ckp_offset append name i writeline ExitSubgraphLine Condition check end loop writeline EnterSubgraphLine while_loop cond_subgraph graph codegen_subgraph while_loop cond_subgraph cond_outer_inputs cond_outer_outputs writeline ExitSubgraphLine writeline f should_loop = cond_outer_outputs Stack outputs after loop completion stack_output writeline Stack outputs after loop completion i range len outer_carried_inputs writeline f len name i + ckp_offset writeline EnterSubgraphLine while_loop body_subgraph graph writeline f name i = torch stack name i + ckp_offset dim= writeline ExitSubgraphLine staticmethod statically_known_int_or_none x try getattr x free_symbols None _maybe_evaluate_static will s s actual codegen will still generate full expression here None isinstance x int x val = V graph _shape_env _maybe_evaluate_static x val None val int val type ignore call-overload except Exception None staticmethod statically_known_list_of_ints_or_none lst result = x lst num = PythonWrapperCodegen statically_known_int_or_none x num None None result append num result staticmethod is_statically_known_list_of_ints lst PythonWrapperCodegen statically_known_list_of_ints_or_none lst None staticmethod static_shape_for_buffer_or_none buffer PythonWrapperCodegen statically_known_list_of_ints_or_none buffer get_size staticmethod can_prove_buffer_has_static_shape buffer PythonWrapperCodegen static_shape_for_buffer_or_none buffer None write_kernel_context_guard kernel_name str node_schedule Union Sequence BaseSchedulerNode ExternKernel write_kernel_context_guard_begin Mark beginning kernel context guard write_kernel_context_guard_end Mark end kernel context guard SubgraphPythonWrapperCodegen PythonWrapperCodegen A wrapper codegen generates code subgraph For most methods we rely implementation PythonWrapperCodegen But we override few functions produce cleaner code like avoiding writing imports twice output code __init__ subgraph_name str parent_wrapper PythonWrapperCodegen partition_signatures Optional ir GraphPartitionSignature = None It necessary set subgraph_name before calling super __init__ because __init__ calls set_launcher_fn_name subgraph_name = subgraph_name parent_wrapper = parent_wrapper partition_signatures = partition_signatures super __init__ set_launcher_fn_name - None This sets up name function containing launcher code subgraph pyrefly ignore bad-assignment launcher_fn_name = subgraph_name write_header - None pass add_benchmark_harness output pass benchmark_compiled_module output pass write_async_compile_wait pass next_kernel_suffix - str Ensures subgraphs kernels do clash each other parent_wrapper next_kernel_suffix generate_after_suffix result IndentedBuffer - None write_launcher_fn_call_get_indent - int prefix splice f launcher_fn_name args prefix_indent = prefix_indent get_wrapper_call_indent - int get_graph_inputs - dict str Union ir TensorBox ir TorchBindObject sympy Expr None signature = partition_signatures inputs = signature input_nodes &#124; str s s s signature symbol_inputs inputs = V graph graph_inputs inputs get_graph_input_names - list str signature = partition_signatures names = list signature input_nodes keys + symbol_input name symbol_input signature symbol_inputs names = V graph graph_input_names names get_graph_outputs - list IRNode signature = partition_signatures outputs = signature output_nodes outputs = V graph graph_outputs outputs codegen_allocation buffer ir Buffer name = buffer get_name signature = partition_signatures name signature input_nodes skip allocation buffer subgraph input This allows reusing input buffer graph partition although allowed general super codegen_allocation buffer cache_on_self write_triton_header_once - None TODO Uncomment future This will needed support subgraph codegen cpp wrapper config triton autotune_at_compile_time import_str = triton_header_str kernel_autotune_calls splice import_str parent_wrapper write_triton_header_once cache_on_self write_get_raw_stream_header_once - None TODO Uncomment future This will needed support subgraph codegen cpp wrapper config triton autotune_at_compile_time kernel_autotune_calls writeline V graph device_ops import_get_raw_stream_as get_raw_stream parent_wrapper write_get_raw_stream_header_once