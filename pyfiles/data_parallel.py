mypy allow-untyped-defs operator warnings collections abc Sequence itertools chain typing Any Generic Optional TypeVar Union torch torch _utils _get_all_device_indices _get_available_device_type _get_device_index _get_devices_properties torch nn modules Module torch nn parallel parallel_apply parallel_apply torch nn parallel replicate replicate torch nn parallel scatter_gather gather scatter_kwargs __all__ = DataParallel data_parallel _check_balance device_ids Sequence Union int torch device - None imbalance_warn = There imbalance between your GPUs You may want exclude GPU which has less than memory cores GPU You can do so setting device_ids argument DataParallel setting CUDA_VISIBLE_DEVICES environment variable device_ids = _get_device_index x True x device_ids dev_props = _get_devices_properties device_ids warn_imbalance get_prop values = get_prop props props dev_props min_pos min_val = min enumerate values key=operator itemgetter max_pos max_val = max enumerate values key=operator itemgetter min_val max_val warnings warn imbalance_warn format device_ids min_pos device_ids max_pos stacklevel= True False warn_imbalance lambda props props total_memory warn_imbalance lambda props props multi_processor_count T = TypeVar T bound=Module DataParallel Module Generic T r Implements data parallelism module level This container parallelizes application given attr ` module ` splitting input across specified devices chunking batch dimension other objects will copied once per device In forward pass module replicated each device each replica handles portion input During backwards pass gradients each replica summed into original module The batch size should larger than number GPUs used warning It recommended use ` ~torch nn parallel DistributedDataParallel ` instead do multi-GPU training even there only single node See ref ` cuda-nn-ddp-instead ` ref ` ddp ` Arbitrary positional keyword inputs allowed passed into DataParallel some types specially handled tensors will scattered dim specified default tuple list dict types will shallow copied The other types will shared among different threads can corrupted written model s forward pass The parallelized attr ` module ` must have its parameters buffers ` ` device_ids ` ` before running ` ~torch nn DataParallel ` module warning In each forward attr ` module ` replicated each device so any updates running module ` ` forward ` ` will lost For example attr ` module ` has counter attribute incremented each ` ` forward ` ` will always stay initial value because update done replicas which destroyed after ` ` forward ` ` However ` ~torch nn DataParallel ` guarantees replica ` ` device ` ` will have its parameters buffers sharing storage base parallelized attr ` module ` So in-place updates parameters buffers ` ` device ` ` will recorded E g ` ~torch nn BatchNorm d ` func ` ~torch nn utils spectral_norm ` rely behavior update buffers warning Forward backward hooks defined attr ` module ` its submodules will invoked ` ` len device_ids ` ` times each inputs located particular device Particularly hooks only guaranteed executed correct order respect operations corresponding devices For example guaranteed hooks set via meth ` ~torch nn Module register_forward_pre_hook ` executed before ` all ` ` ` len device_ids ` ` meth ` ~torch nn Module forward ` calls each such hook executed before corresponding meth ` ~torch nn Module forward ` call device warning When attr ` module ` returns scalar i e -dimensional tensor func ` forward ` wrapper will vector length equal number devices used data parallelism containing result each device note There subtlety using ` ` pack sequence - recurrent network - unpack sequence ` ` pattern ` ~torch nn Module ` wrapped ` ~torch nn DataParallel ` See ref ` pack-rnn-unpack-with-data-parallelism ` section FAQ details Args module Module module parallelized device_ids list int torch device CUDA devices default all devices output_device int torch device device location output default device_ids Attributes module Module module parallelized Example xdoctest +SKIP net = torch nn DataParallel model device_ids= output = net input_var input_var can any device including CPU TODO update notes cuda rst when handles + GPUs well __init__ module T device_ids Optional Sequence Union int torch device = None output_device Optional Union int torch device = None dim int = - None super __init__ torch _C _log_api_usage_once torch nn parallel DataParallel device_type = _get_available_device_type device_type None device_type == mps module = module device_ids = device_ids None device_ids = _get_all_device_indices device_ids None raise RuntimeError no available devices found output_device None output_device = device_ids dim = dim module = module device_ids = _get_device_index x True x device_ids output_device = _get_device_index output_device True pyrefly ignore read-only src_device_obj = torch device device_type device_ids device_type == cuda _check_balance device_ids len device_ids == module src_device_obj forward inputs Any kwargs Any - Any torch autograd profiler record_function DataParallel forward device_ids module inputs kwargs pyrefly ignore bad-argument-type t chain module parameters module buffers t device = src_device_obj raise RuntimeError module must have its parameters buffers f device src_device_obj device_ids found one f them device t device inputs module_kwargs = scatter inputs kwargs device_ids forward function without any inputs empty list dict will created so module can executed one device which first one device_ids inputs module_kwargs inputs = module_kwargs = len device_ids == module inputs module_kwargs replicas = replicate module device_ids len inputs outputs = parallel_apply replicas inputs module_kwargs gather outputs output_device replicate module T device_ids Sequence Union int torch device - list T replicate module device_ids torch is_grad_enabled scatter inputs tuple Any kwargs Optional dict str Any device_ids Sequence Union int torch device - Any scatter_kwargs inputs kwargs device_ids dim=self dim parallel_apply replicas Sequence T inputs Sequence Any kwargs Any - list Any parallel_apply replicas inputs kwargs device_ids len replicas gather outputs Any output_device Union int torch device - Any gather outputs output_device dim=self dim data_parallel module Module inputs Any device_ids Optional Sequence Union int torch device = None output_device Optional Union int torch device = None dim int = module_kwargs Optional Any = None - torch Tensor r Evaluate module input parallel across GPUs given device_ids This functional version DataParallel module Args module Module module evaluate parallel inputs Tensor inputs module device_ids list int torch device GPU ids which replicate module output_device list int torch device GPU location output Use - indicate CPU default device_ids Returns Tensor containing result module input located output_device isinstance inputs tuple inputs = inputs inputs None device_type = _get_available_device_type device_type None raise RuntimeError device type could determined device_ids None device_ids = _get_all_device_indices device_ids None raise RuntimeError no available devices found output_device None output_device = device_ids device_ids = _get_device_index x True x device_ids output_device = _get_device_index output_device True pyrefly ignore no-matching-overload src_device_obj = torch device device_type device_ids pyrefly ignore bad-argument-type t chain module parameters module buffers t device = src_device_obj raise RuntimeError module must have its parameters buffers f device src_device_obj device_ids found one f them device t device inputs module_kwargs = scatter_kwargs inputs module_kwargs device_ids dim module without any inputs empty list dict will created so module can executed one device which first one device_ids inputs module_kwargs inputs = module_kwargs = assert module_kwargs None len device_ids == module inputs module_kwargs used_device_ids = device_ids len inputs replicas = replicate module used_device_ids outputs = parallel_apply replicas inputs module_kwargs used_device_ids gather outputs output_device dim