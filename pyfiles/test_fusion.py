Owner s module intel itertools typing NamedTuple torch torch nn nn torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_utils run_tests TestCase CONV_MODULES = torch nn Conv d torch nn Conv d PointwisePostOp NamedTuple attr str pointwise_module nn Module scalars list = algorithm str = TestoneDNNFusion TestCase _unary_list unary_list = relu PointwisePostOp relu nn ReLU sigmoid PointwisePostOp sigmoid nn Sigmoid tanh PointwisePostOp tanh nn Tanh hardswish PointwisePostOp hardswish nn Hardswish swish PointwisePostOp swish nn SiLU leaky_relu PointwisePostOp leaky_relu nn LeakyReLU inplace=False scalars= hardtanh PointwisePostOp hardtanh nn Hardtanh min_val=- max_val= inplace=False scalars= - gelu_none PointwisePostOp gelu nn GELU approximate= none algorithm= none gelu_tanh PointwisePostOp gelu nn GELU approximate= tanh algorithm= tanh unary_list _binary_list binary_list = add torch add sub torch sub mul torch mul binary_list test_linear_unary_fusion_ops device M nn Module __init__ unary_fn in_channels out_channels bias kwargs super __init__ linear = torch nn Linear in_channels out_channels bias=bias kwargs unary = unary_fn forward x x = linear x x = unary x x pointwise_info _unary_list values options = itertools product True False input_shape bias options torch no_grad mod = M pointwise_info pointwise_module input_shape - bias eval mod = mod device v = torch randn input_shape v = v device ref = mod v attr = pointwise_info attr scalars = pointwise_info scalars algorithm = pointwise_info algorithm fused = torch ops mkldnn _linear_pointwise v mod linear weight mod linear bias attr scalars algorithm assertEqual ref fused test_linear_binary_fusion_ops device M nn Module __init__ binary_fn in_channels out_channels bias kwargs super __init__ linear = torch nn Linear in_channels out_channels bias=bias kwargs binary = binary_fn forward x other x = linear x x = binary x other x out_feature = in_feature = pointwise_name pointwise_fn _binary_list items torch no_grad input = torch randn in_feature device model = M pointwise_fn in_feature out_feature True eval device other = torch randn out_feature device ref = model input other attr = pointwise_name fused = torch ops mkldnn _linear_pointwise input other model linear weight model linear bias attr assertEqual ref fused test_conv_unary_fusion_ops M nn Module __init__ unary_fn dim in_channels out_channels dilation groups bias kwargs super __init__ conv = CONV_MODULES dim in_channels out_channels dilation=dilation groups=groups bias=bias kwargs unary = unary_fn forward x x = conv x x = unary x x input_shapes = pointwise_info _unary_list values dim channels_last = torch channels_last dim == torch channels_last_ d options = itertools product True False torch contiguous_format channels_last bias dilation groups memory_format options oC = groups iC = groups x_shape = iC + input_shapes dim x = torch randn x_shape dtype=torch float memory_format=memory_format mod = M pointwise_info pointwise_module dim iC oC dilation groups bias kernel_size= mod = mod memory_format=memory_format eval torch no_grad x = x xpu mod = mod xpu ref = mod x attr = pointwise_info attr scalars = pointwise_info scalars algorithm = pointwise_info algorithm fused = torch ops mkldnn _convolution_pointwise x mod conv weight mod conv bias mod conv padding mod conv stride mod conv dilation mod conv groups attr scalars algorithm assertEqual ref fused test_conv_binary_fusion_ops M nn Module __init__ binary_fn dim in_channels out_channels dilation groups bias kwargs super __init__ conv = CONV_MODULES dim in_channels out_channels dilation=dilation groups=groups bias=bias kwargs binary = binary_fn forward x other x = conv x x = binary x other x pointwise_name pointwise_fn _binary_list items x = torch randn xpu mod = M pointwise_fn True kernel_size= xpu other = torch randn_like mod conv x torch no_grad ref = mod x other unary_attr = None attr = pointwise_name fused = torch ops mkldnn _convolution_pointwise x other mod conv weight mod conv bias mod conv padding mod conv stride mod conv dilation mod conv groups attr None unary_attr None attr == add fused_inplace = torch ops mkldnn _convolution_pointwise_ other x mod conv weight mod conv bias mod conv padding mod conv stride mod conv dilation mod conv groups attr None unary_attr None assertEqual ref other assertEqual ref fused_inplace assertEqual ref fused atol= e- rtol= e- instantiate_device_type_tests TestoneDNNFusion globals only_for= xpu allow_xpu=True __name__ == __main__ run_tests