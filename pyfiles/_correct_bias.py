mypy allow-untyped-defs torch torch ao nn quantized nnq torch ao ns _numeric_suite ns torch ao quantization torch nn nn __all__ = get_module parent_child_names get_param MeanShadowLogger bias_correction _supported_modules = nn Linear nn Conv d _supported_modules_quantized = nnq Linear nnq Conv d get_module model name Given name submodule function grabs submodule given model dict model named_modules name parent_child_names name Split full name submodule into parent submodule s full name submodule s name split_name = name rsplit len split_name == split_name split_name split_name get_param module attr Get parameter given module attribute Sometimes weights bias attribute gives you raw tensor sometimes gives function will give you raw tensor function takes care logic param = getattr module attr None callable param param param MeanShadowLogger ns Logger Mean Logger Shadow module A logger Shadow module whose purpose record rolling mean data passed floating point quantized models __init__ Set up initial values float quantized stats count float sum quant sum super __init__ stats float = None stats quantized = None count = float_sum = None quant_sum = None forward x y type ignore override Compute average quantized floating-point data modules The inputs x y output data quantized floating-point modules x quantized module y floating point module x is_quantized x = x dequantize count += stats quantized None stats quantized = x quant_sum = x quant_sum += x stats quantized = quant_sum count stats float None stats float = y float_sum = y float_sum += y stats float = float_sum count clear stats float = None stats quantized = None count = float_sum = None quant_sum = None bias_correction float_model quantized_model img_data target_modules=_supported_modules_quantized neval_batches=None Perform bias correction module Using numeric suite shadow module expected output floating point quantized modules recorded Using data bias supported modules shifted compensate drift caused quantization Paper reference https arxiv org pdf pdf Section Args float_model trained model serves reference what bias correction should aim quantized_model quantized form float_model bias correction applied img_data calibration data estimate expected output used find quantization error target_modules specifies what submodules quantized_model need bias correction can extended unquantized submodules neval_batches cap number batches you want used estimating expected output ns prepare_model_with_stubs float_model quantized_model _supported_modules MeanShadowLogger uncorrected_modules = name submodule name submodule quantized_model named_modules type submodule target_modules uncorrected_module uncorrected_modules quantized_submodule = get_module quantized_model uncorrected_module bias = get_param quantized_submodule bias bias None count data enumerate img_data start= quantized_model data count == neval_batches break ob_dict = ns get_logger_dict quantized_model parent_name _ = parent_child_names uncorrected_module float_data = ob_dict parent_name + stats float quant_data = ob_dict parent_name + stats quantized math expected_error quantization_error = quant_data - float_data dims = list range quantization_error dim Note we don t want take mean over output channel dimension dims remove expected_error = torch mean quantization_error dims updated_bias = bias data - expected_error bias data = updated_bias Resets data contained loggers submodule quantized_model modules isinstance submodule MeanShadowLogger submodule clear