TODO rename executorch qnnpack_executorch since executorch general runtime specific backend operator torch torch ao nn qat nnqat torch ao nn quantized reference nnqr torch nn nn torch nn functional F torch ao quantization fuser_method_mappings _sequential_wrapper fuse_conv_bn fuse_conv_bn_relu _common_operator_config_utils _Conv dMetadata backend_config BackendConfig BackendPatternConfig DTypeConfig DTypeWithConstraints ObservationType qnnpack qnnpack_default_op_qint _symmetric_dtype_config qnnpack_weighted_op_qint _symmetric_dtype_config __all__ = get_executorch_backend_config =================== &#124; DTYPE CONFIGS &#124; =================== executorch_weighted_op_int _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch quint weight_dtype=torch qint bias_dtype=torch float executorch_default_op_quint _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch quint executorch_default_dynamic_quint _dtype_config = DTypeConfig input_dtype=torch quint output_dtype=torch float weight_dtype=torch qint bias_dtype=torch float is_dynamic=True executorch_act_qint _scale_min_ _neg_ = DTypeWithConstraints dtype=torch qint scale_min_lower_bound= - executorch_weight_qint _neg_ _to_ _scale_min_ _neg_ = DTypeWithConstraints dtype=torch qint quant_min_lower_bound=- quant_max_upper_bound= scale_min_lower_bound= - executorch_default_dynamic_qint _dtype_config = DTypeConfig input_dtype=executorch_act_qint _scale_min_ _neg_ output_dtype=torch float weight_dtype=executorch_weight_qint _neg_ _to_ _scale_min_ _neg_ bias_dtype=torch float is_dynamic=True executorch_default_dynamic_float _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch float bias_dtype=torch float is_dynamic=True executorch_weight_only_quint _dtype_config = DTypeConfig input_dtype=torch float output_dtype=torch float weight_dtype=torch quint ============================= &#124; BACKEND PATTERN CONFIGS &#124; ============================= _get_linear_configs - list BackendPatternConfig Return all configs related linear modules ops observation_type = ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT dtype_configs = qnnpack_weighted_op_qint _symmetric_dtype_config executorch_weighted_op_int _dtype_config executorch_default_dynamic_quint _dtype_config executorch_default_dynamic_qint _dtype_config executorch_default_dynamic_float _dtype_config linear_configs list BackendPatternConfig = linear module linear_configs append BackendPatternConfig torch nn Linear set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module torch nn Linear set_reference_quantized_module nnqr Linear set_qat_module nnqat Linear linear qat module linear_configs append BackendPatternConfig nnqat Linear set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module torch nn Linear set_reference_quantized_module nnqr Linear functional linear linear_configs append BackendPatternConfig torch nn functional linear set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias linear_configs _get_conv_configs - list BackendPatternConfig Return all configs related conv modules ops observation_type = ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT dtype_configs = qnnpack_weighted_op_qint _symmetric_dtype_config executorch_weighted_op_int _dtype_config conv_configs = convs _Conv dMetadata Single conv modules functions ----------------------------------- conv module conv_configs append BackendPatternConfig convs root set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference set_qat_module convs qat conv qat module conv_configs append BackendPatternConfig convs qat set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference functional conv conv_configs append BackendPatternConfig convs func set_observation_type observation_type noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight bias Conv + relu ----------------------------------- conv module + relu module conv_configs append BackendPatternConfig convs root nn ReLU set_dtype_configs dtype_configs noqa E set_fuser_method _sequential_wrapper convs fused_conv_relu set_fused_module convs fused_conv_relu conv module + functional relu conv_configs append BackendPatternConfig convs root F relu set_dtype_configs dtype_configs noqa E set_fuser_method _sequential_wrapper convs fused_conv_relu set_fused_module convs fused_conv_relu fused conv relu module conv_configs append BackendPatternConfig convs fused_conv_relu set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference set_qat_module convs relu_qat conv relu qat fused module conv_configs append BackendPatternConfig convs relu_qat set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference functional conv + relu module conv_configs append BackendPatternConfig convs func nn ReLU set_observation_type observation_type noqa E set_dtype_configs dtype_configs functional conv + functional relu conv_configs append BackendPatternConfig convs func F relu set_observation_type observation_type noqa E set_dtype_configs dtype_configs fused conv relu conv_configs append BackendPatternConfig convs fused_conv_relu set_dtype_configs dtype_configs noqa E set_qat_module convs relu_qat conv_configs append BackendPatternConfig convs relu_qat set_dtype_configs dtype_configs noqa E set_root_module convs root set_reference_quantized_module convs reference Conv + batchnorm + relu ------------------------------- conv + batchnorm + relu conv_configs append BackendPatternConfig convs root convs bn set_dtype_configs dtype_configs noqa E set_fuser_method fuse_conv_bn set_fused_module convs fused_conv_bn conv + bn + relu module fusion conv_configs append BackendPatternConfig convs root convs bn nn ReLU set_dtype_configs dtype_configs noqa E set_fuser_method fuse_conv_bn_relu set_fused_module convs fused_conv_bn_relu conv + bn + relu functional fusion conv_configs append BackendPatternConfig convs root convs bn F relu set_dtype_configs dtype_configs noqa E set_root_module convs root set_fuser_method fuse_conv_bn_relu set_fused_module convs fused_conv_bn_relu TODO we can add fusion torch relu well conv + bn + relu fused module configs fused conv bn conv_configs append BackendPatternConfig convs fused_conv_bn set_dtype_configs dtype_configs noqa E set_qat_module convs bn_qat fused conv bn relu conv_configs append BackendPatternConfig convs fused_conv_bn_relu set_dtype_configs dtype_configs noqa E set_qat_module convs bn_relu_qat conv bn qat fused module conv_configs append BackendPatternConfig convs bn_qat set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference conv bn relu qat fused module conv_configs append BackendPatternConfig convs bn_relu_qat set_observation_type observation_type noqa E set_dtype_configs dtype_configs set_root_module convs root set_reference_quantized_module convs reference conv_configs _get_binary_ops_configs - list BackendPatternConfig Return all configs related binary ops dtype_configs = qnnpack_default_op_qint _symmetric_dtype_config executorch_weighted_op_int _dtype_config num_tensor_args_to_observation_type_mapping = TODO used right now since we have extra check prepare will need change NO_OBSERVER later after we implemented Tensor dtype inference properly ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT binary_op_configs list BackendPatternConfig = op operator add torch add operator sub torch sub operator mul torch mul bop_patterns = op torch nn ReLU op torch nn functional relu op torch relu op binary_op_configs extend BackendPatternConfig bop_pattern set_dtype_configs dtype_configs noqa E _set_num_tensor_args_to_observation_type num_tensor_args_to_observation_type_mapping bop_pattern bop_patterns binary_op_configs _get_share_qparams_ops_configs - list BackendPatternConfig Return operator configs operators works both float quantized input input quantized output Tensor shares same quantization parameter input Example operator avgpool d reshape transpose maxpool d Example observed operator observer_ - avgpool d - observer_ same observer instance input observation_type = ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT dtype_configs = qnnpack_default_op_qint _symmetric_dtype_config executorch_default_op_quint _dtype_config share_qparams_ops = torch nn Flatten F adaptive_avg_pool d F elu F hardtanh F max_pool d F pad F relu F relu F leaky_relu F leaky_relu_ torch nn AdaptiveAvgPool d torch nn ConstantPad d torch nn ELU torch nn MaxPool d torch nn ReLU torch nn Hardtanh torch nn LeakyReLU torch clamp torch flatten torch mean torch permute torch permute_copy torch squeeze clamp mean permute reshape relu relu_ squeeze squeeze_ leaky_relu share_qparams_op_configs list BackendPatternConfig = BackendPatternConfig op set_observation_type observation_type noqa E set_dtype_configs dtype_configs op share_qparams_ops share_qparams_op_configs _get_bn_configs - list BackendPatternConfig Return all configs related batchnorm observation_type = ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT dtype_configs = qnnpack_default_op_qint _symmetric_dtype_config executorch_default_op_quint _dtype_config bn_configs = bn_configs append BackendPatternConfig nn BatchNorm d set_observation_type observation_type noqa E set_dtype_configs dtype_configs bn_configs _get_cat_configs - list BackendPatternConfig dtype_configs = qnnpack_default_op_qint _symmetric_dtype_config executorch_default_op_quint _dtype_config cat_configs = cat_configs append BackendPatternConfig torch cat set_observation_type ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT set_dtype_configs dtype_configs cat_configs append BackendPatternConfig torch concat set_observation_type ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT set_dtype_configs dtype_configs cat_configs append BackendPatternConfig torch concatenate set_observation_type ObservationType OUTPUT_SHARE_OBSERVER_WITH_INPUT set_dtype_configs dtype_configs cat_configs _get_embedding_op_configs - list BackendPatternConfig dtype_configs = executorch_weight_only_quint _dtype_config embedding_op_configs = embedding_op qat_embedding_op ref_embedding_op nn Embedding nnqat Embedding nnqr Embedding nn EmbeddingBag nnqat EmbeddingBag nnqr EmbeddingBag embedding_op_configs append BackendPatternConfig embedding_op set_observation_type ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT noqa E set_dtype_configs dtype_configs set_qat_module qat_embedding_op set_root_module embedding_op set_reference_quantized_module ref_embedding_op config qat op embedding_op_configs append BackendPatternConfig qat_embedding_op set_observation_type ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT noqa E set_dtype_configs dtype_configs set_root_module embedding_op set_reference_quantized_module ref_embedding_op config functional embedding embedding_op_configs append BackendPatternConfig torch nn functional embedding set_observation_type ObservationType OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT noqa E set_dtype_configs dtype_configs _set_input_type_to_index weight embedding_op_configs ===================== &#124; BACKEND CONFIGS &#124; ===================== get_executorch_backend_config - BackendConfig Return ` BackendConfig ` backends PyTorch lowers through Executorch stack BackendConfig executorch set_backend_pattern_configs _get_linear_configs set_backend_pattern_configs _get_conv_configs set_backend_pattern_configs _get_binary_ops_configs set_backend_pattern_configs _get_share_qparams_ops_configs set_backend_pattern_configs _get_bn_configs set_backend_pattern_configs _get_cat_configs set_backend_pattern_configs _get_embedding_op_configs