Owner s module dynamo unittest unittest mock Mock torch torch _dynamo callback callback_handler CallbackArgs CallbackTrigger torch _dynamo test_case run_tests TestCase torch _guards CompileId torch testing _internal common_utils TEST_WITH_ROCM torch testing _internal triton_utils HAS_CUDA_AND_TRITON requires_gpu device_type = acc type acc = torch accelerator current_accelerator True cpu CallbackTests TestCase setUp - None super setUp _on_compile_start = Mock _on_compile_end = Mock callback_handler register_start_callback _on_compile_start callback_handler register_end_callback _on_compile_end tearDown - None callback_handler clear super tearDown test_callbacks_with_duplicate_prevention - None trigger = CallbackTrigger DYNAMO compile_id = CompileId frame_id= frame_compile_id= callback_handler install_callbacks trigger compile_id callback_handler install_callbacks trigger compile_id _on_compile_start assert_called_once _on_compile_end assert_called_once test_counter - None trigger = CallbackTrigger DYNAMO compile_id = CompileId frame_id= frame_compile_id= callback_handler install_callbacks trigger compile_id assertEqual callback_handler _CompilationCallbackHandler__pending_callbacks_counter assertEqual callback_handler _CompilationCallbackHandler__pending_callbacks_counter test_counter_assertion - None callback_handler _CompilationCallbackHandler__pending_callbacks_counter -= assertRaisesRegex AssertionError Pending callbacks counter cannot become negative trigger = CallbackTrigger DYNAMO compile_id = CompileId frame_id= frame_compile_id= callback_handler install_callbacks trigger str compile_id pass assertEqual callback_handler _CompilationCallbackHandler__pending_callbacks_counter unittest skipIf TEST_WITH_ROCM ROCm outputs different number autotuning logs requires_gpu torch _inductor config patch force_disable_caches=True test_triggers - None torch _dynamo reset order = on_start args CallbackArgs nonlocal order order append f start= args on_end args CallbackArgs nonlocal order order append f end= args torch _dynamo callback on_compile_start on_start torch _dynamo callback on_compile_start on_end TinyModel torch nn Module __init__ super __init__ fc = torch nn Linear relu = torch nn ReLU fc = torch nn Linear forward x temp = fc x temp = relu temp torch _dynamo graph_break fc temp model = TinyModel device_type compiled_model = torch compile model mode= max-autotune x = torch randn device=device_type loss = compiled_model x sum loss backward assertExpectedInline \n join order \ start=CallbackArgs callback_trigger= CallbackTrigger DYNAMO compile_id= end=CallbackArgs callback_trigger= CallbackTrigger DYNAMO compile_id= start=CallbackArgs callback_trigger= CallbackTrigger DYNAMO compile_id= end=CallbackArgs callback_trigger= CallbackTrigger DYNAMO compile_id= start=CallbackArgs callback_trigger= CallbackTrigger LAZY_BACKWARD compile_id= end=CallbackArgs callback_trigger= CallbackTrigger LAZY_BACKWARD compile_id= start=CallbackArgs callback_trigger= CallbackTrigger LAZY_BACKWARD compile_id= end=CallbackArgs callback_trigger= CallbackTrigger LAZY_BACKWARD compile_id= noqa B order clear HAS_CUDA_AND_TRITON compiled_model zero_grad loss = compiled_model x sum loss backward assertExpectedInline \n join order \ start=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= end=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= start=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= end=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= start=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= end=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= start=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= end=CallbackArgs callback_trigger= CallbackTrigger CUDAGRAPH_RECORDING compile_id= noqa B order clear compiled_model zero_grad loss = compiled_model x sum loss backward assertEqual len order __name__ == __main__ run_tests