Owner s oncall distributed sys torch torch distributed dist torch distributed _shard sharded_tensor torch distributed _shard sharding_spec ChunkShardingSpec torch distributed distributed_c d _get_default_group torch testing _internal common_distributed requires_nccl skip_if_lt_x_gpu torch testing _internal common_utils run_tests TEST_WITH_DEV_DBG_ASAN torch testing _internal distributed _shard sharded_tensor ShardedTensorTestBase with_comms TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit TestShardedTensorBinaryOps ShardedTensorTestBase Test base binary comparison functions such torch equal torch allclose etc ShardedTensor seed = get_random_tensors spec spec sizes pg =None pg =None seed_offset= pg = _get_default_group pg None pg pg = _get_default_group pg None pg torch manual_seed TestShardedTensorBinaryOps seed st = sharded_tensor rand spec sizes process_group=pg torch manual_seed TestShardedTensorBinaryOps seed + seed_offset st = sharded_tensor rand spec sizes process_group=pg TestShardedTensorBinaryOps seed += st st get_gpu_specs spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda alt_spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda spec alt_spec _test_common_failures cmp_op spec alt_spec = get_gpu_specs st st = get_random_tensors spec spec rank == torch nn init uniform_ st local_shards tensor assertFalse cmp_op st st st = sharded_tensor ones spec st = sharded_tensor ones spec assertFalse cmp_op st st st st = get_random_tensors spec alt_spec assertFalse cmp_op st st st = sharded_tensor ones spec st = sharded_tensor zeros spec assertFalse cmp_op st st st = sharded_tensor ones spec st = sharded_tensor ones spec dtype=torch double assertFalse cmp_op st st st = sharded_tensor ones spec st = sharded_tensor ones spec requires_grad=True assertFalse cmp_op st st cpu_spec = ChunkShardingSpec dim= placements= rank cpu rank cpu rank cpu rank cpu st = sharded_tensor ones cpu_spec st = sharded_tensor ones cpu_spec pin_memory=True assertFalse cmp_op st st pg = dist new_group st st = get_random_tensors spec spec pg =pg assertRaisesRegex RuntimeError All distributed tensors should use same ProcessGroup cmp_op st st pg = dist new_group st st = get_random_tensors spec spec pg =pg assertRaisesRegex RuntimeError All distributed tensors should use same ProcessGroup cmp_op st st with_comms skip_if_lt_x_gpu requires_nccl test_torch_equal_tensor_specs _test_common_failures torch equal with_comms skip_if_lt_x_gpu requires_nccl test_torch_equal Test torch equal ShardedTensor ShardedTensor spec _ = get_gpu_specs st st = get_random_tensors spec spec assertTrue torch equal st st with_comms skip_if_lt_x_gpu requires_nccl test_torch_allclose_tensor_specs _test_common_failures torch allclose with_comms skip_if_lt_x_gpu requires_nccl test_torch_allclose Test torch allclose ShardedTensor ShardedTensor spec _ = get_gpu_specs st st = get_random_tensors spec spec assertTrue torch allclose st st assertTrue torch allclose st st atol= compare different arrays st st = get_random_tensors spec spec seed_offset= assertFalse torch allclose st st sharded_tensor rand produces uniform values range assertTrue torch allclose st st atol= __name__ == __main__ run_tests