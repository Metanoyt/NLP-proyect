trace_wrapped args fn equivalent fn args twist you make_fx trace through call we will actually trace into fn instead we will directly insert call_function fn graph Unlike make_fx Dynamo WILL inline into fn You can think one off allow_in_graph equivalent proxy tensor tracing Because proxy tensor tracing does actually run function there requirements behavior fn We still figuring out here current state fn SHOULD only take single argument which must tensor fn MUST new tensor same metadata original tensor e g zeros_like input permissible implementation fn This verified via extra assert inserted into traced graph fn MAY have side effects MAY NOT perform metadata mutation other tensors participating proxy tensor tracing MAY mutate other tensors MAY mutate Python state These requirements stem requirement we need continue performing proxy tensor tracing which assumes accurate fake tensor metadata without actually running fn In future we may allow meta function associated fn allow more interesting input-output patterns Note tensors Python state allowed mutated This relaxed constraint always sound sound backward tracing fake tensors takes place AOTAutograd backward pass guaranteed depend concrete tensor values via fake tensor Python state because autograd engine doesn t depend Python The intended use case function allow AOTAutograd defer complex backward hooks compiled autograd AOTAutograd performs make_fx trace which preserves function call graph only when we Dynamo through backward graph compiled autograd do we inline into function typing Any Optional torch torch utils _pytree pytree torch _C DispatchKey torch _higher_order_ops utils autograd_not_implemented torch _ops HigherOrderOperator OpOverload torch _subclasses FakeTensorMode torch fx experimental _backward_state BackwardState torch fx experimental proxy_tensor ProxyTorchDispatchMode track_tensor_tree torch overrides TorchFunctionMode torch utils _python_dispatch _get_current_dispatch_mode torch utils _pytree tree_map_only Tensor = torch Tensor __all__ = trace_wrapped torch library custom_op flex_lib zeros_and_scatter mutates_args= type ignore misc zeros_and_scatter shape list int indices list Tensor vals Tensor - Tensor Custom Op so we can register custom lowering new_output + scatter backwards pass grad = torch zeros shape device=vals device dtype=vals dtype torch ops aten index_put grad indices vals accumulate=True zeros_and_scatter register_fake type ignore misc _ shape list int indices list Tensor vals Tensor - Tensor vals new_empty shape zeros_and_scatter register_vmap type ignore misc _ info indims shape indices value type ignore no-untyped-def The batching rule special returns tensor batched indices_indims = indims expanded_indices = idx idx_indim zip indices indices_indims The index being batched we should unsqueeze expand val idx_indim None expanded_indices append idx expand value shape index being part vmap batch should same size val assert idx shape == value shape expanded_indices append idx out = torch ops flex_lib zeros_and_scatter shape expanded_indices value out None ModIndex torch autograd Function generate_vmap_rule = True staticmethod pyrefly ignore bad-override forward x Tensor indices list Tensor - Tensor torch ops aten index x indices staticmethod setup_context ctx Any inputs tuple Any output Any - None x indices = inputs ctx save_for_backward indices ctx input_shape = x shape staticmethod backward ctx gradOut type ignore no-untyped-def indices = ctx saved_tensors torch ops flex_lib zeros_and_scatter ctx input_shape indices gradOut None classmethod torch _export wrappers allow_in_pre_dispatch_graph apply cls args kwargs type ignore no-untyped-def super apply args kwargs mod_index = ModIndex apply TransformGetItemToIndex TorchFunctionMode This needed since we want support calling A q_idx where q_idx scalar tensor score_mod Today when q_idx scalar tensor we implicitly convert python scalar create view We do want behavior case so we use torchfunctionmode override behavior score_mod wherever we re running __torch_function__ func OpOverload types tuple torch _C _TensorMeta args tuple object = kwargs Optional dict str object = None - object func torch Tensor __getitem__ index_args = pytree tree_leaves args all isinstance x torch Tensor x index_args mod_index args index_args func args kwargs trace_wrapped args Any kwargs Any - Any torch no_grad _trace_wrapped_op args kwargs TraceWrapped HigherOrderOperator __init__ - None super __init__ trace_wrapped __call__ args Any kwargs Any - Any super __call__ args kwargs TODO jansel need ensure does get DCEed _trace_wrapped_op = TraceWrapped _assert_meta grad torch Tensor size tuple int stride tuple int dtype torch dtype - torch Tensor assert grad size == size size mismatch assert grad stride == stride stride mismatch assert grad dtype == dtype dtype mismatch grad _trace_wrapped_op py_impl ProxyTorchDispatchMode inner_trace mode ProxyTorchDispatchMode args Any bw_state Optional BackwardState = None kwargs Any - Any self_invoke args Any dyn_kwargs Any - Any torch no_grad _trace_wrapped_op args dyn_kwargs kwargs unwrap_proxies x Any - Any isinstance x torch Tensor mode tracer unwrap_proxy x type ignore union-attr isinstance x list tuple type x map unwrap_proxies x x None None raise AssertionError f unhandled type type x proxy_kwargs = bw_state None assert isinstance bw_state BackwardState bw_state proxy None proxy_kwargs bw_state = bw_state proxy out_proxy = mode tracer create_proxy call_function self_invoke unwrap_proxies args proxy_kwargs name= trace_wrapped args None grad = args module backward hooks grad = args other backward hooks grad = tree_map_only torch Tensor torch empty_like grad track_tensor_tree grad out_proxy constant=None tracer=mode tracer grad _trace_wrapped_op py_impl FakeTensorMode inner_fake args Any kwargs Any - None raise RuntimeError This op should never invoked here _trace_wrapped_op py_impl DispatchKey CompositeExplicitAutograd _trace_wrapped_op_dense args Any fn Any kwargs Any - Any mode = _get_current_dispatch_mode assert mode None Mode should never enabled CPU CUDA key fn args kwargs _trace_wrapped_op py_impl DispatchKey Autograd autograd_not_implemented _trace_wrapped_op deferred_error=True _trace_wrapped_op py_functionalize_impl _trace_wrapped_functionalized ctx Any args Any kwargs Any - Any unwrapped_args = ctx unwrap_tensors args ctx redispatch_to_next ctx wrap_tensors _trace_wrapped_op unwrapped_args kwargs autograd_function_backward_rewritten original_backward Any - Any new_backward ctx Any grads Any - Any pyrefly ignore bad-assignment grads = g contiguous g grads original_backward ctx grads new_backward