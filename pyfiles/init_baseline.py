Script generate baseline values PyTorch initialization algorithms sys torch HEADER = #include torch types h #include vector namespace expected_parameters FOOTER = namespace expected_parameters PARAMETERS = inline std vector std vector torch Tensor INITIALIZERS = Xavier_Uniform lambda w torch nn init xavier_uniform w Xavier_Normal lambda w torch nn init xavier_normal w Kaiming_Normal lambda w torch nn init kaiming_normal w Kaiming_Uniform lambda w torch nn init kaiming_uniform w emit initializer_parameter_map Don t write generated front file recognized generated print format generated __file__ print HEADER initializer_name weights initializer_parameter_map items print PARAMETERS format initializer_name print sample weights print parameter sample parameter_values = format join map str parameter print f torch tensor parameter_values print print print \n print FOOTER run initializer torch manual_seed layer = torch nn Linear INITIALIZERS initializer layer weight layer = torch nn Linear INITIALIZERS initializer layer weight layer = torch nn Linear INITIALIZERS initializer layer weight weight = layer weight data numpy weight = layer weight data numpy weight = layer weight data numpy weight weight weight main initializer_parameter_map = initializer INITIALIZERS keys sys stderr write f Evaluating initializer \n initializer_parameter_map initializer = run initializer emit initializer_parameter_map __name__ == __main__ main