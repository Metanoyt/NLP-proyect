Owner s module inductor collections unittest torch torch _inductor torch _inductor fx_passes group_batch_fusion torch _dynamo utils counters torch _inductor test_case run_tests TestCase torch testing _internal inductor_utils GPU_TYPE requires_gpu try importing will register fbgemm lowerings inductor deeplearning fbgemm fbgemm_gpu fb inductor_lowerings noqa F has_fbgemm = True except Exception has_fbgemm = False TestHighwaySelfGating torch nn Module __init__ d_model int size int device= cuda - None super __init__ size = size device = device gating_proj = torch nn Linear d_model d_model device transform_proj = torch nn Linear d_model d_model device gating_func = torch nn Sigmoid device d_model = d_model forward inputs list torch Tensor - torch Tensor results = i range size x = inputs i gating_proj = gating_proj x transform_proj = transform_proj x x = gating_proj gating_func transform_proj results append x torch cat results dim=- MyModule torch nn Module __init__ z int has_bias bool device= cuda - None super __init__ z = z device = device seq_len = seq = torch nn Linear z z has_bias device _ range seq_len seq = torch nn Linear z z has_bias device _ range seq_len seq = torch nn Linear z z has_bias device _ range seq_len forward x torch Tensor - torch Tensor x = x + i i range seq_len x = seq i x i i range seq_len x = x i - i i range seq_len x = x i i range + x i i range seq_len x = seq i x i i range seq_len x = x i + seq_len - i i range seq_len x = x i i range + x i i range + x i i range x = seq i x i i range seq_len x = torch cat x dim= x MyModule torch nn Module __init__ - None super __init__ linear = torch nn Linear linear = torch nn Linear linear = torch nn Linear linear = torch nn Linear linear = torch nn Linear linear = torch nn Linear bn = torch nn BatchNorm d bn = torch nn BatchNorm d bn = torch nn BatchNorm d forward x torch Tensor - torch Tensor t = torch split x dim= = bn linear t + = bn linear t + = bn linear t + = linear torch sin t = linear torch cos t = linear torch sin t b = torch cat torch sigmoid b MyModule torch nn Module __init__ device has_weight=True has_bias=True super __init__ device = device scale = torch nn ParameterList torch nn Parameter torch randn _ range device bias = torch nn ParameterList torch nn Parameter torch randn _ range device scale = torch nn ParameterList torch nn Parameter torch randn _ range device has_weight None _ range bias = torch nn ParameterList torch nn Parameter torch randn _ range device has_bias None _ range forward x l _out = torch split x device dim= post_l = torch nn functional layer_norm l _out i weight=self scale i bias=self bias i i range len l _out l _out = torch cat post_l dim= l _out = torch split l _out dim= post_l = torch nn functional layer_norm l _out i weight=self scale i bias=self bias i i range len l _out torch cat post_l dim= MyModule torch nn Module __init__ z device has_bias super __init__ z = z device = device has_bias = has_bias seq_len = weights = torch nn Parameter torch randn z - i z device i range seq_len weights = torch nn Parameter torch randn z - i z device i range seq_len has_bias biases = torch nn Parameter torch randn z - i device i range seq_len biases = torch nn Parameter torch randn z - i device i range seq_len forward x x = x + x = torch nn functional linear x weights i biases i has_bias None i range seq_len x = torch cat x dim= x = torch split x dim= x = torch cat x x = torch nn functional linear x weights i biases i has_bias None i range seq_len x = torch cat x dim= torch sigmoid x MyModule torch nn Module __init__ device has_bias=True super __init__ device = device weights = torch nn ParameterList torch nn Parameter torch randn device _ range biases = torch nn Parameter torch randn device _ range has_bias None _ range forward x l _out = torch split x device dim= l _linear = torch nn functional linear l _out i weights i biases i i range len l _out l _out = torch cat l _linear dim= torch sin l _out TestPoitwiseOps torch nn Module __init__ device has_bias=True super __init__ device = device forward x inputs = torch split x device dim= x_split = torch split inputs device dim= y_split = torch split inputs device dim= sigmoid_ = torch sigmoid x_split i i range len x_split sigmoid_ = torch sigmoid y_split i i range len y_split relu_ = torch nn functional relu sigmoid_ i i range len sigmoid_ relu_ = torch nn functional relu sigmoid_ i i range len sigmoid_ add = torch add relu_ i relu_ i i range len relu_ mul = torch mul add i add i i range len add sub = torch sub mul i mul i i range len mul div = torch div sub i sub i i range len sub torch cat div dim= TestPoitwiseOpsPostGrad torch nn Module __init__ device super __init__ device = device forward x inputs = torch ops aten split x device dim= x_split = torch ops aten split inputs device dim= y_split = torch ops aten split inputs device dim= tanh_ = torch ops aten tanh x_split i i range len x_split tanh_ = torch ops aten tanh y_split i i range len y_split sigmoid_ = torch ops aten sigmoid tanh_ i i range len tanh_ sigmoid_ = torch ops aten sigmoid tanh_ i i range len tanh_ relu_ = torch ops aten relu sigmoid_ i i range len sigmoid_ relu_ = torch ops aten relu sigmoid_ i i range len sigmoid_ add = torch ops aten add relu_ i relu_ i i range len relu_ torch cat add dim= TestMathOps torch nn Module __init__ device super __init__ device = device forward x inputs = x device i range others = x device i range clamp_input = x clamp min=- max= x inputs clamp_other = x clamp min=- max= x others nan_to_num_input = torch nan_to_num x x clamp_input nan_to_num_other = torch nan_to_num x x clamp_other detach_input = x detach x nan_to_num_input detach_other = x detach x nan_to_num_other stack_input = torch stack detach_input dim= stack_other = torch stack detach_other dim= torch stack stack_input stack_other dim= TestDropout torch nn Module __init__ device super __init__ device = device forward x torch Tensor - tuple torch Tensor torch Tensor torch Tensor torch Tensor split = x split getitem_ = split getitem_ = split getitem_ = split getitem_ = split getitem_ = split dropout = torch nn functional dropout getitem_ p= training=True inplace=False dropout_ = torch nn functional dropout getitem_ p= training=True inplace=False dropout_ = torch nn functional dropout getitem_ p= training=True inplace=False dropout_ = torch nn functional dropout getitem_ p= training=True inplace=False dropout_ = torch nn functional dropout getitem_ p= training=True inplace=False dropout dropout_ dropout_ dropout_ dropout_ TestGroupBatchFusion TestCase compare_dict_tensors ref_dict res_dict rtol= e- atol= e- len set ref_dict keys = len set res_dict keys False key ref_dict keys key = _orig_mod + key assert key res_dict f key does exist traced module torch allclose ref_dict key res_dict key rtol=rtol atol=atol False True compare_pred module traced input rtol= e- atol= e- ref = module input res = traced input assertEqual ref res rtol=rtol atol=atol compare_parameters module traced rtol= e- atol= e- ref_params = dict module named_parameters res_params = dict traced named_parameters assertTrue compare_dict_tensors ref_params res_params rtol atol compare_gradients module traced rtol= e- atol= e- ref_grad = key param grad key param module named_parameters res_grad = key param grad key param traced named_parameters assertTrue compare_dict_tensors ref_grad res_grad rtol=rtol atol=atol requires_gpu unittest skipIf has_fbgemm requires fbgemm torch _inductor config patch pre_grad_fusion_options= post_grad_fusion_options= group_linear require_fbgemm True test_group_linear_fusion z = has_bias True False counters clear module = MyModule z has_bias GPU_TYPE input = torch randn z z device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor group_linear ref sum backward res sum backward compare_parameters module traced compare_gradients module traced assertEqual counters inductor group_linear counters clear requires_gpu unittest skipIf has_fbgemm requires fbgemm torch _inductor config patch pre_grad_fusion_options= post_grad_fusion_options= group_linear require_fbgemm True test_group_linear_fusion_different_shapes counters clear module = MyModule eval GPU_TYPE input = torch rand device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor group_linear assertEqual counters inductor batch_fusion ref sum backward res sum backward compare_parameters module traced compare_gradients module traced assertEqual counters inductor group_linear counters clear requires_gpu unittest skipIf GPU_TYPE == mps welford_reduce yet implemented MPS torch _inductor config patch pre_grad_fusion_options= batch_layernorm post_grad_fusion_options= test_batch_layer_norm_fusion has_weight True False has_bias True False counters clear module = MyModule GPU_TYPE has_weight has_bias GPU_TYPE input = torch randn device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_layernorm ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= batch_linear_lhs post_grad_fusion_options= test_batch_linear_lhs_fusion z = has_bias True False counters clear module = MyModule z GPU_TYPE has_bias input = torch randn z device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_linear_lhs ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= batch_linear post_grad_fusion_options= test_batch_linear_pre_grad_fusion has_bias True False counters clear module = MyModule GPU_TYPE has_bias input = torch randn device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_linear ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= batch_relu batch_sigmoid post_grad_fusion_options= batch_aten_add batch_aten_mul batch_aten_sub batch_aten_div test_pointwise_op_fusion counters clear module = TestPoitwiseOps GPU_TYPE input = torch randn requires_grad=True device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_relu assertEqual counters inductor batch_sigmoid assertEqual counters inductor batch_aten_add assertEqual counters inductor batch_aten_mul assertEqual counters inductor batch_aten_sub assertEqual counters inductor batch_aten_div ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= post_grad_fusion_options= batch_aten_relu batch_aten_sigmoid batch_aten_tanh unbind_stack_aten_pass test_pointwise_op_fusion_post_grad counters clear module = TestPoitwiseOpsPostGrad GPU_TYPE input = torch randn requires_grad=True device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_aten_tanh assertEqual counters inductor batch_aten_relu assertEqual counters inductor batch_aten_sigmoid assertEqual counters inductor unbind_stack_aten_pass ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= post_grad_fusion_options= batch_linear_post_grad shape_broadcast_batch_linear True fuse_nodes_with_same_users True batch_aten_mul fuse_nodes_with_same_parent False batch_aten_sigmoid fuse_nodes_with_same_parent True batch_aten_add fuse_nodes_with_same_parent True normalization_aten_pass unbind_stack_aten_pass test_gate_fusion_post_grad counters clear size = module = TestHighwaySelfGating d_model= size=size device=GPU_TYPE input = torch randn requires_grad=True device=GPU_TYPE i range size traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor batch_linear_post_grad assertEqual counters inductor batch_aten_sigmoid assertEqual counters inductor batch_aten_mul assertEqual counters inductor batch_aten_add assertEqual counters inductor normalization_aten_pass assertEqual counters inductor unbind_stack_aten_pass ref sum backward res sum backward compare_parameters module traced rtol= e- atol= e- compare_gradients module traced rtol= e- atol= e- counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= normalization_pass batch_detach batch_nan_to_num batch_clamp unbind_stack_pass unbind_stack_to_slices_pass post_grad_fusion_options= test_math_op_fusion counters clear module = TestMathOps GPU_TYPE input = torch tensor float nan float inf -float inf device=GPU_TYPE traced = torch compile module ref = module input res = traced input compare_pred module traced input assertEqual counters inductor normalization_pass assertEqual counters inductor batch_clamp assertEqual counters inductor batch_detach assertEqual counters inductor batch_nan_to_num assertEqual counters inductor unbind_stack_to_slices_pass assertEqual counters inductor unbind_stack_pass assertTrue torch allclose ref res counters clear requires_gpu torch _inductor config patch pre_grad_fusion_options= normalization_pass batch_dropout test_batch_dropout_pre_grad_fusion counters clear module = TestDropout GPU_TYPE input = torch randn requires_grad=True device=GPU_TYPE traced = torch compile module module input traced input assertEqual counters inductor normalization_pass assertEqual counters inductor batch_dropout counters clear TestBMMFusionModule torch nn Module __init__ - None super __init__ my_modules = torch nn ModuleList _ range my_modules append torch nn Linear forward inputs output = None linear input zip my_modules inputs output None output = linear input output += linear input output requires_gpu torch _inductor config patch post_grad_fusion_options= batch_linear_post_grad require_fbgemm False TestPostGradBatchLinearFusion TestCase test_batch_linear_post_grad_fusion pt _module = TestBMMFusionModule GPU_TYPE inputs = _ range inputs append torch randn GPU_TYPE eager_output = pt _module inputs pt _module = torch compile pt _module pt _output = pt _module inputs assertTrue torch allclose eager_output pt _output assertEqual counters inductor batch_linear_post_grad TestFindIndependentSubsetGreedy TestCase Helper function build Graph data description build_graph desc desc n n n n n n g = torch fx Graph lookup = desc = collections deque k v k v desc items unsatisfied = while desc unsatisfied += assert unsatisfied = len desc cycle bad input name v = desc popleft args = tuple lookup get n n v None args desc append name v continue node = g create_node placeholder target name=name args=args lookup name = node unsatisfied = g lookup verify tree subnodes min_fuse max_fuse expected _ lookup = build_graph tree subnodes = lookup n n subnodes expected = lookup n n sub sub expected opts = min_fuse_set_size min_fuse max_fuse_set_size max_fuse result = list torch _inductor fx_passes group_batch_fusion find_independent_subset_greedy subnodes opts assertEqual expected result test_find_independent_subset_greedy First some randomly generated tests verify n n n n verify n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n verify n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n trivial test min_fuse verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n trivial test max_fuse verify n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n test_find_independent_subset_greedy_fuse ensure fusing sets during iteration results correct iteration results In example graph after we merge n n n no longer independent n g lookup = build_graph n n n n n n n n n opts = min_fuse_set_size max_fuse_set_size subnodes = n n n n n n subnodes = lookup n n subnodes i = torch _inductor fx_passes group_batch_fusion find_independent_subset_greedy subnodes opts assertEqual next i lookup n n n n n fuse n n which makes n now dependent n args = tuple lookup n n n n fused = g create_node placeholder target name= n +n args=args lookup n replace_all_uses_with fused g erase_node lookup n lookup n replace_all_uses_with fused g erase_node lookup n assertEqual next i lookup n n n assertEqual next i lookup n n n n assertRaises StopIteration lambda next i __name__ == __main__ run_tests