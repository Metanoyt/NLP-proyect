Owner s oncall distributed collections inspect logging math operator collections abc Generator dataclasses dataclass functools partial typing Any Callable cast torch torch fx fx torch _dynamo utils counters torch fx passes graph_transform_observer GraphTransformObserver torch fx passes shape_prop _extract_tensor_metadata TensorMetadata torch utils _ordered_set OrderedSet torch utils _pytree tree_flatten tree_map tree_unflatten fx_utils get_fake_args_kwargs virtualized V aten = torch ops aten logger logging Logger = logging getLogger comm_fusion move_block_after block list fx Node target_node fx Node - None node block target_node append node target_node = node move_block_before block list fx Node target_node fx Node - None node block target_node prepend node target_node = node call_function graph fx Graph target str &#124; Callable Any args tuple fx node Argument &#124; None = None kwargs dict str fx node Argument &#124; None = None - fx Node We accept target str avoid typing error type node target str &#124; Callable Any This also allows us avoid writing check every call isinstance target str raise RuntimeError f Call function should get str target target= node = graph call_function target args kwargs _ args kwargs = get_fake_args_kwargs node V fake_mode node meta val = target args kwargs node meta val may container So we use tree_map here recursively extract tensor metadata node meta tensor_meta = tree_map _extract_tensor_metadata node meta val node dataclass unsafe_hash=True CommBlock shape torch Size &#124; list torch Size node_list list fx Node inputs list fx Node wait_nodes list fx Node comm_node fx Node outputs OrderedSet fx Node get_comm_block comm_node fx Node - CommBlock &#124; None Given collective node e g allreduce find out all nodes belong communication Args comm_node fx Node The target communication collective node Returns The CommBlock encapsulates related nodes e g wait_node given comm_node node_list = wait_nodes = inputs _ = tree_flatten comm_node args comm_node kwargs input_nodes = inp inp inputs isinstance inp fx Node If users wait node following items we consinder them part output intermediate_outputs = split reshape getitem detach alias first_user = next iter comm_node users len comm_node users == first_user target torch ops _c d_functional wait_tensor default Collective only one output node_list = comm_node first_user wait_nodes append first_user len comm_node users first_user target operator getitem Collective only more than one output node_list append comm_node user comm_node users user target = operator getitem None len user users = None wait_node = next iter user users wait_node target = torch ops _c d_functional wait_tensor default None wait_nodes append wait_node node_list append user node_list extend wait_nodes None Identify all outputs collective block outputs = OrderedSet fx Node nodes = collections deque wait_nodes while nodes node = nodes popleft user node users isinstance user fx Node user name startswith intermediate_outputs nodes append user node_list append user outputs add node break tensor_meta = input_nodes meta tensor_meta shape torch Size &#124; list torch Size isinstance tensor_meta TensorMetadata shape = tensor_meta shape isinstance tensor_meta list tuple shape = tm shape tm tensor_meta logger warning Unexpected type tensor_meta s type tensor_meta None CommBlock shape=shape node_list=node_list wait_nodes=wait_nodes comm_node=comm_node inputs=input_nodes outputs=outputs get_all_comm_blocks graph fx Graph comm_ops tuple torch _ops OpOverload comm_filter Callable bool &#124; None = None - list CommBlock comm_filter None always_true comm_block CommBlock - bool True comm_filter = always_true blocks = node graph nodes node target comm_ops continue comm_block = get_comm_block node comm_block None comm_filter comm_block blocks append comm_block blocks _fuse_allreduce_by_concat graph fx Graph last_input_node fx Node all_input_nodes list fx Node last_comm_block CommBlock - CommBlock Given list inputs order create fused allreduce using concat Flatten all inputs all_reduce nodes graph inserting_after last_input_node cat_inputs = input_node all_input_nodes assert isinstance input_node args fx Node input_node = input_node args cat_inputs append call_function graph aten flatten using_ints input_node Concat all flattened nodes graph inserting_after cat_inputs cat_node = call_function graph aten cat cat_inputs Insert fused div node remove input div nodes This optimization mandatory fusion divisors = div args div all_input_nodes assert all divisor == divisors divisor divisors graph inserting_after cat_node div_node = call_function graph last_input_node target cat_node divisors Create new Comm all_reduce node last_comm_node = last_comm_block comm_node last_wait_node = last_comm_block wait_nodes graph inserting_after div_node flatten_args spec = tree_flatten last_comm_node args last_comm_node kwargs flatten_args = div_node args kwargs = tree_unflatten flatten_args spec fused_comm_node = call_function graph last_comm_node target args kwargs Create new Wait node graph inserting_after fused_comm_node flatten_args spec = tree_flatten last_wait_node args last_wait_node kwargs flatten_args = fused_comm_node args kwargs = tree_unflatten flatten_args spec fused_wait_node = call_function graph last_wait_node target args kwargs Move fused all_reduce its args right after input node nodes_to_move = cat_inputs + cat_node div_node fused_comm_node fused_wait_node pyrefly ignore bad-argument-type move_block_after nodes_to_move last_input_node CommBlock shape=cast TensorMetadata cat_node meta get tensor_meta shape node_list= fused_comm_node fused_wait_node wait_nodes= fused_wait_node comm_node=fused_comm_node inputs= div_node outputs=OrderedSet fused_wait_node _fuse_with_coalesced_op graph fx Graph last_input_node fx Node all_input_nodes list fx Node last_comm_block CommBlock - CommBlock Given list inputs order create fused allreduce coalesced last_comm_node = last_comm_block comm_node last_wait_node = last_comm_block wait_nodes Insert fused div node remove input div nodes This optimization mandatory fusion dividends = div args div all_input_nodes divisors = div args div all_input_nodes assert all divisor == divisors divisor divisors graph inserting_before last_input_node last_input_node = call_function graph aten _foreach_div Scalar dividends divisors input_node = last_input_node Create new Comm all_reduce_coalesced node graph inserting_after last_comm_node flatten_args spec = tree_flatten last_comm_node args last_comm_node kwargs flatten_args = input_node args kwargs = tree_unflatten flatten_args spec fused_comm_node = call_function graph torch ops _c d_functional all_reduce_coalesced default args kwargs Create new wait node getitem_nodes = wait_nodes = flatten_args spec = tree_flatten last_wait_node args last_wait_node kwargs idx range len all_input_nodes graph inserting_after fused_comm_node gi_node = call_function graph operator getitem fused_comm_node idx getitem_nodes append gi_node flatten_args = gi_node args kwargs = tree_unflatten flatten_args spec graph inserting_after gi_node wait_nodes append call_function graph last_wait_node target args kwargs Move new all_reduce_coalesced its args right after input node nodes_to_move = fused_comm_node + getitem_nodes + wait_nodes move_block_after nodes_to_move last_input_node CommBlock shape= tm shape tm cast list TensorMetadata fused_comm_node meta get tensor_meta node_list= fused_comm_node + getitem_nodes + wait_nodes wait_nodes=wait_nodes comm_node=fused_comm_node inputs= input_node outputs=OrderedSet wait_nodes _scatter_fused_allreduce_waits graph fx Graph fused_comm_block CommBlock orig_comm_blocks list CommBlock node_indices dict fx Node int split_and_reshape bool = True - None Scatters result fused communication node original users If fused method concat splitting output reshape will inserted before inserting getitem Otherwise getitem will used users wait node Before we mass up order we need get index last wait node orig_comm_blocks This index will later used determine what users nodes need move maintain correct topological sort order last_wait_node_idx = pyrefly ignore bad-assignment node graph nodes last_wait_node_idx = max node_indices get node last_wait_node_idx last_wait_node_idx node == orig_comm_blocks - wait_nodes break split_and_reshape fused_wait_node = fused_comm_block wait_nodes graph inserting_after fused_wait_node split_node = call_function graph aten split fused_wait_node math prod cast list int cb shape cb orig_comm_blocks graph inserting_after split_node fused_outputs = idx comm_block enumerate orig_comm_blocks split_idx_node = call_function graph operator getitem split_node idx graph inserting_after split_idx_node fused_outputs append call_function graph aten reshape split_idx_node comm_block shape fused_outputs = fused_comm_block wait_nodes Scatter fused outputs incorrect_order_nodes = comm_block fused_output zip orig_comm_blocks fused_outputs Some descendant users orig_comm_blocks may scheduled before fused all_reduce For example user nodes very first all_reduce may scheduled before second all_reduce Since fused all_reduce inserted right after last all_reduce order can wrong ` incorrect_order_nodes ` records these nodes orig_wait = comm_block wait_nodes nodes = collections deque list orig_wait users while nodes user_node = nodes popleft isinstance user_node fx Node continue pyrefly ignore unsupported-operation node_indices user_node last_wait_node_idx incorrect_order_nodes append user_node nodes extend list user_node users orig_wait replace_all_uses_with fused_output last_fused_result = fused_outputs fused_outputs_set = OrderedSet fused_outputs node graph nodes node fused_outputs_set last_fused_result = node Move incorrect_order_nodes right after last fused_result incorrect_order_nodes = sorted incorrect_order_nodes key=lambda node node_indices node move_block_after incorrect_order_nodes last_fused_result _fuse_allreduce graph fx Graph comm_blocks list CommBlock node_indices dict fx Node int use_concat bool - CommBlock Given list allreduce CommBlock fuse CommBlocks into one CommBlock len comm_blocks == comm_blocks Find last input node all CommBlocks This node will served inserting point new collective op last_input_node = comm_blocks inputs last_input_index = - all_input_nodes = comm_block comm_blocks input_node = comm_block inputs all_input_nodes append input_node index = node_indices input_node index = last_input_index assert index = last_input_index last_input_node = input_node last_input_index = index use_concat fused_comm_block = _fuse_allreduce_by_concat graph last_input_node all_input_nodes comm_blocks - fused_comm_block = _fuse_with_coalesced_op graph last_input_node all_input_nodes comm_blocks - _scatter_fused_allreduce_waits graph fused_comm_block comm_blocks node_indices split_and_reshape=use_concat comm_block comm_blocks wait comm_block wait_nodes graph erase_node wait graph erase_node comm_block comm_node graph eliminate_dead_code fused_comm_block _bucket_size_fusion graph fx Graph comm_blocks list CommBlock bucket_size_mb int - Generator list CommBlock None None MB = bucket_size = MB bucket_cap_size = bucket_size_mb MB curr_size = curr_blocks = count = fuse_count = i block enumerate comm_blocks curr_blocks append block itemsize = block comm_node meta tensor_meta dtype itemsize curr_size += cast torch Size block shape numel itemsize count += curr_size bucket_size i = len comm_blocks - continue fuse_count += torch distributed get_rank == logger info DDP bucketing block d count= d curr_size= d bucket_size= d fuse_count count curr_size bucket_size Set debug counters counters inductor ddp_buckets = fuse_count yield curr_blocks bucket_size = bucket_cap_size curr_blocks = curr_size = count = _fuse_ddp_communication graph fx Graph algorithm_fn Callable Any fusion_fn Callable Any - None output reversed graph nodes output op == output break ddp_reducer_filter block CommBlock - bool isinstance block comm_node args fx Node block comm_node args target = aten div Tensor False len block wait_nodes users = gradient wait node should only used one user False Two cases gradient wait node should directly used output gradient None before bwd gradient wait node should directly used copy_ output block wait_nodes users next iter block wait_nodes users target = aten copy_ default False True ops = torch ops _c d_functional all_reduce_ default torch ops _c d_functional all_reduce default comm_blocks = get_all_comm_blocks graph ops comm_filter=ddp_reducer_filter node_indices = node i i node enumerate graph nodes block algorithm_fn graph comm_blocks fusion_fn graph block node_indices fuse_ddp_with_coalesced_op graph fx Graph bucket_size_mb int - None _fuse_ddp_communication graph partial _bucket_size_fusion bucket_size_mb=bucket_size_mb partial _fuse_allreduce use_concat=False fuse_ddp_with_concat_op graph fx Graph bucket_size_mb int - None _fuse_ddp_communication graph partial _bucket_size_fusion bucket_size_mb=bucket_size_mb partial _fuse_allreduce use_concat=True schedule_comm_wait graph fx Graph - None Delay execution wait tensors allreduce until its first user This algorithm considers intermediate users like split getitem wait node schedule those intermediate users well This will result better overlapping result ops = torch ops _c d_functional all_reduce_ default torch ops _c d_functional all_reduce default torch ops _c d_functional all_reduce_coalesced default torch ops _c d_functional all_reduce_coalesced_ default comm_blocks = get_all_comm_blocks graph ops comm_blocks Find all end users allreduce_users = OrderedSet fx Node allreduce comm_blocks output allreduce outputs allreduce_users update output users node_indices = node i i node enumerate graph nodes allreduce comm_blocks Find earliest first user -- target_node assert len allreduce outputs = f Found allreduce has zero outputs users -- allreduce Initialize target node avoid typing issues target_node = next iter next iter allreduce outputs users target_node_index = user user output allreduce outputs user output users index = node_indices user index target_node_index target_node = user target_node_index = index Move wait nodes all subsequent nodes comm_block before first user -- target_node wait_idx = - wait_idx node enumerate allreduce node_list node == allreduce wait_nodes break assert wait_idx = move_block_before allreduce node_list wait_idx target_node fuse_ddp_communication graph fx Graph passes list Callable None &#124; str bucket_size_mb int - None i pa enumerate passes GraphTransformObserver graph owning_module f fuse_ddp_communication_pass_ i isinstance pa str func = globals pa func = pa bucket_size_mb OrderedSet v name v inspect signature func parameters values func graph bucket_size_mb=bucket_size_mb func graph