Owner s module dynamo unittest collections abc Sequence typing Any Callable Union torch torch _dynamo torch _dynamo test_case torch _dynamo testing torch _dynamo testing EagerAndRecordGraphs torch fx graph_module GraphModule compile_and_extract_graph fn args kwargs - tuple Callable list torch fx GraphModule backend = EagerAndRecordGraphs result_fn = torch compile backend=backend fullgraph=True fn Run fn capture graph _ = result_fn args kwargs result_fn backend graphs get_num_input_nodes graph GraphModule - int Returns number input nodes input GraphModule counting number placeholder tensors placeholder_cnt = node graph graph nodes Missing some export tests so check manually placeholder_is_tensor = example_value node meta isinstance node meta example_value torch Tensor node op == placeholder placeholder_is_tensor placeholder_cnt += placeholder_cnt SimpleLinearModule torch nn Module Simple linear model parameter buffer basic testing purposes __init__ - None super __init__ fwd = torch nn Linear forward x torch Tensor - torch Tensor fwd x ResBlock torch nn Module Basic resnet building block - used testing structure more typical real models i e sequential activations batchnorm __init__ in_ int out_ int super __init__ conv = torch nn Sequential torch nn Conv d in_ out_ kernel_size= padding= torch nn BatchNorm d out_ torch nn ReLU conv = torch nn Sequential torch nn Conv d out_ out_ kernel_size= padding= torch nn BatchNorm d out_ activation = torch nn ReLU forward x torch Tensor - torch Tensor skip = x out = conv x out = conv out out += skip out = activation out out InstallParamsAsGraphAttrTests torch _dynamo test_case TestCase torch _dynamo config patch inline_inbuilt_nn_modules=True torch _dynamo config patch install_free_tensors=False check_num_inputs_and_equality_no_install fn_to_compile Union torch nn Module Callable expected_num_inline_inputs int example_inputs Sequence Any - None Compiles original fn then Checks number inputs graph expected_num_inputs Checks compiled fn original fn equal inlined ex opt_fn graphs = compile_and_extract_graph fn_to_compile example_inputs assertEqual len graphs msg= Expected graph no breaks actual_num_inputs = get_num_input_nodes graphs assertEqual actual_num_inputs expected_num_inline_inputs assertEqual opt_fn example_inputs fn_to_compile example_inputs torch _dynamo config patch inline_inbuilt_nn_modules=True torch _dynamo config patch install_free_tensors=True check_num_inputs_and_equality_install fn_to_compile Union torch nn Module Callable expected_num_installed_inputs int example_inputs Sequence Any - None Compiles original fn then Checks number inputs when installed consistent original_fn Checks compiled fn when installed original fn equal opt_installed_fn graphs = compile_and_extract_graph fn_to_compile example_inputs assertEqual len graphs msg= Expected graph no breaks actual_num_inputs = get_num_input_nodes graphs assertEqual actual_num_inputs expected_num_installed_inputs assertEqual opt_installed_fn example_inputs fn_to_compile example_inputs ==================== Test Params Buffer NN Module ==================== test_optimizing_linear - None net = SimpleLinearModule input = torch randn Expected + = check_num_inputs_and_equality_no_install net input check_num_inputs_and_equality_install net input test_breadth_linear - None BreadthModel torch nn Module __init__ - None super __init__ fwd = torch nn Linear fwd = torch nn Linear fwd = torch nn Linear fwd = torch nn Linear fwd = torch nn Linear forward x torch Tensor - torch Tensor fwd x + fwd x + fwd x + fwd x + fwd x net = BreadthModel input = torch randn Expected + = check_num_inputs_and_equality_no_install net input check_num_inputs_and_equality_install net input test_nested_linear - None NestedModel torch nn Module __init__ inner_module torch nn Module - None super __init__ fwd = torch nn Linear inner_module = inner_module forward x torch Tensor - torch Tensor fwd inner_module x Nest x kDepth = net = SimpleLinearModule _ range kDepth net = NestedModel net input = torch randn check_num_inputs_and_equality_no_install net + kDepth + input check_num_inputs_and_equality_install net input test_simple_batchnorm - None net = torch nn BatchNorm d tensor = torch randn BatchNorm d has params buffers check_num_inputs_and_equality_no_install net tensor check_num_inputs_and_equality_install net tensor test_nets_as_input - None Tests when nn Module input fn we optimizing In case we should treat regular input which means we can lift parameters buffers should install them Test nn model input net = SimpleLinearModule net = SimpleLinearModule x = torch randn test_fn x torch Tensor net torch nn Module - torch Tensor net x When nn input we don t install params check_num_inputs_and_equality_no_install test_fn x net check_num_inputs_and_equality_install test_fn x net test_fn x torch Tensor net torch nn Module net torch nn Module - torch Tensor net x + net x check_num_inputs_and_equality_no_install test_fn x net net check_num_inputs_and_equality_install test_fn x net net test_fn x torch Tensor net torch nn Module - torch Tensor net x + net x In case local scope net here we can install check_num_inputs_and_equality_no_install test_fn x net check_num_inputs_and_equality_install test_fn x net test_fn_list x torch Tensor nets list torch nn Module sum net x net nets check_num_inputs_and_equality_no_install test_fn_list x net net check_num_inputs_and_equality_install test_fn_list x net net test_resnet_structure - None net = ResBlock tensor = torch randn Conv d has params BatchNorm d has buffers + params Relu has params So expected = + + + = + input check_num_inputs_and_equality_no_install net tensor check_num_inputs_and_equality_install net tensor test_transformer - None needs eval mode - must disable dropout transformer = torch nn Transformer d_model= eval src = torch rand tgt = torch rand check_num_inputs_and_equality_no_install transformer src tgt check_num_inputs_and_equality_install transformer src tgt ==================== Test Parameters Buffers input ==================== test_optimizing_params_in_input - None param = torch nn Parameter torch randn net = SimpleLinearModule test_fn x torch Tensor - torch Tensor net x check_num_inputs_and_equality_no_install test_fn param check_num_inputs_and_equality_install test_fn param x = torch randn test_fn x torch Tensor param torch nn Parameter - torch Tensor net x + param net gets installed param does here check_num_inputs_and_equality_no_install test_fn x param check_num_inputs_and_equality_install test_fn x param global global_param global_param = torch nn Parameter torch randn test_fn x torch Tensor - torch Tensor net x + global_param net global does too check_num_inputs_and_equality_no_install test_fn x check_num_inputs_and_equality_install test_fn x test_fn x torch Tensor list_params list torch nn Parameter - torch Tensor net x + sum list_params list_params should installed check_num_inputs_and_equality_no_install test_fn x param param check_num_inputs_and_equality_install test_fn x param param test_optimizing_buffer_in_input - None buf = torch nn Buffer data=torch ones net = SimpleLinearModule test_fn x torch Tensor - torch Tensor net x check_num_inputs_and_equality_no_install test_fn buf check_num_inputs_and_equality_install test_fn buf x = torch randn test_fn x torch Tensor buf torch nn Buffer net x + buf net gets installed buf does here check_num_inputs_and_equality_no_install test_fn x buf check_num_inputs_and_equality_install test_fn x buf global global_buf global_buf = torch nn Buffer torch randn test_fn x torch Tensor - torch Tensor net x + global_buf net global does too check_num_inputs_and_equality_no_install test_fn x check_num_inputs_and_equality_install test_fn x test_optimizing_buffer_and_param_in_input - None param = torch nn Parameter torch randn buf = torch nn Buffer data=torch ones x = torch randn test_linear x torch Tensor - torch Tensor param x + buf check_num_inputs_and_equality_no_install test_linear x check_num_inputs_and_equality_install test_linear x test_linear_explicit x torch Tensor torch Tensor b torch Tensor - torch Tensor x + b Now param buf input so should inlined check_num_inputs_and_equality_no_install test_linear_explicit x param buf check_num_inputs_and_equality_install test_linear_explicit x param buf InstallParamsWhenExport torch _dynamo test_case TestCase torch _dynamo config patch inline_inbuilt_nn_modules=True torch _dynamo config patch install_free_tensors=True check_export_matches_expectation fn_to_export Callable expected_num_exported_inputs int example_inputs Sequence Any - None Exports original fn then Checks number inputs exported expected_num_exported_inputs Checks exported fn original fn equal exported_fn = torch _dynamo export fn_to_export out_graph = exported_fn example_inputs actual_num_inputs = get_num_input_nodes out_graph assertEqual actual_num_inputs expected_num_exported_inputs assertEqual out_graph example_inputs fn_to_export example_inputs test_simple_linear - None net = SimpleLinearModule input = torch randn check_export_matches_expectation net input test_fn x torch Tensor - torch Tensor net x check_export_matches_expectation test_fn input Check multiple inputs test_fn_ x torch Tensor y torch Tensor - torch Tensor net x + net y input = torch randn check_export_matches_expectation test_fn_ input input test_simple_batchnorm - None net = torch nn BatchNorm d tensor = torch randn check_export_matches_expectation net tensor test_fn x torch Tensor - torch Tensor net x check_export_matches_expectation test_fn tensor test_resnet_structure - None net = ResBlock tensor = torch randn check_export_matches_expectation net tensor test_fn x torch Tensor - torch Tensor net x check_export_matches_expectation test_fn tensor test_transformer - None transformer = torch nn Transformer d_model= eval src = torch rand tgt = torch rand check_export_matches_expectation transformer src tgt test_fn src torch Tensor tgt torch Tensor - torch Tensor transformer src tgt check_export_matches_expectation test_fn src tgt test_optimizing_params_in_input - None param = torch nn Parameter torch randn net = SimpleLinearModule test_fn x torch Tensor - torch Tensor net x check_export_matches_expectation net param check_export_matches_expectation test_fn param x = torch randn test_fn x torch Tensor param torch nn Parameter - torch Tensor net x + param net gets installed param does here check_export_matches_expectation test_fn x param test_fn x torch Tensor list_params list torch nn Parameter - torch Tensor net x + sum list_params list_params should installed inlined here check_export_matches_expectation test_fn x param param test_optimizing_buffer_in_input - None buf = torch nn Buffer data=torch ones net = SimpleLinearModule test_fn x torch Tensor - torch Tensor net x check_export_matches_expectation net buf check_export_matches_expectation test_fn buf x = torch randn test_fn x torch Tensor buf torch nn Buffer - torch Tensor net x + buf net gets installed buf does here check_export_matches_expectation test_fn x buf test_optimizing_buffer_and_param_in_input - None param = torch nn Parameter torch randn buf = torch nn Buffer data=torch ones x = torch randn test_linear_explicit x torch Tensor torch Tensor b torch Tensor - torch Tensor x + b Now param buf input so should inlined check_export_matches_expectation test_linear_explicit x param buf test_global_tensor_export - None global x x = torch randn fn torch Tensor - torch Tensor + x inp = torch randn check_export_matches_expectation fn inp test_nonlocal_closure - None x = torch randn fn torch Tensor - torch Tensor + x inp = torch randn check_export_matches_expectation fn inp torch _dynamo config patch inline_inbuilt_nn_modules=True torch _dynamo config patch install_free_tensors=True test_modify_net_state - None Mod torch nn Module __init__ super __init__ linear = torch nn Linear = None forward x None = torch ones_like x linear x + mod = Mod inp = torch randn NOTE since fn modifies original need get reference value before tracing res = mod inp mod = None ep = torch _dynamo export mod graph _ = ep inp assertEqual graph inp res test_list_of_tensor - None fn x list torch Tensor x + x inp = torch tensor torch tensor check_export_matches_expectation fn inp test_nested_list_of_tensor - None fn x list Union list torch Tensor torch Tensor x + x type ignore index inp = torch tensor torch tensor check_export_matches_expectation fn inp test_dict_of_tensor - None inp_dict = temp torch tensor fn inp dict str torch Tensor - torch Tensor inp_dict temp + check_export_matches_expectation fn inp_dict TODO lucaskabela register flatten unflatten function so we can evaluate test unittest expectedFailure test_user_defined_object - None UserDefinedTestClass __init__ x y - None x = x y = y x = torch randn y = torch randn fn obj UserDefinedTestClass inp torch Tensor - torch Tensor obj x + obj y + inp z = torch randn check_export_matches_expectation fn UserDefinedTestClass x y z test_tensors_as_nn_attr - None Mod torch nn Module __init__ super __init__ = torch ones b = torch ones forward x + b + x mod = Mod inp = torch randn check_export_matches_expectation mod inp __name__ == __main__ torch _dynamo test_case run_tests run_tests