mypy allow-untyped-defs functools itertools logging operator typing collections Counter collections abc Sequence typing Any torch torch _guards torch utils _pytree pytree torch _dynamo utils counters torch _inductor constant_folding ConstantFolder torch _inductor fx_passes dedupe_symint_uses _SymHashingDict torch _inductor utils get_gpu_type torch fx experimental symbolic_shapes guard_or_false guard_or_true statically_known_true torch multiprocessing reductions StorageWeakRef torch utils _ordered_set OrderedSet config pattern_matcher Arg CallFunction init_once_fakemode KeywordArg Match MULTIPLE PatternMatcherPass PatternMatcherPassBase register_graph_pattern stable_topological_sort decompose_mem_bound_mm check_device replace_random replace_random_passes PatternMatcherPass = functools partial PatternMatcherPassBase subsystem= joint_graph_passes log = logging getLogger __name__ patterns = PatternMatcherPass aten = torch ops aten prims = torch ops prims pass_patterns = patterns PatternMatcherPass init_once_fakemode lazy_init fuse_attention _sfdp_init misc_patterns _misc_patterns_init pad_mm _pad_mm_init _pad_mm_init _sfdp_init _misc_patterns_init remove_no_ops gm torch fx GraphModule zeros OrderedSet torch fx Node ones OrderedSet torch fx Node torch utils _python_dispatch _disable_current_modes Removes no-ops + - graph = gm graph fake_tensors_eq t t fields= shape dtype device any isinstance t torch Tensor t t t False field fields getattr t field = getattr t field False True replace_no_op node replace_input_index replacement = node args replace_input_index https github com pytorch pytorch issues causes non-Tensor inputs even ops only Tensor inputs TODO - decompose type promote avoid all isinstance arg torch fx Node arg node args fake_tensors_eq node meta val replacement meta val fake_tensors_eq node meta val replacement meta val shape device graph inserting_after node replacement = graph call_function torch ops prims convert_element_type default args= replacement node meta val dtype node replace_all_uses_with replacement replacement meta update node meta graph erase_node node node graph find_nodes op= call_function target=aten add Tensor TODO handle Tensor-Scalar adds s different schema len node args == any e zeros e node args node kwargs get alpha = continue replace_index = node args zeros replace_no_op node replace_index node graph find_nodes op= call_function target=aten sub Tensor len node args == node args zeros node kwargs get alpha = continue replace_no_op node node graph find_nodes op= call_function target=aten mul Tensor len node args == any e ones e node args continue replace_input_index = node args ones replace_no_op node replace_input_index node graph find_nodes op= call_function target=aten div Tensor len node args == node args ones replace_no_op node meta tensors returned graph have no data can replaced empty_strided output_node graph find_nodes op= output had_meta_return = False visit n nonlocal had_meta_return val = n meta get val isinstance val torch Tensor val device type == meta graph inserting_before output_node n replace_all_uses_with graph call_function torch ops aten empty_strided default args= val size val stride kwargs= dtype val dtype device val device had_meta_return = True torch fx map_arg output_node args visit had_meta_return graph eliminate_dead_code remove_redundant_views gm torch fx GraphModule Removes redundant views reusing existing ones torch utils _python_dispatch _disable_current_modes A dictionary mapping tensor all aliased views views dict torch fx Node dict torch dtype torch fx Node = graph = gm graph node graph find_nodes op= call_function target=torch ops aten view dtype src = node args to_type = node args existing_views = views get src is_needed = True existing_views Replace view existing view available alias = existing_views get to_type alias is_needed = False node replace_all_uses_with alias alias meta update node meta graph erase_node node from_type = src meta val dtype existing_views = from_type src views src = existing_views is_needed Save new alias do replace existing one existing_views setdefault to_type node views node = existing_views Clean up unused views while True unused_views = alias alias views alias users len unused_views == break unused unused_views views pop unused graph erase_node unused UniformValueConstantFolder ConstantFolder Runs constant folding replaces tensors have uniform value tensor constructor call aten full shape value __init__ gm skip_constructors=False - None super __init__ gm skip_constructors node_storages_ptrs dict torch fx Node int = constant_data_ptrs dict torch fx Node StorageWeakRef = we may constant fold tensor which graph has sym size see constant folding refining symints node_replacements_shapes dict torch fx Node list int = initialize symint - node mapping so we can use symint nodes full constructors symint_nodes = _SymHashingDict n module graph nodes type ignore union-attr val n meta isinstance n meta val torch SymInt n meta val symint_nodes symint_nodes n meta val = n reference torch _funtorch partitioners py get_default_op_list view_op_packets = aten squeeze aten unsqueeze aten alias aten view aten slice aten t prims broadcast_in_dim aten expand aten as_strided aten permute indexing_op_packets = OrderedSet aten slice _add_peephole_patterns _add_peephole_patterns - None Add peephole patterns nodes where we can infer constant value even some inputs node unknown op itertools chain module graph find_nodes type ignore operator union-attr op= call_function target=torch ops aten mul Tensor module graph find_nodes type ignore operator union-attr op= call_function target=torch ops aten mul Scalar tensor_val = op meta get val None isinstance tensor_val torch Tensor continue is_zero_int arg Any - bool isinstance arg int arg == any is_zero_int op args continue t = torch full shape value dtype=tensor_val dtype device=tensor_val device pin_memory=False add_node_replacement op t _support_dynamic_shape True insertable_tensor_check t torch Tensor - bool True add_node_replacement node torch fx Node tensor torch Tensor - None node_replacements node = tensor flatten item node_replacements_shapes node = node meta val shape constant_data_ptrs node = StorageWeakRef tensor untyped_storage insert_placerholder_values env dict torch fx Node Any - None n module graph find_nodes op= placeholder type ignore operator union-attr val n meta isinstance n meta val torch SymInt env n = n meta val env n = unknown_value _deduce_value node torch fx Node deduce value full-like nodes constructors substitute value tensor size view ops indexing substitute value same input pointwise ops run node get substitute value deal some special ops otherwise stop deduce value unknown value TODO cat more indexing TODO - do cpu avoid syncs single-elem attrs node op == get_attr node op == call_function node target torch ops aten lift_fresh_copy default out = super ConstantFolder run_node node isinstance out torch Tensor out numel == out handle device_put op node target == prims device_put default super ConstantFolder run_node node constructors ops node op == call_function node target aten full default len node args == args kwargs = fetch_args_kwargs_from_env node value = args Don t specialize symbolic value isinstance value torch SymInt torch SymFloat torch SymBool new_args = value aten full default new_args node kwargs handle before view ops because changes value node target aten view dtype super ConstantFolder run_node node view ops input tensor first argument hasattr node target overloadpacket node target overloadpacket view_op_packets node target overloadpacket indexing_op_packets assert isinstance node args torch fx Node env node args we don t want unknown value symints so we can still constant fold through their use constructors views we see them pointwise node e g tensor symint we will bail val node meta isinstance node meta val torch SymInt node meta val pointwise ops isinstance node target torch _ops OpOverload torch Tag pointwise node target tags node target torch ops aten scalar_tensor default args kwargs = fetch_args_kwargs_from_env node flattened_inputs = pytree arg_tree_leaves args kwargs any isinstance inp torch SymInt inp flattened_inputs unknown_value we run ops dim so remove memory_format avoid error kwargs = dict kwargs kwargs pop memory_format None node target args kwargs unknown_value constant_fold_uniform_value gm torch fx GraphModule torch utils _python_dispatch _disable_current_modes Runs constant folding replaces constants which can constructed single ` full ` call Calls into remove_no_ops aten = torch ops aten Constant folding can leak memory especially repeated compilation so we only going remove constants which can replaced constructor cf = UniformValueConstantFolder gm cf run node_replacements = cf node_replacements note constant folding refining symints constant folding will partially evaluate graph such values which have dependencies which entirely known compile time may also become compile time constants some cases will include symints which we had yet previously deduced guaranteed constant value then deduced constant folding example unbacked_symint_eq_ = torch full item torch full unbacked_symint_eq_ node_replacements_shapes = cf node_replacements_shapes graph = gm graph zeros = OrderedSet Any ones = OrderedSet Any Got failures ` test_is_set_to_cuda ` we change aliasing constants so just constant-ify Tensor unaliased constant_data_ptr_count typing Counter StorageWeakRef = Counter node cf node_replacements constant_data_ptr_count cf constant_data_ptrs node += node value node_replacements items we dont have functional way right now instantiating non-contiguous tensor full zeros ones right now hasn t shown up important yet val node meta This can only happen AOTI continue fake_tensor = node meta val fake_tensor is_contiguous memory_format=torch contiguous_format continue TODO - sure about lossy uint- python value- uint conversions fake_tensor dtype torch uint torch uint torch uint torch uint continue constant_data_ptr_count cf constant_data_ptrs node continue graph inserting_after node conversion tensor back value can lossy just use original full ctor value node op == call_function node target aten full default len node args == value = node args refines symints see constant folding refining symints above runtime_size compile_time_size zip node_replacements_shapes node fake_tensor shape torch _check runtime_size == compile_time_size replace SymInt Node before creating new full node e g s - arg _ node_shape = node_replacements_shapes node all isinstance s torch SymInt s cf symint_nodes s node_shape continue shapes = cf symint_nodes s isinstance s torch SymInt s s node_replacements_shapes node zeros ones just get traced into full so we insert those new_node = graph call_function aten full default args= shapes value kwargs= dtype fake_tensor dtype layout torch strided device fake_tensor device pin_memory False new_node meta update node meta node replace_all_uses_with new_node graph erase_node node value == zeros add new_node value == ones add new_node remove_no_ops gm zeros ones remove_redundant_views gm canonicalize_quant_mapping gm torch fx GraphModule torch ops higher_order invoke_quant_packed repeated_subgraph quant_invoke_ _ arg _ arg _ - torch ops higher_order invoke_quant repeated_subgraph arg _ arg _ scheme = nf graph = gm graph invoke_quant_invocations = graph find_nodes op= call_function target=torch ops higher_order invoke_quant_packed invoke_quant invoke_quant_invocations kwargs = dict invoke_quant kwargs quant_options_node = kwargs pop quant_options None quant_options_node None assert isinstance quant_options_node torch fx Node quant_options = torch _higher_order_ops InvokeQuant invoke_quant kwargs quant_options args invoke_quant kwargs quant_options kwargs quant_options = torch _higher_order_ops InvokeQuant subgraph args = invoke_quant args gm graph inserting_before invoke_quant invoke_quant_replacement = graph call_function torch _higher_order_ops invoke_quant subgraph args pyrefly ignore bad-argument-type kwargs invoke_quant_replacement meta update subgraph meta invoke_quant_replacement meta quant_options = quant_options invoke_quant replace_all_uses_with invoke_quant_replacement graph erase_node invoke_quant quant_options_node len quant_options_node users == graph erase_node quant_options_node first_user = next iter invoke_quant_replacement users len invoke_quant_replacement users == len subgraph users == first_user target operator getitem first_user args == subgraph_graph = getattr gm subgraph target output_node = torch _inductor utils output_node subgraph_graph assert isinstance output_node args list tuple len output_node args == unpacked_output = output_node args output_node args = unpacked_output val output_node meta output_node meta val = output_node meta val subgraph_graph recompile invoke_quant_replacement meta update first_user meta first_user replace_all_uses_with invoke_quant_replacement graph erase_node first_user canonicalize_aten_ir_passes gm torch fx GraphModule Canonicalization passes will run immediately after aot autograd tracing Thsis must run before all other graph passes canonicalize_quant_mapping gm joint_graph_passes graph torch fx GraphModule Run FX transformations joint forwards+backwards graph GraphTransformObserver = functools partial torch fx passes graph_transform_observer GraphTransformObserver subsystem= joint_graph_passes lazy_init count = must occur before other passes canonicalize_aten_ir_passes graph config joint_custom_pre_pass None GraphTransformObserver graph joint_custom_pre_pass apply_graph_pass config joint_custom_pre_pass count += post_grad remove_noop_ops GraphTransformObserver graph remove_noop_ops apply_graph_pass remove_noop_ops config joint_graph_constant_folding GraphTransformObserver graph constant_fold_uniform_value apply_gm_pass constant_fold_uniform_value config pattern_matcher i patterns enumerate pass_patterns maybe_count = GraphTransformObserver graph f pass_pattern_ i apply_graph_pass patterns apply count += maybe_count maybe_count None config fallback_random trying into bisector because decomps may have already affected rng reproducibility we ll instead explicitly turn off config count += replace_random_passes graph config joint_custom_post_pass None GraphTransformObserver graph joint_custom_post_pass apply_graph_pass config joint_custom_post_pass count += count stable_topological_sort graph graph graph graph lint graph recompile graph register_graph_pattern CallFunction torch ops prims iota default KeywordArg length start=KeywordArg start step=KeywordArg step dtype=KeywordArg dtype device=KeywordArg device requires_grad=KeywordArg requires_grad pyrefly ignore bad-argument-type pass_dict=patterns fix_iota_device match Match length start step dtype device requires_grad Eager supports aten index cuda_tensor torch arange device= cpu But results implicit host-device-copy breaks cudagraphs Rewrite arange use CUDA node = match nodes user_devices = OrderedSet torch device user node users user op == call_function user target aten index Tensor aten index_put default hasattr user meta get val device user_devices add user meta val device type ignore union-attr bail out len user_devices == val node meta user_device = user_devices device type = user_device type repl = match graph call_function torch ops prims iota default length start start step step dtype dtype device user_device requires_grad requires_grad repl meta update node meta repl meta val = repl meta val user_device node replace_all_uses_with repl match erase_nodes register_graph_pattern CallFunction torch ops prims convert_element_type default CallFunction torch ops prims convert_element_type default KeywordArg arg KeywordArg dtype KeywordArg dtype pyrefly ignore bad-argument-type pass_dict=patterns pointless_convert match Match arg dtype torch dtype dtype torch dtype Remove chain dtype conversions often created AMP graph = match graph node = match output_node allowed = torch float torch bfloat torch float torch float dtype allowed dtype allowed repl = graph call_function torch ops prims convert_element_type default arg dtype repl meta update node meta node replace_all_uses_with repl match erase_nodes definitely_equal old_sizes Sequence torch SymInt &#124; int new_sizes Sequence torch SymInt &#124; torch fx Node &#124; int - bool Leverage guard_or_true false compare two lists int symint equal Useful compare sizes strides etc Can handle - new_sizes which happens size arguments view op old_sizes supposed tensor shape should contain - new_sizes can contains fx Node when dynamic shape enabled In case new_sizes i meta val contains real torch SymInt num_neg = len old_sizes = len new_sizes False lhs_item rhs_item zip old_sizes new_sizes isinstance rhs_item torch fx Node rhs_item = rhs_item meta val assert isinstance lhs_item int torch SymInt type lhs_item assert isinstance rhs_item int torch SymInt type rhs_item It still makes sense call guard_or_true false since lhs_item rhs_item torch SymInt rather than sympy expressions when dynamic shape enabled guard_or_false lhs_item == rhs_item continue guard_or_true rhs_item = - False num_neg += num_neg False True register_graph_pattern CallFunction torch ops aten view default KeywordArg arg KeywordArg size pyrefly ignore bad-argument-type pass_dict=patterns pointless_view match Match arg size Remove no-op view node = match output_node arg_size = list node args meta val shape type ignore union-attr definitely_equal arg_size size node replace_all_uses_with node args type ignore arg-type match erase_nodes register_graph_pattern CallFunction aten view default CallFunction aten view default KeywordArg arg KeywordArg size KeywordArg size pyrefly ignore bad-argument-type pass_dict=patterns pointless_view_pair match Match arg size size Remove pair views pointless node = match output_node arg_size = list arg meta val shape definitely_equal arg_size size node replace_all_uses_with arg match erase_nodes counters inductor removed_pointless_view_pair += register_graph_pattern CallFunction aten permute default CallFunction aten permute default KeywordArg arg KeywordArg perm KeywordArg perm pyrefly ignore bad-argument-type pass_dict=patterns pointless_permute_pair match Match arg perm perm rank = len perm assert len perm == rank i range rank perm perm i = i bail out node = match output_node node replace_all_uses_with arg match erase_nodes register_graph_pattern CallFunction aten bmm Arg Arg pyrefly ignore bad-argument-type pass_dict=patterns bmm_to_mm match Match mat torch fx Node mat torch fx Node Convert bmm mm when batch size repl b torch mm squeeze b squeeze unsqueeze check_device mat meta val mat meta val get_gpu_type statically_known_true mat meta val shape == statically_known_true mat meta val shape == pyrefly ignore bad-argument-type match replace_by_example repl mat mat When softmax used temperature other scaling we get pattern scale x - scale x amax dim keepdim=True which expected most zero we may end up numerical discrepancies between recomputed values scale x inside out reduction depending compiler optimizations e g use fma instructions Here we replace mathematically equivalent scale x - x amax dim keepdim=True which more stable we only compute scaling once NOTE This pattern must come after fused attention matching _partial_softmax_pattern linear_func reverse=False to_dtype=False Allow matching inp other other input reverse scaled = CallFunction linear_func KeywordArg other KeywordArg inp _users=MULTIPLE scaled = CallFunction linear_func KeywordArg inp KeywordArg other _users=MULTIPLE to_dtype scaled = CallFunction prims convert_element_type scaled KeywordArg dtype _users=MULTIPLE amax = CallFunction aten amax default scaled KeywordArg dim KeywordArg keepdim CallFunction aten sub Tensor scaled amax _other_is_broadcasted_in_dim match Check scaling factor constant across reduction dim so scaling doesn t change which index corresponds maximum value other = match kwargs other isinstance other int float True inp = match kwargs inp all isinstance x torch fx Node x inp other False inp_example = inp meta val other_example = other meta val isinstance other_example torch SymInt torch SymFloat True all isinstance x torch Tensor x inp_example other_example False inp_ndim = inp_example ndim other_shape = other_example shape inp_ndim len other_shape False Pad other_shape same ndim inp other_shape = inp_ndim - len other_shape + list other_shape dim = match kwargs dim isinstance dim int dim = dim all statically_known_true other_shape d == d dim mul_softmax_pattern match Match inp other dim keepdim dtype=None repl inp other dtype None inp = inp dtype sign int &#124; float &#124; torch Tensor isinstance other int float torch SymInt torch SymFloat sign = other = - one = torch scalar_tensor dtype=inp dtype device=inp device sign = torch where other = one -one inp = inp sign max_ = torch amax inp dim=dim keepdim=keepdim pyrefly ignore unsupported-operation inp - max_ sign other pyrefly ignore bad-argument-type match replace_by_example repl inp other reverse to_dtype itertools product False True repeat= register_graph_pattern _partial_softmax_pattern aten mul Tensor reverse=reverse to_dtype=to_dtype pyrefly ignore bad-argument-type pass_dict=pass_patterns extra_check=_other_is_broadcasted_in_dim mul_softmax_pattern div_softmax_pattern match Match inp other dim keepdim dtype=None repl inp other dtype None inp = inp dtype sign int &#124; float &#124; torch Tensor isinstance other int float torch SymInt torch SymFloat sign = other = - one = torch scalar_tensor dtype=inp dtype device=inp device sign = torch where other = one -one inp = inp sign max_ = torch amax inp dim=dim keepdim=keepdim pyrefly ignore unsupported-operation inp - max_ sign other pyrefly ignore bad-argument-type match replace_by_example repl inp other to_dtype False True register_graph_pattern _partial_softmax_pattern aten div Tensor to_dtype=to_dtype pyrefly ignore bad-argument-type pass_dict=pass_patterns extra_check=_other_is_broadcasted_in_dim div_softmax_pattern