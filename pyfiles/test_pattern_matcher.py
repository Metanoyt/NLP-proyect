Owner s module inductor copy itertools os unittest collections abc Callable typing Optional torch torch _dynamo config dynamo_config torch _inductor config inductor_config torch _inductor fx_passes post_grad torch nn functional F torch _dynamo utils count_calls counters torch _higher_order_ops auto_functionalize auto_functionalized torch _higher_order_ops out_dtype out_dtype torch _inductor fx_passes joint_graph torch _inductor pattern_matcher Arg CallFunction fwd_only gen_pattern is_mutation_op KeywordArg Match PatternMatcherPass PatternPrettyPrinter register_graph_pattern register_replacement stable_topological_sort torch _inductor test_case run_tests TestCase torch _inductor utils run_and_get_code torch _inductor virtualized V torch fx experimental proxy_tensor make_fx torch testing FileCheck torch testing _internal common_cuda SM OrLater xfailIfSM torch testing _internal common_device_type skipCUDAIf torch testing _internal common_utils instantiate_parametrized_tests IS_LINUX parametrize skipIfRocm skipIfXpu torch testing _internal inductor_utils GPU_TYPE HAS_GPU IS_BIG_GPU torch utils _pytree pytree aten = torch ops aten instantiate_parametrized_tests TestPatternMatcher TestCase device_type = GPU_TYPE common fn args expected_matches expected_nodes additional_check=lambda code None reference_in_float=False counters clear torch manual_seed reference_in_float ref_inputs = pytree tree_map_only torch Tensor lambda x x torch float args ref_inputs = args expected = fn ref_inputs torch manual_seed actual codes = run_and_get_code torch compile fn args len codes == codes = codes torch testing assert_close actual expected check_dtype=not reference_in_float assertEqual counters inductor pattern_matcher_count expected_matches assertEqual counters inductor pattern_matcher_nodes expected_nodes additional_check codes counters clear inductor_config patch max_autotune_gemm=True test_mm_plus_mm fn b c d torch add torch mm b torch mm c d when m == n m == n mm_plus_mm can matched fused op fusible_args_list = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE args fusible_args_list common fn args fusible can only match add mm unfusible_args_list = https github com pytorch pytorch issues torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE args unfusible_args_list common fn args _test_fused_int_mm_mul_impl fn args fused_int_mm_mul_expected=True torch _dynamo reset counters clear ref = fn args test code = run_and_get_code torch compile fn mode= max-autotune args assertEqual triton_tem_fused__int code fused_int_mm_mul_expected fused_int_mm_mul_expected indices = ~ref isinf torch testing assert_close ref indices test indices also checks dtype correct skipIfXpu skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_fused_int_mm_mul fn b c out_dtype torch ops aten mm default torch int b c fn b c out_dtype torch ops aten mm default torch int b c torch bfloat args_list = torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch float device=GPU_TYPE + torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch bfloat device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch float device=GPU_TYPE args args_list _test_fused_int_mm_mul_impl fn args True _test_fused_int_mm_mul_impl fn args True test_duplicate_search collections abc Callable Iterable torch torch _inductor pattern_matcher fwd_only PatternMatcherPass register_replacement pattern x torch Tensor - torch Tensor x + replacement x torch Tensor - torch Tensor x - pattern x torch Tensor - torch Tensor x + replacement x torch Tensor - torch Tensor x - patterns = PatternMatcherPass inputs = torch empty dtype=torch float device=GPU_TYPE register_replacement pattern replacement inputs fwd_only patterns register_replacement pattern replacement inputs fwd_only patterns count = custom_pass graph torch fx Graph nonlocal count count = patterns apply graph custom_backend graph torch fx GraphModule example_inputs Iterable torch Tensor - Callable torch _inductor config current_config = config shallow_copy_dict torch _inductor compile_fx compile_fx current_config post_grad_custom_post_pass = custom_pass compile_fx graph example_inputs config_patches=current_config torch compile backend=custom_backend f x torch Tensor - torch Tensor y = x + y = y relu + y f_replaced x torch Tensor - torch Tensor y = x - y = y relu - y inp = torch rand device=GPU_TYPE assertEqual f inp f_replaced inp assertEqual count skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu inductor_config patch force_fuse_int_mm_with_mul=True inductor_config patch test_configs runtime_triton_dtype_assert True test_fused_int_mm_mul_epilogue fn b c out_dtype torch ops aten mm default torch int b c relu fn b c out_dtype torch ops aten mm default torch int b c torch bfloat relu args_list = torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch float device=GPU_TYPE + torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch bfloat device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch float device=GPU_TYPE args args_list _test_fused_int_mm_mul_impl fn args True _test_fused_int_mm_mul_impl fn args True skipIfRocm skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_fused_int_mm_mul_gating fn b c out_dtype torch ops aten mm default torch int b c args = torch randint - dtype=torch int device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn dtype=torch float device=GPU_TYPE _test_fused_int_mm_mul_impl fn args True _test_mixed_impl fn args mixed_mm_expected fallback_mixed_mm_expected rtol=None atol=None torch _dynamo reset counters clear ref = fn args test code = run_and_get_code torch compile fn args torch testing assert_close ref test rtol=rtol atol=atol mixed_mm_expected FileCheck check k_idx check check tl dot run code extern_kernels mm code FileCheck check k_idx check_not check tl dot run code fallback_mixed_mm_expected extern_mm = extern_kernels mm code FileCheck check call check run check triton_tem extern_mm extern_kernels mm run code skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_mixed_mm fn b torch mm b dtype args_list = torch randn device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch bfloat torch randint - dtype=torch int device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch float torch randint dtype=torch uint device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch float torch randn device=GPU_TYPE dtype=torch bfloat args args_list _test_mixed_impl fn args True False skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_mixed_mm_exhaustive_dtypes fn b torch mm b dtype dtypes_left = torch float torch float torch bfloat dtypes_right = torch int torch uint dtype_ranges = torch uint torch int - dtype_left dtype_right itertools product dtypes_left dtypes_right low high = dtype_ranges dtype_right args = torch randn dtype=dtype_left device=GPU_TYPE torch randint low high dtype=dtype_right device=GPU_TYPE _test_mixed_impl fn args True False rtol= atol= e- skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_mixed_mm_bad_cases fn b torch mm b dtype args_list = torch randn device=GPU_TYPE dtype=torch float torch randint - dtype=torch int device=GPU_TYPE t torch randn device=GPU_TYPE dtype=torch bfloat torch randint dtype=torch uint device=GPU_TYPE t args args_list _test_mixed_impl fn args True False skipCUDAIf SM OrLater need sm_ inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True unittest skipIf IS_BIG_GPU templates require big gpu test_mixed_mm_epi_works fn b c d torch mm b dtype c + d args_list = torch randn device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch bfloat torch randint - dtype=torch int device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch bfloat torch randn device=GPU_TYPE dtype=torch bfloat torch randn device=GPU_TYPE dtype=torch float torch randint dtype=torch uint device=GPU_TYPE torch randn device=GPU_TYPE dtype=torch float torch randn device=GPU_TYPE dtype=torch float args args_list _test_mixed_impl fn args True False skipCUDAIf SM OrLater need sm_ unittest skipIf IS_BIG_GPU templates require big gpu test_mixed_mm_gating fn b torch mm b dtype args = torch randn device=GPU_TYPE torch randint - dtype=torch int device=GPU_TYPE will no max autotune will generate fused template _test_mixed_impl fn args False True inductor_config patch benchmark_epilogue_fusion False max_autotune_gemm_backends TRITON max_autotune_gemm True _test_mixed_impl fn args True False test_mixed_mm_cpu fn b torch mm b dtype args = torch randn torch randint - dtype=torch int _test_mixed_impl fn args False False parametrize case GPU_TYPE dynamic GPU_TYPE test_unsuccessful_partial_reuse case shape device = case test_fn x partial = torch amax x True full = torch amax x partial full shape == dynamic x = torch rand device=GPU_TYPE torch _dynamo mark_dynamic x x = torch randn shape device=device compiled_fn = torch compile test_fn assertEqual compiled_fn x test_fn x assertEqual counters inductor partial_reduction_reuse parametrize case torch amax torch amax torch amin torch min torch amax torch max test_successful_partial_reuse case shape partial_fn full_fn = case test_fn x partial = partial_fn x True full = full_fn x partial full x = torch randn shape device=GPU_TYPE compiled_fn = torch compile test_fn assertEqual compiled_fn x test_fn x assertEqual counters inductor partial_reduction_reuse test_addmm fn b c torch add torch mm b c torch mm b c + args_list = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE True torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE True torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE False torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE False torch randn device=GPU_TYPE torch randn device=GPU_TYPE False b c should_fuse args_list torch _dynamo reset counters clear args = b c e e = fn args = torch compile fn args torch testing assert_close e torch testing assert_close e count nodes = should_fuse assertEqual counters inductor pattern_matcher_count count assertEqual counters inductor pattern_matcher_nodes nodes test_addmm_symbolic_scalar fn m m bias = m size torch add bias torch mm m m torch mm m m + bias m = torch randn device=GPU_TYPE m = torch randn device=GPU_TYPE counters clear expect = fn m m actual = torch compile fn dynamic=True m m assertEqual expect actual assertEqual counters inductor pattern_matcher_count test_addmm_broadcasting_bias Model torch nn Module __init__ - None super __init__ linear = torch nn functional linear linear_weight = torch randn GPU_TYPE bias = torch randn GPU_TYPE forward x x = linear x linear_weight bias x input_tensor = torch randn GPU_TYPE func = Model GPU_TYPE res = func input_tensor jit_func = torch compile func res = jit_func input_tensor assertEqual res res inductor_config patch max_autotune_gemm_backends ATEN test_bmm_to_mm fn b torch bmm b = torch randn device=GPU_TYPE b = torch randn device=GPU_TYPE result code = run_and_get_code torch compile fn b expected = fn b torch testing assert_close result expected The mm kernel should use ATen because we set max_autotune_gemm_backends = ATEN Its name should contain ` aten bmm ` since original aten op where bmm came HAS_GPU FileCheck check extern_kernels mm check_not extern_kernels bmm run code FileCheck check extern_kernels bmm a_multi = torch randn device=GPU_TYPE b_multi = torch randn device=GPU_TYPE result_multi code_multi = run_and_get_code torch compile fn a_multi b_multi expected_multi = fn a_multi b_multi torch testing assert_close result_multi expected_multi FileCheck check extern_kernels bmm run code_multi test_cat_mm fn b c torch cat torch mm b torch mm b c torch mm c args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE out code = run_and_get_code torch compile fn args assertEqual out fn args FileCheck check call check_not run run code test_cat_addmm fn b c torch cat torch addmm b c torch addmm b c torch addmm c b args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE out code = run_and_get_code torch compile fn args assertEqual out fn args FileCheck check call check_not run run code test_cat_slice_cat_cuda fn b cat_ = torch ops aten cat default b slice_ = torch ops aten slice Tensor cat_ slice_ = torch ops aten slice Tensor slice_ torch ops aten cat default cat_ slice_ args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch _dynamo reset counters clear expected = fn args actual = torch compile fn args torch testing assert_close actual expected We don t recompile dynamic-shape cases dynamo_config assume_static_by_default assertEqual counters inductor pattern_matcher_count assertEqual counters inductor pattern_matcher_nodes Verify we fallback non-optimal path negative ` end ` fn b cat_ = torch ops aten cat default b slice_ = torch ops aten slice Tensor cat_ slice_ = torch ops aten slice Tensor slice_ - torch ops aten cat default cat_ slice_ args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args called test_gpu_cpp_wrapper test_cat_slice_cat_xpu = test_cat_slice_cat_cuda test_pointless_view_pair f x x = aten view default x x = aten view default x x x = torch randn device=GPU_TYPE gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph f x x = aten view default x x = aten view default x x x gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph handle negative size argument view f x x = aten view default x x = aten view default x - x gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph test_pointless_view_pair_dynamic_shapes f x s s = x shape x = aten view default x - x = aten view default x s s x x = torch randn device=GPU_TYPE torch _dynamo decorators mark_unbacked x out = torch compile f dynamic=True x assertTrue torch equal x out assertEqual counters inductor removed_pointless_view_pair test_pointless_permute_pair f x x = aten permute default x x = aten permute default x x x = torch randn device=GPU_TYPE gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph f x x = aten permute default x x = aten permute default x x x gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph test_pointless_permute_pair_ d f x x = aten permute default x x = aten permute default x x x = torch randn device=GPU_TYPE gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph f x x = aten permute default x x = aten permute default x x x gm = make_fx f x assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph test_pointless_convert fn x x = torch ops prims convert_element_type default x torch float x = torch ops prims convert_element_type default x torch float x gm = torch fx symbolic_trace fn assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph fn x x = torch ops prims convert_element_type default x torch int x = torch ops prims convert_element_type default x torch float x gm = torch fx symbolic_trace fn assertEqual count_calls gm graph joint_graph joint_graph_passes gm assertEqual count_calls gm graph Constant folding explicitly turned off due issue Turn back test inductor_config patch joint_graph_constant_folding=True test_pointless_cumsum fn ones = torch full layout=torch strided dtype=torch float torch int torch cumsum ones ones fn ones = torch full layout=torch strided dtype=torch float torch int torch cumsum ones fn twos = torch full dtype=torch int torch cumsum twos fn x = torch full dtype=torch float torch cumsum x fn t = torch full t = t dtype=torch bool torch cumsum t fn x = torch full True dtype=torch int torch cumsum x fn fn fn fn fn fn fn result code = run_and_get_code torch compile fn fullgraph=True assertNotIn aten cumsum code assertEqual result fn assertEqual counters inductor pattern_matcher_count counters clear test_splitwithsizes_cat Good case fn split_with_sizes = torch ops aten split_with_sizes default getitem = split_with_sizes getitem_ = split_with_sizes cat = torch ops aten cat default getitem getitem_ cat args = torch randn device=GPU_TYPE common fn args Not all getitems passed cat fn split_with_sizes = torch ops aten split_with_sizes default getitem = split_with_sizes getitem_ = split_with_sizes getitem_ = split_with_sizes cat = torch ops aten cat default getitem getitem_ cat + getitem_ args = torch randn device=GPU_TYPE common fn args Different dimensions TODO case should handled replacing reshape fn split_with_sizes = torch ops aten split_with_sizes default cat = torch ops aten cat default split_with_sizes cat args = torch randn device=GPU_TYPE common fn args https github com pytorch pytorch issues fn x = torch ops aten split_with_sizes default dim= cat = torch ops aten cat default x x x dim= cat args = torch randn device=GPU_TYPE common fn args test_cat_splitwithsizes good case fn b c cat = torch ops aten cat default b c split_with_sizes = torch ops aten split_with_sizes default cat s s split_with_sizes args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args cat node has other users fn b c cat = torch ops aten cat default b c split_with_sizes = torch ops aten split_with_sizes default cat s s split_with_sizes + cat args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args cat split dims different fn b c cat = torch ops aten cat default b c split_with_sizes = torch ops aten split_with_sizes default cat s s split_with_sizes args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args cat split lengths different fn b c cat = torch ops aten cat default b c split_with_sizes = torch ops aten split_with_sizes default cat s s split_with_sizes args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args cat input sizes split sizes different fn b c cat = torch ops aten cat default b c split_with_sizes = torch ops aten split_with_sizes default cat s s split_with_sizes args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE common fn args test_symint_pattern_matching torch _inductor config config torch _inductor pattern_matcher fwd_only PatternMatcherPass register_replacement saved_graph = None _CustomPass PatternMatcherPass __init__ - None super __init__ __call__ g torch fx graph Graph apply g nonlocal saved_graph saved_graph = g config patch leave custom pass only post_grad_passes pattern_matcher=False define pattern match custom post grad opt pass post_grad_custom_pre_pass=None post_grad_custom_post_pass=_CustomPass add x y x + y testing sym_minus x y x - -y size - y - - y size device = cpu my_args = torch empty device=device torch empty device=device invoked = False extra_check match nonlocal invoked invoked = True True register_replacement add sym_minus my_args fwd_only config post_grad_custom_post_pass extra_check=extra_check torch compile dynamic=True foo x y x + y x = torch rand y = torch rand assertEqual foo x y x + y assertTrue invoked we trace out y sym_size replacement FileCheck check sym_size_int check_same num_users= check_same target=torch ops aten sym_size run str saved_graph inductor_config patch fx_graph_remote_cache=False test_match_with_mutation counter = test_pass = PatternMatcherPass pass_name= test register_graph_pattern CallFunction torch add KeywordArg x CallFunction torch sin KeywordArg x pass_dict=test_pass _test match x nonlocal counter counter += fn x y = torch sin x b = torch add x b fn x y = torch sin x x copy_ y b = torch add x b fn x y = torch sin x torch no_grad b = torch add x b fn x y = torch sin x torch autocast GPU_TYPE b = torch add x b fn x y = torch sin x torch manual_seed b = torch add x b fn x y = torch sin x torch add y out=x b = torch add x b args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE unittest mock patch torch _inductor fx_passes pre_grad config pre_grad_fusion_options test unittest mock patch torch _inductor fx_passes pre_grad PRE_GRAD_FUSIONS unittest mock patch torch _inductor fx_passes pre_grad PRE_GRAD_PATTERNS test test_pass fn fn fn fn fn fn fn counter = expected = fn copy deepcopy args actual = torch compile fn copy deepcopy args should match assertEqual counter int fn fn torch testing assert_close actual expected test_remove_pointless_clones torch compile fullgraph=True fn b torch mm b clone _ code = run_and_get_code fn torch randn torch randn clone would create buf assertIn buf code assertNotIn async_compile cpp code test_unfuse_bias_addmm args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch compile fn inp b torch ops aten addmm inp b _ code = run_and_get_code fn args args args FileCheck check extern_kernels addmm run code torch compile fn inp b torch nn functional gelu torch ops aten addmm inp b _ code = run_and_get_code fn args args args FileCheck check_not extern_kernels addmm run code torch compile fn inp b torch nn functional gelu torch ops aten addmm inp b unsqueeze hit view path _ code = run_and_get_code fn args args args FileCheck check_not extern_kernels addmm run code test_serialized_patterns_up_to_date torch utils _pytree pytree torch _inductor fx_passes joint_graph torch _inductor pattern_matcher _known_precompiled_patterns Ensure patterns loaded os environ pop PYTORCH_GEN_PATTERNS None joint_graph lazy_init torch _subclasses FakeTensorMode mode search_fn example_inputs trace_fn scalar_workaround search_fn_pattern _known_precompiled_patterns Because example_inputs saved fake tensors different FakeTensorMode we need update them our FakeTensorMode remap_fake_tensor x isinstance x torch Tensor torch _subclasses FakeTensor from_tensor x mode x example_inputs = pytree tree_map remap_fake_tensor example_inputs pattern = gen_pattern search_fn example_inputs trace_fn scalar_workaround pattern_pp = PatternPrettyPrinter run pattern assertEqual pattern_pp PatternPrettyPrinter run search_fn_pattern msg=f Found mismatched pattern search_fn __name__ Run torchgen fuse gen_patterns py Since we ve already checked serialized patterns match lets verify serializer ensuring generated patterns also match since search_fn_pattern serialized version search_fn assertTrue pattern pattern_eq search_fn_pattern skipIfXpu xfailIfSM inductor_config patch triton unique_kernel_names original_aten fx_graph_remote_cache False max_autotune_gemm_backends TRITON test_original_aten_preserved_split_addmm addmm - elementwise should decomposed into mm - add - elementwise fn x y z torch addmm z x y sin args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE counters clear opt_fn = torch compile fn mode= max-autotune ret code = run_and_get_code opt_fn args assertEqual counters inductor pattern_matcher_count The mm kernel should use template because we set max_autotune_gemm_backends = TRITON Its name should contain ` addmm ` because ` addmm ` original aten op where mm came FileCheck check_not extern_kernels addmm check triton_tem_fused_addmm run code inductor_config patch fx_graph_remote_cache=False test_match_equivalent_function_invocations counter = test_pass = PatternMatcherPass args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE f inp b torch ops aten addmm inp b f inp b torch ops aten addmm inp b beta= f inp b torch ops aten addmm inp b beta= alpha= This graph pattern should successfully match all above functions register_graph_pattern CallFunction torch ops aten addmm Arg Arg Arg beta=KeywordArg beta alpha=KeywordArg alpha pass_dict=test_pass addmm_replacement match Match inp mat mat beta alpha nonlocal counter counter += repl inp x x x x alpha + inp beta V fake_mode match replace_by_example repl inp mat mat unittest mock patch torch _inductor fx_passes post_grad pass_patterns torch _inductor fx_passes post_grad pass_patterns + test_pass fn f f f counter = expected = fn copy deepcopy args opt_fn = torch compile fn actual code = run_and_get_code opt_fn args args args pattern should match assertEqual counter torch testing assert_close actual expected addmm should replaced FileCheck check_not extern_kernels addmm run code test_addmm_dtype_mismatch = torch nn Linear bias=False GPU_TYPE = dtype=torch float w = torch randn device=GPU_TYPE func x = torch ones device=GPU_TYPE dtype=torch float x = x x = x + w x actual code = run_and_get_code torch compile func assertEqual actual func FileCheck check_not addmm run code test_replace_mul_zero test x y x + y x = torch rand device=GPU_TYPE y = torch rand device=GPU_TYPE test_c = torch compile test out code = run_and_get_code test_c x y FileCheck check_not run run code assertEqual out test x y inductor_config patch fx_graph_remote_cache=False test_match_equivalent_function_invocations counter = test_pass = PatternMatcherPass args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE f inp b torch ops aten addmm inp b f inp b torch ops aten addmm inp b beta= f inp b torch ops aten addmm inp b beta= alpha= This graph pattern should only match f register_graph_pattern CallFunction torch ops aten addmm Arg Arg Arg pass_dict=test_pass addmm_replacement match Match inp mat mat nonlocal counter counter += repl inp x x x x + inp V fake_mode match replace_by_example repl inp mat mat unittest mock patch torch _inductor fx_passes post_grad pass_patterns torch _inductor fx_passes post_grad pass_patterns + test_pass fn f f f counter = expected = fn copy deepcopy args actual = torch compile fn copy deepcopy args assertEqual counter torch testing assert_close actual expected test_input_output_same pattern x y out = torch add x y out x replace x y out = torch mul x y out = torch mul out y out out my_patterns = PatternMatcherPass inputs = torch ones torch ones register_replacement pattern replace inputs fwd_only my_patterns custom_pass graph torch fx Graph - torch fx Graph _ = my_patterns apply graph stable_topological_sort graph graph eliminate_dead_code graph torch compile options= post_grad_custom_post_pass custom_pass f x y res = torch add x y sub = torch sub res x sub test code = run_and_get_code f torch ones torch ones assertTrue aten add default code assertTrue aten mul default code inductor_config patch fx_graph_remote_cache=False test_match_equivalent_function_invocations counter = test_pass = PatternMatcherPass args = torch randn device=GPU_TYPE torch randn device=GPU_TYPE torch randn device=GPU_TYPE f inp b torch ops aten addmm inp b f inp b torch ops aten addmm inp b beta= f inp b torch ops aten addmm inp b beta= alpha= This graph pattern should only match f register_graph_pattern CallFunction torch ops aten addmm Arg Arg Arg beta=KeywordArg beta pass_dict=test_pass addmm_replacement match Match inp mat mat beta nonlocal counter counter += repl inp x x x x + inp V fake_mode match replace_by_example repl inp mat mat unittest mock patch torch _inductor fx_passes post_grad pass_patterns torch _inductor fx_passes post_grad pass_patterns + test_pass fn f f f counter = expected = fn copy deepcopy args actual = torch compile fn copy deepcopy args assertEqual counter torch testing assert_close actual expected test_stable_topological_sort fn b + b graph = torch fx Graph = graph placeholder x b = graph placeholder y c = graph call_function fn b stable_topological_sort graph assertEqual list graph nodes b c graph = torch fx Graph b = graph placeholder y = graph placeholder x c = graph call_function fn b stable_topological_sort graph assertEqual list graph nodes b c graph = torch fx Graph = graph placeholder x b = graph placeholder y c = graph call_function fn b c append stable_topological_sort graph assertEqual list graph nodes b c test_scaled_softmax mul_softmax b F softmax b dim= div_softmax x inv_scale F softmax x inv_scale dim= x = torch randn scale = e inv_scale = scale common mul_softmax x scale common mul_softmax scale x common div_softmax x inv_scale scale = torch randn e inv_scale = scale common mul_softmax x scale common mul_softmax scale x common div_softmax x inv_scale scale = torch randn e inv_scale = scale common mul_softmax x scale common mul_softmax scale x common div_softmax x inv_scale Test matching type promotion x = torch randn dtype=torch bfloat scale = torch randn dtype=torch bfloat e inv_scale = scale common mul_softmax x scale reference_in_float=True common mul_softmax scale x reference_in_float=True common div_softmax x inv_scale reference_in_float=True No match scale changes softmax dim scale = torch randn common mul_softmax x scale common mul_softmax scale x common div_softmax x scale test_mutation_op_matching check type func_name args kwargs expect=True assert type call_function call_method graph = torch fx Graph getattr graph type func_name args kwargs res = is_mutation_op next iter graph nodes expect assertTrue res assertFalse res t = torch randn check call_function torch _C _set_grad_enabled False check call_method copy_ t t check call_method relu_ t check call_function torch manual_seed check call_function torch ops aten set_ source_Tensor t t check call_function torch amp autocast_mode _enter_autocast GPU_TYPE None True None check call_function torch amp autocast_mode _exit_autocast None check call_function torch ops _c d_functional all_gather_into_tensor_out t out t check call_function torch ops inductor resize_storage_bytes_ t check call_function torch ops inductor resize_storage_bytes_ default t check call_function torch ops fsdp split_with_sizes_copy t dim out t t t t check call_function torch ops fsdp copy_ t t check call_function torch ops aten __rshift__ Scalar t expect=False check call_function torch ops _c d_functional all_gather_into_tensor t expect=False torch library custom_op vllm fused_rms_norm_quant_static mutates_args= fused_rms_norm_quant_static out torch Tensor input torch Tensor - None pass check call_function torch ops vllm fused_rms_norm_quant_static t t expect=False test_multioutput_register_replacement torch library custom_op vllm fused_rms_norm_quant_static mutates_args= result scale fused_rms_norm_quant_static result torch Tensor input torch Tensor weight torch Tensor scale torch Tensor azp torch Tensor epsilon float - None print vllm fused_rms_norm_quant_static result_rms = torch mul input weight + epsilon _result = torch mul result_rms scale torch int scale fill_ torch library custom_op vllm rms_norm mutates_args= result rms_norm result torch Tensor input torch Tensor weight torch Tensor epsilon float - None bogus implementation doesn t matter _result = torch mul input weight + epsilon torch library custom_op vllm static_scaled_int _quant mutates_args= result scale static_scaled_int _quant result torch Tensor input torch Tensor scale torch Tensor azp Optional torch Tensor = None - None bogus implementation doesn t matter _result = torch mul input scale torch int scale fill_ rms_pattern_static result torch Tensor result_rms torch Tensor input torch Tensor weight torch Tensor scale torch Tensor = auto_functionalized torch ops vllm rms_norm default result=result_rms input=input weight=weight epsilon= e- = auto_functionalized torch ops vllm static_scaled_int _quant default result=result input=at scale=scale azp=None rms_replacement_static result torch Tensor result_rms torch Tensor input torch Tensor weight torch Tensor scale torch Tensor = auto_functionalized torch ops vllm fused_rms_norm_quant_static default result=result input=input weight=weight epsilon= e- scale=scale azp=None empty_bf args kwargs torch empty args kwargs dtype=torch bfloat empty_int args kwargs torch empty args kwargs dtype=torch int my_patterns = PatternMatcherPass inputs = empty_int empty_bf empty_bf empty_bf torch empty register_replacement rms_pattern_static rms_replacement_static inputs fwd_only my_patterns custom_pass graph torch fx Graph - torch fx Graph _count = my_patterns apply graph print f Count _count graph eliminate_dead_code graph print_tabular graph custom_backend graph torch fx GraphModule example_inputs list torch Tensor - Callable torch _inductor config current_config = config shallow_copy_dict torch _inductor compile_fx compile_fx current_config post_grad_custom_post_pass = custom_pass compile_fx graph example_inputs config_patches=current_config torch compile backend=custom_backend my_func_static x w epsilon quant_result = torch empty_like x dtype=torch int result_rms = torch empty_like x dtype=torch bfloat scale = torch ones x = x torch bfloat w = w torch bfloat quant_result scale = rms_pattern_static result=quant_result result_rms=result_rms input=x weight=w scale=scale quant_result scale inputs = torch empty torch empty e- print my_func_static inputs test code = run_and_get_code my_func_static inputs assertTrue static_scaled_int _quant code test_fwd_only_generate_original_aten_meta f x torch ops aten sigmoid x sample_input = torch randn device=GPU_TYPE gm_with_meta = fwd_only f args= sample_input sigmoid_nodes = gm_with_meta graph find_nodes op= call_function target=torch ops aten sigmoid default assertEqual len sigmoid_nodes assertTrue original_aten sigmoid_nodes meta __name__ == __main__ IS_LINUX HAS_GPU run_tests