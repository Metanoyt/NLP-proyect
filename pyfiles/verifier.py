mypy allow-untyped-defs inspect math operator collections abc Iterable typing Any final TYPE_CHECKING torch torch _ops HigherOrderOperator OpOverload torch _subclasses fake_tensor FakeTensor torch export graph_signature CustomObjArgument InputKind SymBoolArgument SymFloatArgument SymIntArgument TensorArgument TokenArgument torch fx GraphModule TYPE_CHECKING torch export exported_program ExportedProgram SpecViolationError Exception pass is_functional op OpOverload - bool op _schema is_mutable _check_has_fake_tensor node torch fx Node - None TODO angelayi remove favor _check_val _check_val node _check_val node torch fx Node - None torch fx experimental symbolic_shapes SymBool SymFloat SymInt _check_correct_val val val None True isinstance val int bool str float True isinstance val torch memory_format torch dtype torch device torch layout True isinstance val FakeTensor torch Tensor TODO zhxchen Remove Tensor True isinstance val SymInt SymFloat SymBool True isinstance val CustomObjArgument True isinstance val Iterable all _check_correct_val x x val False _no_returns op isinstance op OpOverload False len op _schema returns == val node meta node op == call_function _no_returns node target raise SpecViolationError f Node meta node name missing val field val = node meta val _check_correct_val val raise SpecViolationError f Node meta node name has invalid val field val _check_torch_fn node torch fx Node - None torch_fn = node meta get torch_fn torch_fn None raise SpecViolationError f Unable find torch_fn metadata node node name isinstance torch_fn tuple isinstance torch_fn str isinstance torch_fn str raise SpecViolationError f Node meta node name has invalid torch_fn field torch_fn _VerifierMeta type _registry dict str type Verifier = __new__ metacls name bases attrs bases check attrs _check_graph_module attrs raise SyntaxError Overriding method check allowed assert dialect attrs attrs dialect = ATEN assert check attrs assert _check_graph_module attrs assert attrs dialect == ATEN assert isinstance attrs dialect str ret = type __new__ metacls name bases attrs metacls _registry attrs dialect = ret type ignore assignment ret getattr_recursive obj Any target str - Any target_atoms = target split attr_itr = obj i atom enumerate target_atoms hasattr attr_itr atom raise RuntimeError f Node referenced nonexistent target join target_atoms i attr_itr = getattr attr_itr atom attr_itr Verifier metaclass=_VerifierMeta dialect = ATEN allowed_builtin_ops - list operator getitem operator add operator mul operator sub operator truediv operator ge operator le operator gt operator lt operator eq operator ne operator floordiv operator mod operator and_ operator or_ operator not_ operator pow operator neg operator abs operator lshift operator rshift math ceil math floor math trunc round allowed_op_types - tuple type Any OpOverload HigherOrderOperator allowed_getattr_types - tuple type Any torch fx GraphModule torch utils _pytree TreeSpec allowed_getattr_types_for_subgm - tuple type Any subgm HOP s argument could has have getattr weight nodes thus stateful torch fx GraphModule torch nn parameter Parameter torch Tensor buffer constant tensor torch utils _pytree TreeSpec check_valid_op op pass check_additional gm GraphModule - None Additional checks specific some dialects final check ep ExportedProgram - None _check_graph_module ep graph_module _verify_exported_program_module_call_graph ep _verify_exported_program_signature ep final _check_graph_module gm torch fx GraphModule - None _allowed_getattr_types is_toplevel_gm - tuple type Any is_toplevel_gm ret = allowed_getattr_types ret = allowed_getattr_types_for_subgm assert any t object t ret ret _check_valid_op op - None _allowed_builtin_ops - list ret = allowed_builtin_ops assert all inspect isbuiltin op op ret ret _allowed_op_types - tuple type Any ret = allowed_op_types assert any t object t ret ret TODO Remove allowlist _allowed_torch_functions = torch autograd grad_mode set_grad_enabled torch sym_int torch sym_float torch sym_ite torch sym_max torch sym_min torch sym_not torch sym_sqrt torch sym_sum torch export custom_ops _call_custom_autograd_function_in_pre_dispatch TODO tmanlaibaatar Predispatch export able contain autograd ops These will modeled HOO later torch _C _set_grad_enabled torch amp autocast_mode _enter_autocast torch amp autocast_mode _exit_autocast torch fx experimental symbolic_shapes cast_symbool_to_symint_guardless torch _functorch predispatch _add_batch_dim torch _functorch predispatch _remove_batch_dim torch _functorch predispatch _vmap_increment_nesting torch _functorch predispatch _vmap_decrement_nesting torch _functorch predispatch lazy_load_decompositions isinstance op _allowed_op_types op _allowed_builtin_ops op _allowed_torch_functions raise SpecViolationError f Operator op allowed operator type _allowed_op_types \n f Valid builtin ops _allowed_builtin_ops f Valid torch functions _allowed_torch_functions isinstance op OpOverload All ops functional TODO tmanlaibaatar more proper way needed here dialect = TRAINING is_functional op raise SpecViolationError f operator op functional check_valid_op op mod gm modules is_toplevel_gm = mod gm isinstance mod torch fx GraphModule continue mod graph lint node mod graph nodes TODO T should have fake tensor all dialects node op call_module call_method raise SpecViolationError f call_module valid got node target node op == call_function _check_val node _check_valid_op node target node op == get_attr isinstance node target str raise SpecViolationError f Expected get_attr target string got type node target attr = getattr_recursive mod node target isinstance attr torch nn Module _is_type name ty isinstance getattr attr name None ty type attr __name__ == LoweredBackendModule _is_type backend_id str hasattr attr original_module hasattr attr module_name getattr attr backend_id None == aoti continue _is_type backend_id str _is_type processed_bytes bytes _is_type compile_specs list hasattr attr original_module continue backend_id = getattr attr backend_id None processed_bytes = getattr attr processed_bytes None compile_specs = getattr attr compile_specs None raise SpecViolationError f Invalid get_attr type type attr \n f LoweredBackendModule fields f backend_id str type backend_id f processed_bytes bytes type processed_bytes f compile_specs list type compile_specs type attr __name__ == AOTInductorEPModule continue type attr __name__ == AOTInductorRunnerWrapper continue isinstance attr _allowed_getattr_types is_toplevel_gm raise SpecViolationError f Invalid get_attr type type attr target node target \n f Valid get_attr types _allowed_getattr_types is_toplevel_gm node op == placeholder _check_val node TODO zhxchen node op == output _check_flattened_outputs check_additional gm TrainingIRVerifier Verifier dialect = TRAINING _verify_exported_program_module_call_graph exported_program - None module_call_graph = exported_program module_call_graph nodes = node name node exported_program graph nodes entry module_call_graph entry signature None arg entry signature inputs arg name arg name nodes raise SpecViolationError f Input arg name does exist graph arg entry signature outputs arg name arg name nodes raise SpecViolationError f Output arg name does exist graph _verify_exported_program_signature exported_program - None Check ExportedProgram signature matches gs = exported_program graph_signature Check every node signature exists graph input_node_names = node name node exported_program graph nodes node op == placeholder len input_node_names = len gs input_specs raise SpecViolationError f Number graph inputs len input_node_names f does match number inputs graph signature len gs input_specs input_spec node zip gs input_specs input_node_names isinstance input_spec arg TensorArgument SymIntArgument SymFloatArgument SymBoolArgument input_spec arg name = node raise SpecViolationError f Input spec name input_spec arg name does match node name node input_spec kind == InputKind USER_INPUT continue input_spec kind == InputKind PARAMETER isinstance input_spec arg TensorArgument raise SpecViolationError f Parameter input_spec name tensor argument Found input_spec arg instead input_spec target None raise SpecViolationError f InputSpec input_spec name has no target param = input_spec target param exported_program state_dict raise SpecViolationError f Parameter param state dict isinstance exported_program state_dict param torch nn Parameter raise SpecViolationError f State dict entry parameter param instance torch nn Parameter input_spec kind == InputKind BUFFER isinstance input_spec arg TensorArgument raise SpecViolationError f Buffer input_spec name tensor argument Found input_spec arg instead input_spec target None raise SpecViolationError f InputSpec input_spec name has no target buffer = input_spec target input_spec persistent None raise SpecViolationError f Buffer buffer missing persistence flag input_spec persistent True buffer exported_program state_dict raise SpecViolationError f Buffer buffer state dict input_spec persistent False buffer exported_program state_dict raise SpecViolationError f Non-persistent buffer buffer state dict should input_spec kind == InputKind CONSTANT_TENSOR isinstance input_spec arg TensorArgument raise SpecViolationError f Constant tensor input_spec name tensor argument Found input_spec arg instead input_spec target None raise SpecViolationError f InputSpec input_spec name has no target tensor_const = input_spec target tensor_const exported_program constants raise SpecViolationError f Constant tensor tensor_const constants dictionary input_spec kind == InputKind CUSTOM_OBJ isinstance input_spec arg CustomObjArgument raise SpecViolationError f Custom object input_spec name custom object argument Found input_spec arg instead input_spec target None raise SpecViolationError f InputSpec input_spec name has no target custom_obj = input_spec target custom_obj exported_program constants raise SpecViolationError f Custom object custom_obj constants dictionary input_spec kind == InputKind TOKEN isinstance input_spec arg TokenArgument raise SpecViolationError f Constant tensor input_spec name tensor argument Found input_spec arg instead raise SpecViolationError f Unknown InputKind input_spec kind Check outputs output_node = list exported_program graph nodes - assert output_node op == output output_nodes = arg name isinstance arg torch fx Node arg arg output_node args len output_nodes = len gs output_specs raise SpecViolationError f Number output nodes len output_nodes different Than number outputs specified graph signature \n f Number mutated buffers len gs buffers_to_mutate \n f Number user outputs len gs user_outputs \n num_tokens = len gs output_tokens end = len gs buffers_to_mutate + len gs parameters_to_mutate + len gs user_inputs_to_mutate + num_tokens mutate_nodes list str = output_nodes num_tokens end user_output_nodes = output_nodes end end + len gs user_outputs mutation_node mutate_nodes mutation_node gs buffers_to_mutate gs buffers_to_mutate mutation_node gs buffers raise SpecViolationError f Buffer output mutation_node does point buffer exists \n f Dict buffers mutated order gs buffers_to_mutate \n f Buffer nodes available gs buffers \n mutation_node gs parameters_to_mutate gs parameters_to_mutate mutation_node gs parameters raise SpecViolationError f Parameter output mutation_node does point parameter exists \n f Dict parameters mutated order gs parameters_to_mutate \n f Parameter nodes available gs parameters \n mutation_node gs user_inputs_to_mutate gs user_inputs_to_mutate mutation_node gs user_inputs raise SpecViolationError f User input output mutation_node does point user input exists \n f Dict user inputs mutated order gs user_inputs_to_mutate \n f User input nodes available gs user_inputs \n raise SpecViolationError f Mutation node mutation_node neither buffer nor user input f Buffers mutate gs buffers_to_mutate User inputs mutate gs user_inputs_to_mutate user_output_node user_output_name zip user_output_nodes gs user_outputs user_output_node = user_output_name raise SpecViolationError f User output user_output_node correct order found f exported program s user_output list gs user_outputs load_verifier dialect str - type Verifier dialect == ATEN dialect == _VerifierMeta _registry get dialect Verifier _VerifierMeta _registry dialect