mypy ignore-errors re sys time functools partial wraps torch distributed dist torch distributed rpc rpc torch distributed rpc _rref_context_get_debug_info torch testing _internal common_utils FILE_SCHEMA TEST_WITH_TSAN dist is_available print c d available skipping tests file=sys stderr sys exit INIT_METHOD_TEMPLATE = FILE_SCHEMA + file_name dist_init old_test_method=None setup_rpc bool = True clean_shutdown bool = True faulty_messages=None messages_to_delay=None We use decorator setting up tearing down state since MultiProcessTestCase runs each ` test ` method separate process each process just runs ` test ` method without actually calling setUp tearDown methods unittest Note pass string representation MessageTypes should used faulty agent s send function By default all retriable messages RREF_FORK_REQUEST RREF_CHILD_ACCEPT RREF_USER_DELETE CLEANUP_AUTOGRAD_CONTEXT_REQ will use faulty send default set faulty_rpc_agent_test_fixture py If we use dist_init without arguments ex dist_init old_test_method appropriately set we wrapper appropriately On other hand dist_init has arguments ex dist_init clean_shutdown=False old_test_method None we functools partial which real decorator used result we recursively call dist_init old_test_method rest arguments appropriately set old_test_method None partial dist_init setup_rpc=setup_rpc clean_shutdown=clean_shutdown faulty_messages=faulty_messages messages_to_delay=messages_to_delay wraps old_test_method new_test_method arg kwargs Setting _ignore_rref_leak make sure OwnerRRefs properly deleted tests torch distributed rpc api api api _ignore_rref_leak = False worker_id = rank setup_fault_injection faulty_messages messages_to_delay rpc_backend_options = rpc_backend_options setup_rpc TEST_WITH_TSAN TSAN runs much slower rpc_backend_options rpc_timeout = rpc constants DEFAULT_RPC_TIMEOUT_SEC rpc constants DEFAULT_SHUTDOWN_TIMEOUT = rpc init_rpc name=f worker rank d backend=self rpc_backend rank=self rank world_size=self world_size rpc_backend_options=rpc_backend_options return_value = old_test_method arg kwargs setup_rpc rpc shutdown graceful=clean_shutdown return_value new_test_method noop - None pass wait_until_node_failure rank int expected_error_regex str = - str Loops until RPC given rank fails This used indicate node has failed unit tests Args rank int Rank node expected fail expected_error_regex optional str Regex exception message expected Useful ensure specific failure occurs just any while True try rpc rpc_sync f worker rank noop args= time sleep except Exception e re search pattern=expected_error_regex string=str e str e wait_until_pending_futures_and_users_flushed timeout int = - None The RRef protocol holds forkIds rrefs map until those forks confirmed owner The message confirming fork may arrive after our tests check whether map empty which leads failures flaky tests to_here also does guarantee we have finished processind owner s confirmation message RRef This function loops until map empty which means messages have been received processed Call function before asserting map returned _get_debug_info empty start = time time while True debug_info = _rref_context_get_debug_info num_pending_futures = int debug_info num_pending_futures num_pending_users = int debug_info num_pending_users num_pending_futures == num_pending_users == break time sleep time time - start timeout raise ValueError f Timed out waiting flush pending futures users f had num_pending_futures pending futures num_pending_users pending users get_num_owners_and_forks - tuple str str Retrieves number OwnerRRefs forks node _rref_context_get_debug_info rref_dbg_info = _rref_context_get_debug_info num_owners = rref_dbg_info num_owner_rrefs num_forks = rref_dbg_info num_forks num_owners num_forks wait_until_owners_and_forks_on_rank num_owners int num_forks int rank int timeout int = - None Waits until timeout num_forks num_owners exist rank Used ensure proper deletion RRefs tests start = time time while True num_owners_on_rank num_forks_on_rank = rpc rpc_sync worker_name rank get_num_owners_and_forks args= timeout= num_owners_on_rank = int num_owners_on_rank num_forks_on_rank = int num_forks_on_rank num_owners_on_rank == num_owners num_forks_on_rank == num_forks time sleep time time - start timeout raise ValueError f Timed out waiting timeout sec num_owners owners num_forks forks rank f had num_owners_on_rank owners num_forks_on_rank forks initialize_pg init_method rank int world_size int - None This tests using ` dist barrier ` dist is_initialized dist init_process_group backend= gloo init_method=init_method rank=rank world_size=world_size worker_name rank int - str f worker rank get_function_event function_events partial_event_name Returns first event matches partial_event_name provided function_events These function_events should output torch autograd profiler function_events Args function_events function_events returned profiler event_name str partial key event profiled event = event event function_events partial_event_name event name noqa RUF event