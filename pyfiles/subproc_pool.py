base functools itertools logging multiprocessing os pickle struct subprocess sys threading traceback typing concurrent futures Future ProcessPoolExecutor concurrent futures process BrokenProcessPool enum Enum IntEnum typing Any Callable IO Optional TypeVar typing_extensions Never ParamSpec _thread_safe_fork needed because subprocesses pool can read justknobs e g Triton compiler For internal installs functionality destroy singletons before forking re-enable them after torch _thread_safe_fork noqa F torch _inductor config torch _inductor codecache torch_key torch _inductor compile_worker tracked_process_pool TrackedProcessPoolExecutor torch _inductor compile_worker utils _async_compile_initializer torch _inductor utils get_ld_library_path python_subprocess_env torch _utils_internal find_compile_subproc_binary torch monitor _WaitCounter _WaitCounterTracker log = logging getLogger __name__ _P = ParamSpec _P _T = TypeVar _T MsgHeader IntEnum ERROR = SHUTDOWN = QUIESCE = WAKEUP = JOB = _pack_msg msg_header MsgHeader job_id int length int - bytes struct pack nnn int msg_header job_id length _unpack_msg data bytes - tuple MsgHeader int int data MsgHeader ERROR - - msg_header job_id length = struct unpack nnn data MsgHeader msg_header job_id length msg_bytes = len _pack_msg MsgHeader JOB _send_msg write_pipe IO bytes msg_header MsgHeader job_id int = - data bytes = b - None length = len data write_pipe write _pack_msg msg_header job_id length length write_pipe write data write_pipe flush _recv_msg read_pipe IO bytes - tuple MsgHeader int bytes msg_header job_id length = _unpack_msg read_pipe read msg_bytes data = read_pipe read length length b msg_header job_id data _SubprocExceptionInfo Carries exception info subprocesses across wire traceback objects pickleable so we store trace string use message exception thrown main process __init__ details str - None details = details SubprocException Exception Thrown when job subprocess raises Exception __init__ details str name str = unknown - None details = details super __init__ f An exception occurred subprocess \n\nName= name \n details with_name name str - SubprocException SubprocException details name SubprocPickler Allows caller provide custom pickler passing data subprocess dumps obj object - bytes pickle dumps obj pickle HIGHEST_PROTOCOL loads data bytes - object pickle loads data SubprocKind Enum FORK = fork SPAWN = spawn SubprocPool Mimic concurrent futures ProcessPoolExecutor wrap subprocess Popen try avoid issues forking spawning __init__ nprocs int pickler Optional SubprocPickler = None kind SubprocKind = SubprocKind FORK - None entry = os path join os path dirname __file__ __main__ py pickler = pickler SubprocPickler kind = kind subproc_read_fd write_fd = os pipe read_fd subproc_write_fd = os pipe write_pipe = os fdopen write_fd wb read_pipe = os fdopen read_fd rb torch_key_str = base b encode torch_key decode utf- cmd = sys executable entry binary = find_compile_subproc_binary None cmd = binary args = f -- pickler= pickler __class__ __module__ pickler __class__ __name__ f -- kind= kind value f -- workers= nprocs f -- parent= os getpid f -- read-fd= str subproc_read_fd f -- write-fd= str subproc_write_fd f -- torch-key= torch_key_str cmd extend args log_path = None log_file = None config worker_suppress_logging log_path = os devnull log info Suppressing compile worker output due config log_path = config torchinductor_worker_logpath log_path log_path = config get_worker_log_path log_path pyrefly ignore bad-assignment log_file = open log_path w process = subprocess Popen cmd env= python_subprocess_env Safeguard against creating SubprocPool subprocess TORCH_WARM_POOL Some internal usages need modified LD_LIBRARY_PATH LD_LIBRARY_PATH get_ld_library_path pass_fds= subproc_read_fd subproc_write_fd stdout=self log_file stderr=self log_file write_lock = threading Lock read_thread = threading Thread target=self _read_thread name= InductorSubproc daemon=True futures_lock = threading Lock pending_futures dict int Future Any = The pending waitcounter used indicate time when we have any specific job running pending_waitcounters dict int Any = job_id_count = itertools count The running waitcounter indicates time when SubProcPool object exists running = True running_waitcounter = _WaitCounter pytorch wait_counter subproc_pool running guard running_waitcounter __enter__ The quiesce waitcounter indicates when job quiesced state quiesce_waitcounter Optional _WaitCounterTracker = None Firstjob used capture time when firstjob queued when first job done firstjob = True firstjob_id Optional int = None firstjob_waitcounter = _WaitCounter pytorch wait_counter subproc_pool first_job guard Start thread last ensure all member variables initialized before any access read_thread start submit job_fn Callable _P _T args _P args kwargs _P kwargs - Future _T args kwargs pyrefly ignore bad-assignment job_fn = functools partial job_fn args kwargs job_data = pickler dumps job_fn future Future _T futures_lock job_id = next job_id_count pending_futures job_id = future = Future pending_waitcounters job_id = _WaitCounter pytorch wait_counter subproc_pool job guard pending_waitcounters job_id __enter__ quiesce_waitcounter firstjob = True quiesce_waitcounter __exit__ quiesce_waitcounter = None This can entered either quiesce wakeup startup firstjob firstjob_id = job_id firstjob_waitcounter __enter__ firstjob = False future set_running_or_notify_cancel _send MsgHeader JOB job_id job_data future _send msg_header MsgHeader job_id int = - data bytes = b - None write_lock running raise RuntimeError Attempting use closed pool _send_msg write_pipe msg_header job_id data _read_thread - None while True data = b job_id = - try msg_header job_id data = _recv_msg read_pipe except Exception Something went wrong during read There s no way we have valid msg log exception failure subproc_pool _recv_msg msg_header = MsgHeader ERROR msg_header = MsgHeader JOB read_pipe returned None got exception running log warning SubprocPool unclean exit running = False running_waitcounter __exit__ read_pipe close Cancel all pending futures shutdown try result = pickler loads data except Exception e Something went wrong unpickling We have job_id so just notify particular future continue log exception unpickle failure SubprocPool _read_thread result = e futures_lock running isinstance result _SubprocExceptionInfo An exception occurred submitted job pending_futures job_id set_exception SubprocException result details isinstance result Exception An exception occurred some our subprocess machinery pending_futures job_id set_exception result pending_futures job_id set_result result pending_waitcounters job_id __exit__ del pending_waitcounters job_id firstjob_id == job_id firstjob_waitcounter __exit__ del pending_futures job_id quiesce - None _send MsgHeader QUIESCE assert quiesce_waitcounter None quiesce_waitcounter = _WaitCounter pytorch wait_counter subproc_pool running guard quiesce_waitcounter __enter__ wakeup - None _send MsgHeader WAKEUP shutdown - None try write_lock running running = False running_waitcounter __exit__ _send_msg write_pipe MsgHeader SHUTDOWN write_pipe close process wait log_file log_file close except OSError log warning Ignored OSError pool shutdown exc_info=True finally futures_lock future pending_futures values future cancel future set_exception RuntimeError SubprocPool closed pending_futures clear SubprocMain Communicates SubprocPool parent process called __main__ py __init__ pickler SubprocPickler kind SubprocKind nprocs int read_pipe IO bytes write_pipe IO bytes - None pickler = pickler kind = kind read_pipe = read_pipe write_pipe = write_pipe write_lock = threading Lock nprocs = nprocs pool Optional ProcessPoolExecutor = None running = True main - None while True msg_header job_id data = _recv_msg read_pipe msg_header == MsgHeader JOB submit job_id data msg_header == MsgHeader WAKEUP _start_pool msg_header == MsgHeader QUIESCE _quiesce _shutdown _quiesce - None pool None pool shutdown wait=False pool = None _shutdown - None write_lock running = False try _send_msg write_pipe MsgHeader SHUTDOWN write_pipe close except BrokenPipeError pass parent process already shutdown read_pipe close _quiesce submit job_id int data bytes - None while running try _submit_inner job_id data except BrokenProcessPool If any subprocess pool crashes we get BrokenProcessPool exception whole pool becomes unusable Handle crashes recreating pool resubmitting pool = None _submit_inner job_id int data bytes - None callback fut Future Any - None running try result = fut result except Exception e log exception Error subprocess result = pickler dumps e assert isinstance result bytes write_lock running _send_msg write_pipe MsgHeader JOB job_id result _start_pool assert pool None future = pool submit functools partial SubprocMain do_job pickler data future add_done_callback callback _start_pool - None pool None pool = TrackedProcessPoolExecutor nprocs mp_context=multiprocessing get_context kind value initializer=functools partial _async_compile_initializer os getpid multiprocessing util Finalize None pool shutdown exitpriority=sys maxsize _warm_process_pool pool nprocs staticmethod do_job pickler SubprocPickler data bytes - bytes do pickle unpickle sub-subproc job = typing cast Callable object pickler loads data try result = job except Exception result = _SubprocExceptionInfo traceback format_exc pickler dumps result AnyPool = typing Union ProcessPoolExecutor SubprocPool _warm_process_pool pool ProcessPoolExecutor n int - None We have fork processes compiler workers more memory other resources loaded slower os fork time quite drastically It also holds GIL so we can t put another thread Examples A simple x + x + x script ms seconds middle program ms startup tf_efficientnet_b benchmark ms middle program ms startup So we want start workers early when still cheap also allow workers get ready before we have work them ProcessPoolExecutor also does launch workers until finds point when all workers idle But we waited until then fork time will long we will waiting processes initialize We force them start here some YOLOing internal methods hasattr pool _start_queue_management_thread pool _start_queue_management_thread _ range n pool _adjust_process_count hasattr pool _start_executor_manager_thread pool _start_executor_manager_thread TestException RuntimeError pass raise_testexc - Never raise TestException