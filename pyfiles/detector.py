mypy allow-untyped-defs abc ABC abstractmethod collections abc Callable typing Any torch torch ao nn qat nnqat torch nn nn torch ao quantization fake_quantize FakeQuantize torch ao quantization fx _equalize default_equalization_qconfig EqualizationQConfig torch ao quantization fx _model_report model_report_observer ModelReportObserver torch ao quantization fx graph_module GraphModule torch ao quantization observer _is_activation_post_process default_dynamic_quant_observer default_observer default_per_channel_weight_observer default_weight_observer ObserverBase torch ao quantization qconfig _assert_valid_qconfig default_qconfig QConfig Names observer insert keys DETECTOR_TARGET_NODE_KEY = target_node DETECTOR_OBS_TO_INSERT_KEY = observer_to_insert DETECTOR_IS_POST_OBS_KEY = is_post_observer DETECTOR_OBS_ARGS_KEY = observer_args Mapping related code DetectorQConfigInfo r This contains QConfig information single module The list variables values contains can grow depending extensibility qconfig mapping feature set currently includes - activation observer dynamic - weight observer per channel Args module_fqn str The fully qualified name fqn module information contains info relevant qconfig __init__ module_fqn str super __init__ module_fqn = module_fqn populate section all variables we might find important change none your detector actually using is_activation_dynamic = False is_weight_per_channel = False equalization related options is_equalization_recommended = False generate_quantization_qconfig module torch nn Module - QConfig r Args module torch nn Module The module we generating qconfig Returns generated quantization QConfig according what valid configuration Apply suggestions new qconfig module_qconfig = default_qconfig keep track dynamic per_channel recommendations recommendations_list = append list combinations recommendations_list append is_activation_dynamic is_weight_per_channel recommendations_list append is_activation_dynamic False only trying dynamic rec recommendations_list append False is_weight_per_channel only trying dynamic now we try each combinations rec recommendations_list rec - dynamic recommended rec - per channel recommended activation = default_dynamic_quant_observer rec default_observer weight = default_per_channel_weight_observer rec default_weight_observer test_config = QConfig activation weight try _assert_valid_qconfig test_config module module_qconfig = test_config break except AssertionError valid configuration we move next one priority continue QConfig chosen module_qconfig generate_equalization_qconfig - EqualizationQConfig r This returns equalization configuration module For now just returns default more equalization options become possible method can get more fleshed out more nuanced granularity Returns generated equalization QConfig according what valid configuration case we just default equalization config we know valid because only valid modules would even have option default_equalization_qconfig Adding base detectors DetectorBase ABC r Base Detector Module Any detector should derive Concrete detectors should follow same general API which includes - A method calculate observer insertion points - Should both fqns Observer insert - A method report based detector - Should str-based report dict info Tuple str Dict format __init__ - None super __init__ detector_config_info = None abstractmethod determine_observer_insert_points model - dict r Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them Dict This dict maps string keys detector specific information abstractmethod get_detector_name - str r Returns name current detector abstractmethod get_qconfig_info model - dict str DetectorQConfigInfo r Returns DetectorQConfigInfo each module_fqn relevant Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them A DetectorQConfigInfo information generate QConfig specific module _get_targeting_node prepared_fx_model GraphModule target_fqn str - torch fx node Node r Takes GraphModule target_fqn finds node whose target fqn If s found means most likely inside fused layer We just go one layer up terms fqn we searching until we find parent node If we get empty string then we know doesn t exist The reason recursion model we looking got fused we will have module fqn e g x linear graph will only have node fused module which would have fqn x linear so they will match To handle we don t match we then take off last bit fqn e g x linear - x linear more generally foo bar baz - foo bar search again will allow us locate correct module even cases fusion Args prepared_fx_model GraphModule The prepared Fx GraphModule target_fqn str The fqn layer we trying target Returns node object we trying add observers around node prepared_fx_model graph nodes node s target our target node target == target_fqn node getting here means node found no we already base failed parent_fqn_sep_index = target_fqn rfind parent_fqn_sep_index == - raise ValueError passed target_fqn found graph s targets recursively call parent fqn _get_targeting_node prepared_fx_model target_fqn parent_fqn_sep_index abstractmethod generate_detector_report model - tuple str dict str Any r Args model nn Module subclass model find observer insertion points Returns Tuple two elements Str string report suggested improvements Dict contains useful data collected observer pertinent report PerChannelDetector DetectorBase r This used detect any Linear Conv layers model utilize per_channel quantization Only Linear Conv layers can use per_channel now so only these two currently checked per_channel quantization can lead major benefits form accuracy Therefore backend used user supports recommended use Args backend str optional backend user wishes use production Default value current torch backends quantized engine Keys dictionary BACKEND_KEY = backend PER_CHAN_SUPPORTED_KEY = per_channel_quantization_supported PER_CHAN_USED_KEY = per_channel_quantization_used Default map representing supported per channel quantization modules different backends DEFAULT_BACKEND_PER_CHANNEL_SUPPORTED_MODULES dict str set Any = fbgemm nn Linear nn Conv d nn Conv d nn Conv d nnqat Linear nnqat Conv d nnqat Conv d nnqat Conv d qnnpack nn Linear nn Conv d nn Conv d nn Conv d nnqat Linear nnqat Conv d nnqat Conv d nnqat Conv d onednn nn Linear nn Conv d nn Conv d nn Conv d nnqat Linear nnqat Conv d nnqat Conv d nnqat Conv d x nn Linear nn Conv d nn Conv d nn Conv d nnqat Linear nnqat Conv d nnqat Conv d nnqat Conv d __init__ backend str = torch backends quantized engine super __init__ store backend information backend_chosen = backend supported_modules = set backend_chosen DEFAULT_BACKEND_PER_CHANNEL_SUPPORTED_MODULES supported_modules = DEFAULT_BACKEND_PER_CHANNEL_SUPPORTED_MODULES backend_chosen raise ValueError f Not configured work backend_chosen Try different default backend get_detector_name - str r returns string name detector per_channel_detector get_qconfig_info model - dict str DetectorQConfigInfo r Returns DetectorQConfigInfo each module_fqn relevant Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them A DetectorQConfigInfo information generate QConfig specific module run helper function populate dictionary per_channel_info = _detect_per_channel_helper model we actually have qconfig info object we populating module_fqn_to_detector_qconfig_info = module_fqn per_channel_info create detector info instance detector_qconfig_info = DetectorQConfigInfo module_fqn see per channel quantization supported per_chan_supported bool = per_channel_info module_fqn PER_CHAN_SUPPORTED_KEY detector_qconfig_info is_weight_per_channel = per_chan_supported module_fqn_to_detector_qconfig_info module_fqn = detector_qconfig_info module_fqn_to_detector_qconfig_info determine_observer_insert_points model nn Module - dict r There no observers inserted PerChannelDetector Returns empty dictionary since no observers added needed _detect_per_channel_helper model nn Module r determines per_channel quantization supported modules submodules Returns dictionary higher level _detect_per_channel function Each entry maps fully-qualified-name information whether per_channel quantization Args model The current module being checked see per_channel quantizable Returns dictionary mapping fqns per_channel quantization possible create dict we will per_channel_info dict = get fully qualified name check list modules include list modules ignore fqn module model named_modules is_in_include_list = any isinstance module x x supported_modules check module per_channel supported based backend per_channel_supported = False is_in_include_list per_channel_supported = True assert statement MyPy q_config_file = module qconfig isinstance q_config_file QConfig raise AssertionError module qconfig must QConfig object should either fake quant observer q_or_s_obj = module qconfig weight p func isinstance q_or_s_obj FakeQuantize ObserverBase raise AssertionError module qconfig weight must FakeQuantize ObserverBase per_channel_used = False will true found qconfig hasattr q_or_s_obj ch_axis then we know per_channel quantization used all fake quants have channel axis so need check is_per_channel isinstance q_or_s_obj FakeQuantize hasattr q_or_s_obj is_per_channel q_or_s_obj is_per_channel per_channel_used = True isinstance q_or_s_obj ObserverBase should observer otherwise per_channel_used = True raise ValueError Should either observer fake quant per_channel_info fqn = PER_CHAN_SUPPORTED_KEY per_channel_supported PER_CHAN_USED_KEY per_channel_used BACKEND_KEY backend_chosen per_channel_info generate_detector_report model nn Module - tuple str dict str Any r Checks any Linear Conv layers model utilize per_channel quantization Only Linear Conv layers can use per_channel now so only these two currently checked Looks q_config format backend determine per_channel can utilized Uses DEFAULT_BACKEND_PER_CHANNEL_SUPPORTED_MODULES structure determine support Args model The prepared calibrated model we want check using per_channel Returns tuple two elements String report potential actions improve model per_channel quantization available backend Dictionary mapping per_channel quantizable elements whether per_channel quantization supported backend being utilized current model run helper function populate dictionary per_channel_info = _detect_per_channel_helper model String let user know further optimizations further_optims_str = f Further Optimizations backend backend_chosen \n optimizations_possible = False fqn per_channel_info fqn_dict = per_channel_info fqn fqn_dict PER_CHAN_SUPPORTED_KEY fqn_dict PER_CHAN_USED_KEY optimizations_possible = True further_optims_str += f Module fqn can configured use per_channel quantization \n optimizations_possible further_optims_str += To use per_channel quantization make sure qconfig has per_channel weight observer further_optims_str += No further per_channel optimizations possible string dictionary form same information further_optims_str per_channel_info DynamicStaticDetector DetectorBase r Determines whether dynamic static quantization more appropriate given module Takes advantage ModelReportObserver records range information Stationary distribution data strictly above tolerance level comparison statistic S = average_batch_activation_range epoch_activation_range Nonstationary distributions below tolerance level metric If distribution data right after module non-stationary recommend dynamic quantization Otherwise recommend static quantization Args tolerance float optional The threshold where S metric stationary above non-stationary otherwise Default names pre post observers inserted DEFAULT_PRE_OBSERVER_NAME = model_report_pre_observer DEFAULT_POST_OBSERVER_NAME = model_report_post_observer naming conventions stationary vs non-stationary data STATIONARY_STR = stationary NON_STATIONARY_STR = non-stationary naming activation INPUT_ACTIVATION_PREFIX = input_activation_ OUTPUT_ACTIVATION_PREFIX = output_activation_ naming conventions keys module info TOLERANCE_KEY = dynamic_static_tolerance DEFAULT_DYNAMIC_REC_KEY = dynamic_recommended PRE_OBS_COMP_STAT_KEY = INPUT_ACTIVATION_PREFIX + dynamic_static_comp_stat POST_OBS_COMP_STAT_KEY = OUTPUT_ACTIVATION_PREFIX + dynamic_static_comp_stat PRE_OBS_DATA_DIST_KEY = INPUT_ACTIVATION_PREFIX + dynamic_static_data_classification POST_OBS_DATA_DIST_KEY = OUTPUT_ACTIVATION_PREFIX + dynamic_static_data_classification IS_CURRENTLY_SUPPORTED_KEY = is_dynamic_supported modules supported both dynamic static report function DEFAULT_DYNAMIC_STATIC_CHECK_SUPPORTED = nn Linear modules will supported soon both DEFAULT_DYNAMIC_STATIC_FUTURE_SUPPORTED = nn Conv d nn Conv d nn Conv d __init__ tolerance= super __init__ set tolerance level initialize set keep track useful fqn locations tolerance = tolerance useful_observer_fqns set str = set determine_observer_insert_points prepared_fx_model GraphModule - dict str dict str Any r Determines where observers need inserted Dynamic vs Static detector For detector we want place observers either side linear layers model Currently inserts observers linear layers Args prepared_fx_model GraphModule The prepared Fx GraphModule Returns Dict mapping unique observer fqns where we want insert them Dict key target_node - node we trying observe observer torch fx node Node key observer_to_insert - observer we wish insert ObserverBase key is_post_observer - True meant post-observer target_node False pre-observer key observer_args - The arguments meant passed into observer observer detector ModelReportObserver obs_ctr = ModelReportObserver dict obs_fqn_to_info dict str dict str Any = fqn module prepared_fx_model named_modules make sure module supported _is_supported module insert=True s supported type we want get node add observer insert locations targeted_node = _get_targeting_node prepared_fx_model fqn add entry pre-observer pre_obs_fqn = fqn + + DEFAULT_PRE_OBSERVER_NAME obs_fqn_to_info pre_obs_fqn = DETECTOR_TARGET_NODE_KEY targeted_node DETECTOR_OBS_TO_INSERT_KEY obs_ctr DETECTOR_IS_POST_OBS_KEY False DETECTOR_OBS_ARGS_KEY targeted_node args add entry post-observer post_obs_fqn = fqn + + DEFAULT_POST_OBSERVER_NAME obs_fqn_to_info post_obs_fqn = DETECTOR_TARGET_NODE_KEY targeted_node DETECTOR_OBS_TO_INSERT_KEY obs_ctr DETECTOR_IS_POST_OBS_KEY True DETECTOR_OBS_ARGS_KEY targeted_node obs_fqn_to_info get_detector_name - str r returns string name detector dynamic_vs_static_detector get_qconfig_info model - dict str DetectorQConfigInfo r Returns DetectorQConfigInfo each module_fqn relevant Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them A DetectorQConfigInfo information generate QConfig specific module run helper function populate dictionary dynamic_static_info = _generate_dict_info model we actually have qconfig info object we populating module_fqn_to_detector_qconfig_info = module_fqn dynamic_static_info create detector info instance detector_qconfig_info = DetectorQConfigInfo module_fqn see per channel quantization supported dynamic_static_recommended bool = dynamic_static_info module_fqn DEFAULT_DYNAMIC_REC_KEY detector_qconfig_info is_activation_dynamic = dynamic_static_recommended module_fqn_to_detector_qconfig_info module_fqn = detector_qconfig_info module_fqn_to_detector_qconfig_info _is_supported module nn Module insert bool = False - bool r Returns whether given module supported observers Args module The module check ensure supported insert True check observer insertion false report gen Returns True module supported observer False otherwise check see module supported type is_supported_type = any isinstance module x x DEFAULT_DYNAMIC_STATIC_CHECK_SUPPORTED check will supported future_supported_type = any isinstance module x x DEFAULT_DYNAMIC_STATIC_FUTURE_SUPPORTED supported supported = is_supported_type future_supported_type check observer insertion insert supported report gen we also need check contains observers has_obs = hasattr module DEFAULT_PRE_OBSERVER_NAME hasattr module DEFAULT_POST_OBSERVER_NAME supported has_obs _generate_dict_info model GraphModule - dict str Any r Helper function generate_detector_report does generation dictionary This process done specified generate_detector_report documentation Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns Dictionary mapping modules ModelReportObservers around them whether dynamic quantization recommended their S metric input module whether input module stationary non-stationary their S metric output module whether output module stationary non-stationary tolerance level decided whether input output stationary non-stationary whether currently supported planned future store modules dynamic vs static information module_dynamic_static_info = This loop goes through modules extracts all relevant information into module_dynamic_static_info This information primary includes whether data distributions around supported module stationary Based recorded whether dynamic static quantization recommended loop through all submodules included nested ones fqn module model named_modules module Linear has ModelReportObserver attached _is_supported module get pre post observers module pre_obs = getattr module DEFAULT_PRE_OBSERVER_NAME post_obs = getattr module DEFAULT_POST_OBSERVER_NAME get statistics each module pre_stat = pre_obs get_batch_to_epoch_ratio post_stat = post_obs get_batch_to_epoch_ratio record module pre post stat whether do dynamic static based off true post observer data distribution non-stationary false s stationary dynamic_recommended = post_stat = tolerance specify classifications whether data distributions considered stationary non-stationary pre_obs_dist_classif = STATIONARY_STR pre_stat tolerance NON_STATIONARY_STR post_obs_dist_classif = STATIONARY_STR post_stat tolerance NON_STATIONARY_STR check current support future support is_supported_type = any isinstance module x x DEFAULT_DYNAMIC_STATIC_CHECK_SUPPORTED store set important information module module_info = TOLERANCE_KEY tolerance DEFAULT_DYNAMIC_REC_KEY dynamic_recommended PRE_OBS_COMP_STAT_KEY pre_stat PRE_OBS_DATA_DIST_KEY pre_obs_dist_classif POST_OBS_COMP_STAT_KEY post_stat POST_OBS_DATA_DIST_KEY post_obs_dist_classif IS_CURRENTLY_SUPPORTED_KEY is_supported_type module_dynamic_static_info fqn = module_info module_dynamic_static_info generate_detector_report model GraphModule - tuple str dict str Any r Determines whether dynamic static quantization more appropriate given module Takes advantage ModelReportObserver records range information Stationary distribution data strictly above tolerance level comparison statistic S = average_batch_activation_range epoch_activation_range Nonstationary distributions below tolerance level metric If distribution data right after module non-stationary recommend dynamic quantization Otherwise recommend static quantization This will then generate suggestions dynamic vs static quantization focused around Linear Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns tuple two elements String report whether dynamic static quantization recommended certain modules Dictionary mapping modules ModelReportObservers around them whether dynamic quantization recommended their S metric input module whether input module stationary non-stationary their S metric output module whether output module stationary non-stationary tolerance level decided whether input output stationary non-stationary whether currently supported planned future get dictionary information format string report module_dynamic_static_info = _generate_dict_info model dynamic_vs_static_string = Dynamic vs Static Quantization suggestions \n modules_added bool = False check make sure least module added dynamic_benefit = You will get more accurate results you use dynamic quantization static_benefit = You can increase model efficiency you use static quantization future_support_str = This layer yet supported dynamic quantization This loop goes through information collected module_dynamic_static_info Populates string based report information module_dynamic_static_info Compiles complete report appending relevant formatted strings module_fqn module_dynamic_static_info keys there least module suggestion modules_added = True module_info = module_dynamic_static_info module_fqn suggestion_string_template = For module suggested use quantization because \n decide what string formatting values will quantization_type = quantization_reasoning = distribution data before distribution after benefit_str = strings dynamic quantized per tensor needed recommend_per_tensor = We recommend add before module static rec_lay_to_add = dynamic quantize per tensor layer dynamic_per_tensor_string = recommend_per_tensor format rec_lay_to_add dynamic_per_tensor_reasoning_string = This because input module has non-stationary distribution start composing explanation module_info DEFAULT_DYNAMIC_REC_KEY quantization_type = dynamic check currently supported future supported benefit_str = dynamic_benefit module_info IS_CURRENTLY_SUPPORTED_KEY benefit_str += future_support_str quantization_type = static benefit_str = static_benefit now set quantization explanation string quantization_reasoning = quantization_reasoning format module_fqn module_info PRE_OBS_DATA_DIST_KEY module_info POST_OBS_DATA_DIST_KEY + benefit_str we have non-stationary input - linear - stationary we suggested static however we want also recommend they add dynamic quantize per tensor right change made module_info PRE_OBS_DATA_DIST_KEY == NON_STATIONARY_STR module_info POST_OBS_DATA_DIST_KEY == STATIONARY_STR quantization_reasoning = quantization_reasoning + dynamic_per_tensor_string + dynamic_per_tensor_reasoning_string format overall suggestion string specific inputs module_suggestion_string = suggestion_string_template format module_fqn quantization_type quantization_reasoning append overall suggestion dynamic_vs_static_string += module_suggestion_string modules_added dynamic_vs_static_string += No applicable layers suggestions Only linear conv valid \n string well dictionary information dynamic_vs_static_string module_dynamic_static_info InputWeightEqualizationDetector DetectorBase r Determines whether input-weight equalization can help improve quantization certain modules Specifically list modules includes linear conv Determines whether input-weight equalization recommended based comp stat s_c = sqrt w_c W sqrt i_c I where w_c range weight channel c W range weight over all channels i_c range input channel c I range input over all channels s_c = threshold = threshold recommends input-weight equalization Args ratio_threshold float The threshold s_c determine input-weight equalization suggested Should between both non-inclusive ch_axis int optional The channel axis being observed determine input weight equalization Default attr ` ratio_threshold ` The threshold s_c determine input-weight equalization suggested Should between attr ` ch_axis ` The channel axis being observed determine input weight equalization attr ` SUPPORTED_MODULES ` This specifies modules supported input-weight equalization attr ` DEFAULT_PRE_OBSERVER_NAME ` The name pre-observer inserted detector SUPPORTED_MODULES set Callable = nn Linear nn Conv d nn Conv d nn Conv d nnqat Linear nnqat Conv d nnqat Conv d nnqat Conv d names pre post observers inserted DEFAULT_PRE_OBSERVER_NAME str = model_report_pre_observer weight activation prefix each below info WEIGHT_PREFIX = weight_ ACTIVATION_PREFIX = input_activation_ string names keys info dictionaries PER_CHANNEL_MAX_KEY = per_channel_max PER_CHANNEL_MIN_KEY = per_channel_min GLOBAL_MAX_KEY = global_max GLOBAL_MIN_KEY = global_min keys dict recommendations RECOMMENDED_KEY = input_weight_equalization_recommended COMP_METRIC_KEY = input_weight_channel_comparison_metrics THRESHOLD_KEY = input_weight_threshold CHANNEL_KEY = input_weight_channel_axis default weight info strings WEIGHT_STR = weight INPUT_STR = input default what ratio we recommend input weight DEFAULT_RECOMMEND_INPUT_WEIGHT_CHANNEL_RATIO = __init__ ratio_threshold float ch_axis int = ensure passed inputs valid ratio_threshold = ratio_threshold = raise ValueError Make sure threshold initialize attributes based args ratio_threshold float = ratio_threshold ch_axis int = ch_axis _is_supported module nn Module insert bool = False - bool r Returns whether given module supported observers Args module The module check ensure supported insert True check observer insertion false report gen Returns True module supported observer False otherwise check see module supported type is_supported_type = any type module x x SUPPORTED_MODULES check observer insertion insert is_supported_type report gen we also need check contains observers has_obs = hasattr module DEFAULT_PRE_OBSERVER_NAME is_supported_type has_obs get_qconfig_info model - dict str DetectorQConfigInfo r Returns DetectorQConfigInfo each module_fqn relevant Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them A DetectorQConfigInfo information generate QConfig specific module run helper function populate dictionary find range inputs input_values dict str dict = _extract_input_info model find range weights weight_values dict str dict = _extract_weight_info model calculate per_channel comparison statistic s_c comp_stats dict str torch Tensor = _generate_comparison_values input_values weight_values generate dictionary input_weight_equalization_info dict str dict = _generate_dict_info input_values weight_values comp_stats we actually have qconfig info object we populating module_fqn_to_detector_qconfig_info = module_fqn input_weight_equalization_info create detector info instance detector_qconfig_info = DetectorQConfigInfo module_fqn see per channel quantization supported input_weight_recommended bool = input_weight_equalization_info module_fqn RECOMMENDED_KEY detector_qconfig_info is_equalization_recommended = input_weight_recommended module_fqn_to_detector_qconfig_info module_fqn = detector_qconfig_info module_fqn_to_detector_qconfig_info determine_observer_insert_points prepared_fx_model GraphModule - dict str dict str Any r Determines where observers need inserted Input Weight Equalization Detector For detector we want place observers front supported layers Currently inserts observers linear layers conv layers Args prepared_fx_model GraphModule The prepared Fx GraphModule Returns Dict mapping unique observer fqns where we want insert them Dict key target_node - node we trying observe observer torch fx node Node key observer_to_insert - observer we wish insert ObserverBase key is_post_observer - True meant post-observer target_node False pre-observer key observer_args - The arguments meant passed into observer observer detector ModelReportObserver obs_ctr = ModelReportObserver dict obs_fqn_to_info dict str dict str Any = fqn module prepared_fx_model named_modules check see module supported type _is_supported module insert=True s supported type we want get node add observer insert locations targeted_node = _get_targeting_node prepared_fx_model fqn add entry pre-observer pre_obs_fqn = fqn + + DEFAULT_PRE_OBSERVER_NAME obs_fqn_to_info pre_obs_fqn = DETECTOR_TARGET_NODE_KEY targeted_node DETECTOR_OBS_TO_INSERT_KEY obs_ctr ch_axis=self ch_axis DETECTOR_IS_POST_OBS_KEY False DETECTOR_OBS_ARGS_KEY targeted_node args obs_fqn_to_info get_detector_name - str r Returns name detector input_weight_equalization_detector _extract_input_info model GraphModule - dict str dict r Takes calibrated GraphModule then finds relevant observers It then extracts input information each observer returns Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns dict mapping relevant module fqns str dict keys input_activation_per_channel_max maps per_channel max values input_activation_per_channel_min maps per_channel min values input_activation_global_max maps global max recorded input_activation_global_min maps global min recorded dictionary mapping observer fqns desired info input_info dict str dict = fqn module model named_modules module supported has pre-observer _is_supported module get pre observer module pre_obs = getattr module DEFAULT_PRE_OBSERVER_NAME input_info fqn = ACTIVATION_PREFIX + PER_CHANNEL_MAX_KEY pre_obs max_val ACTIVATION_PREFIX + PER_CHANNEL_MIN_KEY pre_obs min_val ACTIVATION_PREFIX + GLOBAL_MAX_KEY max pre_obs max_val ACTIVATION_PREFIX + GLOBAL_MIN_KEY min pre_obs min_val input_info _extract_weight_info model GraphModule - dict str dict r Takes calibrated GraphModule then finds relevant observers It then extracts weight information each layer observer attached Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns dict mapping module fqns str dict keys per_channel_max maps per_channel max values per_channel_min maps per_channel min values global_max maps global max recorded global_min maps global min recorded dictionary mapping observer fqns desired info weight_info dict str dict = fqn module model named_modules module supported has pre-observer _is_supported module we don t need actual observer just module weights calculate min max vals device = module weight device min_val torch Tensor = torch tensor float inf device=device max_val torch Tensor = torch tensor float -inf device=device x_copy = module weight x_dim = x_copy size new_axis_list = i i range len x_dim noqa C new_axis_list ch_axis = new_axis_list = ch_axis y = x_copy permute new_axis_list Need match dtype min max because updates buffers done place types need match comparisons y = y min_val dtype y = torch flatten y start_dim= min_val numel == max_val numel == min_val max_val = torch aminmax y dim= min_val_cur max_val_cur = torch aminmax y dim= min_val = torch min min_val_cur min_val max_val = torch max max_val_cur max_val weight_info fqn = WEIGHT_PREFIX + PER_CHANNEL_MAX_KEY max_val WEIGHT_PREFIX + PER_CHANNEL_MIN_KEY min_val WEIGHT_PREFIX + GLOBAL_MAX_KEY max max_val WEIGHT_PREFIX + GLOBAL_MIN_KEY min min_val weight_info _calculate_range_ratio info_dict dict info_str str module_fqn str - torch Tensor r Takes info dict calculates s_c matrix Args info_dict dict A dictionary either input weight range info info_str str A str describing whether currently looking weight input info Either weight input module_fqn str The fqn module we looking Returns tensor values where each value s_c stat different channel calculate ratios info get prefix str prefix_str = ACTIVATION_PREFIX info_str == INPUT_STR WEIGHT_PREFIX per_channel_range = info_dict prefix_str + PER_CHANNEL_MAX_KEY - info_dict prefix_str + PER_CHANNEL_MIN_KEY global_range = info_dict prefix_str + GLOBAL_MAX_KEY - info_dict prefix_str + GLOBAL_MIN_KEY global_range == range_zero_explanation = We recommend removing channel doesn t provide any useful information raise ValueError f The range info_str data module module_fqn f which means you have constant value channel range_zero_explanation ratio = per_channel_range global_range ratio _generate_comparison_values input_info dict weight_info dict - dict str torch Tensor r Takes information min max values inputs weights Calculates comp stat each channel s_c = sqrt w_c W sqrt i_c I Args input_info dict A dict mapping each observer input range information weight_info dict A dict mapping each observer weight range information Returns dict mapping relevant observer fqns str -D tensor Each value different s_c value different channel create dictionary each observer module_fqn_to_channel dict str torch Tensor = each module both passed dicts should have same keys module_fqn input_info raise error weight info module_fqn weight_info raise KeyError f Unable find weight range stats module module_fqn calculate ratios weight info input info weight_ratio = _calculate_range_ratio weight_info module_fqn WEIGHT_STR module_fqn input_ratio = _calculate_range_ratio input_info module_fqn INPUT_STR module_fqn mismatched size because grouping we want replicate weight enough times weight_channels = len weight_ratio input_channels = len input_ratio weight_channels = input_channels we try replicate input_channels weight_channels = raise AssertionError input channels should divisible weight channels get replication factor rep_factor int = input_channels weight_channels weight ratio n input ratio k we just repeat weight ratio k n weight_ratio = weight_ratio repeat rep_factor calculate s metric per channel s = torch sqrt weight_ratio torch sqrt input_ratio module_fqn_to_channel module_fqn = s compiled observer ratios module_fqn_to_channel _generate_dict_info input_info dict weight_info dict comp_stats dict - dict str dict r Helper function generate_detector_report does generation dictionary This process done specified generate_detector_report documentation Args input_info dict A dict mapping each module input range information weight_info dict A dict mapping each module weight range information comp_stats dict A dict mapping each module its corresponding comp stat Returns dictionary mapping each module relevant ModelReportObservers around them whether input weight equalization recommended their s_c metric compared threshold threshold used make recommendation channel used recording data input channel range info weight channel range info store modules input weight equalization info input_weight_equalization_info dict str dict = each module we add separate set suggestions module_fqn input_info get relevant info module mod_input_info dict = input_info module_fqn mod_weight_info dict = weight_info module_fqn mod_comp_stat dict = comp_stats module_fqn decide each channel should have input weight equalization channel_rec_vals list = val mod_comp_stat float_rep float = val item decide recommending input weight equalization recommended bool = float_rep = ratio_threshold float_rep = ratio_threshold channel_rec_vals append recommended build dict input also unpack input weight dicts into input_weight_equalization_info module_fqn = RECOMMENDED_KEY channel_rec_vals COMP_METRIC_KEY mod_comp_stat THRESHOLD_KEY ratio_threshold CHANNEL_KEY ch_axis mod_input_info mod_weight_info our compiled info each module input_weight_equalization_info generate_detector_report model GraphModule - tuple str dict str Any r Determines whether input weight equalization appropriate given module Takes advantage ModelReport Observer which records per channel information input range It then uses passed weight info inconjunction compute desired ratio Finally gives suggestions based information each module interest Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns tuple two elements String report whether input weight equalization recommended certain modules Dictionary mapping modules interest whether input weight equalization recommended their s_c metric compared threshold threshold used make recommendation channel used recording data input channel range info weight channel range info find range inputs input_values dict str dict = _extract_input_info model find range weights weight_values dict str dict = _extract_weight_info model calculate per_channel comparison statistic s_c comp_stats dict str torch Tensor = _generate_comparison_values input_values weight_values generate dictionary input_weight_equalization_info dict str dict = _generate_dict_info input_values weight_values comp_stats now we can generate report based information input_weight_string = Input-Weight Equalization suggestions \n some strings formatted depending module we adding module_suggestion_str = For Module looked axis \n channel_suggestion_str = \tWe suggest input weight equalization because \n use_str = use no_use_str = use input_weight_benefit_str = channels would benefit we expect significant reduction quantization error input_weight_non_benefit_reasoning = channels benefitting input-weight equalization being applied input_weight_non_benefit_str = we don t expect much improvement input-weight equalization based added module check added_module bool = False compile suggestion string module_fqn input_weight_equalization_info we added least module added_module = True add module level description input_weight_string += module_suggestion_str format module_fqn ch_axis mod_info dict str Any = input_weight_equalization_info module_fqn gather info how many channels would benefit input weight recommendation_per_channel torch Tensor = mod_info RECOMMENDED_KEY num_recs = sum recommendation_per_channel num_recs len recommendation_per_channel = DEFAULT_RECOMMEND_INPUT_WEIGHT_CHANNEL_RATIO input_benefit_formatted = input_weight_benefit_str format num_recs len recommendation_per_channel channel_str = channel_suggestion_str format use_str input_benefit_formatted input_weight_string += channel_str non_benefit_reason_formatted = input_weight_non_benefit_reasoning format num_recs len recommendation_per_channel non_benefit_str = input_weight_non_benefit_str format non_benefit_reason_formatted channel_str = channel_suggestion_str format no_use_str non_benefit_str input_weight_string += channel_str no modules looked amend string added_module input_weight_string += No applicable layers suggestions Only linear conv valid \n tuple string explanation compiled dict info input_weight_string input_weight_equalization_info OutlierDetector DetectorBase r Determines whether there significant outliers activation data around certain layer This ideally used conjunction information stationary vs non-stationary distribution If data stationary there significant outliers then we want flag them We want do per channel basis detecting outliers Determines whether activation data flagged outlier based data stationary p_r = avg th percentile reference_percentile th percentile where p_r average percentile ratio across all batches epoch reference_percentile percentile values between exclusive p_r above some threshold then we consider activations have significant outliers Args ratio_threshold float optional The threshold p_r determine there outliers activations Should = Default reference_percentile float optional The denominator find relative scale th percentile Should between Default fraction_batches_used_threshold float optional Threshold fraction batches per channel determine outlier If fraction below we deem number samples used calculate outliers insignificant alert user regardless whether we detected outliers channel take closer look channel results Should between Default ch_axis int optional The channel axis being observed determine input weight equalization Default attr ` ratio_threshold ` The threshold p_r determine there outliers activations The p_r value average ratio th percentile reference_percentile compared ratio_threshold If significantly greater then we consider outlier This threshold calculated based ratio percentiles normal distribution The calculations behind value choice https drive google com file d N wdtXWI-kOH S HH -PYB_NmqzZil p view usp=sharing attr ` reference_percentile ` The denominator top fraction find relative scale th percentile Should between The calculations behind value choice https drive google com file d N wdtXWI-kOH S HH -PYB_NmqzZil p view usp=sharing attr ` fraction_batches_used_threshold ` The fraction batches determine outliers each channel should above Some batches may used because -based errors so ensure good amount total batches used Should between attr ` ch_axis ` The channel axis being observed determine outliers attr ` DEFAULT_PRE_OBSERVER_NAME ` The name pre-observer inserted detector names pre observers inserted DEFAULT_PRE_OBSERVER_NAME str = model_report_pre_observer pre activation prefix INPUT_ACTIVATION_PREFIX = input_activation_ names dict keys OUTLIER_KEY = outliers_detected NUM_BATCHES_KEY = outlier_detection_batches_used IS_SUFFICIENT_BATCHES_KEY = outlier_detection_is_sufficient_batches COMP_METRIC_KEY = outlier_detection_percentile_ratios RATIO_THRES_KEY = outlier_detection_ratio_threshold REF_PERCENTILE_KEY = outlier_detection_reference_percentile CHANNEL_AXIS_KEY = outlier_detection_channel_axis MAX_VALS_KEY = INPUT_ACTIVATION_PREFIX + per_channel_max CONSTANT_COUNTS_KEY = constant_batch_counts __init__ ratio_threshold float = reference_percentile float = fraction_batches_used_threshold float = ch_axis int = initialize variables interest ratio_threshold = ratio_threshold make sure passed percentile valid reference_percentile reference_percentile raise AssertionError reference_percentile must between fraction_batches_used_threshold = fraction_batches_used_threshold = raise AssertionError fraction_batches_used_threshold must between reference_percentile = reference_percentile fraction_batches_used_threshold = fraction_batches_used_threshold ch_axis = ch_axis get_detector_name - str r Returns name detector outlier_detector _supports_insertion module nn Module - bool r Returns whether given module supported observers insertion Any module doesn t have children isn t observer itself supported Args module The module check ensure supported Returns True module supported observer False otherwise case insertion module check module has any children isn t observer num_children = len list module children num_children == _is_activation_post_process module get_qconfig_info model - dict str DetectorQConfigInfo r Returns DetectorQConfigInfo each module_fqn relevant Args model nn Module subclass model find observer insertion points Returns Dict mapping unique observer fqns where we want insert them A DetectorQConfigInfo information generate QConfig specific module currently doesn t do anything outlier detector _supports_report_gen module nn Module - bool r Returns whether given module supported report generation Any module has model report pre-observer supported Args module The module check ensure supported Returns True module supported observer False otherwise hasattr module DEFAULT_PRE_OBSERVER_NAME determine_observer_insert_points prepared_fx_model GraphModule - dict str dict str Any r Determines where observers need inserted Outlier Detector For detector we want place observers front supported layers Currently inserts observers all layers do have children leaf level layers Args prepared_fx_model GraphModule The prepared Fx GraphModule Returns Dict mapping unique observer fqns where we want insert them Dict key target_node - node we trying observe observer torch fx node Node key observer_to_insert - observer we wish insert ObserverBase key is_post_observer - True meant post-observer target_node False pre-observer key observer_args - The arguments meant passed into observer observer detector ModelReportObserver obs_ctr = ModelReportObserver dict obs_fqn_to_info dict str dict str Any = fqn module prepared_fx_model named_modules check see module supported type _supports_insertion module s supported type we want get node add observer insert locations targeted_node = _get_targeting_node prepared_fx_model fqn add entry pre-observer pre_obs_fqn = fqn + + DEFAULT_PRE_OBSERVER_NAME obs_fqn_to_info pre_obs_fqn = DETECTOR_TARGET_NODE_KEY targeted_node DETECTOR_OBS_TO_INSERT_KEY obs_ctr ch_axis=self ch_axis comp_percentile=self reference_percentile DETECTOR_IS_POST_OBS_KEY False DETECTOR_OBS_ARGS_KEY targeted_node args obs_fqn_to_info _calculate_outlier_info percentile_ratios torch Tensor counted_batches torch Tensor total_batches int - dict str list bool r Gives info whether percentile ratios calculated would considered outliers Also gives information whether collected data statistically significant make claim Args percentile_ratios torch Tensor The average percentile_ratios per channel calculated observer counted_batches torch Tensor The number batches used average calculation per tensor total_batches int The total number batches passed through observer epoch Returns dictionary mapping outliers_detected list bools per channel true considered outlier is_sufficient_batches o_r = fraction_batches_used_threshold where o_r = counted_batches total_batches outlier_dict dict str list bool = OUTLIER_KEY IS_SUFFICIENT_BATCHES_KEY get both flattened lists easy mapping ratios_list list = percentile_ratios tolist num_batches_list list = counted_batches tolist calculate whether channels statistically significant significant_size = batch_size total_batches = fraction_batches_used_threshold batch_size num_batches_list outlier_dict IS_SUFFICIENT_BATCHES_KEY = significant_size calculate each channel whether s outlier based ratio outlier_detected = ratio ratio_threshold ratio ratios_list outlier_dict OUTLIER_KEY = outlier_detected dictionary two lists outlier_dict _generate_info_dict model GraphModule - dict str dict r Helper function generate_detector_report does generation dictionary This process done specified generate_detector_report documentation Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns dict mapping relevant module fqns whether there outliers found activation before number batches used each channel whether fraction applicable batches used above fraction_batches_used_threshold their p_r metric compared threshold threshold used make recommendation reference_percentile used make recommendation channel axis used determine individual channels constant batch counts per channel per channel max values dictionary mapping observer fqns desired info info_dict dict str dict = fqn module model named_modules module supported has pre-observer _supports_report_gen module get pre observer module pre_obs ModelReportObserver = getattr module DEFAULT_PRE_OBSERVER_NAME get number batches calculated ratio thresholds num_batches torch Tensor = pre_obs percentile_batches_tracked average_ratios torch Tensor = pre_obs average_percentile_ratio channel_batch_cnts torch Tensor = pre_obs constant_channels total_batches int = pre_obs num_batches_tracked also get max values max_vals torch Tensor = pre_obs max_val we have specifically modify how we recording negative ratio pre-relu layers index ratio_val enumerate average_ratios check we have negative ratio ratio might negative we have situation where th percentile while nth percentile which case would detected outlier Since we care more about magnitude we make positive ratio_val item first make positive average_ratios index = -ratio_val ratio_val item s less than we have flip well average_ratios index = ratio_val outlier_calcs = _calculate_outlier_info average_ratios num_batches total_batches calculate whether ratios outliers info_dict fqn = CHANNEL_AXIS_KEY ch_axis REF_PERCENTILE_KEY reference_percentile RATIO_THRES_KEY ratio_threshold COMP_METRIC_KEY average_ratios NUM_BATCHES_KEY num_batches OUTLIER_KEY outlier_calcs OUTLIER_KEY IS_SUFFICIENT_BATCHES_KEY outlier_calcs IS_SUFFICIENT_BATCHES_KEY CONSTANT_COUNTS_KEY channel_batch_cnts MAX_VALS_KEY max_vals info_dict generate_detector_report model GraphModule - tuple str dict str Any r Determines whether input weight equalization appropriate given module Takes advantage ModelReport Observer which records relevant percentile information Args model GraphModule The prepared calibrated GraphModule inserted ModelReportObservers Returns tuple two elements String report whether there outliers activations around certain modules Dictionary mapping modules interest whether there outliers found activation before number batches used each channel whether fraction applicable batches used above fraction_batches_used_threshold their p_r metric compared threshold threshold used make recommendation reference_percentile used make recommendation channel axis used determine individual channels constant batch counts per channel per channel max values generate information dictionary outlier information info_dict = _generate_info_dict model now we can generate report based information outlier_string = Outlier detection report \n added module check added_module bool = False some strings formatted depending module we adding module_suggestion_str = For Module looked axis \n channel_suggestion_str = \tFor channel we found outliers preceding activation data \n channel_max_value_str = max value across all batches note_string = Note outlier detection only reliable We recommend ensure most accurate results note_distribution = stationary distributions note_rec = running static vs dynamic detector ensure activation data before modules above stationary suggestion constant batch check since can make no outliers constant_str = \tFor channel we found constant value batches \n constant_suggestion = We recommend taking look dict data see how frequent occurred why compile suggestion string module_fqn info_dict get module specific info mod_info dict str Any = info_dict module_fqn check see we already added high level model desc added_model_desc = False look each individual channel add suggestion index outlier_detected enumerate mod_info OUTLIER_KEY outlier_detected we found least outlier added_model_desc add module level description outlier_string += module_suggestion_str format module_fqn ch_axis added_model_desc = True we mark we found least one outlier added_module = True max_value_found_str = channel_max_value_str format mod_info MAX_VALS_KEY index channel_str = channel_suggestion_str format index max_value_found_str outlier_string += channel_str also check we found constant batch mod_info CONSTANT_COUNTS_KEY index = make sure we add module level highlight added_model_desc add module level description outlier_string += module_suggestion_str format module_fqn ch_axis added_model_desc = True constant_values_for_channel = mod_info CONSTANT_COUNTS_KEY index formatted_str = constant_str format index constant_values_for_channel constant_suggestion outlier_string += formatted_str we also added least one thing description added_module = True found outlier give suggestion give default response added_module compose note string note_composed = note_string format note_distribution note_rec outlier_string += note_composed outlier_string += There no outliers found activations \n outlier_string info_dict