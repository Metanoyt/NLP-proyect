mypy allow-untyped-defs enum functools itertools logging collections abc Callable typing Any torch torch _prims_common utils torch utils _pytree pytree torch _C DispatchKey torch _higher_order_ops partitioner _find_hop_subgraph_outputs HopGraphMinCutPartitioner HopPartitionedGraph torch _higher_order_ops utils _maybe_compile_and_run_fn check_input_alias_and_mutation_return_outputs check_meta_consistency fill_none_with_masks filter_with_masks first_slice_copy get_tensor_mask mask_list materialize_as_graph reenter_make_fx split_into_chunks unique_graph_id validate_subgraph_args_types torch _ops HigherOrderOperator torch _subclasses fake_tensor FakeTensorMode torch fx experimental proxy_tensor disable_proxy_modes_tracing ProxyTorchDispatchMode track_tensor_tree torch utils _python_dispatch _get_current_dispatch_mode logger logging Logger = logging getLogger __name__ aten = torch _ops ops aten wrap_combine_fn_flat args combine_fn spec_init spec_xs num_init_leaves num_inp_leaves assert len args == num_init_leaves + num_inp_leaves f combine_fn received wrong number arguments expected num_init_leaves + num_inp_leaves got len args carry = pytree tree_unflatten args num_init_leaves spec_init xs = pytree tree_unflatten args num_init_leaves spec_xs combine_fn carry xs _extract_carry_and_out flat_out list Any num_carry int split_into_chunks flat_out num_carry len flat_out - num_carry We also do clone contiguous_format This consistent eager semantic scan which stacks outputs The result contiguous result stack operation stack_y y torch Tensor scan_length int - torch Tensor y unsqueeze repeat scan_length + y ndim clone memory_format=torch contiguous_format call_operator operator args pytree tree_leaves operator args scan combine_fn Callable pytree PyTree pytree PyTree tuple pytree PyTree pytree PyTree init pytree PyTree xs pytree PyTree dim int = reverse bool = False - tuple pytree PyTree pytree PyTree r Performs inclusive scan combine function warning ` torch scan ` prototype feature PyTorch It currently does support autograd you may run into miscompiles Read more about feature classification https pytorch org blog pytorch-feature-classification-changes #prototype Args combine_fn Callable A binary callable type ` ` Tensor Tensor - Tensor Tensor ` ` xs pytree ` ` pytree pytree - pytree pytree ` ` The first input ` ` combine_fn ` ` previous initial scan carry second input element ` ` combine_fn ` ` slice input along dim The first output element ` ` combine_fn ` ` next scan carry second output ` ` combine_fn ` ` represents slice output This function must pure i e no lifted arguments supported moment may have any side effects init torch Tensor pytree tensor leaves The initial scan carry tensor nested pytree tensors The ` ` init ` ` expected have same pytree structure first output element i e carry ` ` combine_fn ` ` xs torch Tensor pytree tensor leaves The input tensor nested pytree tensors Kwargs dim int dimension scan over default reverse bool A boolean stating scan should reversed respect ` ` dim ` ` default ` ` False ` ` Returns final_carry torch Tensor pytree tensor leaves final carry scan operation same pytree structure init out torch Tensor pytree tensor leaves each tensor leaf stacked output along first dim where each slice output scan iteration Restrictions - The combine_fn shouldn t have any aliasing between input-input input-output output-output E g view same tensor input supported As workaround can clone output avoid aliasing - The combine_fn shouldn t mutate any inputs We ll remove mutation restriction inference soon Please file issue you input mutation support training needed - The combine_fn s init carry should match next_carry pytree structure tensor metadata Example add x torch Tensor y torch Tensor next_carry = y = x + y clone output avoid output-output aliasing next_carry y clone i = torch zeros xs = torch arange returns torch tensor torch tensor last_carry cumsum = scan add init=i xs=xs The reason we flatten init xs before calling into dynamo we want create consistent input ordering combine_fn we also want input ordering matches output ordering leaves_init spec_init = pytree tree_flatten init leaves_xs_orig spec_xs = pytree tree_flatten xs Shortcut no xs provided len leaves_xs_orig == init _validate_input cfn lxs linit d r Basic arguments check callable cfn raise RuntimeError f Combine_fn must callable got cfn isinstance d int raise RuntimeError Dim must int got + str type d isinstance r bool raise RuntimeError Reverse must bool got + str type r Checks init len linit == raise RuntimeError scan operator requires init leaves x linit isinstance x torch Tensor raise RuntimeError f All init leaves must Tensor got x Checks xs x lxs isinstance x torch Tensor raise RuntimeError f All xs leaves must Tensor got x any x ndim = d x lxs raise RuntimeError All xs leaves must least have dim number dimensions scan dimension any x shape d == x lxs raise RuntimeError All xs leaves must least have dim number dimensions scan dimension ndim = leaves_xs_orig ndim dim = utils canonicalize_dim ndim dim _validate_input combine_fn leaves_xs_orig leaves_init dim reverse Move scan dim always perform scan dim leaves_xs = elem leaves_xs_orig leaves_xs append torch movedim elem dim dim = elem reverse leaves_xs = torch flip elem elem leaves_xs TODO Support _inductor lowering TODO Unify handling pytrees control flow ops such cond while_loop etc combine_fn = functools partial wrap_combine_fn_flat combine_fn=combine_fn spec_init=spec_init spec_xs=spec_xs num_init_leaves=len leaves_init num_inp_leaves=len leaves_xs run_flattened_scan combine_fn leaves_init leaves_xs scan_op combine_fn leaves_init leaves_xs additional_inputs= carry out = _maybe_compile_and_run_fn run_flattened_scan combine_fn leaves_init leaves_xs reverse out = pytree tree_map lambda elem elem flip out carry out ScanOp HigherOrderOperator __init__ super __init__ scan __call__ combine_fn init xs additional_inputs There currently issue ScanOp sometimes called additional_inputs being list See https github com pytorch pytorch issues Once issue resolved assertion should only allow tuples tuple cast should removed assert isinstance additional_inputs tuple list additional_inputs must tuple additional_inputs = tuple additional_inputs isinstance additional_inputs list additional_inputs validate_subgraph_args_types additional_inputs super __call__ combine_fn init xs additional_inputs pyrefly ignore bad-override gen_schema combine_fn init xs additional_inputs torch _higher_order_ops schema HopSchemaGenerator torch _higher_order_ops utils materialize_as_graph all_inputs = tuple list init + first_slice_copy x x xs + list additional_inputs combine_gm torch fx GraphModule = materialize_as_graph combine_fn all_inputs _ _ _ mutated_inputs outputs = check_input_alias_and_mutation_return_outputs combine_gm len mutated_inputs raise RuntimeError For scan combine_fn cannot have in-place mutations found f mutated_inputs -th inputs mutated schema_gen = HopSchemaGenerator schema_gen add_arg combine_fn combine_gm idx arg enumerate init schema_gen add_arg f init idx arg idx arg enumerate xs schema_gen add_arg f xs idx arg idx arg enumerate additional_inputs schema_gen add_arg f additional_input idx arg out outputs schema_gen add_output out schema_gen add_schema_tree_spec combine_fn init xs additional_inputs schema_gen gen_schema scan_op = ScanOp generic_scan operator init xs dim= additional_inputs= _scan init xs Perform scan ` elems ` using ` elems_init carry = init len xs == carry num_elems = xs shape dim ind = Compute dummy shapes pre-allocation num_init_leaves = len init dummy_carry dummy_out = _extract_carry_and_out call_operator operator carry first_slice_copy elem dim elem xs additional_inputs num_init_leaves out_tensor_mask = get_tensor_mask dummy_out dummy_out_masked = mask_list out_tensor_mask dummy_out Pre-allocate outs - Output matrix idxs - Index matrix scatter_ out num_elems M N idx M N outs = torch zeros num_elems + list e size dtype=e dtype device=e device i e enumerate dummy_out_masked idxs = torch ones_like e dtype=torch int unsqueeze i e enumerate dummy_out_masked store_out_in_outs out ind Store intermediate out outs matrix o x idx zip outs out idxs o num_elems M N x M N - M N ind idx M N values ind essentially o ind n k = x n k o scatter_ ind idx x unsqueeze i range num_elems ind = i carry out = _extract_carry_and_out call_operator operator carry elem select dim ind elem xs additional_inputs num_init_leaves Store inits outs matrix store_out_in_outs mask_list out_tensor_mask out ind Expand outs None depending tensor mask output outs_expanded = outs pop out_m None out_m out_tensor_mask carry outs_expanded scans = _scan init xs scans trace_scan proxy_mode func_overload combine_fn Callable init list torch Tensor xs list torch Tensor additional_inputs tuple torch Tensor torch _dynamo utils clone_input disable_proxy_modes_tracing sample_inits = clone_input x_init x_init init sample_inputs = first_slice_copy x x xs sample_additional_inputs = clone_input x isinstance x torch Tensor x x additional_inputs combine_graph = reenter_make_fx combine_fn sample_inits sample_inputs sample_additional_inputs outputs = None node combine_graph graph nodes node op == output assert outputs None assert len node args == outputs = node args assert outputs None carry output = _extract_carry_and_out outputs len init init_fake_tensors list torch Tensor &#124; torch SymInt &#124; int = i clone i init carry_fake_tensors list torch Tensor &#124; torch SymInt &#124; int = c meta val c carry check_meta_consistency init_fake_tensors carry_fake_tensors init carry include_contiguity=False _ combine_graph_name = unique_graph_id proxy_mode prefix= scan_combine_graph proxy_mode tracer root register_module combine_graph_name combine_graph args = combine_graph init xs additional_inputs proxy_args = pytree tree_map proxy_mode tracer unwrap_proxy args out_proxy = proxy_mode tracer create_proxy call_function func_overload proxy_args name= scan disable_proxy_modes_tracing scan_length = xs shape fake_carry fake_outputs = _extract_carry_and_out o meta val o outputs len init out = fake_carry stack_y t scan_length t fake_outputs track_tensor_tree out out_proxy constant=None tracer=proxy_mode tracer scan_op py_impl DispatchKey CompositeExplicitAutograd scan_op_dense combine_fn init xs additional_inputs mode = _get_current_dispatch_mode assert mode None Mode should never enabled CPU CUDA key generic_scan combine_fn init xs additional_inputs=additional_inputs ScanAutogradOp torch autograd Function NOTE scan partial grad handling If any element init xs outputs additional_inputs does require gradients i e requires_grad=False there will still gradients returned those elements those gradients will tensor filled zeros same shape element itself A special case additional_inputs tensors Such inputs can occur example symbolic tracing where shape symbol SymInt becomes additional_input For such cases we compute ` ` additional_inputs_tensor_mask ` ` which True elements additional_inputs tensors False otherwise Gradients additional_inputs only accumulated mask True otherwise value initial_g_additional_inputs passed which None non-Tensor values staticmethod pyrefly ignore bad-override forward ctx hop_partitioned_graph n_init n_xs n_additional_inputs operands init xs additional_inputs = split_into_chunks operands n_init n_xs n_additional_inputs ctx _scan_impl = ScanAutogradImpl hop_partitioned_graph init xs additional_inputs torch _C _AutoDispatchBelowAutograd ctx _scan_impl call_forward staticmethod backward ctx grad_fw_outputs None None None None ctx _scan_impl call_backward grad_fw_outputs ScanForwardIntermediatesHandlingPolicy enum Enum Partitioner can add interemdiates output original graph These intermediates fall into categories we want have different policies handling them modifying graph CLONE we clone intermediate when carried input i e init In case carry will replaced new values each forward step so we need clone carry part i e ys so remove aliasing each step s intermediate will stacked together saved bacwkard REMOVE_XS we remove intermediate output when part xs Since xs read-only case we can directly save them backward use REMOVE_ADDITIONAL_INPUTS we remove intermediate output when part additinonal_inputs additional_inputs also read-only each step we can directly save them bacwkard use We differentiate XS ADDITIONAL_INPUTS so we could have different treatment them backward In backward we need put xs intermediates carry put additional_inputs backward scan s additional_inputs KEEP corresponds real intermediate tensor operations output It varies each forward step we could just keep part ys KEEP = CLONE = REMOVE_XS = REMOVE_ADDITIONAL_INPUTS = ScanAutogradImpl Wraps over partitioned graph encapsulates scan-specific implementation details __init__ hop_partitioned_graph HopPartitionedGraph init xs additional_inputs hop_partitioned_graph = hop_partitioned_graph init = init xs = xs additional_inputs = additional_inputs forward_intermediates_handling_policies list ScanForwardIntermediatesHandlingPolicy = saved_fw_xs list Any = saved_fw_additional_inputs list Any = saved_intermediates list Any = fw_spec = pytree tree_flatten init xs additional_inputs _optimize_forward_intermediates _insert_clone need_copy_node torch fx Node output_node torch fx Node - torch fx Node graph torch fx Graph = output_node graph graph inserting_before output_node clone_node = graph call_function torch ops aten clone default args= need_copy_node clone_node meta = need_copy_node meta copy hasattr need_copy_node meta clone_node _optimize_forward_intermediates We optimize forward intermediates categorize forward intermediates into categories construct ScanForwardIntermediatesHandlingPolicy them logger isEnabledFor logging DEBUG logger debug Need remove aliasing fw_gm \n s hop_partitioned_graph fw_gm print_readable print_output=False fw_gm = hop_partitioned_graph fw_gm fw_all_outputs = _find_hop_subgraph_outputs fw_gm phs = list fw_gm graph find_nodes op= placeholder fw_outputs = fw_all_outputs hop_partitioned_graph n_fw_outputs fw_intermediates = fw_all_outputs hop_partitioned_graph n_fw_outputs init_phs xs_phs additional_inputs_phs = pytree tree_unflatten phs fw_spec init_node_set xs_node_set addi_node_set = set init_phs set xs_phs set additional_inputs_phs assert len forward_intermediates_handling_policies == assert len saved_fw_xs == assert len saved_fw_additional_inputs == intermediate_idx_to_ph_idx = ph_idx = ph i i ph enumerate phs i out enumerate fw_intermediates out init_node_set forward_intermediates_handling_policies append ScanForwardIntermediatesHandlingPolicy CLONE intermediate_idx_to_ph_idx i = ph_idx out out xs_node_set forward_intermediates_handling_policies append ScanForwardIntermediatesHandlingPolicy REMOVE_XS intermediate_idx_to_ph_idx i = ph_idx out out addi_node_set forward_intermediates_handling_policies append ScanForwardIntermediatesHandlingPolicy REMOVE_ADDITIONAL_INPUTS intermediate_idx_to_ph_idx i = ph_idx out forward_intermediates_handling_policies append ScanForwardIntermediatesHandlingPolicy KEEP new_output_node = real_graph_inputs = list init + list xs + list additional_inputs fw_output_node = next iter fw_gm graph find_nodes op= output intermediate_idx node policy enumerate zip fw_intermediates forward_intermediates_handling_policies policy == ScanForwardIntermediatesHandlingPolicy CLONE new_output_node append _insert_clone node fw_output_node policy == ScanForwardIntermediatesHandlingPolicy REMOVE_XS assert intermediate_idx intermediate_idx_to_ph_idx inp_idx = intermediate_idx_to_ph_idx intermediate_idx saved_fw_xs append real_graph_inputs inp_idx policy == ScanForwardIntermediatesHandlingPolicy REMOVE_ADDITIONAL_INPUTS assert intermediate_idx intermediate_idx_to_ph_idx inp_idx = intermediate_idx_to_ph_idx intermediate_idx saved_fw_additional_inputs append real_graph_inputs inp_idx new_output_node append node fw_output_node args = tuple fw_outputs + tuple new_output_node fw_gm graph lint fw_gm recompile logger isEnabledFor logging DEBUG logger debug after removing aliasing \n s fw_gm print_readable print_output=False call_forward fw_outputs_and_intermediates tuple Any = scan_op hop_partitioned_graph fw_gm init xs additional_inputs type ignore return-type fw_outs = fw_outputs_and_intermediates hop_partitioned_graph n_fw_outputs saved_intermediates = fw_outputs_and_intermediates hop_partitioned_graph n_fw_outputs assert len saved_intermediates == saved_intermediates extend saved_intermediates tuple fw_outs call_backward grad_fw_outputs Recall fw_outputs = carry ys bw_gm takes fw_intermediates grad_carry grad_ys returns grad_init grad_xs grad_additional_inputs The bacwkard reversed scan can constructed follows grad_additonal_inputs = torch zeros_like additional_inputs bw_init = grad_carry grad_additional_inputs bw_xs = fw_intermediates grad_ys grad_init grad_additional_inputs grad_xs = scan combine_fn bw_init bw_xs reverse = True where combine_fn defined follows combine_fn bw_init bw_xs grad_carry grad_additional_inputs = bw_init fw_intermediates grad_y = bw_xs nxt_grad_carry grad_x nxt_grad_additional_inputs = bw_gm fw_intermediates grad_carry grad_y nxt_grad_carry grad_additional_inputs + nxt_grad_additional_inputs grad_x Note grad_additional_inputs accumulated add grad_carry carried over next iteration grad_x ys output which will stacked together after loop will have same shape xs fw_policy = forward_intermediates_handling_policies saved_intermediates = saved_intermediates saved_fw_xs = saved_fw_xs saved_fw_additional_inputs = saved_fw_additional_inputs n_carry = len init grad_carry grad_ys = grad_fw_outputs n_carry grad_fw_outputs n_carry additional_inputs_tensor_masks = bool isinstance t torch Tensor t additional_inputs grad_additional_inputs = torch zeros_like t t filter_with_masks additional_inputs additional_inputs_tensor_masks bw_init = grad_carry grad_additional_inputs bw_xs = grad_ys saved_fw_xs saved_intermediates bw_additional_inputs = saved_fw_additional_inputs _ flat_spec = pytree tree_flatten bw_init bw_xs bw_additional_inputs grad_spec = None bw_single_step_wrapper args bw_init bw_xs bw_additional_inputs = pytree tree_unflatten args flat_spec grad_carry grad_additional_inputs = bw_init grad_y saved_fw_xs saved_intermediates = bw_xs saved_fw_additional_inputs = bw_additional_inputs fw_intermediates = xs_it = iter saved_fw_xs carry_it = iter saved_intermediates addi_it = iter saved_fw_additional_inputs policy fw_policy policy ScanForwardIntermediatesHandlingPolicy CLONE ScanForwardIntermediatesHandlingPolicy KEEP fw_intermediates append next carry_it policy == ScanForwardIntermediatesHandlingPolicy REMOVE_XS fw_intermediates append next xs_it policy == ScanForwardIntermediatesHandlingPolicy REMOVE_ADDITIONAL_INPUTS fw_intermediates append next addi_it raise RuntimeError f Unknown policy policy grad_fw_outputs = grad_carry grad_y flat_out = hop_partitioned_graph bw_gm fw_intermediates grad_fw_outputs next_grad_carry grad_xs grad_addi = split_into_chunks flat_out type ignore arg-type len init len xs len additional_inputs nonlocal grad_spec flat_grads grad_spec = pytree tree_flatten next_grad_carry prev + cur prev cur zip grad_additional_inputs filter_with_masks grad_addi additional_inputs_tensor_masks grad_xs flat_grads single_step_bw_xs = pytree tree_map lambda t t bw_xs bw_single_step_gm = materialize_as_graph bw_single_step_wrapper tuple pytree tree_flatten bw_init single_step_bw_xs bw_additional_inputs flat_grads = scan_op bw_single_step_gm pytree tree_flatten bw_init TODO torch flip copies tensor we should optimize away torch flip x x pytree tree_flatten bw_xs pytree tree_flatten bw_additional_inputs assert grad_spec None grad_init grad_additional_inputs grad_xs = pytree tree_unflatten flat_grads grad_spec grad_init torch flip elem elem grad_xs fill_none_with_masks grad_additional_inputs additional_inputs_tensor_masks scan_op py_autograd_impl scan_autograd combine_fn init xs additional_inputs disable_proxy_modes_tracing hop_partitioned_graph HopPartitionedGraph = HopGraphMinCutPartitioner create_partitioned_graph combine_fn init x x xs additional_inputs always_recompute_complex_exprs=True ScanAutogradOp apply hop_partitioned_graph len init len xs len additional_inputs init xs additional_inputs scan_op py_impl ProxyTorchDispatchMode scan_proxy_mode mode combine_fn init xs additional_inputs trace_scan mode scan_op combine_fn init xs additional_inputs scan_op py_impl FakeTensorMode scan_fake_tensor_mode mode combine_fn init xs additional_inputs mode scan_length = xs shape carry outputs = _extract_carry_and_out combine_fn init first_slice_copy inp inp xs additional_inputs len init out = carry stack_y t scan_length t outputs out scan_op py_functionalize_impl scan_functionalize ctx combine_fn init xs additional_inputs torch _higher_order_ops utils _check_alias_and_mutation _maybe_run_with_interpreter unwrapped_xs = ctx unwrap_tensors xs unwrapped_init = ctx unwrap_tensors init unwrapped_additional_inputs = ctx unwrap_tensors additional_inputs ctx redispatch_to_next functional_combine_fn = ctx functionalize _maybe_run_with_interpreter combine_fn sample_unwrapped_xs_sliced = first_slice_copy inp inp unwrapped_xs sample_inputs = list itertools chain unwrapped_init sample_unwrapped_xs_sliced unwrapped_additional_inputs pre_dispatch = hasattr ctx mode ctx mode pre_dispatch _check_alias_and_mutation combine_fn sample_inputs scan pre_dispatch ret = scan_op functional_combine_fn unwrapped_init unwrapped_xs unwrapped_additional_inputs ctx wrap_tensors ret scan_op py_impl torch _C _functorch TransformType Vmap scan_batch_rule interpreter combine_fn init xs additional_inputs torch _functorch vmap restore_vmap unwrap_batched wrap_batched unbatched_args in_dims = unwrap_batched init xs additional_inputs interpreter level move last dim interfere scan s batching unbatched_init unbatched_xs unbatched_additional_inputs = pytree tree_map lambda x bdim x movedim bdim - bdim None x unbatched_args in_dims after_move_dims = tuple pytree tree_flatten pytree tree_map lambda x - x None None in_dims interpreter lower out_dims = None wrapper args nonlocal out_dims outputs per_slice_out_dims = restore_vmap combine_fn after_move_dims interpreter batch_size interpreter randomness args Note outputs batched we just move batch dim end avoid interfering scan s batching outputs = tuple pytree tree_map lambda out out_bdim out movedim out_bdim - out_bdim None out outputs per_slice_out_dims out_dims = tuple pytree tree_map lambda out_bdim - out_bdim None None per_slice_out_dims outputs unwrapped_out = scan_op wrapper unbatched_init unbatched_xs unbatched_additional_inputs assert out_dims None batched_out = wrap_batched unwrapped_out out_dims interpreter level batched_out dense implementation scan Used testing only _fake_scan combine_fn init xs=None dim= reverse=False carry_leaves carry_spec = pytree tree_flatten init inp_leaves inp_spec = pytree tree_flatten xs xs None len inp_leaves == init result_flat = carry = carry_leaves op = reversed reverse lambda x x dummy_carry dummy_out = combine_fn pytree tree_unflatten carry carry_spec pytree tree_unflatten first_slice_copy elem dim elem inp_leaves inp_spec dummy_out_leaves dummy_out_spec = pytree tree_flatten dummy_out num_leaves = len dummy_out_leaves ind op range inp_leaves size dim xs = elem select dim ind elem inp_leaves carry y = combine_fn pytree tree_unflatten carry carry_spec pytree tree_unflatten xs inp_spec carry _ = pytree tree_flatten carry y _ = pytree tree_flatten y result_flat append y results = torch stack e leave_ind e op result_flat leave_ind range num_leaves pytree tree_unflatten carry carry_spec pytree tree_unflatten results dummy_out_spec