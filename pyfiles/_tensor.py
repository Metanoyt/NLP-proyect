mypy allow-untyped-defs copyreg enum functools itertools warnings collections OrderedDict collections abc Callable copy deepcopy numbers Number typing Any cast Concatenate Optional TypeVar Union typing_extensions ParamSpec torch torch _C _C torch _namedtensor_internals check_serializing_named_tensor is_ellipsis resolve_ellipsis single_ellipsis_index unzip_namedshape update_names torch overrides get_default_nowrap_functions handle_torch_function has_torch_function has_torch_function_unary has_torch_function_variadic _P = ParamSpec _P _TensorLike = TypeVar _TensorLike bound=_C TensorBase _handle_torch_function_and_wrap_type_error_to_not_implemented f Callable Concatenate _TensorLike _P Tensor - Callable Concatenate _TensorLike _P Tensor functools wraps f wrapped _TensorLike args _P args kwargs _P kwargs - Tensor try See https github com pytorch pytorch issues sargs = args has_torch_function sargs handle_torch_function wrapped sargs sargs kwargs f args kwargs except TypeError NotImplemented wrapped Should used kept only BC loading old serialized Tensor subclasses _rebuild_from_type func type args dict type Tensor func args ret = func args as_subclass type ret __dict__ = dict ret _rebuild_from_type_v func new_type args state ret = func args type ret new_type ret = ret as_subclass new_type Tensor does define __setstate__ even though doesn t define __getstate__ So only use __setstate__ NOT one defined Tensor getattr ret __class__ __setstate__ Tensor __setstate__ Tensor __setstate__ ret __setstate__ state ret = torch _utils _set_obj_state ret state ret _dtype_to_typestr dtype CUDA devices little-endian tensors stored native byte order -byte entries endian-agnostic torch complex c torch complex c torch bfloat V Same ml_dtypes bfloat dtype str torch float f torch float f torch float f torch uint &#124; u torch int &#124; i torch uint u torch int i torch uint u torch int i torch uint u torch int i torch bool &#124; b dtype NB If you subclass Tensor want share subclassed across processes you must also update torch multiprocessing reductions py define ForkingPickler serialization mode NB If you add new method Tensor you must update torch _C __init__ pyi add type annotation your method otherwise will show up autocomplete Tensor torch _C TensorBase _is_param bool _clear_non_serializable_cached_data r Clears any data cached tensor s ` ` __dict__ ` ` would prevent tensor being serialized For example subclasses custom dispatched sizes strides cache info non-serializable PyCapsules within ` ` __dict__ ` ` must cleared out serialization function Any subclass overrides MUST call ` ` super _clear_non_serializable_cached_data ` ` Additional data cleared within override must able re-cached transparently avoid breaking subclass functionality has_torch_function_unary handle_torch_function Tensor _clear_non_serializable_cached_data NB Wrapper subclasses implement custom-dispatched sizes strides cache info via non-serializable PyCapsules CACHED_SIZES_STRIDES_KEYS = _sym_sizes_capsule _sym_sizes_capsule_len _sym_strides_capsule _sym_strides_capsule_len key CACHED_SIZES_STRIDES_KEYS __dict__ pop key None __deepcopy__ memo has_torch_function_unary handle_torch_function Tensor __deepcopy__ memo is_leaf raise RuntimeError Only Tensors created explicitly user graph leaves support deepcopy protocol moment If you attempting deepcopy module may because torch nn utils weight_norm usage see https github com pytorch pytorch pull id memo memo id torch no_grad TODO skipping storage copy wrong meta meta does accurate alias tracking however code below doesn t work because https github com pytorch pytorch issues Update test test_serialization you remove meta here is_sparse device type lazy xla mtia mps maia meta ipu torch _C _has_storage device type == torch _C _get_privateuse _backend_name type Tensor data_ptr == new_tensor = clone type new_tensor type raise RuntimeError The default implementation __deepcopy__ wrapper subclasses only works subclass types implement clone which cloning returns another instance same subclass You should either properly implement clone your subclass override __deepcopy__ intended behavior clone instance different type new_storage = _typed_storage _deepcopy memo is_quantized quantizer_params can different type based torch attribute quantizer_params Union tuple torch qscheme float int tuple torch qscheme Tensor Tensor int qscheme == torch per_tensor_affine quantizer_params = qscheme q_scale q_zero_point qscheme torch per_channel_affine torch per_channel_affine_float_qparams quantizer_params = qscheme q_per_channel_scales q_per_channel_zero_points q_per_channel_axis raise RuntimeError f Unsupported qscheme qscheme deepcopy TODO Once we decide break serialization FC no longer need wrap TypedStorage new_tensor = torch _utils _rebuild_qtensor torch storage TypedStorage wrap_storage=new_storage _untyped_storage dtype=self dtype _internal=True storage_offset size stride quantizer_params requires_grad _backward_hooks type new_tensor type raise RuntimeError The default implementation __deepcopy__ quantized tensors expects tensor returned torch _utils _rebuild_qtensor match type instance being copied If you encounter please open issue PyTorch s GitHub new_tensor = new_empty type new_tensor type raise RuntimeError The default implementation __deepcopy__ non-wrapper subclasses only works subclass types implement new_empty which function returns another instance same subclass You should either properly implement new_empty your subclass override __deepcopy__ intended behavior new_empty instance different type new_tensor set_ new_storage storage_offset size stride is_conj new_tensor = new_tensor conj_physical is_neg new_tensor = new_tensor neg requires_grad new_tensor requires_grad_ grad None new_tensor grad = grad __deepcopy__ memo type Tensor type new_tensor type raise RuntimeError Type deepcopy result does match type source tensor If you encounter please open issue PyTorch s GitHub Plain Tensors don t have slots slots_to_save = copyreg _slotnames __class__ type ignore attr-defined slot slots_to_save hasattr slot setattr new_tensor slot deepcopy getattr slot memo don t try deepcopy non-serializable cached data _clear_non_serializable_cached_data new_tensor __dict__ = deepcopy __dict__ memo memo id = new_tensor new_tensor __reduce_ex__ proto materialize_fake_tensors = torch serialization _serialization_tls materialize_fake_tensors state = torch _utils _get_obj_state Ignore all state when using FakeTensor skip_data materialize_fake_tensors because FakeTensor has some state cannot pickled TODO remove hasattr s hack support versions torch don t have _subclasses hasattr torch _subclasses type torch _subclasses fake_tensor FakeTensor materialize_fake_tensors type Tensor state Fast path regular tensor without Python state _reduce_ex_internal proto has_torch_function_unary handle_torch_function Tensor __reduce_ex__ proto func args = _reduce_ex_internal proto sizes strides cache needs cleared here because ll just re-cached cleared earlier Note state references -actual- tensor dict _clear_non_serializable_cached_data _rebuild_from_type_v func type args state storage r storage - torch TypedStorage Returns underlying ` TypedStorage ` warning ` TypedStorage ` deprecated It will removed future ` UntypedStorage ` will only storage To access ` UntypedStorage ` directly use attr ` Tensor untyped_storage ` has_torch_function_unary handle_torch_function Tensor storage torch storage _warn_typed_storage_removal stacklevel= _typed_storage For internal use only avoid raising deprecation warning _typed_storage untyped_storage = untyped_storage torch TypedStorage wrap_storage=untyped_storage dtype=self dtype _internal=True _reduce_ex_internal proto check_serializing_named_tensor torch utils hooks warn_if_has_hooks See Note Don t serialize hooks warn_if_has_hooks backward_hooks dict Any Any = OrderedDict skip_data = torch serialization _serialization_tls skip_data materialize_fake_tensors = torch serialization _serialization_tls materialize_fake_tensors device type xla maia mtia torch _C _has_storage device type == torch _C _get_privateuse _backend_name skip_data raise RuntimeError Cannot serialize tensors backends no storage under skip_data context manager cpu_tensor = cpu torch _utils _rebuild_device_tensor_from_cpu_tensor cpu_tensor dtype str device requires_grad device type == meta NB This implementation BREAKS storage sharing Current hypothesis no one cares meta tensors skip_data warnings warn Serializing tensors meta device under skip_data context manager no-op stacklevel= arg_meta = dtype tuple size stride requires_grad torch _utils _rebuild_meta_tensor_no_storage arg_meta is_quantized skip_data raise RuntimeError Cannot serialize qtensor under skip_data context manager file issue you need feature quantizer_params can different type based torch attribute quantizer_params Union tuple torch qscheme float int tuple Any Tensor Tensor int qscheme == torch per_tensor_affine quantizer_params = torch per_tensor_affine q_scale q_zero_point qscheme torch per_channel_affine torch per_channel_affine_float_qparams convert scales zero points tuple avoid recursive calls when we get multi-axis quantized tensors future shape recoverable main tensor shape quantizer_params = torch per_channel_affine q_per_channel_scales q_per_channel_zero_points q_per_channel_axis raise RuntimeError f Serialization supported tensors type qscheme TODO Once we decide break serialization FC no longer need wrap TypedStorage args_qtensor = torch storage TypedStorage wrap_storage=self _typed_storage _untyped_storage dtype=self dtype _internal=True storage_offset tuple size stride quantizer_params requires_grad backward_hooks torch _utils _rebuild_qtensor args_qtensor is_sparse layout == torch sparse_coo args_sparse = layout _indices _values size is_coalesced raise NotImplementedError f sparse tensor __reduce_ex__ layout ` layout ` torch _utils _rebuild_sparse_tensor args_sparse layout torch sparse_csr torch sparse_csc torch sparse_bsr torch sparse_bsc layout torch sparse_csr torch sparse_bsr compressed_indices plain_indices = crow_indices col_indices compressed_indices plain_indices = ccol_indices row_indices args_sparse_compressed = layout compressed_indices plain_indices values size torch _utils _rebuild_sparse_tensor args_sparse_compressed is_nested skip_data raise RuntimeError Cannot serialize nested tensor under skip_data context manager file issue you need feature args_nested = NB values currently returns storage buffer unsafe way Ideally we d use private API instead TODO Switch we ever get around adding values _nested_tensor_size _nested_tensor_strides _nested_tensor_storage_offsets torch _utils _rebuild_nested_tensor args_nested type torch Tensor type __torch_dispatch__ torch Tensor __torch_dispatch__ isinstance torch _subclasses functional_tensor FunctionalTensor isinstance torch _subclasses fake_tensor FakeTensor data_ptr == arg_wrapper_subclass = type dtype tuple size stride storage_offset layout device requires_grad torch _utils _rebuild_wrapper_subclass arg_wrapper_subclass type torch Tensor type __torch_dispatch__ torch Tensor __torch_dispatch__ isinstance torch _subclasses fake_tensor FakeTensor skip_data materialize_fake_tensors arg_wrapper_subclass = type dtype tuple size stride storage_offset layout device requires_grad torch _utils _rebuild_wrapper_subclass arg_wrapper_subclass v _dtypes = torch storage _new_dtypes dtype v _dtypes rebuild_func = torch _utils _rebuild_tensor_v storage = untyped_storage TODO Once we decide break serialization FC no longer need wrap TypedStorage rebuild_func = torch _utils _rebuild_tensor_v type ignore assignment storage = torch storage TypedStorage wrap_storage=self _typed_storage _untyped_storage dtype=self dtype _internal=True type ignore assignment TODO remove hasattr s hack support versions torch don t have _subclasses hasattr torch _subclasses isinstance torch _subclasses fake_tensor FakeTensor skip_data storage _fake_device = device args = storage storage_offset tuple size stride requires_grad backward_hooks previously _backward_hooks isinstance storage torch storage UntypedStorage args = args + dtype type ignore assignment metadata = torch _utils get_tensor_metadata metadata args = args + metadata type ignore assignment rebuild_func args __setstate__ state has_torch_function_unary handle_torch_function Tensor __setstate__ state Warning method NOT called when you torch load tensor managed _rebuild_tensor_v is_leaf raise RuntimeError __setstate__ can only called leaf Tensors len state == legacy serialization Tensor pyrefly ignore not-iterable set_ state len state == legacy serialization Variable data = state state = state state state The setting _backward_hooks expected no-op See Note Don t serialize hooks requires_grad _ _backward_hooks = state __repr__ tensor_contents=None has_torch_function_unary handle_torch_function Tensor __repr__ tensor_contents=tensor_contents All strings unicode Python torch _tensor_str _str tensor_contents=tensor_contents backward gradient=None retain_graph=None create_graph=False inputs=None r Computes gradient current tensor wrt graph leaves The graph differentiated using chain rule If tensor non-scalar i e its data has more than one element requires gradient function additionally requires specifying ` ` gradient ` ` It should tensor matching type shape represents gradient differentiated function w r t ` ` ` ` This function accumulates gradients leaves - you might need zero ` ` grad ` ` attributes set them ` ` None ` ` before calling See ref ` Default gradient layouts default-grad-layouts ` details memory layout accumulated gradients note If you run any forward ops create ` ` gradient ` ` call ` ` backward ` ` user-specified CUDA stream context see ref ` Stream semantics backward passes bwd-cuda-stream-semantics ` note When ` ` inputs ` ` provided given input leaf current implementation will call its grad_fn though strictly needed get gradients It implementation detail which user should rely See https github com pytorch pytorch pull #issuecomment- more details Args gradient Tensor optional The gradient function being differentiated w r t ` ` ` ` This argument can omitted ` ` ` ` scalar Defaults ` ` None ` ` retain_graph bool optional If ` ` False ` ` graph used compute grads will freed If ` ` True ` ` will retained The default ` ` None ` ` which case value inferred ` ` create_graph ` ` i e graph retained only when higher-order derivative tracking requested Note nearly all cases setting option True needed often can worked around much more efficient way create_graph bool optional If ` ` True ` ` graph derivative will constructed allowing compute higher order derivative products Defaults ` ` False ` ` inputs Sequence Tensor optional Inputs w r t which gradient will accumulated into ` ` grad ` ` All other tensors will ignored If provided gradient accumulated into all leaf Tensors used compute attr ` tensors ` Defaults ` ` None ` ` has_torch_function_unary handle_torch_function Tensor backward gradient=gradient retain_graph=retain_graph create_graph=create_graph inputs=inputs torch autograd backward gradient retain_graph create_graph inputs=inputs index positions dims Index regular tensor binding specified positions dims This converts regular tensor first-class tensor binding specified positional dimensions Dim objects Args positions Tuple dimension positions bind dims Dim objects tuple Dim objects bind Returns First-class tensor specified dimensions bound TODO make possible dispatch positions dims has_torch_function_unary handle_torch_function Tensor index positions dims functorch dim index index positions dims register_hook hook r Registers backward hook The hook will called every time gradient respect Tensor computed The hook should have following signature hook grad - Tensor None The hook should modify its argument can optionally new gradient which will used place attr ` grad ` This function returns handle method ` ` handle remove ` ` removes hook module note See ref ` backward-hooks-execution ` more information how when hook executed how its execution ordered relative other hooks Example v = torch tensor requires_grad=True h = v register_hook lambda grad grad double gradient v backward torch tensor v grad torch FloatTensor size h remove removes hook has_torch_function_unary handle_torch_function Tensor register_hook hook requires_grad raise RuntimeError cannot register hook tensor doesn t require gradient _backward_hooks None _backward_hooks = OrderedDict grad_fn None grad_fn _register_hook_dict torch utils hooks RemovableHandle handle = RemovableHandle _backward_hooks _backward_hooks handle id = hook handle register_post_accumulate_grad_hook hook r Registers backward hook runs after grad accumulation The hook will called after all gradients tensor have been accumulated meaning grad field has been updated tensor The post accumulate grad hook ONLY applicable leaf tensors tensors without grad_fn field Registering hook non-leaf tensor will error The hook should have following signature hook param Tensor - None Note unlike other autograd hooks hook operates tensor requires grad grad itself The hook can in-place modify access its Tensor argument including its grad field This function returns handle method ` ` handle remove ` ` removes hook module note See ref ` backward-hooks-execution ` more information how when hook executed how its execution ordered relative other hooks Since hook runs during backward pass will run no_grad mode unless create_graph True You can use torch enable_grad re-enable autograd within hook you need Example v = torch tensor requires_grad=True lr = simulate simple SGD update h = v register_post_accumulate_grad_hook lambda p p add_ p grad alpha=-lr v backward torch tensor v tensor - - - requires_grad=True h remove removes hook has_torch_function_unary handle_torch_function Tensor register_post_accumulate_grad_hook hook requires_grad raise RuntimeError cannot register hook tensor doesn t require gradient grad_fn None raise RuntimeError post accumulate grad hooks cannot registered non-leaf tensors _post_accumulate_grad_hooks None _post_accumulate_grad_hooks dict Any Any = pyrefly ignore bad-assignment OrderedDict torch utils hooks RemovableHandle handle = RemovableHandle _post_accumulate_grad_hooks _post_accumulate_grad_hooks handle id = hook handle reinforce reward trim str \n join line strip line str split \n raise RuntimeError trim r reinforce removed Use torch distributions instead See https pytorch org docs main distributions html Instead probs = policy_network state action = probs multinomial next_state reward = env step action action reinforce reward action backward Use probs = policy_network state NOTE categorical equivalent what used called multinomial m = torch distributions Categorical probs action = m sample next_state reward = env step action loss = -m log_prob action reward loss backward detach = _C _add_docstr _C TensorBase detach r Returns new Tensor detached current graph The result will never require gradient This method also affects forward mode AD gradients result will never have forward mode AD gradients note Returned Tensor shares same storage original one In-place modifications either them will seen may trigger errors correctness checks detach_ = _C _add_docstr _C TensorBase detach_ r Detaches Tensor graph created making leaf Views cannot detached in-place This method also affects forward mode AD gradients result will never have forward mode AD gradients is_shared r Checks tensor shared memory This always ` ` True ` ` CUDA tensors has_torch_function_unary handle_torch_function Tensor is_shared _typed_storage _is_shared share_memory_ r Moves underlying storage shared memory This no-op underlying storage already shared memory CUDA tensors Tensors shared memory cannot resized See meth ` torch UntypedStorage share_memory_ ` more details has_torch_function_unary handle_torch_function Tensor share_memory_ _typed_storage _share_memory_ module_load other assign=False r Defines how transform ` ` other ` ` when loading into ` ` ` ` meth ` ~nn Module load_state_dict ` Used when func ` ~torch __future__ get_swap_module_params_on_conversion ` ` ` True ` ` It expected ` ` ` ` parameter buffer ` ` nn Module ` ` ` ` other ` ` value state dictionary corresponding key method defines how ` ` other ` ` remapped before being swapped ` ` ` ` via func ` ~torch utils swap_tensors ` meth ` ~nn Module load_state_dict ` note This method should always new object ` ` ` ` ` ` other ` ` For example default implementation returns ` ` copy_ other detach ` ` ` ` assign ` ` ` ` False ` ` ` ` other detach ` ` ` ` assign ` ` ` ` True ` ` Args other Tensor value state dict key corresponding ` ` ` ` assign bool assign argument passed meth ` nn Module load_state_dict ` has_torch_function_variadic other handle_torch_function Tensor module_load other other assign=assign assign other detach copy_ other detach __reversed__ r Reverses tensor along dimension has_torch_function_unary handle_torch_function Tensor __reversed__ dim == flip norm p Optional Union float str = fro dim=None keepdim=False dtype=None r See func ` torch norm ` has_torch_function_unary handle_torch_function Tensor norm p=p dim=dim keepdim=keepdim dtype=dtype torch norm p dim keepdim dtype=dtype solve other torch _linalg_utils solve solve other lstsq other torch _linalg_utils lstsq lstsq other eig eigenvectors=False torch _linalg_utils eig eig eigenvectors=eigenvectors symeig eigenvectors=False torch _linalg_utils _symeig _symeig eigenvectors=eigenvectors lu pivot=True get_infos=False r See func ` torch lu ` If get_infos True then we don t need check errors vice versa has_torch_function_unary handle_torch_function Tensor lu pivot=pivot get_infos=get_infos LU pivots infos = torch _lu_with_info pivot=pivot check_errors= get_infos get_infos LU pivots infos LU pivots stft n_fft int hop_length Optional int = None win_length Optional int = None window Optional Tensor = None center bool = True pad_mode str = reflect normalized bool = False onesided Optional bool = None return_complex Optional bool = None align_to_window Optional bool = None r See func ` torch stft ` warning This function changed signature version Calling previous signature may cause error incorrect result has_torch_function_unary handle_torch_function Tensor stft n_fft hop_length=hop_length win_length=win_length window=window center=center pad_mode=pad_mode normalized=normalized onesided=onesided return_complex=return_complex align_to_window=align_to_window torch stft n_fft hop_length win_length window center pad_mode normalized onesided return_complex=return_complex align_to_window=align_to_window istft n_fft int hop_length Optional int = None win_length Optional int = None window Optional Tensor = None center bool = True normalized bool = False onesided Optional bool = None length Optional int = None return_complex bool = False r See func ` torch istft ` has_torch_function_unary handle_torch_function Tensor istft n_fft hop_length=hop_length win_length=win_length window=window center=center normalized=normalized onesided=onesided length=length return_complex=return_complex torch istft n_fft hop_length win_length window center normalized onesided length return_complex=return_complex resize sizes has_torch_function_unary handle_torch_function Tensor resize sizes warnings warn non-inplace resize deprecated stacklevel= torch autograd _functions Resize Resize apply sizes resize_as tensor has_torch_function_variadic tensor handle_torch_function Tensor resize_as tensor tensor warnings warn non-inplace resize_as deprecated stacklevel= torch autograd _functions Resize Resize apply tensor size split split_size dim= r See func ` torch split ` has_torch_function_unary handle_torch_function Tensor split split_size dim=dim isinstance split_size Tensor try split_size = int split_size except ValueError pass isinstance split_size int torch SymInt torch _VF split split_size dim type ignore attr-defined torch _VF split_with_sizes pyrefly ignore bad-argument-type split_size dim unique sorted=True return_inverse=False return_counts=False dim=None r Returns unique elements input tensor See func ` torch unique ` has_torch_function_unary handle_torch_function Tensor unique sorted=sorted return_inverse=return_inverse return_counts=return_counts dim=dim torch unique sorted=sorted return_inverse=return_inverse return_counts=return_counts dim=dim unique_consecutive return_inverse=False return_counts=False dim=None r Eliminates all first element every consecutive group equivalent elements See func ` torch unique_consecutive ` has_torch_function_unary handle_torch_function Tensor unique_consecutive return_inverse=return_inverse return_counts=return_counts dim=dim torch unique_consecutive return_inverse=return_inverse return_counts=return_counts dim=dim _handle_torch_function_and_wrap_type_error_to_not_implemented __rsub__ other Union Tensor int float bool complex - Tensor _C _VariableFunctions rsub other _handle_torch_function_and_wrap_type_error_to_not_implemented __rdiv__ other Union Tensor int float bool complex - Tensor reciprocal other __rtruediv__ = __rdiv__ __itruediv__ = _C TensorBase __idiv__ pyrefly ignore bad-override __pow__ = cast Callable torch _C TensorBase Union Tensor int float bool complex Tensor _handle_torch_function_and_wrap_type_error_to_not_implemented _C TensorBase pow __ipow__ = _handle_torch_function_and_wrap_type_error_to_not_implemented _C TensorBase pow_ _handle_torch_function_and_wrap_type_error_to_not_implemented __rmod__ other Union Tensor int float bool complex - Tensor torch remainder other __format__ format_spec has_torch_function_unary handle_torch_function Tensor __format__ format_spec dim == is_meta type Tensor Use detach here avoid warning when converting scalar Tensor requires gradients python number It ok formatting detach item __format__ format_spec object __format__ format_spec _handle_torch_function_and_wrap_type_error_to_not_implemented __rpow__ other Union Tensor int float bool complex - Tensor torch pow other _handle_torch_function_and_wrap_type_error_to_not_implemented __floordiv__ other Union Tensor int float bool - Tensor type ignore override TODO rec superclass says accepts complex here torch floor_divide says doesn t torch floor_divide other _handle_torch_function_and_wrap_type_error_to_not_implemented __rfloordiv__ other Union Tensor int float bool - Tensor type ignore override torch floor_divide other _handle_torch_function_and_wrap_type_error_to_not_implemented __rlshift__ other Union Tensor int float bool complex - Tensor torch bitwise_left_shift other _handle_torch_function_and_wrap_type_error_to_not_implemented __rrshift__ other Union Tensor int float bool complex - Tensor torch bitwise_right_shift other _handle_torch_function_and_wrap_type_error_to_not_implemented __rmatmul__ other Tensor - Tensor torch matmul other __pos__ = _C TensorBase positive __neg__ = _C TensorBase neg __abs__ = _C TensorBase abs __len__ has_torch_function_unary handle_torch_function Tensor __len__ dim == raise TypeError len -d tensor torch _C _get_tracing_state warnings warn Using len get tensor shape might cause trace incorrect Recommended usage would tensor shape Passing tensor different shape might lead errors silently give incorrect results category=torch jit TracerWarning stacklevel= shape __iter__ NB we use imap map here so Python we get generator don t eagerly perform all indexes This could save us work also helps keep trace ordering deterministic e g you zip hiddens eager map will force all indexes hiddens before hiddens while generator map will interleave them NB We have intentionally skipped __torch_function__ dispatch here See gh- dim == raise TypeError iteration over -d tensor torch _C _get_tracing_state warnings warn Iterating over tensor might cause trace incorrect Passing tensor different shape won t change number iterations executed might lead errors silently give incorrect results category=torch jit TracerWarning stacklevel= iter unbind __hash__ Do NOT handle __torch_function__ here user s default implementation handle most functions will most likely do wrong It can easily overridden defining method user subclass needed id __dir__ has_torch_function_unary handle_torch_function Tensor __dir__ tensor_methods = dir __class__ tensor_methods remove volatile deprecated attrs = list __dict__ keys keys = tensor_methods + attrs property only available dense cuda tensors is_cuda is_sparse keys remove __cuda_array_interface__ sorted keys Numpy array interface support ` numpy asarray tensor - ndarray ` __array_priority__ = prefer Tensor ops over numpy ones __array__ dtype=None has_torch_function_unary handle_torch_function Tensor __array__ dtype=dtype dtype None numpy numpy astype dtype copy=False Wrap Numpy array again suitable tensor when done support e g ` numpy sin tensor - tensor ` ` numpy greater tensor - ByteTensor ` __array_wrap__ array has_torch_function_unary handle_torch_function Tensor __array_wrap__ array=array array dtype == bool Workaround torch has no built-in bool tensor array = array astype uint torch from_numpy array __contains__ element Any - bool r Check ` element ` present tensor Args element Tensor scalar element checked presence current tensor has_torch_function_unary handle_torch_function Tensor __contains__ element isinstance element torch Tensor Number torch SymInt torch SymFloat torch SymBool type hint doesn t understand __contains__ result array bool element == any item type ignore union-attr raise RuntimeError f Tensor __contains__ only supports Tensor scalar you passed type element property __cuda_array_interface__ Array view description cuda tensors See https numba pydata org numba-doc dev cuda cuda_array_interface html has_torch_function_unary TODO mypy doesn t support property see https github com python mypy issues handle_torch_function Tensor __cuda_array_interface__ __get__ type ignore attr-defined raise AttributeError unsupported tensors so hasattr cpu_tensor __cuda_array_interface__ False is_cuda raise AttributeError f Can t get __cuda_array_interface__ non-CUDA tensor type type If CUDA data required use tensor cuda copy tensor device memory is_sparse raise AttributeError f Can t get __cuda_array_interface__ sparse type type Use Tensor to_dense convert dense tensor first RuntimeError matching tensor __array__ behavior requires_grad raise RuntimeError Can t get __cuda_array_interface__ Variable requires grad If gradients aren t required use var detach get Variable doesn t require grad typestr = _dtype_to_typestr dtype itemsize = element_size shape = tuple shape is_contiguous __cuda_array_interface__ v requires strides omitted either set set None C-contiguous arrays strides = None strides = tuple s itemsize s stride data_ptr = data_ptr numel data = data_ptr False read-only false dict typestr=typestr shape=shape strides=strides data=data version= storage_type r storage_type - type Returns type underlying storage has_torch_function_unary handle_torch_function Tensor storage_type torch storage _warn_typed_storage_removal _typed_storage _get_legacy_storage_class refine_names names pyrefly ignore bad-override r Refines dimension names attr ` ` according attr ` names ` Refining special case renaming lifts unnamed dimensions A ` ` None ` ` dim can refined have any name named dim can only refined have same name Because named tensors can coexist unnamed tensors refining names gives nice way write named-tensor-aware code works both named unnamed tensors attr ` names ` may contain up one Ellipsis ` ` ` ` The Ellipsis expanded greedily expanded in-place fill attr ` names ` same length ` ` dim ` ` using names corresponding indices ` ` names ` ` Python does support Ellipsis one may use string literal instead ` ` ` ` Args names iterable str The desired names output tensor May contain up one Ellipsis Examples imgs = torch randn named_imgs = imgs refine_names N C H W named_imgs names N C H W tensor = torch randn tensor = tensor refine_names A B C tensor names A None None B C warning The named tensor API experimental subject change has_torch_function_unary handle_torch_function Tensor refine_names names names = resolve_ellipsis names names refine_names super refine_names names align_to names pyrefly ignore bad-override r Permutes dimensions attr ` ` tensor match order specified attr ` names ` adding size-one dims any new names All dims attr ` ` must named order use method The resulting tensor view original tensor All dimension names attr ` ` must present attr ` names ` attr ` names ` may contain additional names ` ` names ` ` output tensor has size-one dimension each those new names attr ` names ` may contain up one Ellipsis ` ` ` ` The Ellipsis expanded equal all dimension names attr ` ` mentioned attr ` names ` order they appear attr ` ` Python does support Ellipsis one may use string literal instead ` ` ` ` Args names iterable str The desired dimension ordering output tensor May contain up one Ellipsis expanded all unmentioned dim names attr ` ` Examples tensor = torch randn named_tensor = tensor refine_names A B C D E F Move F E dims front while keeping rest order named_tensor align_to F E warning The named tensor API experimental subject change has_torch_function_unary handle_torch_function Tensor align_to names ellipsis_idx = single_ellipsis_index names align_to ellipsis_idx None super align_to names super align_to name name names is_ellipsis name ellipsis_idx unflatten dim sizes type ignore override r unflatten dim sizes - Tensor See func ` torch unflatten ` has_torch_function_unary handle_torch_function Tensor unflatten dim sizes sizes raise RuntimeError unflatten sizes must non-empty names = None isinstance sizes OrderedDict isinstance sizes tuple list isinstance sizes tuple list names sizes = unzip_namedshape sizes super unflatten dim sizes names super unflatten dim sizes rename_ names rename_map In-place version meth ` ~Tensor rename ` has_torch_function_unary handle_torch_function Tensor rename_ names rename_map Note rename_ rename API The Python API these different C++ API In Python tensor rename names takes vararglist names tensor rename rename_map takes map names rename C++ static making difficult implement similar behavior update_names names rename_map inplace=True rename names rename_map Renames dimension names attr ` ` There two main usages ` ` rename rename_map ` ` returns view tensor has dims renamed specified mapping attr ` rename_map ` ` ` rename names ` ` returns view tensor renaming all dimensions positionally using attr ` names ` Use ` ` rename None ` ` drop names tensor One cannot specify both positional args attr ` names ` keyword args attr ` rename_map ` Examples imgs = torch rand names= N C H W renamed_imgs = imgs rename N= batch C= channels renamed_imgs names batch channels H W renamed_imgs = imgs rename None renamed_imgs names None None None None renamed_imgs = imgs rename batch channel height width renamed_imgs names batch channel height width warning The named tensor API experimental subject change has_torch_function_unary handle_torch_function Tensor rename names rename_map See Note rename_ rename API update_names names rename_map inplace=False to_sparse_coo Convert tensor ref ` coordinate format sparse-coo-docs ` Examples dense = torch randn sparse = dense to_sparse_coo sparse _nnz to_sparse dim_order ambiguity_check Union bool list torch memory_format = False dim_order ambiguity_check=False - tuple Returns uniquely determined tuple int describing dim order physical layout attr ` ` The dim order represents how dimensions laid out memory dense tensors starting outermost innermost dimension Note dim order may always uniquely determined If ` ambiguity_check ` True function raises RuntimeError when dim order cannot uniquely determined If ` ambiguity_check ` list memory formats function raises RuntimeError when tensor can interpreted into exactly one given memory formats cannot uniquely determined If ` ambiguity_check ` False will one legal dim order s without checking its uniqueness Otherwise will raise TypeError Args ambiguity_check bool List torch memory_format The check method ambiguity dim order Examples torch empty dim_order torch empty transpose dim_order torch empty memory_format=torch channels_last dim_order torch empty dim_order try torch empty dim_order ambiguity_check=True except RuntimeError e print e The tensor does have unique dim order cannot map exact one given memory formats torch empty dim_order ambiguity_check= torch contiguous_format torch channels_last It can mapped contiguous format try torch empty dim_order ambiguity_check= ILLEGAL except TypeError e print e The ambiguity_check argument must bool list memory formats warning The dim_order tensor API experimental subject change has_torch_function_unary handle_torch_function Tensor dim_order is_sparse raise AttributeError f Can t get dim order sparse type type Use Tensor to_dense convert dense tensor first Sanity check ambiguity_check data types isinstance ambiguity_check bool isinstance ambiguity_check list raise TypeError The ambiguity_check argument must bool list memory formats memory_format ambiguity_check isinstance memory_format torch memory_format raise TypeError The ambiguity_check argument must bool list memory formats invalid_unique_memory_format tensor valid_memory_formats Returns True tensor cannot uniquely mapped any given memory formats False otherwise n_legality = memory_format valid_memory_formats tensor is_contiguous memory_format=memory_format n_legality += n_legality = has_multiple_dim_order tensor Returns True there re multiple legal dim orders given tensor False otherwise The tensor considered have multiple legal dim orders either following conditions met Singleton Dimensions There s least one singleteon dimension tensor Since their size they don t affect memory offset stride index zero because index always zero Therefore they can placed anywhere dimension order without changing how data accessed Same strides Strides reflect how tensor stored memory If any two dimensions have same stride swapping these dimensions won t change how data accessed leading multiple correct dimension orders torch fx experimental symbolic_shapes guard_or_false sizes = tensor size strides = tensor stride Check there any duplicate strides has_duplicate_strides = any guard_or_false earlier == later earlier later itertools pairwise strides Check there any singleton dimensions has_singleton_dims = any guard_or_false size == size sizes has_duplicate_strides has_singleton_dims valid_memory_formats = ambiguity_check isinstance ambiguity_check list check_multiple_dim_order = ambiguity_check isinstance ambiguity_check bool True check_multiple_dim_order has_multiple_dim_order invalid_unique_memory_format valid_memory_formats raise RuntimeError The tensor does have unique dim order cannot map exact one given memory formats torch _prims_common utils out_perm raise_ambiguity = utils compute_elementwise_output_logical_to_physical_perm ambiguity_check=ambiguity_check raise_ambiguity raise RuntimeError The tensor does have unique dim order tuple out_perm _update_names names inplace has_torch_function_unary handle_torch_function Tensor _update_names names inplace See Note rename_ rename API inplace super rename_ names super rename names classmethod __torch_function__ cls func types args= kwargs=None This __torch_function__ implementation wraps subclasses such methods called subclasses subclass instance instead ` ` torch Tensor ` ` instance One corollary you need coverage torch Tensor methods implementing __torch_function__ subclasses We recommend always calling ` ` super __torch_function__ ` ` base case when doing above While mandatory we recommend making ` __torch_function__ ` classmethod kwargs None kwargs = all issubclass cls t t types NotImplemented _C DisableTorchFunctionSubclass ret = func args kwargs func get_default_nowrap_functions ret _convert ret cls __torch_dispatch__ = _C _disabled_torch_dispatch_impl __dlpack__ stream Optional Any = - max_version Optional tuple int int = None dl_device Optional tuple enum IntEnum int = None copy Optional bool = None Creates DLpack ` capsule https data-apis org array-api latest design_topics data_interchange html#data-interchange ` _ current tensor exported other libraries This function will called ` from_dlpack ` method library will consume capsule ` from_dlpack ` passes current stream method part specification Args stream integer None An optional Python integer representing pointer CUDA stream The current stream synchronized stream before capsule created since capsule shares its storage tensor make safe access both streams If - passed then no synchronization performed If CUDA ROCM then default stream used synchronization This API intentionally slightly deviates DLPack guidance default stream - stream-preserving no cross-stream sync because many from_dlpack implementations intend stream preservation For non-CUDA devices - treated same None max_version tuple int int None An optional Python tuple integers representing maximum version caller supports If None default PyTorch will fallback DLPack dl_device tuple DLDeviceType int None An optional tuple specifying which device exported DLPack capsule should If None default exported DLPack capsule will same device ` ` ` ` copy bool None An optional boolean indicating whether copy ` ` ` ` If None PyTorch will copy only necessary has_torch_function_unary args = kwargs = stream stream max_version max_version dl_device dl_device copy copy handle_torch_function Tensor __dlpack__ args kwargs DLPack capsules can t capture all PyTorch s semantics so we prohibit exporting tensors would lose their properties like requires_grad having conjugate bit set requires_grad raise BufferError Can t export tensors require gradient use tensor detach is_conj raise BufferError Can t export tensors conjugate bit set layout = torch strided raise BufferError Can t export tensors layout other than torch strided device type == cuda device index = torch cuda current_device raise BufferError Can t export tensors different CUDA device index f Expected device index f Current device torch cuda current_device stream None type stream int Stream pointers CUDA ROCm uniquely numbered can retrieved their integer value raise TypeError stream must ` ` int ` ` ` ` none ` ` device type == cuda stream = - NB This logic handles special case values default streams must kept sync from_dlpack torch utils dlpack py is_rocm = torch version hip None is_cuda = is_rocm stream None is_rocm stream == is_cuda stream == stream = torch cuda default_stream is_cuda stream == raise BufferError per-thread default stream supported device_str = CUDA is_cuda ROCm assert is_cuda stream = is_rocm stream f unsupported stream device_str stream stream = torch cuda ExternalStream stream Only synchronize different streams current_stream = torch cuda current_stream stream = current_stream event = torch cuda Event event record current_stream stream wait_event event device type == cpu assert stream None stream == - stream should None cpu device type == xla torch_xla torch_xla utils dlpack xla_dlpack len torch_xla real_devices = cuda torch_xla real_devices lower raise RuntimeError Can t export dlpack XLA tensor CUDA Does support DLPack yet xla_dlpack to_dlpack max_version None max_version Fallback old unversioned variant _C _to_dlpack dl_device=dl_device copy=copy _C _to_dlpack_versioned dl_device=dl_device copy=copy __dlpack_device__ - tuple enum IntEnum int has_torch_function_unary handle_torch_function Tensor __dlpack_device__ torch utils dlpack DLDeviceType device = device idx = device index device index None torch_device_type = device type torch_device_type == cuda torch version hip None device_type = DLDeviceType kDLROCM torch_device_type == cpu is_pinned device_type = DLDeviceType kDLCUDAHost torch_device_type == cuda device_type = DLDeviceType kDLCUDA torch_device_type == cpu device_type = DLDeviceType kDLCPU torch_device_type == xpu device_type = DLDeviceType kDLOneAPI device type == privateuse device_type = DLDeviceType kDLExtDev torch_device_type == xla torch_xla len torch_xla real_devices = cuda torch_xla real_devices lower raise ValueError f Unknown device type torch_device_type Dlpack device_type = DLDeviceType kDLCUDA torch_device_type == mps device_type = DLDeviceType kDLMetal raise ValueError f Unknown device type torch_device_type Dlpack device_type idx __module__ = torch _convert ret cls cls Tensor ret isinstance ret Tensor isinstance ret cls ret = ret as_subclass cls isinstance ret tuple list Also handles things like namedtuples ret = type ret _convert r cls r ret ret