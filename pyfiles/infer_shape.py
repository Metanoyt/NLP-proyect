mypy allow-untyped-defs copy collections defaultdict torch torch _dynamo source LocalSource torch _subclasses FakeTensorMode torch fx experimental proxy_tensor make_fx torch fx experimental shape_inference infer_symbol_values infer_symbol_values torch fx experimental symbolic_shapes DimDynamic ShapeEnv torch utils _pytree This function runs shape inference It will modify input graph module so shapes annotated infer_shape gm input_tensors Prepare environments shape_env = ShapeEnv fake_mode = FakeTensorMode shape_env=shape_env allow_non_fake_inputs=True flatten_inputs spec = _pytree tree_flatten input_tensors dim_count = input_tensor flatten_inputs dim_count += input_tensor dim - sample = f s i i range dim_count init_symints = mksym shape_env v LocalSource k DimDynamic DYNAMIC k v sample items symints = copy deepcopy init_symints symbol_to_idx_dict = f s i i i range dim_count padding_constraints = defaultdict list type ignore var-annotated complete_flag = False allowed_try_times = dim_count while complete_flag allowed_try_times Create symbolic input tensors fake_mode sym_tensors = i = input_tensor flatten_inputs curr_dim = input_tensor dim desired_size = symints + symints ii ii range i i + curr_dim - sym_tensor = torch randn desired_size sym_tensors append sym_tensor i += curr_dim - sym_tensors = _pytree tree_unflatten sym_tensors spec try fake_mode make_fx gm tracing_mode= symbolic _allow_non_fake_inputs=True pre_dispatch=True _allow_fake_constant=True sym_tensors complete_flag = True gm input_tensors fake_mode symints except RuntimeError e e infer_symbol_values symints init_symints symbol_to_idx_dict padding_constraints str e allowed_try_times -= except ValueError e e infer_symbol_values symints init_symints symbol_to_idx_dict padding_constraints str e allowed_try_times -= mksym shape_env value source dynamic_dim shape_env create_symintnode shape_env create_symbol value source=source dynamic_dim=dynamic_dim hint=value source=source