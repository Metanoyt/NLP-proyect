mypy allow-untyped-decorators mypy allow-untyped-defs contextlib functools logging warnings collections abc Callable typing Any Optional Union torch torch utils _pytree pytree torch _C DispatchKey torch _C _functorch _add_batch_dim get_unwrapped is_batchedtensor maybe_get_bdim torch _functorch utils exposed_in torch _higher_order_ops utils _maybe_run_with_interpreter check_input_alias_and_mutation_return_outputs create_bw_fn fill_none_with_masks filter_with_masks materialize_as_graph reenter_make_fx save_tensors_and_symints_for_backward saved_tensors_and_symints unique_graph_id validate_subgraph_args_types torch _ops HigherOrderOperator torch _subclasses fake_tensor FakeTensor FakeTensorMode torch fx experimental proxy_tensor ProxyTorchDispatchMode track_tensor_tree torch utils _python_dispatch _get_current_dispatch_mode log = logging getLogger __name__ We re going define ` cond_op ` operation In order do we need implementations each dispatch keys CondOp HigherOrderOperator __init__ super __init__ cond __call__ pred true_fn false_fn operands validate_subgraph_args_types operands super __call__ pred true_fn false_fn operands pyrefly ignore bad-override gen_schema pred true_fn false_fn operands torch _higher_order_ops schema HopSchemaGenerator torch _higher_order_ops utils materialize_as_graph then_gm torch fx GraphModule = materialize_as_graph true_fn operands else_gm torch fx GraphModule = materialize_as_graph false_fn operands _ _ _ then_mutated_inputs then_outputs = check_input_alias_and_mutation_return_outputs then_gm _ _ _ else_mutated_inputs else_outputs = check_input_alias_and_mutation_return_outputs else_gm mutated_inputs = set then_mutated_inputs &#124; set else_mutated_inputs schema_gen = HopSchemaGenerator schema_gen add_arg pred pred schema_gen add_arg true_fn then_gm schema_gen add_arg false_fn else_gm idx arg enumerate operands schema_gen add_arg f operand idx arg is_mutated=idx mutated_inputs out then_outputs schema_gen add_output out schema_gen add_schema_tree_spec pred true_fn false_fn operands schema_gen gen_schema cond_op = CondOp exposed_in torch cond pred Union bool int float torch Tensor true_fn Callable false_fn Callable operands Union tuple list = - Any r Conditionally applies ` true_fn ` ` false_fn ` warning ` torch cond ` prototype feature PyTorch It has limited support input output types doesn t support training currently Please look forward more stable implementation future version PyTorch Read more about feature classification https pytorch org blog pytorch-feature-classification-changes #prototype ` cond ` structured control flow operator That like Python if-statement has restrictions ` true_fn ` ` false_fn ` ` operands ` enable capturable using torch compile torch export Assuming constraints ` cond ` s arguments met ` cond ` equivalent following cond pred true_branch false_branch operands pred true_branch operands false_branch operands Args pred Union bool torch Tensor A boolean expression tensor one element indicating which branch function apply true_fn Callable A callable function - b within scope being traced false_fn Callable A callable function - b within scope being traced The true branch false branch must have consistent input outputs meaning inputs have same outputs have same type shape Int output also allowed We ll make output dynamic turning into symint operands Tuple possibly nested dict list tuple torch Tensor A tuple inputs true false functions It can empty true_fn false_fn doesn t require input Defaults Example true_fn x torch Tensor x cos false_fn x torch Tensor x sin cond x shape true_fn false_fn x Restrictions - The conditional statement aka ` pred ` must meet one following constraints - It s ` torch Tensor ` only one element torch bool dtype - It s boolean expression e g ` x shape ` ` x dim x shape ` - The branch function aka ` true_fn ` ` false_fn ` must meet all following constraints - The function signature must match operands - The function must tensor same metadata e g shape dtype etc - The function cannot have in-place mutations inputs global variables Note in-place tensor operations such ` add_ ` intermediate results allowed branch torch compiler is_dynamo_compiling cond_op pred true_fn false_fn operands isinstance pred bool int float This non-strict export case Strict export torch compile handled above dynamo torch compiler is_compiling warnings warn Pred Python constant When used torch cond specializes one branches If you want torch cond preserve two branches please make predicate boolean tensor SymBool UserWarning stacklevel= This eager case We can just run true false branch pred true_fn operands false_fn operands _validate_input pred true_fn false_fn operands isinstance pred bool torch Tensor torch SymBool raise RuntimeError f Expected pred bool tensor got pred isinstance pred torch Tensor pred numel = raise RuntimeError f Expected pred bool single-element tensor got pred callable true_fn callable false_fn raise RuntimeError Expect both branches callable isinstance operands tuple list pytree tree_any lambda t isinstance t torch Tensor operands raise RuntimeError Expect operands tuple possibly nested dict list tuple only f consists tensor leaves got operands _validate_input pred true_fn false_fn operands torch _dynamo is_dynamo_supported raise RuntimeError torch cond requires dynamo support Dynamo expecting callable __code__ attribute We cannot directly pass cond_op So we wrap dummy function _cond_op_wrapper args kwargs cond_op args kwargs torch _higher_order_ops utils setup_compilation_env setup_compilation_env backend torch compile _cond_op_wrapper backend=backend fullgraph=True pred true_fn false_fn operands trace_cond proxy_mode func_overload pred true_fn false_fn operands assert isinstance operands list tuple f Cond operands must list tuple tensors SymInts operands true_graph = reenter_make_fx true_fn operands false_graph = reenter_make_fx false_fn operands true_outs = false_outs = node true_graph graph nodes node op == output true_outs extend node args node false_graph graph nodes node op == output false_outs extend node args flat_true_outs = pytree arg_tree_leaves true_outs flat_false_outs = pytree arg_tree_leaves false_outs len flat_true_outs = len flat_false_outs raise torch _dynamo exc CondOpArgsMismatchError f Expected same number outputs got f \n true branch returns len flat_true_outs item s f \n false branch returns len flat_false_outs item s i true_name = unique_graph_id proxy_mode prefix= true_graph false_name = f false_graph_ i assert hasattr proxy_mode tracer root false_name proxy_mode tracer root register_module true_name true_graph proxy_mode tracer root register_module false_name false_graph args = pred true_graph false_graph operands proxy_args = pytree tree_map proxy_mode tracer unwrap_proxy args out_proxy = proxy_mode tracer create_proxy call_function func_overload proxy_args out = func_overload pred true_graph false_graph operands track_tensor_tree out out_proxy constant=None tracer=proxy_mode tracer cond_op py_impl DispatchKey CompositeExplicitAutograd cond_op_dense pred true_fn false_fn operands assert all isinstance o torch Tensor int o operands f Dense implementation operands must list tensors ints operands mode = _get_current_dispatch_mode assert mode None Mode should never enabled CPU CUDA key pred true_fn operands false_fn operands CondAutogradOp torch autograd Function staticmethod pyrefly ignore bad-override forward ctx pred true_fn false_fn operands ctx _pred = pred ctx _true_bw_fn = create_bw_fn true_fn operands ctx _false_bw_fn = create_bw_fn false_fn operands We snapshot dispatch keys forward materializing bw_graph backward ctx _fw_include_key_set = torch _C _dispatch_tls_local_include_set ctx _fw_exclude_key_set = torch _C _dispatch_tls_local_exclude_set save_tensors_and_symints_for_backward ctx operands torch _C _AutoDispatchBelowAutograd cond_op pred true_fn false_fn operands staticmethod backward ctx flat_grads operands = saved_tensors_and_symints ctx args = operands + flat_grads TODO we need materialize bw graphs because dynamo unable trace through joint function when torch compile torch autograd grad grads_tensor_masks = create_fn_remove_none fn functools wraps fn wrapped args nonlocal grads_tensor_masks true_outputs = fn args grads_tensor_masks = bool isinstance out torch Tensor out true_outputs filter_with_masks true_outputs grads_tensor_masks wrapped true_bw_gm = materialize_as_graph create_fn_remove_none ctx _true_bw_fn args ctx _fw_include_key_set ctx _fw_exclude_key_set force_enable_grad=True false_bw_gm = materialize_as_graph create_fn_remove_none ctx _false_bw_fn args ctx _fw_include_key_set ctx _fw_exclude_key_set force_enable_grad=True grads = cond_op ctx _pred true_bw_gm false_bw_gm args None None None fill_none_with_masks grads grads_tensor_masks Note As long one tensors pred operands requires grad all output would require grad backward fn set CondAutogradOp This consistent autograd Function s semantic cond_op py_autograd_impl cond_autograd pred true_fn false_fn operands CondAutogradOp apply pred true_fn false_fn operands cond_op py_impl ProxyTorchDispatchMode inner mode pred true_fn false_fn operands trace_cond mode cond_op pred true_fn false_fn operands cond_op py_impl FakeTensorMode cond_fake_tensor_mode mode pred true_fn false_fn operands Ignore here because you ve gotten here you re manually tracing inner graphs means you intend reuse graph directly Which means old unbacked symbol bindings appropriate This strategy will work unbacked symbols can escape ignore_fresh_unbacked = contextlib nullcontext mode shape_env ignore_fresh_unbacked = mode shape_env ignore_fresh_unbacked_symbols mode ignore_fresh_unbacked flat_true_outs true_out_spec = pytree tree_flatten true_fn operands flat_false_outs false_out_spec = pytree tree_flatten false_fn operands true_out_spec = false_out_spec raise RuntimeError Unmatched output spec torch cond branches f true branch tree_spec true_out_spec vs false branch tree_spec false_out_spec merged_outs = true_out false_out zip flat_true_outs flat_false_outs merged_outs append _merge_output true_out false_out mode pytree tree_unflatten merged_outs true_out_spec check_tensor_meta_match t torch Tensor t torch Tensor attr_names tuple str msg_prefix str - None _get_attr_maybe_call t torch Tensor attr_name str - Any attr = getattr t attr_name callable attr attr attr attr_name attr_names lattr = _get_attr_maybe_call t attr_name rattr = _get_attr_maybe_call t attr_name torch _check lattr == rattr lambda f msg_prefix expected same attr_name got lattr rattr _merge_output Optional Union torch Tensor int b Optional Union torch Tensor int mode FakeTensorMode torch fx experimental symbolic_shapes has_free_unbacked_symbols SymIntEqByExpr None b None assert None b None b None min_max s s _bound s lower_bound bool isinstance s int s r = mode shape_env var_to_range get type ignore union-attr s node expr torch utils _sympy value_ranges ValueRanges unknown r lower lower_bound r upper min _bound s True _bound s True max _bound s False _bound s False type int type b int == b assert mode shape_env None merged_out = mode shape_env create_unbacked_symint mode shape_env constrain_symbol_range merged_out node expr min_max b merged_out assert type FakeTensor type b FakeTensor type b type b Note we don t check size stride because they ll merged unbacked symints they differ _meta_to_check = dtype device layout dim is_quantized is_conj is_sparse storage_offset check_tensor_meta_match b tuple _meta_to_check msg_prefix= When merging two branches output torch cond NYI assert is_quantized b is_quantized assert is_sparse b is_sparse assert is_conj b is_conj Step create unbacked symints sizes different along same axis For example size s s b size s s merged_size will u u u u where u has range min s s max s s u has range min s s max s s u has range u has range merged_size list Union int torch SymInt = _has_unbacked_symbols s Union int torch SymInt - bool isinstance s int False has_free_unbacked_symbols s node expr s s zip size b size If there unbacked symbols leaked out true_branch false_branch we need merge them new unbacked symbol track parent graph _has_unbacked_symbols s _has_unbacked_symbols s SymIntEqByExpr s == SymIntEqByExpr s merged_size append s assert mode shape_env None new_size = mode shape_env create_unbacked_symint mode shape_env constrain_symbol_range new_size node expr min_max s s merged_size append new_size This follows logic symbolic_shapes _compute_symbolic_stride Step Since tensor stride accumulative multiplication sizes which permutated due view ops non-descending sequence Case No size In case strides have unique values For example suppose we have tensor size stride merged_size u u u u u u We visit strides ascending order In each step we check whether current stride bounded bound next stride setting stride_expr next_stride = current_stride_expr current_size_expr st round current_stride current_size so next_stride = current_stride_expr set current_size_expr u so stride_expr therefore u = u nd round current_stride current_size so next_stride = current_stride_expr stride_expr i e u current_size_expr u so stride_expr = u u Case At least one dimension has size which can produce duplicates strides In case theoretically we cannot uniquely determine expr strides because accessing stride_expr same key different order causes final stride expression different Suppose we have size stride merged_size u u The stride expr could either u u depending whether we start u u For reason we try break tie sorting via descending index so we always get u Note backend might optimize strides anyway so usually problem long two branches matches See relevant discussions https github com pytorch pytorch issues Case Dim has stride stride doesn t participate accumulative multiplication sizes So they re always treated constant even their corresponding size turned into unbacked symint Suppose we have size stride merged_size u u The merged stride would _bound_stride a_ex_size torch Size b_ex_size torch Size a_ex_stride tuple int b_ex_stride tuple int merged_size list Union int torch SymInt - list Union int torch SymInt torch _inductor ir get_stride_order a_sorted_stride_idx = get_stride_order a_ex_stride mode shape_env b_sorted_stride_idx = get_stride_order b_ex_stride mode shape_env a_stride_li list Optional tuple Union int torch SymInt int = None len a_ex_stride b_stride_li list Optional tuple Union int torch SymInt int = None len b_ex_stride i idx enumerate a_sorted_stride_idx a_stride_li idx = a_ex_stride i -i i idx enumerate b_sorted_stride_idx b_stride_li idx = b_ex_stride i -i a_pair b_pair zip a_stride_li b_stride_li assert a_pair None b_pair None _ a_idx = a_pair _ b_idx = b_pair a_idx = b_idx raise RuntimeError f The sorted order strides two branches output doesn t match f indicates contiguousness two branches different f True branch has stride a_ex_stride false branch has stride b_ex_stride f Consider using contiguous make two branches have same contiguousness _maybe_expr s Union int torch SymInt isinstance s int s s node expr a_stride_expr dict Any Union int torch SymInt = b_stride_expr dict Any Union int torch SymInt = merged_strides list Union int torch SymInt = None len a_ex_stride type ignore list-item a_pair b_pair zip a_stride_li b_stride_li assert a_pair None b_pair None a_val neg_i = a_pair b_val _ = b_pair i = -neg_i a_val == assert b_val == a_val b_val merged_strides i = continue _maybe_expr a_val a_stride_expr a_expr = a_stride_expr _maybe_expr a_val assert b_stride_expr _maybe_expr b_val == a_expr f a_stride_expr a_stride_expr b_stride_expr b_stride_expr merged_strides i = a_expr a_val == assert b_val == a_stride_expr _maybe_expr a_val = b_stride_expr _maybe_expr b_val = merged_strides i = If we cannot find expr a_val a_stride_expr means strides simple accumulative multiplication sizes In case we cannot determine expr strides new shapes so we error out hint users call contiguous raise RuntimeError f It seems one cond s output stride simple accumulative multiplication sizes f This could because cond returns slice tensor which dense memory f True branch has size a_ex_size stride a_ex_stride false branch has size b_ex_size f stride b_ex_stride Hint can call t contiguous nxt_merged_stride_expr = merged_strides i merged_size i a_stride_expr _maybe_expr a_val a_ex_size i = nxt_merged_stride_expr b_stride_expr _maybe_expr b_val b_ex_size i = nxt_merged_stride_expr merged_strides merged_stride list Union int torch SymInt = _bound_stride size b size stride b stride merged_size mode torch empty_strided merged_size merged_stride dtype=a dtype device=a device cond_op py_functionalize_impl cond_func ctx pred true_fn false_fn inputs torch _higher_order_ops utils _check_alias_and_mutation unwrapped_inputs = ctx unwrap_tensors inputs unwrapped_pred = ctx unwrap_tensors pred ctx redispatch_to_next functional_true = ctx functionalize _maybe_run_with_interpreter true_fn functional_false = ctx functionalize _maybe_run_with_interpreter false_fn pre_dispatch = hasattr ctx mode ctx mode pre_dispatch branch branch_name true_fn cond_true false_fn cond_false _check_alias_and_mutation branch unwrapped_inputs branch_name pre_dispatch cond_return = cond_op unwrapped_pred functional_true functional_false unwrapped_inputs ctx wrap_tensors cond_return cond_op py_impl torch _C _functorch TransformType Vmap cond_batch_rule interpreter pred true_fn false_fn inputs assert isinstance inputs list tuple Cond inputs must list tuple tensors assert all isinstance i torch Tensor i inputs Cond inputs must list tensors pred_is_batched = isinstance pred torch Tensor is_batchedtensor pred pred_ = get_unwrapped pred pred_is_batched pred unbatched tensors vmapped tensors in_dims = zip get_unwrapped t maybe_get_bdim t is_batchedtensor t t None t inputs pred_is_batched prepend pred vmap everything tensors = pred_ + tensors in_dims = + in_dims fn p args t = true_fn args f = false_fn args torch where p t f interpreter lower result = torch vmap fn in_dims=in_dims tensors predicate known stage boolean expression tensor one element true_fn = torch vmap true_fn in_dims=in_dims false_fn = torch vmap false_fn in_dims=in_dims interpreter lower result = cond_op pred true_fn false_fn tensors isinstance result tuple result = result lvl = interpreter level tuple _add_batch_dim r lvl r result