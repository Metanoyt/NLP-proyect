mypy allow-untyped-defs builtins importlib importlib machinery inspect io linecache os sys types collections abc Callable Iterable contextlib contextmanager typing Any cast Optional TYPE_CHECKING Union weakref WeakValueDictionary torch torch serialization _get_restore_location _maybe_decode_ascii torch types FileLike _directory_reader DirectoryReader _importlib _calc___package__ _normalize_line_endings _normalize_path _resolve_name _sanity_check _mangling demangle PackageMangler _package_unpickler PackageUnpickler file_structure_representation _create_directory_from_file_list Directory importer Importer TYPE_CHECKING glob_group GlobPattern __all__ = PackageImporter This list imports implicitly allowed even they haven t been marked extern This work around fact Torch implicitly depends numpy package can t track https github com pytorch multipy issues codespell ignore multipy IMPLICIT_IMPORT_ALLOWLIST Iterable str = numpy numpy core numpy core _multiarray_umath FX GraphModule might depend builtins module users usually don t extern builtins Here we here default builtins Compatibility name mapping facilitate upgrade external modules The primary motivation enable Numpy upgrade many modules depend The latest release Numpy removed ` numpy str ` ` numpy bool ` breaking unpickling many modules EXTERN_IMPORT_COMPAT_NAME_MAPPING dict str dict str Any = numpy str str bool bool PackageImporter Importer Importers allow you load code written packages ` PackageExporter ` Code loaded hermetic way using files package rather than normal python system This allows packaging PyTorch model code data so can run server used future transfer learning The importer packages ensures code module can only loaded within package except modules explicitly listed external during export The file ` ` extern_modules ` ` zip archive lists all modules package externally depends This prevents implicit dependencies where package runs locally because importing locally-installed package then fails when package copied another machine The dictionary already loaded modules package equivalent ` ` sys modules ` ` local importer modules dict str types ModuleType __init__ file_or_buffer Union FileLike torch _C PyTorchFileReader module_allowed Callable str bool = lambda module_name True Open ` ` file_or_buffer ` ` importing This checks imported package only requires modules allowed ` ` module_allowed ` ` Args file_or_buffer file-like object has implement meth ` read ` meth ` readline ` meth ` tell ` meth ` seek ` string ` ` os PathLike ` ` object containing filename module_allowed Callable str bool optional A method determine externally provided module should allowed Can used ensure packages loaded do depend modules server does support Defaults allowing anything Raises ImportError If package will use disallowed module torch _C _log_api_usage_once torch package PackageImporter zip_reader Any isinstance file_or_buffer torch _C PyTorchFileReader filename = pytorch_file_reader zip_reader = file_or_buffer isinstance file_or_buffer os PathLike str filename = os fspath file_or_buffer os path isdir filename zip_reader = torch _C PyTorchFileReader filename zip_reader = DirectoryReader filename filename = binary zip_reader = torch _C PyTorchFileReader file_or_buffer torch _C _log_api_usage_metadata torch package PackageImporter metadata serialization_id zip_reader serialization_id file_name filename root = _PackageNode None modules = extern_modules = _read_extern extern_module extern_modules module_allowed extern_module raise ImportError f package file_or_buffer needs external module extern_module f module has been disallowed _add_extern extern_module fname zip_reader get_all_records _add_file fname patched_builtins = builtins __dict__ copy patched_builtins __import__ = __import__ Allow packaged modules reference their PackageImporter modules torch_package_importer = type ignore assignment _mangler = PackageMangler used reduce deserializaiton storage_context Any = None last_map_location = None used torch serialization _load Unpickler = lambda args kwargs PackageUnpickler args kwargs import_module name str package=None Load module package hasn t already been loaded then module Modules loaded locally importer will appear ` ` modules ` ` rather than ` ` sys modules ` ` Args name str Fully qualified name module load package type optional Unused present match signature importlib import_module Defaults ` ` None ` ` Returns types ModuleType The possibly already loaded module We should always able support importing modules package This support something like obj = importer load_pickle importer import_module obj __module__ - string will mangled Note _mangler demangle will demangle any module names produced different PackageImporter instance name = _mangler demangle name _gcd_import name load_binary package str resource str - bytes Load raw bytes Args package str The name module package e g ` ` my_package my_subpackage ` ` resource str The unique name resource Returns bytes The loaded data path = _zipfile_path package resource zip_reader get_record path load_text package str resource str encoding str = utf- errors str = strict - str Load string Args package str The name module package e g ` ` my_package my_subpackage ` ` resource str The unique name resource encoding str optional Passed ` ` decode ` ` Defaults ` ` utf- ` ` errors str optional Passed ` ` decode ` ` Defaults ` ` strict ` ` Returns str The loaded text data = load_binary package resource data decode encoding errors load_pickle package str resource str map_location=None - Any Unpickles resource package loading any modules needed construct objects using meth ` import_module ` Args package str The name module package e g ` ` my_package my_subpackage ` ` resource str The unique name resource map_location Passed ` torch load ` determine how tensors mapped devices Defaults ` ` None ` ` Returns Any The unpickled object pickle_file = _zipfile_path package resource restore_location = _get_restore_location map_location loaded_storages = loaded_reduces = storage_context = torch _C DeserializationStorageContext load_tensor dtype size key location restore_location name = f key storage storage_context has_storage name storage = storage_context get_storage name dtype _typed_storage tensor = zip_reader get_storage_from_record data + name size dtype isinstance zip_reader torch _C PyTorchFileReader storage_context add_storage name tensor storage = tensor _typed_storage loaded_storages key = restore_location storage location persistent_load saved_id assert isinstance saved_id tuple typename = _maybe_decode_ascii saved_id data = saved_id typename == storage storage_type key location size = data storage_type torch UntypedStorage dtype = torch uint dtype = storage_type dtype key loaded_storages load_tensor dtype size key _maybe_decode_ascii location restore_location storage = loaded_storages key TODO Once we decide break serialization FC we can stop wrapping TypedStorage torch storage TypedStorage wrap_storage=storage _untyped_storage dtype=dtype _internal=True typename == reduce_package fix BC breaking change objects load path will loaded multiple times erroneously len data == func args = data func args reduce_id func args = data reduce_id loaded_reduces loaded_reduces reduce_id = func args loaded_reduces reduce_id f Unknown typename persistent_load expected storage reduce_package got typename Load data which may turn use ` persistent_load ` load tensors data_file = io BytesIO zip_reader get_record pickle_file unpickler = Unpickler data_file unpickler persistent_load = persistent_load type ignore assignment contextmanager set_deserialization_context let reduce_package access deserializaiton context storage_context = storage_context last_map_location = map_location try yield finally storage_context = None last_map_location = None set_deserialization_context result = unpickler load TODO zdevito This stateful weird function will need removed our efforts unify format It has race condition multiple python threads try read independent files torch _utils _validate_loaded_sparse_tensors result id Returns internal identifier torch package uses distinguish ` PackageImporter ` instances Looks like torch_package_ _mangler parent_name file_structure include GlobPattern = exclude GlobPattern = - Directory Returns file structure representation package s zipfile Args include Union List str str An optional string e g ` ` my_package my_subpackage ` ` optional list strings names files included zipfile representation This can also glob-style pattern described meth ` PackageExporter mock ` exclude Union List str str An optional pattern excludes files whose name match pattern Returns ` Directory ` _create_directory_from_file_list filename zip_reader get_all_records include exclude python_version Returns version python used create package Note function experimental Forward Compatible The plan move into lock file later Returns ` Optional str ` python version e g None no version stored package python_version_path = data python_version zip_reader get_record python_version_path decode utf- strip zip_reader has_record python_version_path None _read_extern zip_reader get_record data extern_modules decode utf- splitlines keepends=False _make_module name str filename Optional str is_package bool parent str mangled_filename = _mangler mangle filename filename None spec = importlib machinery ModuleSpec name type ignore arg-type origin= package_importer is_package=is_package module = importlib util module_from_spec spec modules name = module module __name__ = _mangler mangle name ns = module __dict__ ns __spec__ = spec ns __loader__ = ns __file__ = mangled_filename ns __cached__ = None ns __builtins__ = patched_builtins ns __torch_package__ = True Add module our private global registry It should unique due mangling assert module __name__ _package_imported_modules _package_imported_modules module __name__ = module preemptively install parent prevent IMPORT_FROM trying access sys modules _install_on_parent parent name module filename None assert mangled_filename None preemptively install source ` linecache ` so stack traces ` inspect ` etc work assert filename linecache cache type ignore attr-defined linecache lazycache mangled_filename ns code = _compile_source filename mangled_filename exec code ns module _load_module name str parent str cur _PathNode = root atom name split isinstance cur _PackageNode atom cur children name IMPLICIT_IMPORT_ALLOWLIST module = modules name = importlib import_module name module raise ModuleNotFoundError f No module named name self-contained archive filename f module also list allowed external modules extern_modules name=name cur = cur children atom isinstance cur _ExternNode module = modules name = importlib import_module name compat_mapping = EXTERN_IMPORT_COMPAT_NAME_MAPPING get name old_name new_name compat_mapping items module __dict__ setdefault old_name new_name module _make_module name cur source_file type ignore attr-defined isinstance cur _PackageNode parent _compile_source fullpath str mangled_filename str source = zip_reader get_record fullpath source = _normalize_line_endings source compile source mangled_filename exec dont_inherit=True note named ` get_source ` so linecache can find source when __loader__ module get_source module_name - str linecache calls ` get_source ` ` module __name__ ` argument so we must demangle here module = import_module demangle module_name zip_reader get_record demangle module __file__ decode utf- note named ` get_resource_reader ` so importlib resources can find This otherwise considered internal method get_resource_reader fullname try package = _get_package fullname except ImportError None package __loader__ None _PackageResourceReader fullname _install_on_parent parent str name str module types ModuleType parent Set module attribute its parent parent_module = modules parent parent_module __loader__ setattr parent_module name rpartition module note copied cpython s code call create module replaced _make_module _do_find_and_load name parent = name rpartition module_name_no_parent = name rpartition - parent parent modules _gcd_import parent Crazy side-effects name modules modules name parent_module = modules parent try parent_module __path__ type ignore attr-defined except AttributeError when we attempt package only containing pybinded files parent directory isn t always package defined python so we search package actually there before calling error isinstance parent_module __loader__ importlib machinery ExtensionFileLoader name extern_modules msg = _ERR_MSG + r c extension module which externed C extension modules \ need externed PackageExporter order used we do support interning them format name name raise ModuleNotFoundError msg name=name None isinstance parent_module __dict__ get module_name_no_parent types ModuleType msg = _ERR_MSG + r c extension package which does contain r format name parent name raise ModuleNotFoundError msg name=name None msg = _ERR_MSG + r package format name parent raise ModuleNotFoundError msg name=name None module = _load_module name parent _install_on_parent parent name module module note copied cpython s code _find_and_load name module = modules get name _NEEDS_LOADING module _NEEDS_LOADING _do_find_and_load name module None message = f name halted None sys modules raise ModuleNotFoundError message name=name To handle https github com pytorch pytorch issues where std s creation fake submodules via hacking sys modules friendly name == os modules os path = cast Any module path name == typing sys version_info modules typing io = cast Any module io modules typing re = cast Any module re module _gcd_import name package=None level= Import module based its name package call being made level adjustment This function represents greatest common denominator functionality between import_module __import__ This includes setting __package__ loader did _sanity_check name package level level name = _resolve_name name package level _find_and_load name note copied cpython s code _handle_fromlist module fromlist recursive=False Figure out what __import__ should The import_ parameter callable which takes name module It required decouple function assuming importlib s implementation desired module_name = demangle module __name__ The hell fromlist If package imported try stuff fromlist hasattr module __path__ x fromlist isinstance x str recursive where = module_name + __all__ where = ` ` list raise TypeError f Item where must str type x __name__ x == recursive hasattr module __all__ _handle_fromlist module module __all__ recursive=True hasattr module x from_name = f module_name x try _gcd_import from_name except ModuleNotFoundError exc Backwards-compatibility dictates we ignore failed imports triggered fromlist modules don t exist exc name == from_name modules get from_name _NEEDS_LOADING None continue raise module __import__ name globals=None locals=None fromlist= level= level == module = _gcd_import name globals_ = globals globals None package = _calc___package__ globals_ module = _gcd_import name package level fromlist Return up first dot name This complicated fact name may relative level == _gcd_import name partition name module Figure out where slice module s name up first dot name cut_off = len name - len name partition Slice end needs positive alleviate need special-case when ` ` name ` ` module_name = demangle module __name__ modules module_name len module_name - cut_off _handle_fromlist module fromlist _get_package package Take package name module object module If name module imported If passed imported module object package raise exception hasattr package __spec__ package __spec__ submodule_search_locations None raise TypeError f package __spec__ name r package package module = import_module package module __spec__ submodule_search_locations None raise TypeError f package r package module _zipfile_path package resource=None package = _get_package package assert package __loader__ name = demangle package __name__ resource None resource = _normalize_path resource f name replace resource f name replace _get_or_create_package atoms list str - Union _PackageNode _ExternNode cur = root i atom enumerate atoms node = cur children get atom None node None node = cur children atom = _PackageNode None isinstance node _ExternNode node isinstance node _ModuleNode name = join atoms i raise ImportError f inconsistent module structure module name package has submodules assert isinstance node _PackageNode cur = node cur _add_file filename str Assembles Python module out given file Will ignore files data directory Args filename str name file inside package archive added prefix last = filename split len prefix prefix == data package = _get_or_create_package prefix isinstance package _ExternNode raise ImportError f inconsistent module structure package contains module file filename f subpackage module marked external last == __init__ py package source_file = filename last endswith py package_name = last -len py package children package_name = _ModuleNode filename _add_extern extern_name str prefix last = extern_name split package = _get_or_create_package prefix isinstance package _ExternNode shorter extern covers extern case package children last = _ExternNode _NEEDS_LOADING = object _ERR_MSG_PREFIX = No module named _ERR_MSG = _ERR_MSG_PREFIX + r _PathNode pass _PackageNode _PathNode __init__ source_file Optional str source_file = source_file children dict str _PathNode = _ModuleNode _PathNode __slots__ = source_file __init__ source_file str source_file = source_file _ExternNode _PathNode pass A private global registry all modules have been package-imported _package_imported_modules WeakValueDictionary = WeakValueDictionary ` inspect ` default only looks ` sys modules ` find source files classes Patch check our private registry package-imported modules well _orig_getfile = inspect getfile _patched_getfile object inspect isclass object object __module__ _package_imported_modules _package_imported_modules object __module__ __file__ _orig_getfile object inspect getfile = _patched_getfile _PackageResourceReader Private used support PackageImporter get_resource_reader Confirms importlib abc ResourceReader interface Allowed access innards PackageImporter __init__ importer fullname importer = importer fullname = fullname open_resource resource io BytesIO BytesIO importer load_binary fullname resource resource_path resource The contract resource_path either returns concrete file system path raises FileNotFoundError isinstance importer zip_reader DirectoryReader importer zip_reader has_record os path join fullname resource os path join importer zip_reader directory fullname resource raise FileNotFoundError is_resource name path = importer _zipfile_path fullname name importer zip_reader has_record path contents pathlib Path filename = fullname replace fullname_path = Path importer _zipfile_path fullname files = importer zip_reader get_all_records subdirs_seen = set filename files try relative = Path filename relative_to fullname_path except ValueError continue If path file which relative top zip namespace relative package given when resource reader created has parent then s name subdirectory thus we skip parent_name = relative parent name len parent_name == yield relative name parent_name subdirs_seen subdirs_seen add parent_name yield parent_name