usr bin python mypy allow-untyped-defs itertools torch pyrefly ignore deprecated torch autograd profiler_legacy profile _disable_server_process_global_profiler _enable_server_process_global_profiler __all__ list str = _server_process_global_profile profile It has same API ` ` torch autograd profiler profile ` ` except enables profiling all threads running RPC server request callbacks Context manager manages autograd profiler state holds summary results Under hood just records events functions being executed C++ exposes those events Python You can wrap any code into will only report runtime PyTorch functions Note profiler thread local automatically propagated into async tasks Args enabled bool optional Setting False makes context manager no-op Default ` ` True ` ` use_cuda bool optional Enables timing CUDA events well using cudaEvent API Adds approximately us overhead each tensor operation Default ` ` False ` ` record_shapes bool optional If shapes recording set information about input dimensions will collected This allows one see which dimensions have been used under hood further group them using prof key_averages group_by_input_shape=True Please note shape recording might skew your profiling data It recommended use separate runs without shape recording validate timing Most likely skew will negligible bottom most events case nested function calls But higher level functions total cpu time might artificially increased because shape collection profile_memory bool optional Whether report memory usage default ` ` False ` ` warning Enabling memory profiling incurs additional profiler overhead warning Due some CUDA multiprocessing limitations see ref ` multiprocessing-cuda-note ` one cannot use profiler ` ` use_cuda = True ` ` benchmark DataLoaders ` ` num_workers ` ` If you wish benchmark data loading please use ` ` use_cuda = False ` ` ` ` num_workers = ` ` Example xdoctest +SKIP On worker torch torch distributed rpc rpc rpc init_rpc worker rank= world_size= x y = torch tensor torch tensor outer_profile_rref = rpc remote dst_worker_name rpc _server_process_global_profile outer_profile_rref rpc_sync __enter__ rpc rpc_sync dst_worker_name torch add x y inner_profile_rref = rpc remote dst_worker_name rpc _server_process_global_profile inner_profile_rref rpc_sync __enter__ rpc rpc_sync dst_worker_name torch sub x y inner_profile_rref rpc_sync __exit__ None None None outer_profile_rref rpc_sync __exit__ None None None print inner_profile_rref rpc_sync key_averages --------- --------------- --------------- --------------- --------------- --------------- --------------- Name Self CPU total Self CPU total CPU total CPU total CPU time avg Number Calls --------- --------------- --------------- --------------- --------------- --------------- --------------- sub us us us empty us us us --------- --------------- --------------- --------------- --------------- --------------- --------------- Self CPU time total us print outer_profile_rref rpc_sync key_averages --------- --------------- --------------- --------------- --------------- --------------- --------------- Name Self CPU total Self CPU total CPU total CPU total CPU time avg Number Calls --------- --------------- --------------- --------------- --------------- --------------- --------------- sub us us us empty us us us add us us us --------- --------------- --------------- --------------- --------------- --------------- --------------- Self CPU time total us rpc shutdown On worker torch distributed rpc rpc rpc init_rpc worker rank= world_size= wait worker finish work then shutdown rpc shutdown __init__ args kwargs super __init__ args kwargs __enter__ Turn server-side process-global profiling This enables thread-local profiler all RPC threads running server-side request callbacks enabled entered type ignore has-type raise RuntimeError autograd profiler traces reentrant entered = True profiler_kind = torch autograd ProfilerState CUDA use_cuda torch autograd ProfilerState CPU profiler_config = torch autograd ProfilerConfig profiler_kind record_shapes profile_memory False False False torch profiler _ExperimentalConfig _enable_server_process_global_profiler profiler_config __exit__ exc_type exc_val exc_tb Turn off server-side process-global profiling Aggregate all profiling events recorded RPC threads These attributes assigned exiting context Attributes function_events torch autograd profiler EventList It s list has helper methods like show record items pretty-print table do averaging grouping keys more process_global_function_events List torch autograd profiler FunctionEvent It s list ` ` FunctionEvent ` ` elements Every element profiling result RPC request handling within profiling range enabled process_global_events = _disable_server_process_global_profiler Every element list thread profiling result RPC request handling process_global_function_events = thread_local_events process_global_events Parse ` ` Event ` ` s ` ` FunctionEvent ` ` s thread_local_function_events = torch autograd profiler_legacy _parse_legacy_records thread_local_events thread_local_function_events sort key=lambda function_event function_event time_range start - function_event time_range end process_global_function_events append thread_local_function_events flattened_function_events = list itertools chain from_iterable process_global_function_events pyrefly ignore bad-assignment function_events = torch autograd profiler_util EventList flattened_function_events use_device= cuda use_cuda None profile_memory=self profile_memory pyrefly ignore missing-attribute function_events _build_tree process_global_function_events = process_global_function_events False