Owner s module codegen __future__ annotations tempfile unittest expecttest torchgen gen _GLOBAL_PARSE_NATIVE_YAML_CACHE noqa F torchgen gen_backend_stubs run gen_backend_stubs py integration point called directly external backends The tests here confirm badly formed inputs result reasonable error messages TestGenBackendStubs expecttest TestCase setUp - None global _GLOBAL_PARSE_NATIVE_YAML_CACHE _GLOBAL_PARSE_NATIVE_YAML_CACHE clear assert_success_from_gen_backend_stubs yaml_str str - None tempfile NamedTemporaryFile mode= w fp fp write yaml_str fp flush run fp name True get_errors_from_gen_backend_stubs yaml_str str kernels_str str &#124; None = None - str tempfile NamedTemporaryFile mode= w fp fp write yaml_str fp flush try kernels_str None run fp name True tempfile NamedTemporaryFile mode= w kernel_file kernel_file write kernels_str kernel_file flush run fp name True impl_path=kernel_file name except AssertionError e Scrub out temp file name any error messages simplify assertions str e replace fp name fail Expected gen_backend_stubs raise AssertionError did test_valid_single_op - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - abs assert_success_from_gen_backend_stubs yaml_str test_valid_multiple_ops - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - add Tensor - abs assert_success_from_gen_backend_stubs yaml_str test_valid_zero_ops - None yaml_str = \ backend XLA cpp_namespace torch_xla supported assert_success_from_gen_backend_stubs yaml_str test_valid_zero_ops_doesnt_require_backend_dispatch_key - None yaml_str = \ backend BAD_XLA cpp_namespace torch_xla supported External codegen yaml file no operators effectively no-op so there s no reason parse backend assert_success_from_gen_backend_stubs yaml_str test_valid_with_autograd_ops - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - abs autograd - add Tensor External codegen yaml file no operators effectively no-op so there s no reason parse backend assert_success_from_gen_backend_stubs yaml_str test_missing_backend - None yaml_str = \ cpp_namespace torch_xla supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide value backend test_empty_backend - None yaml_str = \ backend cpp_namespace torch_xla supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide value backend test_backend_invalid_dispatch_key - None yaml_str = \ backend NOT_XLA cpp_namespace torch_xla supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error \ unknown dispatch key NOT_XLA The provided value backend must valid DispatchKey got NOT_XLA noqa B test_missing_cpp_namespace - None yaml_str = \ backend XLA supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide value cpp_namespace test_whitespace_cpp_namespace - None yaml_str = \ backend XLA cpp_namespace \t supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide value cpp_namespace supported single item should list test_nonlist_supported - None yaml_str = \ backend XLA cpp_namespace torch_xla supported abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error expected supported list got abs type str supported contains op isn t native_functions yaml test_supported_invalid_op - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - abs_BAD output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error Found invalid operator name abs_BAD The backend valid doesn t have valid autograd key They can t override autograd kernels case Only using Vulkan here because has valid backend key autograd key- changes we can update test test_backend_has_no_autograd_key_but_provides_entries - None yaml_str = \ backend Vulkan cpp_namespace torch_vulkan supported - add autograd - sub output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error Found invalid operator name add noqa B operator group currently all operators must either registered backend autograd kernel Here functional out mismatch test_backend_autograd_kernel_mismatch_out_functional - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - add Tensor autograd - add out output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error Currently all variants op must either registered backend key backend s autograd key They cannot mix matched If something you need feel free create issue add listed under supported add_out listed under autograd noqa B operator group currently all operators must either registered backend autograd kernel Here functional inplace mismatch test_backend_autograd_kernel_mismatch_functional_inplace - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - add Tensor autograd - add_ Tensor output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error Currently all variants op must either registered backend key backend s autograd key They cannot mix matched If something you need feel free create issue add listed under supported add_ listed under autograd noqa B Currently same operator can t listed under both supported autograd which would involve registering same kernel both XLA AutogradXLA keys If we need functionality future we ll need augment codegen test_op_appears_in_supported_and_autograd_lists - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - add Tensor autograd - add Tensor output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error Currently all variants op must either registered backend key backend s autograd key They cannot mix matched If something you need feel free create issue add listed under supported add listed under autograd noqa B unrecognized extra yaml key test_unrecognized_key - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - abs invalid_key invalid_val output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error contains unexpected keys invalid_key Only following keys supported backend class_name cpp_namespace extra_headers supported autograd full_codegen non_native ir_gen symint noqa B use_out_as_primary provided must bool test_use_out_as_primary_non_bool - None yaml_str = \ backend XLA cpp_namespace torch_xla use_out_as_primary frue supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide either True False use_out_as_primary Provided frue noqa B device_guard provided must bool test_device_guard_non_bool - None yaml_str = \ backend XLA cpp_namespace torch_xla device_guard frue supported - abs output_error = get_errors_from_gen_backend_stubs yaml_str assertExpectedInline output_error You must provide either True False device_guard Provided frue noqa B test_incorrect_kernel_name - None yaml_str = \ backend XLA cpp_namespace torch_xla supported - abs autograd - add Tensor Codegen will expect two kernel names try parse them regex XLANativeFunctions abs XLANativeFunctions add kernels_str = \ Tensor XLANativeFunctions absWRONG Tensor Tensor XLANativeFunctions add Tensor output_error = get_errors_from_gen_backend_stubs yaml_str kernels_str=kernels_str assertExpectedInline output_error \ XLANativeFunctions missing kernel definition abs We found kernel s name expected kernel s The expected function schemas missing operator Tensor abs const Tensor __name__ == __main__ unittest main