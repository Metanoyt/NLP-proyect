usr bin env python csv itertools sys time warnings contextlib nullcontext click numpy np operator_inp_utils OperatorInputsLoader tqdm tqdm torch torch _dynamo backends cudagraphs cudagraphs_inner torch _dynamo testing same torch _inductor compile_fx compile_fx torch _inductor decomposition decompositions torch _inductor lowering lowerings torch _inductor runtime benchmarking benchmarker torch _inductor utils gen_gm_and_inputs torch utils _pytree tree_map_only aten = torch ops aten profile_enabled = False inductor_config_options = halide cpu_backend halide cuda_backend halide autotune max_autotune_pointwise True max_autotune True max_autotune_gemm True coordinate_descent_tuning True maybe_record_function name torch profiler record_function name profile_enabled nullcontext compute_speedups operator models example_inputs repeats accuracy_checking=False device= cuda expected = models example_inputs accuracy_checking model models actual = model example_inputs change assert later try same actual expected cos_similarity=True equal_nan=True except AssertionError e print e print f Accuracy check failed operator print expected - actual abs max timings = np zeros repeats len models np float rep range repeats maybe_record_function f rep_ rep interleave runs handle frequency scaling load changes m model enumerate models maybe_record_function f model_ m device == cuda model example_inputs benchmarker benchmark_gpu clears L cache hide latency CPU launch time along cuda synchronization timings rep m = benchmarker benchmark_gpu lambda model example_inputs torch _inductor utils timed timings rep m = timed model example_inputs np median timings axis= strip_overloads gm Modifies target graph nodes attr ` gm ` strip overloads Args gm fx GraphModule The input Fx graph module modified node gm graph nodes isinstance node target torch _ops OpOverload node target = node target overloadpacket gm recompile convert_to_jit gm gm_args strip_overloads gm try torch jit script gm except Exception pass torch jit trace gm gm_args to_channels_last ten ten ten ndim = ten memory_format=torch channels_last microbenchmark operator args kwargs accuracy_checking repeats inductor_configs measure_nvfuser device gm gm_args = gen_gm_and_inputs operator args kwargs torch jit _builtins _register_builtin torch ops aten convolution_backward default aten convolution_backward compiled = gm config inductor_configs t = -time perf_counter compiled append compile_fx gm gm_args config_patches=config t += time perf_counter t print f slow compile inductor t f s config measure_nvfuser g = convert_to_jit gm gm_args cudagraphs_jit = cudagraphs_inner g gm_args copy_outputs=False copy_inputs=False compiled += cudagraphs_jit accuracy_checking repeats = medians = compute_speedups operator compiled gm_args repeats accuracy_checking device medians quantiles_thresholds = quantiles timings np quantile timings quantiles_thresholds tolist skip_operator operator nyi_strings = aten gather default nll_loss aten index aten scatter_ masked_fill_ Scalar any nyi_string str operator nyi_string nyi_strings maybe disable aten native_layer_norm default TODO - inputs cannot randomly initialized causes cyda failures print f Skipping operator input generator nyi True covered other non-compute operator heuristics operator == torch ops aten _unsafe_view default print f Skipping operator non compute operator True some inductor registered OpOverload some registered OpOverloadPacket op_impls = operator isinstance operator torch _ops OpOverload op_impls append operator overloadpacket TODO - skip benchmarking fallbacks some ops we have both lowerings fallbacks so its clear just operator what will lowered all op decompositions op lowerings op op_impls print f Skipping operator no inductor impl True convolution str operator True False click command click option -- suite help= suite load inps options timm huggingface torchbench default= torchbench click option -- op help= operator overload benchmark default= all click option -- dtype help= dtype benchmark default= float click option -- max-samples help= max samples per op default= click option -- accuracy-checking help= check accuracy default=False click option -- repeats help= how many times repeat perf measurement default= click option -- inductor-config multiple=True help= Custom inductor config options + join inductor_config_options click option -- measure-nvfuser -- no-measure-nvfuser help= default we only measure inductor default=False click option -- device help= cpu cuda default= cuda click option -- inp-file help= use custom input file instead suite default=None click option -- start-idx help= specify start index samples default= click option -- channels-last help= force inputs channels last is_flag=True default=False click option -- profile help= profile benchmark is_flag=True default=False benchmark suite op dtype max_samples accuracy_checking repeats inductor_config measure_nvfuser device inp_file start_idx channels_last profile warnings filterwarnings ignore module= torch jit _check torch set_float _matmul_precision high global profile_enabled inp_file None loader = OperatorInputsLoader inp_file assert suite timm huggingface torchbench f got suite suite == timm loader = OperatorInputsLoader get_timm_loader suite == huggingface loader = OperatorInputsLoader get_huggingface_loader loader = OperatorInputsLoader get_torchbench_loader assert dtype float float f got dtype inductor_configs = backend_names = inductor name inductor_config backend_names append name inductor_configs append inductor_config_options name measure_nvfuser backend_names append nvfuser compare = len backend_names == compare b = backend_names backend_names append f b output_fd = None output_csv = None op == all filename = f operatorbench_ suite _ dtype csv output_fd = open filename w output_csv = csv writer output_fd output_csv writerow operator f b b itertools product backend_names f x f th x quantiles_thresholds elapsed map abs format eager backend_names dtype = torch float dtype == float torch float op == all ops = loader get_all_ops ops = eval op max_samples = max_samples + start_idx profile_enabled = profile operator ops skip_operator operator continue start = time perf_counter inp_gen = loader get_inputs_for_operator operator dtype=dtype device=device timings = inputs_list = _ range min max_samples try inps = next inp_gen inputs_list append inps except StopIteration break profiler_context = torch profiler profile activities= torch profiler ProfilerActivity CPU torch profiler ProfilerActivity CUDA record_shapes=False profile_memory=False on_trace_ready=torch profiler tensorboard_trace_handler f log operator_ operator use_gzip=True profile_enabled nullcontext profiler_context i inps enumerate tqdm inputs_list start_idx desc=str operator inps None break args kwargs = inps channels_last args kwargs = tree_map_only torch Tensor to_channels_last args kwargs try maybe_record_function f iter_ i aten nvfuser inductor timings append microbenchmark operator args kwargs accuracy_checking repeats inductor_configs measure_nvfuser device except Exception e print f error operator input i type e __name__ e comment out line avoid blocking other tests raise e timings continue timings = np stack timings speedups = quantiles timings timings x x range timings shape compare speedups append quantiles timings timings assert len backend_names == len speedups row = f operator sys stdout write f operator backend low mid high zip backend_names speedups sys stdout write f backend = mid f x low f - high f row extend map f format low mid high elapsed = time perf_counter - start row append f elapsed f row extend map f format np mean timings axis= tolist sys stdout write f took elapsed f s\n sys stdout flush output_csv output_csv writerow row output_fd flush output_fd print f Wrote filename output_fd close __name__ == __main__ benchmark