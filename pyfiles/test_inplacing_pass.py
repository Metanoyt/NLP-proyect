Owner s module inductor torch torch _inductor config inductor_config functorch make_fx torch Tensor torch _dynamo utils ReinplaceCounters torch _higher_order_ops auto_functionalize auto_functionalized auto_functionalized_v torch _inductor fx_passes reinplace reinplace_inplaceable_ops_core torch _inductor test_case run_tests TestCase InductorTestCase torch testing _internal common_utils instantiate_parametrized_tests IS_LINUX parametrize subtest torch testing _internal inductor_utils GPU_TYPE HAS_GPU torch testing _internal logging_utils logs_to_string aten = torch ops aten const = torch tensor device = GPU_TYPE num_reinplacing_failures ReinplaceCounters get_total_missed miss_inplaced_bytes ReinplaceCounters get_total_missed_bytes torch library custom_op _reinplacing sin mutates_args= result sin x torch Tensor result torch Tensor - None result copy_ x sin torch library custom_op _reinplacing sin_cos mutates_args= out_sin out_cos sin_cos x torch Tensor out_sin torch Tensor out_cos torch Tensor - None out_sin copy_ x sin out_cos copy_ x cos HAS_GPU triton manual triton language tl manual triton jit sin_kernel in_ptr out_ptr n_elements BLOCK_SIZE tl constexpr pid = tl program_id axis= block_start = pid BLOCK_SIZE offsets = block_start + tl arange BLOCK_SIZE mask = offsets n_elements x = tl load in_ptr + offsets mask=mask output = tl sin x tl store out_ptr + offsets output mask=mask sin_triton x out n_elements = x numel sin_kernel n_elements x out n_elements BLOCK_SIZE= sin_triton x out torch library custom_op test_view boo mutates_args= x boo x torch Tensor - None x sin_ TestReinplacingPassCorrectness InductorTestCase setUp ReinplaceCounters clear super setUp _test f nf = torch compile f inp = torch randn device=device torch ones device=device dtype=torch int inp = inp clone inp clone assertEqual f inp nf inp assertEqual inp inp test_dont_modify_live f x y x = x cos x = x index_put y const x x _test f test_dont_modify_view_of_live f x y x = x cos x = aten alias x x = x index_put y const y = x + x cos y _test f test_dont_modify_input f x y x index_put y const _test f test_should_modify_inner f x y x = x cos x = x index_put y const x _test f test_should_modify_input f x y x = x index_put_ y const x _test f test_counters_functionalize_old ReinplaceCounters clear f x out = torch empty_like x _ new_out = auto_functionalized sin _opoverload x=x result=out y = out new_out new_out y x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph We shouldn t have been able reinplace ` out ` because used after auto_functionalized Note usually doesn t happen practice we re artificially creating example test counter IF THIS NUMBER GOES TO ZERO PLEASE FIND ANOTHER EXAMPLE assertEqual num_reinplacing_failures assertEqual miss_inplaced_bytes test_counters_functionalize_v ReinplaceCounters clear f x out = torch empty_like x _ new_out = auto_functionalized_v sin _opoverload x=x _result_base_index= _result_size= _result_stride= _result_storage_offset= _all_bases= out y = out new_out new_out y x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph We shouldn t have been able reinplace ` out ` because used after auto_functionalized Note usually doesn t happen practice we re artificially creating example test counter IF THIS NUMBER GOES TO ZERO PLEASE FIND ANOTHER EXAMPLE assertEqual num_reinplacing_failures get_not_inplaced_count graph counter = auto_functionalized_found = False node graph nodes node target == torch ops higher_order auto_functionalized node target == torch ops higher_order auto_functionalized_v auto_functionalized_found = True counter += len node meta only_clone_these_tensors assert auto_functionalized_found counter test_view_inplaced_functionalize_v f arg _ torch ops aten select int arg _ auto_functionalized = auto_functionalized_v torch ops test_view boo default _x_base_index= _x_size= _x_stride= _x_storage_offset= _all_bases= arg _ getitem_ = auto_functionalized torch ops aten copy_ default arg _ getitem_ x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph assertEqual get_not_inplaced_count gm graph introduce view another_view used ` after ` copy test_view_inplaced _functionalize_v f arg _ _select = torch ops aten select int arg _ another_view = arg _ auto_functionalized = auto_functionalized_v torch ops test_view boo default _x_base_index= _x_size= _x_stride= _x_storage_offset= _all_bases= arg _ getitem_ = auto_functionalized _copy = torch ops aten copy_ default arg _ getitem_ another_view x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph assertEqual get_not_inplaced_count gm graph introduce view another_view used ` before ` copy test_views_not_inplaced_functionalize_v f arg _ _select = torch ops aten select int arg _ another_view = arg _ auto_functionalized = auto_functionalized_v torch ops test_view boo default _x_base_index= _x_size= _x_stride= _x_storage_offset= _all_bases= arg _ getitem_ = auto_functionalized use_another_view = another_view _copy = torch ops aten copy_ default arg _ getitem_ use_another_view x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph assertEqual get_not_inplaced_count gm graph view over input without copy node inplace allowed test_views_not_inplaced _functionalize_v f arg _ _select = torch ops aten select int arg _ _another_view = arg _ auto_functionalized = auto_functionalized_v torch ops test_view boo default _x_base_index= _x_size= _x_stride= _x_storage_offset= _all_bases= arg _ _getitem_ = auto_functionalized x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph assertEqual get_not_inplaced_count gm graph no copy nodes view over local use another view test_views_not_inplaced _functionalize_v f arg _ = torch ones another_view = auto_functionalized = auto_functionalized_v torch ops test_view boo default _x_base_index= _x_size= _x_stride= _x_storage_offset= _all_bases= _getitem_ = auto_functionalized another_view x = torch randn device=device gm = make_fx f tracing_mode= fake x reinplace_inplaceable_ops_core gm graph assertEqual get_not_inplaced_count gm graph test_multi_output_intermediate requires_grad False True enable_v False True inductor_config patch enable_auto_functionalized_v enable_v ReinplaceCounters clear f x out = torch empty_like x out = torch empty_like x sin_cos x out out out out x x = torch randn device=device requires_grad=requires_grad res res _ = torch compile f x assertEqual res x sin assertEqual res x cos assertEqual num_reinplacing_failures test_multiple_mutations ReinplaceCounters clear f x out sin x out sin out out sin out out out x = torch randn device=device out = torch randn device=device result = torch compile f x out assertEqual result x sin sin sin assertEqual result out assertEqual num_reinplacing_failures test_multiple_intermediate ReinplaceCounters clear f x out = torch empty_like x sin x out sin out out sin out out out x = torch randn device=device result = torch compile f x assertEqual result x sin sin sin assertEqual num_reinplacing_failures test_lists_functionalize_v inductor_config patch enable_auto_functionalized_v True torch library custom_op mylib mutate_op mutates_args= y mutate_op y list Tensor - None y add_ y add_ torch compile fullgraph=True dynamic=False backend= inductor f b mutate_op b b x = torch tensor device=device log_stream ctx = logs_to_string torch _inductor compile_fx post_grad_graphs ctx torch compile f backend= inductor fullgraph=True x post_grad_graphs = \n join log_stream getvalue strip split \n strip We can inplace base y no clones emitted assertEqual num_reinplacing_failures assertEqual miss_inplaced_bytes assertEqual post_grad_graphs count aten clone test_lists_old_functionalize inductor_config patch enable_auto_functionalized_v False torch library custom_op mylib mutate_op mutates_args= y mutate_op y list Tensor - None y add_ y add_ torch compile fullgraph=True dynamic=False backend= inductor f b mutate_op b b x = torch tensor device=device log_stream ctx = logs_to_string torch _inductor compile_fx post_grad_graphs ctx torch compile f backend= inductor fullgraph=True x post_grad_graphs = \n join log_stream getvalue strip split \n strip Can t reinplace views yet entire list failing reinplace assertEqual num_reinplacing_failures assertEqual miss_inplaced_bytes Both list inputs failed reinplace So we should have emitted clones them assertEqual post_grad_graphs count aten clone test_generalized_scatter This integration test reinplacing pass fn x_ = torch ones c = torch ones copy_ c d = clone e = torch ops aten as_strided default d f = e clone g = torch zeros e copy_ g h = torch zeros h copy_ f add_ = d + h add_ x = torch randn expected = fn x result = torch compile fn fullgraph=True backend= inductor x assertEqual result expected parametrize factory_op subtest torch ones_like name= ones_like subtest torch empty_like name= empty_like parametrize sin_op subtest sin name= sin_op subtest sin_triton name= sin_triton test_partitioner_recomputes_factory factory_op sin_op MySin torch autograd Function staticmethod forward ctx x out = factory_op x sin_op x out ctx save_for_backward out out staticmethod backward ctx grad saved = ctx saved_tensors out = factory_op grad sin_op saved out out torch compile backend= inductor f x MySin apply x x = torch randn requires_grad=True device=device f x assertEqual num_reinplacing_failures instantiate_parametrized_tests TestReinplacingPassCorrectness __name__ == __main__ IS_LINUX HAS_GPU run_tests needs= filelock