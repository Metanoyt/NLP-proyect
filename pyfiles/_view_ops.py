mypy allow-untyped-defs Copyright c Meta Platforms Inc affiliates collections abc Callable Iterable Sequence dataclasses dataclass typing cast Optional Union torch torch Tensor torch _prims_common DimsType torch distributed tensor _dtensor_spec DTensorSpec torch distributed tensor _op_schema OpSchema OpSpec OpStrategy RuntimeSchemaInfo StrategyType torch distributed tensor _ops utils generate_redistribute_costs normalize_dim normalize_dims prod register_op_strategy torch distributed tensor placement_types _StridedShard Placement Replicate Shard aten = torch ops aten Shape = tuple int dataclass DimSpec Specifies how output dimension maps input dimension inputs - Iterable DimSpec Rules map each dimension output dimensions input tensor DimMap = tuple DimSpec dataclass Singleton DimSpec Output dimension singleton dataclass InputDim DimSpec Output dimension maps directly input dimension input_dim int dataclass Broadcast DimSpec Output broadcast singleton input dimension dim DimSpec dim_size int classmethod new cls dim DimSpec dim_size int - DimSpec Broadcast dim dim_size inputs - Iterable DimSpec dim dataclass NewDim DimSpec This new dimension created op size int classmethod new cls size int - DimSpec Singleton size == NewDim size dataclass Repeat DimSpec Output dimension input dimension repeated n-times input_dim DimSpec times int classmethod new cls dim DimSpec times int - DimSpec times == dim isinstance dim Singleton repeating singleton same broadcasting Broadcast dim times Repeat dim times inputs - Iterable DimSpec input_dim dataclass Flatten DimSpec Flatten set input dimensions ensuring right-most adjacent elements remain adjacent output input_dims Sequence DimSpec classmethod new cls dims Sequence DimSpec - DimSpec len dims == flattening scalar leads singleton Singleton len dims == flattening single dimension no-op dims Flatten dims inputs - Iterable DimSpec input_dims dataclass Split DimSpec This dimension member decomposition input dim Note input_dim itself could Flattened set input dims input_dim DimSpec group_shape Shape split_id int classmethod new cls dim DimSpec group_shape tuple int idx int - DimSpec len group_shape raise AssertionError f Expected group_shape length got len group_shape len group_shape == really group just input dim back idx == raise AssertionError f Expected idx == got idx dim group_shape idx == Singleton remove singletons group group_mapping = new_index shape old_index group_mapping = list enumerate s i i s enumerate group_shape s = new_group_shape = tuple m m group_mapping new_idx = next filter lambda x x == idx group_mapping Split dim new_group_shape new_idx inputs - Iterable DimSpec input_dim dim_pad_left ndim int min_dims int - DimMap Singleton max min_dims - ndim + tuple InputDim i i range ndim dim_atleast_ d ndim int - DimMap ndim == Singleton Singleton Singleton ndim == Singleton InputDim Singleton ndim == InputDim InputDim Singleton tuple InputDim i i range ndim expand input_shape Shape shape Shape - DimMap Implement broadcast multiple dimensions len shape = len input_shape raise AssertionError f Expected len shape = len input_shape got len shape len input_shape create padded input dimensions padded_input = dim_pad_left len input_shape len shape check input shapes compatible mapping = p desired_s zip padded_input shape isinstance p Singleton actual_s = desired_s = raise AssertionError f Expected desired_s = got desired_s isinstance p InputDim raise AssertionError f DimSpec supported expand p actual_s = input_shape p input_dim actual_s == desired_s == - desired_s == actual_s raise AssertionError f Expected actual_s == desired_s == - f desired_s == actual_s got actual_s= actual_s desired_s= desired_s mapping append p desired_s - desired_s == actual_s Broadcast new p desired_s tuple mapping normalize_sizes sizes Union Shape tuple Shape - Shape isinstance sizes int cast Shape sizes len sizes == sizes raise RuntimeError Size must int tuple dim_flatten ndim int start_dim= end_dim=- - DimMap ndim == Singleton ndim == InputDim only flattening dims start_dim end_dim inclusive other dims passed through end_dim end_dim += ndim results list DimSpec = InputDim i i range start_dim results append Flatten new tuple InputDim i i range start_dim end_dim + results extend InputDim i i range end_dim + ndim tuple results dim_movedim ndim int input DimsType destination DimsType - DimMap input = normalize_dims input ndim destination = normalize_dims destination ndim len input == len destination raise AssertionError f Expected len input == len destination got len input = len destination input_set = set input len input_set == len input raise AssertionError Found repeated input dims len set destination == len destination raise AssertionError Found repeated output dims max input ndim raise AssertionError f Expected max input ndim got max input = ndim max destination ndim raise AssertionError f Expected max destination ndim got max destination = ndim dest = - ndim i d zip input destination dest d = i unused_inputs_iter = iter i i range ndim i input_set i range ndim dest i == - dest i = next unused_inputs_iter tuple InputDim i i dest dim_repeat ndim int sizes Shape - DimMap sizes = normalize_sizes sizes len sizes = ndim raise AssertionError f Number dimensions repeat dims sizes can smaller than number dimensions tensor ndim pad = len sizes - ndim tuple Repeat new Singleton s s sizes pad + tuple Repeat new InputDim i s i s enumerate sizes pad infer_size total_size int sizes Shape - Shape One dimension input view may - Infer size dimension given total_size infers = i i s enumerate sizes s == - size = prod sizes len infers = raise AssertionError can only infer one size infers size = -size missing_size = total_size size total_size size == raise AssertionError f size inferred - integral sizes should have total_size elements tuple s s = - missing_size s sizes size == total_size raise AssertionError f sizes do match total_size vs size sizes view_groups from_size Shape to_size Shape - DimMap Decompose reshape operation into forwarding flattening splitting dimensions each output dimension A view reshape operation can decomposed into set types smaller operations Forward dimension input output Flatten set dimensions into single dimension Split one dimension into multiple dimensions view_groups identifies these operations returns each output dimension what operation performed input dimension For example view_groups - InputDim Flatten InputDim InputDim - output dimension maps input dimension - output dimension maps flattened input dimensions view_groups - Split Flatten InputDim InputDim Split Flatten InputDim InputDim - above input flattened into single dimension then split into two separate dimensions different sizes input from_nelem = prod from_size to_size = infer_size from_nelem normalize_sizes to_size from_nelem == prod to_size raise AssertionError Total view shape does add up from_idx = to_idx = from_len = len from_size to_len = len to_size result_pp = while from_idx from_len to_idx to_len from_group_dim to_group_shape = from_idx = from_len f = f = from_size from_idx from_group_dim append from_idx from_idx += to_idx = to_len t = t = to_size to_idx to_group_shape append t to_idx += any groups singleton great we need backtrack though f == t = produces to_idx -= to_group_shape = f = t == produces from_idx -= from_group_dim = produces while f = t f t nf = from_size from_idx from_group_dim append from_idx from_idx += f = nf nt = to_size to_idx to_group_shape append nt to_idx += t = nt len to_group_shape flattened = Flatten new tuple InputDim fi fi from_group_dim from_size fi = result_pp += Split new flattened tuple to_group_shape i i range len to_group_shape tuple result_pp dim_tile ndim int dims tuple int - DimMap len dims ndim dims = ndim - len dims + dims dim_repeat ndim dims dim_transpose ndim int dim int dim int - DimMap dim = normalize_dim dim ndim dim = normalize_dim dim ndim dim ndim raise AssertionError f Expected dim ndim got dim = ndim dim ndim raise AssertionError f Expected dim ndim got dim = ndim dimmap = InputDim i i range ndim swapdim = dimmap dim dimmap dim = dimmap dim dimmap dim = swapdim tuple dimmap dim_squeeze shape Shape dim Optional int = None - DimMap FIXME wrong when dim=None one dimensions equals size mesh For example squeeze DTensor tensor Shard could end up squeeze tensor we have devices would lead removal dimension actually singleton tuple InputDim i i s enumerate shape s dim None i = normalize_dim dim len shape dim_unsqueeze ndim int dim int - DimMap dims = tuple InputDim i i range ndim dim dim += ndim + dims dim + Singleton + dims dim dim_view_as_real shape Shape - DimMap ndim = len shape results list DimSpec = InputDim i i range ndim - each complex number split into two real numbers resulting one more dimension size results append Split InputDim ndim - shape - results append Split InputDim ndim - shape - tuple results dim_reduction ndim int dim_or_dims Optional DimsType keepdim bool - DimMap General fallback reduction ops where Partial does apply This will cause incoming tensor replicated reducing dimensions dim_or_dims None dim_or_dims = tuple range ndim isinstance dim_or_dims int dim_or_dims = dim_or_dims dim_or_dims = tuple d d = d + ndim d dim_or_dims tuple InputDim i i dim_or_dims Singleton i range ndim i dim_or_dims keepdim dim_maps dict Callable torch Tensor Callable DimMap = torch atleast_ d lambda x dim_pad_left x ndim torch atleast_ d lambda x dim_pad_left x ndim torch atleast_ d lambda x dim_atleast_ d x ndim torch broadcast_to lambda input shape expand input shape shape Tensor expand lambda sizes expand shape normalize_sizes sizes torch flatten lambda tensor dim_flatten tensor ndim torch movedim lambda input source destination dim_movedim input ndim source destination torch permute lambda input dims tuple InputDim i i normalize_dims dims input ndim torch ravel lambda tensor dim_flatten tensor ndim Tensor repeat lambda sizes dim_repeat ndim sizes torch reshape lambda input shape view_groups input shape shape torch squeeze lambda input dim=None dim_squeeze input shape dim torch tile lambda input dims dim_tile input ndim dims torch transpose lambda input dim dim dim_transpose input ndim dim dim torch unsqueeze lambda input dim dim_unsqueeze input ndim dim Tensor view lambda input shape view_groups input shape shape torch view_as_complex lambda input dim_flatten input ndim input ndim - torch view_as_real lambda input dim_view_as_real input shape propagate_shape_and_sharding input_src_placements Sequence Placement global_input_shape Shape rule DimMap mesh_sizes Shape strict_view bool = False - tuple Sequence Placement Sequence Placement Determine input target sharding output sharding based given global tensor shape input source sharding Sharding propagation follows mapped dimensions - An output dimension maps directly input dimension sharded equally - An output dimension flattened set input dimensions can only sharded only leftmost flattened dimension sharded - An output dimension split input dimension can only sharded leftmost split size divisible mesh dimension len input_src_placements == len mesh_sizes raise AssertionError f input_src_placements = mesh_sizes each input dim each mesh dim provides list possible shardable dimensions mesh_ndim = len mesh_sizes shardable_dims dict int list bool = case input dimension disappears e g collapsing reduction we cannot shard dimension we need replication fall-back rule seen_input_dims set int = set collect_used_inputs cmd DimSpec - None isinstance cmd InputDim seen_input_dims add cmd input_dim inp cmd inputs collect_used_inputs inp cmd rule collect_used_inputs cmd dim range len global_input_shape shardable_dims dim = dim seen_input_dims mesh_ndim maybe_get_shard_mesh_dim_and_placement input_dim InputDim - tuple Optional int Optional Shard input_dim sharded mesh_dim shard placement i placement enumerate input_src_placements isinstance placement Shard placement dim == input_dim input_dim i placement None None NOTE This function has three responsibilities determine theoretically output dimension can sharded i e fill shardable_dims map determine theoretically corresponding input dimension shard via value throw error when strict_view enabled we cannot shard output dimension doesn t require info whether current input sharded requires info decide whether we can error out Maybe we can refactor make function purely theoretical get_in_dim_to_shard cmd DimSpec - Optional InputDim isinstance cmd InputDim cmd isinstance cmd Flatten i dim enumerate cmd input_dims so far all Flatten always composed InputDims revisit needed isinstance dim InputDim raise AssertionError f Expected InputDim got type dim can_shard_dim = True shard_mesh_dim shard_placement = maybe_get_shard_mesh_dim_and_placement dim input_sharded = shard_mesh_dim None i can_shard_dim = False strict_view input_sharded raise RuntimeError f Attempted flatten multiple dimensions dimension dim input_dim being sharded It cannot performed without redistribution which disallowed current operator input_sharded shard_placement None shard_mesh_dim None raise AssertionError Expected shard_placement shard_mesh_dim None tensor_dim_size = global_input_shape shard_placement dim mesh_dim_size = mesh_sizes shard_mesh_dim tensor_dim_size mesh_dim_size = can_shard_dim = False strict_view raise RuntimeError f Attempted flatten unevenly sharded dimension i which would require resharding input Please explicitly redistribute tensor instead shardable_dims dim input_dim = can_shard_dim mesh_ndim isinstance cmd input_dims InputDim raise AssertionError f Expected InputDim got type cmd input_dims cmd input_dims isinstance cmd Split in_dim = get_in_dim_to_shard cmd input_dim out_size = cmd group_shape cmd split_id cmd split_id == in_dim None we need check input dimension divisible size submesh we re sharding NOTE would possible shard same input dimension more than one mesh dimension In case dimension needs divisible product mesh sizes In order keep problem more tractable we will consider double resharding suggestion e g Shard Shard we will allow s input s compatible dimension shardable each individual mesh dim shardable_dims in_dim input_dim = out_size mesh_dim_size == mesh_dim_size mesh_sizes shard_mesh_dim _ = maybe_get_shard_mesh_dim_and_placement in_dim strict_view shard_mesh_dim None shardable_dims in_dim input_dim shard_mesh_dim raise RuntimeError f Attempted split sharded dimension in_dim input_dim into multiple subdimensions It cannot performed without redistribution which disallowed current operator here we special case things like Shard Shard submesh_size = size shard zip mesh_sizes input_src_placements isinstance shard Shard shard dim == in_dim submesh_size = size out_size submesh_size == raise AssertionError f Resulting dimension size out_size divisible its mesh dimension submesh_size we will only shard our first component split in_dim cmd split_id == None isinstance cmd Repeat in_dim = get_in_dim_to_shard cmd input_dim in_dim None shardable_dims in_dim input_dim = False mesh_ndim None None each output dim find corresponding input dim terms sharding prop shard_dim_map = dim cmd enumerate rule in_dim = get_in_dim_to_shard cmd in_dim None shard_dim_map in_dim input_dim = dim input_tgt_placements = Replicate isinstance p Shard shardable_dims p dim mesh_dim p mesh_dim p enumerate input_src_placements _rewrite_shard_dim p Shard Rewrite shard dim corresponding tensor dim output For ` ` _StridedShard ` ` we can safely keep placement type ` ` split_factor ` ` unchanged only rewrite ` ` dim ` ` because ` ` _StridedShard ` ` has no impact sharding i e how tensor partitioned compared ` ` Shard ` ` It only changes how shards permute across devices ` ` view ` ` op DTensor strictly forbids shard redistribution which means ` ` view ` ` may cause shard permutation across devices should rejected This enforced today s sharding prop ` ` view ` ` Since DTensor ` ` view ` ` won t introduce any redistribution s certain ` ` placements ` ` won t change except inner ` ` dim ` ` attribute ` ` Shard ` ` ` ` _StridedShard ` ` isinstance p _StridedShard _StridedShard shard_dim_map p dim split_factor=p split_factor Shard shard_dim_map p dim output_placements = _rewrite_shard_dim p isinstance p Shard p p input_tgt_placements input_tgt_placements output_placements register_op_strategy_map aten_op_overload torch _ops OpOverload local_op_name Callable torch Tensor schema_info Optional RuntimeSchemaInfo = None strict_view bool = False - None Helper registers strategies view-like operators follow pattern define way input dims split combined form output dims dim_maps register strategy op schema uses dim_map sharding prop rule strict_view True we will error out view-operation would require resharding input Currently should set true any view ops We could diverge behavior reshape ops which could perform redistribute implicitly dim_map Callable DimMap = dim_maps local_op_name register_op_strategy aten_op_overload schema_info=schema_info reshape_strategy op_schema OpSchema - StrategyType rules = dim_map op_schema args_schema op_schema kwargs_schema input_strategy = cast OpStrategy op_schema args_schema mesh = op_schema get_mesh_from_args validate=False global_in_shape = input_strategy shape global_in_shape None raise AssertionError Shape required output_strategy = OpStrategy input_placement_strategy input_strategy strategies input_src_spec = input_placement_strategy output_spec input_tgt_placements output_placements = propagate_shape_and_sharding input_src_spec placements tuple global_in_shape rules mesh shape strict_view TODO optimize we shouldn t simply blindly replicate unshardable dims FIXME can wrong situations where we have Shard Shard input_tgt_spec = DTensorSpec placements=tuple input_tgt_placements mesh=mesh tensor_meta=input_src_spec tensor_meta redistribute_costs list list float = generate_redistribute_costs input_strategy input_tgt_spec output_spec = DTensorSpec mesh=mesh placements=tuple output_placements output_strategy strategies append OpSpec output_specs=output_spec input_specs= input_tgt_spec redistribute_cost=redistribute_costs output_strategy register_op_strategy_map aten squeeze default torch squeeze register_op_strategy_map aten squeeze_ dim torch squeeze schema_info=RuntimeSchemaInfo register_op_strategy_map aten squeeze dim torch squeeze schema_info=RuntimeSchemaInfo register_op_strategy_map aten view default Tensor view schema_info=RuntimeSchemaInfo strict_view=True register_op_strategy_map aten reshape default torch reshape schema_info=RuntimeSchemaInfo register_op_strategy_map aten _unsafe_view default Tensor view schema_info=RuntimeSchemaInfo strict_view=True register_op_strategy_map aten unsqueeze default torch unsqueeze schema_info=RuntimeSchemaInfo register_op_strategy_map aten expand default Tensor expand schema_info=RuntimeSchemaInfo register_op_strategy_map aten permute default torch permute schema_info=RuntimeSchemaInfo register_op_strategy_map aten repeat default Tensor repeat schema_info=RuntimeSchemaInfo register_op_strategy_map aten transpose int torch transpose schema_info=RuntimeSchemaInfo register_op_strategy_map aten view_as_complex default torch view_as_complex register_op_strategy_map aten view_as_real default torch view_as_real