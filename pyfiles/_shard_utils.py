mypy allow-untyped-defs copy itertools math typing Optional torch torch distributed dist torch _utils _get_device_module torch distributed distributed_c d torch distributed _shard sharded_tensor Shard ShardedTensor ShardedTensorMetadata TensorProperties torch distributed _shard sharding_spec ShardMetadata torch distributed tensor DeviceMesh DTensor Replicate Shard DShard _get_remote_device_str rank device_type num_devices_per_node device_type lower == cpu f rank rank device_type device_type lower == hpu f rank rank device_type _get_device_module device_type current_device f rank rank device_type rank num_devices_per_node _create_chunk_sharded_tensor tensor torch Tensor rank int world_size int num_devices_per_node int pg dist ProcessGroup device Optional torch device = None - ShardedTensor Shard tensor chunks along first dimension The local rank will gets its corresponding chunk local shard create ShardedTensor chunks = tensor chunk world_size dim= len chunks rank local_shard = chunks rank clone offsets = _ tensor size offsets = math ceil tensor size world_size rank local_shards = Shard from_tensor_and_offsets local_shard offsets rank local_shards = Create ShardedTensor without invoking communication chunk_sizes = list chunk size chunk chunks dim _offsets = + list itertools accumulate chunk_size chunk_size chunk_sizes - offsets = len chunk_sizes - chunk_offsets = d + offsets d dim _offsets device_type = distributed_c d _get_pg_default_device pg type device None device type placements = _get_remote_device_str dist get_global_rank pg r device_type num_devices_per_node r range len chunk_sizes len chunk_sizes = len chunk_offsets len chunk_sizes = len placements raise AssertionError f Expected chunk_sizes chunk_offsets placements have same length f got len chunk_sizes len chunk_offsets len placements shard_metadata = ShardMetadata offset size placement offset size placement zip chunk_offsets chunk_sizes placements sharded_tensor_metadata = ShardedTensorMetadata shards_metadata=shard_metadata size=tensor size tensor_properties=TensorProperties dtype=tensor dtype layout=tensor layout requires_grad=False memory_format=torch contiguous_format pin_memory=tensor is_pinned ShardedTensor _init_from_local_shards_and_global_metadata local_shards sharded_tensor_metadata=sharded_tensor_metadata process_group=pg _create_chunk_dtensor tensor torch Tensor rank int device_mesh DeviceMesh - DTensor Shard tensor chunks along first dimension The local rank will gets its corresponding chunk local tensor create DTensor We need explicitly call detach new tensor detached current graph tensor = tensor detach clone FSDP placements Shard HSDP placements Replicate Shard replicate_placements = Replicate _ range device_mesh ndim shard_placements = Replicate _ range device_mesh ndim shard_placements - = DShard type ignore call-overload DTensor from_local tensor device_mesh replicate_placements run_check=False redistribute placements=shard_placements _all_gather_dtensor tensor DTensor root_mesh Optional DeviceMesh - torch Tensor All gather DTensor its sharded dimension local tensor root_mesh = tensor device_mesh raise AssertionError The device mesh tensor should root mesh placements = list copy deepcopy tensor placements FSDP placements Shard - Replicate HSDP placements Replicate Shard - Replicate Replicate placements - = Replicate tensor = tensor redistribute device_mesh=tensor device_mesh placements=placements tensor to_local