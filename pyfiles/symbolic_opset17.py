mypy allow-untyped-defs mypy disable-error-code=arg-type This file exports ONNX ops opset Note ONNX Operators added updated opset ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ https github com onnx onnx blob main docs Changelog md#version- -of-the-default-onnx-operator-set New operators BlackmanWindow DFT HammingWindow HannWindow LayerNormalization MelWeightMatrix STFT SequenceMap functools collections abc Sequence typing Optional torch torch _C torch onnx errors torch onnx _internal torchscript_exporter _type_utils jit_utils registration symbolic_helper EDITING THIS FILE READ THIS FIRST see Note Edit Symbolic Files README md __all__ = layer_norm stft quantized_layer_norm _onnx_symbolic = functools partial registration onnx_symbolic opset= _onnx_symbolic aten layer_norm symbolic_helper parse_args v v v f none layer_norm g jit_utils GraphContext input _C Value normalized_shape Sequence int weight _C Value bias _C Value eps float cudnn_enable bool normalized_shape input shape expected input size axis The first normalization dimension layer_norm normalizes last D dimensions where D size normalized_shape axis = -len normalized_shape scalar_type = _type_utils JitScalarType from_value input _type_utils JitScalarType FLOAT dtype = scalar_type dtype symbolic_helper _is_none weight weight_value = torch ones normalized_shape dtype=dtype weight = g op Constant value_t=weight_value symbolic_helper _is_none bias bias_value = torch zeros normalized_shape dtype=dtype bias = g op Constant value_t=bias_value g op LayerNormalization input weight bias epsilon_f=eps axis_i=axis _onnx_symbolic quantized layer_norm quantized_layer_norm g jit_utils GraphContext x normalized_shape weight bias eps op_scale op_zero_point x _ _ _ = symbolic_helper dequantize_helper g x output = layer_norm g x normalized_shape weight bias eps False symbolic_helper quantize_helper g output op_scale op_zero_point _compute_edge_sizes n_fft window_size Helper function compute sizes edges left right given window centered within FFT size left = n_fft - window_size right = n_fft - left - window_size left right _onnx_symbolic aten stft symbolic_helper parse_args v i i i v b b b b stft g jit_utils GraphContext input _C Value n_fft int hop_length Optional int = None win_length Optional int = None window Optional _C Value = None normalized bool = False onesided Optional bool = True return_complex Optional bool = False align_to_window Optional bool = None - _C Value Associates ` torch stft ` ` STFT ` ONNX operator Note torch stft calls _VF stft without centering padding options Hence function does contain these two arguments See torch stft source code more info Args g Graph write ONNX representation into input Input tensor transformation n_fft FFT size hop_length Size hop Defaults ` floot n_fft ` win_length Size analysis window Defaults ` n_fft ` window Analysis window Defaults window all ones normalized Whether normalized STFT onesided Whether only half + results given symmetry STFT return_complex Whether complex value Note Must ` False ` ` None ` Returns op Operator torch stft associated STFT ONNX Checks return_complex raise errors SymbolicValueError msg= STFT does currently support complex types value=input align_to_window None raise errors SymbolicValueError msg= STFT does currently support align_to_window option value=input TODO add compatibility align_to_window option Get STFT sizes frame_step_value = hop_length hop_length None n_fft frame_step_const = g op Constant value_t=torch tensor frame_step_value dtype=torch int frame_length_const = g op Constant value_t=torch tensor n_fft dtype=torch int Pre-process input needed signal = input signal_rank = symbolic_helper _get_tensor_rank signal signal_rank == Add batch dimension signal = g op Unsqueeze signal g op Constant value_t=torch tensor dtype=torch int signal_rank None signal_rank raise errors SymbolicValueError msg= STFT can only take inputs signal batch signal dimensions f Current rank signal signal_rank please reduce value=input Get window make sure s same size ` win_length ` ` n_fft ` pyrefly ignore bad-argument-type n_win = symbolic_helper _get_tensor_dim_size window dim= n_win None win_length_default = win_length win_length n_fft assert n_win == win_length_default Analysis window size must equal ` win_length ` ` n_fft ` f Please set ` win_length ` ` n_fft ` match ` window ` size n_win Center window around zeros needed required ONNX s STFT n_win n_fft left right = _compute_edge_sizes n_fft n_win left_win = g op Constant value_t=torch zeros left right_win = g op Constant value_t=torch zeros right pyrefly ignore bad-argument-type window = g op Concat left_win window right_win axis_i= Create window needed symbolic_helper _is_none window win_length win_length n_fft raise errors SymbolicValueError msg= The analysis window can t longer than size FFT f Please set ` win_length ` win_length ` n_fft ` n_fft less value=input Center window needed left right = _compute_edge_sizes n_fft win_length torch_window = torch hstack torch zeros left torch ones win_length torch zeros right Rectangle window torch_window = torch ones n_fft assert torch_window shape == n_fft window = g op Constant value_t=torch_window window = g op Cast pyrefly ignore bad-argument-type window to_i=_type_utils JitScalarType from_value signal onnx_type Run STFT result = g op STFT signal frame_step_const window frame_length_const onesided_i= onesided None onesided Transpose mimic torch stft s behavior result = g op Transpose result perm_i= Remove batch dimension needed signal_rank == result = g op Squeeze result g op Constant value_t=torch tensor dtype=torch int Normalize needed normalized sqrt_nfft = torch sqrt torch tensor n_fft dtype=signal type dtype result = g op Div result g op Constant value_t=sqrt_nfft result