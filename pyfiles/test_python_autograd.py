Owner s module dynamo typing Callable NamedTuple Optional torch torch _dynamo torch _dynamo test_case run_tests TestCase torch _dynamo testing CompileCounter same This example pure-python version autograd implemented zdevito It represents rather challenging test case TorchDynamo push limits what can do _name int = fresh_name - str create new unique name variable v v v global _name r = f v _name _name += r Variable __init__ value torch Tensor name Optional str = None value = value name = name fresh_name We need start some tensors whose values computed inside autograd This function constructs leaf nodes staticmethod constant value torch Tensor name Optional str = None Variable value name __repr__ repr value This performs pointwise multiplication Variable tracking gradients __mul__ rhs Variable - Variable defined later notebook operator_mul rhs __add__ rhs Variable - Variable operator_add rhs sum name Optional str = None - Variable operator_sum name expand sizes list int - Variable operator_expand sizes TapeEntry NamedTuple names inputs original computation inputs list str names outputs original computation outputs list str apply chain rule propagate Callable list Variable list Variable gradient_tape list TapeEntry = reset_tape gradient_tape clear global _name _name = grad L desired_results list Variable - list Variable map holds dL dX all values X dL_d dict str Variable = It starts initializing seed dL dL which dL_d L name = Variable torch ones print f d L name ------------------------ look up dL_dentries If variable never used compute loss we consider its gradient None see note below about zeros more information gather_grad entries list str dL_d get entry entry entries propagate gradient information backward entry reversed gradient_tape dL_doutputs = gather_grad entry outputs all dL_doutput None dL_doutput dL_doutputs optimize case where some gradient pathways zero See The note below more details continue perform chain rule propagation specific each compute dL_dinputs = entry propagate dL_doutputs Accumulate gradient produced each input Each use variable produces some gradient dL_dinput use The multivariate chain rule tells us safe sum all contributions together input dL_dinput zip entry inputs dL_dinputs input dL_d dL_d input = dL_dinput dL_d input value += dL_dinput value print some information understand values each intermediate name value dL_d items print f d L name _d name = value name print f ------------------------ gather_grad desired name desired desired_results operator_mul Variable rhs Variable - Variable isinstance rhs float rhs == peephole optimization define forward r = Variable value rhs value print f r name = name rhs name record what inputs outputs op inputs = name rhs name outputs = r name define backprop propagate dL_doutputs list Variable dL_dr = dL_doutputs dr_dself = rhs partial derivative r = rhs dr_drhs = partial derivative r = rhs chain rule propagation outputs inputs multiply dL_dself = dL_dr dr_dself dL_drhs = dL_dr dr_drhs dL_dinputs = dL_dself dL_drhs dL_dinputs finally we record compute we did tape gradient_tape append TapeEntry inputs=inputs outputs=outputs propagate=propagate r operator_add Variable rhs Variable - Variable Add follows similar pattern Mul doesn t end up capturing any variables r = Variable value + rhs value print f r name = name + rhs name propagate dL_doutputs list Variable dL_dr = dL_doutputs dr_dself = dr_drhs = dL_dself = dL_dr dr_dself dL_drhs = dL_dr dr_drhs dL_dself dL_drhs gradient_tape append TapeEntry inputs= name rhs name outputs= r name propagate=propagate r operator_sum Variable name Optional str - Variable r = Variable torch sum value name=name print f r name = name sum propagate dL_doutputs list Variable dL_dr = dL_doutputs size = value size dL_dr expand size gradient_tape append TapeEntry inputs= name outputs= r name propagate=propagate r operator_expand Variable sizes list int - Variable assert value dim == only works scalars r = Variable value expand sizes print f r name = name expand sizes propagate dL_doutputs list Variable dL_dr = dL_doutputs dL_dr sum gradient_tape append TapeEntry inputs= name outputs= r name propagate=propagate r simple b t = + b t b TestPythonAutograd TestCase _common fn expected_ops args = torch randn torch randn args = torch randn torch randn cnt = CompileCounter fn_dynamo = torch _dynamo optimize_assert cnt fn reset_tape res = fn_dynamo args reset_tape res = fn_dynamo args reset_tape assertTrue same res fn args reset_tape assertTrue same res fn args reset_tape assertEqual cnt frame_count assertEqual cnt op_count expected_ops test_forwards fn b = Variable constant name= b = Variable constant b name= b loss = simple b sum loss _common fn test_forwards fn b reset_tape = Variable constant name= b = Variable constant b name= b loss = simple b sum reset_tape loss _common fn test_backwards fn b = Variable constant name= b = Variable constant b name= b loss = simple b sum grad loss b _common fn test_backwards fn b reset_tape = Variable constant name= b = Variable constant b name= b loss = simple b sum res = grad loss b reset_tape res _common fn test_split v = Variable constant torch randn name= v = Variable constant torch randn name= b cnt = CompileCounter forward b simple b sum reset_tape loss = forward v v grad = grad loss v v reset_tape opt_forward = torch _dynamo optimize_assert cnt forward opt_grad = torch _dynamo optimize_assert cnt grad loss = opt_forward v v force two frames grad = opt_grad loss v v assertTrue same loss loss assertTrue same grad grad assertEqual cnt frame_count assertEqual cnt op_count __name__ == __main__ run_tests