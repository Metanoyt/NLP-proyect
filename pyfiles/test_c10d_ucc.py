Owner s oncall distributed copy logging math operator os random sys tempfile functools reduce torch torch distributed c d c d is_available c d is_ucc_available print c d UCC available skipping tests file=sys stderr sys exit test_c d_common test_c d_common gpus_for_rank ModuleForDdpCommHook SparseGradientModule Task torch distributed dist torch nn functional F torch testing _internal common_utils common torch nn torch nn parallel DistributedDataParallel torch testing _internal common_distributed MultiProcessTestCase requires_ucc skip_if_lt_x_gpu verify_ddp_error_logged torch testing _internal common_utils retry_on_connect_failures run_tests skip_but_pass_in_sandcastle TestCase simple_reduce_tests rank world_size tests = c d ReduceOp SUM torch tensor rank + torch tensor float world_size world_size + c d ReduceOp PRODUCT torch tensor rank + torch tensor float math factorial world_size c d ReduceOp MIN torch tensor rank + torch tensor c d ReduceOp MAX torch tensor rank + torch tensor world_size Generate tests BAND The bit set changes every iteration check output changes accordingly i range vin = rank &#124; i vout = i tests append c d ReduceOp BAND torch tensor vin dtype=torch int torch tensor vout dtype=torch int Generate tests BOR These emulate larger world size per iteration having every rank contribute multiple values pre-OR ed i range vin = reduce operator or_ rank i + j j range i vout = reduce operator or_ range world_size i tests append c d ReduceOp BOR torch tensor vin dtype=torch int torch tensor vout dtype=torch int Generate tests XOR These emulate larger world size per iteration having every rank contribute multiple values pre-XOR ed i range vin = reduce operator xor rank i + j j range i vout = reduce operator xor range world_size i tests append c d ReduceOp BXOR torch tensor vin dtype=torch int torch tensor vout dtype=torch int tests RendezvousEnvTest TestCase requires_ucc retry_on_connect_failures test_logging_init os environ WORLD_SIZE = os environ MASTER_ADDR = os environ MASTER_PORT = str common find_free_port os environ RANK = previous_handlers = logging root handlers c d init_process_group backend= ucc init_method= env current_handlers = logging root handlers assertEqual len previous_handlers len current_handlers current previous zip current_handlers previous_handlers assertEqual current previous c d destroy_process_group TimeoutTest test_c d_common AbstractTimeoutTest TestCase requires_ucc retry_on_connect_failures test_default_store_timeout_ucc _test_default_store_timeout ucc ProcessGroupUCCTest MultiProcessTestCase _create_process_group_ucc store = c d FileStore file_name world_size c d ProcessGroupUCC store rank world_size setUp super setUp _spawn_processes tearDown super tearDown try os remove file_name except OSError pass requires_ucc test_empty_tensors pg = _create_process_group_ucc xs = torch FloatTensor fut = pg broadcast xs get_future fut wait output = fut value assertEqual output numel assertEqual xs output exact_dtype=False TODO add error check testing _test_broadcast_basics fn pg = _create_process_group_ucc broadcast xs rootRank rootTensor opts = c d BroadcastOptions opts rootRank = rootRank opts rootTensor = rootTensor fut = pg broadcast xs opts get_future fut wait fut value Every rank root once i range world_size Run input tensor x = fn torch tensor rank output = broadcast x i assertEqual torch tensor i output exact_dtype=False TODO UCC currently does support multi tensor input Test overloaded convenience function x = torch tensor rank + fut = pg broadcast x root= get_future fut wait result = fut value assertEqual torch tensor result requires_ucc test_broadcast_basics _test_broadcast_basics lambda t t clone TODO test_broadcast_basics_cuda times out locally _test_allreduce_basics fn pg = _create_process_group_ucc Single input tests tests = simple_reduce_tests rank world_size op input expected tests opts = c d AllreduceOptions opts reduceOp = op tensor = fn input fut = pg allreduce tensor opts get_future fut wait result = fut value assertEqual expected result exact_dtype=False TODO UCC currently does support multi tensor input Test overloaded convenience function defaults using sum x = fn torch tensor rank + fut = pg allreduce x get_future fut wait result = fut value assertEqual torch tensor float world_size world_size + result requires_ucc test_allreduce_basics _test_allreduce_basics lambda t t clone TODO test_allreduce_basics_cuda times out locally _test_allgather_basics fn pg = _create_process_group_ucc TODO Run N input tensor per rank now UCC only supports single tensor input so N= n input = fn torch tensor n rank + i i range n output = fn torch tensor - _ range n world_size _ range n expected_output = fn torch tensor i i range n world_size _ range n fut = pg allgather output input get_future fut wait result = fut value n == result = result assertEqual expected_output result test_allgather_basics _test_allgather_basics lambda t t clone _test_reduce_basics fn pg = _create_process_group_ucc op input output simple_reduce_tests rank world_size root range world_size opts = c d ReduceOptions opts reduceOp = op opts rootRank = root tmp = fn input fut = pg reduce tmp opts get_future fut wait result = fut value root == rank assertEqual output result exact_dtype=False requires_ucc test_reduce_basics _test_reduce_basics lambda t t clone TODO test_reduce_basics_cuda times out locally requires_ucc test_send_recv_all_to_all pg = _create_process_group_ucc Preallocate tensors input output inputs = torch tensor rank _ range world_size outputs = torch tensor - _ range world_size Issue sends send_work = i range world_size i == rank continue send_work append pg send inputs i i Issue recvs recv_work = i range world_size i == rank continue recv_work append pg recv outputs i i Wait sends complete work send_work work wait assertTrue work is_completed Wait recvs complete work recv_work work wait assertTrue work is_completed Test every output other than our own contains respective rank i range world_size i == rank continue assertEqual torch tensor i outputs i TODO test_barrier_implies_wait fails numerical mismatch will investigate later skip_but_pass_in_sandcastle fails numerical mismatch skip now requires_ucc test_barrier_implies_wait pg = _create_process_group_ucc Kick off allreduce operations size = num = tensors = torch full size float i i range num tensor tensors Note leak returned work handle pg allreduce tensor Barrier should ensure all previous work has completed pg barrier get_future wait i tensor enumerate tensors assertEqual torch full size float i world_size tensor requires_ucc _test_reduce_scatter_base_basics fn pg = _create_process_group_ucc n = world_size input = fn torch ones n n rank + output = fn torch zeros expected_output = fn torch ones n + n fut = pg _reduce_scatter_base output input get_future fut wait result = fut value assertEqual result expected_output test_reduce_scatter_base_basics _test_reduce_scatter_base_basics lambda t t clone DistributedDataParallelTest test_c d_common CommonDistributedDataParallelTest MultiProcessTestCase setUp super setUp _spawn_processes _get_process_group store = _get_store c d init_process_group ucc store=store rank=self rank world_size=self world_size c d distributed_c d _get_default_group _test_ucc_backend devices device_ids multi_device=False gradient_as_bucket_view=False process_group = _get_process_group _test_ddp_with_process_group process_group devices device_ids multi_device gradient_as_bucket_view requires_ucc test_ucc_backend_cpu_module _test_ucc_backend torch device cpu None requires_ucc test_ucc_backend_cpu_module_grad_is_view _test_ucc_backend torch device cpu None gradient_as_bucket_view=True requires_ucc skip_if_lt_x_gpu test_ucc_backend_ gpu_module_device_ids_integer_list int_devices = gpus_for_rank world_size rank devices = torch device cuda + str i i int_devices _test_ucc_backend devices int_devices requires_ucc skip_if_lt_x_gpu test_ucc_backend_ gpu_module_device_ids_torch_device_list int_devices = gpus_for_rank world_size rank devices = torch device cuda + str i i int_devices _test_ucc_backend devices devices TODO test_ucc_backend_ gpu_module test_ucc_backend_ gpu_module require broadcast_coalesced which supported ucc currently skip_but_pass_in_sandcastle requires broadcast coalesced which supported ucc currently requires_ucc skip_if_lt_x_gpu test_ucc_backend_ gpu_module int_devices = gpus_for_rank world_size rank devices = torch device cuda + str i i int_devices _test_ucc_backend devices None multi_device=True skip_but_pass_in_sandcastle requires broadcast coalesced which supported ucc currently requires_ucc skip_if_lt_x_gpu test_ucc_backend_ gpu_module int_devices = gpus_for_rank world_size rank devices = torch device cuda + str i i int_devices _test_ucc_backend devices None multi_device=True _test_global_local_unused_params_grad gradient_as_bucket_view=False static_graph=False By simulating multi-task training test make sure DDP does touch grad globally unused parameters DDP does update grad locally unused parameters GlobalLocalUnusedParamModule nn Module __init__ - None super __init__ t = Task t = Task task_unused = Task task_parameters t p t p task_unused p forward x rank t x rank == t x run_and_verify_grad model Run forward output = model rank The grads all parameters should None point t _p t _p task_unused_p = model module task_parameters assertIsNone t _p grad assertIsNone t _p grad assertIsNone task_unused_p grad Run backward output mean backward Now locally unused parameter should have grad updated all ranks However globally unused parameter should still have None grad assertIsNotNone t _p grad assertIsNotNone t _p grad assertIsNone task_unused_p grad process_group = _get_process_group Test CPU cpu_model = DistributedDataParallel GlobalLocalUnusedParamModule cpu process_group=process_group find_unused_parameters=True gradient_as_bucket_view=gradient_as_bucket_view static_graph=static_graph run_and_verify_grad cpu_model Test GPU device_id = gpus_for_rank world_size rank gpu_model = DistributedDataParallel GlobalLocalUnusedParamModule device_id device_ids= device_id process_group=process_group find_unused_parameters=True gradient_as_bucket_view=gradient_as_bucket_view static_graph=static_graph run_and_verify_grad gpu_model TODO times out skip_but_pass_in_sandcastle times out requires_ucc skip_if_lt_x_gpu test_global_local_unused_params_grad _test_global_local_unused_params_grad TODO times out skip_but_pass_in_sandcastle times out requires_ucc skip_if_lt_x_gpu test_global_local_unused_params_grad_with_grad_is_view _test_global_local_unused_params_grad gradient_as_bucket_view=True TODO times out skip_but_pass_in_sandcastle times out requires_ucc skip_if_lt_x_gpu test_global_local_unused_params_grad_with_static_graph _test_global_local_unused_params_grad static_graph=True TODO times out skip_but_pass_in_sandcastle times out requires_ucc skip_if_lt_x_gpu test_find_unused_parameters_when_unused_parameters_empty An empty unused_parameters array does imply find_unused_parameters = false This test makes sure DDP allreduces unused parameters accordingly where forward pass some process uses all parameters This unit test creates module uses all parameters rank = has unused parameters other ranks FindUnusedParamModule nn Module __init__ - None super __init__ t = Task t = Task task_parameters t p t p forward x rank t t x rank == t x run_and_verify_grad model Run forward output = model rank The grads all parameters should None point assertIsNone t_p grad t_p model module task_parameters Run backward output mean backward Now locally unused parameter should have grad updated all ranks assertIsNotNone t_p grad t_p model module task_parameters process_group = _get_process_group Test CPU cpu_model = DistributedDataParallel FindUnusedParamModule cpu process_group=process_group find_unused_parameters=True run_and_verify_grad cpu_model Test GPU device_id = gpus_for_rank world_size rank gpu_model = DistributedDataParallel FindUnusedParamModule device_id device_ids= device_id process_group=process_group find_unused_parameters=True run_and_verify_grad gpu_model requires_ucc test_ignored_output Test output model can ignored there no implicit requirement ` backward ` gets called process_group = _get_process_group IgnoredOutput nn Module __init__ - None super __init__ fc = nn Linear bias=False fc = nn Linear bias=False relu = nn ReLU forward x x = relu fc x x = relu fc x F softmax x dim= model = DistributedDataParallel IgnoredOutput float process_group=process_group batch_size = criterion = nn CrossEntropyLoss input = torch rand batch_size dtype=torch float target = torch LongTensor random randrange _ range batch_size Run few iterations where we ignore output _ range output = model input del output Run few iterations where we use output _ range output = model input loss = criterion output target loss backward requires_ucc test_ignored_output_with_unused_parameters Test output model can ignored there no implicit requirement ` backward ` gets called all model parameters participated computing model output process_group = _get_process_group IgnoredOutputWithUnusedParameters nn Module __init__ - None super __init__ fc = nn Linear bias=False fc = nn Linear bias=False fc = nn Linear bias=False relu = nn ReLU forward x x = relu fc x x = relu fc x F softmax x dim= model = DistributedDataParallel IgnoredOutputWithUnusedParameters float process_group=process_group find_unused_parameters=True batch_size = criterion = nn CrossEntropyLoss input = torch rand batch_size dtype=torch float target = torch LongTensor random randrange _ range batch_size Run few iterations where we ignore output _ range output = model input del output Run few iterations where we use output _ range output = model input loss = criterion output target loss backward _run_and_verify_sparse_gradients vanilla_model ddp_model mult = batch_size = mult world_size criterion = nn CrossEntropyLoss input = torch randint batch_size target = torch randint batch_size Run entire batch against single process version criterion vanilla_model input target backward Run partial batch against multi process version partial_input = input split mult rank partial_target = target split mult rank criterion ddp_model partial_input partial_target backward Check gradients sparse identical vanilla_parameter = next vanilla_model parameters ddp_parameter = next ddp_model parameters assertEqual vanilla_parameter grad coalesce ddp_parameter grad coalesce requires_ucc skip_if_lt_x_gpu test_save_load_checkpoint dist init_process_group ucc init_method=f file file_name world_size=self world_size rank=self rank TestModel nn Module __init__ - None super __init__ fc = nn Linear bias=False fc = nn Linear bias=False relu = nn ReLU forward x x = relu fc x x = relu fc x F softmax x dim= train_loop model optimizer iterations _ range iterations optimizer zero_grad output = model input loss = criterion output target loss backward optimizer step device_id = gpus_for_rank world_size rank model_withload = TestModel float device_id model_withoutload = TestModel float device_id ddp_withload = DistributedDataParallel model_withload device_ids= device_id ddp_withoutload = DistributedDataParallel model_withoutload device_ids= device_id ensure all three models start same set parameters By default they randomized construction p ddp_withload parameters torch no_grad p zero_ p model_withload parameters torch no_grad p zero_ p ddp_withoutload parameters torch no_grad p zero_ batch_size = criterion = nn CrossEntropyLoss optimizer_withload = torch optim SGD ddp_withload parameters lr= optimizer_non_ddp_withload = torch optim SGD model_withload parameters lr= optimizer_withoutload = torch optim SGD ddp_withoutload parameters lr= input = torch rand batch_size dtype=torch float device_id target = torch LongTensor random randrange _ range batch_size device_id run model iterations checkpoint middle train_loop ddp_withload optimizer_withload zero out parameters both DDP non-DDP models reload them DDP state dict checkpoint_path = tempfile gettempdir + model checkpoint rank == torch save ddp_withload state_dict checkpoint_path dist barrier map_location = cuda f cuda rank d ddp_state_dict = torch load checkpoint_path map_location=map_location model ddp_withload model_withload p model parameters torch no_grad p zero_ ddp_withload load_state_dict ddp_state_dict non-DDP model needs first remove prefix module DDP state dict torch nn modules utils consume_prefix_in_state_dict_if_present ddp_state_dict module model_withload load_state_dict ddp_state_dict train_loop ddp_withload optimizer_withload train_loop model_withload optimizer_non_ddp_withload re-run model same inputs iterations no checkpoint train_loop ddp_withoutload optimizer_withoutload p_withload p_withoutload p_non_ddp_withload zip ddp_withload parameters ddp_withoutload parameters model_withload parameters assertEqual p_withload p_withoutload assertEqual p_non_ddp_withload p_withoutload _test_sparse_gradients gradient_as_bucket_view=False process_group = _get_process_group Ensure initialized weights inputs identical across processes torch manual_seed vanilla_model = SparseGradientModule ddp_model = DistributedDataParallel copy deepcopy vanilla_model process_group=process_group gradient_as_bucket_view=gradient_as_bucket_view _run_and_verify_sparse_gradients vanilla_model ddp_model TODO backward pass input tensor has dense skip_but_pass_in_sandcastle backward pass input tensor has dense requires_ucc test_sparse_gradients _test_sparse_gradients TODO backward pass input tensor has dense skip_but_pass_in_sandcastle backward pass input tensor has dense requires_ucc test_sparse_gradients_grad_is_view _test_sparse_gradients gradient_as_bucket_view=True requires_ucc test_ddp_comm_hook_future_passing_cpu This unit test verifies whether Future object passed properly The callback function creates Future object sets value process_group = _get_process_group Test CPU cpu_model = DistributedDataParallel ModuleForDdpCommHook cpu process_group=process_group Register DDP Communication Hook cpu_model register_comm_hook None _simple_hook check whether grads equal what then callback returns without comm_hook result would torch ones _run_and_verify_hook cpu_model torch ones _gpu_model_with_ddp_comm_hook process_group hook=None gradient_as_bucket_view=False state=None device_id = gpus_for_rank world_size rank gpu_model = DistributedDataParallel ModuleForDdpCommHook device_id device_ids= device_id process_group=process_group gradient_as_bucket_view=gradient_as_bucket_view Register DDP communication hook any hook None gpu_model register_comm_hook state hook gpu_model requires_ucc skip_if_lt_x_gpu test_ddp_comm_hook_future_passing_gpu_ucc This unit test verifies whether Future object passed properly using ucc backend The hook callback function creates Future object sets value process_group = _get_process_group Get GPU model simple_hook registered gpu_model = _gpu_model_with_ddp_comm_hook process_group _simple_hook check whether grads equal what simple_hook s then callback returns without comm_hook result would torch ones _run_and_verify_hook gpu_model torch ones requires_ucc test_ddp_invalid_comm_hook_init This unit test makes sure register_comm_hook properly checks format hook defined user The Python hook must callable This test also checks whether bucket annotation checked properly defined process_group = _get_process_group model = DistributedDataParallel ModuleForDdpCommHook process_group=process_group assertRaisesRegex TypeError Communication hook must callable model register_comm_hook state=None hook= assertRaisesRegex ValueError bucket annotation should dist GradBucket comm_hook state object bucket int - torch futures Future torch Tensor torch futures Future model register_comm_hook state=None hook=comm_hook requires_ucc test_ddp_invalid_comm_hook_return_type This test checks whether annotation checked properly defined It also checks whether internal error thrown type incorrect user hasn t specified any type annotation process_group = _get_process_group model = DistributedDataParallel ModuleForDdpCommHook process_group=process_group expected_err = Communication hook annotation should torch futures Future assertRaisesRegex ValueError expected_err comm_hook state object bucket dist GradBucket - int torch futures Future model register_comm_hook state=None hook=comm_hook verify_ddp_error_logged model expected_err assertRaisesRegex RuntimeError callback must torch futures Future object got comm_hook state object bucket dist GradBucket model register_comm_hook state=None hook=comm_hook Run forward output = model rank Run backward output mean backward requires_ucc test_ddp_comm_hook_register_just_once DDP communication hook can only registered once This test validates whether error thrown properly when register_comm_hook called more than once process_group = _get_process_group model = DistributedDataParallel ModuleForDdpCommHook process_group=process_group dummy_hook state bucket fut = torch futures Future fut set_result bucket buffer fut model register_comm_hook None dummy_hook assertRaisesRegex RuntimeError register_comm_hook register_builtin_comm_hook can only called once model register_comm_hook None dummy_hook TODO backward pass input tensor must dense skip_but_pass_in_sandcastle backward pass input tensor has dense requires_ucc test_ddp_comm_hook_sparse_gradients Runs test_sparse_gradients unit test DDP communication hook We define simple hook does allreduce works ucc backend test process_group = _get_process_group Ensure initialized weights inputs identical across processes torch manual_seed vanilla_model = SparseGradientModule ddp_model = DistributedDataParallel copy deepcopy vanilla_model process_group=process_group allreduce_hook_ucc state object bucket dist GradBucket - torch futures Future torch Tensor div_by_world_size fut Divide result world_size fut wait world_size Prepare allreduced grad bucket tensors running async work fut = process_group allreduce bucket buffer get_future fut then div_by_world_size ddp_model register_comm_hook None allreduce_hook_ucc _run_and_verify_sparse_gradients vanilla_model ddp_model CommTest test_c d_common AbstractCommTest MultiProcessTestCase property device cpu setUp super setUp _spawn_processes tearDown super tearDown try os remove file_name except OSError pass requires_ucc skip_if_lt_x_gpu test_sequence_num_set_default_pg_ucc _test_sequence_num_set_default_pg backend= ucc requires_ucc skip_if_lt_x_gpu test_sequence_num_set_ucc_new_group _test_sequence_num_set_new_group backend= ucc skip_if_lt_x_gpu requires_ucc test_sequence_num_incremented_ucc_default _test_sequence_num_incremented_default_group ucc skip_if_lt_x_gpu requires_ucc test_sequence_num_incremented_ucc_subgroup world_size skip_but_pass_in_sandcastle Test requires world_size least _test_sequence_num_incremented_subgroup ucc skip_but_pass_in_sandcastle Fails M requires_ucc test_ucc_barrier_device_ids store = c d FileStore file_name world_size c d init_process_group backend= ucc rank=self rank world_size=self world_size store=store assertRaisesRegex RuntimeError device_ids supported c d barrier device_ids= rank skip_but_pass_in_sandcastle Fails M skip_if_lt_x_gpu requires_ucc test_ucc_warn_not_in_group _test_warn_not_in_group backend= ucc skip_if_lt_x_gpu requires_ucc test_ucc_rank_membership _test_rank_membership backend= ucc skip_if_lt_x_gpu requires_ucc test_tensor_dtype_mismatch _test_tensor_dtype_mismatch backend= ucc skip_if_lt_x_gpu requires_ucc test_tensor_dtype_complex _test_tensor_dtype_complex backend= ucc UccProcessGroupWithDispatchedCollectivesTests test_c d_common ProcessGroupWithDispatchedCollectivesTests skip_but_pass_in_sandcastle Fails M requires_ucc skip_if_lt_x_gpu test_collectives includes reduce broadcast all_reduce all_gather reduce_scatter barrier all_to_all scatter _test_collectives backend= ucc skip_but_pass_in_sandcastle Fails M requires_ucc skip_if_lt_x_gpu test_allgather_base store = dist FileStore file_name world_size dist init_process_group ucc world_size=self world_size rank=self rank store=store device = cuda tensor = torch ones device=torch device device output_tensor = torch zeros device=torch device device dist all_gather_into_tensor output_tensor tensor assertEqual output_tensor tensor __name__ == __main__ assert torch cuda _initialized test_distributed must have initialized CUDA context main process run_tests