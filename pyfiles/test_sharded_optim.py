Owner s oncall distributed copy deepcopy torch torch optim optim torch distributed _shard shard_parameter sharded_tensor torch distributed _shard sharded_optim ShardedOptimizer torch distributed _shard sharding_spec ChunkShardingSpec torch testing _internal common_distributed requires_nccl skip_if_lt_x_gpu torch testing _internal common_utils run_tests torch testing _internal distributed _shard sharded_tensor ShardedTensorTestBase with_comms MyShardedModel torch nn Module __init__ spec=None group=None super __init__ Use same seed torch manual_seed param = torch nn Parameter torch rand spec None sharded_param = torch nn Parameter sharded_tensor rand spec requires_grad=True process_group=group sharded_param = torch nn Parameter torch rand forward input isinstance sharded_param sharded_tensor ShardedTensor param + sharded_param local_shards tensor + input sharded_param + param + input MyShardedLinear torch nn Module __init__ rank=None super __init__ Use same seed torch manual_seed linear = torch nn Linear linear = torch nn Linear gelu = torch nn GELU rank linear cuda rank linear cuda rank shard_parameter rowwise_sharding_spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda colwise_sharding_spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda shard_parameter linear weight rowwise_sharding_spec shard_parameter linear weight colwise_sharding_spec forward inp linear gelu linear inp TestShardedOptimizer ShardedTensorTestBase with_comms init_rpc=False skip_if_lt_x_gpu requires_nccl test_sharded_optim rowwise_spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda local_model = MyShardedModel cuda sharded_model = MyShardedModel spec=rowwise_spec cuda copy parameters local model sharded_model sharded_param local_shards tensor = local_model sharded_param detach clone requires_grad_ local_optim = optim SGD local_model parameters lr= sharded_model_params = dict sharded_model named_parameters sharded_optim = ShardedOptimizer sharded_model_params optim SGD lr= local_optim zero_grad sharded_optim zero_grad before_update = deepcopy sharded_optim named_params inp = torch rand cuda rank requires_grad_ run forward local_output = local_model inp sharded_output = sharded_model inp backward local_output sum backward sharded_output sum backward optimizer update local_optim step sharded_optim step make sure parameters including sharded param get updated optimizer updated local params same sharded params key val before_update items new_val = sharded_optim named_params key isinstance val sharded_tensor ShardedTensor assertNotEqual val local_shards tensor new_val local_shards tensor assertEqual new_val local_shards tensor local_model sharded_param assertNotEqual val new_val assertEqual new_val local_model param with_comms init_rpc=False skip_if_lt_x_gpu requires_nccl test_named_params_with_sharded_tensor rowwise_spec = ChunkShardingSpec dim= placements= rank cuda rank cuda rank cuda rank cuda sharded_model = MyShardedModel spec=rowwise_spec cuda sharded_model_params = dict sharded_model named_parameters param_keys = list sharded_model_params keys assertEqual len param_keys assertTrue param param_keys assertTrue sharded_param param_keys sharded_linear = MyShardedLinear rank=self rank cuda sharded_linear shard_parameter sharded_linear_params = dict sharded_linear named_parameters param_keys = list sharded_linear_params keys assertEqual len param_keys assertTrue linear bias param_keys assertTrue linear bias param_keys assertTrue linear weight param_keys assertTrue linear weight param_keys assertFalse bias param_keys __name__ == __main__ run_tests