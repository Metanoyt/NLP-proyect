mypy allow-untyped-defs collections logging operator collections OrderedDict collections abc Iterable Iterator typing Any torch torch _dynamo utils counters is_node_meta_valid torch _logging trace_structured torch fx passes graph_transform_observer GraphTransformObserver torch utils _ordered_set OrderedSet config pattern_matcher CallFunctionVarArgs get_arg_value stable_topological_sort utils OPTIMUS_EXCLUDE_POST_GRAD try importing will register fbgemm lowerings inductor deeplearning fbgemm fbgemm_gpu fb inductor_lowerings noqa F has_fbgemm = True except Exception has_fbgemm = False aten = torch ops aten log = logging getLogger __name__ DEFAULT_BETA = DEFAULT_ALPHA = MIN_FUSE_SET_SIZE = MAX_FUSE_SET_SIZE = MAX_FUSE_SEARCH_DEPTH = The maximum tensor size can go into fusion group MAX_FUSE_TENSOR_SIZE_GROUP_LINEAR = Whether we only fuse nodes same parent node FUSE_NODES_WITH_SAME_PARENT = False Whether we enable add broadcast batch linear SHAPE_BROADCAST_BATCH_LINEAR = False Whether we enable fuse nodes same users Fuse_NODES_WITH_SAME_USERS = False exclude these nodes BFS excluding get item improves optimizer compilation time s SEARCH_EXCLUSIONS = OrderedSet operator getitem default_graph_search_options = min_fuse_set_size MIN_FUSE_SET_SIZE max_fuse_set_size MAX_FUSE_SET_SIZE max_fuse_search_depth MAX_FUSE_SEARCH_DEPTH max_fuse_tensor_size_group_linear MAX_FUSE_TENSOR_SIZE_GROUP_LINEAR fuse_nodes_with_same_parent FUSE_NODES_WITH_SAME_PARENT shape_broadcast_batch_linear SHAPE_BROADCAST_BATCH_LINEAR fuse_nodes_with_same_users Fuse_NODES_WITH_SAME_USERS graph_search_options = default_graph_search_options update_stack_example_value node metadata dim= op=torch stack Update example value node graph enable followup split cat opt node None hasattr node meta op torch stack example_value = torch stack metadata dim=dim op torch unbind example_value = torch unbind metadata dim=dim type ignore assignment node meta example_value = example_value update_pointwise_example_value pointwise_node input other op Update example value add node graph enable followup split cat opt pointwise_node None hasattr pointwise_node meta op torch add example_value = torch add input other op torch mul example_value = torch mul input other pointwise_node meta example_value = example_value GroupBatchFusionBase __init__ kwargs - None graph_search_options = kwargs pop graph_search_options default_graph_search_options match node raise NotImplementedError match called base fuse graph subset raise NotImplementedError fuse called base PRE_GRAD_FUSIONS dict str GroupBatchFusionBase = POST_GRAD_FUSIONS dict str GroupBatchFusionBase = register_fusion name str pre_grad=True decorator fusion_cls GroupBatchFusionBase pre_grad PRE_GRAD_FUSIONS name = fusion_cls POST_GRAD_FUSIONS name = fusion_cls fusion_cls decorator list_group_batch_fusions pre_grad=True - list str pre_grad list PRE_GRAD_FUSIONS keys list POST_GRAD_FUSIONS keys decompose_stack graph torch fx GraphModule input_tensors list Any - Any unsqueezed_inputs = unsqueezed_inputs_meta = input_tensor input_tensors unsqueezed_input = graph call_function type ignore operator aten unsqueeze args= input_tensor kwargs= dim unsqueezed_inputs append unsqueezed_input unsqueezed_input meta val = aten unsqueeze input_tensor meta val dim= type ignore assignment unsqueezed_inputs_meta append unsqueezed_input meta val stacked_inputs = graph call_function type ignore operator aten cat args= unsqueezed_inputs kwargs= dim stacked_inputs meta val = aten cat unsqueezed_inputs_meta dim= type ignore assignment stacked_inputs GroupFusion GroupBatchFusionBase Fuse ops group way e g fuse mm addmm arbitrary input shapes fbgemm gmm BatchFusion GroupBatchFusionBase Fuse ops batch way e g fuse mm addmm same input shapes bmm BatchPointwiseOpsFusionFactory BatchFusion __init__ op kwargs - None super __init__ kwargs op = op register_fusion batch_linear_post_grad pre_grad=False PostGradBatchLinearFusion BatchFusion Fuse ops batch way post grad aten level _addmm_node_can_be_fused node torch fx Node - bool pyre-fixme Incompatible type node kwargs get beta DEFAULT_BETA == DEFAULT_BETA node kwargs get alpha DEFAULT_ALPHA == DEFAULT_ALPHA type ignore return-value _is_input_ d input torch fx Node - bool input_shapes = input meta val shape len input_shapes == isinstance input_shapes int isinstance input_shapes int match node torch fx Node - tuple str int int int bool str &#124; None CallFunctionVarArgs aten mm match node input_m weight_m = node args bias_m = None CallFunctionVarArgs aten addmm default match node _addmm_node_can_be_fused node bias_m input_m weight_m = node args None get user node graph_search_options get fuse_nodes_with_same_users False users = user target user node users keys users = type ignore assignment only handle cases where inputs D tensors _is_input_ d input_m _is_input_ d weight_m type ignore arg-type None m k = input_m meta val shape type ignore union-attr n = weight_m meta val shape type ignore union-attr batch_key = batch_linear_post_grad m k n bias_m None str users batch_key fuse graph torch fx GraphModule subset list torch fx Node batch_inputs = batch_weights = batch_biases = batch_nodes = batch_inputs_meta = batch_weights_meta = batch_biases_meta = node subset CallFunctionVarArgs aten addmm default match node bias input weight = node args CallFunctionVarArgs aten mm default match node input weight = node args bias = None batch_nodes append node batch_inputs append input type ignore possibly-undefined batch_weights append weight type ignore possibly-undefined batch_biases append bias type ignore possibly-undefined batch_inputs_meta append input meta type ignore possibly-undefined union-attr batch_weights_meta append weight meta type ignore possibly-undefined union-attr bias None type ignore possibly-undefined batch_biases_meta append bias meta type ignore possibly-undefined union-attr batch_biases_meta append None graph inserting_before subset - type ignore operator fused_inputs = decompose_stack graph batch_inputs fused_weights = decompose_stack graph batch_weights fused_inputs_meta_val = torch stack input val input batch_inputs_meta fused_weights_meta_val = torch stack weight val weight batch_weights_meta fused_bmm = graph call_function type ignore operator aten bmm args= fused_inputs fused_weights fused_bmm meta val = aten bmm fused_inputs_meta_val fused_weights_meta_val i original_mm enumerate batch_nodes has_bias = False graph inserting_after fused_bmm type ignore operator new_mm = graph call_function aten select args= fused_bmm i type ignore operator new_mm meta val = aten select fused_bmm meta val i batch_biases i has_bias = True broadcast bias same shape mm output graph_search_options get shape_broadcast_batch_linear False broadcast_shape = torch broadcast_shapes batch_biases_meta i val shape new_mm meta val shape broadcast_bias = graph call_function type ignore operator aten broadcast_to default args= batch_biases i kwargs= size broadcast_shape broadcast_bias meta val = aten broadcast_to batch_biases_meta i val broadcast_shape type ignore assignment new_bias_add = graph call_function type ignore operator aten add Tensor args= broadcast_bias new_mm new_bias_add meta val = aten add Tensor broadcast_bias meta val new_mm meta val new_bias_add = graph call_function type ignore operator aten add args= batch_biases i new_mm new_bias_add meta val = aten add Tensor batch_biases_meta i val new_mm meta val new_mm_cont = new_bias_add has_bias new_mm type ignore possibly-undefined original_mm replace_all_uses_with new_mm_cont new_mm_cont meta update original_mm meta graph erase_node original_mm type ignore operator counters inductor batch_linear_post_grad += register_fusion group_linear pre_grad=False GroupLinearFusion GroupFusion _addmm_node_can_be_fused node torch fx Node input_shape = node args meta val shape type ignore union-attr weight_shape = node args meta val shape type ignore union-attr node kwargs get beta DEFAULT_BETA == DEFAULT_BETA node kwargs get alpha DEFAULT_ALPHA == DEFAULT_ALPHA len input_shape == len weight_shape == all x == x input_shape + weight_shape all shape = graph_search_options max_fuse_tensor_size_group_linear shape input_shape + weight_shape _mm_node_can_be_fused node torch fx Node input_shape = node args meta val shape type ignore union-attr weight_shape = node args meta val shape type ignore union-attr len input_shape == len weight_shape == all x == x input_shape + weight_shape all shape = graph_search_options max_fuse_tensor_size_group_linear shape input_shape + weight_shape match node torch fx Node - tuple str bool &#124; None CallFunctionVarArgs aten mm default match node _mm_node_can_be_fused node group_key = group_linear True CallFunctionVarArgs aten addmm default match node _addmm_node_can_be_fused node bias = node args group_key = group_linear bias None group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node group_inputs = group_weights = group_biases = group_nodes = node subset CallFunctionVarArgs aten addmm default match node bias input weight = node args assert CallFunctionVarArgs aten mm default match node input weight = node args bias = None group_nodes append node group_inputs append input group_weights append weight group_biases append bias all bias None bias group_biases group_biases = None type ignore assignment graph inserting_before subset type ignore operator fused_mm = graph call_function type ignore operator torch ops fbgemm gmm default args= group_inputs group_weights group_biases kwargs= smart_fused True i original_mm enumerate group_nodes graph inserting_after fused_mm type ignore operator new_mm = graph call_function operator getitem args= fused_mm i type ignore operator original_mm replace_all_uses_with new_mm new_mm meta update original_mm meta graph erase_node original_mm type ignore operator counters inductor group_linear += BatchPointwiseMathOpsPostGradFusion BatchPointwiseOpsFusionFactory Batch pointwise math operator e g add mul post grad pass __init__ op kwargs - None super __init__ op kwargs op = op _pointwise_node_can_be_fused node torch fx Node note we only consider case where inputs tensors mixed precision training we need make sure inputs aten cat when do stack should same dtype otherwise output aten cat may same its inputs cause dtype same error mm addmm input other = node args input meta val shape == other meta val shape type ignore union-attr input other can scalars where they have no attribute meta hasattr input meta hasattr other meta is_node_meta_valid input type ignore arg-type union-attr is_node_meta_valid other type ignore arg-type union-attr torch SymInt torch SymFloat object has no attribute shape isinstance input meta val torch Tensor type ignore union-attr isinstance other meta val torch Tensor type ignore union-attr False match node torch fx Node CallFunctionVarArgs op match node _pointwise_node_can_be_fused node alpha = node kwargs get alpha DEFAULT_ALPHA rounding_mode = node kwargs get rounding_mode None input other = node args shape = list input meta val shape type ignore union-attr graph_search_options get fuse_nodes_with_same_parent False only consider linear case so far pyre-fixme input target aten select other target aten select type ignore union-attr parent = pyre-fixme input args type ignore union-attr pyre-fixme input target aten select type ignore union-attr other args type ignore union-attr parent = parent = group_key = batch_aten_ + op __name__ lower split str shape str input meta val dtype type ignore union-attr str other meta val dtype type ignore union-attr str alpha str rounding_mode str parent group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_inputs batch_others = alpha = subset kwargs get alpha DEFAULT_ALPHA batch_inputs_meta batch_others_meta = node subset input other = node args batch_inputs append input batch_others append other batch_inputs_meta append input meta type ignore possibly-undefined union-attr batch_others_meta append other meta type ignore possibly-undefined union-attr graph inserting_before subset type ignore operator stack_inputs = decompose_stack graph batch_inputs stack_others = decompose_stack graph batch_others stack_inputs_meta = torch stack input val input batch_inputs_meta stack_others_meta = torch stack other val other batch_others_meta batch_op = graph call_function type ignore operator op args= stack_inputs stack_others kwargs= alpha alpha op == aten add Tensor batch_op meta val = op stack_inputs_meta stack_others_meta i original_add enumerate subset graph inserting_after batch_op type ignore operator new_add = graph call_function type ignore operator torch ops aten select args= batch_op i original_add replace_all_uses_with new_add new_add meta update original_add meta graph erase_node original_add type ignore operator counters inductor batch_aten_ + op __name__ lower split += register_fusion batch_linear_lhs BatchLinearLHSFusion BatchFusion Batch linear left-hand side fusion This pass tries fuse following patterns torch nn functional linear x w linear x w linear x wn - torch mm x torch cat w w wn transpose We have separate pass eliminate contiguous transpose generic way match node torch fx Node - tuple str bool Any &#124; None CallFunctionVarArgs torch nn functional linear match node is_linear_node_can_be_fused node input = get_arg_value node input bias = get_arg_value node bias group_key = batch_linear_lhs bias None input group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_nodes = batch_input = None batch_weights batch_weights_meta = batch_biases batch_biases_meta = split_sections = node subset input = get_arg_value node input weight = get_arg_value node weight bias = get_arg_value node bias batch_nodes append node batch_input None batch_input = input assert batch_input input batch_weights append weight batch_weights_meta append weight meta example_value bias batch_biases append bias batch_biases_meta append bias meta example_value split_sections append weight meta example_value shape graph inserting_before subset type ignore operator cat_weights = graph call_function type ignore operator torch cat args= batch_weights kwargs= dim cat_weights meta example_value = torch cat batch_weights_meta dim= transposed_weights = graph call_function type ignore operator torch transpose args= cat_weights transposed_weights meta example_value = torch transpose cat_weights meta example_value len batch_biases cat_biases = graph call_function type ignore operator torch cat args= batch_biases kwargs= dim cat_biases meta example_value = torch cat batch_biases_meta dim= fused_lhs = graph call_function type ignore operator torch addmm args= cat_biases batch_input transposed_weights fused_lhs meta example_value = torch addmm cat_biases meta example_value batch_input meta example_value type ignore union-attr transposed_weights meta example_value fused_lhs = graph call_function type ignore operator torch mm args= batch_input transposed_weights fused_lhs meta example_value = torch mm batch_input meta example_value type ignore union-attr transposed_weights meta example_value fused_lhs_list = graph call_function type ignore operator torch split args= fused_lhs split_sections kwargs= dim i node enumerate batch_nodes graph inserting_after fused_lhs_list type ignore operator new_node = graph call_function type ignore operator operator getitem args= fused_lhs_list i node replace_all_uses_with new_node new_node meta update node meta graph erase_node node type ignore operator counters inductor batch_linear_lhs += Poor person s check node graph mutates its input graph torch IR so we will see torch fns python operators _is_mutable_node tgt str tgt endswith _ e g torch mul_ torch Tensor mul_ True hasattr tgt __module__ tgt __module__ == _operator tgt __name__ startswith i e g operator iand operator imul True False is_linear_node_can_be_fused node torch fx Node input = get_arg_value node input weight = get_arg_value node weight is_node_meta_valid node is_node_meta_valid input is_node_meta_valid weight len input meta example_value shape == len weight meta example_value shape == mm - bmm transform adds unbind op which safe autograd when output mm mutated don t pattern match any users mm mutate input any _is_mutable_node user target user node users register_fusion batch_linear PreGradBatchLinearFusion BatchFusion Batch linear fusion pre grad pass Fuse linear same size torch baddmm _getitem_args getitem_node torch fx Node getitem_node target = operator __getitem__ getitem_node op = call_function None getitem_node args match node torch fx Node CallFunctionVarArgs torch nn functional linear match node is_linear_node_can_be_fused node input = get_arg_value node input weight = get_arg_value node weight bias = get_arg_value node bias graph_search_options get fuse_nodes_with_same_users False users = user target user node users keys users = type ignore assignment group_key = batch_linear _getitem_args input str input meta example_value shape str weight meta example_value shape bias None str users group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_nodes = batch_inputs = batch_weights = batch_biases = batch_inputs_metadata = batch_weights_metadata = batch_biases_metadata = node subset batch_nodes append node input = get_arg_value node input batch_inputs append input batch_inputs_metadata append input meta example_value weight = get_arg_value node weight batch_weights append weight batch_weights_metadata append weight meta example_value bias = get_arg_value node bias batch_biases append bias bias None hasattr bias meta batch_biases_metadata append bias meta example_value graph inserting_before subset type ignore operator stack_inputs = graph call_function type ignore operator torch stack args= batch_inputs kwargs= dim update_stack_example_value stack_inputs batch_inputs_metadata stack_weights = graph call_function type ignore operator torch stack args= batch_weights kwargs= dim update_stack_example_value stack_weights batch_weights_metadata transpose_weight = graph call_function type ignore operator torch transpose args= stack_weights transpose_weight meta example_value = torch transpose stack_weights meta example_value all bias None bias batch_biases bmm = graph call_function type ignore operator torch bmm args= stack_inputs transpose_weight bmm meta example_value = torch bmm stack_inputs meta example_value transpose_weight meta example_value bmm_meta = bmm meta example_value stack_biases = graph call_function type ignore operator torch stack args= batch_biases kwargs= dim update_stack_example_value stack_biases batch_biases_metadata unsqueeze_biases = graph call_function type ignore operator torch unsqueeze args= stack_biases unsqueeze_biases meta example_value = torch unsqueeze stack_biases meta example_value bmm = graph call_function type ignore operator torch baddbmm args= unsqueeze_biases stack_inputs transpose_weight try will have runtime error broadcast when has dynamic shape included meta data so we need skip update meta data bmm meta example_value = torch baddbmm unsqueeze_biases meta example_value stack_inputs meta example_value transpose_weight meta example_value bmm_meta = bmm meta example_value except Exception e log debug f exception when update bmm meta data stack error tracekey e noqa G bmm_meta = None bmm = graph call_function torch unbind args= bmm kwargs= dim type ignore operator bmm_meta None bmm meta example_value = torch unbind bmm_meta dim= i linear enumerate batch_nodes graph inserting_after bmm type ignore operator getitem = graph call_function operator getitem args= bmm i type ignore operator linear replace_all_uses_with getitem getitem meta update linear meta graph erase_node linear type ignore operator counters inductor batch_linear += register_fusion batch_layernorm BatchLayernormFusion BatchFusion Batch layer norm fusion pre grad pass match node torch fx Node CallFunctionVarArgs torch nn functional layer_norm match node input = get_arg_value node input weight = get_arg_value node weight bias = get_arg_value node bias graph_search_options get fuse_nodes_with_same_users False users = user target user node users keys users = type ignore assignment group_key = batch_layernorm str input meta example_value shape str weight meta example_value shape weight None str bias meta example_value shape bias None str get_arg_value node normalized_shape str get_arg_value node eps str users example_value input meta is_node_meta_valid weight is_node_meta_valid bias None group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node group_inputs = group_shapes = group_weights = group_biases = group_epss = group_nodes = group_inputs_metadata = group_biases_metadata = group_weights_metadata = node subset group_nodes append node input = get_arg_value node input group_inputs append input group_inputs_metadata append input meta example_value group_shapes append get_arg_value node normalized_shape weight = get_arg_value node weight group_weights append weight weight None hasattr weight meta group_weights_metadata append weight meta example_value bias = get_arg_value node bias group_biases append bias bias None hasattr bias meta group_biases_metadata append bias meta example_value eps = get_arg_value node eps eps None eps = e- group_epss append eps stack_dim = - - len group_shapes - all bias None bias group_biases group_biases = None type ignore assignment all weight None weight group_weights group_weights = None type ignore assignment assert all eps == group_epss eps group_epss all epsilon values must equal graph inserting_before subset type ignore operator stack_input = graph call_function type ignore operator torch stack args= group_inputs kwargs= dim stack_dim update_stack_example_value stack_input group_inputs_metadata stack_dim group_weights None stack_weight = graph call_function type ignore operator torch stack args= group_weights kwargs= dim update_stack_example_value stack_weight group_weights_metadata stack_weight = None group_biases None stack_bias = graph call_function type ignore operator torch stack args= group_biases kwargs= dim update_stack_example_value stack_bias group_biases_metadata stack_bias = None batch_layer_norm = graph call_function type ignore operator torch nn functional layer_norm args= stack_input group_shapes - kwargs= eps group_epss - batch_layer_norm meta example_value = stack_input meta example_value group_weights None group_biases None previous_batch_layer_norm_meta = batch_layer_norm meta example_value batch_layer_norm = graph call_function type ignore operator torch mul args= stack_weight batch_layer_norm update_pointwise_example_value batch_layer_norm pyrefly ignore missing-attribute stack_weight meta example_value previous_batch_layer_norm_meta torch mul previous_batch_layer_norm_meta = batch_layer_norm meta example_value batch_layer_norm = graph call_function type ignore operator torch add args= stack_bias batch_layer_norm update_pointwise_example_value batch_layer_norm pyrefly ignore missing-attribute stack_bias meta example_value previous_batch_layer_norm_meta torch add group_weights None group_biases None previous_batch_layer_norm_meta = batch_layer_norm meta example_value pyrefly ignore not-callable batch_layer_norm = graph call_function torch mul args= stack_weight batch_layer_norm update_pointwise_example_value batch_layer_norm pyrefly ignore missing-attribute stack_weight meta example_value previous_batch_layer_norm_meta torch mul group_weights None group_biases None previous_batch_layer_norm_meta = batch_layer_norm meta example_value pyrefly ignore not-callable batch_layer_norm = graph call_function torch add args= stack_bias batch_layer_norm update_pointwise_example_value batch_layer_norm pyrefly ignore missing-attribute stack_bias meta example_value previous_batch_layer_norm_meta torch add batch_layer_norm_unbind = graph call_function type ignore operator torch unbind args= batch_layer_norm kwargs= dim stack_dim update_stack_example_value batch_layer_norm_unbind batch_layer_norm meta example_value op=torch unbind dim=stack_dim i node enumerate group_nodes graph inserting_after batch_layer_norm_unbind type ignore operator new_node = graph call_function type ignore operator operator getitem args= batch_layer_norm_unbind i node replace_all_uses_with new_node new_node meta update node meta graph erase_node node type ignore operator counters inductor batch_layernorm += BatchPointwiseOpsPreGradFusion BatchPointwiseOpsFusionFactory Batch pointwise ops e g sigmoid relu tanh fusion pre grad pass We fuse random place introduced stack node may merged split cat __init__ op kwargs - None super __init__ op kwargs op = op match node torch fx Node input = get_arg_value node input CallFunctionVarArgs op match node is_node_meta_valid node graph_search_options get fuse_nodes_with_same_parent False pyre-fixme parent = node args parent = parent target parent None type ignore union-attr parent = relu op we also use inplace construct key group_key = batch_ + op __name__ lower split str input meta example_value shape str node kwargs get inplace False str parent group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_nodes = batch_inputs = batch_inputs_metadata = node subset batch_nodes append node input = get_arg_value node input batch_inputs append input batch_inputs_metadata append input meta example_value graph inserting_before subset type ignore operator stack_inputs = graph call_function type ignore operator torch stack args= batch_inputs kwargs= dim update_stack_example_value stack_inputs batch_inputs_metadata op torch nn functional relu batch_op = graph call_function type ignore operator op args= stack_inputs kwargs= inplace subset kwargs get inplace False batch_op meta example_value = op stack_inputs meta example_value inplace=subset kwargs get inplace False batch_op = graph call_function type ignore operator op args= stack_inputs batch_op meta example_value = op stack_inputs meta example_value unbind_op = graph call_function type ignore operator torch unbind args= batch_op kwargs= dim unbind_op meta example_value = torch unbind batch_op meta example_value dim= i node enumerate batch_nodes graph inserting_after unbind_op type ignore operator getitem = graph call_function operator getitem args= unbind_op i type ignore operator node replace_all_uses_with getitem getitem meta update node meta graph erase_node node type ignore operator counters inductor batch_ + op __name__ lower split += BatchPointwiseOpsPostGradFusion BatchPointwiseOpsFusionFactory Batch pointwise ops e g sigmoid relu tanh fusion post grad pass The introduced stack node may merged split cat __init__ op kwargs - None super __init__ op kwargs op = op match node torch fx Node input = get_arg_value node input CallFunctionVarArgs op match node is_node_meta_valid node relu op we also use inplace construct key we batch ops same parent enable followup split cat parent = node args parent = parent target type ignore union-attr graph_search_options get fuse_nodes_with_same_parent False group_key = batch_aten_ + op __name__ lower split str input meta val shape str node kwargs get inplace False pyre-fixme str parent group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_nodes = batch_inputs = batch_inputs_metadata = node subset batch_nodes append node input = get_arg_value node input batch_inputs append input batch_inputs_metadata append input meta val graph inserting_before subset type ignore operator stack_inputs = decompose_stack graph batch_inputs update_stack_example_value stack_inputs batch_inputs_metadata batch_op = graph call_function type ignore operator op args= stack_inputs i node enumerate batch_nodes graph inserting_after batch_op type ignore operator getitem = graph call_function aten select args= batch_op i type ignore operator node replace_all_uses_with getitem getitem meta update node meta graph erase_node node type ignore operator counters inductor batch_aten_ + op __name__ lower split += BatchMathOpsPreGradFusion BatchPointwiseOpsFusionFactory Batch simple match related ops such nan_to_num pre grad pass __init__ op kwargs super __init__ op kwargs op = op match node torch fx Node input = get_arg_value node input CallFunctionVarArgs op match node is_node_meta_valid node check input has same shape its users have same target check all clamp operators have same min max values nan_to_num operators use same default value child = next iter node users keys group_key = str input meta example_value shape + str node kwargs + str child target group_key = None group_key fuse graph torch fx GraphModule subset list torch fx Node batch_nodes = batch_inputs = batch_inputs_metadata = kwargs = subset kwargs node subset batch_nodes append node input = get_arg_value node input batch_inputs append input batch_inputs_metadata append input meta example_value graph inserting_before subset type ignore operator stack_inputs = graph call_function type ignore operator torch stack args= batch_inputs kwargs= dim update_stack_example_value stack_inputs batch_inputs_metadata batch_op = graph call_function type ignore operator op args= stack_inputs kwargs=kwargs batch_op meta example_value = op stack_inputs meta example_value kwargs unbind_op = graph call_function type ignore operator torch unbind args= batch_op kwargs= dim unbind_op meta example_value = torch unbind batch_op meta example_value dim= i node enumerate batch_nodes graph inserting_after unbind_op type ignore operator getitem = graph call_function operator getitem args= unbind_op i type ignore operator node replace_all_uses_with getitem getitem meta update node meta graph erase_node node type ignore operator counters inductor batch_ + op __name__ lower split += register_fusion batch_tanh BatchTanhPreGradFusion BatchPointwiseOpsPreGradFusion __init__ kwargs - None super __init__ torch tanh kwargs register_fusion batch_sigmoid BatchSigmoidPreGradFusion BatchPointwiseOpsPreGradFusion __init__ kwargs - None super __init__ torch sigmoid kwargs register_fusion batch_relu BatchReLuPreGradFusion BatchPointwiseOpsPreGradFusion __init__ kwargs - None super __init__ torch nn functional relu kwargs register_fusion batch_detach BatchDetachPreGradFusion BatchMathOpsPreGradFusion __init__ kwargs super __init__ torch detach kwargs register_fusion batch_nan_to_num BatchNanToNumPreGradFusion BatchMathOpsPreGradFusion __init__ kwargs super __init__ torch nan_to_num kwargs register_fusion batch_clamp BatchClampPreGradFusion BatchMathOpsPreGradFusion __init__ kwargs super __init__ torch clamp kwargs register_fusion batch_dropout BatchDropoutPreGradFusion BatchMathOpsPreGradFusion __init__ kwargs super __init__ torch nn functional dropout kwargs register_fusion batch_aten_tanh pre_grad=False BatchTanhPostGradFusion BatchPointwiseOpsPostGradFusion __init__ kwargs - None super __init__ aten tanh default kwargs register_fusion batch_aten_sigmoid pre_grad=False BatchSigmoidPostGradFusion BatchPointwiseOpsPostGradFusion __init__ kwargs - None super __init__ aten sigmoid default kwargs register_fusion batch_aten_relu pre_grad=False BatchReLuPostGradFusion BatchPointwiseOpsPostGradFusion __init__ kwargs - None super __init__ aten relu default kwargs register_fusion batch_aten_add pre_grad=False BatchAddPostGradFusion BatchPointwiseMathOpsPostGradFusion __init__ kwargs - None super __init__ aten add Tensor kwargs register_fusion batch_aten_sub pre_grad=False BatchSubPostGradFusion BatchPointwiseMathOpsPostGradFusion __init__ kwargs - None super __init__ aten sub Tensor kwargs register_fusion batch_aten_div pre_grad=False BatchDivPostGradFusion BatchPointwiseMathOpsPostGradFusion __init__ kwargs - None super __init__ aten div Tensor kwargs register_fusion batch_aten_mul pre_grad=False BatchMulPostGradFusion BatchPointwiseMathOpsPostGradFusion __init__ kwargs - None super __init__ aten mul Tensor kwargs _OrderedSet __init__ param=None - None param rep = OrderedDict dict fromkeys param rep = OrderedDict __contains__ o - bool o rep __len__ - int rep __len__ append o rep o = None __iter__ rep keys __iter__ find_independent_subset_greedy node_list Iterable torch fx Node graph_search_options dict str Any - Iterator Iterable torch fx Node Yields list subsets ` node_list ` where no element subset depends any other element subset This results set independent nodes which can fused together The order ` node_list ` preserved within each subset so we can benefit split-cat elimination later passes During iteration only safe mutate graph changing nodes have been returned graph_search_options - min_fuse_set_size Minimum size subset consider Subsets below size will ignored - max_fuse_set_size Maximum size subset consider Subsets will broken most size Compute all children ` node ` which members ` interesting_nodes ` find_dependent_nodes node interesting_nodes visited_node_set = OrderedSet torch fx Node dep_set = OrderedSet torch fx Node work = node while work node = work pop input_node node all_input_nodes input_node interesting_nodes dep_set add input_node input_node visited_node_set visited_node_set add input_node work append input_node dep_set min_fuse_set_size = graph_search_options min_fuse_set_size max_fuse_set_size = graph_search_options max_fuse_set_size node_list needs set because we only track nodes left we want do ` ` set list But we want keep correct order node_list = _OrderedSet node_list cache dict torch fx Node OrderedSet torch fx Node = while node_list subset list torch fx Node = subset_deps = OrderedSet torch fx Node next_round_node_list = _OrderedSet node node_list len subset = max_fuse_set_size node subset_deps next_round_node_list append node continue dep_set = cache pop node None dep_set None dep_set = find_dependent_nodes node node_list dep_set intersection subset subset append node subset_deps update dep_set next_round_node_list append node cache node = dep_set len subset = min_fuse_set_size Careful here - caller uses subsets fuse nodes together so we need clear any cache entry contains one returned nodes because dependency list could different larger after merge cache = k v k v cache items v isdisjoint subset yield subset node_list = next_round_node_list get_fusion_candidates rule GroupBatchFusionBase root_node torch fx Node fused_set OrderedSet torch fx Node - collections defaultdict Any list torch fx Node Search fusion candidates specific rule using BFS starting root node We only search subgraph within graph_search_options max_fuse_search_depth q collections deque tuple int torch fx Node = collections deque candidate_dict collections defaultdict Any list torch fx Node = collections defaultdict list root_node target SEARCH_EXCLUSIONS candidate_dict visited_set = OrderedSet torch fx Node next_node root_node all_input_nodes q append next_node visited_set add next_node while len q depth node = q popleft node fused_set continue key = rule match node key None candidate_nodes = candidate_dict key node candidate_nodes candidate_nodes append node depth rule graph_search_options max_fuse_search_depth next_node node all_input_nodes next_node visited_set visited_set add next_node q append depth + next_node candidate_dict apply_group_batch_fusion graph torch fx GraphModule rule GroupBatchFusionBase stable_topological_sort graph type ignore arg-type fused_set = OrderedSet torch fx Node log_to_scuba = False node reversed graph nodes type ignore arg-type candidates = get_fusion_candidates rule node fused_set key candidate_nodes candidates items len candidate_nodes rule graph_search_options min_fuse_set_size continue subset find_independent_subset_greedy candidate_nodes rule graph_search_options rule fuse graph subset fused_set update subset log debug f rule __class__ __name__ key = key subset size = len list subset noqa G log_to_scuba = True log_to_scuba torch fx _lazy_graph_module _LazyGraphModule Force graph re-compile otherwise output python code may broken gm = graph _owning_module isinstance gm _LazyGraphModule _LazyGraphModule recompile assert isinstance gm torch fx GraphModule gm recompile graph_str = gm print_readable print_output=False include_stride=True include_device=True name = f optimus_ str rule __class__ __name__ MTIA name name = f cff_ str rule __class__ __name__ trace_structured artifact metadata_fn=lambda name name encoding string payload_fn=lambda graph_str generate_fusion_from_config config_options dict str Any pre_grad=True fusions list GroupBatchFusionBase = name options config_options items we skip all patterns pattern_matcher passes e g split_cat name PRE_GRAD_FUSIONS name POST_GRAD_FUSIONS continue fusion_cls = PRE_GRAD_FUSIONS name pre_grad POST_GRAD_FUSIONS name _options = graph_search_options copy _options update options fusions append fusion_cls graph_search_options=_options type ignore operator fusions group_batch_fusion_passes graph torch fx Graph pre_grad=True fusions list GroupBatchFusionBase = we keep all current pre grad fusions keep current implementation will remove later pre_grad fusions += generate_fusion_from_config config pre_grad_fusion_options pre_grad=True fbgemm_fusion_keys = x x config post_grad_fusion_options x OPTIMUS_EXCLUDE_POST_GRAD config post_grad_fusion_options x get require_fbgemm False fbgemm_fusions = fusion config post_grad_fusion_options fusion fusion fbgemm_fusion_keys non_fbgemm_fusions = fusion config post_grad_fusion_options fusion fusion config post_grad_fusion_options keys fusion fbgemm_fusion_keys fusions += generate_fusion_from_config non_fbgemm_fusions pre_grad=False has_fbgemm fusions += generate_fusion_from_config fbgemm_fusions pre_grad=False i rule enumerate fusions GraphTransformObserver graph owning_module f group_batch_fusion_ i apply_group_batch_fusion graph rule type ignore arg-type