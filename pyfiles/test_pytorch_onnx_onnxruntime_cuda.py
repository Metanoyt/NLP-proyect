Owner s module onnx unittest onnx_test_common onnxruntime noqa F parameterized onnx_test_common MAX_ONNX_OPSET_VERSION MIN_ONNX_OPSET_VERSION pytorch_test_common skipIfNoBFloat Cuda skipIfNoCuda skipIfUnsupportedMinOpsetVersion skipScriptTest test_pytorch_onnx_onnxruntime _parameterized_class_attrs_and_values torch torch cuda amp autocast torch testing _internal common_utils parameterized parameterized_class _parameterized_class_attrs_and_values MIN_ONNX_OPSET_VERSION MAX_ONNX_OPSET_VERSION class_name_func=onnx_test_common parameterize_class_name TestONNXRuntime_cuda onnx_test_common _TestONNXRuntime skipIfUnsupportedMinOpsetVersion skipIfNoCuda test_gelu_fp GeluModel torch nn Module forward x torch nn functional gelu x x = torch randn requires_grad=True dtype=torch float device=torch device cuda run_test GeluModel x rtol= e- atol= e- skipIfUnsupportedMinOpsetVersion skipIfNoCuda skipScriptTest test_layer_norm_fp LayerNormModel torch nn Module __init__ - None super __init__ layer_norm = torch nn LayerNorm autocast forward x layer_norm x x = torch randn requires_grad=True dtype=torch float device=torch device cuda run_test LayerNormModel cuda x rtol= e- atol= e- skipIfUnsupportedMinOpsetVersion skipIfNoCuda skipScriptTest test_softmaxCrossEntropy_fusion_fp FusionModel torch nn Module __init__ - None super __init__ loss = torch nn NLLLoss reduction= none m = torch nn LogSoftmax dim= autocast forward input target output = loss m input target output N C = input = torch randn N dtype=torch float device=torch device cuda target = torch empty N dtype=torch long device=torch device cuda random_ C using test data containing default ignore_index=- target target == = - run_test FusionModel input target skipIfNoCuda skipScriptTest test_apex_o LinearModel torch nn Module __init__ - None super __init__ linear = torch nn Linear forward x linear x try apex amp except Exception e raise unittest SkipTest Apex available e input = torch randn device=torch device cuda model = amp initialize LinearModel opt_level= O run_test model input ONNX supports bfloat opsets = Add Sub Mul ops don t support bfloat cpu onnxruntime skipIfUnsupportedMinOpsetVersion skipIfNoBFloat Cuda test_arithmetic_bfp MyModule torch nn Module forward x y = torch ones dtype=torch bfloat device=torch device cuda x = x type_as y torch mul torch add x y torch sub x y dtype=torch float x = torch ones requires_grad=True dtype=torch float device=torch device cuda run_test MyModule x rtol= e- atol= e- skipIfNoCuda test_deduplicate_initializers_diff_devices Model torch nn Module __init__ - None super __init__ w = torch nn Parameter torch ones device=torch device cpu b = torch nn Parameter torch ones device=torch device cuda forward x y torch matmul w x y + b x = torch randn device=torch device cpu y = torch randn device=torch device cuda run_test Model x y __name__ == __main__ common_utils run_tests