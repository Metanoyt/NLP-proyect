Owner s module onnx Simple API tests ONNX exporter __future__ annotations io logging os onnxscript BOOL FLOAT opset op torch torch onnx _internal exporter _testing onnx_testing torch testing _internal common_utils SampleModel torch nn Module forward x y = x + z = y relu y z SampleModelTwoInputs torch nn Module forward x b y = x + b z = y relu y z SampleModelReduction torch nn Module forward x x sum SampleModelForDynamicShapes torch nn Module forward x b x relu b sigmoid NestedModelForDynamicShapes torch nn Module forward x torch Tensor ys list torch Tensor zs dict str torch Tensor c torch Tensor y = ys + ys + zs + zs b w = x shape c shape = x + w x + y c x - w x - y c SampleModelForDimOne torch nn Module forward x y z torch cat x y axis= + z TestExportAPIDynamo common_utils TestCase Tests ONNX exporter API when dynamo=True assert_export args strategy str &#124; None = TorchExportNonStrictStrategy kwargs onnx_program = torch onnx export args kwargs dynamo=True fallback=False verbose=False assert onnx_program None onnx_testing assert_onnx_program onnx_program strategy=strategy onnx_program test_args_normalization_with_no_kwargs assert_export SampleModelTwoInputs torch randn torch randn test_lower_opset_support First test opset torchlib opset works onnx_program = assert_export SampleModelReduction torch randn opset_version= assertEqual onnx_program model opset_imports onnx_program = assert_export SampleModelReduction torch randn opset_version= assertEqual onnx_program model opset_imports test_symbolic_argument_user_input_is_supported_by_report_and_call constant_plus_tensor_inputs torch nn Module forward x + torch tensor + x Capture log output log_capture = io StringIO log_handler = logging StreamHandler log_capture log_handler setLevel logging ERROR Get logger used _core py logger = logging getLogger torch onnx _internal exporter _core original_level = logger level logger addHandler log_handler logger setLevel logging ERROR try common_utils TemporaryDirectoryName temp_dir assert_export constant_plus_tensor_inputs torch ones dynamic_shapes= torch export Dim DYNAMIC torch export Dim DYNAMIC report=True artifacts_dir=temp_dir Check expected error logged log_output = log_capture getvalue assertNotIn Failed save report due error log_output assertNotIn KeyError tensor_meta log_output Note We don t call assert_onnx_program here because will fail due input name mismatch issue mentioned your error finally Clean up logging logger removeHandler log_handler logger setLevel original_level test_constant_argument_user_input_is_omitted_in_onnx_graph constant_plus_tensor_inputs torch nn Module forward x + torch tensor + x onnx_program = torch onnx export constant_plus_tensor_inputs torch ones dynamic_shapes= None torch export Dim DYNAMIC dynamo=True assertEqual len onnx_program model graph inputs test_dynamic_axes_enable_dynamic_shapes_with_fully_specified_axes assert_export SampleModelForDynamicShapes torch randn b torch randn dynamic_axes= x customx_dim_ customx_dim_ customx_dim_ b customb_dim_ customb_dim_ customb_dim_ test_dynamic_axes_enable_dynamic_shapes_with_default_axe_names assert_export SampleModelForDynamicShapes torch randn b torch randn dynamic_axes= x b test_dynamic_axes_supports_partial_dynamic_shapes assert_export SampleModelForDynamicShapes torch randn b torch randn input_names= x b dynamic_axes= b test_dynamic_axes_supports_output_names assert_export SampleModelForDynamicShapes torch randn b torch randn input_names= x b dynamic_axes= b assert_export SampleModelForDynamicShapes torch randn torch randn input_names= x b output_names= x_out b_out dynamic_axes= b b_out test_from_dynamic_axes_to_dynamic_shapes_deprecation_warning assertWarnsRegex DeprecationWarning from_dynamic_axes_to_dynamic_shapes deprecated will removed future release This function converts dynamic_axes format \\ including custom axis names\\ dynamic_shapes format Instead relying conversion provide dynamic_shapes directly custom names assert_export SampleModelForDynamicShapes torch randn b torch randn dynamic_axes= x b test_from_dynamic_axes_to_dynamic_shapes_keeps_custom_axis_names model = SampleModelForDynamicShapes input = torch randn b torch randn dynamic_axes = x customx_x_ customx_x_ customx_x_ b customb_b_ customb_b_ customb_b_ x_out customx_out_x_ customx_out_x_ customx_out_x_ b_out customb_out_b_ customb_out_b_ customb_out_b_ onnx_program = torch onnx export model input dynamic_axes=dynamic_axes input_names= x b output_names= x_out b_out dynamo=True Check whether dynamic dimension names preserved assertIs onnx_program model graph inputs shape value customx_x_ assertIs onnx_program model graph inputs shape value customx_x_ assertIs onnx_program model graph inputs shape value customx_x_ assertIs onnx_program model graph inputs shape value customb_b_ assertIs onnx_program model graph inputs shape value customb_b_ assertIs onnx_program model graph inputs shape value customb_b_ test_saved_f_exists_after_export common_utils TemporaryFileName suffix= onnx path _ = torch onnx export SampleModel torch randn path dynamo=True assertTrue os path exists path test_dynamic_shapes_with_fully_specified_axes ep = torch export export SampleModelForDynamicShapes torch randn torch randn dynamic_shapes= x torch export Dim customx_dim_ torch export Dim customx_dim_ torch export Dim customx_dim_ b torch export Dim customb_dim_ torch export Dim customb_dim_ torch export Dim customb_dim_ strict=True assert_export ep strategy=None test_partial_dynamic_shapes assert_export SampleModelForDynamicShapes torch randn torch randn dynamic_shapes= x None b torch export Dim customb_dim_ torch export Dim customb_dim_ torch export Dim customb_dim_ test_dynamic_shapes_supports_nested_input_model_with_input_names_assigned kwargs can still renamed long s order input_names = input_x input_y input_z d e f dynamic_axes = input_x dim input_y dim input_z dim d dim e dim model = NestedModelForDynamicShapes input = torch ones torch zeros torch ones torch zeros b torch ones torch ones assert_export model input dynamic_axes=dynamic_axes input_names=input_names Check whether inputs dynamically shaped onnx_program = torch onnx export model input dynamic_axes=dynamic_axes input_names=input_names dynamo=True assertTrue all input type tensor_type shape dim dim_param input onnx_program model_proto graph input - test_upgraded_torchlib_impl GeluModel torch nn Module forward input Use GELU activation function torch nn functional gelu input approximate= tanh input = torch randn onnx_program_op = torch onnx export GeluModel input opset_version= dynamo=True all_nodes_op = n op_type n onnx_program_op model graph assertIn Tanh all_nodes_op assertNotIn Gelu all_nodes_op onnx_program_op = torch onnx export GeluModel input opset_version= dynamo=True all_nodes_op = n op_type n onnx_program_op model graph assertIn Gelu all_nodes_op test_refine_dynamic_shapes_with_onnx_export NOTE From test export test_export py refine lower upper bound TestRefineDynamicShapeModel torch nn Module forward x y x shape = y shape = x y + inps = torch randn torch randn dynamic_shapes = x torch export Dim dx y torch export Dim dy assert_export TestRefineDynamicShapeModel inps dynamic_shapes=dynamic_shapes test_zero_output_aten_node Model torch nn Module forward x torch ops aten _assert_async msg torch tensor True assertion failed x + x input = torch randn assert_export Model input test_export_successful_when_dynamic_dimension_is_one assert_export SampleModelForDimOne torch randn torch randn torch randn dynamic_shapes= batch sequence batch sequence batch sequence test_is_in_onnx_export Mod torch nn Module forward x f x x sin torch onnx is_in_onnx_export x cos f x assertFalse torch onnx is_in_onnx_export onnx_program = torch onnx export Mod torch randn dynamo=True fallback=False assertFalse torch onnx is_in_onnx_export node_names = n op_type n onnx_program model graph assertIn Sin node_names test_torchscript_exporter_raises_deprecation_warning Test deprecation warning raised when using torchscript exporter assertWarnsRegex DeprecationWarning You using legacy TorchScript-based ONNX export torch onnx export SampleModel torch randn io BytesIO dynamo=False test_model_output_can_be_none ModelWithNoneOutput torch nn Module forward x x + None onnx_program = torch onnx export ModelWithNoneOutput torch randn dynamo=True onnx_testing assert_onnx_program onnx_program TestCustomTranslationTable common_utils TestCase test_custom_translation_table_overrides_ops onnxscript opset op Model torch nn Module forward x y x + y custom_add other Replace add sub op Sub other custom_translation_table = torch ops aten add Tensor custom_add onnx_program = torch onnx export Model torch randn torch randn custom_translation_table=custom_translation_table dynamo=True all_nodes = n op_type n onnx_program model graph assertIn Sub all_nodes assertNotIn Add all_nodes test_custom_translation_table_supports_overloading_ops Model torch nn Module forward x y torch ops aten logical_and default x y custom_add_bool BOOL other BOOL - BOOL Replace add sub op Sub other custom_add FLOAT other FLOAT - FLOAT Replace add mul op Mul other custom_translation_table = torch ops aten logical_and default custom_add custom_add_bool onnx_program = torch onnx export Model torch tensor dtype=torch bool torch tensor dtype=torch bool custom_translation_table=custom_translation_table dynamo=True all_nodes = n op_type n onnx_program model graph The dispatcher should pick correct overload based input types assertIn Sub all_nodes assertNotIn Add all_nodes assertNotIn Mul all_nodes test_custom_translation_table_supports_custom_op_as_target Define custom op use model torch library custom_op custom add mutates_args= custom_add torch Tensor b torch Tensor - torch Tensor + b custom_add register_fake _ torch Tensor b torch Tensor - torch Tensor torch empty_like + torch empty_like b Model torch nn Module forward x y custom_add x y onnx_add FLOAT other FLOAT - FLOAT Replace add Sub op Sub other custom_translation_table = torch ops custom add default onnx_add onnx_program = torch onnx export Model torch tensor dtype=torch bool torch tensor dtype=torch bool custom_translation_table=custom_translation_table dynamo=True all_nodes = n op_type n onnx_program model graph assertIn Sub all_nodes assertNotIn Add all_nodes test_custom_translation_table_supports_custom_op_with_its_decomp torch library _scoped_library mylib FRAGMENT lib torch library define mylib foo Tensor Tensor b - Tensor tags=torch Tag pt _compliant_tag lib=lib torch library impl mylib foo CompositeImplicitAutograd lib=lib torch library register_fake mylib foo foo_impl b + b M torch nn Module forward x y torch ops mylib foo x y onnx_add FLOAT other FLOAT - FLOAT Replace add Sub op Sub other With custom op defined we can use model replace custom translation table custom_translation_table = torch ops mylib foo default onnx_add onnx_program = torch onnx export M torch ones torch ones custom_translation_table=custom_translation_table dynamo=True all_nodes = n op_type n onnx_program model graph assertIn Sub all_nodes assertNotIn Add all_nodes Without custom op defined s going decomposed onnx_program_decomp = torch onnx export M torch ones torch ones dynamo=True all_nodes_decomp = n op_type n onnx_program_decomp model graph assertIn Add all_nodes_decomp assertNotIn Sub all_nodes_decomp test_ _specialization_with_run_decomp_is_supported Phi RMSNorm changes redo shape inference after ` run_decompositions ` call We need test make sure everything we do fx graph covered backed_size_oblivious Phi RMSNorm torch nn Module __init__ hidden_size eps= e- Phi RMSNorm equivalent T LayerNorm super __init__ weight = torch nn Parameter torch ones hidden_size variance_epsilon = eps forward hidden_states input_dtype = hidden_states dtype hidden_states = hidden_states torch float variance = hidden_states pow mean - keepdim=True hidden_states = hidden_states torch rsqrt variance + variance_epsilon weight hidden_states input_dtype op = torch onnx export Phi RMSNorm eval args= kwargs= hidden_states torch rand dynamic_shapes= hidden_states batch_size seq_len dynamo=True batch size fixed assertNotEqual op model graph outputs shape __name__ == __main__ common_utils run_tests