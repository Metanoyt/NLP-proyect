Owner s oncall distributed sys torch torch distributed dist torch distributed checkpoint FileSystemReader FileSystemWriter load save torch distributed fsdp FullyShardedDataParallel FSDP StateDictType torch distributed fsdp fully_sharded_data_parallel FullyShardedDataParallel torch distributed fsdp wrap enable_wrap wrap torch testing _internal common_device_type instantiate_device_type_tests torch testing _internal common_distributed skip_if_lt_x_gpu torch testing _internal common_fsdp FSDPTest SkipModel torch testing _internal common_utils parametrize run_tests TEST_WITH_DEV_DBG_ASAN torch testing _internal distributed checkpoint_utils with_temp_dir dist is_available print Distributed available skipping tests file=sys stderr sys exit TEST_WITH_DEV_DBG_ASAN print Skip dev-asan torch + multiprocessing spawn have known issues file=sys stderr sys exit _DISTRIBUTED_STATE_DICT_IMPLS = StateDictType LOCAL_STATE_DICT StateDictType SHARDED_STATE_DICT TestDistributedCheckpoint FSDPTest property world_size torch accelerator is_available gpu_cnt = torch accelerator device_count gpu_cnt gpu_cnt skip_if_lt_x_gpu with_temp_dir parametrize state_dict_type _DISTRIBUTED_STATE_DICT_IMPLS test_distributed_checkpoint state_dict_type - None enable_wrap wrapper_cls=FSDP torch manual_seed model = wrap SkipModel double_nest=True torch manual_seed new_model = wrap SkipModel double_nest=True FullyShardedDataParallel summon_full_params model FullyShardedDataParallel summon_full_params new_model params = list model parameters new_params = list new_model parameters assertNotEqual params new_params writer = FileSystemWriter temp_dir reader = FileSystemReader temp_dir FSDP state_dict_type model state_dict_type FSDP state_dict_type new_model state_dict_type state_dict = model state_dict save state_dict writer FSDP state_dict_type model state_dict_type FSDP state_dict_type new_model state_dict_type state_dict = new_model state_dict load state_dict reader new_model load_state_dict state_dict FullyShardedDataParallel summon_full_params model FullyShardedDataParallel summon_full_params new_model params = list model parameters new_params = list new_model parameters assertEqual params new_params TODO add resharding test case devices = cuda hpu xpu instantiate_device_type_tests TestDistributedCheckpoint globals only_for=devices allow_xpu=True __name__ == __main__ run_tests