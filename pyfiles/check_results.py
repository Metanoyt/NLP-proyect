copy csv json sys dataclasses dataclass torch _logging scribe scribe dataclass ExpectedFileEntry benchmark_name str metric_name str expected_value int noise_margin float dataclass ResultFileEntry benchmark_name str metric_name str actual_value int replace_with_zeros num Keeps first three digits integer replaces rest zeros Args num int The number modify Returns int The modified number Raises ValueError If input integer Check input integer isinstance num int raise ValueError Input must integer Calculate number digits remove digits_to_remove = len str abs num - Replace digits zeros digits_to_remove modified_num = num digits_to_remove digits_to_remove modified_num = num modified_num main Expected file file have results we comparing against Expected has following format benchmark_name metric name expected value noise margin percentage Example add_loop_eager compile_time_instruction_count noise margin expected_file_path = sys argv Result file file have results current run It has following format benchmark_name metric name expected value noise margin percentage Example add_loop_eager compile_time_instruction_count result_file_path = sys argv A path where new expected results file will written can used replace expected_results csv case failure In case no failure content file will match expected_file_path reference_expected_results_path = sys argv Read expected data file expected_data dict str ExpectedFileEntry = open expected_file_path f reader = csv reader f row reader len row == continue entry = ExpectedFileEntry benchmark_name=row strip metric_name=row strip expected_value=int row noise_margin=float row key = entry benchmark_name entry metric_name assert key expected_data f Duplicate entry key expected_data key = entry Read result data file result_data dict str ResultFileEntry = open result_file_path f reader = csv reader f row reader entry = ResultFileEntry benchmark_name=row strip metric_name=row strip actual_value=int row key = entry benchmark_name entry metric_name assert key result_data f Duplicate entry key result_data key = entry fail = False new_expected = copy deepcopy expected_data key entry expected_data items key result_data print f Missing entry key result file sys exit low = entry expected_value - entry expected_value entry noise_margin high = entry expected_value + entry expected_value entry noise_margin result = result_data key actual_value ratio = float result - entry expected_value entry expected_value log event_name scribe open_source_signpost subsystem= pr_time_benchmarks name=event_name parameters=json dumps benchmark_name entry benchmark_name metric_name entry metric_name actual_value result expected_value entry expected_value noise_margin entry noise_margin change_ratio ratio new_entry = copy deepcopy entry only change abs ratio entry noise_margin new_entry expected_value = replace_with_zeros result abs ratio entry noise_margin entry expected_value new_expected key = new_entry result high fail = True print f REGRESSION benchmark key failed actual result result f ratio f higher than expected entry expected_value ± entry noise_margin + f f expected regression please update expected results \n print please update all results changed significantly only failed ones log fail_regression result low fail = True print f WIN benchmark key failed actual result result ratio + f lower than f expected entry expected_value ± entry noise_margin f f please OPEN THE TEST RESULTS update ALL BENCHMARKS RESULT new printed expected results ALL ALL ALL\n print please update all results changed significantly only failed ones log fail_win print f PASS benchmark key pass actual result result ratio + f within f expected entry expected_value ± entry noise_margin f \n log pass Log all benchmarks do have regression test enabled them key entry result_data items key expected_data print f MISSING REGRESSION TEST benchmark key does have regression test enabled \n scribe open_source_signpost subsystem= pr_time_benchmarks name= missing_regression_test parameters=json dumps benchmark_name entry benchmark_name metric_name entry metric_name open reference_expected_results_path w newline= csvfile writer = csv writer csvfile entry new_expected values Write data CSV file print f entry benchmark_name entry metric_name round entry expected_value entry noise_margin writer writerow entry benchmark_name entry metric_name entry expected_value entry noise_margin Three empty rows merge conflicts writer writerow writer writerow writer writerow print = print = print = print To update expected results run following command print print cat benchmarks dynamo pr_time_benchmarks expected_results csv EOF open reference_expected_results_path f print f read rstrip print EOF print print = print = print = fail print f There some failures you can use new reference expected result stored path f reference_expected_results_path printed above\n print To reproduce locally follow following instructions note absolute instructions count going different than CI hence you might want run locally without your change \n cd benchmarks dynamo pr_time_benchmarks \n python benchmarks BENCHMARK py result csv \n note BENCHMARK py name file containing failing benchmark sys exit print All benchmarks passed __name__ == __main__ main