json os pprint re subprocess requests CONFIGS = dynamo linux-jammy-py -clang test dynamo_wrapped linux xlarge linux-jammy-py -clang test dynamo_wrapped linux xlarge linux-jammy-py -clang test dynamo_wrapped linux xlarge dynamo linux-jammy-py -clang test dynamo_wrapped linux xlarge linux-jammy-py -clang test dynamo_wrapped linux xlarge linux-jammy-py -clang test dynamo_wrapped linux xlarge eager linux-jammy-py -clang test default linux xlarge linux-jammy-py -clang test default linux xlarge linux-jammy-py -clang test default linux xlarge linux-jammy-py -clang test default linux xlarge linux-jammy-py -clang test default linux xlarge download_reports commit_sha configs= dynamo dynamo eager log_dir = tmp_test_reports_ + commit_sha subdir_path config f log_dir config config configs assert config CONFIGS keys config subdir_paths = subdir_path config config configs See which configs we haven t downloaded logs yet missing_configs = config path zip configs subdir_paths os path exists path continue missing_configs append config len missing_configs == print f All required logs appear exist downloading again Run ` rm -rf log_dir ` case subdir_paths output = subprocess check_output gh run list -c commit_sha -w pull -- json databaseId decode workflow_run_id = str json loads output databaseId output = subprocess check_output gh run view workflow_run_id workflow_jobs = parse_workflow_jobs output print found following workflow jobs pprint pprint workflow_jobs Figure out which jobs we need download logs required_jobs = config configs required_jobs extend list CONFIGS config job required_jobs assert job workflow_jobs f job found commit_sha correct has job finished running The GitHub API may take couple minutes update This page lists all artifacts listings = requests get f https hud pytorch org api artifacts s workflow_run_id json download_report job_name subdir job_id = workflow_jobs job_name listing listings name = listing name name startswith test-reports- continue name endswith f _ job_id zip url = listing url subprocess run wget -P subdir url check=True path_to_zip = f subdir name dir_name = path_to_zip - subprocess run unzip path_to_zip -d dir_name check=True raise AssertionError should hit os path exists log_dir os mkdir log_dir config set configs - set missing_configs print f Logs config already exist downloading again Run ` rm -rf subdir_path config ` case config missing_configs subdir = subdir_path config os mkdir subdir job_names = CONFIGS config job_name job_names download_report job_name subdir subdir_paths parse_workflow_jobs output result = lines = output decode split \n line lines match = re search r \S+ \ ID \d+ \ line match None continue result match group = match group result