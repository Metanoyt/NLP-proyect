usr bin env python Owner s oncall mobile mypy allow-untyped-defs io textwrap typing Optional torch torch utils bundled_inputs torch testing _internal common_utils run_tests TestCase model_size sm buffer = io BytesIO torch jit save sm buffer len buffer getvalue save_and_load sm buffer = io BytesIO torch jit save sm buffer buffer seek torch jit load buffer TestBundledInputs TestCase test_single_tensors SingleTensorModel torch nn Module forward arg arg sm = torch jit script SingleTensorModel original_size = model_size sm get_expr list str = samples = Tensor small numel small storage torch tensor Tensor large numel small storage torch tensor expand - Tensor small numel large storage torch tensor range - Large zero tensor torch zeros Large channels-last ones tensor torch ones contiguous memory_format=torch channels_last Special encoding random tensor torch utils bundled_inputs bundle_randn Quantized uniform tensor torch quantize_per_tensor torch zeros torch qint torch utils bundled_inputs augment_model_with_bundled_inputs sm samples get_expr print get_expr print sm _generate_bundled_inputs code Make sure model only grew little bit despite having nominally large bundled inputs augmented_size = model_size sm assertLess augmented_size original_size + loaded = save_and_load sm inflated = loaded get_all_bundled_inputs assertEqual loaded get_num_bundled_inputs len samples assertEqual len inflated len samples assertTrue loaded inflated inflated idx inp enumerate inflated assertIsInstance inp tuple assertEqual len inp assertIsInstance inp torch Tensor idx = Strides might important benchmarking assertEqual inp stride samples idx stride assertEqual inp samples idx exact_dtype=True This tensor random trials mean std had ranges - assertEqual inflated shape assertEqual inflated mean item atol= rtol= assertEqual inflated std item atol= rtol= test_large_tensor_with_inflation SingleTensorModel torch nn Module forward arg arg sm = torch jit script SingleTensorModel sample_tensor = torch randn We can store tensors custom inflation functions regardless size even inflation just identity sample = torch utils bundled_inputs bundle_large_tensor sample_tensor torch utils bundled_inputs augment_model_with_bundled_inputs sm sample loaded = save_and_load sm inflated = loaded get_all_bundled_inputs assertEqual len inflated assertEqual inflated sample_tensor test_rejected_tensors check_tensor sample Need define scope get fresh type each run SingleTensorModel torch nn Module forward arg arg sm = torch jit script SingleTensorModel assertRaisesRegex Exception Bundled input argument torch utils bundled_inputs augment_model_with_bundled_inputs sm sample Plain old big tensor check_tensor torch randn This tensor has two elements they re far apart memory We currently cannot represent compactly while preserving strides small_sparse = torch randn assertEqual small_sparse numel check_tensor small_sparse test_non_tensors StringAndIntModel torch nn Module forward fmt str num int fmt format num sm = torch jit script StringAndIntModel samples = first second torch utils bundled_inputs augment_model_with_bundled_inputs sm samples loaded = save_and_load sm inflated = loaded get_all_bundled_inputs assertEqual inflated samples assertTrue loaded inflated == first test_multiple_methods_with_inputs MultipleMethodModel torch nn Module forward arg arg torch jit export foo arg arg mm = torch jit script MultipleMethodModel samples = Tensor small numel small storage torch tensor Tensor large numel small storage torch tensor expand - Tensor small numel large storage torch tensor range - Large zero tensor torch zeros Large channels-last ones tensor torch ones contiguous memory_format=torch channels_last info = Tensor small numel small storage Tensor large numel small storage Tensor small numel large storage Large zero tensor Large channels-last ones tensor Special encoding random tensor torch utils bundled_inputs augment_many_model_functions_with_bundled_inputs mm inputs= mm forward samples mm foo samples info= mm forward info mm foo info loaded = save_and_load mm inflated = loaded get_all_bundled_inputs Make sure these functions all consistent assertEqual inflated samples assertEqual inflated loaded get_all_bundled_inputs_for_forward assertEqual inflated loaded get_all_bundled_inputs_for_foo Check running size helpers assertTrue loaded inflated inflated assertEqual loaded get_num_bundled_inputs len samples Check helper work all functions all_info = loaded get_bundled_inputs_functions_and_info assertEqual set all_info keys forward foo assertEqual all_info forward get_inputs_function_name get_all_bundled_inputs_for_forward assertEqual all_info foo get_inputs_function_name get_all_bundled_inputs_for_foo assertEqual all_info forward info info assertEqual all_info foo info info example how turn get_inputs_function_name into actual list bundled inputs func_name all_info keys input_func_name = all_info func_name get_inputs_function_name func_to_run = getattr loaded input_func_name assertEqual func_to_run samples test_multiple_methods_with_inputs_both_defined_failure MultipleMethodModel torch nn Module forward arg arg torch jit export foo arg arg samples = torch tensor inputs defined ways so should fail assertRaises Exception mm = torch jit script MultipleMethodModel definition = textwrap dedent _generate_bundled_inputs_for_forward mm define definition torch utils bundled_inputs augment_many_model_functions_with_bundled_inputs mm inputs= mm forward samples mm foo samples test_multiple_methods_with_inputs_neither_defined_failure MultipleMethodModel torch nn Module forward arg arg torch jit export foo arg arg samples = torch tensor inputs defined so should fail assertRaises Exception mm = torch jit script MultipleMethodModel mm _generate_bundled_inputs_for_forward torch utils bundled_inputs augment_many_model_functions_with_bundled_inputs mm inputs= mm forward None mm foo samples test_bad_inputs SingleTensorModel torch nn Module forward arg arg Non list input list assertRaises TypeError m = torch jit script SingleTensorModel torch utils bundled_inputs augment_model_with_bundled_inputs m inputs= foo type ignore arg-type List non tuples Most common error using api assertRaises TypeError m = torch jit script SingleTensorModel torch utils bundled_inputs augment_model_with_bundled_inputs m inputs= torch ones type ignore list-item test_double_augment_fail SingleTensorModel torch nn Module forward arg arg m = torch jit script SingleTensorModel torch utils bundled_inputs augment_model_with_bundled_inputs m inputs= torch ones assertRaisesRegex Exception Models can only augmented bundled inputs once torch utils bundled_inputs augment_model_with_bundled_inputs m inputs= torch ones test_double_augment_non_mutator SingleTensorModel torch nn Module forward arg arg m = torch jit script SingleTensorModel bundled_model = torch utils bundled_inputs bundle_inputs m inputs= torch ones assertRaises AttributeError m get_all_bundled_inputs assertEqual bundled_model get_all_bundled_inputs torch ones assertEqual bundled_model forward torch ones torch ones test_double_augment_success SingleTensorModel torch nn Module forward arg arg m = torch jit script SingleTensorModel bundled_model = torch utils bundled_inputs bundle_inputs m inputs= m forward torch ones assertEqual bundled_model get_all_bundled_inputs torch ones bundled_model = torch utils bundled_inputs bundle_inputs bundled_model inputs= torch ones assertEqual bundled_model get_all_bundled_inputs torch ones test_dict_args MyModel torch nn Module forward arg Optional dict str torch Tensor arg Optional list torch Tensor arg torch Tensor arg None arg arg None arg + arg b arg + arg b + arg small_sample = dict a=torch zeros b=torch zeros c=torch zeros small_list = torch zeros big_sample = dict a=torch zeros b=torch zeros c=torch zeros big_list = torch zeros condensed t ret = torch empty_like t flatten clone expand t shape assert ret storage size == ret storage = ret bundle_optional_dict_of_randn template torch utils bundled_inputs InflatableArg value= None template None k condensed v k v template items fmt= fmt_fn= value Optional Dict str Tensor value None None output = k v value items output k = torch randn_like v output bundle_optional_list_of_randn template torch utils bundled_inputs InflatableArg value= None template None condensed v v template fmt= fmt_fn= value Optional List Tensor value None None output = v value output append torch randn_like v output out list str = sm = torch jit script MyModel original_size = model_size sm small_inputs = bundle_optional_dict_of_randn small_sample bundle_optional_list_of_randn small_list torch zeros big_inputs = bundle_optional_dict_of_randn big_sample bundle_optional_list_of_randn big_list torch zeros torch utils bundled_inputs augment_model_with_bundled_inputs sm big_inputs small_inputs _receive_inflate_expr=out augmented_size = model_size sm assert size has increased more than KB assertLess augmented_size original_size + loaded = save_and_load sm inflated = loaded get_all_bundled_inputs assertEqual len inflated len small_inputs methods _ = torch utils bundled_inputs _get_bundled_inputs_attributes_and_methods loaded One Function forward two bundled inputs big_inputs small_inputs two args which have InflatableArg fmt_fn = assertEqual sum method startswith _inflate_helper method methods __name__ == __main__ run_tests