mypy allow-untyped-defs r Definition DataLoader associated iterators subclass _BaseDataLoaderIter To support these two classes ` _utils ` we define many utility methods functions run multiprocessing E g data loading worker loop ` _utils worker py ` __future__ annotations functools itertools logging multiprocessing python_multiprocessing os queue threading warnings collections abc Callable typing Any Generic Optional TYPE_CHECKING TypeVar Union typing_extensions Self torch torch distributed dist torch utils data graph_settings torch _utils ExceptionWrapper torch utils data _utils torch utils data datapipes datapipe _IterDataPipeSerializationWrapper _MapDataPipeSerializationWrapper IterDataPipe MapDataPipe torch utils data dataset Dataset IterableDataset torch utils data sampler BatchSampler RandomSampler Sampler SequentialSampler TYPE_CHECKING collections abc Iterable __all__ = DataLoader get_worker_info default_collate default_convert _T = TypeVar _T _T_co = TypeVar _T_co covariant=True _worker_init_fn_t = Callable int None Ideally we would parameterize ` DataLoader ` type ` collate_fn ` there currently no way have type parameter set default value user doesn t pass custom collate_fn See https github com python mypy issues _collate_fn_t = Callable list _T Any These functions used defined file However moved _utils collate py Although rather hard access user land one has explicitly directly ` torch utils data dataloader ` there probably user code out there using This aliasing maintains BC aspect default_collate _collate_fn_t = _utils collate default_collate default_convert = _utils collate default_convert get_worker_info = _utils worker get_worker_info logger = logging getLogger __name__ _DatasetKind Map = Iterable = staticmethod create_fetcher kind dataset auto_collation collate_fn drop_last kind == _DatasetKind Map _utils fetch _MapDatasetFetcher dataset auto_collation collate_fn drop_last _utils fetch _IterableDatasetFetcher dataset auto_collation collate_fn drop_last _InfiniteConstantSampler Sampler r Analogous ` ` itertools repeat None None ` ` Used sampler ` ~torch utils data IterableDataset ` __iter__ while True yield None _get_distributed_settings dist is_available dist is_initialized dist get_world_size dist get_rank _sharding_worker_init_fn worker_init_fn world_size rank_id worker_id global_worker_id = worker_id info = torch utils data get_worker_info info None raise AssertionError Worker info None sharding worker init function total_workers = info num_workers datapipe = info dataset isinstance datapipe IterDataPipe MapDataPipe raise AssertionError datapipe must instance IterDataPipe MapDataPipe To distribute elements across distributed process evenly we should shard data distributed processes first then shard worker processes total_workers = world_size global_worker_id = global_worker_id world_size + rank_id For BC use default SHARDING_PRIORITIES torch utils data graph_settings apply_sharding datapipe total_workers global_worker_id worker_init_fn None worker_init_fn worker_id _share_dist_seed generator pg _shared_seed = torch empty dtype=torch int random_ generator=generator isinstance pg dist ProcessGroup dist broadcast _shared_seed src= group=pg _shared_seed item DataLoader Generic _T_co r Data loader combines dataset sampler provides iterable over given dataset The ` ~torch utils data DataLoader ` supports both map-style iterable-style datasets single- multi-process loading customizing loading order optional automatic batching collation memory pinning See py mod ` torch utils data ` documentation page more details Args dataset Dataset dataset which load data batch_size int optional how many samples per batch load default ` ` ` ` shuffle bool optional set ` ` True ` ` have data reshuffled every epoch default ` ` False ` ` sampler Sampler Iterable optional defines strategy draw samples dataset Can any ` ` Iterable ` ` ` ` __len__ ` ` implemented If specified attr ` shuffle ` must specified batch_sampler Sampler Iterable optional like attr ` sampler ` returns batch indices time Mutually exclusive attr ` batch_size ` attr ` shuffle ` attr ` sampler ` attr ` drop_last ` num_workers int optional how many subprocesses use data loading ` ` ` ` means data will loaded main process default ` ` ` ` collate_fn Callable optional merges list samples form mini-batch Tensor s Used when using batched loading map-style dataset pin_memory bool optional If ` ` True ` ` data loader will copy Tensors into device CUDA pinned memory before returning them If your data elements custom type your attr ` collate_fn ` returns batch custom type see example below drop_last bool optional set ` ` True ` ` drop last incomplete batch dataset size divisible batch size If ` ` False ` ` size dataset divisible batch size then last batch will smaller default ` ` False ` ` timeout numeric optional positive timeout value collecting batch workers Should always non-negative default ` ` ` ` worker_init_fn Callable optional If ` ` None ` ` will called each worker subprocess worker id int ` ` num_workers - ` ` input after seeding before data loading default ` ` None ` ` multiprocessing_context str multiprocessing context BaseContext optional If ` ` None ` ` default ` multiprocessing context https docs python org library multiprocessing html#contexts-and-start-methods ` _ noqa D your operating system will used default ` ` None ` ` generator torch Generator optional If ` ` None ` ` RNG will used RandomSampler generate random indexes multiprocessing generate ` ` base_seed ` ` workers default ` ` None ` ` prefetch_factor int optional keyword-only arg Number batches loaded advance each worker ` ` ` ` means there will total num_workers batches prefetched across all workers default value depends set value num_workers If value num_workers= default ` ` None ` ` Otherwise value ` ` num_workers ` ` default ` ` ` ` persistent_workers bool optional If ` ` True ` ` data loader will shut down worker processes after dataset has been consumed once This allows maintain workers ` Dataset ` instances alive default ` ` False ` ` pin_memory_device str optional Deprecated current ref ` accelerator accelerators ` will used device ` ` pin_memory=True ` ` in_order bool optional If ` ` False ` ` data loader will enforce batches returned first-in first-out order Only applies when ` ` num_workers ` ` default ` ` True ` ` warning If ` ` spawn ` ` start method used attr ` worker_init_fn ` cannot unpicklable object e g lambda function See ref ` multiprocessing-best-practices ` more details related multiprocessing PyTorch warning ` ` len dataloader ` ` heuristic based length sampler used When attr ` dataset ` ` ~torch utils data IterableDataset ` instead returns estimate based ` ` len dataset batch_size ` ` proper rounding depending attr ` drop_last ` regardless multi-process loading configurations This represents best guess PyTorch can make because PyTorch trusts user attr ` dataset ` code correctly handling multi-process loading avoid duplicate data However sharding results multiple workers having incomplete last batches estimate can still inaccurate because otherwise complete batch can broken into multiple ones more than one batch worth samples can dropped when attr ` drop_last ` set Unfortunately PyTorch can detect such cases general See ` Dataset Types ` _ more details these two types datasets how ` ~torch utils data IterableDataset ` interacts ` Multi-process data loading ` _ warning See ref ` reproducibility ` ref ` dataloader-workers-random-seed ` ref ` data-loading-randomness ` notes random seed related questions warning Setting ` in_order ` ` False ` can harm reproducibility may lead skewed data distribution being fed trainer cases imbalanced data dataset Dataset _T_co batch_size Optional int num_workers int pin_memory bool drop_last bool timeout float sampler Union Sampler Iterable pin_memory_device str prefetch_factor Optional int _iterator Optional _BaseDataLoaderIter __initialized = False __init__ dataset Dataset _T_co batch_size Optional int = shuffle Optional bool = None sampler Union Sampler Iterable None = None batch_sampler Union Sampler list Iterable list None = None num_workers int = collate_fn Optional _collate_fn_t = None pin_memory bool = False drop_last bool = False timeout float = worker_init_fn Optional _worker_init_fn_t = None multiprocessing_context=None generator=None prefetch_factor Optional int = None persistent_workers bool = False pin_memory_device str = in_order bool = True - None torch _C _log_api_usage_once python data_loader num_workers raise ValueError num_workers option should non-negative use num_workers= disable multiprocessing timeout raise ValueError timeout option should non-negative num_workers == prefetch_factor None raise ValueError prefetch_factor option could only specified multiprocessing let num_workers enable multiprocessing otherwise set prefetch_factor None num_workers prefetch_factor None prefetch_factor = prefetch_factor None prefetch_factor raise ValueError prefetch_factor option should non-negative persistent_workers num_workers == raise ValueError persistent_workers option needs num_workers dataset = dataset num_workers = num_workers prefetch_factor = prefetch_factor pin_memory = pin_memory pin_memory_device = pin_memory_device timeout = timeout worker_init_fn = worker_init_fn multiprocessing_context = multiprocessing_context in_order = in_order Adds forward compatibilities so classic DataLoader can work DataPipes _DataPipeSerializationWrapper container makes easier serialize without redefining pickler isinstance dataset IterDataPipe dataset = _IterDataPipeSerializationWrapper dataset isinstance dataset MapDataPipe dataset = _MapDataPipeSerializationWrapper dataset Arg-check dataset related before checking samplers because we want tell users iterable-style datasets incompatible custom samplers first so they don t learn combo doesn t work after spending time fixing custom sampler errors isinstance dataset IterableDataset _dataset_kind = _DatasetKind Iterable NOTE Custom Samplers IterableDataset ` IterableDataset ` does support custom ` batch_sampler ` ` sampler ` since key irrelevant unless we support generator-style dataset one day For ` sampler ` we always create dummy sampler This infinite sampler even when dataset may have implemented finite ` __len__ ` because multi-process data loading naive settings will duplicated data which may desired thus using sampler length matching dataset will cause data lost you may have duplicates first couple batches never see anything afterwards Therefore ` Iterabledataset ` always uses infinite sampler instance ` _InfiniteConstantSampler ` defined above A custom ` batch_sampler ` essentially only controls batch size However unclear how useful would since iterable-style dataset can handle within itself Moreover pointless multi-process data loading assignment order batches workers implementation detail so users can control how batchify each worker s iterable Thus we disable option If turns out useful future we can re-enable support custom samplers specify assignments specific workers isinstance dataset IterDataPipe shuffle None dataset = torch utils data graph_settings apply_shuffle_settings dataset shuffle=shuffle We cannot check ` shuffle None ` here since previously ` shuffle=False ` default shuffle False None raise ValueError f DataLoader IterableDataset expected unspecified shuffle option got shuffle= shuffle sampler None See NOTE Custom Samplers IterableDataset raise ValueError f DataLoader IterableDataset expected unspecified sampler option got sampler= sampler batch_sampler None See NOTE Custom Samplers IterableDataset raise ValueError DataLoader IterableDataset expected unspecified f batch_sampler option got batch_sampler= batch_sampler shuffle = bool shuffle _dataset_kind = _DatasetKind Map sampler None shuffle raise ValueError sampler option mutually exclusive shuffle batch_sampler None auto_collation custom batch_sampler batch_size = shuffle sampler None drop_last raise ValueError batch_sampler option mutually exclusive batch_size shuffle sampler drop_last batch_size = None drop_last = False batch_size None no auto_collation drop_last raise ValueError batch_size=None option disables auto-batching mutually exclusive drop_last sampler None give default samplers _dataset_kind == _DatasetKind Iterable See NOTE Custom Samplers IterableDataset sampler = _InfiniteConstantSampler map-style shuffle sampler = RandomSampler dataset generator=generator type ignore arg-type sampler = SequentialSampler dataset type ignore arg-type batch_size None batch_sampler None auto_collation without custom batch_sampler batch_sampler = BatchSampler sampler batch_size drop_last batch_size = batch_size drop_last = drop_last sampler = sampler batch_sampler = batch_sampler generator = generator collate_fn None _auto_collation collate_fn = _utils collate default_collate collate_fn = _utils collate default_convert collate_fn = collate_fn persistent_workers = persistent_workers __initialized = True _IterableDataset_len_called = None See NOTE IterableDataset __len__ _iterator = None check_worker_number_rationality torch set_vital Dataloader enabled True type ignore attr-defined _get_iterator - _BaseDataLoaderIter num_workers == _SingleProcessDataLoaderIter check_worker_number_rationality _MultiProcessingDataLoaderIter property multiprocessing_context __multiprocessing_context multiprocessing_context setter multiprocessing_context multiprocessing_context multiprocessing_context None num_workers isinstance multiprocessing_context str valid_start_methods = torch multiprocessing get_all_start_methods multiprocessing_context valid_start_methods raise ValueError multiprocessing_context option f should specify valid start method valid_start_methods r got f multiprocessing_context= multiprocessing_context r multiprocessing_context = torch multiprocessing get_context multiprocessing_context isinstance multiprocessing_context python_multiprocessing context BaseContext raise TypeError multiprocessing_context option should valid context object string specifying start method got f multiprocessing_context= multiprocessing_context raise ValueError multiprocessing_context can only used multi-process loading num_workers got f num_workers= num_workers __multiprocessing_context = multiprocessing_context __setattr__ attr val __initialized attr batch_size batch_sampler sampler drop_last dataset persistent_workers raise ValueError f attr attribute should set after __class__ __name__ initialized super __setattr__ attr val __iter__ - _BaseDataLoaderIter When using single worker returned iterator should created every time avoid resetting its state However case multiple workers iterator iterator only created once lifetime DataLoader object so workers can reused persistent_workers num_workers _iterator None _iterator = _get_iterator _iterator _reset _iterator _get_iterator property _auto_collation batch_sampler None property _index_sampler The actual sampler used generating indices ` _DatasetFetcher ` see _utils fetch py read data each time This would ` batch_sampler ` auto-collation mode ` sampler ` otherwise We can t change ` sampler ` ` batch_sampler ` attributes BC reasons _auto_collation batch_sampler sampler __len__ - int _dataset_kind == _DatasetKind Iterable NOTE IterableDataset __len__ For ` IterableDataset ` ` __len__ ` could inaccurate when one naively does multi-processing data loading since samples will duplicated However no real use case should actually using behavior so should count user error We should generally trust user code do proper thing e g configure each replica differently ` __iter__ ` give us correct ` __len__ ` they choose implement will still throw dataset does implement ` __len__ ` To provide further warning we track ` __len__ ` called ` DataLoader ` save returned value ` _len_called ` warn iterator ends up yielding more than number samples Cannot statically verify dataset Sized length = _IterableDataset_len_called = len dataset type ignore assignment arg-type batch_size None IterableDataset doesn t allow custom sampler batch_sampler math ceil drop_last length = length batch_size length = ceil length batch_size length len _index_sampler check_worker_number_rationality This function check whether dataloader s worker number rational based current system s resource Current rule number workers Dataloader will create bigger than number logical cpus allowed use than we will pop up warning let user pay attention eg If current system has physical CPUs cores each And each core support threads then total logical cpus here = Let s say current DataLoader process can use half them which then rational max number worker initiated process Now let s say created DataLoader has num_works = which bigger than So warning message triggered notify user lower worker number necessary Note Please note function respects ` cpuset ` only when os sched_getaffinity available available most Linux system OSX Windows When os sched_getaffinity available os cpu_count called instead doesn t respect cpuset We don t take threading into account since each worker process single threaded time We don t set any threading flags eg OMP_NUM_THREADS MKL_NUM_THREADS etc other than ` torch set_num_threads ` worker process passing functions use rd party modules rely those threading flags determine how many thread create eg numpy etc then caller s responsibility set those flags correctly _create_warning_msg num_worker_suggest num_worker_created cpuset_checked suggested_max_worker_msg = Our suggested max number worker current system which smaller than what DataLoader going create format num_worker_suggest cpuset_checked ` cpuset ` taken into account num_worker_suggest None DataLoader able compute suggested max number worker current system warn_msg = f This DataLoader will create num_worker_created worker processes total suggested_max_worker_msg Please aware excessive worker creation might get DataLoader running slow even freeze lower worker number avoid potential slowness freeze necessary warn_msg num_workers num_workers == try compute suggested max number worker based system s resource max_num_worker_suggest = None cpuset_checked = False hasattr os sched_getaffinity try max_num_worker_suggest = len os sched_getaffinity cpuset_checked = True except Exception pass max_num_worker_suggest None os cpu_count could Optional int get cpu count first check None order satisfy mypy check cpu_count = os cpu_count cpu_count None max_num_worker_suggest = cpu_count max_num_worker_suggest None warnings warn _create_warning_msg max_num_worker_suggest num_workers cpuset_checked stacklevel= num_workers max_num_worker_suggest warnings warn _create_warning_msg max_num_worker_suggest num_workers cpuset_checked stacklevel= _BaseDataLoaderIter __init__ loader DataLoader - None _dataset = loader dataset _shared_seed = None _pg = None isinstance _dataset IterDataPipe dist is_available dist is_initialized _pg = dist new_group backend= gloo _shared_seed = _share_dist_seed loader generator _pg shared_rng = torch Generator shared_rng manual_seed _shared_seed _dataset = torch utils data graph_settings apply_random_seed _dataset shared_rng _dataset_kind = loader _dataset_kind _IterableDataset_len_called = loader _IterableDataset_len_called _auto_collation = loader _auto_collation _drop_last = loader drop_last _index_sampler = loader _index_sampler _num_workers = loader num_workers ws rank = _get_distributed_settings _world_size = ws _rank = rank loader pin_memory loader pin_memory_device warnings warn pin_memory_device deprecated current accelerator will used device f ignore pin_memory_device= loader pin_memory_device stacklevel= loader pin_memory torch accelerator is_available warn_msg = pin_memory argument set true no accelerator found then device pinned memory won t used warnings warn warn_msg stacklevel= Enabling pin_memory _BaseDataLoaderIter support identical behavior forked implementations using _BaseDataLoaderIter _pin_memory = loader pin_memory torch accelerator is_available Set pin memory device based current accelerator _pin_memory_device = acc type _pin_memory acc = torch accelerator current_accelerator None None Currently pin_memory would raise error MPS backend see https github com pytorch pytorch issues so forcibly disable pin_memory MPS Remove restriction once pinned memory allocation MPS fixed _pin_memory_device == mps _pin_memory = False warn_msg = pin_memory argument set true supported MPS now device pinned memory won t used warnings warn warn_msg stacklevel= _timeout = loader timeout _collate_fn = loader collate_fn _sampler_iter = iter _index_sampler _base_seed = torch empty dtype=torch int random_ generator=loader generator item _persistent_workers = loader persistent_workers _num_yielded = _profile_name = f enumerate DataLoader __class__ __name__ __next__ __iter__ - Self _reset loader first_iter=False _sampler_iter = iter _index_sampler _num_yielded = _IterableDataset_len_called = loader _IterableDataset_len_called isinstance _dataset IterDataPipe _shared_seed = _share_dist_seed loader generator _pg shared_rng = torch Generator shared_rng manual_seed _shared_seed _dataset = torch utils data graph_settings apply_random_seed _dataset shared_rng _next_index next _sampler_iter may raise StopIteration _next_data raise NotImplementedError __next__ - Any torch autograd profiler record_function _profile_name _sampler_iter None TODO https github com pytorch pytorch issues _reset type ignore call-arg data = _next_data _num_yielded += _dataset_kind == _DatasetKind Iterable _IterableDataset_len_called None _num_yielded _IterableDataset_len_called warn_msg = f Length IterableDataset _dataset reported _IterableDataset_len_called f when accessing len dataloader _num_yielded samples have been fetched _num_workers warn_msg += For multiprocessing data-loading could caused properly configuring IterableDataset replica each worker Please see https pytorch org docs stable data html#torch utils data IterableDataset examples warnings warn warn_msg stacklevel= data __len__ - int len _index_sampler __getstate__ TODO add limited pickling support sharing iterator across multiple threads HOGWILD Probably best way do moving sample pushing separate thread then just sharing data queue signalling end tricky without non-blocking API raise NotImplementedError cannot pickled __class__ __name__ _SingleProcessDataLoaderIter _BaseDataLoaderIter __init__ loader super __init__ loader _timeout = raise AssertionError _SingleProcessDataLoaderIter requires timeout == _num_workers = raise AssertionError _SingleProcessDataLoaderIter requires num_workers == Adds forward compatibilities so classic DataLoader can work DataPipes Taking care distributed sharding isinstance _dataset IterDataPipe MapDataPipe For BC use default SHARDING_PRIORITIES torch utils data graph_settings apply_sharding _dataset _world_size _rank _dataset_fetcher = _DatasetKind create_fetcher _dataset_kind _dataset _auto_collation _collate_fn _drop_last _next_data index = _next_index may raise StopIteration data = _dataset_fetcher fetch index may raise StopIteration _pin_memory data = _utils pin_memory pin_memory data _pin_memory_device data _MultiProcessingDataLoaderIter _BaseDataLoaderIter r Iterates once over DataLoader s dataset specified sampler NOTE Data Loader Multiprocessing Shutdown Logic Preliminary Our data model looks like queues indicated curly brackets main process &#124; &#124; &#124; &#124; &#124; index_queue &#124; &#124; &#124; &#124; &#124; worker processes &#124; &#124; DATA &#124; &#124; &#124; worker_result_queue &#124; &#124; FLOW &#124; &#124; &#124; pin_memory_thread main process &#124; &#124; DIRECTION &#124; &#124; &#124; data_queue &#124; &#124; &#124; &#124; &#124; data output \ P S ` worker_result_queue ` ` pin_memory_thread ` part may omitted ` pin_memory=False ` Terminating multiprocessing logic requires very careful design In particular we need make sure The iterator gracefully exits workers when its last reference gone depleted In case workers should gracefully exited because main process may still need continue run we want cleaning up code workers executed e g releasing GPU memory Naturally we implement shutdown logic ` __del__ ` DataLoaderIterator We delay discussion logic case until later The iterator exits workers when loader process worker processes exits normally error We set all workers ` pin_memory_thread ` have ` daemon=True ` You may ask why can t we make workers non-daemonic gracefully exit using same logic we have ` __del__ ` when iterator gets deleted see above First all ` __del__ ` guaranteed called when interpreter exits Even called time executes many Python core library resources may already freed even simple things like acquiring internal lock queue may hang Therefore case we actually need prevent ` __del__ ` being executed rely automatic termination daemonic children Thus we register ` atexit ` hook sets global flag ` _utils python_exit_status ` Since ` atexit ` hooks executed reverse order registration we guaranteed flag set before library resources we use freed which least CPython done via ` atexit ` handler defined ` multiprocessing util py ` https github com python cpython blob c af d cb b fb bb b f b Lib multiprocessing util py#L -L registered when object requiring mechanism first created e g ` mp Queue ` https github com python cpython blob c af d cb b fb bb b f b Lib multiprocessing context py#L -L https github com python cpython blob c af d cb b fb bb b f b Lib multiprocessing queues py#L So ` __del__ ` we check ` _utils python_exit_status ` set ` None ` freed perform no-op so However simply letting library clean-up codes run can also bad because such codes i e ` multiprocessing util _exit_function ` include join putting threads ` mp Queue ` which can blocking Hence main process putting threads called ` cancel_join_thread ` creation See later section b A process won t hang when putting into queue more details Here two example cases where library clean-up codes can run before ` __del__ ` called If we hold onto reference iterator more often than tries do ` multiprocessing ` library cleaning before clearing alive referenced objects https github com pytorch pytorch issues thus prevents our cleaning-up code run first A similar issue araises when ` DataLoader ` used subprocess When process ends shuts all its daemonic children down SIGTERM instead joining them without timeout Similarly threads different mechanism This fact together few implementation details multiprocessing forces us make workers daemonic All our problems arise when DataLoader used subprocess caused multiprocessing code which looks more less like try your_function_using_a_dataloader finally multiprocessing util _exit_function The joining termination mentioned above happens inside ` _exit_function ` Now ` your_function_using_a_dataloader ` throws stack trace stored exception will prevent frame which uses ` DataLoaderIter ` freed If frame has any reference ` DataLoaderIter ` e g method iter its ` __del__ ` which starts shutdown procedure will called That turn means workers aren t notified Attempting join ` _exit_function ` will then result hang For context ` _exit_function ` also registered ` atexit ` call So unclear me ssnl why needed finally block The code dates back there no comment original PEP patch https bugs python org issue containing both finally block ` atexit ` registration explains Finally another choice just shutdown workers logic above whenever we see error ` next ` This isn t ideal because It prevents users using try-catch resume data loading b It doesn t prevent hanging users have references iterator All processes exit any them die unexpectedly fatal signals As shown above workers set daemonic children main process However automatic cleaning-up such child processes only happens parent process exits gracefully e g via fatal signals like SIGKILL So we must ensure each process will exit even process should send receive data killed i e A process won t hang when getting queue Even carefully designed data dependencies i e ` put ` always corresponding ` get ` hanging ` get ` can still happen when data queue corrupted e g due ` cancel_join_thread ` unexpected exit For child exit we set timeout whenever we try get data ` data_queue ` check workers status each timeout error See ` _DataLoaderiter _get_batch ` ` _DataLoaderiter _try_get_data ` details Additionally child exit non-Windows platforms we also register SIGCHLD handler which supported Windows main process which checks any workers fail Python handler This more efficient faster detecting worker failures compared only using above mechanism See ` DataLoader cpp ` ` _utils signal_handling py ` details For ` get ` calls where sender s workers we guard them timeouts check status sender when timeout happens + workers ` _utils worker ManagerWatchdog ` checks status main process + ` pin_memory=True ` when getting ` pin_memory_thread ` check ` pin_memory_thread ` status periodically until ` get ` returns see ` pin_memory_thread ` died b A process won t hang when putting into queue We use ` mp Queue ` which has separate background thread put objects unbounded buffer array The background thread daemonic usually automatically joined when process exits In case receiver has ended abruptly while reading pipe join will hang forever The usual solution Python calling ` q cancel_join_thread ` which prevents automatically joining when finalizing exiting Nonetheless ` cancel_join_thread ` must only called when queue going read write into another process because may hold onto lock leave corrupted data queue leading other readers writers hang Hence + For worker processes we only do so their output queues i e ` worker_result_queue ` before exiting + For ` pin_memory_thread ` its output queue ` data_queue ` ` queue Queue ` does blocking ` put ` queue full So there no above problem result ` _pin_memory_loop ` we do need wrap ` put ` loop breaks only upon success also when main process stops reading i e shutting down + For loader process we ` cancel_join_thread ` all ` _index_queues ` because whole purpose workers ` pin_memory_thread ` serve loader process If loader process already exiting we don t really care queues corrupted Now let s get back how we gracefully exit workers when last reference iterator gone To achieve we implement following logic along design choices mentioned above ` workers_done_event ` A ` multiprocessing Event ` shared among main process all worker processes This used signal workers iterator shutting down After set they will send processed data queues anymore only wait final ` None ` before exiting ` done_event ` isn t strictly needed I e we can just check ` None ` input queue allows us skip wasting resources processing data we already shutting down ` pin_memory_thread_done_event ` A ` threading Event ` similar purpose ` workers_done_event ` ` pin_memory_thread ` The reason separate events needed ` pin_memory_thread ` reads output queue workers But workers upon seeing ` workers_done_event ` set only wants see final ` None ` required flush all data output queue e g may call ` cancel_join_thread ` queue its ` IterableDataset ` iterator happens exhaust coincidentally which out control main process Thus since we will exit ` pin_memory_thread ` before workers see below two separate events used NOTE In short protocol main process will set these ` done_event ` s then corresponding processes threads ` None ` they may exit any time after receiving ` None ` NOTE Using ` None ` final signal valid since normal data will always -tuple st element being index data transferred different dataset index key nd being either dataset key data sample depending which part data model queue worker processes While loader process alive Get ` index_queue ` If get anything Check ` workers_done_event ` If set continue next iteration i e keep getting until see ` None ` then exit Otherwise process data If fetching ` IterableDataset ` iterator exhausted send ` _IterableDatasetStopIteration ` object signal iteration end The main process upon receiving such object will send ` None ` worker use corresponding ` index_queue ` anymore If timed out No matter ` workers_done_event ` set still need see ` None ` must continue next iteration outside loop If ` workers_done_event ` set can False ` IterableDataset ` ` data_queue cancel_join_thread ` Everything ending here main process won t read other workers will also call ` cancel_join_thread ` pin_memory_thread No need check main thread If thread alive main loader thread must alive because thread set daemonic While ` pin_memory_thread_done_event ` set Get ` worker_result_queue ` If timed out continue get next iteration Otherwise process data While ` pin_memory_thread_done_event ` set Put processed data ` data_queue ` ` queue Queue ` blocking put If timed out continue put next iteration Otherwise break i e continuing out loop NOTE we don t check status main thread because process killed fatal signal ` pin_memory_thread ` ends other cases either cleaning-up __del__ automatic exit daemonic thread will take care This won t busy-wait either because ` get timeout ` does busy-wait main process In DataLoader Iter s ` __del__ ` b Exit ` pin_memory_thread ` i Set ` pin_memory_thread_done_event ` ii Put ` None ` ` worker_result_queue ` iii Join ` pin_memory_thread ` iv ` worker_result_queue cancel_join_thread ` c Exit workers i Set ` workers_done_event ` ii Put ` None ` each worker s ` index_queue ` iii Join workers iv Call ` cancel_join_thread ` each worker s ` index_queue ` NOTE c better placed after b because may leave corrupted data ` worker_result_queue ` which ` pin_memory_thread ` reads which case ` pin_memory_thread ` can only happen timing out which slow Nonetheless same thing happens worker killed signal unfortunate times other cases we better off having non-corrupted ` worker_result_queue ` ` pin_memory_thread ` NOTE If ` pin_memory=False ` there no ` pin_memory_thread ` b can omitted NB ` done_event ` s isn t strictly needed E g we can just check ` None ` ` index_queue ` allows us skip wasting resources processing indices already ` index_queue ` we already shutting down __init__ loader super __init__ loader _prefetch_factor = loader prefetch_factor _in_order = loader in_order _num_workers = raise AssertionError num_workers must greater than MultiProcessingDataLoaderIter _prefetch_factor = raise AssertionError prefetch_factor must greater than MultiProcessingDataLoaderIter loader multiprocessing_context None multiprocessing_context = torch multiprocessing multiprocessing_context = loader multiprocessing_context _worker_init_fn = loader worker_init_fn Adds forward compatibilities so classic DataLoader can work DataPipes Additional worker init function will take care sharding MP Distributed isinstance _dataset IterDataPipe MapDataPipe _worker_init_fn = functools partial _sharding_worker_init_fn _worker_init_fn _world_size _rank No certainty which module multiprocessing_context _worker_result_queue = multiprocessing_context Queue type ignore var-annotated _worker_pids_set = False _shutdown = False _workers_done_event = multiprocessing_context Event _index_queues = _workers = i range _num_workers No certainty which module multiprocessing_context index_queue = multiprocessing_context Queue type ignore var-annotated Need ` cancel_join_thread ` here See sections b above index_queue cancel_join_thread w = multiprocessing_context Process target=_utils worker _worker_loop args= _dataset_kind _dataset index_queue _worker_result_queue _workers_done_event _auto_collation _collate_fn _drop_last _base_seed _worker_init_fn i _num_workers _persistent_workers _shared_seed w daemon = True NB Process start actually take some time needs start process pass arguments over via pipe Therefore we only add worker _workers list after started so we do call join program dies before starts __del__ tries join will get AssertionError can only join started process w start _index_queues append index_queue _workers append w _pin_memory _pin_memory_thread_done_event = threading Event Queue type-annotated _data_queue = queue Queue type ignore var-annotated current_device_id = torch accelerator current_device_index pin_memory_thread = threading Thread target=_utils pin_memory _pin_memory_loop args= _worker_result_queue _data_queue current_device_id _pin_memory_thread_done_event _pin_memory_device pin_memory_thread daemon = True pin_memory_thread start Similar workers see comment above we only register pin_memory_thread once started _pin_memory_thread = pin_memory_thread _data_queue = _worker_result_queue type ignore assignment In some rare cases persistent workers daemonic processes would terminated before ` __del__ ` iterator invoked when main process exits It would cause failure when pin_memory_thread tries read corrupted data worker_result_queue atexit used shutdown thread child processes right sequence before main process exits _persistent_workers _pin_memory atexit w _workers atexit register _MultiProcessingDataLoaderIter _clean_up_worker w pid can None only before process spawned case so ignore _utils signal_handling _set_worker_pids id tuple w pid w _workers type ignore misc _utils signal_handling _set_SIGCHLD_handler _worker_pids_set = True _reset loader first_iter=True _reset loader first_iter=False super _reset loader first_iter _send_idx = idx next task sent workers _rcvd_idx = idx next task returned __next__ information about data yet yielded i e tasks w indices range rcvd_idx send_idx map task idx = - worker_id data isn t fetched outstanding \ worker_id data data already fetched out-of-order _task_info = _tasks_outstanding = always equal count v v task_info values len v == A list booleans representing whether each worker still has work do i e having exhausted its iterable dataset object It always contains all ` True ` s using iterable-style dataset i e kind = Iterable Not indicates worker still has work do epoch It does mean worker dead In case ` _persistent_workers ` worker will reset available next epoch _workers_status = True i range _num_workers A list integers representing how many tasks outstanding each worker Incremented when task dispatched worker Decremented when data has been given main thread Each worker should have most _prefetch_factor tasks outstanding _workers_num_tasks = i range _num_workers Reset worker queue cycle so resumes next epoch worker _worker_queue_idx_cycle = itertools cycle range _num_workers We resume prefetching case enabled first_iter idx range _num_workers _index_queues idx put _utils worker _ResumeIteration _shared_seed resume_iteration_cnt = _num_workers while resume_iteration_cnt return_idx return_data = _get_data isinstance return_idx _utils worker _ResumeIteration return_data None raise AssertionError Expected return_data None when resuming iteration resume_iteration_cnt -= prime prefetch loop _ range _prefetch_factor _num_workers _try_put_index _try_get_data timeout=_utils MP_STATUS_CHECK_INTERVAL Tries fetch data ` _data_queue ` once given timeout This can also used inner loop fetching without timeout sender status loop condition This raises ` RuntimeError ` any worker died expectedly This error can come either SIGCHLD handler ` _utils signal_handling py ` only non-Windows platforms manual check below errors timeouts Returns -tuple bool whether successfully get data any data successful None try data = _data_queue get timeout=timeout True data except Exception e At timeout error we manually check whether any worker has failed Note only mechanism Windows detect worker failures failed_workers = worker_id w enumerate _workers _workers_status worker_id w is_alive failed_workers append w _mark_worker_as_unavailable worker_id len failed_workers pids_str = join str w pid w failed_workers raise RuntimeError f DataLoader worker pid s pids_str exited unexpectedly e isinstance e queue Empty False None errno tempfile try Raise exception we close FDs limit Apparently trying open only one file sufficient test See NOTE DataLoader Linux open files limit fds_limit_margin = tempfile NamedTemporaryFile i range fds_limit_margin except OSError e e errno == errno EMFILE raise RuntimeError Too many open files Communication workers no longer possible Please increase limit using ` ulimit -n ` shell change sharing strategy calling ` torch multiprocessing set_sharing_strategy file_system ` beginning your code None raise NOTE DataLoader Linux open files limit On Linux when DataLoader used multiprocessing we pass data between root process workers through SHM files We remove those files filesystem soon they created keep them alive passing around their file descriptors through AF_UNIX sockets See docs source multiprocessing rst Multiprocessing Technical Notes ` wiki https github com pytorch pytorch wiki This sometimes leads us exceeding open files limit When happens offending file descriptor coming over socket ` socket ` Python package silently strips file descriptor message setting only ` MSG_CTRUNC ` flag which might bit misleading since manpage says _indicates some control data discarded due lack space buffer ancillary data_ This might reflect C implementation AF_UNIX sockets This behaviour can reproduced script instructions bottom note When happens standard Python ` multiprocessing ` ` torch multiprocessing ` raises ` RuntimeError received items ancdata ` Sometimes instead FD being stripped you may get ` OSError Too many open files ` both script below DataLoader However rare seems nondeterministic usr bin env python sys socket os array shutil socket len sys argv = print Usage sys argv tmp_dirname iteration send &#124; recv sys exit __name__ == __main__ dirname = sys argv sock_path = dirname + sock iterations = int sys argv dummy_path i dirname + + str i + dummy sys argv == send while os path exists sock_path pass client = socket socket socket AF_UNIX socket SOCK_DGRAM client connect sock_path i range iterations fd = os open dummy_path i os O_WRONLY &#124; os O_CREAT ancdata = array array i fd msg = bytes i print Sending fd fd iteration i client sendmsg msg socket SOL_SOCKET socket SCM_RIGHTS ancdata assert sys argv == recv os path exists dirname raise Exception Directory exists os mkdir dirname print Opening socket server = socket socket socket AF_UNIX socket SOCK_DGRAM server bind sock_path print Listening i range iterations = array array i msg ancdata flags addr = server recvmsg socket CMSG_SPACE itemsize assert len ancdata == cmsg_level cmsg_type cmsg_data = ancdata frombytes cmsg_data print Received fd iteration i shutil rmtree dirname Steps reproduce Run two shells set lower file descriptor limit receiving one shell ulimit -n shell ulimit -n Run script above ` recv ` option first shell shell test_socket py sock_tmp recv Run script ` send ` option second shell shell test_socket py sock_tmp send _get_data Fetches data ` _data_queue ` We check workers status every ` MP_STATUS_CHECK_INTERVAL ` seconds which we achieve running ` _try_get_data timeout=MP_STATUS_CHECK_INTERVAL ` loop This only mechanism detect worker failures Windows For other platforms SIGCHLD handler also used worker failure detection If ` pin_memory=True ` we also need check ` pin_memory_thread ` had died timeouts _timeout success data = _try_get_data _timeout success data raise RuntimeError f DataLoader timed out after _timeout seconds _pin_memory while _pin_memory_thread is_alive success data = _try_get_data success data while condition false i e pin_memory_thread died raise RuntimeError Pin memory thread exited unexpectedly In case ` _data_queue ` ` queue Queue ` But we don t need call ` task_done ` because we don t use ` join ` while True success data = _try_get_data success data _next_data while True If worker responsible ` _rcvd_idx ` has already ended unable fulfill task due exhausting ` IterableDataset ` we try advance ` _rcvd_idx ` find next valid index This part needs run loop because both ` _get_data ` call ` _IterableDatasetStopIteration ` check below can mark extra worker s dead while _rcvd_idx _send_idx info = _task_info get _rcvd_idx None info worker_id = info len info == _workers_status worker_id has data still active break del _task_info _rcvd_idx _rcvd_idx += no valid ` _rcvd_idx ` found i e didn t break _persistent_workers _shutdown_workers raise StopIteration Now ` _rcvd_idx ` batch index we want fetch Check next sample has already been generated len _task_info _rcvd_idx == worker_id data = _task_info pop _rcvd_idx _rcvd_idx += _process_data data worker_id _shutdown _tasks_outstanding = raise AssertionError Invalid iterator state shutdown no outstanding tasks when fetching next data idx data = _get_data _tasks_outstanding -= _dataset_kind == _DatasetKind Iterable Check _IterableDatasetStopIteration isinstance data _utils worker _IterableDatasetStopIteration _persistent_workers _workers_status data worker_id = False _mark_worker_as_unavailable data worker_id _try_put_index continue idx = _rcvd_idx _in_order don t store later process now delete _task_info immediately keeps object size manageable worker_id = _task_info pop idx _process_data data worker_id store out-of-order samples _task_info idx += data worker_id = _task_info pop idx _rcvd_idx += _process_data data worker_id _try_put_index max_tasks = _prefetch_factor _num_workers _tasks_outstanding = max_tasks raise AssertionError Number outstanding tasks exceeded maximum allowed tasks try index = _next_index except StopIteration _ range _num_workers find next active worker any worker_queue_idx = next _worker_queue_idx_cycle _workers_status worker_queue_idx _in_order break _workers_num_tasks worker_queue_idx max_tasks sum _workers_status when _in_order False distribute work worker has capacity _workers_status updated only thread so sum guaranteed break found i e didn t break _index_queues worker_queue_idx put _send_idx index type ignore possibly-undefined _task_info _send_idx = worker_queue_idx _workers_num_tasks worker_queue_idx += _tasks_outstanding += _send_idx += _process_data data worker_idx _workers_num_tasks worker_idx -= _try_put_index isinstance data ExceptionWrapper data reraise data _mark_worker_as_unavailable worker_id shutdown=False Mark worker having finished its work e g due exhausting ` IterableDataset ` This should used only when ` _MultiProcessingDataLoaderIter ` going continue running _workers_status worker_id _persistent_workers shutdown raise AssertionError Worker status inconsistent when marking worker unavailable Signal termination specific worker q = _index_queues worker_id Indicate no more data will put queue current process q put None Note we don t actually join worker here nor do we remove worker s pid C side struct because joining may slow since we don t join worker may still raise error we prefer capturing those rather than ignoring them even though they raised after worker has finished its job Joining deferred ` _shutdown_workers ` which called when all workers finish their jobs e g ` IterableDataset ` replicas when iterator garbage collected _workers_status worker_id = False _workers_done_event is_set = shutdown raise AssertionError _workers_done_event state does match shutdown flag _shutdown_workers Called when shutting down ` _MultiProcessingDataLoaderIter ` See NOTE Data Loader Multiprocessing Shutdown Logic details logic function _utils None _utils python_exit_status True _utils python_exit_status None See note If Python shutting down do no-op Normal exit when last reference gone iterator depleted See second half note _shutdown _shutdown = True try Normal exit when last reference gone iterator depleted See second half note Exit ` pin_memory_thread ` first because exiting workers may leave corrupted data ` worker_result_queue ` which ` pin_memory_thread ` reads hasattr _pin_memory_thread Use hasattr case error happens before we set attribute _pin_memory_thread_done_event set Send something pin_memory_thread case waiting so can wake up check ` pin_memory_thread_done_event ` _worker_result_queue put None None _pin_memory_thread join _worker_result_queue cancel_join_thread _worker_result_queue close Exit workers now _workers_done_event set worker_id range len _workers Get number workers ` len _workers ` instead ` _num_workers ` case we error before starting all workers If we using workers_status persistent_workers we have shut down because worker paused _persistent_workers _workers_status worker_id _mark_worker_as_unavailable worker_id shutdown=True w _workers We should able join here case anything went wrong we set timeout workers fail join they killed ` finally ` block w join timeout=_utils MP_STATUS_CHECK_INTERVAL q _index_queues q cancel_join_thread q close finally Even though all function does putting into queues we have called ` cancel_join_thread ` weird things can happen when worker killed signal e g hanging ` Event set ` So we need guard SIGCHLD handler remove pids C side data structure only end FIXME Unfortunately Windows we missing worker error detection mechanism here function doesn t provide SIGCHLD handler _worker_pids_set _utils signal_handling _remove_worker_pids id _worker_pids_set = False w _workers w is_alive Existing mechanisms try make workers exit peacefully case we unfortunately reach here which we shouldn t e g pytorch pytorch# we kill worker w terminate staticmethod used remove reference ` _MultiProcessingDataLoaderIter ` staticmethod _clean_up_worker w try w join timeout=_utils MP_STATUS_CHECK_INTERVAL finally w is_alive w terminate __del__ _shutdown_workers