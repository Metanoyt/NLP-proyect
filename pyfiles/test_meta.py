Owner s module decompositions ruff noqa F itertools torch os numpy np enum Enum torch overrides resolve_name torch utils _dtype_abbrs dtype_abbrs torch utils _pytree tree_map tree_map_only tree_flatten tree_unflatten torch utils _pytree pytree torch _subclasses meta_utils MetaConverter assert_metadata_eq is_sparse_any torch utils _python_dispatch torch _dispatch python enable_python_dispatcher torch _ops OpOverload OpOverloadPacket torch fx experimental _config exp_config torch testing make_tensor torch testing _internal common_utils unMarkDynamoStrictTest torch testing _internal common_utils TestCase skipIfCrossRef suppress_warnings TEST_WITH_TORCHDYNAMO run_tests parametrize xfailIfTorchDynamo torch testing _internal common_device_type ops instantiate_device_type_tests onlyCUDA onlyCPU OpDTypes torch testing _internal common_methods_invocations binary_ufuncs op_db foreach_unary_op_db foreach_binary_op_db foreach_pointwise_op_db foreach_reduce_op_db foreach_other_op_db torch testing _internal opinfo core S SampleInput torchgen yaml_utils YamlLoader torchgen model OperatorName copy sys yaml atexit re collections defaultdict collections abc Iterable unittest warnings weakref functools partial wraps bf = torch bfloat f = torch float f = torch float f = torch float c = torch complex c = torch complex c = torch complex i = torch int i = torch int i = torch int i = torch int b = torch bool u = torch uint u = torch uint u = torch uint u = torch uint foreach_op_db = foreach_unary_op_db + foreach_binary_op_db + foreach_pointwise_op_db + foreach_reduce_op_db + foreach_other_op_db TestMetaConverter TestCase assertSameVersionCounter m m Cannot easily test m m have same storage due lack Storage bindings Use version counter vc = m _version assertEqual m _version vc Doing way ensures we get VC bump even leaves torch no_grad m _base add_ assertNotEqual m _version vc assertEqual m _version m _version assertMetadataMatches m m assert_metadata_eq assertEqual m m test_view_of_non_leaf x = torch randn requires_grad=True y = x neg z = y z = y to_meta = MetaConverter m = to_meta z m = to_meta z check test actually testing what claims assertTrue m _is_view assertFalse m _base is_leaf assertIsNot m m assertMetadataMatches m z assertMetadataMatches m z assertSameVersionCounter m m test_view_of_leaf x = torch randn requires_grad=True z = x z = x to_meta = MetaConverter m = to_meta z m = to_meta z check test actually testing what claims assertTrue m _is_view assertTrue m _base is_leaf assertIsNot m m assertMetadataMatches m z assertMetadataMatches m z assertSameVersionCounter m m test_view_of_view_of_leaf x = torch randn y = x view y requires_grad = True z = y view to_meta = MetaConverter mx = to_meta x mz = to_meta z assertFalse z is_leaf assertMetadataMatches mx x assertMetadataMatches mz z test_leaf x = torch randn requires_grad=True to_meta = MetaConverter m = to_meta x check test actually testing what claims assertTrue m is_leaf assertTrue m requires_grad assertMetadataMatches m x test_non_leaf x = torch randn requires_grad=True y = x neg to_meta = MetaConverter m = to_meta y check test actually testing what claims assertFalse m is_leaf assertTrue m requires_grad assertMetadataMatches m y test_requires_grad_false x = torch randn requires_grad=False to_meta = MetaConverter m = to_meta x check test actually testing what claims assertFalse m requires_grad assertMetadataMatches m x test_channels_last x = torch empty memory_format=torch channels_last to_meta = MetaConverter m = to_meta x check test actually testing what claims assertTrue m is_leaf assertMetadataMatches m x test_channels_last_leaf x = torch empty memory_format=torch channels_last requires_grad=True to_meta = MetaConverter m = to_meta x check test actually testing what claims assertTrue m requires_grad assertTrue m is_leaf assertMetadataMatches m x test_channels_last_non_leaf x = torch empty memory_format=torch channels_last requires_grad=True y = x + sanity assertEqual x stride y stride assertFalse y is_leaf to_meta = MetaConverter m = to_meta y check test actually testing what claims assertTrue m requires_grad assertFalse m is_leaf assertMetadataMatches m y Check we can autograd m input without erroring see https github com pytorch pytorch issues loss = m sum torch autograd grad loss m test_empty_strided_non_dense_leaf x = torch empty_strided requires_grad=True to_meta = MetaConverter m = to_meta x check test actually testing what claims assertTrue m requires_grad assertTrue m is_leaf assertMetadataMatches m x test_view_mutate x = torch zeros y = x view to_meta = MetaConverter m = to_meta y y add_ torch randn requires_grad=True m add_ torch randn device= meta requires_grad=True test_non_leaf_torture x = torch empty requires_grad=True torch no_grad x set_ x storage to_meta = MetaConverter m = to_meta x check test actually testing what claims assertTrue m requires_grad assertTrue m is_leaf assertMetadataMatches m x NB complex stuff actually exercised right now because we have blanket exclusion complex conversion test_view_as_real x = torch randn dtype=torch complex y = torch view_as_real x m = MetaConverter y assertMetadataMatches m y test_complex_noncontiguous_bug x = torch randn dtype=torch complex m = MetaConverter x assertMetadataMatches m x test_view_as_complex x = torch randn dtype=torch float y = torch view_as_complex x m = MetaConverter y assertMetadataMatches m y test_view_dtype x = torch randn dtype=torch float y = x view dtype=torch int m = MetaConverter y assertMetadataMatches m y test_imag x = torch randn dtype=torch complex y = x imag m = MetaConverter y assertMetadataMatches m y test_inplace_set_storage x = torch tensor dtype=torch int storage = x untyped_storage ssize = storage size meta = torch empty dtype=torch int meta set_ storage assertEqual storage size ssize xfailIfTorchDynamo test_weakref x = torch randn m = MetaConverter y = m x z = m x assertIs y z assertEqual len m tensor_memo assertEqual len m storage_memo assertEqual len m describer lookup_tensor assertEqual len m describer lookup_storage del x Entries Tensor - int get deallocated when real tensor disappears assertEqual len m describer lookup_tensor assertEqual len m describer lookup_storage del y del z int - FakeTensor entries don t die until fake tensors themselves die because user may have held onto int key expecting get consistent fake tensor case assertEqual len m tensor_memo assertEqual len m storage_memo li = r = i range li append torch rand i r append m li - assertEqual len m tensor_memo assertEqual len m storage_memo assertEqual len m describer lookup_tensor assertEqual len m describer lookup_storage del li assertEqual len m describer lookup_tensor assertEqual len m describer lookup_storage del r assertEqual len m tensor_memo assertEqual len m storage_memo xfailIfTorchDynamo test_tensor_outlives_converter m = MetaConverter ref = weakref ref m x = torch randn y = m x del m assertIs ref None aten = torch ops aten CHECK_STRIDES = torch Tensor __getitem__ CHECK_ALL_STRIDES = aten unsqueeze default CHECK_STRIDES_SKIPS = aten _conj_physical default aten _fft_c c default aten _fft_c r default aten _fft_r c default aten _linalg_svd default aten binary_cross_entropy default aten complex default aten polar default aten copysign Tensor aten div Tensor_mode aten floor_divide default aten heaviside default aten lerp Scalar aten lerp Tensor aten logaddexp default aten logical_and default aten logical_or default aten logical_xor default aten pow Scalar aten prelu default aten special_xlog py default aten xlogy Tensor aten nll_loss d_forward default channel_last channel_last_ d related failures aten convolution default following ops fails include_storage_offset = True these bit edge casey we should still fix them leaving them here tracking aten _reshape_alias default repro test_dispatch_symbolic_meta_outplace_all_strides_matmul_cuda_float aten view default repro test_dispatch_symbolic_meta_outplace_all_strides_unflatten_cuda_float CHECK_CONJ_SKIPS = The conj bit copied see https github com pytorch pytorch pull aten linalg_lu_solve out CheckStrides Enum NONE = SIGNIFICANT = ALL = should_check_strides func func CHECK_ALL_STRIDES CheckStrides ALL func CHECK_STRIDES CheckStrides SIGNIFICANT func CHECK_STRIDES_SKIPS CheckStrides NONE isinstance func torch _ops OpOverload CheckStrides NONE Prims expected model strides correctly func namespace == prims CheckStrides SIGNIFICANT Check s view testing any returns have non-empty alias set any r alias_info before_set r func _schema returns r alias_info CheckStrides SIGNIFICANT TODO check TensorIterator CheckStrides SIGNIFICANT assert_ref_meta_equal test_case func meta_rs rs msg_callable flat_meta_rs = pytree tree_leaves meta_rs flat_rs = pytree tree_leaves rs test_case assertEqual len flat_meta_rs len flat_rs i meta_r r zip range len flat_rs flat_meta_rs flat_rs test_assert cond msg cond raise RuntimeError f output i msg_callable msg isinstance r torch Tensor continue test_assert isinstance meta_r torch Tensor f real i th result Tensor test_assert meta_r dtype == r dtype f element i meta_r dtype real dtype r dtype test_assert meta_r shape == r shape f element i meta_r shape real shape r shape See https github com pytorch pytorch issues should_check_strides func == CheckStrides ALL same_strides _ = torch _prims_common check_all_strides meta_r r test_assert same_strides f element i meta_r stride real stride r stride should_check_strides func == CheckStrides SIGNIFICANT same_strides _ = torch _prims_common check_significant_strides meta_r r test_assert same_strides f element i meta_r stride real stride r stride test_assert meta_r storage_offset == r storage_offset f element i meta_r storage_offset real storage_offset r storage_offset test_assert meta_r requires_grad == r requires_grad f element i meta_r requires_grad real requires_grad r requires_grad func CHECK_CONJ_SKIPS test_assert meta_r is_conj == r is_conj f element i meta_r is_conj real is_conj r is_conj test_assert meta_r is_neg == r is_neg f element i meta_r is_neg real is_neg r is_neg This environment variable controls whether we print expected failure lists end test suite run The intended usage looks like Run ` PYTORCH_COLLECT_EXPECT= python test test_meta py ` CUDA build PyTorch has LAPACK MAGMA installed You can filter ` -k test_meta ` ` -k test_dispatch_meta ` only focus one another list Given printed skip xfail list add them corresponding lists torch entries go meta_function aten entries go meta_dispatch If there preexisting entries you need merge entries This somewhat manual typically you shouldn t need do unless you ve made major change e g added new dtype PyTorch need refresh lists If you want do scratch just clear out preexisting lists before running WARNING Python dict literals will silently ignore duplicate keys COLLECT_EXPECT = os getenv PYTORCH_COLLECT_EXPECT == seen_succeeded = seen_failed = failed_reasons = defaultdict set print_seen expected_failures = skips = fmt_dtypes dtypes r = join sorted dtype_abbrs d d dtypes + r + op failed_dtypes seen_failed items ops = resolve_name op succeeded_dtypes = seen_succeeded get op set expected_failures_dtypes = failed_dtypes - succeeded_dtypes skips_dtypes = failed_dtypes succeeded_dtypes reasons = failed_reasons op reasons = + join sorted failed_reasons op expected_failures_dtypes expected_failures append f ops fmt_dtypes expected_failures_dtypes reasons skips_dtypes skips append f ops fmt_dtypes skips_dtypes expected_failures sort skips sort nl = \n print f \ expected_failures = nl join expected_failures skips = nl join skips COLLECT_EXPECT atexit register print_seen Success forces pass failure forces fail skip unconditionally skips testing TestExpect = Enum TestExpect SUCCESS XFAILURE SKIP unlike print produce strides verbose_print e Lit __init__ s s = s __repr__ s go t is_sparse_any t t isinstance t torch Tensor Lit f t stride= t stride t repr tree_map go e run_meta_crossref test_case test_expect func args kwargs dtype device_type run_symbolic_meta bool to_meta = MetaConverter do_meta = test_expect TestExpect SKIP do_meta try meta_args = tree_map to_meta args meta_kwargs = tree_map to_meta kwargs except Exception e raise RuntimeError f failed convert args meta f originally args kwargs e try rs = func args kwargs except Exception e raise AssertionError Original OpInfo broken e TODO also handle cases where func raise exception For now only attempt we managed convert all tensor types any them failed we re mixed device situation isn t well supported do_meta to_meta successful Special cases func torch tensor_split Use original indices_or_sections argument data dependent meta_args = meta_args args + meta_args func torch Tensor __getitem__ Ensure boolean tensors use original assert len args == flat_args = pytree tree_leaves args flat_meta_args spec = tree_flatten meta_args flat_new_args = ma zip flat_args flat_meta_args flat_new_args append isinstance torch Tensor dtype torch int torch bool ma meta_args = meta_args tree_unflatten flat_new_args spec func torch ops aten repeat_interleave Tensor torch ops aten repeat_interleave Tensor_out kwargs get output_size None None meta_args = args func torch ops aten repeat_interleave Tensor_out meta_kwargs out = kwargs out func torch ops aten index Tensor torch ops aten index Tensor_out Don t convert boolean tensors meta they will have nonzero called them indices = meta_index real_index zip meta_args args meta_index None meta_index dtype torch int torch bool indices append real_index indices append meta_index meta_args = meta_args indices func torch nn functional ctc_loss all isinstance args list isinstance args list torch ops aten _ctc_loss IntList has meta kernel torch ops aten _ctc_loss Tensor does test_expect = TestExpect SUCCESS kwargs get device None None meta_kwargs device = meta try Suppress warnings doesn t matter test_meta py does matter you want use decorator cross-ref testing some tests may looking errors warnings catch_warnings warnings simplefilter ignore run_symbolic_meta Run decomps meta kernels registered python dispatcher instead regular dispatcher This should same set kernels fake tensor runs dynamic shapes mode enable_python_dispatcher meta_rs = func meta_args meta_kwargs meta_rs = func meta_args meta_kwargs except Exception e test_expect TestExpect XFAILURE rs seen_failed setdefault func set add dtype isinstance e NotImplementedError m = RE_NOT_IMPLEMENTED_MSG search e args m failed_reasons func add m group COLLECT_EXPECT rs raise RuntimeError f \ failed run resolve_name func verbose_print meta_args verbose_print meta_kwargs e try delim = \n assert_ref_meta_equal test_case func meta_rs rs lambda msg f \ meta disagrees real impl resolve_name func delim join map verbose_print meta_args delim join k + + verbose_print v k v meta_kwargs items = verbose_print meta_rs msg except Exception test_expect TestExpect XFAILURE rs seen_failed setdefault func set add dtype COLLECT_EXPECT rs raise seen_succeeded setdefault func set add dtype test_expect TestExpect XFAILURE COLLECT_EXPECT raise RuntimeError f unexpected success resolve_name func meta_args meta_kwargs rs RE_NOT_IMPLEMENTED_MSG = re compile r Could run ^ + arguments meta_function_expected_failures = torch Tensor to_sparse f i c i i f u c bf b i f torch allclose f f c c bf f torch argwhere f i c i i f u c bf b i f torch combinations f i c i i f u c bf b i f torch corrcoef f i c i i u c bf f i f torch cov f i c i i u c bf i f f torch functional istft f c c f torch geqrf f c c f torch masked_select f i c i i f u c bf b i f torch nonzero f i c i i c f u c bf b i f torch Tensor nonzero f i c i i c f u c bf b i f torch Tensor item f i c i i f u c c bf b i f torch bincount i i u i i torch functional unique f i i u i f bf b i f u u u torch functional unique_consecutive f i i u i f bf b i f u u u torch histogram f f torch histogramdd f f torch nn functional ctc_loss f f torch nn functional gaussian_nll_loss f f bf f torch linalg lstsq f f c c meta_function_expected_failures_conditional = torch repeat_interleave lambda dtype args kwargs isinstance kwargs get repeats None int kwargs get output_size None None This some sample code how we could dump these dicts into YAML file easier reading writing yaml print yaml dump resolve_name k dtype_abbrs d d v k v meta_function_expected_failures items default_flow_style=None sys sys exit meta_function_skips = torch Tensor __rmatmul__ bf c f f f c torch Tensor matmul f f c c torch functional atleast_ d bf i c i u c b f i i f f c torch functional atleast_ d bf i c i u c b f i i f f c torch functional cartesian_prod bf i i u c b f i i f f c torch functional einsum bf c f f f c torch inner f bf i i u c f i f i c torch linalg matrix_norm c f c f torch linalg matrix_rank c c torch linalg svd c c torch matmul bf c f f f c torch nanquantile f f torch narrow bf i i u c b f i i f f c c torch nn functional batch_norm f f torch nn functional binary_cross_entropy bf f f f torch nn functional dropout d bf f f f torch nn functional local_response_norm bf f f f torch svd c c torch take_along_dim bf i i u c b f i i f f c torch vstack bf i c i u c b f i i f f c torch diff b torch equal bf i c i u c b f i i f f c torch nanmean bf f f f c c c torch nn functional cross_entropy bf f f torch nn functional nll_loss bf f f torch linalg cond c c f f torch linalg vecdot bf f f f torch empty bf i c i u c b f i i f f c torch Tensor addbmm_ bf c c f f i i i i u torch nn functional one_hot i meta_function_device_expected_failures = defaultdict dict meta_function_device_expected_failures_only_outplace = defaultdict dict meta_function_device_skips = defaultdict dict meta_function_device_expected_failures cpu = TODO The decomps these batch norm ops different dtypes depending device We should make work better meta tensors torch native_batch_norm bf f torch _native_batch_norm_legit bf f torch ops aten _batch_norm_with_update bf f torch native_layer_norm bf f meta_function_device_expected_failures cuda = torch corrcoef bf f aten _local_scalar_dense torch cov f aten _local_scalar_dense torch functional unique f aten _unique aten unique_dim torch functional unique_consecutive f aten unique_consecutive torch geqrf f f aten geqrf meta_function_device_skips cpu = TODO The decomps these batch norm ops different dtypes depending device We should make work better meta tensors torch native_batch_norm f f torch _native_batch_norm_legit f f torch ops aten _batch_norm_with_update f f meta_function_device_skips cuda = torch inner f torch linalg matrix_rank f f torch linalg svd f f torch nn functional cross_entropy f torch nn functional interpolate f torch nn functional nll_loss f torch svd f f This __torch_function__ mode when enabled interposes every Torch API call runs operator normal then reruns meta inputs then checks everything about output agrees Most logic deals faithfully replicating original tensor meta tensor which nontrivial because there lot subsystems may potentially exercised That being said little overkill what doing test file since I could have just inlined __torch_function__ OpInfo call OpInfos generally have very regular inputs will useful more comprehensive testing e g seen https github com pytorch pytorch pull The big benefit A LOT more efficient torch dispatch mode cost less coverage MetaCrossRefFunctionMode torch overrides TorchFunctionMode test_case TestCase device_type str dtype torch dtype __init__ test_case device dtype inplace test_case = test_case device_type = torch device device type dtype = dtype inplace = inplace __torch_function__ func types args= kwargs=None kwargs = kwargs torch jit is_tracing isinstance func torch ScriptMethod meta converter doesn t work correctly when no_dispatch so skip running crossref test case torch _C _dispatch_tls_local_exclude_set has torch _C DispatchKey Python func args kwargs dtype meta_function_skips get func set test_expect = TestExpect SKIP dtype meta_function_device_skips device_type get func set test_expect = TestExpect SKIP dtype meta_function_expected_failures get func set test_expect = TestExpect XFAILURE dtype meta_function_device_expected_failures device_type get func set test_expect = TestExpect XFAILURE meta_function_expected_failures_conditional get func lambda _ __ False dtype args kwargs test_expect = TestExpect XFAILURE inplace \ dtype meta_function_device_expected_failures_only_outplace device_type get func set test_expect = TestExpect XFAILURE test_expect = TestExpect SUCCESS run_meta_crossref test_case test_expect func args kwargs dtype=self dtype device_type=self device_type run_symbolic_meta=False these always fail meta_dispatch_expected_failures = aten allclose default f bf f f c c NotImplementedError aten _local_scalar_dense aten geqrf default c c f f aten linalg_lstsq default c c f f aten masked_select default c f i f c i bf f i b i u aten masked_select out c f i f c i bf f i b i u aten nonzero default c f i f c i bf f i c b i u aten nonzero out c f i f c i bf f i c b i u aten _to_sparse default c f i f c i bf f i b i u aten _to_sparse sparse_dim c f i f c i bf f i b i u aten _ctc_loss Tensor f f Shape second output depends data aten _histogramdd_bin_edges default f f aten _histogramdd_from_bin_cts default f f aten _histogramdd_from_bin_tensors default f f aten _local_scalar_dense default c c f i f c i bf f i b i u aten _unique default i f i f bf f i b i u u u u aten bincount default i i i i u aten equal default c f i f c i bf f i b i u aten histogram bin_ct f f aten histogram bins_tensor f f aten unique_consecutive default i f i f bf f i b i u u u u aten unique_dim default i f i f bf f i b i u u u u aten upsample_nearest d vec bf f f u these sometimes pass sometimes fail meta_dispatch_skips = aten index Tensor i bf f u b f i f i i c c c nonzero doesn t have Meta function aten _to_copy default i bf f u b f i f i i c c c aten empty memory_format b bf c c c f f f i i i i u aten addbmm_ default bf c c f f i i i i u For CompositeImplicitAutograd functions fail before hitting Mode meta_dispatch_early_skips = set torch Tensor float_power_ Errors out one tests while ProxyTensor passes torch Tensor cumprod_ torch Tensor cumsum_ meta_inplace_skips = set Errors out one tests while ProxyTensor passes torch Tensor cumprod_ torch Tensor cumsum_ meta_dispatch_device_expected_failures = defaultdict dict meta_dispatch_device_skips = defaultdict dict meta_dispatch_device_expected_failures cpu = TODO The decomps these batch norm ops different dtypes depending device We should make work better meta tensors aten native_batch_norm default bf f aten _native_batch_norm_legit default bf f aten _native_batch_norm_legit no_stats bf f aten _batch_norm_with_update default bf f aten native_layer_norm default bf f meta_dispatch_device_expected_failures cuda = aten _unique default f aten _unique aten _use_cudnn_ctc_loss default f f aten _use_cudnn_ctc_loss aten _use_cudnn_ctc_loss Tensor f f aten _use_cudnn_ctc_loss Tensor aten cudnn_grid_sampler default f f f aten cudnn_grid_sampler aten geqrf default f f aten geqrf aten linalg_eigvalsh out f f aten linalg_eigvalsh out aten log_sigmoid_forward default bf f f f aten log_sigmoid_forward output bf f f f aten log_sigmoid_forward output aten unique_consecutive default f aten unique_consecutive aten unique_dim default f aten unique_dim aten upsample_nearest d vec f aten upsample_nearest d vec meta_dispatch_device_skips cpu = aten _embedding_bag_forward_only default bf f f f TODO The decomps these batch norm ops different dtypes depending device We should make work better meta tensors aten native_batch_norm default f f aten _native_batch_norm_legit default f f aten _native_batch_norm_legit no_stats f f aten _batch_norm_with_update default f f If computation dtype different input dtype will fail CPU execution may also have different output other devices aten native_batch_norm out bf f f f meta_dispatch_device_skips cuda = aten _conj default c f file issue aten _linalg_svd default c c aten linalg_eigvalsh out aten cudnn_batch_norm default f f aten log_softmax int c c aten softmax int c c aten softmax int c c ROCm stuff technically should expected failure s worth these should get unified anyway aten miopen_batch_norm default f get_strided_args args get_strided_variants t include_storage_offset=False variants = contiguous variants append t transposed t ndim perm = list reversed range t ndim transposed = torch empty t shape - device=t device dtype=t dtype requires_grad=t requires_grad permute perm copy_ t variants append transposed nondense t ndim nondense = torch repeat_interleave t dim=- variants append nondense channel_last t ndim == variants append t contiguous memory_format=torch channels_last channel_last_ d t ndim == variants append t contiguous memory_format=torch channels_last_ d storage_offset include_storage_offset buffer = torch empty t numel + device=t device dtype=t dtype requires_grad=t requires_grad buffer = buffer as_strided t shape t stride storage_offset= buffer copy_ t variants append buffer variants strided_args = arg args isinstance arg torch Tensor arg is_sparse_csr arg is_contiguous strided_arg_variants = get_strided_variants arg strided_arg_variants = arg strided_args append strided_arg_variants yield itertools product strided_args MetaCrossRefDispatchMode torch utils _python_dispatch TorchDispatchMode test_case TestCase device torch device dtype torch dtype aten_olp_no_out_overload set = set __init__ test_case device dtype symbolic_meta bool inplace bool supports_out bool test_case = test_case save TLS precision = test_case precision rel_tol = test_case rel_tol device_type = torch device device type dtype = dtype symbolic_meta = symbolic_meta inplace = inplace supports_out = supports_out staticmethod try_resolve_aten_out_overload ol args kwargs num_outputs ol_args = ol _schema arguments olp OpOverloadPacket = ol _overloadpacket olp MetaCrossRefDispatchMode aten_olp_no_out_overload None None None candidate_ols = candidate_ol_name olp overloads candidate_ol = getattr olp candidate_ol_name any arg is_out arg candidate_ol _schema arguments candidate_ols append candidate_ol candidate_ols MetaCrossRefDispatchMode aten_olp_no_out_overload add olp None None None Now match based args kwargs number required outputs candidate_ol OpOverload = None candidate_ol candidate_ols candidate_ol_args = candidate_ol _schema arguments len args = len candidate_ol_args continue Positional arguments must have same type all ol_args pos_arg_ind type == candidate_ol_args pos_arg_ind type pos_arg_ind range len args continue Number outputs must match candidate_out_names = out_arg name out_arg candidate_ol_args -num_outputs out_arg is_out len candidate_out_names = num_outputs continue Now try match kwargs Just need ensure remaining kwargs allow out overload called For example we can throw away parameters like ` dtype ` may passed functional version op since ` dtype ` will already present ` out ` argument new_kwargs = kwargs_match = True arg candidate_ol_args len args -num_outputs arg name kwargs arg has_default_value new_kwargs arg name = arg default_value isinstance arg type torch OptionalType isinstance arg type getElementType torch BoolType new_kwargs arg name = False new_kwargs arg name = None kwargs_match = False break new_kwargs arg name = kwargs arg name kwargs_match candidate_ol candidate_out_names new_kwargs None None None _get_expected_test_result func OpOverload dtype meta_dispatch_skips get func set test_expect = TestExpect SKIP dtype meta_dispatch_device_skips device_type get func set test_expect = TestExpect SKIP dtype meta_dispatch_expected_failures get func set test_expect = TestExpect XFAILURE dtype meta_dispatch_device_expected_failures device_type get func set test_expect = TestExpect XFAILURE test_expect = TestExpect SUCCESS test_expect __torch_dispatch__ func types args= kwargs=None kwargs = kwargs test_case precision = precision test_case rel_tol = rel_tol test_expect = _get_expected_test_result func expected = run_meta_crossref test_case test_expect func args kwargs dtype=self dtype device_type=self device_type run_symbolic_meta=self symbolic_meta This test torch ops do have out parameter have aten op overloads have out parameters Additionally Python decompositions may register OpOverloadPacket s so decompositions need tested ensure all OpOverloads still function Meta key e g python decomposition registered aten op aten foo overloads default out python function needs support receiving ` out ` arguments inplace supports_out test_expect == TestExpect SUCCESS torch is_tensor expected isinstance expected Iterable check see there potential out overload num_outputs = torch is_tensor expected len expected func_out_overload out_param_names kwargs = try_resolve_aten_out_overload func args kwargs num_outputs func_out_overload num_outputs == kwargs out_param_names = expected ind out_param_name enumerate out_param_names kwargs out_param_name = expected ind test_expect = _get_expected_test_result func_out_overload run_meta_crossref test_case test_expect func_out_overload args kwargs dtype=self dtype device_type=self device_type run_symbolic_meta=self symbolic_meta expected NB we re running these tests only CUDA because there some inconsistencies between CUDA CPU running CUDA makes easier ignore CPU case when inconsistencies arise Ideally we deal inconsistencies takes time unMarkDynamoStrictTest TestMeta TestCase Copies inputs inplace operations avoid inplace modifications leaves requiring gradient _get_safe_inplace inplace_variant wraps inplace_variant _fn t args kwargs isinstance t list inplace_variant x clone x t args kwargs inplace_variant t clone args kwargs _fn skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_meta_outplace device dtype op _scaled_mm op name raise unittest SkipTest _scaled_mm dose support meta device skip_op_names = fft ihfft fft ihfft linalg lu_solve TEST_WITH_TORCHDYNAMO op name skip_op_names raise unittest SkipTest flaky run OpInfo sample inputs cross-referencing them meta implementation check results same All heavy lifting happens MetaCrossRefFunctionMode func = op get_op samples = op sample_inputs device dtype requires_grad=False sample_input samples args = sample_input input + list sample_input args kwargs = sample_input kwargs MetaCrossRefFunctionMode dtype=dtype device=device inplace=False expected = func args kwargs isinstance expected torch Tensor op supports_out func args kwargs out=expected Special test functions taking device kwarg The crossref tests replacing device meta works This part makes sure _like functions work well meta Tensor their original device argument device kwargs _like op name torch random fork_rng torch manual_seed ref = func args kwargs _like functions take Tensor first argument assert isinstance args torch Tensor torch random fork_rng torch manual_seed args = args device= meta meta = func args kwargs empty_like deterministic op name = empty_like assertEqual ref meta skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_meta_inplace device dtype op func = op get_inplace func skipTest No inplace variable op op promotes_int_to_float dtype is_floating_point skipTest Op promotes float which impossible inplace non-float input func meta_inplace_skips skipTest Skipped func = _get_safe_inplace func samples = op sample_inputs device dtype requires_grad=False sample_input samples sample_input broadcasts_input continue args = sample_input input + list sample_input args kwargs = sample_input kwargs MetaCrossRefFunctionMode dtype=dtype device=device inplace=True expected = func args kwargs _run_dispatch_meta_test device dtype op symbolic_meta inplace all_stride_variants=False _scaled_mm op name raise unittest SkipTest _scaled_mm dose support meta device inplace func = op get_inplace func skipTest No inplace variable op op promotes_int_to_float dtype is_floating_point skipTest Op promotes float which impossible inplace non-float input func = op get_op func meta_dispatch_early_skips skipTest Function dispatch early skips inplace func = _get_safe_inplace func samples = op sample_inputs device dtype requires_grad=False sample_input samples inplace sample_input broadcasts_input continue sample_args = sample_input input + list sample_input args kwargs = sample_input kwargs all_stride_variants sum isinstance arg torch Tensor arg sample_args = test inputs = tensors avoid combinatorial explosion strided_args = get_strided_args sample_args strided_args = sample_args args strided_args MetaCrossRefDispatchMode push dtype=dtype device=device symbolic_meta=symbolic_meta inplace=inplace supports_out=op supports_out expected = func args kwargs inplace isinstance expected torch Tensor op supports_out func args kwargs out=expected skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_dispatch_meta_outplace device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=False inplace=False skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_dispatch_meta_inplace device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=False inplace=True skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_dispatch_symbolic_meta_outplace device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=True inplace=False skipIfCrossRef suppress_warnings ops itertools chain op_db foreach_op_db test_dispatch_symbolic_meta_inplace device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=True inplace=True skipIfCrossRef suppress_warnings only test one dtype output stride behavior same all dtypes ops itertools chain op_db foreach_op_db dtypes=OpDTypes any_common_cpu_cuda_one Only test CUDA CUDA kernel s stride reference onlyCUDA test_dispatch_symbolic_meta_outplace_all_strides device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=True inplace=False all_stride_variants=True skipIfCrossRef suppress_warnings only test one dtype output stride behavior same all dtypes ops itertools chain op_db foreach_op_db dtypes=OpDTypes any_common_cpu_cuda_one Only test CUDA CUDA kernel s stride reference onlyCUDA test_dispatch_symbolic_meta_inplace_all_strides device dtype op _run_dispatch_meta_test device dtype op symbolic_meta=True inplace=True all_stride_variants=True skipIfCrossRef suppress_warnings only test one dtype output stride behavior same all dtypes ops binary_ufuncs allowed_dtypes= torch float Only test CUDA CUDA kernel s stride reference onlyCUDA test_binary_ufuncs_mixed_dtype device dtype op make_arg = partial make_tensor device=device sample_input op device dtype requires_grad kwargs yield SampleInput make_arg S dtype=dtype make_arg S dtype=torch float op = copy copy op op sample_inputs_func = sample_input _run_dispatch_meta_test device dtype op symbolic_meta=True inplace=False test_empty_quantized r = torch empty device= meta dtype=torch qint assertEqual r device type meta test_nan_to_num t = torch tensor float nan float inf -float inf device= meta r = t nan_to_num assertEqual r device type meta test_inplace_masked_fill_error t = torch randn device= meta assertRaisesRegex RuntimeError doesn t match broadcast t masked_fill_ t unsqueeze test_inplace_bin_ops_error t = torch randn device= meta op torch Tensor add_ torch Tensor sub_ torch Tensor mul_ torch Tensor div_ torch Tensor logical_and_ torch Tensor logical_or_ torch Tensor logical_xor_ assertRaisesRegex RuntimeError doesn t match broadcast op t t clone unsqueeze onlyCPU test_meta_autograd_no_error torch library _scoped_library meta_test DEF lib torch library _scoped_library meta_test IMPL CPU impl_cpu torch library _scoped_library meta_test IMPL Meta impl_meta foo_impl x x + lib define foo Tensor - Tensor impl_meta impl foo foo_impl impl_cpu impl foo foo_impl = torch ones device= meta The point test should error We have fallthrough kernel registered AutogradMeta key custom ops so s fine ` foo ` doesn t have autograd kernel b = torch ops meta_test foo default test_huber_loss_backward inps = torch rand device= meta _ range r = torch ops aten huber_loss_backward inps assertEqual r device type meta assertEqual r shape inps shape _norm_backwards_test_helper op args output_mask expected_shapes dtype = torch float device = meta test functional call grads = op args output_mask assertEqualShapes res exp assertIsNone res exp None assertEqual exp res shape assertEqualShapes grads expected_shapes assertEqualShapes grads expected_shapes assertEqualShapes grads expected_shapes out_kwargs = f out i torch empty device=device dtype=dtype i range len output_mask test call out parameters grads = op args output_mask out_kwargs assertEqualShapes res exp assertEqual exp res shape exp None True assertEqualShapes out_kwargs out expected_shapes assertEqualShapes out_kwargs out expected_shapes assertEqualShapes out_kwargs out expected_shapes onlyCPU parametrize output_mask list itertools product True False True False True False test_layer_norm_backward output_mask torch testing _internal common_methods_invocations sample_inputs_layer_norm device = meta dtype = torch float samples = sample_inputs_layer_norm None device dtype requires_grad=False sample samples subTest sample=sample handle optional weight bias len sample args = sample args = sample args None - len sample args grad_out = torch ones_like sample input normalized_shape weight bias = sample args ndims_after_reduction = sample input ndim - len normalized_shape mean_shape = grad_out shape ndims_after_reduction mean = torch zeros mean_shape device=device dtype=dtype rstd = torch zeros mean_shape device=device dtype=dtype expected_shapes = sample input shape output_mask None weight shape output_mask weight None None bias shape output_mask bias None None args = grad_out sample input normalized_shape mean rstd weight bias _norm_backwards_test_helper torch ops aten native_layer_norm_backward args output_mask expected_shapes onlyCPU parametrize output_mask list itertools product True False True False True False test_group_norm_backward output_mask torch testing _internal common_methods_invocations sample_inputs_group_norm input args num_groups kwargs weight bias eps device = meta dtype = torch float samples = sample_inputs_group_norm None device dtype requires_grad=False sample samples subTest sample=sample grad_out = torch ones_like sample input N C = sample input shape HxW = torch prod torch as_tensor sample input shape dtype=torch int item group = sample args mean = torch zeros N group device=device dtype=dtype rstd = torch zeros N group device=device dtype=dtype weight = torch zeros C device=device dtype=dtype args = grad_out sample input mean rstd weight N C HxW group expected_shapes = sample input shape output_mask None weight shape output_mask None weight shape output_mask None test functional call _norm_backwards_test_helper torch ops aten native_group_norm_backward args output_mask expected_shapes onlyCPU parametrize output_mask list itertools product True True False True False test_batch_norm_backward output_mask torch testing _internal common_methods_invocations sample_inputs_batch_norm input args num_groups kwargs weight bias eps device = meta dtype = torch float samples = sample_inputs_batch_norm None device dtype requires_grad=False sample samples subTest sample=sample sample input dim continue grad_out = torch ones_like sample input running_mean running_var weight bias = sample args train = sample kwargs get training True save_mean = torch zeros sample input shape device=device dtype=dtype train None save_invstd = torch zeros sample input shape device=device dtype=dtype train None args = grad_out sample input weight running_mean running_var save_mean save_invstd train sample kwargs get eps e- expected_shapes = sample input shape torch Size sample input shape output_mask None torch Size sample input shape output_mask None _norm_backwards_test_helper torch ops aten native_batch_norm_backward args output_mask expected_shapes test_fill__alias_relationship inps = torch rand device= meta r = torch ops aten fill_ inps aten fill_ returns alias assertEqual id inps id r aten fill returns new tensor r = torch ops aten fill inps assertNotEqual id inps id r test_meta__fused_moving_avg_obs_fq_helper device torch ao quantization FusedMovingAvgObsFakeQuantize to_meta = MetaConverter x = torch randn device=device running_min_op = torch tensor float inf device=device running_max_op = torch tensor float -inf device=device avg_const = scale = torch tensor device=device zero_point = torch tensor dtype=torch int device=device mod = FusedMovingAvgObsFakeQuantize torch ao quantization enable_fake_quant mod torch ao quantization enable_observer mod mod device meta_x = to_meta x args = x mod observer_enabled mod fake_quant_enabled running_min_op running_max_op scale zero_point avg_const meta_args = args copy meta_args = meta_x kwargss = per_row_fake_quant False symmetric_quant False per_row_fake_quant False symmetric_quant True kwargs kwargss ref_out = aten _fused_moving_avg_obs_fq_helper default args kwargs meta_out = aten _fused_moving_avg_obs_fq_helper default meta_args kwargs assertEqual ref_out size meta_out size assertEqual ref_out stride meta_out stride assertEqual ref_out size meta_out size assertEqual ref_out stride meta_out stride test_cdist_forward device to_meta = MetaConverter x = torch rand device=device x = torch rand device=device p = compute_mode None ref = aten _cdist_forward default x x p compute_mode res = aten _cdist_forward default to_meta x to_meta x p compute_mode assertEqual res device type meta assertEqual ref shape res shape test_quantized_embedding_bag tab_shape = emb_size ind_len off_len = tab_shape f_table = torch from_numpy np random random_sample tab_shape + astype np float q_table = torch ops quantized embedding_bag_byte_prepack f_table indices = torch from_numpy np random randint low= high=emb_size size=ind_len int max_length = len indices off_len - max_length max_length = np_lengths = np random randint max_length + size=off_len - astype np int offsets = torch cat torch zeros torch cumsum torch from_numpy np_lengths int eb = torch ops quantized embedding_bag_byte_rowwise_offsets q_table device= meta indices device= meta offsets device= meta mode= sum per_sample_weights=None include_last_offset=True assertEqual eb shape assertEqual eb dtype torch float assertEqual eb untyped_storage data_ptr Tests mean max Can t easily test sum because there fast path sum which causes offset bag get allocated backward function needs offset bag computation lives inside derivatives yaml formula directly so there no way access To test sum need manually compute offset bag parametrize mode test_embedding_bag_dense_backward mode weight = torch randn requires_grad=True indices = torch tensor offsets = torch tensor scale_grad_by_freq = False sparse = False per_sample_weights = None include_last_offset = False padding_idx = - output offset bag bag_size maximum_indices = torch ops aten _embedding_bag default weight indices offsets scale_grad_by_freq mode sparse per_sample_weights include_last_offset padding_idx grad = torch randn_like output Call function example inputs grad_weight = torch ops aten _embedding_bag_dense_backward default grad indices offset bag bag_size maximum_indices weight size scale_grad_by_freq mode per_sample_weights padding_idx meta_grad_weight = torch ops aten _embedding_bag_dense_backward default grad meta indices meta offset bag meta bag_size meta maximum_indices meta weight size scale_grad_by_freq mode per_sample_weights padding_idx assertEqual grad_weight meta meta_grad_weight test_segment_reduce_backward grad = torch ones dtype=torch float output = torch ones dtype=torch float data = torch ones dtype=torch float reduce_str = max lengths = torch ones dtype=torch long out = torch ops aten _segment_reduce_backward grad output data reduce_str lengths=lengths out_meta = torch ops aten _segment_reduce_backward grad device= meta output device= meta data device= meta reduce_str lengths=lengths device= meta assertEqual out shape out_meta shape assertEqual out stride out_meta stride assertEqual out dtype out_meta dtype assertEqual out layout out_meta layout noncontiguous grad = torch ones dtype=torch float data = torch ones dtype=torch float out = torch ops aten _segment_reduce_backward grad output data reduce_str lengths=lengths out_meta = torch ops aten _segment_reduce_backward grad device= meta output device= meta data device= meta reduce_str lengths=lengths device= meta assertEqual out shape out_meta shape assertEqual out stride out_meta stride assertEqual out dtype out_meta dtype assertEqual out layout out_meta layout test_embedding_bag_dense_backward_per_sample_weights weight = torch randn requires_grad=True indices = torch tensor offsets = torch tensor scale_grad_by_freq = False sparse = False mode = per_sample_weights = torch randn requires_grad=True include_last_offset = False padding_idx = - output offset bag bag_size maximum_indices = torch ops aten _embedding_bag default weight indices offsets scale_grad_by_freq mode sparse per_sample_weights include_last_offset padding_idx grad = torch randn_like output Call function example inputs grad_weight = torch ops aten _embedding_bag_per_sample_weights_backward default grad weight indices offsets offset bag mode padding_idx meta_grad_weight = torch ops aten _embedding_bag_per_sample_weights_backward default grad meta weight meta indices meta offsets meta offset bag meta mode padding_idx assertEqual grad_weight meta meta_grad_weight opinfo test using aten fill_ s testing aten fill onlyCUDA test_fill_stride to_meta = MetaConverter sample_args = torch rand args get_strided_args sample_args meta_args = to_meta args ref_out = torch ops aten fill args meta_out = torch ops aten fill meta_args assertEqual ref_out size meta_out size assertEqual ref_out stride meta_out stride test_map_location_deserialize io t = torch rand b = io BytesIO torch save t b b seek r = torch load b map_location=torch device meta assertEqual r device type meta assertEqual r shape t shape assertEqual r dtype t dtype assertEqual r storage data_ptr test_embedding_bag_byte_prepack batch_size = num_embeddings = embedding_dim = res_shape = batch_size num_embeddings ed + ed embedding_dim ed rs zip embedding_dim res_shape weight = torch randn batch_size num_embeddings ed dtype=torch float res = torch ops quantized embedding_bag_byte_prepack weight device= meta assertEqual res shape rs assertEqual res dtype torch float assertEqual res untyped_storage data_ptr test_embedding_bag_byte_unpack batch_size = num_embeddings = embedding_dim = res_shape = batch_size num_embeddings ed ed embedding_dim ed rs zip embedding_dim res_shape packed_weight = torch randn batch_size num_embeddings ed + dtype=torch float res = torch ops quantized embedding_bag_byte_unpack packed_weight device= meta assertEqual res shape rs assertEqual res dtype torch float assertEqual res untyped_storage data_ptr test_index_select_out f input = torch randn device= meta index = torch tensor device= meta out = torch empty device= meta torch index_select input=input dim= index=index out=out enable_python_dispatcher out = f assertEqual out shape test_local_scalar_dense_call assertRaisesRegex RuntimeError cannot called meta tensors meta_tensor = torch randn device= meta meta_tensor item test_triangular_solve_out Get what s expected output given example A = torch randn triu b = torch randn out = torch triangular_solve b A Call function again transforming every tensor input including out tensor into meta tensor meta_out = tree_map_only torch Tensor lambda t t meta out torch triangular_solve b meta A meta out=meta_out assertEqual out shape meta_out shape assertEqual out dtype meta_out dtype assertEqual out shape meta_out shape assertEqual out dtype meta_out dtype test_meta_consistency_out_dtype_mismatch_pow_Tensor_Scalar S = run device = torch rand S device=device dtype=torch float b = out = torch empty S device=device dtype=torch float try torch pow b out=out except Exception e e cpu_err = run cpu meta_err = run meta cpu_err None meta_err None raise RuntimeError cpu didn t fail meta did meta_err cpu_err None meta_err None raise RuntimeError cpu failed meta didn t cpu_err test_nonzero t = torch randn device= meta exp_config patch meta_nonzero_assume_all_nonzero=True nz = t nonzero assertEqual nz dtype torch int assertEqual nz device type meta assertEqual nz shape torch Size assertEqual nz stride torch Size test_stride_for_index_Tensor torch _subclasses FakeTensorMode x = torch randn memory_format=torch channels_last x = x view i = torch arange unsqueeze - i = torch argsort torch rand dim=- out = x i i mode = FakeTensorMode mode f_x = mode from_tensor x f_i = mode from_tensor i f_i = mode from_tensor i f_out = f_x f_i f_i assertEqual out stride f_out stride parametrize in_dtype torch float torch float parametrize bias_dtype torch float torch float None test_mixed_dtype_for_native_layer_norm_backward in_dtype bias_dtype in_dtype == torch float bias_dtype == torch float skipTest f supported input dtype in_dtype bias dtype bias_dtype device = meta fn input weight bias need_grad_input outputs = torch nn functional layer_norm input input shape - weight bias grad_outs = torch ones_like outputs grad_ins = torch autograd grad outputs need_grad_input grad_outs grad_ins input = torch randn dtype=in_dtype device=device requires_grad=True need_grad_input = input bias_dtype weight = torch randn dtype=bias_dtype device=device requires_grad=True bias = torch randn dtype=bias_dtype device=device requires_grad=True need_grad_input append weight need_grad_input append bias weight = None bias = None outs = fn input weight bias need_grad_input out_dtype = t dtype t outs bias_dtype assertEqual out_dtype in_dtype bias_dtype bias_dtype assertEqual out_dtype in_dtype instantiate_device_type_tests TestMeta globals print_op_str_if_not_supported op_str op = OperatorName parse op_str packet = getattr torch ops aten str op name overload = getattr packet op overload_name op overload_name default any overload d d meta_dispatch_skips meta_dispatch_device_skips cuda print f overload SKIP any overload d d meta_dispatch_expected_failures meta_dispatch_device_expected_failures cuda print overload __name__ == __main__ COMPARE_XLA = os getenv PYTORCH_COMPARE_XLA None COMPARE_XLA None open COMPARE_XLA f d = yaml load f Loader=YamlLoader ops = d get full_codegen + d get supported + d get autograd op_str ops print_op_str_if_not_supported op_str sys exit COMPARE_TEXT = os getenv PYTORCH_COMPARE_TEXT None COMPARE_TEXT None open COMPARE_TEXT f op_str f print_op_str_if_not_supported op_str strip sys exit run_tests