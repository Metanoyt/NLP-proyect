mypy allow-untyped-defs typing Optional torch torch nn nn torch ao pruning sparsifier utils fqn_to_module module_to_fqn SUPPORTED_MODULES = nn Embedding nn EmbeddingBag _fetch_all_embeddings model Fetches Embedding EmbeddingBag modules model embedding_modules = stack = model while stack module = stack pop _ child module named_children fqn_name = module_to_fqn model child type child SUPPORTED_MODULES embedding_modules append fqn_name child stack append child embedding_modules post_training_sparse_quantize model data_sparsifier_class sparsify_first=True select_embeddings Optional list nn Module = None sparse_config Takes model applies sparsification quantization only embeddings embeddingbags The quantization step can happen before after sparsification depending ` sparsify_first ` argument Args - model nn Module model whose embeddings needs sparsified - data_sparsifier_class type data sparsifier Type sparsification needs applied model - sparsify_first bool true sparsifies first then quantizes otherwise quantizes first then sparsifies - select_embeddings List Embedding modules List embedding modules model sparsified quantized If None all embedding modules sparsified - sparse_config Dict config will passed constructor data sparsifier object Note When ` sparsify_first=False ` quantization occurs first followed sparsification - before sparsifying embedding layers dequantized - scales zero-points saved - embedding layers sparsified ` squash_mask ` applied - embedding weights requantized using saved scales zero-points When ` sparsify_first=True ` sparsification occurs first followed quantization - embeddings sparsified first - quantization applied sparsified embeddings data_sparsifier = data_sparsifier_class sparse_config select_embeddings None perform all embeddings select_embeddings None embedding_modules = _fetch_all_embeddings model embedding_modules = isinstance select_embeddings list raise AssertionError embedding_modules must list embedding modules emb select_embeddings type emb SUPPORTED_MODULES raise AssertionError embedding_modules list must embedding embedding bags fqn_name = module_to_fqn model emb fqn_name None raise AssertionError embedding modules must part input model embedding_modules append fqn_name emb sparsify_first sparsify name emb_module embedding_modules valid_name = name replace _ data_sparsifier add_data name=valid_name data=emb_module data_sparsifier step data_sparsifier squash_mask quantize _ emb_module embedding_modules emb_module qconfig = torch ao quantization float_qparams_weight_only_qconfig torch ao quantization prepare model inplace=True torch ao quantization convert model inplace=True quantize _ emb_module embedding_modules emb_module qconfig = torch ao quantization float_qparams_weight_only_qconfig torch ao quantization prepare model inplace=True torch ao quantization convert model inplace=True retrieve scale zero_points quantize_params dict str dict = scales zero_points dequant_weights axis dtype name _ embedding_modules quantized_emb = fqn_to_module model name quantized_emb None raise AssertionError f quantized embedding name found model quantized_weight = quantized_emb weight type ignore operator quantize_params scales name = quantized_weight q_per_channel_scales quantize_params zero_points name = quantized_weight q_per_channel_zero_points quantize_params dequant_weights name = torch dequantize quantized_weight quantize_params axis name = quantized_weight q_per_channel_axis quantize_params dtype name = quantized_weight dtype attach data sparsifier data_sparsifier add_data name=name replace _ data=quantize_params dequant_weights name data_sparsifier step data_sparsifier squash_mask name _ embedding_modules quantized_emb = fqn_to_module model name quantized_emb None raise AssertionError f quantized embedding name found model requantized_vector = torch quantize_per_channel quantize_params dequant_weights name scales=quantize_params scales name zero_points=quantize_params zero_points name dtype=quantize_params dtype name axis=quantize_params axis name quantized_emb set_weight requantized_vector type ignore operator