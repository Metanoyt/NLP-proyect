Owner s oncall pt functools itertools os sys textwrap unittest torch torch _inductor async_compile noqa F required warm up AsyncCompile pools torch _dynamo testing make_test_cls_with_patches torch _inductor config torch _inductor codecache HalideCodeCache torch _inductor runtime hints HalideInputSpec HalideMeta torch _inductor test_case run_tests TestCase torch _inductor utils parallel_num_threads run_and_get_code torch testing _internal common_utils IS_CI IS_MACOS IS_WINDOWS torch testing _internal inductor_utils HAS_CPU torch utils _triton has_triton IS_WINDOWS IS_CI sys stderr write Windows CI does have necessary dependencies test_torchinductor_dynamic_shapes yet\n __name__ == __main__ sys exit raise unittest SkipTest requires sympy functorch filelock try halide manual HAS_HALIDE = halide None except ImportError HAS_HALIDE = False try test_torchinductor except ImportError test_torchinductor manual=fbcode caffe test inductor test_inductor-library test_classes = make_halide cls suffix = _halide cls_prefix = Halide test_class = make_test_cls_with_patches cls cls_prefix suffix config halide scan_kernels True config cpu_backend halide config cuda_backend halide xfail_prop= _expected_failure_halide test_classes test_class __name__ = test_class REMOVING THIS LINE WILL STOP TESTS FROM RUNNING globals test_class __name__ = test_class test_class __module__ = __name__ test_class unittest skipUnless HAS_HALIDE requires halide HalideTests TestCase test_codecache fn = HalideCodeCache generate_halide HalideMeta argtypes= HalideInputSpec ctype= float name= in_ptr shape= L stride= L offset= HalideInputSpec ctype= float name= in_ptr shape= L stride= L offset= HalideInputSpec ctype= float name= out_ptr shape= L stride= L offset= target= host-no_runtime scheduler= Mullapudi scheduler_flags= parallelism parallel_num_threads textwrap dedent halide hl hl generator name= kernel Kernel in_ptr = hl InputBuffer hl Float in_ptr = hl InputBuffer hl Float out_ptr = hl OutputBuffer hl Float generate g in_ptr = g in_ptr in_ptr = g in_ptr out_ptr = g out_ptr xindex = hl Var xindex x = xindex tmp = hl Func tmp xindex = in_ptr x tmp = hl Func tmp xindex = in_ptr x tmp = hl Func tmp xindex = tmp xindex + tmp xindex out_ptr x = tmp xindex assert g using_autoscheduler in_ptr set_estimates hl Range in_ptr set_estimates hl Range out_ptr set_estimates hl Range __name__ == __main__ hl main = torch randn b = torch randn c = torch randn fn b c assertEqual c + b test_manual_schedule fn = HalideCodeCache generate_halide HalideMeta argtypes= HalideInputSpec ctype= float name= in_ptr shape= L stride= L offset= HalideInputSpec ctype= float name= in_ptr shape= L stride= L offset= HalideInputSpec ctype= float name= out_ptr shape= L stride= L offset= target= host-no_runtime scheduler=None textwrap dedent halide hl hl generator name= kernel Kernel in_ptr = hl InputBuffer hl Float in_ptr = hl InputBuffer hl Float out_ptr = hl OutputBuffer hl Float generate g in_ptr = g in_ptr in_ptr = g in_ptr out_ptr = g out_ptr xindex = hl Var xindex x = xindex tmp = hl Func tmp xindex = in_ptr x tmp = hl Func tmp xindex = in_ptr x tmp = hl Func tmp xindex = tmp xindex + tmp xindex out_ptr x = tmp xindex assert g using_autoscheduler i = hl Var j = hl Var out_ptr compute_root out_ptr split xindex i j out_ptr parallel i out_ptr vectorize j tmp compute_at out_ptr i tmp store_at out_ptr i tmp compute_inline __name__ == __main__ hl main = torch randn b = torch randn c = torch randn fn b c assertEqual c + b unittest skipUnless has_triton requires triton test_random_consistency seed = shape = dtype = torch float rand_fn itertools product functools partial torch rand shape dtype=dtype device= cuda functools partial torch randn shape dtype=dtype device= cuda functools partial torch randint - size=shape dtype=torch int device= cuda torch compile backend= inductor options= cuda_backend halide get_rand_halide rand_fn torch compile backend= inductor options= cuda_backend triton get_rand_triton rand_fn torch manual_seed seed halide_output = get_rand_halide torch manual_seed seed triton_output = get_rand_triton assertEqual halide_output triton_output test_compile_options torch compile backend= inductor options= cuda_backend halide cpu_backend halide halide scheduler_cuda Anderson halide scheduler_cpu Adams halide b torch softmax - + torch softmax b - _ code = run_and_get_code halide torch randn torch randn assertIn hl generator code torch cuda is_available _ code = run_and_get_code halide torch randn device= cuda torch randn device= cuda assertIn hl generator code test_torchinductor HAS_CPU HAS_HALIDE make_halide test_torchinductor SweepInputsCpuTest make_halide test_torchinductor CpuTests test_torchinductor HAS_GPU HAS_HALIDE os environ get TEST_HALIDE_GPU == make_halide test_torchinductor SweepInputsGPUTest make_halide test_torchinductor GPUTests __name__ == __main__ HAS_CPU IS_MACOS HAS_HALIDE run_tests needs= filelock