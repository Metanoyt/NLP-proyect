Owner s oncall distributed os unittest torch torch nn nn torch distributed _tools MemoryTracker torch testing _internal common_utils run_tests TestCase TestMemoryTracker TestCase unittest skipIf torch accelerator is_available no accelerator test_local_model Minimal test case check memory tracker can collect expected memory stats operator level well can print summary result without crash device = torch accelerator current_accelerator Create model hierarchy modules torch manual_seed model = nn Sequential nn Sequential nn Conv d kernel_size= padding= bias=False nn BatchNorm d nn ReLU inplace=False nn AdaptiveAvgPool d output_size= nn Flatten start_dim= nn Sequential nn Linear nn ReLU inplace=True device Run one iteration forward backward pass tracker = MemoryTracker tracker start_monitor model x = torch randn size= device=device torch LongTensor expects cpu device type gpu device type constructor so calling outside constructor here target = torch LongTensor device criterion = nn CrossEntropyLoss criterion model x target backward assertTrue len tracker _hooks tracker stop assertTrue len tracker _hooks == path = memory trace tracker save_stats path tracker load path tracker summary os path exists path os remove path assertTrue tracker _op_index assertTrue len tracker _operator_names assertEqual len tracker memories_allocated tracker _op_index assertEqual len tracker memories_active tracker _op_index assertEqual len tracker memories_reserved tracker _op_index assertTrue len tracker _markers == assertTrue tracker _cur_module_name = assertTrue hasattr tracker _num_alloc_retries __name__ == __main__ run_tests