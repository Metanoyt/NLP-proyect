mypy allow-untyped-defs operator warnings collections abc Callable Iterable typing TypeVar typing_extensions ParamSpec torch torch fx _symbolic_trace _assert_is_none torch fx experimental migrate_gradual_types constraint ApplyBroadcasting BinConstraintD BinConstraintT CalcConv CalcMaxPool CalcProduct CanReshape Conj DGreatestUpperBound Disj DVar F GetItem GetItemTensor IndexSelect T TGreatestUpperBound Transpose TVar torch fx experimental migrate_gradual_types operation op_add op_consistency op_div op_eq op_gt op_leq op_lt op_matching op_mul op_neq op_precision op_sub torch fx experimental migrate_gradual_types util gen_bvar gen_dvar gen_nat_constraints gen_tensor_dims gen_tvar torch fx node Node Target torch fx tensor_type Dyn TensorType torch nn modules batchnorm BatchNorm d torch nn modules conv Conv d _T = TypeVar _T _P = ParamSpec _P _INFERENCE_RULES dict Target Callable = MAX_TENSOR_RANK = __all__ = ConstraintGenerator adaptive_inference_rule add_layer_norm_constraints add_linear_constraints arange_inference_rule assert_inference_rule batchnorm_inference_rule bmm_inference_rule broadcasting_inference_rule conv d_inference_rule cumsum_inference_rule embedding_inference_rule embedding_inference_rule_functional eq_inference_rule equality_inference_rule expand_inference_rule flatten_inference_rule full_inference_rule gen_broadcasting_constraints gen_embedding_rules gen_layer_norm_constraints generate_flatten_constraints get_attr_inference_rule getitem_inference_rule gt_inference_rule index_select_inference_rule layer_norm_functional layer_norm_inference_rule linear_constraints linear_inference_rule lt_inference_rule masked_fill_inference_rule maxpool_inference_rule neq_inference_rule range_check register_inference_rule relu_inference_rule reshape_inference_rule size_inference_rule tensor_inference_rule torch_dim_inference_rule torch_linear_inference_rule transpose_inference_rule type_inference_rule view_inference_rule register_inference_rule call_target Target - Callable Callable _P _T Callable _P _T register fn Callable _P _T - Callable _P _T call_target _INFERENCE_RULES raise RuntimeError f Inference rule already registered call_target _INFERENCE_RULES call_target = fn fn register generate_flatten_constraints start_dim end_dim input flattened n counter d counter = gen_tensor_dims n counter c = BinConstraintT input TensorType d op_eq start_dim = n start_dim == - abs start_dim end_dim = n + end_dim + end_dim end_dim + c = CalcProduct start_dim end_dim flattened d nat_constraints = gen_nat_constraints d Conj c c nat_constraints counter register_inference_rule getattr get_attr_inference_rule n Node symbols constraints counter If attribute device then tensor shape preserved assert isinstance n args Node assert isinstance n args str output counter = gen_tvar counter symbols n = output input = symbols n args attr = n args attr == device BinConstraintT input output op_eq counter raise NotImplementedError Not yet implemented register_inference_rule torch bmm bmm_inference_rule n Node symbols constraints counter Constraints match input size tensor switch dimensions according rules batch multiplication assert isinstance n args Node assert isinstance n args Node bmm_output counter = gen_tvar counter symbols n = bmm_output bmm_input = symbols n args bmm_input = symbols n args dims_input counter = gen_tensor_dims counter dims_input counter = gen_tensor_dims counter inputs_dyn = Conj BinConstraintT bmm_input Dyn op_eq BinConstraintT bmm_input Dyn op_eq BinConstraintT bmm_output Dyn op_eq input _dyn = Conj BinConstraintT bmm_input Dyn op_eq BinConstraintT bmm_input TensorType dims_input op_eq BinConstraintT bmm_output TensorType dims_input Dyn dims_input op_eq input _dyn = Conj BinConstraintT bmm_input Dyn op_eq BinConstraintT bmm_input TensorType dims_input op_eq BinConstraintT bmm_output TensorType dims_input dims_input Dyn op_eq consistency_constraints = BinConstraintD dims_input dims_input op_consistency batch_size counter = gen_dvar counter inputs_are_tensors = Conj BinConstraintT bmm_input TensorType dims_input op_eq BinConstraintT bmm_input TensorType dims_input op_eq BinConstraintT bmm_output TensorType batch_size dims_input dims_input op_eq consistency_constraints DGreatestUpperBound batch_size dims_input dims_input Disj inputs_dyn input _dyn input _dyn inputs_are_tensors counter register_inference_rule index_select index_select_inference_rule n Node symbols constraints counter We constrain second argument vector Dyn The output replaces input shape vector position given index first argument print n args assert isinstance n args Node assert isinstance n args int assert isinstance n args Node index_select counter = gen_tvar counter symbols n = index_select dims counter = gen_tensor_dims counter equality constraint is_size_ = BinConstraintT symbols n args TensorType dims op_eq is_dyn = BinConstraintT symbols n args Dyn op_eq c = Conj is_size_ Disj IndexSelect i + symbols n args dims n args index_select i range MAX_TENSOR_RANK c = Conj is_dyn Disj IndexSelect i + symbols n args Dyn n args index_select i range MAX_TENSOR_RANK Disj c c counter register_inference_rule expand expand_inference_rule n Node symbols constraints counter We generate exact constraints we do tensor additions we constraint rank expression equal len n args so only those cases get considered output assert isinstance n args Node define output expand expand counter = gen_tvar counter symbols n = expand since we do have two nodes here we will construct argument variable e = symbols n args e counter = gen_tvar counter e _nat_constraints = arg n args assert isinstance arg Node int isinstance arg Node assert isinstance symbols arg DVar e _nat_constraints append BinConstraintD symbols arg op_leq e _constraint = BinConstraintT e TensorType arg isinstance arg int symbols arg arg n args op_eq constraints counter = gen_broadcasting_constraints e e symbols counter expand constraint output size dims counter = gen_tensor_dims len n args counter nat_constraints = gen_nat_constraints dims c = BinConstraintT expand TensorType dims op_eq nat_constraints e _constraint e _nat_constraints constraints += c constraints counter register_inference_rule torch nn functional gelu register_inference_rule torch nn functional dropout register_inference_rule torch nn functional softmax register_inference_rule detach register_inference_rule register_inference_rule int register_inference_rule long register_inference_rule contiguous register_inference_rule torch ones register_inference_rule torch zeros equality_inference_rule n Node symbols constraints counter We generate constraint input = output output counter = gen_tvar counter symbols n = output isinstance n args Node input = symbols n args isinstance input TVar BinConstraintT input output op_eq counter then we have dimension variables arg n args assert isinstance symbols arg DVar my_size = symbols arg arg n args BinConstraintT output TensorType my_size op_eq counter isinstance n args tuple then tuple size assert len n args = my_size = symbols arg arg n args BinConstraintT output TensorType my_size op_eq counter raise NotImplementedError Method yet implemented register_inference_rule transpose transpose_inference_rule n Node symbols constraints counter Can considered sequence two index selects so we generate constraints accordingly assert isinstance n args Node assert isinstance n args int assert isinstance n args int output counter = gen_tvar counter symbols n = output from_arg = symbols n args assert isinstance from_arg TVar input output dyn is_dyn = Conj BinConstraintT from_arg Dyn op_eq BinConstraintT output Dyn op_eq input tensor we actually do replacement c = Disj Transpose i + from_arg n args n args output i range MAX_TENSOR_RANK Disj is_dyn c counter register_inference_rule type_as type_inference_rule n Node symbols constraints counter We generate constraint input = output assert isinstance n args Node assert isinstance n args Node output counter = gen_tvar counter symbols n = output from_arg = symbols n args to_arg = symbols n args assert isinstance from_arg TVar assert isinstance to_arg TVar BinConstraintT from_arg to_arg op_consistency BinConstraintT output to_arg op_eq counter register_inference_rule masked_fill_ masked_fill_inference_rule n Node symbols constraints counter Similar addition For now we implement constraints when argument boolean tensor There also case when condition We will leave out now assert isinstance n args Node assert isinstance n args Node We will retrieve type variables symbol table confirm they tensor variables e = symbols n args e = symbols n args isinstance e TVar isinstance e TVar masked_fill_tensor counter = gen_tvar counter symbols n = masked_fill_tensor gen_broadcasting_constraints e e symbols counter masked_fill_tensor raise NotImplementedError Not yet implemented register_inference_rule torch nn functional embedding embedding_inference_rule_functional n Node symbols constraints counter assert isinstance n args Node embedding_dim_weights = symbols n args will treat static shape So we will use matching weight_dims counter = gen_tensor_dims counter equality_constraint = BinConstraintT embedding_dim_weights TensorType weight_dims op_eq embedding_dim = weight_dims constraints counter = gen_embedding_rules n symbols embedding_dim counter equality_constraint + constraints counter register_inference_rule torch nn modules sparse Embedding embedding_inference_rule n Node module_instance symbols constraints counter The output shape differs input shape last dimension assert isinstance n args Node gen_embedding_rules n symbols module_instance embedding_dim counter gen_embedding_rules n Node symbols embedding_dim counter embedding_output counter = gen_tvar counter symbols n = embedding_output embedding_input = symbols n args input_dyn = BinConstraintT embedding_input Dyn op_eq output_dyn = BinConstraintT embedding_output Dyn op_eq c = Conj input_dyn output_dyn c = i range MAX_TENSOR_RANK new_dims counter = gen_tensor_dims i counter nat_constraints = gen_nat_constraints new_dims we consider all tensor sizes append embedding_dim end output dimension all cases c_tensor_i = Conj BinConstraintT embedding_input TensorType new_dims op_eq BinConstraintT embedding_output TensorType new_dims + embedding_dim op_eq + nat_constraints c append c_tensor_i Disj c Disj c counter register_inference_rule torch tensor tensor_inference_rule n Node symbols constraints counter If tensor scalar we will skip since we do support scalars yet We will add support future s needed For our examples so far scalars needed counter register_inference_rule reshape register_inference_rule view view_inference_rule n Node symbols constraints counter Similar reshape extra condition strides assert isinstance n args Node generate new variable my_view counter = gen_tvar counter symbols n = my_view src_var = symbols n args t = symbols elem isinstance elem Node elem elem n args target shape t _type = num_constraints = t t t == - var counter = gen_dvar counter t _type append var pyrefly ignore bad-argument-type num_constraints append BinConstraintD var Dyn op_neq pyrefly ignore bad-argument-type num_constraints append BinConstraintD t Dyn op_neq t _type append t type ignore arg-type t _type = TensorType t _type type ignore assignment c = BinConstraintT my_view t _type op_eq c = CanReshape src_var t _type TODO add extra check mentioned here https pytorch org docs stable generated torch Tensor view html#torch Tensor view c c + num_constraints counter type ignore operator register_inference_rule size size_inference_rule n Node symbols constraints counter The constraint just lhs = rhs Ex size = input_ids size len n args == generate new variable size counter = gen_tvar counter symbols n = size input = symbols n args c = BinConstraintT input size op_eq c counter len n args == TODO review rule should input = dyn output = dyn included here isinstance n args int generate new variable size_index counter = gen_dvar counter symbols n = size_index input = symbols n args c = GetItem i + n args size_index input i range MAX_TENSOR_RANK c = BinConstraintD size_index op_leq input_dyn = BinConstraintT input Dyn op_eq output_dyn = BinConstraintD size_index Dyn op_eq c = Conj input_dyn output_dyn Disj c Conj Disj c c counter raise NotImplementedError raise NotImplementedError range_check i n Checks index i within range size n list Args i index n list size Returns Boolean i = T i n F T i = n F register_inference_rule torch cumsum cumsum_inference_rule n Node symbols constraints counter Input output shapes should equal We should verify index valid assert isinstance n args Node arg_ = n args len n args n kwargs dim assert isinstance arg_ int output counter = gen_tvar counter symbols n = output input = symbols n args input_dyn = BinConstraintT input Dyn op_eq output_dyn = BinConstraintT output Dyn op_eq c = Conj input_dyn output_dyn c = i range MAX_TENSOR_RANK + new_dims counter = gen_tensor_dims i counter nat_constraints = gen_nat_constraints new_dims c_tensor_i = Conj BinConstraintT input TensorType new_dims op_eq BinConstraintT output TensorType new_dims op_eq + range_check arg_ i + nat_constraints c append c_tensor_i dyn_or_tensor = Disj c Disj c dyn_or_tensor counter register_inference_rule _assert_is_none assert_inference_rule n Node symbols constraints counter assert len n users == counter register_inference_rule operator getitem getitem_inference_rule n Node symbols constraints counter assert isinstance n args Node dimension output case isinstance n args int create store new dimension variable get_item_output counter = gen_dvar counter symbols n = get_item_output retrieve arg variables get_item_arg = symbols n args assert isinstance get_item_arg TVar input dynamic we accept any index dynamic dimension output input_dyn = BinConstraintT get_item_arg Dyn op_eq output_dyn = BinConstraintD get_item_output Dyn op_eq c = Conj input_dyn output_dyn input tensor generate getItem constraint which will expanded based tensor dimension c = GetItem i + n args get_item_output get_item_arg i range MAX_TENSOR_RANK since output dimension we make sure s natural number added conjunction disjunction c c = BinConstraintD get_item_output op_leq Disj c Conj Disj c c counter tensor output case isinstance n args tuple create store new tensor variable get_item_output counter = gen_tvar counter type ignore arg-type assignment symbols n = get_item_output retrieve arg variables n args symbols get_item_arg = symbols n args assert isinstance get_item_arg TVar input_dyn = BinConstraintT get_item_arg Dyn op_eq output_dyn = BinConstraintT get_item_output Dyn op_eq type ignore assignment c = Conj input_dyn output_dyn c = GetItemTensor i + n args get_item_output get_item_arg type ignore misc i range MAX_TENSOR_RANK TODO we should figure out why there key-error here counter Disj c c counter raise RuntimeError Method yet implemented register_inference_rule operator gt gt_inference_rule n Node symbols constraints counter assert isinstance n args Node int assert isinstance n args Node int We make sure node will used again We do generate constraint about node Only about operands e = symbols n args isinstance n args Node n args e = symbols n args isinstance n args Node n args isinstance n args Node isinstance n args Node isinstance e TVar isinstance e TVar gt_tensor counter = gen_tvar counter symbols n = gt_tensor gen_broadcasting_constraints e e symbols counter gt_tensor isinstance e DVar isinstance e DVar This meant used flow analysis only gt_constraint = BinConstraintD e e op_gt my_gt counter = gen_bvar counter equality_constraint = BinConstraintD my_gt gt_constraint op_eq equality_constraint counter raise RuntimeError Sort Mismatch isinstance n args Node isinstance n args Node isinstance e DVar This meant used flow analysis only gt_constraint = BinConstraintD e e op_gt my_gt counter = gen_bvar counter equality_constraint = BinConstraintD my_gt gt_constraint op_eq equality_constraint counter isinstance e TVar isinstance e int then we made wrong assumption about argument being tensor so we should fix assumption warnings warn f Made wrong assumption node n Correctness guaranteed new_e counter = gen_dvar counter symbols n args = new_e symbols n args gt_constraint = BinConstraintD new_e e op_gt my_gt counter = gen_bvar counter equality_constraint = BinConstraintD my_gt gt_constraint op_eq equality_constraint counter raise NotImplementedError Method yet implemented raise NotImplementedError Method yet implemented register_inference_rule operator eq eq_inference_rule n Node symbols constraints counter assert isinstance n args Node int assert isinstance n args Node int e = symbols n args isinstance n args Node n args e = symbols n args isinstance n args Node n args isinstance n args Node isinstance n args Node isinstance e TVar isinstance e TVar eq_tensor counter = gen_tvar counter symbols n = eq_tensor gen_broadcasting_constraints e e symbols counter eq_tensor isinstance e DVar isinstance e DVar This meant used flow analysis only eq_constraint = BinConstraintD e e op_eq my_eq counter = gen_bvar counter equality_constraint = BinConstraintD my_eq eq_constraint op_eq equality_constraint counter raise RuntimeError Sort Mismatch isinstance n args Node isinstance n args Node isinstance e DVar This meant used flow analysis only eq_constraint = BinConstraintD e e op_eq my_eq counter = gen_bvar counter equality_constraint = BinConstraintD my_eq eq_constraint op_eq equality_constraint counter raise NotImplementedError Method yet implemented raise NotImplementedError Method yet implemented register_inference_rule operator ne neq_inference_rule n Node symbols constraints counter Translates inconsistent gradual types To prove inequality we should prove tensors either different sizes disagree least one dimension This WIP works when condition false We working making operation work when condition true well assert isinstance n args Node assert isinstance n args tuple implementing size len n args == assert isinstance n args Node int assert isinstance n args Node int assert isinstance n args Node int lhs = symbols n args b counter = gen_tensor_dims counter input_is_size = BinConstraintT lhs TensorType b b b op_eq d = n args isinstance n args int symbols n args d = n args isinstance n args int symbols n args d = n args isinstance n args int symbols n args dimensions equal my_ne counter = gen_bvar counter neq_ = BinConstraintD d b op_neq neq_ = BinConstraintD d b op_neq neq_ = BinConstraintD d b op_neq dimensions inconsistent dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Disj dims_inconsistent dims_inconsistent dims_inconsistent we covering size only now ne_constraint = Conj input_is_size dims_inconsistent my_ne counter = gen_bvar counter equality_constraint = BinConstraintD my_ne ne_constraint op_eq len n args == assert isinstance n args Node int assert isinstance n args Node int assert isinstance n args Node int assert isinstance n args Node int lhs = symbols n args b counter = gen_dvar counter b counter = gen_dvar counter b counter = gen_dvar counter b counter = gen_dvar counter input_is_size = BinConstraintT lhs TensorType b b b b op_eq d = n args isinstance n args int symbols n args d = n args isinstance n args int symbols n args d = n args isinstance n args int symbols n args d = n args isinstance n args int symbols n args dimensions equal my_ne counter = gen_bvar counter neq_ = BinConstraintD d b op_neq neq_ = BinConstraintD d b op_neq neq_ = BinConstraintD d b op_neq neq_ = BinConstraintD d b op_neq dimensions inconsistent dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Conj BinConstraintD d Dyn op_neq BinConstraintD b Dyn op_neq neq_ dims_inconsistent = Disj dims_inconsistent dims_inconsistent dims_inconsistent dims_inconsistent ne_constraint = Conj input_is_size dims_inconsistent my_ne counter = gen_bvar counter equality_constraint = BinConstraintD my_ne ne_constraint op_eq raise NotImplementedError Method yet implemented equality_constraint counter register_inference_rule operator lt lt_inference_rule n Node symbols constraints counter assert isinstance n args Node int assert isinstance n args Node int We make sure node will used again We do generate constraint about node Only about operands e = symbols n args isinstance n args Node n args e = symbols n args isinstance n args Node n args isinstance n args Node isinstance n args Node isinstance e TVar isinstance e TVar lt_tensor counter = gen_tvar counter symbols n = lt_tensor gen_broadcasting_constraints e e symbols counter lt_tensor isinstance e DVar isinstance e DVar This meant used flow analysis only lt_constraint = BinConstraintD e e op_lt my_lt counter = gen_bvar counter equality_constraint = BinConstraintD my_lt lt_constraint op_eq equality_constraint counter raise RuntimeError Sort Mismatch isinstance n args Node isinstance n args Node isinstance e DVar This meant used flow analysis only lt_constraint = BinConstraintD e e op_lt my_lt counter = gen_bvar counter equality_constraint = BinConstraintD my_lt lt_constraint op_eq equality_constraint counter raise NotImplementedError Method yet implemented raise NotImplementedError Method yet implemented register_inference_rule torch full full_inference_rule n Node symbols constraints counter full counter = gen_tvar counter symbols n = full res = assert isinstance n args Iterable arg n args dim = arg isinstance arg int symbols arg res append dim c = BinConstraintT full TensorType list res op_eq type ignore arg-type c counter TODO normalize index register_inference_rule torch arange arange_inference_rule n Node symbols constraints counter start = step = len n args == end = symbols n args raise NotImplementedError Not yet implemented int end - start step d counter = gen_dvar counter size_constraint = BinConstraintD d BinConstraintD BinConstraintD end start op_sub step op_div op_eq arange counter = gen_tvar counter symbols n = arange either parameter number Dyn c = Disj BinConstraintD end Dyn op_eq BinConstraintD start Dyn op_eq BinConstraintD step Dyn op_eq c = BinConstraintD d Dyn op_eq both_dyn = Conj c c c = Conj BinConstraintD end Dyn op_neq BinConstraintD start Dyn op_neq BinConstraintD step Dyn op_neq c = BinConstraintD d Dyn op_neq both_numbers = Conj c c size_constraint BinConstraintT arange TensorType d op_eq Disj both_dyn both_numbers counter gen_broadcasting_constraints e e symbols counter output_var additional vars don t correspond expressions e counter = gen_tvar counter e counter = gen_tvar counter generate constraints c = TGreatestUpperBound output_var e e c = ApplyBroadcasting e e e e c = BinConstraintT e e op_consistency c c c counter register_inference_rule operator mul register_inference_rule torch ne register_inference_rule ne register_inference_rule torch add register_inference_rule operator add broadcasting_inference_rule n Node symbols constraints counter op_code = None n target operator add n target torch add op_code = op_add n target operator mul op_code = op_mul isinstance n args Node isinstance n args Node isinstance symbols n args TVar isinstance symbols n args TVar my_output counter = gen_tvar counter symbols n = my_output e = symbols n args e = symbols n args gen_broadcasting_constraints e e symbols counter my_output raise NotImplementedError Method yet implemented isinstance n args Node isinstance n args int float isinstance symbols n args TVar my_output counter = gen_tvar counter symbols n = my_output e = symbols n args BinConstraintT my_output e op_eq counter isinstance symbols n args DVar my_output counter = gen_dvar counter type ignore arg-type assignment symbols n = my_output e = symbols n args we will propagate runtime value here since regular addition c = Conj BinConstraintD my_output BinConstraintD e n args op_code op_eq BinConstraintD my_output op_leq c counter isinstance n args Node isinstance n args int float isinstance symbols n args TVar my_output counter = gen_tvar counter symbols n = my_output e = symbols n args BinConstraintT my_output e op_eq counter isinstance symbols n args DVar my_output counter = gen_dvar counter type ignore arg-type assignment symbols n = my_output e = symbols n args we will propagate runtime value here since regular addition c = Conj BinConstraintD my_output BinConstraintD e n args op_code op_eq BinConstraintD my_output op_leq c counter raise NotImplementedError Method yet implemented TODO generate add constraints scalar addition raise NotImplementedError Addition yet implemented register_inference_rule torch flatten flatten_inference_rule n Node symbols constraints counter assert isinstance n args Node generate new variable flattened counter = gen_tvar counter symbols n = flattened input = symbols n args set default start end dims start_dim = end_dim = - len n args assert isinstance n args int start_dim = n args len n args assert isinstance n args int end_dim = n args c = BinConstraintT input Dyn op_eq c = BinConstraintT flattened Dyn op_eq both_dyn = Conj c c const = i range MAX_TENSOR_RANK + c counter = generate_flatten_constraints start_dim end_dim input flattened i counter const append c Disj both_dyn const counter register_inference_rule torch nn functional layer_norm layer_norm_functional n Node symbols constraints counter We generate constraint input = output assert isinstance n args Node gen_layer_norm_constraints n n args symbols counter register_inference_rule torch nn LayerNorm layer_norm_inference_rule n Node module_instance symbols constraints counter Input output shapes should equal Input should consistent normalized_shape assert isinstance n args Node gen_layer_norm_constraints n module_instance normalized_shape symbols counter gen_layer_norm_constraints n Node normalized_shape symbols counter output counter = gen_tvar counter symbols n = output input = symbols n args input_dyn = BinConstraintT input Dyn op_eq output_dyn = BinConstraintT output Dyn op_eq c = Conj input_dyn output_dyn c = i range MAX_TENSOR_RANK + new_dims_rhs counter = gen_tensor_dims i counter nat_constraints = gen_nat_constraints new_dims_rhs c_tensor_i = Conj BinConstraintT input TensorType new_dims_rhs op_eq BinConstraintT output TensorType new_dims_rhs op_eq + add_layer_norm_constraints new_dims_rhs list normalized_shape + nat_constraints c append c_tensor_i Disj c Disj c counter register_inference_rule torch nn Dropout register_inference_rule torch nn ReLU relu_inference_rule n Node module_instance symbols constraints counter Input output shapes should equal assert isinstance n args Node output counter = gen_tvar counter symbols n = output input = symbols n args assert isinstance input TVar BinConstraintT input output op_eq counter register_inference_rule torch nn Linear linear_inference_rule n Node module_instance symbols constraints counter Input output sizes should same except last dimension If input Dyn then so should output assert isinstance n args Node linear_constraints n module_instance in_features module_instance out_features symbols counter register_inference_rule dim torch_dim_inference_rule n Node symbols constraints counter assert isinstance n args Node my_dim counter = gen_dvar counter symbols n = my_dim input = symbols n args input_dyn = BinConstraintT input Dyn op_eq output_dyn = BinConstraintD my_dim Dyn op_eq c = i range MAX_TENSOR_RANK + new_dims_rhs_ counter = gen_tensor_dims i counter c_tensor_i = Conj BinConstraintT input TensorType new_dims_rhs_ op_eq BinConstraintD my_dim i op_eq c append c_tensor_i Disj Conj input_dyn output_dyn Disj c counter register_inference_rule torch _C _nn linear torch_linear_inference_rule n Node symbols constraints counter assert isinstance n args Node weight_dims counter = gen_tensor_dims counter equality_constraint = BinConstraintT symbols n args TensorType weight_dims op_eq constraints counter = linear_constraints n weight_dims weight_dims symbols counter equality_constraint + constraints counter linear_constraints n Node in_features out_features symbols counter linear_output counter = gen_tvar counter symbols n = linear_output linear_input = symbols n args input_dyn = BinConstraintT linear_input Dyn op_eq output_dyn = BinConstraintT linear_output Dyn op_eq c = Conj input_dyn output_dyn c = i range MAX_TENSOR_RANK + new_dims_rhs_ counter = gen_tensor_dims i counter new_dims_rhs_ counter = gen_tensor_dims i counter nat_constraints = gen_nat_constraints new_dims_rhs_ + new_dims_rhs_ c_tensor_i = Conj BinConstraintT linear_input TensorType new_dims_rhs_ op_eq BinConstraintT linear_output TensorType new_dims_rhs_ op_eq + add_linear_constraints new_dims_rhs_ new_dims_rhs_ in_features out_features + nat_constraints c append c_tensor_i Disj c Disj c counter add_layer_norm_constraints input_dim normalized_dim The constraints say type has te form while normalized_dim have form Args input_dim Input shape layer norm normalized_dim normalized_dim parameter module instance case we false since there s pattern mismatch len normalized_dim len input_dim F constraints = i n zip reversed input_dim reversed normalized_dim constraints append BinConstraintD i n op_consistency constraints add_linear_constraints dims dims in_features out_features assert len dims == len dims constraints = i range len dims i == len dims - constraints append BinConstraintD dims i in_features op_consistency constraints append BinConstraintD dims i out_features op_eq constraints append BinConstraintD dims i dims i op_eq constraints register_inference_rule torch reshape reshape_inference_rule n Node symbols constraints counter assert isinstance n args Node generate new variable my_reshape counter = gen_tvar counter symbols n = my_reshape src_var = symbols n args t = n args t _type = TensorType Dyn elem == - elem elem t type ignore union-attr c = BinConstraintT my_reshape t _type op_eq type ignore union-attr c = CanReshape src_var t _type c c counter register_inference_rule BatchNorm d batchnorm_inference_rule n Node module_instance symbols constraints counter assert isinstance n args Node generate new variable batchnorm_output counter = gen_tvar counter symbols n = batchnorm_output batchnorm_input = symbols n args dim vars d counter = gen_dvar counter d counter = gen_dvar counter d counter = gen_dvar counter d counter = gen_dvar counter nat_constraints = gen_nat_constraints d d d d c = BinConstraintT batchnorm_input TensorType d d d d op_matching c = BinConstraintT batchnorm_input batchnorm_output op_eq c c nat_constraints counter register_inference_rule torch nn AdaptiveAvgPool d adaptive_inference_rule n Node module_instance symbols constraints counter assert isinstance n args Node avg_pool counter = gen_tvar counter symbols n = avg_pool input_var = symbols n args dim vars d counter = gen_dvar counter d counter = gen_dvar counter d counter = gen_dvar counter d counter = gen_dvar counter nat_constraints = gen_nat_constraints d d d d c = BinConstraintT input_var TensorType d d d d op_matching c = BinConstraintT avg_pool TensorType d d module_instance output_size module_instance output_size op_eq c c nat_constraints counter register_inference_rule Conv d conv d_inference_rule n Node module_instance symbols constraints counter assert isinstance n args Node my_conv counter = gen_tvar counter symbols n = my_conv input_var = symbols n args dim vars d d d d counter = gen_tensor_dims MAX_TENSOR_RANK counter c = Matching input_var TensorType d d d d c = BinConstraintT input_var TensorType d d d d op_matching c = DConsistency module_instance in_channels d c = BinConstraintD module_instance in_channels d op_consistency c = CalcConv my_conv input_var module_instance out_channels module_instance kernel_size module_instance padding module_instance stride module_instance dilation d d d d nat_constraints = gen_nat_constraints d d d d c c c nat_constraints counter register_inference_rule torch nn MaxPool d maxpool_inference_rule n Node module_instance symbols constraints counter assert isinstance n args Node maxpool counter = gen_tvar counter symbols n = maxpool input_var = symbols n args dim vars d d d d counter = gen_tensor_dims MAX_TENSOR_RANK counter c = BinConstraintT input_var TensorType d d d d op_matching c = CalcMaxPool maxpool input_var module_instance kernel_size module_instance padding module_instance stride module_instance dilation d d d d nat_constraints = gen_nat_constraints d d d d c c nat_constraints counter ConstraintGenerator __init__ traced graph=None traced = traced traced tracer root traced_params = dict traced named_parameters constraints = symbol_dict = graph = traced graph hasattr traced graph graph generate_constraints counter= Iterate through every node generate constraints Effect constraints will populated final constraints graph = graph all_constraints = pyrefly ignore missing-attribute n graph nodes constraints counter = generate_constraints_node n counter all_constraints += constraints Conj all_constraints counter generate_constraints_node n Node counter Generate constraints given node Currently supported operations - Reshape - Add - conv d n op == placeholder x counter = gen_tvar counter symbol_dict n = x my_type = n type n type = Dyn isinstance n type TensorType n type == torch nn parameter Parameter since we have parameter shape must static assert example_value n meta my_type = TensorType n meta example_value size my_type = Dyn c = BinConstraintT my_type x op_precision c = BinConstraintT x MAX_TENSOR_RANK op_leq c c counter n op == call_function n target _INFERENCE_RULES _INFERENCE_RULES n target n symbol_dict constraints counter raise RuntimeError f No inference rule registered target n target n op == call_module module_instance = traced get_submodule n target type module_instance _INFERENCE_RULES _INFERENCE_RULES type module_instance n module_instance symbol_dict constraints counter raise RuntimeError f No inference rule registered type module_instance n op == call_method n target _INFERENCE_RULES _INFERENCE_RULES n target n symbol_dict constraints counter raise RuntimeError f No inference rule registered target n target n op == get_attr t = traced_params get n target None isinstance t torch Tensor len t shape res = list t shape attr_type = TensorType res output counter = gen_tvar counter symbol_dict n = output BinConstraintT output attr_type op_eq counter scalar counter counter n op == output counter raise NotImplementedError f Method n op yet implemented