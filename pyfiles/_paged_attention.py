mypy allow-untyped-defs This module implements Paged Attention top flex_attention This module experimental subject change typing Optional Union torch torch nn attention flex_attention _identity _mask_mod_signature _score_mod_signature BlockMask noop_mask __all__ = PagedAttention _cdiv x Union int float torch Tensor multiple Union int float torch Tensor x + multiple - multiple PagedAttention PagedAttention supports flex attention inference large batch size With PagedAttention batch key value tensors varying kv length split into tensor blocks fixed length cached compact way Thus we can avoid redundant memory consumption due varying kv length support larger batch size __init__ n_pages int page_size int max_batch_size int device str = cuda number pages n_pages = n_pages number tokens per page page_size = page_size page table batch logical_block_idx - physical_page_idx page_table = -torch ones max_batch_size n_pages dtype=torch int device=device capacity batch_idx - allocated sequence length capacity = torch zeros max_batch_size dtype=torch int device=device index empty pages available allocation empty_pages = list range n_pages - - - mapping physical page index logical page index physical_to_logical = -torch ones max_batch_size n_pages dtype=torch int device=device reserve batch_idx torch Tensor seq_len torch Tensor - None Requests capacity given batch least enough hold ` seq_len ` elements Args batch_idx Tensor batch index reserved shape math ` ` seq_len Tensor minimum capacity given batch shape math ` ` seq_len = capacity batch_idx num_pages_to_allocate = _cdiv seq_len - capacity batch_idx page_size assert len empty_pages = num_pages_to_allocate f requested num_pages_to_allocate item pages f there only len empty_pages empty pages start_page_idx = capacity batch_idx page_size end_page_idx = start_page_idx + num_pages_to_allocate find empty physical pages allocated_pages = torch tensor empty_pages -num_pages_to_allocate device=num_pages_to_allocate device empty_pages = empty_pages -num_pages_to_allocate update page table page_table batch_idx start_page_idx end_page_idx = allocated_pages update metadata physical_to_logical batch_idx allocated_pages = torch arange start_page_idx item end_page_idx item device=num_pages_to_allocate device capacity batch_idx += num_pages_to_allocate page_size erase batch_idx torch Tensor - None Removes single batch paged attention Args batch_idx Tensor batch index removed shape math ` ` find allocated pages allocated_page_idx = page_table batch_idx = - allocated_pages = page_table batch_idx allocated_page_idx clean metadata capacity batch_idx = empty_pages += allocated_pages tolist physical_to_logical batch_idx allocated_pages = - page_table batch_idx = - assign batch_idx torch Tensor input_pos torch Tensor k_val torch Tensor v_val torch Tensor k_cache torch Tensor v_cache torch Tensor - None Assigns new contents ` val ` storage ` cache ` location ` batch_idx ` ` input_pos ` Args batch_idx Tensor batch index shape math ` B ` input_pos Tensor input positions assigned given batch shape math ` B S ` val Tensor value assigned shape math ` B H S D ` cache Tensor cache store values shape ` H MAX_S D ` k_val requires_grad raise RuntimeError val must require gradient B H S K_D = k_val shape V_D = v_val shape B = batch_idx shape raise RuntimeError f Expect val batch_idx have same batch size f got B= B B= batch_idx shape H = k_cache shape raise RuntimeError f Expect val cache has same number heads f got H= H H= k_cache shape S = input_pos shape raise RuntimeError f Expect val input_pos has same length f got S= S S= input_pos shape K_D = k_cache shape raise RuntimeError f Expect k_val k_cache has same hidden dim f got D= K_D D= k_cache shape V_D = v_cache shape raise RuntimeError f Expect v_val v_cache has same hidden dim f got D= V_D D= v_cache shape find address logical_block_idx = input_pos page_size B S logical_block_offset = input_pos page_size B S physical_block_idx = torch gather page_table batch_idx logical_block_idx torch int torch int B S addr = physical_block_idx page_size + logical_block_offset view - B S k_val = k_val permute contiguous view H B S K_D v_val = v_val permute contiguous view H B S V_D k_cache addr = k_val v_cache addr = v_val convert_logical_block_mask block_mask BlockMask batch_idx Optional torch Tensor = None kv_len Optional torch Tensor = None - BlockMask Converts logical block mask mapping its logical kv indices corresponding physical kv indices Args block_mask BlockMask logical block mask kv_indices shape math ` B H ROWS MAX_BLOCKS_IN_COL ` batch_idx Tensor batch index corresponding block_mask batch dimension This provides flexibility convert block mask smaller batch size than page table shape math ` B ` kv_len Optional Tensor actual KV sequence length upper bound check shape math ` B ` handle multiple batches B H ROWS MAX_BLOCKS_IN_COL = block_mask kv_indices shape block_mask BLOCK_SIZE = page_size raise RuntimeError f Expect block_mask has same column block size page_size f got size= block_mask BLOCK_SIZE size= page_size Increase num columns converted block mask logical block mask s num columns n_pages since converted block mask may have larger indices values b ` _ordered_to_dense ` realizes dense tensor these converted indices There would IndexError using logical block mask s num columns device = block_mask kv_num_blocks device batch_idx None batch_idx = torch arange B device=device page_table = page_table batch_idx new_kv_num_blocks = block_mask kv_num_blocks clone new_kv_indices = torch zeros B H ROWS n_pages dtype=torch int device=device new_kv_indices MAX_BLOCKS_IN_COL = torch gather page_table block_mask kv_indices view B - torch int view block_mask kv_indices shape torch int new_full_kv_indices new_full_kv_num_blocks = None None block_mask full_kv_num_blocks None assert block_mask full_kv_indices None new_full_kv_num_blocks = block_mask full_kv_num_blocks clone new_full_kv_indices = torch zeros B H ROWS n_pages dtype=torch int device=device new_full_kv_indices MAX_BLOCKS_IN_COL = torch gather page_table block_mask full_kv_indices view B - torch int view block_mask full_kv_indices shape torch int new_mask_mod = get_mask_mod block_mask mask_mod kv_len seq_lengths = block_mask seq_lengths n_pages page_size BlockMask from_kv_blocks new_kv_num_blocks new_kv_indices new_full_kv_num_blocks new_full_kv_indices block_mask BLOCK_SIZE new_mask_mod seq_lengths=seq_lengths get_mask_mod mask_mod Optional _mask_mod_signature kv_len Optional torch Tensor = None - _mask_mod_signature Converts mask_mod based mapping physical block index logical block index Args mask_mod _mask_mod_signature mask_mod based logical block index kv_len Optional torch Tensor actual KV sequence length upper bound check mask_mod None mask_mod = noop_mask new_mask_mod b torch Tensor h torch Tensor q_idx torch Tensor physical_kv_idx torch Tensor physical_kv_block = physical_kv_idx page_size physical_kv_offset = physical_kv_idx page_size logical_block_idx = physical_to_logical b physical_kv_block logical_kv_idx = logical_block_idx page_size + physical_kv_offset live_block = logical_block_idx = within_upper_bound = logical_kv_idx kv_len b kv_len None True within_lower_bound = logical_kv_idx = is_valid = live_block within_upper_bound within_lower_bound torch where is_valid mask_mod b h q_idx logical_kv_idx False new_mask_mod get_score_mod score_mod Optional _score_mod_signature kv_len Optional torch Tensor = None - _score_mod_signature Converts score_mod based mapping physical block index logical block index Args score_mod _score_mod_signature score_mod based logical block index ` kv_len Optional torch Tensor actual KV sequence length upper bound check score_mod None score_mod = _identity new_score_mod score torch Tensor b torch Tensor h torch Tensor q_idx torch Tensor physical_kv_idx torch Tensor physical_kv_block = physical_kv_idx page_size physical_kv_offset = physical_kv_idx page_size logical_block_idx = physical_to_logical b physical_kv_block logical_kv_idx = logical_block_idx page_size + physical_kv_offset live_block = logical_block_idx = within_upper_bound = logical_kv_idx kv_len b kv_len None True within_lower_bound = logical_kv_idx = is_valid = live_block within_upper_bound within_lower_bound torch where is_valid score_mod score b h q_idx logical_kv_idx float -inf new_score_mod