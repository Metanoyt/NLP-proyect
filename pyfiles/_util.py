mypy ignore-errors Assorted utilities which do need anything other then torch stdlib operator torch _dtypes_impl https github com numpy numpy blob v numpy distutils misc_util py#L -L is_sequence seq isinstance seq str False try len seq except Exception False True AxisError ValueError IndexError pass UFuncTypeError TypeError RuntimeError pass cast_if_needed tensor dtype NB no casting dtype=None dtype None tensor dtype = dtype tensor = tensor dtype tensor cast_int_to_float x cast integers bools default float dtype _dtypes_impl _category x dtype x = x _dtypes_impl default_dtypes float_dtype x replica version numpy numpy core src multiarray common h normalize_axis_index ax ndim argname=None -ndim = ax ndim raise AxisError f axis ax out bounds array dimension ndim ax ax += ndim ax https github com numpy numpy blob main numpy core numeric py#L normalize_axis_tuple axis ndim argname=None allow_duplicate=False Normalizes axis argument into tuple non-negative integer axes This handles shorthands such ` ` ` ` converts them ` ` ` ` well performing handling negative indices covered ` normalize_axis_index ` By default forbids axes being specified multiple times Used internally multi-axis-checking logic Parameters ---------- axis int iterable int The un-normalized index indices axis ndim int The number dimensions array ` axis ` should normalized against argname str optional A prefix put before error message typically name argument allow_duplicate bool optional If False default disallow axis being specified twice Returns ------- normalized_axes tuple int The normalized axis index such ` = normalized_axis ndim ` Optimization speed-up most common cases type axis tuple list try axis = operator index axis except TypeError pass Going via iterator directly slower than via list comprehension axis = tuple normalize_axis_index ax ndim argname ax axis allow_duplicate len set map int axis = len axis argname raise ValueError f repeated axis ` argname ` argument raise ValueError repeated axis axis allow_only_single_axis axis axis None axis len axis = raise NotImplementedError does handle tuple axis axis expand_shape arr_shape axis taken numpy x expand_dims function type axis list tuple axis = axis out_ndim = len axis + len arr_shape axis = normalize_axis_tuple axis out_ndim shape_it = iter arr_shape shape = ax axis next shape_it ax range out_ndim shape apply_keepdims tensor axis ndim axis None tensor scalar shape = ndim tensor = tensor expand shape contiguous shape = expand_shape tensor shape axis tensor = tensor reshape shape tensor axis_none_flatten tensors axis=None Flatten arrays axis None axis None tensors = tuple ar flatten ar tensors tensors tensors axis typecast_tensor t target_dtype casting Dtype-cast tensor target_dtype Parameters ---------- t torch Tensor The tensor cast target_dtype torch dtype object The array dtype cast all tensors casting str The casting mode see ` np can_cast ` Returns ------- ` torch Tensor ` ` target_dtype ` dtype Raises ------ ValueError argument cannot cast according ` casting ` rule can_cast = _dtypes_impl can_cast_impl can_cast t dtype target_dtype casting=casting raise TypeError f Cannot cast array data t dtype f target_dtype according rule casting cast_if_needed t target_dtype typecast_tensors tensors target_dtype casting tuple typecast_tensor t target_dtype casting t tensors _try_convert_to_tensor obj try tensor = torch as_tensor obj except Exception e mesg = f failed convert obj ndarray \nInternal error str e raise NotImplementedError mesg noqa B tensor _coerce_to_tensor obj dtype=None copy=False ndmin= The core logic array function Parameters ---------- obj tensor_like The thing coerce dtype torch dtype object None Coerce torch dtype copy bool Copy ndmin int The results least many dimensions is_weak bool Whether obj weakly typed python scalar Returns ------- tensor torch Tensor tensor object requested dtype ndim copy semantics Notes ----- This almost tensor_like coercive function Does handle wrapper ndarrays those should handled ndarray-aware layer prior invoking function isinstance obj torch Tensor tensor = obj tensor dtype pytorch default typically float If obj s elements exactly representable float we ve lost precision torch as_tensor e item - e - default_dtype = torch get_default_dtype torch set_default_dtype _dtypes_impl get_default_dtype_for torch float try tensor = _try_convert_to_tensor obj finally torch set_default_dtype default_dtype type cast requested tensor = cast_if_needed tensor dtype adjust ndim needed ndim_extra = ndmin - tensor ndim ndim_extra tensor = tensor view ndim_extra + tensor shape copy requested copy tensor = tensor clone tensor ndarrays_to_tensors inputs Convert all ndarrays ` inputs ` tensors other things intact _ndarray ndarray len inputs == ValueError len inputs == input_ = inputs isinstance input_ ndarray input_ tensor isinstance input_ tuple result = sub_input input_ sub_result = ndarrays_to_tensors sub_input result append sub_result tuple result input_ assert isinstance inputs tuple sanity check ndarrays_to_tensors inputs